{"references": [{"fullname_first_author": "Wang, J.", "paper_title": "Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration", "publication_date": "2024-06-01", "reason": "This paper is a direct predecessor to the current work, and its multi-agent framework is significantly improved upon in this work."}, {"fullname_first_author": "Zhang, C.", "paper_title": "Appagent: Multimodal agents as smartphone users", "publication_date": "2023-XX-XX", "reason": "This paper is a state-of-the-art mobile agent framework, which is used as a baseline and compared to the current work in the experiments."}, {"fullname_first_author": "Wang, J.", "paper_title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception", "publication_date": "2024-01-16", "reason": "This paper is another important baseline mobile agent system used for comparison with the current work."}, {"fullname_first_author": "Team, G.", "paper_title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context", "publication_date": "2024-03-05", "reason": "This paper introduces the Gemini language model, which is one of the backbones used for experiments in this work."}, {"fullname_first_author": "OpenAI", "paper_title": "GPT-40 System Card", "publication_date": "2024-XX-XX", "reason": "This paper introduces the GPT-40 language model, which is one of the backbones used for experiments in this work."}]}