[{"figure_path": "https://arxiv.org/html/2501.11733/x2.png", "caption": "Figure 1: We propose Mobile-Agent-E, a novel hierarchical multi-agent mobile assistant that outperforms previous state-of-the-art approaches\u00a0(Zhang et\u00a0al., 2023; Wang et\u00a0al., 2024b, a) on complex real-world tasks. Mobile-Agent-E disentangles high-level planning and low-level action decision with dedicated agents. Equipped with a newly introduced self-evolution module that learns general Tips and reusable Shortcuts from past experiences, Mobile-Agent-E demonstrates further improvements in both performance and efficiency.", "description": "\uadf8\ub9bc 1\uc740 \ubcf5\uc7a1\ud55c \uc2e4\uc81c \uc138\uacc4 \uc791\uc5c5\uc5d0\uc11c \uc774\uc804 \ucd5c\ucca8\ub2e8 \ubc29\uc2dd(Zhang et al., 2023; Wang et al., 2024b, a)\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub09c \uc0c8\ub85c\uc6b4 \uacc4\uce35\uc801 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubaa8\ubc14\uc77c \uc5b4\uc2dc\uc2a4\ud134\ud2b8\uc778 Mobile-Agent-E\ub97c \uc81c\uc548\ud569\ub2c8\ub2e4. Mobile-Agent-E\ub294 \uc804\uc6a9 \uc5d0\uc774\uc804\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uace0\uae09 \uacc4\ud68d \ubc0f \uc800\uae09 \uc791\uc5c5 \uacb0\uc815\uc744 \ubd84\ub9ac\ud569\ub2c8\ub2e4. \uc0c8\ub86d\uac8c \ub3c4\uc785\ub41c \uc790\uae30 \uc9c4\ud654 \ubaa8\ub4c8\uc744 \ud1b5\ud574 \uacfc\uac70 \uacbd\ud5d8\uc5d0\uc11c \uc77c\ubc18\uc801\uc778 \ud301\uacfc \uc7ac\uc0ac\uc6a9 \uac00\ub2a5\ud55c \ubc14\ub85c \uac00\uae30\ub97c \ud559\uc2b5\ud558\ub294 Mobile-Agent-E\ub294 \uc131\ub2a5\uacfc \ud6a8\uc728\uc131 \ubaa8\ub450 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Mobile-Agent-E\ub294 \uad00\ub9ac\uc790 \uc5d0\uc774\uc804\ud2b8, \uc778\uc9c0 \uc5d0\uc774\uc804\ud2b8, \uc6b4\uc601 \uc5d0\uc774\uc804\ud2b8, \ud589\ub3d9 \ubc18\uc601 \uc5d0\uc774\uc804\ud2b8, \ud544\uae30 \uc5d0\uc774\uc804\ud2b8\uc758 \ub2e4\uc12f \uac00\uc9c0 \uc5d0\uc774\uc804\ud2b8\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \uacc4\uce35\uc801 \uad6c\uc870\ub97c \ud1b5\ud574 \uac01 \uc5d0\uc774\uc804\ud2b8\ub294 \ud2b9\uc815 \uc5ed\ud560\uc744 \uc218\ud589\ud558\uba70,  \uc790\uae30 \uc9c4\ud654 \ubaa8\ub4c8\uc740 \uc7a5\uae30 \uae30\uc5b5\uc5d0 \ud301\uacfc \ubc14\ub85c \uac00\uae30\ub97c \uc800\uc7a5\ud558\uace0 \uc774\ub97c \ud1b5\ud574 \uc9c0\uc18d\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc774\ub8f9\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 Mobile-Agent-E\uc758 \uc544\ud0a4\ud14d\ucc98\uc640 \ub2e4\uc591\ud55c \uc791\uc5c5 \uc608\uc2dc, \uadf8\ub9ac\uace0 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ubc29\uc2dd\uacfc\uc758 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\uac00 \uc2dc\uac01\uc801\uc73c\ub85c \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.11733/x3.png", "caption": "Figure 2: An overview of the Mobile-Agent-E framework, where the Manager, Perceptor (\ud835\udc9cPsubscript\ud835\udc9c\ud835\udc43\\mathcal{A}_{P}caligraphic_A start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT), Operator, Action Reflector, and Notetaker are involved in the main agent loop for each task, while two Experience Reflectors contribute to updating long-term memory across tasks. Decision-making at each step is disentangled into high-level planning by the Manager and low-level actions by the Operator. The Action Reflector verifies the outcome of each action, tracks progress, and provides error feedback. The Notetaker aggregates important information during navigation. A detailed example illustrating one step in the agent loop and the self-evolution process is presented in Figures\u00a03 and 4.", "description": "\uadf8\ub9bc 2\ub294 Mobile-Agent-E \ud504\ub808\uc784\uc6cc\ud06c\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Manager, Perceptor(\ub370\uc774\ud130 \uc218\uc9d1 \uc5d0\uc774\uc804\ud2b8), Operator(\uc791\uc5c5 \uc2e4\ud589 \uc5d0\uc774\uc804\ud2b8), Action Reflector(\uacb0\uacfc \uac80\uc99d \uc5d0\uc774\uc804\ud2b8), Notetaker(\uc815\ubcf4 \ucde8\ud569 \uc5d0\uc774\uc804\ud2b8)\uac00 \uac01 \uc791\uc5c5\uc758 \uba54\uc778 \uc5d0\uc774\uc804\ud2b8 \ub8e8\ud504\uc5d0 \uad00\uc5ec\ud558\uba70, \ub450 \uac1c\uc758 Experience Reflector(\uacbd\ud5d8 \ubc18\uc601 \uc5d0\uc774\uc804\ud2b8)\ub294 \uc791\uc5c5 \uac04 \uc7a5\uae30 \uba54\ubaa8\ub9ac\ub97c \uc5c5\ub370\uc774\ud2b8\ud558\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\uc758 \uc758\uc0ac\uacb0\uc815\uc740 Manager\uc5d0 \uc758\ud55c \uc0c1\uc704 \uc218\uc900 \uacc4\ud68d\uacfc Operator\uc5d0 \uc758\ud55c \ud558\uc704 \uc218\uc900 \uc791\uc5c5 \uc2e4\ud589\uc73c\ub85c \ubd84\ub9ac\ub429\ub2c8\ub2e4. Action Reflector\ub294 \uac01 \uc791\uc5c5\uc758 \uacb0\uacfc\ub97c \uac80\uc99d\ud558\uace0 \uc9c4\ud589 \uc0c1\ud669\uc744 \ucd94\uc801\ud558\uba70 \uc624\ub958 \ud53c\ub4dc\ubc31\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. Notetaker\ub294 \ud0d0\uc0c9 \uc911 \uc911\uc694\ud55c \uc815\ubcf4\ub97c \ucde8\ud569\ud569\ub2c8\ub2e4. \uadf8\ub9bc 3\uacfc 4\uc5d0\uc11c\ub294 \uc5d0\uc774\uc804\ud2b8 \ub8e8\ud504\uc758 \ud55c \ub2e8\uacc4\uc640 \uc790\uae30 \uc9c4\ud654 \uacfc\uc815\uc744 \uc790\uc138\ud788 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2. Mobile-Agent-E"}]