[{"figure_path": "https://arxiv.org/html/2412.12083/x1.png", "caption": "Figure 1: IDArb tackles intrinsic decomposition for an arbitrary number of views under unconstrained illumination. Our approach (a) achieves multi-view consistency compared to learning-based methods and (b) better disentangles intrinsic components from lighting effects via learnt priors compared to optimization-based methods. Our method could enhance a wide range of applications such as image relighting and material editing, photometric stereo, and 3D reconstruction.", "description": "IDArb\ub294 \uc81c\uc57d \uc5c6\ub294 \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ub2e4\uc591\ud55c \uc218\uc758 \ubdf0\ub97c \uc785\ub825\ubc1b\uc544 \ub0b4\uc7ac \ubd84\ud574\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. \ud559\uc2b5 \uae30\ubc18 \ubc29\ubc95\uacfc \ube44\uad50\ud558\uc5ec \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131\uc744 \ub2ec\uc131\ud558\uace0 \ucd5c\uc801\ud654 \uae30\ubc18 \ubc29\ubc95\uacfc \ube44\uad50\ud558\uc5ec \ud559\uc2b5\ub41c \uc0ac\uc804 \uc9c0\uc2dd\uc744 \ud1b5\ud574 \uc870\uba85 \ud6a8\uacfc\uc5d0\uc11c \ub0b4\uc7ac \uc694\uc18c\ub97c \ub354 \uc798 \ubd84\ub9ac\ud569\ub2c8\ub2e4. \uc774\ubbf8\uc9c0 \uc7ac\uc870\uba85 \ubc0f \uc7ac\uc9c8 \ud3b8\uc9d1, \uc0ac\uc9c4 \uce21\ub7c9 \uc2a4\ud14c\ub808\uc624, 3D \uc7ac\uad6c\uc131\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc751\uc6a9 \ubd84\uc57c\ub97c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2412.12083/x2.png", "caption": "Figure 2: Top: Overview of \u00a0IDArb. Bottom: Illustration of the attention block within the UNet.\nOur training batch consists of N\ud835\udc41Nitalic_N input images, sampled from Nvsubscript\ud835\udc41\ud835\udc63N_{v}italic_N start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT viewpoints and Nisubscript\ud835\udc41\ud835\udc56N_{i}italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT illuminations. The latent vector for each image is concatenated with Gaussian noise for denoising. Intrinsic components are divided into three triplets (D\ud835\udc37Ditalic_D=3): Albedo, Normal and Metallic&Roughness. Specific text prompts are used to guide the model toward different intrinsic components. For attention block inside UNet, we introduce cross-component and cross-view attention module into it, where attention is applied across components and views, facilitating global information exchange.", "description": "IDArb\ub294 \ub2e4\uc591\ud55c \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ucd2c\uc601\ub41c \uc784\uc758 \uac1c\uc218\uc758 \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\ubc1b\uc544 intrinsic decomposition\uc744 \uc218\ud589\ud558\ub294 \ud655\uc0b0 \uae30\ubc18 \ubaa8\ub378\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 IDArb\uc758 \uc804\uccb4\uc801\uc778 \uad6c\uc870\uc640 UNet \ub0b4\ubd80\uc758 attention block\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0\ub4e4\uc740 N_v\uac1c\uc758 \uc2dc\uc810\uacfc N_i\uac1c\uc758 \uc870\uba85 \uc870\uac74\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ub418\uba70, \uac01 \uc774\ubbf8\uc9c0\uc758 latent vector\ub294 \uac00\uc6b0\uc2dc\uc548 \ub178\uc774\uc988\uc640 \uc5f0\uacb0\ub418\uc5b4 denoising\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. Intrinsic component\ub294 Albedo, Normal, Metallic&Roughness\uc758 \uc138 \uac00\uc9c0 triplet\uc73c\ub85c \ub098\ub258\uba70, \uac01\uac01 \ud2b9\uc815 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \uc548\ub0b4\ud569\ub2c8\ub2e4. UNet \ub0b4\ubd80\uc758 attention block\uc740 cross-component attention\uacfc cross-view attention \ubaa8\ub4c8\uc744 \ud1b5\ud574 component\uc640 \uc2dc\uc810 \uac04\uc758 \uc815\ubcf4 \uad50\ud658\uc744 \ucd09\uc9c4\ud558\uc5ec, \uc804\uc5ed \uc815\ubcf4 \uad50\ud658\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "3. METHOD"}, {"figure_path": "https://arxiv.org/html/2412.12083/x3.png", "caption": "Figure 3: Overview of the Arb-Objaverse dataset. Our custom dataset features a diverse collection of objects rendered under various lighting conditions, accompanied by their intrinsic components.", "description": "ARB-Objaverse \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \ubb3c\uccb4\ub4e4\uc744 \uc5ec\ub7ec \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ub80c\ub354\ub9c1\ud558\uc5ec \uc870\uba85 \ubcc0\ud654\uc5d0 \uac15\uc778\ud55c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uac01 \ubb3c\uccb4\ub294 albedo, normal, metallic, roughness\uc640 \uac19\uc740 intrinsic \uc694\uc18c\ub4e4\uacfc \ud568\uaed8 \uc81c\uacf5\ub429\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c ABO, G-Objaverse, A12-Objaverse \ub370\uc774\ud130\uc14b\uacfc \ube44\uad50\ud558\uc5ec ARB-Objaverse\uc758 \ub2e4\uc591\ud55c \ubb3c\uccb4 \ubc0f \uc870\uba85 \uc870\uac74\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 ARB-OBJAVERSE DATASET"}, {"figure_path": "https://arxiv.org/html/2412.12083/x4.png", "caption": "(a) Albedo estimation. Our method effectively removes highlights and shadows.", "description": "(a) \uc54c\ubca0\ub3c4 \ucd94\uc815. IDArb\ub294 \ud559\uc2b5 \uae30\ubc18 \uc811\uadfc \ubc29\uc2dd\uacfc \ub2ec\ub9ac \ud558\uc774\ub77c\uc774\ud2b8\uc640 \uadf8\ub9bc\uc790\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc81c\uac70\ud558\uc5ec \ub354 \uc815\ud655\ud55c \uc54c\ubca0\ub3c4 \ub9f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \ucd5c\uc801\ud654 \uae30\ubc18 \ubc29\ubc95\uacfc \ube44\uad50\ud588\uc744 \ub54c, IDArb\ub294 \uc870\uba85 \ud6a8\uacfc\ub97c \uc54c\ubca0\ub3c4\uc5d0 \uc0bd\uc785\ud558\uc9c0 \uc54a\uace0 \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \ubcf4\uc785\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x5.png", "caption": "(b) Normal estimation. Our method gives shape geometry while correctly predicting flat surface.", "description": "IDArb\uac00 \ub2e4\ub978 \ubc29\ubc95\ub4e4(RGB\u2192X, GeoWizard)\uacfc \ube44\uad50\ud558\uc5ec, \ud3c9\uba74\uc744 \uc62c\ubc14\ub974\uac8c \uc608\uce21\ud558\uba74\uc11c\ub3c4 \ubb3c\uccb4\uc758 \ud615\ud0dc\ub97c \uc798 \ub098\ud0c0\ub0b4\ub294 \ub178\uba40 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. RGB\u2192X\ub294 \ubb3c\uccb4\uc758 \ud14d\uc2a4\ucc98\uc5d0 \uc758\ud574 \uac04\uc12d\uc744 \ubc1b\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc774\uba70, GeoWizard\ub294 \ud750\ub9bf\ud55c \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x6.png", "caption": "(c) Metallic estimation. Our method outperforms IID and RGB\u2194\u2194\\leftrightarrow\u2194X with plausible results free of interference from texture patterns and lighting.", "description": "IDArb\ub294 \ud14d\uc2a4\ucc98 \ud328\ud134 \ubc0f \uc870\uba85\uc758 \uac04\uc12d \uc5c6\uc774 \uc2e4\uc81c\uc640 \uac19\uc740 \uacb0\uacfc\ub97c \uc0dd\uc131\ud558\uc5ec \uae08\uc18d\uc131 \ucd94\uc815\uc5d0\uc11c IID \ubc0f RGB\u2194X\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x7.png", "caption": "(d) Roughness estimation. Our method outperforms IID and RGB\u2194\u2194\\leftrightarrow\u2194X with plausible results free of interference from texture patterns and lighting.", "description": "IDArb\uac00 \ud14d\uc2a4\ucc98 \ud328\ud134 \ubc0f \uc870\uba85\uc758 \uac04\uc12d \uc5c6\uc774 \uadf8\ub7f4\ub4ef\ud55c \uacb0\uacfc\ub97c \uc0dd\uc131\ud558\uc5ec IID\uc640 RGB\u2194X\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc73c\ub85c \uac70\uce60\uae30\ub97c \uc608\uce21\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x8.png", "caption": "Figure 4: Qualitative comparison on synthetic data. \u00a0IDArb demonstrates superior intrinsic estimation compared to all other methods.", "description": "IDArb \ubaa8\ub378\uc740 \ud569\uc131 \ub370\uc774\ud130\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud558\uc5ec \uc6b0\uc218\ud55c \ub0b4\uc7ac\uc801 \ucd94\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc740 albedo, normal, metallic, roughness \ucd94\uc815 \uacb0\uacfc\ub97c IID, RGB\u2192X, IntrinsicAnything, GeoWizard \uc640 \uac19\uc740 \uae30\uc874 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. IDArb\ub294 albedo\uc5d0\uc11c \ud558\uc774\ub77c\uc774\ud2b8\uc640 \uadf8\ub9bc\uc790\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc81c\uac70\ud558\uace0, normal\uc5d0\uc11c \uc815\ud655\ud55c \uae30\ud558\ud559\uc801 \ud615\ud0dc\ub97c \uc81c\uacf5\ud558\uba70, metallic\uacfc roughness\uc5d0\uc11c \ud14d\uc2a4\ucc98 \ud328\ud134 \ubc0f \uc870\uba85\uc758 \uac04\uc12d\uc744 \uc81c\uac70\ud558\uc5ec \uc0ac\uc2e4\uc801\uc778 \uacb0\uacfc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x9.png", "caption": "Figure 5: Qualitative comparison on real-world data. \u00a0IDArb generalizes well to real data, with accurate, convincing decompositions and high-frequency details.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ub370\uc774\ud130\uc5d0 \ub300\ud55c IDArb\uc758 \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IDArb\uc740 \uc2e4\uc81c \ub370\uc774\ud130\uc5d0 \ub300\ud574\uc11c\ub3c4 \uc798 \uc77c\ubc18\ud654\ub418\uc5b4 \uc815\ud655\ud558\uace0 \uc124\ub4dd\ub825 \uc788\ub294 \ubd84\ud574\ub2a5\uacfc \uace0\uc8fc\ud30c \ub514\ud14c\uc77c\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc67c\ucabd\uc5d0\uc11c \uc624\ub978\ucabd\uc73c\ub85c \uc785\ub825 \uc774\ubbf8\uc9c0, IntrinsicAnything\ub85c \uc608\uce21\ud55c \uacb0\uacfc, IDArb\uc73c\ub85c \uc608\uce21\ud55c \uc54c\ubca0\ub3c4, \ub178\ub9d0, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IDArb\uc740 IntrinsicAnything\ubcf4\ub2e4 \ub354 \ub098\uc740 \ub514\ud14c\uc77c\uacfc \uc0ac\uc2e4\uc801\uc778 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4.2 EXPERIMENTAL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x10.png", "caption": "(a)", "description": "(a) \uc5ec\ub7ec \uc785\ub825 \uc774\ubbf8\uc9c0\ub85c \uad6c\uc131\ub41c \uc0d8\ud50c\uc758 \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131 \uc2dc\uac01\uc801 \ube44\uad50\uc785\ub2c8\ub2e4. IDArb\ub294 \ud559\uc2b5 \uae30\ubc18 \ubc29\ubc95(IntrinsicAnything)\uacfc \ube44\uad50\ud558\uc5ec \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131\uc744 \ub2ec\uc131\ud558\uace0 \ucd5c\uc801\ud654 \uae30\ubc18 \ubc29\ubc95\uc744 \ud1b5\ud574 \ud559\uc2b5\ub41c \uc0ac\uc804\uc744 \ud1b5\ud574 \uc870\uba85 \ud6a8\uacfc\uc5d0\uc11c \ub0b4\uc7ac\uc801 \uad6c\uc131 \uc694\uc18c\ub97c \ub354 \uc798 \ubd84\ub9ac\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.12083/x11.png", "caption": "(b)", "description": "(b) \ucd5c\uc801\ud654 \uae30\ubc18 \ubc29\ubc95(NVDiffRecMC)\uacfc \ud559\uc2b5 \uae30\ubc18 \ubc29\ubc95(IntrinsicAnything)\uc758 \ub2e8\uc810\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4. NVDiffRecMC\ub294 \uc870\uba85 \ud6a8\uacfc\uac00 \uc7ac\uc9c8\uc5d0 \uc798\ubabb \ubc18\uc601\ub418\uc5b4(\uc608: \uae08\uc18d\uc131 \uc624\ube0c\uc81d\ud2b8\uc758 \uc5b4\ub450\uc6b4 \uc0c9\uc0c1), IntrinsicAnything\ub294 \uba40\ud2f0 \ubdf0 \uc785\ub825\uc5d0 \ub300\ud574 \uc77c\uad00\uc131 \uc5c6\ub294 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\uc5d0 \ubc18\ud574 IDArb\ub294 \ud559\uc2b5 \uae30\ubc18 \ubc29\uc2dd\uc73c\ub85c \uba40\ud2f0 \ubdf0 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c \uc870\uba85 \ud6a8\uacfc\uc640 \uc7ac\uc9c8\uc744 \ub354 \uc798 \ubd84\ub9ac\ud569\ub2c8\ub2e4.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2412.12083/x12.png", "caption": "Figure 6: Ablative studies on (a) cross-component attention and (b) training strategy.", "description": "\uc774 \uadf8\ub9bc\uc740 \uad50\ucc28 \uad6c\uc131 \uc694\uc18c \uc8fc\uc758 \ubc0f \ud6c8\ub828 \uc804\ub7b5\uc5d0 \ub300\ud55c \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uad50\ucc28 \uad6c\uc131 \uc694\uc18c \uc8fc\uc758\uac00 \uc5c6\uc744 \ub54c \uae08\uc18d \ubc0f \uac70\uce60\uae30\uc640 \uac19\uc740 \ubcf8\uc9c8\uc801\uc778 \uad6c\uc131 \uc694\uc18c\uc758 \uc608\uce21\uc774 \uc800\ud558\ub428\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uc774\ub294 \uc774\ub7ec\ud55c \uad6c\uc131 \uc694\uc18c \uac04\uc758 \uc0c1\ud638 \uc791\uc6a9\uc744 \ubaa8\ub378\ub9c1\ud558\ub294 \uac83\uc758 \uc911\uc694\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. (b)\ub294 \ub2e4\uc911 \ubdf0 \uc785\ub825\uacfc \ub2e8\uc77c \uc774\ubbf8\uc9c0 \uc785\ub825\uc744 \ubaa8\ub450 \uc0ac\uc6a9\ud55c \ud6c8\ub828 \uc804\ub7b5\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc911 \ubdf0 \uc785\ub825\ub9cc \uc0ac\uc6a9\ud558\uc5ec \ud6c8\ub828\ud558\uba74 \ub2e8\uc77c \uc774\ubbf8\uc9c0 \uc785\ub825\uc5d0 \ub300\ud55c \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \ubc18\uba74, \uc81c\uc548\ub41c \ud6c8\ub828 \uc804\ub7b5\uc740 \ub2e4\uc591\ud55c \uc785\ub825 \uc720\ud615\uc5d0 \ub300\ud55c \uac15\ub825\ud55c \uc77c\ubc18\ud654 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c, \ub192\uc740 \ub178\uc774\uc988 \ub808\ubca8\ub85c \ub178\uc774\uc988 \uc2a4\ucf00\uc904\ub7ec\ub97c \uc774\ub3d9\ud558\uba74 \uae08\uc18d \ubc0f \uac70\uce60\uae30 \uad6c\uc131 \uc694\uc18c\uc758 \uc608\uce21\uc774 \ud5a5\uc0c1\ub429\ub2c8\ub2e4.", "section": "4.3 ANALYSIS AND ABLATIVE STUDY"}, {"figure_path": "https://arxiv.org/html/2412.12083/x13.png", "caption": "Figure 7: Effects of number of viewpoints and lighting conditions. We find increasing the number of viewpoints and the lighting conditions generally improves decomposition performance.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc218\uc758 \ubdf0\ud3ec\uc778\ud2b8\uc640 \uc870\uba85 \uc870\uac74\uc5d0\uc11c IDArb \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubdf0\ud3ec\uc778\ud2b8 \uc218(#V)\uc640 \uc870\uba85 \uc870\uac74 \uc218(#L)\ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\uacbd\ud558\uba70 \uc2e4\ud5d8\ud55c \uacb0\uacfc, \ubdf0\ud3ec\uc778\ud2b8\uc640 \uc870\uba85 \uc870\uac74\uc758 \uc218\uac00 \uc99d\uac00\ud560\uc218\ub85d \uc804\ubc18\uc801\uc778 \ubd84\ud574 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 \uae08\uc18d\uc131 \ubc0f \uac70\uce60\uae30 \uc608\uce21\uc758 \uacbd\uc6b0, \ub2e4\uc911 \uc870\uba85 \ucea1\ucc98\uac00 \uc870\uba85 \ud6a8\uacfc\ub85c \uc778\ud55c \ubaa8\ud638\uc131\uc744 \ud574\uacb0\ud558\ub294 \ub370 \ub9e4\uc6b0 \ud6a8\uacfc\uc801\uc785\ub2c8\ub2e4. 8\uac1c \uc774\uc0c1\uc758 \ubdf0\ud3ec\uc778\ud2b8\ub97c \ucd94\uac00\ud558\uba74 \uc131\ub2a5 \ud5a5\uc0c1\uc774 \uac10\uc18c\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. x\ucd95\uc740 \ubdf0\ud3ec\uc778\ud2b8 \uc218\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \uc54c\ubca0\ub3c4, \ub178\uba40, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4 \uac01\uac01\uc758 \uc131\ub2a5 \uc9c0\ud45c \uac12\uc758 \ubcc0\ud654\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc0c9\uc0c1 \ubcc0\ud654\ub97c \ud1b5\ud574 \ubdf0\ud3ec\uc778\ud2b8 \uc218\uc640 \uc870\uba85 \uc870\uac74 \uc218\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 ANALYSIS AND ABLATIVE STUDY"}, {"figure_path": "https://arxiv.org/html/2412.12083/x14.png", "caption": "Figure 8: Relighting and material editing results. From in-the-wild captures (a), our model allows for relighting under novel illumination (b) and material property modifications (c).", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ud658\uacbd\uc5d0\uc11c \ucd2c\uc601\ub41c \uc774\ubbf8\uc9c0(a)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0c8\ub85c\uc6b4 \uc870\uba85 \uc870\uac74\uc5d0\uc11c\uc758 \ub9ac\ub77c\uc774\ud305 \uacb0\uacfc(b)\uc640 \uc7ac\uc9c8 \uc18d\uc131 \ubcc0\uacbd \uacb0\uacfc(c)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IDArb \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uba74 \uc785\ub825 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc54c\ubca0\ub3c4, \ub178\ub9d0, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4 \ub4f1\uc758 \uace0\uc720 \uc694\uc18c\ub97c \ucd94\ucd9c\ud558\uc5ec \uc7ac\uc9c8 \ubc0f \uc870\uba85 \ud3b8\uc9d1\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc5d0 \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 APPLICATIONS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x15.png", "caption": "Figure 9: Optimization-based inverse rendering results. Our method guides NVDiffecMC generate more plausible material results.", "description": "\uc774 \uadf8\ub9bc\uc740 \ucd5c\uc801\ud654 \uae30\ubc18 \uc5ed\ub80c\ub354\ub9c1 \uae30\ubc95\uc778 NVDiffRecMC\uc5d0 \uc800\uc790\ub4e4\uc774 \uc81c\uc548\ud55c \ubc29\ubc95\uc744 \uc801\uc6a9\ud558\uc5ec \uc7ac\uc9c8 \ucd94\uc815 \uacb0\uacfc\ub97c \ud5a5\uc0c1\uc2dc\ud0a8 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc800\uc790\ub4e4\uc758 \ubc29\ubc95\uc740 \uac01 \ud559\uc2b5 \uc774\ubbf8\uc9c0\ub97c \ud574\ub2f9\ud558\ub294 \uc7ac\uc9c8 \uc694\uc18c\ub85c \ubd84\ud574\ud558\uace0, \uc774\ub97c pseudo-material label\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ub9e4 \ubc18\ubcf5\ub9c8\ub2e4 NVDiffRecMC\uc5d0\uc11c \uc608\uce21\ud55c \uc7ac\uc9c8 \uc694\uc18c\uc640 \uc800\uc790\ub4e4\uc758 \ubc29\ubc95\uc73c\ub85c \uc608\uce21\ud55c \uac12 \uc0ac\uc774\uc758 L2 \uc815\uaddc\ud654 \ud56d\uc744 \ucd94\uac00\ud558\uc5ec \ubb3c\ub9ac\uc801 \ud0c0\ub2f9\uc131\uc744 \ubcf4\uc7a5\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774, \uc800\uc790\ub4e4\uc758 \ubc29\ubc95\uc744 \uc801\uc6a9\ud558\uba74 NVDiffRecMC\uc5d0\uc11c \uc7ac\uad6c\uc131\ub41c albedo\uc758 \uc0c9\uc0c1 \ubcc0\ud654 \ubb38\uc81c\uac00 \ud06c\uac8c \uc644\ud654\ub418\uc5b4, \ub354 \ub098\uc740 \ud488\uc9c8\uc758 \ub80c\ub354\ub9c1 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 APPLICATIONS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x16.png", "caption": "Figure 10: Photometric stereo results using 4 OLAT images in OpenIllumination and NeRFactor.", "description": "\uc774 \uadf8\ub9bc\uc740 OpenIllumination \ubc0f NeRFactor \ub370\uc774\ud130\uc14b\uc5d0\uc11c 4\uac1c\uc758 OLAT(One-Light-At-a-Time) \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\ud55c \uc0ac\uc9c4 \uce21\ub7c9 \uc2a4\ud14c\ub808\uc624 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OLAT \uc870\uac74\uc5d0\uc11c\ub294 \uac01 \uc774\ubbf8\uc9c0\uac00 \uc8fc\ubcc0 \uc870\uad11 \uc5c6\uc774 \ub2e8\uc77c \uc810 \uad11\uc6d0\uc73c\ub85c \uc870\uba85\ub418\uc5b4 \uadf8\ub9bc\uc790\uac00 \uc0dd\uae41\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \uc785\ub825 OLAT \uc774\ubbf8\uc9c0, \uc608\uce21\ub41c \uc54c\ubca0\ub3c4 \ubc0f \ubc95\uc120 \ub9f5\uc774 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. IDArb\uc740 OLAT\uc640 \uac19\uc740 \uae4c\ub2e4\ub85c\uc6b4 \uc870\uac74\uc5d0\uc11c\ub3c4 \uc2e4\uc81c \ubc0f \ud569\uc131 \ub370\uc774\ud130 \ubaa8\ub450\uc5d0\uc11c \uc88b\uc740 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.12083/x17.png", "caption": "Figure 11: More results on real-world data.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ucd94\ucd9c\ud55c \uc54c\ubca0\ub3c4, \ub178\uba40, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4 \ub9f5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. IDArb\uc740 \ub2e4\uc591\ud55c \uc2e4\uc81c \ubb3c\uccb4\uc5d0 \ub300\ud574 \uc0ac\uc2e4\uc801\uc774\uace0 \uc138\ubd80\uc801\uc778 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub294 IDArb\uc774 \ud569\uc131 \ub370\uc774\ud130\ub85c \ud6c8\ub828\ub418\uc5c8\uc74c\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc5d0 \uc798 \uc77c\ubc18\ud654\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.12083/x18.png", "caption": "Figure 12: More results on real-world data. We also provide the reconstructed and relighting images.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ucd94\uac00 \uacb0\uacfc\uc640 \uc7ac\uad6c\uc131 \ubc0f \uc7ac\uc870\uba85 \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc608\uce21\ub41c albedo, normal, metallic, roughness\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub80c\ub354\ub9c1\ub41c \uc774\ubbf8\uc9c0(Recon)\uc640 \ub2e4\uc591\ud55c \uc870\uba85 \uc870\uac74\uc5d0\uc11c \uc7ac\uc870\uba85\ub41c \uc774\ubbf8\uc9c0(Relit 1, 2, 3)\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc624\ud1a0\ubc14\uc774, \uc790\ub3d9\ucc28, \ud2b8\ub7fc\ud3ab, \ube75\uacfc \uc7bc \ub4f1 \ub2e4\uc591\ud55c \uc885\ub958\uc758 \ubb3c\uccb4\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud558\uc5ec \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.12083/x19.png", "caption": "Figure 13: More results on multi-view data.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc5ec\ub7ec \uc2dc\uc810\uc5d0\uc11c \ucd2c\uc601\ub41c \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \uc11c\ub85c \ub2e4\ub978 \ub2e4\uc911 \uc2dc\uc810 \ub370\uc774\ud130\uc14b\uc744 \ub098\ud0c0\ub0b4\uba70, \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \uc608\uce21\ub41c \uc54c\ubca0\ub3c4, \ub178\uba40, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4 \ub9f5\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud589\uc740 \ub4dc\ub7fc \uc138\ud2b8, \ub450 \ubc88\uc9f8 \ud589\uc740 \ub2e4\uc591\ud55c \uc74c\uc2dd\uc774 \ub2f4\uae34 \uc811\uc2dc, \uc138 \ubc88\uc9f8 \ud589\uc740 \uc0cc\ub4dc\uc704\uce58\uc640 \ud56b\ub3c4\uadf8\uac00 \ub2f4\uae34 \uc811\uc2dc\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 IDArb \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub2e4\uc911 \uc2dc\uc810 \ub370\uc774\ud130\uc5d0\uc11c \uc77c\uad00\uc131 \uc788\ub294 \ubcf8\uc9c8\uc801 \uc694\uc18c\ub97c \ucd94\ucd9c\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12083/x20.png", "caption": "Figure 14: Multiview images with extreme lighting variation.\nFor each scene in NeRD dataset\u00a0(Boss et\u00a0al., 2021a), we input 4 views.", "description": "NeRD \ub370\uc774\ud130\uc14b(Boss \uc678, 2021a)\uc758 \uac01 \uc7a5\uba74\uc5d0 \ub300\ud574 4\uac1c\uc758 \ubdf0\ub97c \uc785\ub825\ud558\uc5ec \uadf9\ub2e8\uc801\uc778 \uc870\uba85 \ubcc0\ud654\uac00 \uc788\ub294 \ub2e4\uc911 \ubdf0 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ubcf8 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uac01 \ubdf0\ub294 \uc11c\ub85c \ub2e4\ub978 \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ub80c\ub354\ub9c1\ub429\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0, \uc54c\ubca0\ub3c4, \ub178\uba40, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4\ub97c \uc608\uce21\ud55c \uacb0\uacfc\uac00 \ud45c\uc2dc\ub429\ub2c8\ub2e4.", "section": "4.3 ANALYSIS AND ABLATIVE STUDY"}, {"figure_path": "https://arxiv.org/html/2412.12083/x21.png", "caption": "Figure 15: Failure cases.", "description": "\uc774 \uadf8\ub9bc\uc740 IDArb \ubaa8\ub378\uc758 \uc2e4\ud328 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud589\uc740 \uc57c\uc678 \uc7a5\uba74\uc73c\ub85c, \ubaa8\ub378\uc774 \uac1d\uccb4 \uc911\uc2ec \ub370\uc774\ud130\uc5d0 \ub300\ud574 \uc8fc\ub85c \ud6c8\ub828\ub418\uc5c8\uae30 \ub54c\ubb38\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\uc2b5\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \ud589\uc740 \ud14d\uc2a4\ud2b8\uac00 \uc788\ub294 \uc774\ubbf8\uc9c0\ub85c, \ubaa8\ub378\uc774 \uc62c\ubc14\ub978 \ud14d\uc2a4\ud2b8 \uad6c\uc870\ub97c \ubcf5\uad6c\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4. \uc138 \ubc88\uc9f8 \ud589\uc740 \uc804\ud654\uae30 \uc774\ubbf8\uc9c0\ub85c, \ubaa8\ub378\uc774 \ubbf8\ubb18\ud55c \uc7ac\uc9c8 \ub514\ud14c\uc77c\uc744 \ubcf4\uc874\ud558\uc9c0 \ubabb\ud558\uace0 \uc9c0\ub098\uce58\uac8c \ub2e8\uc21c\ud654\ub41c \ucd9c\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubb38\uc81c\ub294 \ud569\uc131 \ud6c8\ub828 \ub370\uc774\ud130\uac00 \uc885\uc885 \ub354 \ub2e8\uc21c\ud55c \uc7ac\uc9c8 \ubcc0\ud615\uc744 \ud3ec\ud568\ud558\uace0 \uc788\uc5b4 \ubaa8\ub378\uc774 \uc138\ubc00\ud55c \uc7ac\uc9c8 \uc18d\uc131\uc744 \uacfc\ub3c4\ud558\uac8c \ub2e8\uc21c\ud654\ud558\uac8c \ub9cc\ub4dc\ub294 \uac83\uc5d0\uc11c \ube44\ub86f\ub429\ub2c8\ub2e4.", "section": "F. FAILURE CASES"}, {"figure_path": "https://arxiv.org/html/2412.12083/x22.png", "caption": "Figure 16: Results on Mip-NeRF 360\u00a0(Barron et\u00a0al., 2022) (Part 1, outdoor). We input 4 views for each scene.", "description": "Mip-NeRF 360 \ub370\uc774\ud130\uc14b\uc758 \uc57c\uc678 \uc7a5\uba74\uc5d0 \ub300\ud55c IDArb\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc7a5\uba74\uc5d0 \ub300\ud574 4\uac1c\uc758 \ubdf0\ub97c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \uc785\ub825 \uc774\ubbf8\uc9c0, \uc608\uce21\ub41c \uc54c\ubca0\ub3c4, \ubc95\uc120, \uba54\ud0c8\ub9ad, \ub7ec\ud504\ub2c8\uc2a4 \ub9f5\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. IDArb\uc740 \ub2e4\uc591\ud55c \uc57c\uc678 \uc7a5\uba74\uc5d0\uc11c \uc77c\uad00\ub418\uace0 \uc815\ud655\ud55c \ub0b4\uc7ac\uc801 \uc774\ubbf8\uc9c0 \ubd84\ud574\ub97c \uc218\ud589\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 APPLICATIONS"}]