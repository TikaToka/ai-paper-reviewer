{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper provides technical details of GPT-4, a large language model used in the benchmark experiments."}, {"fullname_first_author": "Ting Bai", "paper_title": "Baijia: A large scale role-playing agent corpus of chinese historical charcaters", "publication_date": "2024-12-20", "reason": "This paper introduces Baijia, a large-scale corpus of role-playing agents in Chinese history, which is highly relevant to the CTM benchmark's focus on Chinese historical knowledge."}, {"fullname_first_author": "Zheng Cai", "paper_title": "InternLM2 technical report", "publication_date": "2024-03-17", "reason": "InternLM2 is a large language model evaluated in the benchmark and its technical report provides details relevant to understanding its performance."}, {"fullname_first_author": "Zheng Chu", "paper_title": "TimeBench: A comprehensive evaluation of temporal reasoning abilities in large language models", "publication_date": "2024-00-00", "reason": "This paper introduces TimeBench, a benchmark for evaluating temporal reasoning in LLMs, directly compared against in the current work."}, {"fullname_first_author": "Duygu Sezen Islakoglu", "paper_title": "Chronosense: Exploring temporal understanding in large language models with time intervals of events", "publication_date": "2025-01-03", "reason": "Chronosense, another benchmark for temporal reasoning in LLMs, is discussed and compared with the proposed CTM benchmark."}]}