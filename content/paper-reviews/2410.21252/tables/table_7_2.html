<br><table id='6' style='font-size:14px'><tr><td>Method</td><td>MT-Bench</td><td>AlpacaEval2</td></tr><tr><td>Llama-3.1-8B</td><td></td><td></td></tr><tr><td>officially post-trained</td><td>8.13</td><td>22.9</td></tr><tr><td>SFT</td><td>7.12</td><td>12.4</td></tr><tr><td>DPO w/ SRM</td><td>7.58</td><td>13.7</td></tr><tr><td>DPO w/ Contrast</td><td>7.58</td><td>13.8</td></tr><tr><td>DPO w/ LongReward</td><td>7.24</td><td>14.2</td></tr><tr><td>GLM-4-9B</td><td></td><td></td></tr><tr><td>officially post-trained</td><td>8.09</td><td>22.4</td></tr><tr><td>SFT</td><td>7.37</td><td>12.5</td></tr><tr><td>DPO w/ SRM</td><td>7.50</td><td>14.2</td></tr><tr><td>DPO w/ Contrast</td><td>7.54</td><td>14.5</td></tr><tr><td>DPO w/ LongReward</td><td>7.58</td><td>15.4</td></tr></table>