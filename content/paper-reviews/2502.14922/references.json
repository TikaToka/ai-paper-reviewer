{"references": [{"fullname_first_author": "Daya Guo", "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "publication_date": "2025-01-12", "reason": "This paper introduces DeepSeek-R1, a model that significantly improves multi-step reasoning capabilities, which is directly compared and improved upon by the proposed method."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 Herd of Models", "publication_date": "2024-07-21", "reason": "This paper introduces the Llama 3 models which are used as baselines to showcase performance improvements."}, {"fullname_first_author": "Takeshi Kojima", "paper_title": "Large Language Models are Zero-Shot Reasoners", "publication_date": "2022-12-31", "reason": "This paper is foundational in establishing the zero-shot reasoning capability of LLMs, a key concept extended in this work."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training Verifiers to Solve Math Word Problems", "publication_date": "2021-10-14", "reason": "This paper introduces the GSM8K dataset, a benchmark used for evaluating mathematical reasoning capabilities of LLMs."}, {"fullname_first_author": "Hunter Lightman", "paper_title": "Let's Verify Step by Step", "publication_date": "2023-05-20", "reason": "This paper introduces the MATH-500 dataset, another benchmark used to evaluate the reasoning capabilities of LLMs."}]}