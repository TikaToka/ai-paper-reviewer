{"references": [{"fullname_first_author": "Carbune, V.", "paper_title": "Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs", "publication_date": "2024-03-12", "reason": "This paper is cited as a recent work that utilizes LLMs for figure generation, a method compared to the proposed method in this paper."}, {"fullname_first_author": "Han, Y.", "paper_title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation", "publication_date": "2023-11-16", "reason": "This paper is cited as a recent example of LLM-based figure generation, which, unlike the current work, is inefficient and prone to code errors."}, {"fullname_first_author": "Masry, A.", "paper_title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning", "publication_date": "2022-12-01", "reason": "This paper introduces the ChartQA dataset, a standard benchmark for figure question answering which the current work improves upon."}, {"fullname_first_author": "Kim, G.", "paper_title": "OCR-Free Document Understanding Transformer", "publication_date": "2022-10-01", "reason": "This paper introduces the Donut model, the main model used for experimental evaluation in this paper, showcasing its effectiveness."}, {"fullname_first_author": "Lee, K.", "paper_title": "Pix2Struct: screenshot parsing as pretraining for visual language understanding", "publication_date": "2023-07-01", "reason": "This paper introduces the Pix2Struct model, an alternative model used for experimental evaluation demonstrating the generalizability of the proposed approach."}]}