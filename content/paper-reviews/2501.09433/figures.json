[{"figure_path": "https://arxiv.org/html/2501.09433/x1.png", "caption": "Figure 1: CaPa pipeline.\nWe first generate 3D geometry using a 3D latent diffusion model.\nUsing the learned 3D latent space with ShapeVAE, we train a 3D Latent Diffusion Model that generates 3D geometries, guided by multi-view images to ensure alignment between the generated shape and texture.\nAfter the 3D geometry is created, we render four orthogonal views of the mesh, which serve as inputs for texture generation.\nTo produce a high-quality texture while preventing the Janus problem, we utilize a novel, model-agnostic spatially decoupled attention.\nFinally, we obtain a hyper-quality textured mesh through back projection and a 3D-aware occlusion inpainting algorithm.", "description": "\uadf8\ub9bc 1\uc740 CaPa \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800 3D \uc7a0\uc7ac \ud655\uc0b0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec 3D \uae30\ud558 \ud615\ud0dc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. ShapeVAE\ub85c \ud559\uc2b5\ub41c 3D \uc7a0\uc7ac \uacf5\uac04\uc744 \uc0ac\uc6a9\ud558\uc5ec, \uc0dd\uc131\ub41c \ud615\ud0dc\uc640 \uc9c8\uac10 \uac04\uc758 \uc815\ub82c\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \ub2e4\uc911 \ubdf0 \uc774\ubbf8\uc9c0\ub85c \uc548\ub0b4\ub418\ub294 3D \uc7a0\uc7ac \ud655\uc0b0 \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0b5\ub2c8\ub2e4. 3D \uae30\ud558 \ud615\ud0dc\uac00 \uc0dd\uc131\ub41c \ud6c4, \uba54\uc2dc\uc758 \uc0ac\uc911 \uc9c1\uad50 \ubdf0\ub97c \ub80c\ub354\ub9c1\ud558\uc5ec \uc9c8\uac10 \uc0dd\uc131\uc744 \uc704\ud55c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc0c8\ub85c\uc6b4 \ubaa8\ub378 \ub3c5\ub9bd\uc801\uc778 \uacf5\uac04 \ubd84\ub9ac \uc8fc\uc758 \uc9d1\uc911 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec, \uc81c\uc544\ub204\uc2a4 \ubb38\uc81c\ub97c \ubc29\uc9c0\ud558\uba74\uc11c \uace0\ud488\uc9c8 \uc9c8\uac10\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc5ed\ud22c\uc601\uacfc 3D \uc778\uc2dd \ud3d0\uc0c9 \ud398\uc778\ud305 \uc54c\uace0\ub9ac\uc998\uc744 \ud1b5\ud574 \ucd08\uace0\ud488\uc9c8 \uc9c8\uac10 \uba54\uc2dc\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.09433/x2.png", "caption": "Figure 2: Spatially Decoupled Cross Attention.\nTo produce high-quality multi-view images for a given geometry, we design a model-agnostic Spatially Decoupled Cross Attention.\nDuring cross-attention in denoising U-Net, we replicate hidden feature channels so that each duplicated channels focuses solely on the designated view.\nSince the design is model-agnostic, we can utilize an external ControlNet to guide the textures aligned with the input mesh.", "description": "\uadf8\ub9bc 2\ub294 CaPa \ubaa8\ub378\uc758 \ud575\uc2ec \uad6c\uc131 \uc694\uc18c\uc778 \uacf5\uac04\uc801\uc73c\ub85c \ubd84\ub9ac\ub41c \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158(Spatially Decoupled Cross Attention) \uba54\ucee4\ub2c8\uc998\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uba54\ucee4\ub2c8\uc998\uc740 \uc8fc\uc5b4\uc9c4 3D \uae30\ud558 \uad6c\uc870\uc5d0 \ub300\ud574 \uace0\ud488\uc9c8\uc758 \ub2e4\uc911 \ubdf0 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud574 \uc124\uacc4\ub418\uc5c8\uc73c\uba70, \ubaa8\ub378\uacfc \ubb34\uad00\ud558\uac8c(model-agnostic) \ub3d9\uc791\ud569\ub2c8\ub2e4.  \uae30\uc874\uc758 \ub2e4\uc911 \ubdf0 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubc29\uc2dd\uacfc \ub2ec\ub9ac, \ub178\uc774\uc988 \uc81c\uac70 U-Net \ub0b4\ubd80\uc758 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \uacfc\uc815\uc5d0\uc11c \uc740\ub2c9 \ud2b9\uc9d5 \ucc44\ub110(hidden feature channels)\uc744 \ubcf5\uc81c\ud558\uc5ec \uac01 \ubcf5\uc81c\ub41c \ucc44\ub110\uc774 \ud2b9\uc815 \ubdf0\uc5d0\ub9cc \uc9d1\uc911\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uac01 \ubdf0\uc758 \uacf5\uac04\uc801 \uc815\ubcf4\uac00 \ub3c5\ub9bd\uc801\uc73c\ub85c \ucc98\ub9ac\ub418\uba74\uc11c\ub3c4 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ub610\ud55c, \uc774\ub7ec\ud55c \ubaa8\ub378 \ub3c5\ub9bd\uc801\uc778 \uc124\uacc4 \ub355\ubd84\uc5d0 \uc678\ubd80 ControlNet\uc744 \ud65c\uc6a9\ud558\uc5ec \uc785\ub825 \uba54\uc2dc\uc5d0 \uc815\ub82c\ub41c \ud14d\uc2a4\ucc98\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \ubc1b\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2.1 \uacf5\uac04\uc801\uc73c\ub85c \ubd84\ub9ac\ub41c \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 (Spatially Decoupled Cross Attention)"}, {"figure_path": "https://arxiv.org/html/2501.09433/x3.png", "caption": "Figure 3: 3D-Aware Occlusion Inpainting.\nFirst, we cluster the normal and spatial coordinates of the occluded face.\nUsing clustered centers as viewpoints, we create specialized UV maps through projection mapping.\nThis approach captures surface locality, allowing 2D diffusion-based inpainting to effectively fill occluded regions. Note that this UV map is utilized solely for occlusion.", "description": "\uadf8\ub9bc 3\uc740 CaPa\uc758 3D-Aware Occlusion Inpainting \uc54c\uace0\ub9ac\uc998\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800, \ud14d\uc2a4\ucc98\uac00 \uc0dd\uc131\ub418\uc9c0 \uc54a\uc740(occluded) \uba74\ub4e4\uc758 \ubc95\uc120 \ubca1\ud130\uc640 \uacf5\uac04 \uc88c\ud45c\ub97c \ud074\ub7ec\uc2a4\ud130\ub9c1\ud569\ub2c8\ub2e4. \ud074\ub7ec\uc2a4\ud130 \uc911\uc2ec\uc744 \uc0c8\ub85c\uc6b4 \ubdf0\ud3ec\uc778\ud2b8\ub85c \uc0ac\uc6a9\ud558\uc5ec \ud22c\uc601 \ub9e4\ud551\uc744 \ud1b5\ud574 \ud2b9\uc218\ud55c UV \ub9f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 UV \ub9f5\uc740 \ud45c\uba74\uc758 \uc9c0\uc5ed\uc801 \ud2b9\uc9d5(surface locality)\uc744 \ubcf4\uc874\ud558\uc5ec 2D \ud655\uc0b0 \uae30\ubc18\uc758 \uc778\ud398\uc778\ud305(inpainting)\uc744 \ud1b5\ud574 \ud14d\uc2a4\ucc98\uac00 \uc5c6\ub294 \uc601\uc5ed\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ucc44\uc6b8 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774 UV \ub9f5\uc740 \uc624\uc9c1 \ud3d0\uc0c9 \uc601\uc5ed\uc744 \ucc44\uc6b0\ub294 \uc6a9\ub3c4\ub85c\ub9cc \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "3.2.2 Occlusion Inpainting"}, {"figure_path": "https://arxiv.org/html/2501.09433/extracted/6135590/figs/other_texture.png", "caption": "Figure 4: Comparison of Texturing Method.\nUnlike prior works, CaPa effectively resolved the Janus problem with consistent ID.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \uae30\uc874\uc758 \ud14d\uc2a4\ucc98 \uc0dd\uc131 \ubc29\ubc95\uacfc CaPa\uc758 \ud14d\uc2a4\ucc98 \uc0dd\uc131 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec CaPa\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 \ubc29\ubc95\ub4e4\uc740 \ubdf0 \uac04\uc758 \uc77c\uad00\uc131\uc774 \ubd80\uc871\ud558\uc5ec Janus \ubb38\uc81c(\uc5ec\ub7ec \uc5bc\uad74\uc774 \ub098\ud0c0\ub098\ub294 \ud604\uc0c1)\uac00 \ubc1c\uc0dd\ud588\uc9c0\ub9cc, CaPa\ub294 \ub3c5\ucc3d\uc801\uc778 \uacf5\uac04\uc801 \ubd84\ub9ac \uc5b4\ud150\uc158(Spatially Decoupled Attention) \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud558\uace0 \uc77c\uad00\ub41c \ud14d\uc2a4\ucc98\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub294  ID \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c \uace0\ud488\uc9c8 \ud14d\uc2a4\ucc98\ub97c \uc0dd\uc131\ud558\ub294 CaPa\uc758 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2. \uc9c8\uc801 \ube44\uad50 (Qualitative Comparison)"}, {"figure_path": "https://arxiv.org/html/2501.09433/x4.png", "caption": "Figure 5: Qualitative Comparison of Image-to-3D Generation.\nWe compare CaPa with state-of-the-art Image-to-3D methods.\nHere, all the assets are converted to polygonal mesh, using its official code.\nThe proposed CaPa significantly outperforms both geometry stability and texture quality, especially for the back and side view\u2019s visual fidelity and texture coherence.", "description": "\uc774 \uadf8\ub9bc\uc740 CaPa\ub97c \ucd5c\ucca8\ub2e8 \uc774\ubbf8\uc9c0 \ud22c 3D \ubcc0\ud658 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud558\uc5ec, \uc0dd\uc131\ub41c 3D \uc790\uc0b0\uc758 \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \uc790\uc0b0\uc740 \uacf5\uc2dd \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uac01\ud615 \uba54\uc26c\ub85c \ubcc0\ud658\ub418\uc5c8\uc2b5\ub2c8\ub2e4. CaPa\ub294 \ud2b9\ud788 \ud6c4\uba74 \ubc0f \uce21\uba74 \ubdf0\uc5d0\uc11c \uae30\ud558\ud559\uc801 \uc548\uc815\uc131\uacfc \uc9c8\uac10 \ud488\uc9c8 \uba74\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ud6e8\uc52c \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud6c4\uba74 \ubc0f \uce21\uba74 \ubdf0\uc758 \uc2dc\uac01\uc801 \ucda9\uc2e4\ub3c4\uc640 \uc9c8\uac10 \uc77c\uad00\uc131\uc774 \ud2b9\ud788 \ud5a5\uc0c1\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "4.2. \uc9c8\uc801 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2501.09433/x5.png", "caption": "Figure 6: Ablation Study.\n(a) demonstrates that using multi-view guidance significantly increases the geometry quality.\n(b) shows our Spatially Decoupled Attention effectively resolves the Janus problem, achieving high-fidelity texture coherence,\n(c) reveals our occlusion inpainting outperforms previous inpainting methods like UV-ControlNet, presented in Paint3D\u00a0[59].", "description": "\uadf8\ub9bc 6\uc740 CaPa \ubaa8\ub378\uc758 ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e4\uc911 \ubdf0 \uac00\uc774\ub4dc\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c \uae30\ud558\ud559\uc801 \ud488\uc9c8\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 CaPa\uc758 \uacf5\uac04\uc801\uc73c\ub85c \ubd84\ub9ac\ub41c \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc774 \uc81c\uc774\ub108\uc2a4 \ubb38\uc81c(Janus problem)\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud558\uace0 \uace0\ud488\uc9c8\uc758 \uc9c8\uac10 \uc77c\uad00\uc131\uc744 \ub2ec\uc131\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (c)\ub294 CaPa\uc758 \ud3d0\uc0c9 \ubcf4\uac04\ubc95(occlusion inpainting)\uc774 Paint3D [59] \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c UV-ControlNet\uacfc \uac19\uc740 \uae30\uc874\uc758 \ubcf4\uac04\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc(Experiments)"}, {"figure_path": "https://arxiv.org/html/2501.09433/extracted/6135590/figs/scalability.png", "caption": "Figure 7: Scalability of CaPa.\n(a) Original result of CaPa.\n(b) 3D inpainting result using text-prompt (\u201corange sofa, orange pulp\u201d). CaPa\u2019s texture generation extends smoothly to 3D inpainting, stylizing the generated asset.\n(c) CaPa w/ LoRA\u00a0[14] adaptation. The model-agnostic approach allows CaPa to leverage pre-trained LoRA (balloon style) without additional 3D-specific retraining.", "description": "\uadf8\ub9bc 7\uc740 CaPa\uc758 \ud655\uc7a5\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 CaPa\uc758 \uae30\ubcf8 \uacb0\uacfc\ubb3c\uc774\uace0, (b)\ub294 \"\uc624\ub80c\uc9c0\uc0c9 \uc18c\ud30c, \uc624\ub80c\uc9c0\uc0c9 \uacfc\uc721\"\uc774\ub77c\ub294 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec 3D \ud398\uc778\ud305 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. CaPa\uc758 \ud14d\uc2a4\ucc98 \uc0dd\uc131\uc740 3D \ud398\uc778\ud305\uc73c\ub85c \ub9e4\ub044\ub7fd\uac8c \ud655\uc7a5\ub418\uc5b4 \uc0dd\uc131\ub41c \uc790\uc0b0\uc744 \uc2a4\ud0c0\uc77c\ub9c1\ud569\ub2c8\ub2e4. (c)\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c LoRA(\ud48d\uc120 \uc2a4\ud0c0\uc77c)\ub97c \ucd94\uac00\uc801\uc778 3D \ud2b9\uc815 \uc7ac\ud6c8\ub828 \uc5c6\uc774 \ud65c\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 CaPa\uc758 \ubaa8\ub378 \ub3c5\ub9bd\uc801 \uc811\uadfc \ubc29\uc2dd\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.5 CaPa\uc758 \ud655\uc7a5\uc131"}, {"figure_path": "https://arxiv.org/html/2501.09433/x6.png", "caption": "Figure 8: Result of the CaPa with PBR Understanding.\nWe demonstrate CaPa\u2019s capability for disentangling physically based rendering (PBR) materials.\nThe figure shows PBR-aware generation results under various lighting conditions: \u2018city,\u2019 \u2018studio,\u2019 and \u2018night,\u2019 using Blender\u2019s default environment settings\u00a0[7].\nAs shown, CaPa effectively adapts to different light environments, highlighting its potential for PBR-aware asset generation.", "description": "\uadf8\ub9bc 8\uc740 CaPa\uac00 \ubb3c\ub9ac \uae30\ubc18 \ub80c\ub354\ub9c1(PBR) \uba38\ud2f0\ub9ac\uc5bc\uc744 \ubd84\ub9ac\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 '\ub3c4\uc2dc', '\uc2a4\ud29c\ub514\uc624', '\ubc24'\uc758 \uc138 \uac00\uc9c0 \uc870\uba85 \uc870\uac74\uc5d0\uc11c PBR \uc778\uc2dd \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Blender\uc758 \uae30\ubcf8 \ud658\uacbd \uc124\uc815\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4. CaPa\ub294 \ub2e4\uc591\ud55c \uc870\uba85 \ud658\uacbd\uc5d0 \ud6a8\uacfc\uc801\uc73c\ub85c \uc801\uc751\ud558\uc5ec PBR \uc778\uc2dd \uc790\uc0b0 \uc0dd\uc131\uc758 \uc7a0\uc7ac\ub825\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.  \uc989, CaPa\uac00 \uc0dd\uc131\ud55c 3D \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc870\uba85 \ud658\uacbd\uc5d0\uc11c\ub3c4 \uc77c\uad00\ub41c \uc678\uad00\uc744 \uc720\uc9c0\ud558\uba70, \ubb3c\ub9ac \uae30\ubc18 \ub80c\ub354\ub9c1(PBR) \uba38\ud2f0\ub9ac\uc5bc\uc5d0 \ub300\ud55c \uc774\ud574\ub3c4\ub97c \uac00\uc9c0\uace0 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "A. \ub17c\uc758 \ubc0f \ud55c\uacc4\uc810"}, {"figure_path": "https://arxiv.org/html/2501.09433/x7.png", "caption": "Figure 9: Additional Image-to-3D Results of CaPa.\nCaPa can generate diverse objects from textual, and visual input.\nThe result demonstrates our diversity across the various categories, marking a significant advancement in practical 3D asset generation methodologies.", "description": "\uadf8\ub9bc 10\uc740 CaPa\uc758 \ucd94\uac00\uc801\uc778 \uc774\ubbf8\uc9c0-\ud22c-3D \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. CaPa\ub294 \ud14d\uc2a4\ud2b8 \ubc0f \ube44\uc8fc\uc5bc \uc785\ub825\uc73c\ub85c \ub2e4\uc591\ud55c \ubb3c\uccb4\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uacb0\uacfc\ub294 \ub2e4\uc591\ud55c \ubc94\uc8fc\uc5d0\uc11c CaPa\uc758 \ub2e4\uc591\uc131\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uc2e4\uc6a9\uc801\uc778 3D \uc790\uc0b0 \uc0dd\uc131 \ubc29\ubc95\ub860\uc5d0\uc11c \uc911\uc694\ud55c \ubc1c\uc804\uc744 \uc774\ub8e8\uc5c8\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "B. \ucd94\uac00 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.09433/x8.png", "caption": "Figure 10: Additional Comparison of Image-to-3D Generation.\nCaPa significantly outperforms both geometry stability and texture quality, especially for the back and side view\u2019s visual fidelity and texture coherence.", "description": "\uc774 \uadf8\ub9bc\uc740 CaPa \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c 3D \ubaa8\ub378\uc758 \ud488\uc9c8\uc744 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ubc29\ubc95\ub4e4(Unique3D, Era3D, DreamCraft3D, SF3D)\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \ub4b7\uba74\uacfc \uce21\uba74\uacfc \uac19\uc774 \uac00\ub824\uc9c4 \ubd80\ubd84\uc5d0\uc11c CaPa \ubaa8\ub378\uc774 \uae30\ud558\ud559\uc801 \uc548\uc815\uc131\uacfc \uc9c8\uac10\uc758 \uc815\ud655\uc131 \uce21\uba74\uc5d0\uc11c \ud6e8\uc52c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc815\uba74, \uce21\uba74, \ud6c4\uba74 \uc774\ubbf8\uc9c0\ub97c \ube44\uad50\ud558\uc5ec CaPa\uc758 \uc6b0\uc218\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 CaPa\uac00 \ub2e4\uc591\ud55c \uc2dc\uc810\uc5d0\uc11c\ub3c4 \uc77c\uad00\ub41c \uace0\ud488\uc9c8 \ud14d\uc2a4\ucc98\ub97c \uc0dd\uc131\ud558\uba70, \uae30\uc874 \ubc29\ubc95\ub4e4\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud568\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2. Qualitative Comparison"}, {"figure_path": "https://arxiv.org/html/2501.09433/x9.png", "caption": "Figure 11: Impact of Spatially Decoupled Cross Attention on Janus Artifacts.\nIn this additional figure, We demonstrate the capability of Janus prevention in the proposed spatially decoupled cross-attention mechanism.\nEach row depicts, (a) with spatially decoupled cross attention, (b) without spatially decoupled cross attention, and (c) a mesh rendering of the current view, respectively.", "description": "\uadf8\ub9bc 11\uc740 \uc81c\uc548\ub41c \uacf5\uac04\uc801 \ubd84\ub9ac \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc790\ub204\uc2a4 \ud604\uc0c1 \ubc29\uc9c0 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 (a) \uacf5\uac04\uc801 \ubd84\ub9ac \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \uc801\uc6a9, (b) \uacf5\uac04\uc801 \ubd84\ub9ac \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ubbf8\uc801\uc6a9, (c) \ud604\uc7ac \ubdf0\uc758 \uba54\uc2dc \ub80c\ub354\ub9c1\uc744 \uac01\uac01 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ubdf0\uc5d0\uc11c \uc77c\uad00\ub41c \uace0\ud488\uc9c8 \ud14d\uc2a4\ucc98\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uc788\uc5b4\uc11c \uacf5\uac04\uc801 \ubd84\ub9ac \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ucd94\uac00\uc801\uc778 \uc2e4\ud5d8 \uacb0\uacfc\uc785\ub2c8\ub2e4. \uc790\ub204\uc2a4 \ud604\uc0c1\uc774\ub780, 3D \ubaa8\ub378\uc758 \uc11c\ub85c \ub2e4\ub978 \ubdf0\uc5d0\uc11c \ud14d\uc2a4\ucc98\uac00 \ubd88\uc77c\uce58\ud558\ub294 \ud604\uc0c1\uc744 \ub9d0\ud569\ub2c8\ub2e4.", "section": "B.2. Impact of Spatially Decoupled Cross Attention on Janus Artifacts"}, {"figure_path": "https://arxiv.org/html/2501.09433/x10.png", "caption": "Figure 12: Qualitative results for different occlusion inpainting methods.\n(a) shows results from our 3D-aware occlusion inpainting method, (b) uses automatic view selection, and (c) employs UV ControlNet.", "description": "\uadf8\ub9bc 12\ub294 \uc138 \uac00\uc9c0 \uc11c\ub85c \ub2e4\ub978 \ud3d0\uc0c9 \uc601\uc5ed \ucc44\uc6b0\uae30 \ubc29\ubc95\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 3D-aware \ud3d0\uc0c9 \uc601\uc5ed \ucc44\uc6b0\uae30 \ubc29\ubc95\uc758 \uacb0\uacfc\uc774\uace0, (b)\ub294 \uc790\ub3d9 \ubdf0 \uc120\ud0dd \ubc29\ubc95\uc758 \uacb0\uacfc\uc774\uba70, (c)\ub294 UV ControlNet\uc744 \uc0ac\uc6a9\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uac01 \ubc29\ubc95\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubcf4\uc5ec\uc8fc\uace0 3D \uc790\uc0b0 \uc0dd\uc131\uc5d0\uc11c \ud3d0\uc0c9 \uc601\uc5ed \ucc98\ub9ac\uc758 \uc911\uc694\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. \ud2b9\ud788, \ub2e4\uc591\ud55c \ubb3c\uccb4\uc5d0 \ub300\ud55c \uac01 \ubc29\ubc95\uc758 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \uc5b4\ub5a4 \ubc29\ubc95\uc774 \ubcf5\uc7a1\ud55c \ud3d0\uc0c9 \uc601\uc5ed \ucc98\ub9ac\uc5d0 \ub354 \uc801\ud569\ud55c\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc740 \uc11c\ub85c \ub2e4\ub978 \uc7a5\uc810\uacfc \ub2e8\uc810\uc744 \uac00\uc9c0\uace0 \uc788\uc73c\ubbc0\ub85c, \uc2e4\uc81c \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0\uc11c\ub294 \uc5ec\ub7ec \uac00\uc9c0 \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uac00\uc7a5 \uc801\ud569\ud55c \ubc29\ubc95\uc744 \uc120\ud0dd\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4.", "section": "B.3. \ud3d0\uc0c9 \uc601\uc5ed \ubd84\uc11d"}, {"figure_path": "https://arxiv.org/html/2501.09433/x11.png", "caption": "Figure 13: Text-to-3D Results of CaPa.\nCaPa can generate diverse objects from textual, and visual input.\nThe result underscores CaPa\u2019s strengths in generating high-resolution textures that align with well-defined geometries.", "description": "\uc774 \uadf8\ub9bc\uc740 CaPa \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8 \ubc0f \uc2dc\uac01\uc801 \uc785\ub825\uc73c\ub85c\ubd80\ud130 \ub2e4\uc591\ud55c 3D \uac1c\uccb4\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0dd\uc131\ub41c 3D \ubaa8\ub378\ub4e4\uc740 \uace0\ud574\uc0c1\ub3c4\uc758 \uc9c8\uac10\uacfc \uc798 \uc815\uc758\ub41c \uae30\ud558\ud559\uc801 \ud615\ud0dc\ub97c \uac00\uc9c0\uace0 \uc788\uc73c\uba70, CaPa\uac00 \uace0\ud488\uc9c8\uc758 \ud14d\uc2a4\ucc98\uc640 \uc815\ud655\ud55c \uae30\ud558\ud559\uc801 \uad6c\uc870\ub97c \ub3d9\uc2dc\uc5d0 \uc0dd\uc131\ud558\ub294 \ub370 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \uac00\uc9d0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "B. \ucd94\uac00 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.09433/extracted/6135590/figs/remeshing_draft.png", "caption": "Figure 14: Results of Our Remeshing Algorithm.\nWe employ a carefully designed remeshing scheme after geometry generation for better practical usage for broader applications.\n(a) shows the original polygonal mesh, (b) shows remeshed output of quadrilateral faces, and (c) shows remeshed output of triangular faces.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 3D \uba54\uc26c \uc0dd\uc131 \uc54c\uace0\ub9ac\uc998\uc5d0 \ub300\ud55c \ud6c4\ucc98\ub9ac \uacfc\uc815\uc778 \ub9ac\uba54\uc2f1(remeshing) \uae30\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc6d0\ubcf8 \ub2e4\uac01\ud615 \uba54\uc26c(a)\uc5d0\uc11c \uc0ac\uac01\ud615 \uba74\uc73c\ub85c \uad6c\uc131\ub41c \ub9ac\uba54\uc2f1 \uacb0\uacfc(b)\uc640 \uc0bc\uac01\ud615 \uba74\uc73c\ub85c \uad6c\uc131\ub41c \ub9ac\uba54\uc2f1 \uacb0\uacfc(c)\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub9ac\uba54\uc2f1\uc740 3D \uc790\uc0b0\uc744 \ub2e4\uc591\ud55c \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0 \uc2e4\uc81c\ub85c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574 \uae30\ud558\ud559\uc801 \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uacfc\uc815\uc785\ub2c8\ub2e4.  (b)\uc640 (c)\uc758 \uacb0\uacfc\ub294 \ub2e4\uc591\ud55c \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc5d0 \uc801\ud569\ud55c \uace0\ud488\uc9c8 \uba54\uc26c\ub97c \uc5bb\uae30 \uc704\ud55c \uc0ac\uac01\ud615\uacfc \uc0bc\uac01\ud615 \uba54\uc26c\uc758 \uac01\uac01\uc758 \uc7a5\ub2e8\uc810\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud569\ub2c8\ub2e4.", "section": "C.1. \uc790\ub3d9\ud654\ub41c \ub9ac\uba54\uc2f1 \ud6c4\ucc98\ub9ac \uacfc\uc815"}]