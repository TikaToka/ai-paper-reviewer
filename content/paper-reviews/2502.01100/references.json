{"references": [{"fullname_first_author": "Brown, T. B.", "paper_title": "Language models are few-shot learners", "publication_date": "2020-XX-XX", "reason": "This paper is foundational to the field of large language models (LLMs), introducing the concept of few-shot learning and demonstrating its effectiveness, which this paper builds upon."}, {"fullname_first_author": "Chowdhery, A.", "paper_title": "Palm: Scaling language modeling with pathways", "publication_date": "2022-XX-XX", "reason": "This paper explores the scaling of language models and contributes significantly to understanding the capabilities and limitations of LLMs in handling complex language tasks."}, {"fullname_first_author": "Clark, P.", "paper_title": "Transformers as soft reasoners over language", "publication_date": "2020-XX-XX", "reason": "This paper is highly relevant as it introduces the use of transformers as 'soft reasoners', providing a framework to evaluate the logical reasoning capabilities of LLMs, directly relevant to this paper's methodology."}, {"fullname_first_author": "Dechter, R.", "paper_title": "Constraint Processing", "publication_date": "2003-XX-XX", "reason": "This book provides fundamental concepts and techniques in constraint satisfaction problems (CSPs), the theoretical foundation on which this paper's evaluation framework is built."}, {"fullname_first_author": "Liu, H.", "paper_title": "LogiQA: A challenge dataset for machine reading comprehension with logical reasoning", "publication_date": "2020-XX-XX", "reason": "This paper introduces the LogiQA dataset, a benchmark for evaluating logical reasoning in LLMs, offering valuable context and comparison for the ZebraLogic dataset presented in this paper."}]}