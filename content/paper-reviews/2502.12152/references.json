{"references": [{"fullname_first_author": "Yoshua Bengio", "paper_title": "Curriculum learning", "publication_date": "2009-00-00", "reason": "This paper introduces the concept of curriculum learning, a crucial technique used in the two-stage training approach of HUMANUP."}, {"fullname_first_author": "Matthew Loper", "paper_title": "SMPL: a skinned multi-person linear model", "publication_date": "2015-00-00", "reason": "This paper introduces the SMPL model, which provides a detailed 3D human body model used to simulate humanoid robots."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-00-00", "reason": "This paper introduces the Proximal Policy Optimization (PPO) algorithm, the core reinforcement learning algorithm used to train the getting-up policies."}, {"fullname_first_author": "Josh Tobin", "paper_title": "Domain randomization for transferring deep neural networks from simulation to the real world", "publication_date": "2017-00-00", "reason": "This paper details the importance of domain randomization in successfully transferring learned policies from simulation to real-world robots, a key aspect of HUMANUP."}, {"fullname_first_author": "Unitree", "paper_title": "Unitree G1: Humanoid Agent AI Avatar", "publication_date": "2024-00-00", "reason": "This reference provides details on the Unitree G1 robot, the platform on which the learned getting-up policies are tested and deployed."}]}