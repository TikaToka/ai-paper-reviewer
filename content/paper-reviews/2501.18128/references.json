{"references": [{"fullname_first_author": "W. S. El-Kassas", "paper_title": "Automatic text summarization: A comprehensive survey", "publication_date": "2020-07-01", "reason": "This paper provides a comprehensive overview of automatic text summarization techniques, serving as a foundational resource for the current study."}, {"fullname_first_author": "M. F. Mridha", "paper_title": "A Survey of Automatic Text Summarization: Progress, Process and Challenges", "publication_date": "2021-11-01", "reason": "This survey offers insights into the progress, challenges, and future directions of automatic text summarization research, informing the scope of the current study."}, {"fullname_first_author": "M. Zhang", "paper_title": "A Comprehensive Survey of Abstractive Text Summarization Based on Deep Learning", "publication_date": "2022-08-01", "reason": "Focusing specifically on abstractive summarization using deep learning, this paper provides a detailed analysis of relevant methods and techniques."}, {"fullname_first_author": "K. M. Hermann", "paper_title": "Teaching Machines to Read and Comprehend", "publication_date": "2015-11-01", "reason": "This influential paper introduced the CNN/Daily Mail dataset, a key benchmark dataset utilized in the current study for evaluating news summarization models."}, {"fullname_first_author": "R. Nallapati", "paper_title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond", "publication_date": "2016-02-01", "reason": "This paper significantly advanced abstractive text summarization using sequence-to-sequence RNNs, a technique relevant to the current work's investigation of different language models."}]}