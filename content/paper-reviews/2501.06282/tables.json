[{"content": "| Module | Description | Number of Parameters |\n|---|---|---|\n| Voice Encoder | Initialized with the encoder parameters of the pre-trained SenseVoice-Large audio understanding model (An et al., 2024) | ~636M |\n| Input Projector | 2 Transformer layer and 1 CNN layer for dimensional transformation and perform 2x downsampling on the input | ~170M |\n| Large Language Model | Initialized with Qwen2.5-7B-instruct (Team, 2024) | 7B |\n| Output Projector | Linear layer for dimensional transformation | ~6M |\n| Voice Token LM | Initialized with the LLM of the pre-trained CosyVoice2 (Du et al., 2024b) | ~370M |\n| Full Duplex Predictor | 1 Transformer layer and 1 linear-softmax output layer, both randomly initialized | ~18M |", "caption": "Table 1: Descriptions of the modules in MinMo as depicted in Figure\u00a03. MinMo has approximately 8 billion parameters in total.", "description": "\ud45c 1\uc740 \ub17c\ubb38\uc758 \uadf8\ub9bc 3\uc5d0 \ubb18\uc0ac\ub41c MinMo \ubaa8\ub378\uc758 \uac01 \ubaa8\ub4c8\uc5d0 \ub300\ud55c \uc124\uba85\uc744 \uc790\uc138\ud788 \uc81c\uacf5\ud569\ub2c8\ub2e4. MinMo \ubaa8\ub378\uc740 \ucd1d \uc57d 80\uc5b5 \uac1c\uc758 \ud30c\ub77c\ubbf8\ud130\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub4c8\uc758 \uc774\ub984, \uc124\uba85, \uadf8\ub9ac\uace0 \ud30c\ub77c\ubbf8\ud130 \uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 MinMo \ubaa8\ub378\uc758 \uad6c\uc870\uc640 \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uc5ed\ud560\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. Voice Encoder\ub294 \uc74c\uc131 \uc774\ud574\ub97c \ub2f4\ub2f9\ud558\uba70, Input Projector\ub294 \ucc28\uc6d0 \uc815\ud569\uc744 \uc704\ud574 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. Large Language Model\uc740 \uc0ac\uc804 \ud6c8\ub828\ub41c \uc5b8\uc5b4 \ubaa8\ub378\uc774\uace0, Output Projector\uc640 Voice Token LM\uc740 \uc74c\uc131 \uc0dd\uc131\uc5d0 \uad00\uc5ec\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c Full Duplex Predictor\ub294 \uc591\ubc29\ud5a5 \ub300\ud654\ub97c \uc81c\uc5b4\ud558\ub294 \ubaa8\ub4c8\uc785\ub2c8\ub2e4.", "section": "3 MinMo"}, {"content": "| Category | Specific Tasks | Hours |\n|---|---|---|\n| **Speech-to-Text** | Automatic Speech Recognition (ASR) | 630k |\n|  | Speech-to-Text Translation (S2TT) | 451k |\n|  | Language Identification (LID) | 34k |\n|  | Contextual Bias Speech Recognition | 50k |\n|  | Speech Emotion Recognition (SER) | 48k |\n|  | Audio Event Detection (AED) | 11k |\n|  | Speaker Analysis | 24k |\n|  | Spoken Language Smoothing | 0.4k |\n|  | Speech-to-Text Chat | 10k |\n| **Text-to-Speech** | Speech Synthesis | 170k |\n|  | Instruct Speech Synthesis | 1k |\n| **Speech-to-Speech** | Speech-to-Speech chat | 10k |\n|  | Style-controllable Speech-to-Speech Chat | 0.1k |\n| **Speech-to-ControlToken** | Full Duplex Interaction | 4k |", "caption": "Table 2: The multitask training data for MinMo. Task specifications can be found in Section\u00a04.", "description": "MinMo \ubaa8\ub378\uc758 \ub2e4\uc911 \uc791\uc5c5 \ud6c8\ub828 \ub370\uc774\ud130\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \uc791\uc5c5\uc758 \uc885\ub958(\uc74c\uc131 \uc778\uc2dd, \uc74c\uc131-\ud14d\uc2a4\ud2b8 \ubcc0\ud658, \ud14d\uc2a4\ud2b8-\uc74c\uc131 \ubcc0\ud658, \uc74c\uc131 \ub300\ud654 \ub4f1)\uc640 \uac01 \uc791\uc5c5\uc5d0 \uc0ac\uc6a9\ub41c \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uc2dc\uac04(\uc2dc\uac04)\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0 \uc81c\uc2dc\ub41c \uac01 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ubcf8\ubb38 4\uc808\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 \uc791\uc5c5 \ubc0f \ud6c8\ub828 \ub370\uc774\ud130"}, {"content": "| User | Assistant |\n|---|---| \n| **User:** Please speaking very fast: Today is a happy day, full of laughter and joy. | **Assistant:** (Fast speaking rate) Today is a happy day, full of laughter and joy. |\n| **User:** Speaking with a tone of sadness: I miss my dear friend who moved away last month. | **Assistant:** (Sad) I miss my dear friend who moved away last month. |", "caption": "Table 3: Examples of text-to-speech data controlled by instructions.", "description": "\ud45c 3\uc740 \uc0ac\uc6a9\uc790\uc758 \uc9c0\uc2dc\uc5d0 \ub530\ub77c \uc81c\uc5b4\ub418\ub294 \uc74c\uc131\ud569\uc131 \ub370\uc774\ud130\uc758 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc0ac\uc6a9\uc790\uc758 \uac10\uc815, \ubc29\uc5b8, \ub9d0\ud558\ub294 \uc18d\ub3c4, \uc5ed\ud560\uadf9\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc18d\uc131\uc744 \uc9c0\uc815\ud558\ub294 \uc9c0\uc2dc\uc5b4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc74c\uc131\uc744 \uc0dd\uc131\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \ud45c\ub294 \uc774\ub7ec\ud55c \uc9c0\uc2dc\uc5b4\uc5d0 \ub530\ub978 \uc0ac\uc6a9\uc790 \uc785\ub825\uacfc \uc2dc\uc2a4\ud15c\uc758 \uc74c\uc131 \uc751\ub2f5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \uc0ac\uc6a9\uc790\uc758 \uc9c0\uc2dc\uc5d0 \ub530\ub77c \uc74c\uc131 \ud569\uc131\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \uc81c\uc5b4\ud560 \uc218 \uc788\ub294 MinMo \ubaa8\ub378\uc758 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "3.3 \uc791\uc5c5 \ubc0f \ud6c8\ub828 \ub370\uc774\ud130"}, {"content": "| Model | Fleurs(102) |\n|---|---| \n| w2v-bert-51 (0.6B) | 71.4 |\n| mSLAM-CTC (2B) | 77.7 |\n| Zero-shot Whisper | 64.5 |\n| MinMo | **85.3** |", "caption": "Table 4: Summary of evaluation benchmarks for MinMo in this report.", "description": "\ubcf8 \ud45c\ub294 MinMo \ubaa8\ub378\uc758 \uc131\ub2a5 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ubca4\uce58\ub9c8\ud06c\ub4e4\uc758 \uc694\uc57d \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc790\uc138\ud788 \uc0b4\ud3b4\ubcf4\uba74, \ub2e4\uad6d\uc5b4 \uc74c\uc131 \uc778\uc2dd \ubc0f \ubc88\uc5ed, \uc74c\uc131 \ubd84\uc11d \ubc0f \uc774\ud574(\uc74c\uc131 \uac10\uc815 \uc778\uc2dd, \ud654\uc790 \ubd84\uc11d, \uc624\ub514\uc624 \uc774\ubca4\ud2b8 \ud0d0\uc9c0 \ub4f1), \uc74c\uc131 \ud5a5\uc0c1(\ud654\uc790 \uc5b8\uc5b4 \ubd80\ub4dc\ub7fd\uac8c \ud558\uae30, \uad6c\ub450\uc810 \uc0bd\uc785, \uc5ed \uc815\uaddc\ud654 \ub4f1), \uc74c\uc131 \uc0dd\uc131(\ud14d\uc2a4\ud2b8 \uc74c\uc131 \ubcc0\ud658 \ubc0f \uc9c0\uc2dc\uc5b4 \ub530\ub978 \uc74c\uc131 \uc0dd\uc131), \uadf8\ub9ac\uace0 \uc74c\uc131 \ucc44\ud305(\uc9c8\ubb38 \ub2f5\ubcc0, \ub300\ud654, \uc591\ubc29\ud5a5 \ub300\ud654 \ub4f1)\uacfc \uad00\ub828\ub41c \ub2e4\uc591\ud55c \uc791\uc5c5\ub4e4\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ub370\uc774\ud130\uc14b, \ud3c9\uac00 \uc9c0\ud45c\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 Experiments"}, {"content": "| Test Set | MinMo |  |  | SALMONN |  |  | Qwen-Audio |  |  | EmoBox |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | UA | WA | F1 | UA | WA | F1 | UA | WA | F1 | UA | WA | F1 |\n| CASIA | **98.1** | **98.1** | **98.1** | 35.9 | 35.6 | 33.8 | 40.0 | 38.4 | 36.0 | 59.6 | 59.6 | 56.3 |\n| CREMA-D | **94.8** | **94.8** | **94.8** | 49.7 | 50.2 | 43.7 | 82.2 | 83.8 | 83.2 | 76.8 | 76.5 | 76.6 |\n| ESD | **99.9** | **99.9** | **99.9** | 33.9 | 34.5 | 31.7 | 47.3 | 47.4 | 43.6 | 84.6 | 84.6 | 84.3 |\n| IEMOCAP | **74.9** | **75.7** | **74.2** | 59.0 | 60.6 | 59.0 | 69.6 | 67.6 | 62.9 | 73.5 | 72.9 | 73.1 |\n| MELD | **61.0** | **65.1** | **54.0** | 39.2 | 47.2 | 39.6 | 49.9 | 56.8 | 46.8 | 31.5 | 51.9 | 32.9 |\n| MSPPodcast | **66.4** | **74.5** | **62.5** | 40.1 | 58.0 | 40.3 | 57.9 | 70.0 | 54.6 | 21.4 | 43.4 | 21.5 |", "caption": "Table 5: Multilingual speech recognition results from our MinMo and baseline models in terms of word error rate (WER) and character error rate (CER) on Mandarin, English, and multilingual public test sets. Results in parentheses are directly cited from papers. The best result for each test set is boldfaced.", "description": "\ud45c 5\ub294 MinMo\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \ub2e4\uad6d\uc5b4 \uc74c\uc131 \uc778\uc2dd \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub9cc\ub2e4\ub9b0\uc5b4, \uc601\uc5b4 \ubc0f \ub2e4\uad6d\uc5b4 \uacf5\uac1c \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c \ub2e8\uc5b4 \uc624\ub958\uc728(WER)\uacfc \ubb38\uc790 \uc624\ub958\uc728(CER)\uc744 \uae30\uc900\uc73c\ub85c \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4.  \uad04\ud638 \uc548\uc758 \uacb0\uacfc\ub294 \ub17c\ubb38\uc5d0\uc11c \uc9c1\uc811 \uc778\uc6a9\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0 \ub300\ud55c \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub294 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 \uc74c\uc131 \uc778\uc2dd \ubc0f \ubc88\uc5ed"}, {"content": "| Task | MinMo | Qwen-Audio Turbo | Qwen-Audio | Pandagpt | SALMONN | Next-gpt |\n|---|---|---|---|---|---|---|\n| Language ID | **99.2%** | 95.9% | 92.8% | 34.6% | 28.1% | 23.7% |\n| Gender | **86.7%** | 82.5% | 67.2% | 66.5% | 35.5% | 57.0% |\n| Age | **70.1%** | 58.8% | 36.0% | 42.5% | 48.7% | 62.4% |\n| Emotion | **64.5%** | 60.0% | 43.2% | 26.0% | 29.9% | 25.7% |\n| Vocal Sound | **93.0%** | 78.1% | 84.9% | 31.6% | 45.3% | 23.5% |\n| Sound Question | 50.3% | 62.8% | **64.6%** | 48.7% | 28.4% | 18.8% |", "caption": "Table 6: Multilingual speech translation results from MinMo and baseline models on CoVoST2 and Fleurs test sets, in terms of BLEU score (higher is better). Results marked with \u2020 are obtained using translation prompts that specify the source language, rather than only indicating the target language. Results not reported in the original papers have been reproduced by the authors of this work.", "description": "\ud45c 6\uc740 MinMo\uc640 \uae30\uc900 \ubaa8\ub378\uc774 CoVoST2 \ubc0f Fleurs \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c \ub2ec\uc131\ud55c \ub2e4\uad6d\uc5b4 \uc74c\uc131 \ubc88\uc5ed \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. BLEU \uc810\uc218(\ub192\uc744\uc218\ub85d \uc88b\uc74c)\ub97c \uae30\uc900\uc73c\ub85c \ud3c9\uac00\ud588\uc73c\uba70, \u2020 \ud45c\uc2dc\ub294 \ubc88\uc5ed \ud504\ub86c\ud504\ud2b8\uc5d0\uc11c \ub300\uc0c1 \uc5b8\uc5b4\ubfd0 \uc544\ub2c8\ub77c \uc6d0\ubcf8 \uc5b8\uc5b4\ub3c4 \uba85\uc2dc\ud55c \uacbd\uc6b0\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc6d0 \ub17c\ubb38\uc5d0 \ubcf4\uace0\ub418\uc9c0 \uc54a\uc740 \uacb0\uacfc\ub294 \ubcf8 \uc5f0\uad6c \uc800\uc790\ub4e4\uc774 \uc7ac\ud604\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4.1 Speech Recognition and Translation"}, {"content": "| Model | AESDD (el) | CAFE (fr) | RESD (ru) | ASED (am) | EmoDB (de) | EMOVO (it) | MESD (es) | Polish (pl) | SUBESCO (bn) | ShEMO (fa) | URDU (ur) | TurEV-DB (tr) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| wavlm-large | 78.9, 67.6, 67.6 | 62.2, 61.3, 61.1 | 55.8, 56.4, 55.8 | 96.4, 96.4, 96.4 | 92.5, 92.6, 92.5 | 48.8, 48.8, 44.1 | 62.5, 62.4, 62.3 | 79.2, 79.2, 79.0 | 65.3, 65.3, 65.0 | 71.7, 87.1, 73.5 | 86.6, 86.6, 86.6 | 79.5, 80.0, 79.5 |\n| data2vec2.0-large | 72.2, 72.3, 71.8 | 59.0, 58.0, 57.5 | 44.0, 44.6, 44.2 | 94.3, 94.2, 94.2 | 79.3, 80.4, 79.9 | 45.8, 45.8, 43.6 | 48.4, 48.4, 46.8 | 74.0, 74.0, 74.0 | 66.4, 66.4, 66.2 | 64.0, 82.6, 68.4 | 78.1, 78.1, 78.1 | 63.7, 64.1, 63.0 |\n| whisper-large-v3 | 79.1, 79.1, 79.1 | 69.4, 68.8, 68.0 | 54.9, 55.5, 54.9 | **96.7**, **96.7**, **96.7** | 91.2, 92.4, 91.8 | 57.8, 57.8, 56.0 | 69.7, 69.6, 69.6 | **83.2**, **83.2**, **82.7** | 73.0, 73.0, 72.9 | **80.2**, **89.5**, **82.9** | 82.5, 82.5, 82.4 | 81.3, 81.5, 81.3 |\n| MinMo | **96.1**, **96.5**, **96.2** | **94.9**, **94.8**, **94.9** | **76.7**, **78.6**, **76.3** | 75.3, 75.2, 73.7 | **98.4**, **98.7**, **98.7** | **81.7**, **81.1**, **68.3** | **89.5**, **89.1**, **88.6** | 58.1, 58.1, 55.9 | **80.1**, **80.5**, **72.8** | 70.9, 84.0, 72.7 | 82.1, 82.1, 79.4 | **82.0**, **82.1**, **81.6** |", "caption": "Table 7: Language identification results from MinMo and baseline models on the Fleurs data set (covering 102 languages), in terms of Accuracy.", "description": "\ud45c 7\uc740 Fleurs \ub370\uc774\ud130\uc14b(102\uac1c \uc5b8\uc5b4 \ud3ec\ud568)\uc744 \uc0ac\uc6a9\ud558\uc5ec MinMo \ubc0f \uae30\uc900 \ubaa8\ub378\uc758 \uc5b8\uc5b4 \uc2dd\ubcc4 \uacb0\uacfc\ub97c \uc815\ud655\ub3c4 \uce21\uba74\uc5d0\uc11c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  MinMo\uc758 \uc131\ub2a5\uacfc \ube44\uad50 \ub300\uc0c1 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec MinMo \ubaa8\ub378\uc758 \uc5b8\uc5b4 \uc2dd\ubcc4 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uace0, \ub2e4\uc591\ud55c \uc5b8\uc5b4\uc5d0 \ub300\ud55c MinMo\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.", "section": "4.1 Speech Recognition and Translation"}, {"content": "| Source | Target |\n|---|---| \n| **Source** | eh? You have more 1, eh, more one voice, eh, eh, produced in the in the moment. | \n| **Target** | You have more voices producing in the moment. | \n| **Source** | so what, what do they need to do left? | \n| **Target** | What tasks do they need to complete? | \n| **Source** | Well, I think you two, especially you and, and Daniel, you both had, the less creative, roles and the project. That\u2019s true. Of course. | \n| **Target** | I believe that you two, especially you and Daniel, had the less creative roles in the project. |", "caption": "Table 8: Statistics of the test sets for evaluating contextual biasing speech recognition. (hc denotes hard-case hotwords, which are hotwords with recall rates under 40% in basic speech recognition.", "description": "\ud45c 8\uc740 \ubb38\ub9e5\uc801 \ud3b8\ud5a5 \uc74c\uc131 \uc778\uc2dd \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud55c \uc138 \uac00\uc9c0 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub294 \ub2e4\ub978 \ud2b9\uc9d5\uc744 \uac00\uc9c0\uace0 \uc788\uc73c\uba70, \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc758 \ud06c\uae30, \ud3ec\ud568\ub41c \ud56b\uc6cc\ub4dc\uc758 \ube44\uc728, \uae30\ubcf8 \uc74c\uc131 \uc778\uc2dd\uc5d0\uc11c \uc7ac\ud604\uc728\uc774 40% \ubbf8\ub9cc\uc778 \ud558\ub4dc\ucf00\uc774\uc2a4 \ud56b\uc6cc\ub4dc\uc758 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uc815\ubcf4\ub294 \ubb38\ub9e5\uc801 \ud3b8\ud5a5 \uc74c\uc131 \uc778\uc2dd \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uce21\uc815\ud558\uace0 \ube44\uad50\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "3.3 \uc791\uc5c5 \ubc0f \ud6c8\ub828 \ub370\uc774\ud130"}, {"content": "| Model | CER \u2193 | BLEU \u2191 | ROUGE-L \u2191 | BLEURT \u2191 | S-Faithful \u2191 (Human) | S-Faithful \u2191 (LLM) | S-Formal \u2191 (Human) | S-Formal \u2191 (LLM) |\n|---|---|---|---|---|---|---|---|---|\n| Qwen2.5-7B | 0.75 | 21.06 | **42.01** | **64.61** | **9.04** | **8.06** | **9.80** | **7.63** |\n| MinMo | **0.72** | **22.31** | 41.42 | 61.50 | 8.66 | 7.59 | 9.72 | 7.52 |", "caption": "Table 9: Performance of contextual biasing speech recognition from MinMo and the baseline model on the hotwords biasing test sets, in terms of character error rate (CER), recall of hotwords (R), and recall of hard-case hotwords (R-hc).", "description": "\ud45c 9\ub294 MinMo\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc138 \uac00\uc9c0 \uce21\uba74(CER, R, R-hc)\uc5d0\uc11c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \uc9c0\ud45c\ub294 \uac01\uac01 \ubb38\uc790 \uc624\ub958\uc728(Character Error Rate), \ud56b\uc6cc\ub4dc \uc7ac\ud604\uc728(Recall of hotwords), \uc5b4\ub824\uc6b4 \ud56b\uc6cc\ub4dc \uc7ac\ud604\uc728(Recall of hard-case hotwords)\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud56b\uc6cc\ub4dc \ud3b8\ud5a5 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c MinMo\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uc5ec \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 MinMo\uac00 \ud56b\uc6cc\ub4dc \uae30\ubc18 \uc74c\uc131 \uc778\uc2dd \uc791\uc5c5\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1 \uc74c\uc131 \uc778\uc2dd \ubc0f \ubc88\uc5ed"}, {"content": "| Model | PUNC |  | ITN |  | \n|---|---|---|---|---| \n|  | Fleurs-zh | Fleurs-en | Fleurs-zh | Fleurs-en | \n| SenseVoice-L | 2.49 | 1.40 | 2.48 | 1.48 | \n| whisper-large-v3 | 1.23 | 2.49 | 1.39 | 2.43 | \n| MinMo | **2.65** | **2.58** | **2.61** | **2.57** | ", "caption": "Table 10: Performance of contextual biasing speech recognition from MinMo on the general biasing test sets, in terms of character error rate (CER), precision (P), and recall (R).", "description": "\ud45c 10\uc740 \uc77c\ubc18\uc801\uc778 \ubc14\uc774\uc5b4\uc2a4 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c MinMo\uc758 \ubb38\ub9e5 \ubc14\uc774\uc5b4\uc2a4 \uc74c\uc131 \uc778\uc2dd \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \uc8fc\uc694 \uc9c0\ud45c\uc778 \ubb38\uc790 \uc624\ub958\uc728(CER), \uc815\ubc00\ub3c4(P), \uc7ac\ud604\uc728(R)\uc744 \uc0ac\uc6a9\ud558\uc5ec MinMo \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  CER\uc740 \uc624\ub958 \ube44\uc728\uc744 \ub098\ud0c0\ub0b4\uba70, \ub0ae\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. \uc815\ubc00\ub3c4\ub294 \uc62c\ubc14\ub974\uac8c \uc608\uce21\ub41c \ube44\uc728\uc744, \uc7ac\ud604\uc728\uc740 \uc2e4\uc81c \uc591\uc131 \uc0ac\ub840 \uc911 \uc62c\ubc14\ub974\uac8c \uc608\uce21\ub41c \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub192\uc744\uc218\ub85d \uc88b\uc740 \uc9c0\ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 MinMo \ubaa8\ub378\uc774 \ubb38\ub9e5 \ubc14\uc774\uc5b4\uc2a4 \uc74c\uc131 \uc778\uc2dd \uc791\uc5c5\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uace0 \ud6a8\uc728\uc801\uc778\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc815\ub7c9\uc801 \uacb0\uacfc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4.2 \uc74c\uc131 \ubd84\uc11d \ubc0f \uc774\ud574"}, {"content": "| Model | zh CER | zh NMOS | en WER | en NMOS |\n|---|---|---|---|---|\n| CosyVoice 2.0-SFT | 2.06 | 3.73 | 3.19 | 3.71 |\n| MinMo | 2.48 | 3.69 | 2.90 | 3.56 |", "caption": "Table 11: Speech emotion recognition performance from MinMo and the baseline models on various evaluation benchmarks, in terms of unweighted average accuracy (UA), weighted average accuracy (WA), and macro F1 score (F1). Results for SALMONN and Qwen-Audio are reproduced by the authors of this work.", "description": "\ud45c 11\uc740 \ub2e4\uc591\ud55c \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c MinMo\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \uc74c\uc131 \uac10\uc815 \uc778\uc2dd \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc131\ub2a5 \uc9c0\ud45c\ub294 \uac00\uc911\uce58\uac00 \uc5c6\ub294 \ud3c9\uade0 \uc815\ud655\ub3c4(UA), \uac00\uc911\uce58\uac00 \uc788\ub294 \ud3c9\uade0 \uc815\ud655\ub3c4(WA), \uadf8\ub9ac\uace0 \ub9e4\ud06c\ub85c F1 \uc810\uc218(F1)\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. SALMONN\uacfc Qwen-Audio\uc758 \uacb0\uacfc\ub294 \ub17c\ubb38 \uc800\uc790\ub4e4\uc5d0 \uc758\ud574 \uc7ac\ud604\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \uac01 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b(CREMA-D, MELD, IEMOCAP, MSP-Podcast, CASIA, MER2023, ESD)\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc74c\uc131 \uac10\uc815\uc744 \uc778\uc2dd\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc740 \ub2e4\ub978 \uc5b8\uc5b4\uc640 \uc2dc\ub098\ub9ac\uc624 (\uc5f0\uae30, \ub4dc\ub77c\ub9c8, \uc77c\uc0c1 \ub300\ud654 \ub4f1)\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 \uc74c\uc131 \ubd84\uc11d \ubc0f \uc774\ud574"}, {"content": "| Model | Emotion | Dialect | Speaking Rate | Role-playing | Default | Total |\n|---|---|---|---|---|---|---|\n| GLM-4-Voice | 75.6 | 42.9 | 80.0 | 70.4 | 88.2 | 63.1 |\n| MinMo | 97.6 | 100 | 100 | 96.3 | 96.3 | 98.4 |", "caption": "Table 12: Performance comparison between MinMo and the baseline models on the AIR-Bench benchmark, including Language ID, Gender, Age, Emotion, Vocal Sound, and Sound Question classification tasks, in terms of Accuracy. Results of Qwen-Audio and Qwen-Audio-Turbo\u00a0(Chu et\u00a0al., 2023), Pandagpt\u00a0(Su et\u00a0al., 2023), SALMONN\u00a0(Tang et\u00a0al., 2024) and Next-gpt\u00a0(Wu et\u00a0al., 2024) are cited from the official AIR-Bench website.", "description": "\ud45c 12\ub294 AIR-Bench \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c MinMo\uc640 \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc5b8\uc5b4 \uc2dd\ubcc4, \uc131\ubcc4, \ub098\uc774, \uac10\uc815, \uc74c\uc131 \uc0ac\uc6b4\ub4dc \ubc0f \uc0ac\uc6b4\ub4dc \uc9c8\ubb38 \ubd84\ub958 \uc791\uc5c5\uc744 \ud3ec\ud568\ud558\uba70, \uc815\ud655\ub3c4\ub97c \uae30\uc900\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4. Qwen-Audio \ubc0f Qwen-Audio-Turbo (Chu et al., 2023), Pandagpt (Su et al., 2023), SALMONN (Tang et al., 2024) \ubc0f Next-gpt (Wu et al., 2024)\uc758 \uacb0\uacfc\ub294 \uacf5\uc2dd AIR-Bench \uc6f9\uc0ac\uc774\ud2b8\uc5d0\uc11c \uc778\uc6a9\ud588\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Llama Question |  | TriviaQA* |  | Web Questions |  |\n|---|---|---|---|---|---|---|\n| Moshi (D\u00e9fossez et al., 2024) | 62.3 | 21 | 22.8 | 7.3 | 26.6 | 9.2 |\n| GLM-4-Voice (Zeng et al., 2024) | 64.7 | 50.7 | 39.1 | 26.5 | 32.2 | 15.9 |\n| Freeze-Omni (Wang et al., 2024b) | 72.0 | - | 53.9 | - | 44.7 | - |\n| MinMo | **78.9** | **64.1** | 48.3 | 37.5 | **55.0** | **39.9** |\n|  | S2T | S2S | S2T | S2S | S2T | S2S |", "caption": "Table 13: SER performance of MinMo and the baseline models on the multi-languages datasets from EmoBox, in terms of unweighted average accuracy (UA), weighted average accuracy (WA), and macro F1 score (F1).", "description": "\ud45c 13\uc740 \ub2e4\uc591\ud55c \uc5b8\uc5b4\uc758 EmoBox \ub370\uc774\ud130\uc14b\uc5d0\uc11c MinMo\uc640 \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uc74c\uc131 \uac10\uc815 \uc778\uc2dd(SER) \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ud3c9\uac00 \uc9c0\ud45c\uc778 \uac00\uc911\uce58 \uc5c6\ub294 \ud3c9\uade0 \uc815\ud655\ub3c4(UA), \uac00\uc911\uce58 \uc788\ub294 \ud3c9\uade0 \uc815\ud655\ub3c4(WA), \uadf8\ub9ac\uace0 \ub9e4\ud06c\ub85c F1 \uc810\uc218(F1)\ub97c \uc0ac\uc6a9\ud558\uc5ec MinMo\uc758 SER \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uae30\uc900 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 MinMo\uc758 \ub2e4\uad6d\uc5b4 SER \uc131\ub2a5\uacfc \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4.2 \uc74c\uc131 \ubd84\uc11d \ubc0f \uc774\ud574"}, {"content": "|                   | Alpaca Test (Li et al., 2023) | ChitChat Test |\n| :----------------- | :------------------------: | :------------: |\n| Ground Truth        | 7.73                        | 7.62          |\n| ASR + Qwen2.5      | 6.59                        | 7.18          |\n| MinMo              | 6.48                        | 7.20          |", "caption": "Table 14: Examples of the source and the prediction of MinMo for the spoken language smoothing task, sampled from the SWAB test set.", "description": "\ubcf8 \ud45c\ub294 \ub17c\ubb38\uc758 SWAB \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ud55c \uc74c\uc131 \uc5b8\uc5b4 \ub2e4\ub4ec\uae30 \uc791\uc5c5\uc5d0 \ub300\ud55c MinMo\uc758 \uc18c\uc2a4 \ubc0f \uc608\uce21 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  MinMo \ubaa8\ub378\uc774 ASR \uc804\uc0ac\ub97c \uc5bc\ub9c8\ub098 \uc798 \ub2e4\ub4ec\uc5b4\uc11c \uc790\uc5f0\uc2a4\ub7fd\uace0 \ud615\uc2dd\uc801\uc778 \ud14d\uc2a4\ud2b8\ub85c \ubcc0\ud658\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uad6c\uccb4\uc801\uc778 \uc608\uc2dc\ub4e4\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uac01 \uc608\uc2dc\ub294 \uc6d0\ubcf8 ASR \uacb0\uacfc(Source)\uc640 MinMo \ubaa8\ub378\uc758 \uc608\uce21 \uacb0\uacfc(Target)\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc9c1\uc811\uc801\uc73c\ub85c \ube44\uad50\ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4.", "section": "4.3 Speech-to-Text Enhancement"}, {"content": "| Full-duplex predictor | Speech-to-text | Text-to-speech token | Token2Wav |\n|---|---|---|---| \n| (Assistant turn-taking) | (1 or 5 text tokens) | (15 speech tokens) |  |\n| 250ms | 95ms or 150ms | 70ms | 130ms |", "caption": "Table 15: Spoken language smoothing performance of MinMo and Qwen2.5-7B on the SWAB test set, in terms of objective metrics (CER, BLEU, ROUGE-L, and BLEURT)", "description": "\ud45c 15\ub294 SWAB \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c MinMo\uc640 Qwen2.5-7B\uc758 \uc5b4\ud718 \ub2e8\uc704 \ud3c9\uac00 \uc9c0\ud45c(CER, BLEU, ROUGE-L, BLEURT)\ub97c \uae30\ubc18\uc73c\ub85c \ud55c \uad6c\uc5b4\uccb4 \uc5b8\uc5b4 \ub2e4\ub4ec\uae30 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CER(Character Error Rate)\uc740 \ubb38\uc790 \uc624\ub958\uc728, BLEU(Bilingual Evaluation Understudy)\ub294 \uae30\uacc4 \ubc88\uc5ed\uc758 \uc815\ud655\ub3c4\ub97c \uce21\uc815\ud558\ub294 \uc9c0\ud45c, ROUGE-L(Recall-Oriented Understudy for Gisting Evaluation)\uc740 \uc694\uc57d\uc758 \uc77c\uce58\ub3c4\ub97c \uce21\uc815\ud558\ub294 \uc9c0\ud45c, BLEURT(Bilingual Evaluation Understudy using Representations from Transformers)\ub294 \ucd5c\uc2e0\uc758 \ubb38\uc7a5 \uc0dd\uc131 \ud3c9\uac00 \uc9c0\ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 MinMo\uc640 Qwen2.5-7B \ubaa8\ub378\uc774 \uc5bc\ub9c8\ub098 \ud6a8\uacfc\uc801\uc73c\ub85c \uad6c\uc5b4\uccb4 \ud14d\uc2a4\ud2b8\ub97c \uae54\ub054\ud558\uace0 \uc815\ud655\ud55c \ubb38\uc7a5\uc73c\ub85c \ubc14\uafb8\ub294\uc9c0\ub97c \ubaa9\ud45c \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3.3 \uc791\uc5c5 \ubc0f \ud6c8\ub828 \ub370\uc774\ud130"}, {"content": "| Data | Assistant's Turn-taking (Pos. F1, @K=1/5/10) | User's Turn-taking (Pos. F1, @K=1/5/10) | User's Back-channel (Acc.) |\n|---|---|---|---|\n| Alimeeting | 0.6138 / 0.7542 / 0.8036 | 0.4751 / 0.9366 / 1 | 0.7124 |\n| Fisher | 0.6682 / 0.8372 / 0.8813 | 0.4271 / 0.9455 / 0.9994 | 0.8123 |\n| Simulation | 0.7868 / 0.9616 / 0.985 | 0.2571 / 0.8152 / 0.9942 | - |", "caption": "Table 16: GPT-4 Turbo ranking scores of punctuation insertion and ITN for MinMo and the baseline models on the Chinese and English subsets of the Fleurs dataset.", "description": "\ubcf8 \ud45c\ub294 Fleurs \ub370\uc774\ud130\uc14b\uc758 \uc911\uad6d\uc5b4 \ubc0f \uc601\uc5b4 \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 MinMo\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \uad6c\ub450\uc810 \uc0bd\uc785 \ubc0f ITN(Inverse Text Normalization) \uc131\ub2a5\uc744 GPT-4 Turbo \uc21c\uc704 \uc810\uc218\ub85c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 GPT-4 Turbo\uc5d0 \uc758\ud574 \uc8fc\uad00\uc801\uc73c\ub85c \ud3c9\uac00\ub418\uc5c8\uc73c\uba70,  \uad6c\ub450\uc810 \uc0ac\uc6a9\uc758 \uc801\uc808\uc131 \ubc0f ITN\uc758 \uc815\ud655\uc131\uc744 \uc885\ud569\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4. 1\uc704\ub294 3\uc810, 2\uc704\ub294 2\uc810, 3\uc704\ub294 1\uc810\uc73c\ub85c \uc810\uc218\uac00 \ub9e4\uaca8\uc9c0\uace0, \ucd5c\uc885 \uc810\uc218\ub294 \ubaa8\ub4e0 \uc810\uc218\uc758 \ud3c9\uade0\uc785\ub2c8\ub2e4.", "section": "4.3 \uc74c\uc131 \uc0dd\uc131"}, {"content": "| Assistant\u2019s Turn-taking |\n|---|---|---|---|---|\n| (Pos. F1, @K=1/5/10) | | | | |", "caption": "Table 17: Performance comparison of content consistency (CER/WER) and objective speech quality (NMOS) between MinMo and the TTS baseline CosyVoice 2.0-SFT on the text-to-speech Chinese (zh) and English (en) test sets.", "description": "\ud45c 17\uc740 \uc911\uad6d\uc5b4(zh)\uc640 \uc601\uc5b4(en) \ud14d\uc2a4\ud2b8 \uc74c\uc131 \ubcc0\ud658 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c MinMo\uc640 TTS \uae30\uc900 \ubaa8\ub378\uc778 CosyVoice 2.0-SFT\uc758 \ub0b4\uc6a9 \uc77c\uad00\uc131(CER/WER)\uacfc \uac1d\uad00\uc801 \uc74c\uc131 \ud488\uc9c8(NMOS)\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub0b4\uc6a9 \uc77c\uad00\uc131\uc740 \uc790\ub3d9 \uc74c\uc131 \uc778\uc2dd \uc624\ub958\uc728(CER)\uacfc \ub2e8\uc5b4 \uc624\ub958\uc728(WER)\ub85c \uce21\uc815\ub418\uc5c8\uace0, \uc74c\uc131 \ud488\uc9c8\uc740 NMOS \uc810\uc218\ub85c \ud3c9\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 MinMo\uc758 \uc74c\uc131 \uc0dd\uc131 \uc131\ub2a5\uacfc \uae30\uc900 \ubaa8\ub378\uacfc\uc758 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc8fc\uc694 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3.2 \uc2a4\ud2b8\ub9ac\ubc0d \uc74c\uc131 \ub514\ucf54\ub354"}, {"content": "| User\u2019s Turn-taking |\n|---|---|---| \n| (Pos. F1, @K=1/5/10) | | |", "caption": "Table 18: Performance comparison of instruction-following voice generation between MinMo and the baseline GLM-4-Voice on the multi-turn speech-to-speech Chinese test set.", "description": "\ud45c 18\uc740 MinMo\uc640 \uae30\uc900 GLM-4-Voice \ubaa8\ub378\uc758 \uba85\ub839\uc5b4\ub97c \ub530\ub974\ub294 \uc74c\uc131 \uc0dd\uc131 \uc131\ub2a5\uc744 \ub2e4\uc911 \ud68c\uc804 \uc74c\uc131-\uc74c\uc131 \uc911\uad6d\uc5b4 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc9c0\uc2dc(\uac10\uc815, \ubc29\uc5b8, \ub9d0\ud558\uae30 \uc18d\ub3c4, \uc5ed\ud560\uadf9 \ub4f1)\uc5d0 \ub530\ub978 \uc74c\uc131 \uc0dd\uc131 \uc815\ud655\ub3c4\ub97c \ud3c9\uac00\ud558\uc5ec MinMo\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 \uc74c\uc131 \uc0dd\uc131"}, {"content": "| User\u2019s Back-channel |\n|---|---| \n|(Acc. )|", "caption": "Table 19: Comparison of Spoken Question Answering Performance: Results for Moshi, GLM-4-Voice, and Freeze-Omni are sourced from their respective papers. S2T refers to the Speech-to-Text evaluation, while S2S denotes the Speech-to-Speech evaluation. The metric used for these assessments is accuracy. The TriviaQA\u2217 dataset does not provide a public test set, so the numerical results are not directly comparable and should be considered for reference only.", "description": "\ud45c 19\ub294 \uc74c\uc131 \uc9c8\ubb38 \ub2f5\ubcc0 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Moshi, GLM-4-Voice, Freeze-Omni \ubaa8\ub378\uc758 \uacb0\uacfc\ub294 \ud574\ub2f9 \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4. S2T\ub294 \uc74c\uc131-\ud14d\uc2a4\ud2b8 \ud3c9\uac00\ub97c, S2S\ub294 \uc74c\uc131-\uc74c\uc131 \ud3c9\uac00\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud3c9\uac00 \uc9c0\ud45c\ub294 \uc815\ud655\ub3c4\uc785\ub2c8\ub2e4. TriviaQA* \ub370\uc774\ud130\uc14b\uc740 \uacf5\uac1c \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub97c \uc81c\uacf5\ud558\uc9c0 \uc54a\uc73c\ubbc0\ub85c, \uc218\uce58 \uacb0\uacfc\ub294 \uc9c1\uc811 \ube44\uad50\ud560 \uc218 \uc5c6\uc73c\uba70 \ucc38\uace0\uc6a9\uc73c\ub85c\ub9cc \uac04\uc8fc\ud574\uc57c \ud569\ub2c8\ub2e4.", "section": "4.5 \uc74c\uc131 \ucc44\ud305"}, {"content": "| Data | Average Latency (ms.) |  | \n|---|---|---| \n|  | Assistant\u2019s Turn-taking | User\u2019s Turn-taking | \n| Alimeeting | 448.8 | 663.4 | \n| Fisher | 189.1 | 641.8 | \n| Simulation | 88.8 | 673.7 | ", "caption": "Table 20: Performance of MinMo in two in-house multi-turn speech-to-speech test sets: the Alpaca test set and the ChitChat test set. The Alpaca test set focuses on assessing logical reasoning capabilities, while the ChitChat test set is designed to evaluate casual conversational scenarios. For scoring, we utilized the Qwen-Max model.", "description": "\ud45c 20\uc740 MinMo \ubaa8\ub378\uc758 \ub300\ud654 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \ub450 \uac00\uc9c0 \uc0ac\ub0b4 \ub2e4\ud68c\ucc28 \uc74c\uc131-\uc74c\uc131 \ub300\ud654 \ud14c\uc2a4\ud2b8 \uc138\ud2b8(\uc54c\ud30c\uce74 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc640 ChitChat \ud14c\uc2a4\ud2b8 \uc138\ud2b8)\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc54c\ud30c\uce74 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub294 \ub17c\ub9ac\uc801 \ucd94\ub860 \ub2a5\ub825 \ud3c9\uac00\uc5d0 \uc911\uc810\uc744 \ub450\uace0, ChitChat \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub294 \uc77c\uc0c1\uc801\uc778 \ub300\ud654 \uc0c1\ud669 \ud3c9\uac00\uc5d0 \ucd08\uc810\uc744 \ub9de\ucda5\ub2c8\ub2e4. \uc810\uc218\ub294 Qwen-Max \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc790\ub3d9\uc73c\ub85c \ub9e4\uacbc\uc2b5\ub2c8\ub2e4.", "section": "4 Experiments"}]