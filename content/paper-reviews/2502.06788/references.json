{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-XX", "reason": "This paper introduces Flamingo, a significant visual language model that heavily influenced the design and development of encoder-free VLMs, forming a crucial foundational model for the current research."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-XX-XX", "reason": "This work is highly influential for introducing the Transformer architecture to image recognition, which has become a cornerstone for many modern vision and vision-language models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-XX", "reason": "This paper introduced CLIP, a groundbreaking model demonstrating the effectiveness of learning visual representations from natural language supervision, significantly impacting the field of vision-language research."}, {"fullname_first_author": "Junnan Li", "paper_title": "BLIP: bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-XX-XX", "reason": "BLIP is a highly influential model that demonstrated the potential of unified vision-language models, paving the way for simpler and more efficient multimodal systems, directly impacting the development of encoder-free approaches."}, {"fullname_first_author": "Haiwen Diao", "paper_title": "Unveiling encoder-free vision-language models", "publication_date": "2024-06-XX", "reason": "This paper is a direct predecessor to the current work, laying the groundwork for exploring and improving encoder-free VLMs, providing valuable insights and strategies for the current research."}]}