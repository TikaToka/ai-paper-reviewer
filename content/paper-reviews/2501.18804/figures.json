[{"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/diagram_new.png", "caption": "Figure 1: \nMVGD is a state-of-the-art method that generates\nimages and scale-consistent depth maps from novel viewpoints given an arbitrary number of posed input views. In the above, red cameras are used as conditioning to directly generate RGB-D predictions from green cameras. To highlight the multi-view consistency of our method, predicted colored pointclouds from all novel viewpoints are stacked together for visualization without any post-processing. More examples and videos can be found in https://mvgd.github.io/", "description": "\uadf8\ub9bc 1\uc740 \uc81c\uc2dc\ub41c \uc784\uc758\uc758 \uc218\uc758 \ud3ec\uc988\ub41c \uc785\ub825 \ubdf0\ub97c \uae30\ubc18\uc73c\ub85c \uc0c8\ub85c\uc6b4 \ubdf0\ud3ec\uc778\ud2b8\uc5d0\uc11c \uc774\ubbf8\uc9c0\uc640 \ud06c\uae30\uac00 \uc77c\uad00\ub41c \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \ucd5c\ucca8\ub2e8 \ubc29\ubc95\uc778 MVGD\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube68\uac04\uc0c9 \uce74\uba54\ub77c\ub294 \ucd08\ub85d\uc0c9 \uce74\uba54\ub77c\uc758 RGB-D \uc608\uce21\uc744 \uc9c1\uc811 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \uc870\uac74\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\uc758 \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131\uc744 \uac15\uc870\ud558\uae30 \uc704\ud574 \ubaa8\ub4e0 \uc0c8\ub85c\uc6b4 \ubdf0\ud3ec\uc778\ud2b8\uc5d0\uc11c \uc608\uce21\ub41c \uc0c9\uc0c1 \ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc\uac00 \ud6c4\ucc98\ub9ac \uc5c6\uc774 \uc2dc\uac01\ud654\ub97c \uc704\ud574 \ud568\uaed8 \uc313\uc5ec\uc838 \uc788\uc2b5\ub2c8\ub2e4. \ub354 \ub9ce\uc740 \uc608\uc2dc\uc640 \ube44\ub514\uc624\ub294 https://mvgd.github.io/ \uc5d0\uc11c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/motion/all_mod22.png", "caption": "Figure 2: \nDiagram of our proposed Multi-View Geometric Diffusion (MVGD) framework, at inference time. N\ud835\udc41Nitalic_N input images \ud835\udc08cnsuperscriptsubscript\ud835\udc08\ud835\udc50\ud835\udc5b\\mathbf{I}_{c}^{n}bold_I start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT with cameras \ud835\udc9ecnsuperscriptsubscript\ud835\udc9e\ud835\udc50\ud835\udc5b\\mathcal{C}_{c}^{n}caligraphic_C start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT are used for scene conditioning, and a different camera \ud835\udc9etsubscript\ud835\udc9e\ud835\udc61\\mathcal{C}_{t}caligraphic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is selected for novel view and depth synthesis.", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c \ub2e4\uc911 \ubdf0 \uae30\ud558\ud559\uc801 \ud655\uc0b0(MVGD) \ud504\ub808\uc784\uc6cc\ud06c\uc758 \ucd94\ub860 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  N\uac1c\uc758 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uce74\uba54\ub77c \uc815\ubcf4\uac00 \uc7a5\uba74 \uc870\uac74 \uc124\uc815\uc5d0 \uc0ac\uc6a9\ub418\uace0, \uc0c8\ub85c\uc6b4 \ubdf0\uc640 \uae4a\uc774 \ud569\uc131\uc744 \uc704\ud574 \ub2e4\ub978 \uce74\uba54\ub77c\uac00 \uc120\ud0dd\ub429\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0\ub4e4\uc740 \uac01\uac01 \uace0\uc720\ud55c \uce74\uba54\ub77c \uc704\uce58\uc640 \ubc29\ud5a5 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc73c\uba70, \uc774 \uc815\ubcf4\ub4e4\uc740 \uc0c8\ub85c\uc6b4 \ubdf0\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud55c \uae30\uc900\uc73c\ub85c \ud65c\uc6a9\ub429\ub2c8\ub2e4. MVGD\ub294 \uc774\ub7ec\ud55c \ub2e4\uc911 \ubdf0 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc744 \ub3d9\uc2dc\uc5d0 \uc0dd\uc131\ud558\ub294 \ub2e4\uc911 \uc791\uc5c5 \ud559\uc2b5 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.  \ub808\uc774(Ray) \uc778\ucf54\ub354\ub294 \uce74\uba54\ub77c \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\uc5ec \uacf5\uac04\uc801 \uc815\ubcf4\ub97c \ucd94\uac00\ud558\uace0, \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\ub294 \uc785\ub825 \uc774\ubbf8\uc9c0\uc758 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4.  \uc774 \uc815\ubcf4\ub4e4\uc740 \ud655\uc0b0 \uacfc\uc815\uc744 \ud1b5\ud574 \uc0c8\ub85c\uc6b4 \ubdf0\uc640 \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \uc7a5\uba74 \ud1a0\ud070(Scene Tokens)\uc740 \uc7a5\uba74 \uc815\ubcf4\ub97c \ub098\ud0c0\ub0b4\uace0, \uc608\uce21 \ud1a0\ud070(Prediction Tokens)\uc740 \uc0dd\uc131\ub420 \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc758 \uc885\ub958\ub97c \uacb0\uc815\ud569\ub2c8\ub2e4.  \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc740 \uc7a5\uba74 \ud06c\uae30\uc5d0 \ub9de\ucdb0 \uc815\uaddc\ud654\ub418\uc5b4 \uc77c\uad00\uc131 \uc788\ub294 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "3. Multi-View Geometric Diffusion"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/motion/all_mod2.png", "caption": "Figure 3: \nMVGD novel view and depth synthesis results randomly sampled from different evaluation benchmarks and in-the-wild datasets. Top images are conditioning views (colored cameras), and bottom images are the target view (black camera), showing from left-to-right: ground-truth image, predicted image, and predicted depth map. These predictions are used to produce a colored 3D pointcloud observed from the target view. For more examples and additional visualizations, please refer to the supplementary material.", "description": "\uadf8\ub9bc 3\uc740 \uc81c\uc548\ub41c \ub2e4\uc911 \ubdf0 \uae30\ud558\ud559\uc801 \ud655\uc0b0(MVGD) \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c \ubc0f \uc2e4\uc81c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc0dd\uc131\ud55c \uc0c8\ub85c\uc6b4 \ubdf0\uc640 \uae4a\uc774 \ud569\uc131 \uacb0\uacfc\ub97c \ubb34\uc791\uc704\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc704\ucabd \uc774\ubbf8\uc9c0\ub294 \uc870\uac74 \uc774\ubbf8\uc9c0(\uc0c9\uc0c1\uc774 \uc788\ub294 \uce74\uba54\ub77c)\uc774\uace0, \uc544\ub798\ucabd \uc774\ubbf8\uc9c0\ub294 \ubaa9\ud45c \ubdf0(\uac80\uc740\uc0c9 \uce74\uba54\ub77c)\uc774\uba70, \uc67c\ucabd\uc5d0\uc11c \uc624\ub978\ucabd\uc73c\ub85c \uc21c\uc11c\ub300\ub85c \uc2e4\uc81c \uc774\ubbf8\uc9c0, \uc608\uce21 \uc774\ubbf8\uc9c0, \uc608\uce21 \uae4a\uc774 \ub9f5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \uc608\uce21\uc740 \ubaa9\ud45c \ubdf0\uc5d0\uc11c \uad00\ucc30\ub41c 3D \uc810 \uad6c\ub984\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \ub354 \ub9ce\uc740 \uc608\uc640 \ucd94\uac00 \uc2dc\uac01\ud654\ub294 \ubcf4\ucda9 \uc790\ub8cc\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/incremental2/RealEstate10k/5/all.png", "caption": "Table 6: Stereo depth experiments, with 2 conditioning views. Results on ScanNet are in-domain, and results on SUN3D and RGB-D are zero-shot.", "description": "\ud45c 6\uc740 \ub450 \uac1c\uc758 \uc870\uac74\ubd80 \ubdf0\ub97c \uc0ac\uc6a9\ud55c \uc2a4\ud14c\ub808\uc624 \uae4a\uc774 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ScanNet\uc5d0 \ub300\ud55c \uacb0\uacfc\ub294 \ub3c4\uba54\uc778 \ub0b4\uc774\uba70, SUN3D \ubc0f RGB-D\uc5d0 \ub300\ud55c \uacb0\uacfc\ub294 \uc81c\ub85c\uc0f7\uc785\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b(ScanNet, SUN3D, RGB-D)\uc5d0\uc11c \uc81c\ub85c\uc0f7(zero-shot) \ubc29\uc2dd\uc73c\ub85c \uae4a\uc774 \uc608\uce21 \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \uac1c\uc758 \uc785\ub825 \uc774\ubbf8\uc9c0\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc5ec \uae4a\uc774 \ub9f5\uc744 \uc608\uce21\ud558\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  ScanNet\uc740 \ubaa8\ub378\uc774 \ud559\uc2b5\ub41c \ub370\uc774\ud130\uc14b\uc774\ubbc0\ub85c \ub3c4\uba54\uc778 \ub0b4(in-domain) \ud3c9\uac00\uc774\uace0, SUN3D\uc640 RGB-D\ub294 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\uc14b\uc774\ubbc0\ub85c \uc81c\ub85c\uc0f7(zero-shot) \ud3c9\uac00\uc785\ub2c8\ub2e4.  Abs. Rel, Sq. Rel, RMSE, \u03b41, \u03b42, \u03b43 \uc9c0\ud45c\ub97c \ud1b5\ud574 \uae4a\uc774 \uc608\uce21\uc758 \uc815\ud655\ub3c4\ub97c \ub2e4\uac01\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4.4. Multi-View Depth Estimation"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/incremental2/CO3Dv2/2/all.png", "caption": "Table 7: Video depth experiments on ScanNet (in-domain), with 10101010 conditioning views.", "description": "\ud45c 7\uc740 ScanNet \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'in-domain'\uc774\ub77c\ub294 \uac83\uc740, \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uacfc \uac19\uc740 \uc885\ub958\uc758 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud588\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. 10\uac1c\uc758 \uc870\uac74\ubd80 \ubdf0(conditioning views)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\ud5d8\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc744 \ube44\uad50\ud558\uc5ec MVGD \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ubaa9\uc801\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 \uc808\ub300 \uc0c1\ub300 \uc624\ucc28(Abs. Rel), \uc81c\uacf1 \uc0c1\ub300 \uc624\ucc28(Sq. Rel), RMSE(Root Mean Squared Error) \ub4f1\uc758 \uc9c0\ud45c\ub85c \ud3c9\uac00\ub429\ub2c8\ub2e4.  \uae4a\uc774 \ucd94\uc815\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec MVGD\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4. \uba40\ud2f0\ubdf0 \uae4a\uc774 \ucd94\uc815"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/teaser5.png", "caption": "Figure 4: \nZero-Shot MVGD novel view and depth synthesis results randomly sampled from different evaluation benchmarks and in-the-wild datasets. Top left images are conditioning views (colored cameras), and bottom images are the target view (black camera), showing from left-to-right: ground-truth image, predicted image, and predicted depth map. These predictions are used to produce a colored 3D pointcloud observed from the target viewpoint.", "description": "\uadf8\ub9bc 4\ub294 \uc81c\ub85c\uc0f7 MVGD\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c \ubc0f \uc2e4\uc81c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \uc0d8\ud50c\ub9c1\ud55c \uc0c8\ub85c\uc6b4 \ubdf0 \ubc0f \uae4a\uc774 \ud569\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uc0c1\ub2e8 \uc774\ubbf8\uc9c0\ub294 \uc870\uac74\ubd80 \ubdf0(\uc0c9\uc0c1 \uce74\uba54\ub77c)\uc774\uace0, \uc544\ub798\ucabd \uc774\ubbf8\uc9c0\ub294 \ub300\uc0c1 \ubdf0(\uac80\uc815\uc0c9 \uce74\uba54\ub77c)\uc774\uba70, \uc67c\ucabd\uc5d0\uc11c \uc624\ub978\ucabd\uc73c\ub85c \uc21c\uc11c\ub300\ub85c \uc2e4\uc81c \uc774\ubbf8\uc9c0, \uc608\uce21 \uc774\ubbf8\uc9c0, \uc608\uce21 \uae4a\uc774 \ub9f5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc608\uce21\uc740 \ub300\uc0c1 \ubdf0\ud3ec\uc778\ud2b8\uc5d0\uc11c \uad00\ucc30\ub41c \uceec\ub7ec 3D \ud3ec\uc778\ud2b8 \ud074\ub77c\uc6b0\ub4dc\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 MVGD \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc0c8\ub85c\uc6b4 \ubdf0\uc640 \uae4a\uc774\ub97c \uc815\ud655\ud558\uac8c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/teaser3.png", "caption": "Figure 5: Accumulated MVGD pointclouds, obtained by generating novel images and depth maps from various viewpoints (black cameras), using the same conditioning views (colored cameras), and stacking them together without any post-processing. Our zero-shot architecture is capable of directly generating multi-view consistent predictions that match the scale from conditioning cameras.", "description": "\uadf8\ub9bc 5\ub294 \uc81c\uc548\ub41c \ub2e4\uc911 \ubdf0 \uae30\ud558\ud559\uc801 \ud655\uc0b0(MVGD) \ubaa8\ub378\uc774 \uc5ec\ub7ec \uad00\uc810(\uac80\uc740\uc0c9 \uce74\uba54\ub77c)\uc5d0\uc11c \uc0c8\ub85c\uc6b4 \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\uc5ec \uc5bb\uc5b4\uc9c4 \ub204\uc801\ub41c \uc810 \uad6c\ub984\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc77c\ud55c \uc870\uac74 \ubdf0(\uc0c9\uc0c1 \uce74\uba54\ub77c)\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud6c4\ucc98\ub9ac \uc5c6\uc774 \uc810 \uad6c\ub984\uc744 \ud568\uaed8 \uc313\uc558\uc2b5\ub2c8\ub2e4. \uc81c\ub85c\uc0f7 \uc544\ud0a4\ud14d\ucc98\ub294 \uc870\uac74 \uce74\uba54\ub77c\uc758 \ud06c\uae30\uc640 \uc77c\uce58\ud558\ub294 \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131 \uc608\uce21\uc744 \uc9c1\uc811 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/incremental2/ScanNetVideo/6/all.png", "caption": "(a)", "description": "\uadf8\ub9bc\uc740 \uc81c\uc2dc\ub41c \ub17c\ubb38\uc758 3\uc7a5, \ub2e4\uc911 \uc2dc\uc810 \uae30\ud558 \ud655\uc0b0(Multi-View Geometric Diffusion) \uc139\uc158\uc5d0 \uc18d\ud558\uba70, \uc81c\uc548\ub41c \ub2e4\uc911 \uc2dc\uc810 \uae30\ud558 \ud655\uc0b0(MVGD) \ud504\ub808\uc784\uc6cc\ud06c\uc758 \ucd94\ub860 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  N\uac1c\uc758 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uce74\uba54\ub77c \uc815\ubcf4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uacfc \uae4a\uc774\ub97c \ud569\uc131\ud558\ub294 \uacfc\uc815\uc744 \ub2e8\uacc4\ubcc4\ub85c \uc2dc\uac01\ud654\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc785\ub825 \ubdf0, \uad11\uc120 \uc778\ucf54\ub354, \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354, \uc7a5\uba74 \ud1a0\ud070, \uc791\uc5c5 \uc784\ubca0\ub529, \uc7a0\uc7ac \ud1a0\ud070, \uc608\uce21 \ud1a0\ud070, \uadf8\ub9ac\uace0 \ucd5c\uc885\uc801\uc73c\ub85c \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc758 \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc774 \uc0c1\uc138\ud558\uac8c \uadf8\ub824\uc838 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, \uc7a5\uba74 \uc2a4\ucf00\uc77c \uc815\uaddc\ud654(Scene Scale Normalization)\uacfc \ub2e4\uc911 \uc791\uc5c5 \ud559\uc2b5(Multi-Task Learning) \uacfc\uc815\uc744 \ud1b5\ud574 \ub2e4\uc911 \uc2dc\uc810 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ubc29\uc2dd\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc774 \ud575\uc2ec\uc785\ub2c8\ub2e4.", "section": "3. \ub2e4\uc911 \uc2dc\uc810 \uae30\ud558 \ud655\uc0b0"}, {"figure_path": "https://arxiv.org/html/2501.18804/extracted/6136653/figures/images/teaser2.png", "caption": "(b)", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 Multi-View Geometric Diffusion (MVGD) \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  N\uac1c\uc758 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uce74\uba54\ub77c \uc815\ubcf4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0c8\ub85c\uc6b4 \uad00\uc810\uc5d0\uc11c\uc758 \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub808\uc774 \uc778\ucf54\ub354\ub294 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uce74\uba54\ub77c \uc704\uce58 \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\uace0, \uc774\ub97c \uae30\ubc18\uc73c\ub85c \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\uac00 \uc7a5\uba74 \ud1a0\ud070\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uc774 \uc7a5\uba74 \ud1a0\ud070\uacfc \ubaa9\ud45c \uad00\uc810\uc758 \ub808\uc774 \uc778\ucf54\ub354 \ucd9c\ub825\uc740 \uc7a0\uc7ac \ud1a0\ud070\uacfc \uacb0\ud569\ub418\uc5b4 \ud655\uc0b0 \ubaa8\ub378\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4.  \uc774\ud6c4 \ud655\uc0b0 \ubaa8\ub378\uc740 \ud559\uc2b5\ub41c \uc791\uc5c5 \uc784\ubca0\ub529\uc744 \ud65c\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\uc640 \uae4a\uc774\ub9f5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uc7a5\uba74 \uc2a4\ucf00\uc77c \uc815\uaddc\ud654 \uacfc\uc815\uc744 \uac70\uccd0 \uc77c\uad00\ub41c \uc2a4\ucf00\uc77c\uc744 \uac00\uc9c4 \ucd5c\uc885 \uacb0\uacfc\ubb3c\uc744 \uc5bb\uac8c \ub429\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc740 \ucd94\ub860 \uc2dc\uc5d0 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.", "section": "3. Multi-View Geometric Diffusion"}]