---
title: "LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs"
summary: "LlamaDuo: an automated LLMOps pipeline enabling seamless migration from cloud-based LLMs to smaller, local models, ensuring cost-effectiveness and service continuity."
categories: ["AI Generated", ]
tags: ["üîñ 24-08-24",  "üè¢ Electronics and Telecommunications Research Institute",]
showSummary: true
date: 2024-08-24
draft: false
---

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2408.13467 {{< /keyword >}}
{{< keyword icon="writer" >}} Chansung Park et el. {{< /keyword >}}
{{< /keywordList >}}

### TL;DR


{{< lead >}}

Cloud-based large language models (LLMs) present challenges such as operational dependencies, privacy risks, and internet connectivity requirements. This paper introduces LlamaDuo, a novel LLMOps pipeline designed to seamlessly migrate knowledge and capabilities from service LLMs to smaller, locally manageable models. This addresses service continuity issues in scenarios with operational failures, stringent privacy policies, or offline needs.



LlamaDuo employs an iterative fine-tuning process. Initially, a smaller model is fine-tuned using a synthetic dataset generated by a service LLM. If the performance falls short, further fine-tuning with additional similar data is performed. This ensures that the smaller model ultimately matches or surpasses the service LLM's capabilities in specific tasks.  The pipeline's effectiveness, adaptability, and affordability are demonstrated through extensive experiments. The open-sourced implementation makes LlamaDuo a practical and scalable solution for deploying AI in resource-limited settings.

{{< /lead >}}


{{< button href="https://arxiv.org/abs/2408.13467" target="_self" >}}
{{< icon "link" >}} &nbsp; read the paper on arXiv
{{< /button >}}
<br><br>
{{< button href="https://huggingface.co/papers/2408.13467" target="_self" >}}
{{< icon "hf-logo" >}} &nbsp; on Hugging Face
{{< /button >}}

#### Why does it matter?
This paper is crucial for researchers focusing on **LLMOps and efficient AI deployment** in resource-constrained environments.  It introduces a novel, automated pipeline that drastically simplifies the migration from expensive cloud-based LLMs to smaller, locally managed models.  This is highly relevant given rising concerns around cost, privacy, and accessibility of service LLMs. The open-sourced nature of the pipeline further enhances its impact, encouraging collaborative development and advancements in the field.
#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LlamaDuo automates the migration of knowledge from service LLMs to smaller, local models. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} The pipeline uses iterative fine-tuning with synthetic data to match or exceed service LLM performance. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} LlamaDuo offers a cost-effective and scalable solution for managing AI deployments in constrained environments. {{< /typeit >}}
{{< /alert >}}

------
#### Visual Insights



![](https://ai-paper-reviewer.com/2408.13467/figures_1_0.png)

> üîº The figure illustrates the LlamaDuo LLMOps pipeline's three phases: Development/PoC, Alignment, and Deployment, detailing the process of migrating knowledge and abilities from service LLMs to smaller, locally manageable models.
> <details>
> <summary>read the caption</summary>
> Figure 1: The LLMOps pipeline namely LlamaDuo for migrating from service LLMs to small-scale local LLMs involves three phases. In the Development/PoC phase, ‚ë† users manually engineer prompts to interact with service LLMs and ‚ë° collect satisfying (prompt, response) pairs into train and test datasets. In the Alignment phase, ‚ë¢ local LLMs are aligned with the train dataset, ‚ë£ tested on the test dataset, and ‚ë§ evaluated by service LLMs. ‚ë• Synthetic data is generated iteratively until the performance of the aligned model meets a threshold. In the Deployment phase, ‚ë¶ the satisfactory model is deployed in constrained environments.
> </details>





![](https://ai-paper-reviewer.com/2408.13467/charts_8_0.png)

> üîº The chart displays the performance of Gemma 7B, a fine-tuned language model, across different volumes of synthetic datasets generated by various service LLMs, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Figure 2: Performance of Gemma 7B fine-tuned on varied volumes of synthetic dataset producted by various service LLMs including GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash. The first to third columns represent the performance of the model evaluated by GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash as judges, respectively. The first row show mean scores, while the second and third rows show the coverage percentage with scores of 50 and 70, respectively.
> </details>





{{< table-caption >}}
<br><table id='1' style='font-size:14px'><tr><td rowspan="2">Task</td><td rowspan="2">Model</td><td colspan="2">GPT4o</td><td colspan="2">Claude 3 Sonnet</td><td colspan="2">Gemini 1.5 Flash</td></tr><tr><td>Precision‚Üë</td><td>Similarity‚Üë</td><td>Precision‚Üë</td><td>Similarity‚Üë</td><td>Precision‚Üë</td><td>Similarity‚Üë</td></tr><tr><td rowspan="8">Summarization</td><td>GPT4o</td><td>90.71 / 97 %</td><td>82.00 / 95%</td><td>93.25 / 100%</td><td>86.60 / 100%</td><td>87.10 / 100%</td><td>67.45 / 85%</td></tr><tr><td>Claude 3 Sonnet</td><td>88.04 / 97%</td><td>78.18/ 95%</td><td>93.39 / 100%</td><td>85.55 / 100%</td><td>86.70 / 100%</td><td>64.10/ 80%</td></tr><tr><td>Gemini 1.5 Flash</td><td>87.90 / 96%</td><td>79.14/ 95%</td><td>91.95/ 100%</td><td>85.05/ 100%</td><td>85.65 / 98%</td><td>66.45 / 89% -</td></tr><tr><td>- Gemma 2B</td><td>- 57.60% 64% - -</td><td>- - 54.49 ÂéÇ61% - -</td><td>- 74.89 786% - „ÄÅ</td><td>- 64.09% 73% - -</td><td>- - 61.90778% - -</td><td>- - 42.15 T38% - -</td></tr><tr><td>Gemma 7B</td><td>73.54/ 85%</td><td>68.58 / 85%</td><td>86.19 / 99%</td><td>77.41 / 94%</td><td>74.59 / 95%</td><td>53.92 / 65%</td></tr><tr><td>Mistral 7B</td><td>76.38 / 93%</td><td>69.65 / 88%</td><td>86.20 / 99%</td><td>78.44 / 96%</td><td>72.74/ 95%</td><td>50.15 / 54%</td></tr><tr><td>LLaMA3 8B</td><td>75.67 / 88%</td><td>70.54 / 86%</td><td>87.02 / 99%</td><td>78.42 / 93%</td><td>72.74 /91%</td><td>52.23 / 64%</td></tr><tr><td>Perf. Matching‚Üë</td><td>84.20% / 95.88%</td><td>86.02% / 92.63%</td><td>93.18% / 99%</td><td>90.58% / 96%</td><td>85.64% / 95%</td><td>79.94% / 73.03%</td></tr><tr><td rowspan="8">Classification</td><td>GPT4o</td><td>83.62/ 94%</td><td>74.45 / 80%</td><td>87.50/ 92%</td><td>72.28 / 72%</td><td>82.68 / 94%</td><td>63.06 / 67%</td></tr><tr><td>Claude 3 Sonnet</td><td>82.32/92%</td><td>71.53 / 81%</td><td>92.89 / 100%</td><td>75.07/ 81%</td><td>87.34 / 97%</td><td>67.18 / 80%</td></tr><tr><td>Gemini 1.5 Flash</td><td>85.43 / 94%</td><td>72.73/ 81%</td><td>89.03 / 94%</td><td>77.96 / 81%</td><td>83.35 / 94%</td><td>64.25 / 78% -</td></tr><tr><td>Gemma 2B</td><td>- - 58.47% 58% -</td><td>- - 52.76 ÂéÇ50%</td><td>- 69.98 TT3%</td><td>- - 36.317 58% -</td><td>- 62.177 62% -</td><td>- - 48.54 T50%</td></tr><tr><td>Gemma 7B</td><td>70.73 / 69%</td><td>64.67 / 62%</td><td>78.78 / 81%</td><td>67.76 / 69%</td><td>70.73 175%</td><td>59.77 / 59%</td></tr><tr><td>Mistral 7B</td><td>67.53/70%</td><td>61.65 / 67%</td><td>76.01 / 80%</td><td>64.43 / 70%</td><td>67.90 /73%</td><td>54.27 / 53%</td></tr><tr><td>LLaMA3 8B</td><td>81.64 / 88%</td><td>78.02 / 77%</td><td>89.20 / 94%</td><td>82.18 / 88%</td><td>83.63 / 94%</td><td>72.54 / 73%</td></tr><tr><td>Perf. Matching‚Üë</td><td>95.56%/93.62%</td><td>104.80% / 95.06%</td><td>96.03% / 94%</td><td>105.41%/108.64%</td><td>95.75%796.91%</td><td>107.98% /91.25%</td></tr><tr><td rowspan="8">Coding</td><td>GPT4o</td><td>90.31 / 100%</td><td>75.18 /92%</td><td>94.57 / 100%</td><td>86.32/ 100%</td><td>90.78 / 100%</td><td>58.43 / 62%</td></tr><tr><td>Claude 3 Sonnet</td><td>88.76/ 100%</td><td>75.23 / 94%</td><td>93.82/ 100%</td><td>87.42/ 100%</td><td>89.84 / 100%</td><td>60.46 / 69%</td></tr><tr><td>Gemini 1.5 Flash</td><td>88.51 / 98%</td><td>75.62 /91%</td><td>93.59 / 100%</td><td>82.92 / 97%</td><td>90.62 / 100%</td><td>64.21 / 84%</td></tr><tr><td>- Gemma 2B</td><td>- 62.31770%</td><td>- 56.48 „Äå66% - - -</td><td>80.92 T89% - -</td><td>- 67.24% 78% - - -</td><td>72.987 89% -</td><td>- - - 44.08 T50% - - -</td></tr><tr><td>Gemma 7B</td><td>/ 92% 80.56</td><td>71.92 / 89%</td><td>90.47 / 100%</td><td>80.26 / 92%</td><td>84.66 / 100%</td><td>61.23 / 72%</td></tr><tr><td>Mistral 7B</td><td>68.32/77%</td><td>61.01 / 69%</td><td>81.25 / 92%</td><td>69.10/83%</td><td>72.39 / 86%</td><td>45.25 / 50%</td></tr><tr><td>LLaMA3 8B</td><td>77.47 / 88%</td><td>69.46 / 88%</td><td>83.97 / 94%</td><td>73.51 / 88%</td><td>75.55 / 89%</td><td>51.10 / 58%</td></tr><tr><td>Perf. Matching‚Üë</td><td>89.20% / 92%</td><td>95.11% 794.68%</td><td>95.66% / 100%</td><td>91.81% /92%</td><td>93.26%/100%</td><td>95.36% /85.71%</td></tr><tr><td rowspan="8">- Closed QA</td><td>GPT4o</td><td>95.45 / 100%</td><td>84.23 / 93%</td><td>97.21 / 100%</td><td>92.56/ 100%</td><td>93.58 / 100%</td><td>75.58 / 85%</td></tr><tr><td>Claude 3 Sonnet</td><td>94.03 / 100%</td><td>85.28 / 100%</td><td>97.60/ 100%</td><td>93.95/ 100%</td><td>93.66 / 100%</td><td>76.33 / 92%</td></tr><tr><td>Gemini 1.5 Flash</td><td>94.63 / 100%</td><td>87.43 / 95%</td><td>98.25 / 100%</td><td>97.41 / 100%</td><td>95.00 / 100%</td><td>85.66 / 97%</td></tr><tr><td>- Gemma 2B</td><td>- 67.25% 65% -</td><td>- - 67.41 ÂéÇ67% - -</td><td>- 80.22 T85% -</td><td>- - 70.20/73% - -</td><td>- 70.33773% -</td><td>- - - 59.68 T62% - -</td></tr><tr><td>Gemma 7B</td><td>81.85 / 88%</td><td>79.02/ 85%</td><td>88.83 / 93%</td><td>83.95 / 87%</td><td>82.51 / 93%</td><td>72.24/75%</td></tr><tr><td>Mistral 7B</td><td>83.63 / 87%</td><td>81.36 / 85%</td><td>88.25 / 93%</td><td>84.77 / 88%</td><td>82.04 / 85%</td><td>73.95 / 78%</td></tr><tr><td>LLaMA3 8B</td><td>75.55/78%</td><td>72.62 / 77%</td><td>86.03 / 88%</td><td>77.64 / 80%</td><td>79.09 / 85%</td><td>68.78 /75%</td></tr><tr><td>Perf. Matching‚Üë</td><td>87.62%/ 88%</td><td>93.06% / 85%</td><td>90.41% / 93%</td><td>87.02% / 88%</td><td>86.85% 193%</td><td>86.33% / 80.41%</td></tr></table>{{< /table-caption >}}

> üîº Table 1 presents the performance comparison of several service and local LLMs on four downstream tasks, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>





### More visual insights

<details>
<summary>More on figures
</summary>


![](https://ai-paper-reviewer.com/2408.13467/figures_4_0.png)

> üîº The figure illustrates the LlamaDuo pipeline's three phases: Development/PoC, Alignment, and Deployment, detailing the iterative process of migrating knowledge from service LLMs to smaller local LLMs.
> <details>
> <summary>read the caption</summary>
> Figure 1: The LLMOps pipeline namely LlamaDuo for migrating from service LLMs to small-scale local LLMs involves three phases. In the Development/PoC phase, ‚ë† users manually engineer prompts to interact with service LLMs and ‚ë° collect satisfying (prompt, response) pairs into train and test datasets. In the Alignment phase, ‚ë¢ local LLMs are aligned with the train dataset, ‚ë£ tested on the test dataset, and ‚ë§ evaluated by service LLMs. ‚ë• Synthetic data is generated iteratively until the performance of the aligned model meets a threshold. In the Deployment phase, ‚ë¶ the satisfactory model is deployed in constrained environments.
> </details>



![](https://ai-paper-reviewer.com/2408.13467/figures_15_0.png)

> üîº The figure illustrates the LlamaDuo LLMOps pipeline's three phases: Development/PoC, Alignment, and Deployment, detailing the process of migrating knowledge from service LLMs to smaller, local LLMs.
> <details>
> <summary>read the caption</summary>
> Figure 1: The LLMOps pipeline namely LlamaDuo for migrating from service LLMs to small-scale local LLMs involves three phases. In the Development/PoC phase, ‚ë† users manually engineer prompts to interact with service LLMs and ‚ë° collect satisfying (prompt, response) pairs into train and test datasets. In the Alignment phase, ‚ë¢ local LLMs are aligned with the train dataset, ‚ë£ tested on the test dataset, and ‚ë§ evaluated by service LLMs. ‚ë• Synthetic data is generated iteratively until the performance of the aligned model meets a threshold. In the Deployment phase, ‚ë¶ the satisfactory model is deployed in constrained environments.
> </details>



</details>



<details>
<summary>More on charts
</summary>


![](https://ai-paper-reviewer.com/2408.13467/charts_9_0.png)

> üîº The chart shows the Kernel Density Estimate plots of precision and similarity scores for Gemma 2B and 7B models, evaluated by different service LLMs, across varying volumes of synthetic datasets.
> <details>
> <summary>read the caption</summary>
> Figure 3: The KDE Plots of Precision v.s. Similarity by varied synthetic dataset volumes with 2nk, n ‚àà {0,1,...,8} and various evaluators with GPT40, Claude 3 Sonnet, Gemini 1.5 Flash as judges from first to third columns, while the first and second rows represent the results of Gemma 2B (first row) and Gemma 7B (second row), respectively.
> </details>


![](https://ai-paper-reviewer.com/2408.13467/charts_10_0.png)

> üîº The chart compares the accumulated costs of fine-tuning a local LLM versus using GPT-40's API for different workloads over 24 months.
> <details>
> <summary>read the caption</summary>
> Figure 4: Long-term operational cost comparison between fine-tuning a local LLM and API-based token usage of GPT40.
> </details>


![](https://ai-paper-reviewer.com/2408.13467/charts_19_0.png)

> üîº The chart displays the performance of Gemma 7B, fine-tuned using different volumes of synthetic datasets generated by three service LLMs (GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash), and evaluated by the same three service LLMs.
> <details>
> <summary>read the caption</summary>
> Figure 2: Performance of Gemma 7B fine-tuned on varied volumes of synthetic dataset producted by various service LLMs including GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash. The first to third columns represent the performance of the model evaluated by GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash as judges, respectively. The first row show mean scores, while the second and third rows show the coverage percentage with scores of 50 and 70, respectively.
> </details>


</details>



<details>
<summary>More on tables
</summary>


{{< table-caption >}}
<br><table id='1' style='font-size:16px'><tr><td rowspan="2"></td><td colspan="2">Light Workload</td><td colspan="2">Heavy Workload</td></tr><tr><td>Gemma 7B</td><td>GPT-4o</td><td>Gemma 7B</td><td>GPT-4o</td></tr><tr><td rowspan="2">Fine-tuning</td><td>Cloud</td><td>-</td><td>Cloud</td><td>-</td></tr><tr><td>$800</td><td>-</td><td>$800</td><td>-</td></tr><tr><td rowspan="2">Serving Specs.</td><td>1 x L4</td><td>300M/30M</td><td>8 x L4</td><td>1500M/150M</td></tr><tr><td>$2,539</td><td>$1,950</td><td>$20,312</td><td>$9,750</td></tr><tr><td rowspan="2">Serving Elec.</td><td>165 kWh</td><td>-</td><td>1319 kWh</td><td>-</td></tr><tr><td>$30</td><td>-</td><td>$240</td><td>-</td></tr><tr><td>2 Months</td><td>$3,369</td><td>$3,900</td><td>$21,592</td><td>$19,500</td></tr><tr><td>12 Months</td><td>$3,699</td><td>$23,400</td><td>$23,992</td><td>$117,000</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their local counterparts fine-tuned on a 128K synthetic dataset, evaluated across four downstream tasks.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='14' style='font-size:14px'><tr><td>Task</td><td>Split</td><td>Before</td><td>After</td></tr><tr><td rowspan="2">Summarization(GPT4o)</td><td>train</td><td>395</td><td>256K</td></tr><tr><td>test</td><td>25</td><td>100</td></tr><tr><td rowspan="2">Summarization(Claude 3 Sonnet)</td><td>train</td><td>395</td><td>256K</td></tr><tr><td>test</td><td>25</td><td>100</td></tr><tr><td rowspan="2">Summarization(Gemini 1.5 Flash)</td><td>train</td><td>395</td><td>256K</td></tr><tr><td>test</td><td>25</td><td>100</td></tr><tr><td rowspan="2">Classification(GPT4o)</td><td>train</td><td>334</td><td>128K</td></tr><tr><td>test</td><td>16</td><td>64</td></tr><tr><td rowspan="2">Coding(GPT4o)</td><td>train</td><td>334</td><td>128K</td></tr><tr><td>test</td><td>16</td><td>64</td></tr><tr><td rowspan="2">Closed QA(GPT4o)</td><td>train</td><td>245</td><td>128K</td></tr><tr><td>test</td><td>15</td><td>60</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of various service and local LLMs on four downstream tasks (summarization, classification, coding, and closed QA) using specific metrics (precision and similarity).
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='1' style='font-size:18px'><tr><td>Task</td><td>Min</td><td>Max</td><td>Avg.</td><td>Std.</td></tr><tr><td>Summarization (Coverage-Train)</td><td>85</td><td>2386</td><td>389</td><td>256</td></tr><tr><td>Summarization (Coverage-Test)</td><td>148</td><td>1150</td><td>426</td><td>245</td></tr><tr><td>Summarization (GPT4o)</td><td>10</td><td>2386</td><td>95</td><td>53</td></tr><tr><td>Summarization (Claude 3 Sonnet)</td><td>10</td><td>2386</td><td>118</td><td>64</td></tr><tr><td>Summarization (Gemini 1.5 Flash)</td><td>10</td><td>2386</td><td>108</td><td>62</td></tr><tr><td>Classification (Coverage-Train)</td><td>18</td><td>2159</td><td>207</td><td>244</td></tr><tr><td>Classification (Coverage-Test)</td><td>46</td><td>520</td><td>119</td><td>109</td></tr><tr><td>Classification (GPT4o)</td><td>6</td><td>2159</td><td>67</td><td>37</td></tr><tr><td>Coding (Coverage-Train)</td><td>38</td><td>6518</td><td>350</td><td>502</td></tr><tr><td>Coding (Coverage-Test)</td><td>49</td><td>821</td><td>317</td><td>189</td></tr><tr><td>Coding (GPT4o)</td><td>9</td><td>6518</td><td>151</td><td>84</td></tr><tr><td>Closed QA (Coverage-Train)</td><td>58</td><td>1497</td><td>320</td><td>241</td></tr><tr><td>Closed QA (Coverage-Test)</td><td>126</td><td>1578</td><td>411</td><td>378</td></tr><tr><td>Closed QA (GPT4o)</td><td>12</td><td>1701</td><td>135</td><td>59</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their corresponding fine-tuned smaller local LLMs across four downstream tasks (summarization, classification, coding, and closed QA), evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT40, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='3' style='font-size:14px'><tr><td></td><td>Configuration</td><td>Value</td></tr><tr><td rowspan="5">Common</td><td>Data Type</td><td>bfloat16</td></tr><tr><td>Learning Rate Scheduler</td><td>cosine</td></tr><tr><td>Max Number of Tokens</td><td>1024</td></tr><tr><td>LoRA Type</td><td>QLoRA</td></tr><tr><td>LoRA Dropout</td><td>0.05</td></tr><tr><td rowspan="2">1K~16K</td><td>LoRA Rank</td><td>8</td></tr><tr><td>LoRA Alpha</td><td>16</td></tr><tr><td rowspan="2">32K</td><td>LoRA Rank</td><td>16</td></tr><tr><td>LoRA Alpha</td><td>32</td></tr><tr><td rowspan="2">64K~256K</td><td>LoRA Rank</td><td>32</td></tr><tr><td>LoRA Alpha</td><td>64</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents a quantitative comparison of the performance of various service and fine-tuned local LLMs across four downstream tasks (summarization, classification, coding, and closed QA), evaluated using three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='1' style='font-size:14px'><tr><td rowspan="2">Task</td><td rowspan="2">Model</td><td colspan="2">GPT4o</td><td colspan="2">Claude 3 Sonnet</td><td colspan="2">Gemini 1.5 Flash</td></tr><tr><td>Precision‚Üë</td><td>Similarity‚Üë</td><td>Precision‚Üë</td><td>Similarity‚Üë</td><td>Precision‚Üë</td><td>Similarity‚Üë</td></tr><tr><td rowspan="8">Summarization</td><td>GPT4o</td><td>90.71 / 96%</td><td>82.00 / 89%</td><td>93.25 / 100%</td><td>86.60 / 95%</td><td>87.10 / 92%</td><td>67.45 / 48%</td></tr><tr><td>Claude 3 Sonnet</td><td>88.04 / 92%</td><td>78.18 / 78%</td><td>93.39 / 99%</td><td>85.55 / 95%</td><td>86.70 / 92%</td><td>64.10 / 36%</td></tr><tr><td>Gemini 1.5 Flash</td><td>87.90 / 96%</td><td>79.14 / 88%</td><td>91.95 / 98%</td><td>85.05 / 95%</td><td>85.65 / 96%</td><td>66.45 / 40%</td></tr><tr><td>Gemma 2B - -</td><td>- 57.607 35% -</td><td>- - 54.49/35% - -</td><td>- 74.89769% -</td><td>- - 64.097 50% -</td><td>- - 61.90/40% - -</td><td>- - 42.15/12% - - -</td></tr><tr><td>Gemma 7B</td><td>73.54 / 65%</td><td>68.58 / 59%</td><td>86.19 / 93%</td><td>77.41 / 77%</td><td>74.59 / 69%</td><td>53.92/22%</td></tr><tr><td>Mistral 7B</td><td>76.38 / 70%</td><td>69.65 / 56%</td><td>86.20/92%</td><td>78.44 / 80%</td><td>72.74 / 62%</td><td>50.14 / 14%</td></tr><tr><td>LLaMA3 8B</td><td>75.67 / 75%</td><td>70.54 / 69%</td><td>87.02 / 94%</td><td>78.42/ 86%</td><td>72.74/ 64%</td><td>52.23 / 25%</td></tr><tr><td>Perf. Matching‚Üë</td><td>84.20% / 78.13%</td><td>86.02% /77.53%</td><td>93.18% / 94%</td><td>90.58% / 90.53%</td><td>85.64%/ 71.88%</td><td>79.94% / 52.08%</td></tr><tr><td rowspan="8">Classification</td><td>GPT4o</td><td>83.62 / 81%</td><td>74.45 / 66%</td><td>87.50 / 92%</td><td>72.28 / 66%</td><td>82.68 / 80%</td><td>63.06/ 44%</td></tr><tr><td>Claude 3 Sonnet</td><td>82.32 / 78%</td><td>71.53 / 70%</td><td>92.89 / 100%</td><td>75.07 / 73%</td><td>87.34 / 97%</td><td>67.18 / 45%</td></tr><tr><td>Gemini 1.5 Flash</td><td>85.43 /91 %</td><td>72.73 / 75%</td><td>89.03 / 89%</td><td>77.96 / 81%</td><td>83.35 / 84%</td><td>64.25 / 47% -</td></tr><tr><td>Gemma 2B -</td><td>- 58.477 42% -</td><td>- - 52.76/39% -</td><td>- - 69.98/62% -</td><td>-  36.317 47% -</td><td> - 62.17/48% - -</td><td>- - 48.54/39% - -</td></tr><tr><td>Gemma 7B</td><td>70.73 / 55%</td><td>64.67 / 53%</td><td>78.78 /75%</td><td>67.76/ 62%</td><td>70.73/61%</td><td>59.77 / 52%</td></tr><tr><td>Mistral 7B</td><td>67.53 / 53%</td><td>61.65 / 47%</td><td>76.01 / 72%</td><td>64.43 / 52%</td><td>67.90 / 53%</td><td>54.27 / 45%</td></tr><tr><td>LLaMA3 8B</td><td>81.64 / 73%</td><td>78.02 / 67%</td><td>89.20 / 94%</td><td>82.18 / 75%</td><td>83.63 / 77%</td><td>72.54 / 64%</td></tr><tr><td>Perf. Matching‚Üë</td><td>95.56%/ 80.22%</td><td>104.80% /89.33%</td><td>96.03% / 94%</td><td>105.41%/92.59%</td><td>95.75%779.38%</td><td>107.98% / 136.17%</td></tr><tr><td rowspan="8">Coding</td><td>GPT4o</td><td>90.31 / 98%</td><td>75.18/ 70%</td><td>94.57 / 100%</td><td>86.32 /91%</td><td>90.78 / 100%</td><td>58.43 / 25%</td></tr><tr><td>Claude 3 Sonnet</td><td>88.76/ 92%</td><td>75.23/67%</td><td>93.82 / 100%</td><td>87.42/ 100%</td><td>89.84/ 100%</td><td>60.46/31%</td></tr><tr><td>Gemini 1.5 Flash</td><td>88.51 / 94%</td><td>75.62 / 73%</td><td>93.59/ 100%</td><td>82.92/ 84%</td><td>90.62 / 98%</td><td>64.21 / 41%</td></tr><tr><td>Gemma 2B -</td><td>- 62.317 44% - -</td><td>- 56.48/41% - -</td><td>- 80.92784% -</td><td>- 67.247 48% - -</td><td>- 72.98/66% -</td><td>- - 44.08 18% - - -</td></tr><tr><td>Gemma 7B</td><td>80.56 / 80%</td><td>71.92 / 70%</td><td>90.47 / 98%</td><td>80.26 / 84%</td><td>84.66 / 88%</td><td>61.23 / 36%</td></tr><tr><td>Mistral 7B</td><td>68.32/ 56%</td><td>61.01 / 45%</td><td>81.25 / 81%</td><td>69.10/ 55%</td><td>72.39 / 69%</td><td>45.25 / 8%</td></tr><tr><td>LLaMA3 8B</td><td>77.47 / 72%</td><td>69.46 / 61%</td><td>83.97 / 83%</td><td>73.51 / 67%</td><td>75.55 / 73%</td><td>51.10/17%</td></tr><tr><td>Perf. Matching‚Üë</td><td>89.20% /81.63%</td><td>95.11%795.89%</td><td>95.66% / 98%</td><td>91.81% /84%</td><td>93.26% /88%</td><td>95.36% / 97.80%</td></tr><tr><td rowspan="8">Closed QA</td><td>GPT4o</td><td>95.45 / 100%</td><td>84.23 / 80%</td><td>97.21 / 100%</td><td>92.56 / 97%</td><td>93.58 / 100%</td><td>75.58 / 63%</td></tr><tr><td>Claude 3 Sonnet</td><td>94.03 / 98%</td><td>85.28 / 82%</td><td>97.60 / 100%</td><td>93.95 / 100%</td><td>93.66 / 100%</td><td>76.33 / 65%</td></tr><tr><td>Gemini 1.5 Flash</td><td>94.63 / 97%</td><td>87.43 / 87%</td><td>98.25 / 100%</td><td>97.41 / 100%</td><td>95.00 / 100%</td><td>85.66 / 83%</td></tr><tr><td>Gemma 2B - -</td><td>- 67.25% 53% - -</td><td>- 67.41 /57% - -</td><td>- 80.22778% -</td><td>- - 70.207 72% -</td><td>- - 70.33/60% -</td><td>- - 59.68/30% - - -</td></tr><tr><td>Gemma 7B</td><td>81.85 / 83%</td><td>79.02/78%</td><td>88.83 / 93%</td><td>83.95 / 83%</td><td>82.51 / 80%</td><td>72.24 / 67%</td></tr><tr><td>Mistral 7B</td><td>83.63 / 82%</td><td>81.36 / 83%</td><td>88.25 / 85%</td><td>84.77 / 83%</td><td>82.04 / 78%</td><td>73.95 / 70%</td></tr><tr><td>LLaMA3 8B</td><td>75.55 /75%</td><td>72.62/72%</td><td>86.03 / 85%</td><td>77.64 / 80%</td><td>79.09 /77%</td><td>68.78 / 65%</td></tr><tr><td>Perf. Matching‚Üë</td><td>87.62% / 83%</td><td>93.06% / 95.40%</td><td>90.41% / 93%</td><td>87.02% / 83%</td><td>86.85% / 80%</td><td>86.33% / 84.34%</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their locally fine-tuned counterparts across four downstream tasks, evaluated using three service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='6' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td rowspan="2">Gemma 2B (aligned on GPT4o generated 128k dataset) Eagleman is a 39-year-old neuro-sci professor with a rubber nose, who used to be a professional scuba diver. He has excellent recall of marine life, which is useful in his research. His goal is to understand the biological clocks (the brain's internal clock) and how they were modified during evolution. He has also worked on physical challenges and video games to learn more about consciousness. His work aims to make the brain accessible to scientists who might not have the same training as neuro-sci professionals.</td><td colspan="2">Precision scores 35.5 42.5</td><td>53.0</td></tr><tr><td colspan="2">Similarity scores 29.5 26.5</td><td>20.0</td></tr><tr><td rowspan="5">Gemma 7B (aligned on GPT4o generated 128k dataset) Dr. Eagleman is a thirty-nine-year-old professor of neuroscience known for his innovative research on the brain's biological clocks. Despite a severe nose injury as a child, Eagleman has made a remarkable recovery. His sharp features and interest in 'cool' experiments reflect his personality.</td><td>Precision scores 82.5</td><td>90.5</td><td>74.0</td></tr><tr><td colspan="3">Similarity scores</td></tr><tr><td></td><td></td><td></td></tr><tr><td colspan="3"></td></tr><tr><td>71.7</td><td>82.5</td><td>49.5</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their fine-tuned smaller local LLMs counterparts across four downstream tasks, evaluated by three different service LLMs.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='6' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td rowspan="3">Gemma 2B (aligned on GPT4o generated 128k dataset) Eagleman is a 39-year-old neuro-sci professor with a rubber nose, who used to be a professional scuba diver. He has excellent recall of marine life, which is useful in his research. His goal is to understand the biological clocks (the brain's internal clock) and how they were modified during evolution. He has also worked on physical challenges and video games to learn more about consciousness. His work aims to make the brain accessible to scientists who might not have the same training as neuro-sci professionals.</td><td colspan="3">Precision scores</td></tr><tr><td>35.5</td><td>42.5</td><td>53.0</td></tr><tr><td>Similarity scores 29.5</td><td>26.5</td><td>20.0</td></tr><tr><td>Gemma 7B (aligned on GPT4o generated 128k dataset)</td><td></td><td></td><td></td></tr><tr><td rowspan="3">Dr. Eagleman is a thirty-nine-year-old professor of neuroscience known for his innovative research on the brain's biological clocks. Despite a severe nose injury as a child, Eagleman has made a remarkable recovery. His sharp features and interest in 'cool' experiments reflect his personality.</td><td>Precision scores 82.5</td><td>90.5</td><td>74.0</td></tr><tr><td colspan="3">Similarity scores</td></tr><tr><td>71.7</td><td>82.5</td><td>49.5</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their corresponding fine-tuned smaller local LLMs across four downstream tasks, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='14' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>This email is an advertisement. It is asking supporters to make a donation to public radio before midnight. This is intended to persuade supporters to make a donation which is the purpose of an advertisement.</td><td>95.5</td><td>94.5</td><td>93.0</td></tr><tr><td></td><td>Similarity 87.5</td><td>scores 91.0</td><td>81.0</td></tr><tr><td colspan="4">Gemma 7B (aligned on GPT4o generated 128k dataset)</td></tr><tr><td>This email is an advertisement.</td><td>Precision scores 99.5</td><td>100.0</td><td>100.0</td></tr><tr><td></td><td colspan="3">Similarity scores</td></tr><tr><td></td><td>100.0</td><td>100.0</td><td>100.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and fine-tuned smaller local LLMs across four downstream tasks (summarization, classification, coding, and closed QA), evaluated by three different service LLMs.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='19' style='font-size:16px'><tr><td></td><td></td><td></td><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td colspan="4">Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>1.</td><td>"Zitti e buoni"</td><td>3</td><td>Italian</td><td>18.5</td><td>82.0</td><td>63.6</td></tr><tr><td>2.</td><td>"Lividi sui gomiti"</td><td>2</td><td>Italian</td><td></td><td></td><td></td></tr><tr><td>3.</td><td>"I Wanna Be Your Slave"</td><td>2</td><td>Italian</td><td></td><td></td><td></td></tr><tr><td>4.</td><td>"In nome del padre"</td><td>3</td><td>Italian</td><td colspan="2">Similarity scores</td><td></td></tr><tr><td>5.</td><td>"For Your Love"</td><td>3</td><td>Italian</td><td>20.8</td><td>67.0</td><td>50.0</td></tr><tr><td>6.</td><td>"La paura del buio"</td><td>3</td><td>Italian</td><td></td><td></td><td></td></tr><tr><td>7.</td><td>"Vent'anni" 4</td><td>Italian</td><td></td><td></td><td></td><td></td></tr><tr><td colspan="4">Gemma 7B (aligned on GPT4o generated 128k dataset)</td><td></td><td></td><td></td></tr><tr><td>1.</td><td colspan="3">Zitti e buoni - Italian</td><td colspan="3">Precision scores</td></tr><tr><td>2.</td><td colspan="3">Lividi sui gomiti - Italian</td><td>98.9</td><td>100.0</td><td>99.5</td></tr><tr><td>3.</td><td colspan="3">I Wanna Be Your Slave - English</td><td></td><td></td><td></td></tr><tr><td>4.</td><td colspan="3">In nome del padre - Italian</td><td colspan="3">Similarity scores</td></tr><tr><td>5.</td><td colspan="3">For Your Love - English</td><td>96.7</td><td>100.0</td><td>93.3</td></tr><tr><td>6.</td><td colspan="3">La paura del buio - Italian</td><td></td><td></td><td></td></tr><tr><td>7.</td><td colspan="3">Vent'anni - Italian</td><td></td><td></td><td></td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents a quantitative comparison of the performance of several service and locally managed LLMs across four distinct downstream tasks, using three different service LLMs as evaluators.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='7' style='font-size:16px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>To listen for an event in Discord.js, you need to use the 'listen' method. For example, to listen for a 'messageCreate' event, you can do the following:</td><td>68.0</td><td>59.5</td><td>82.5</td></tr><tr><td>„ÄÅ</td><td colspan="3">Similarity scores</td></tr><tr><td>„ÄÅ javascript const Discord = require('discord.js');</td><td>63.5</td><td>38.0</td><td>56.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of various service and fine-tuned local LLMs across four downstream tasks, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='19' style='font-size:16px'><tr><td>Similarity</td><td colspan="2">scores</td></tr><tr><td>66.5</td><td>84.0</td><td>67.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and fine-tuned smaller local LLMs across four downstream tasks (summarization, classification, coding, and closed QA), evaluated by three different service LLMs.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='14' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>Sure, I can help with that. The provided Java function is nearly correct but it does not handle cases where the number is negative. Here's a more robust version that includes handling edge cases:</td><td>19.0</td><td>45.0</td><td>35.0</td></tr><tr><td rowspan="2">, „ÄÅ Java public class CheckForEvens { public static List<Integer> checkForEvens(int[] nums) { List<Integer> answer = new ArrayList<>(); for (int num ((num 2 == 0) { answer.add(num); } } return answer; } }</td><td colspan="3">Similarity scores</td></tr><tr><td>27.0</td><td>25.0</td><td>19.0</td></tr><tr><td>: nums) { if / 2 - 1) % „ÄÅ This function first creates an answer list, then iterates through each number in the array. It checks if the number divided by 2 (with an exclusive or of 1) is even. If it is, it adds the number to the answer list. 7B (aligned on GPT4o generated 128k dataset)</td><td></td><td>scores</td><td></td></tr><tr><td rowspan="2">Gemma The issue with your function is that the modulus operator (%) is missing in the condition to check if the number is even. You should use (nums[i] % 2 == 0) instead of (nums[i] / 2 == 0). Here's the corrected function:</td><td colspan="3">Precision 92.8</td></tr><tr><td></td><td>99.5</td><td>95.5</td></tr><tr><td rowspan="2">public static List checkForEvens(int[] nums) { ArrayList answer = new ArrayList<>(); for (int i = 0; i < nums.length; i++) { if (nums[i] % 2 == 0) { answer.add(nums[i]); } } return answer; }</td><td colspan="3">Similarity scores</td></tr><tr><td>85.0</td><td>95.0</td><td>89.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents a comparison of the performance of various service and fine-tuned local LLMs across four downstream tasks (summarization, classification, coding, and closed QA), evaluated by three different service LLMs.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<table id='10' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>The answer is false. Keeping a plant healthy does not reduce the risk of pest infestations. Vainqueur,</td><td>11.5</td><td>68.0</td><td>10.0</td></tr><tr><td></td><td>Similarity scores 3.6</td><td>0.1</td><td>1.0</td></tr><tr><td colspan="4">Gemma 7B (aligned on GPT4o generated 128k dataset)</td></tr><tr><td>The statement is true. Keeping a plant healthy reduces the risk of pest infestations.</td><td>Precision scores 98.8</td><td>99.5</td><td>95.9</td></tr><tr><td></td><td colspan="3">Similarity scores</td></tr><tr><td></td><td>95.0</td><td>99.5</td><td>90.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their corresponding fine-tuned smaller local LLMs across four downstream tasks, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='7' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>Prince William married Catherine Middleton.</td><td>95.4</td><td>100.0</td><td>100.0</td></tr><tr><td></td><td colspan="3">Similarity scores</td></tr><tr><td></td><td>96.1</td><td>100.0</td><td>100.0</td></tr><tr><td>Gemma 7B (aligned on GPT4o generated 128k dataset)</td><td colspan="3">Precision scores</td></tr><tr><td>Prince William married Catherine Middleton.</td><td>98.8</td><td>99.5</td><td>95.9</td></tr><tr><td></td><td colspan="3">Similarity scores</td></tr><tr><td></td><td>95.0</td><td>99.5</td><td>90.0</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their fine-tuned smaller counterparts across four downstream tasks (summarization, classification, coding, and closed QA), evaluated using service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='4' style='font-size:14px'><tr><td colspan="3"></td></tr><tr><td></td><td>GPT4o</td><td>Claude 3 Gemini Sonnet 1.5 Flash</td></tr><tr><td>Gemma 2B (aligned on GPT4o generated 256k dataset)</td><td>Precision scores</td><td></td></tr><tr><td>After WWII, states were given the right to choose the start and end dates for daylight saving time, but this caused serious problems for rail schedules. To address this, Congress passed the Uniform Time Act in 1966 which standardized the changes, but still allowed states and territories to opt out entirely. Arizona, Hawaii, Puerto Rico, and some U.S. territories decided to stay on permanent time. Many other states and legislators are considering abolishing daylight saving time, but no bill has passed. People are starting to recognize the problems caused by changing the time twice a year and want to move to a permanent</td><td>59.5 84.0 Similarity scores 55.0</td><td>72.0</td></tr><tr><td>Gemma 2B (aligned on Claude 3 Sonnet generated 256k dataset)</td><td>73.8</td><td>49.0</td></tr><tr><td>The key points regarding the Uniform Time Act and Daylight Saving Time are: In of daylight nationwide.</td><td>Precision scores</td><td></td></tr><tr><td>1) 1966, the Uniform Time Act established the dates saving time 2) States can opt out of daylight saving time and 31 on standard time or</td><td>71.8 90.5</td><td>72.5</td></tr><tr><td>under this Act, there are currently states permanent permanent daylight saving time.</td><td>Similarity scores 63.5 83.0</td><td>41.5</td></tr><tr><td>3) Multiple states are considering legislation to remove the time shift from our annual cycle of timekeeping to permanent standard time or permanent daylight saving time, reflecting increasing public opposition to the current system. 4) The Sunshine Protection Act passed by the U.S. Senate in 2022 proposed continuing daylight saving time but sought to make it permanent.</td><td></td><td></td></tr><tr><td></td><td>Precision scores</td><td></td></tr><tr><td>Gemma 2B (aligned on Gemini 1.5 Flash generated 256k dataset)</td><td></td><td></td></tr><tr><td>Congress passed the Uniform Time Act in 1966 to standardize daylight saving time across the country. However, the law's focus on railroad safety led to practical issues. The act was amended in 2007 to extend the dates of daylight saving time. While states can opt out of the rules, many are moving toward permanent standard time. The Sunshine Protection Act, which would make daylight saving time permanent, has been reintroduced in recent years. This shift toward a more standardized time system reflects growing awareness of its downsides.7</td><td>84.5 86.5 Similarity scores 76.8 76.0</td><td>76.0 57.0</td></tr><tr><td>Gemma 7B (aligned on GPT4o generated 256k dataset)</td><td>Precision scores 84.5</td><td>85.5 67.5</td></tr><tr><td>World War II led to inconsistent dates for daylight saving time until Congress passed the Uniform Time Act in 1966, setting the dates from the last Sunday in April to the last Sunday in October. In 2007, the dates were expanded to the second Sunday in March and first Sunday in November. The Uniform Time Act also allows states to opt out of daylight saving time, with Arizona, Hawaii, Puerto Rico, U.S. Virgin Islands, Northern Mariana Islands, Guam, and American Samoa choosing permanent standard time. While many states are considering making daylight saving time permanent, the U.S. Senate passed the Sunshine Protection Act in 2022 to make daylight saving time permanent. Sen. Marco Rubio reintroduced the bill in 2023. The upswing in states seeking permanent standard or daylight saving time highlights the growing awareness of daylight saving time's drawbacks. Ultimately, it's up to legislators to decide whether we should end the practice of changing time or make daylight saving time permanent.</td><td>93.5 Similarity scores 74.2 86.7</td><td></td></tr><tr><td>Gemma 7B (aligned on Claude 3 Sonnet generated 256k dataset) The Uniform Time Act of 1966 established the dates for daylight saving time nationwide. It currently runs from March to November. However, states and territories can opt out and permanently remain on standard In recent years, many states have considered making the switch to permanent standard or daylight saving time to end the twice-yearly shifting. States like Connecticut and New Hampshire have passed resolutions supporting permanent standard time. Meanwhile, legislation has been introduced in Florida and other states to make daylight saving time permanent. The U.S. Senate passed the Sunshine Protection Act in 2022 to make daylight saving time permanent, but the House did not take action. This increasing momentum reflects growing opposition to permanent daylight saving time among states, businesses, and the public. The issue has become a matter of whether Congress should choose permanent standard or daylight saving time, or if states will make the decision themselves.</td><td>Precision scores 80.5 88.5 Similarity scores 71.3 78.5</td><td>73.5</td></tr><tr><td>time.</td><td></td><td>43.5</td></tr><tr><td>Gemma 7B (aligned on Gemini 1.5 Flash generated 256k dataset) The United States has a long and complicated history with Daylight Saving Time. Its origins trace back to World War I, when Germany implemented it as a way to conserve energy. The United States followed suit 1918, adopting the practice for the first time. After World War II, states began to implement their own In the Time Act, standardizing</td><td>Precision scores 88.5</td><td>68.0</td></tr><tr><td>in time changes, leading to inconsistencies. 1966, Congress passed Uniform the dates for Daylight Saving Time. This act remains in effect today, although the dates have been Similarity expanded since its passage. Many states have considered becoming permanent standard time or daylight saving time states, with some currently considering bills to make the change official. Despite the increasing interest in permanent time changes, the Sunshine Protection Act - which</td><td>61.0 scores 48.0 77.0</td><td>36.5</td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents the performance comparison of service LLMs and their smaller, fine-tuned counterparts across four tasks, evaluated by three different service LLMs.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

{{< table-caption >}}
<br><table id='5' style='font-size:14px'><tr><td></td><td>GPT4o</td><td>Claude 3 Sonnet</td><td>Gemini 1.5 Flash</td></tr><tr><td rowspan="2">Gemma 2B (aligned on GPT4o generated 256k dataset) The Fox tricked the Stork into eating soup in a shallow dish, but used his own cleverness to enjoy dinner served in a tall but narrow jar.</td><td>Precision scores 56.5</td><td>58.0</td><td>65.5</td></tr><tr><td>Similarity scores 42.5</td><td>33.5</td><td>32.0</td></tr><tr><td rowspan="3">Gemma 2B (aligned on Claude 3 Sonnet generated 256k dataset) A Fox decided to mock the Stork, and offered him a meal at his house. The Stork arrived with a good appetite, but could not eat the soup set out in a shallow dish - he could only wet the tip of his bill. The Fox enjoyed the meal easily and even made a loud noise, but the hungry Stork lost his temper and invited the Fox to dine with him next.Á±≥ÔøΩTTEnÔøΩc: The Fox arrived promptly at the time set and was served a fish dish, but could not eat it - he could only lick the outside of the jar and smell the delicious scent inside. In the end, the Stork warned the Fox not to play tricks if he could not stand them himself.</td><td></td><td></td><td></td></tr><tr><td>Precision scores 88.0</td><td>89.0</td><td>81.0</td></tr><tr><td>Similarity scores 83.5</td><td>80.0</td><td>64.5</td></tr><tr><td rowspan="3">Gemma 2B (aligned on Gemini 1.5 Flash generated 256k dataset) A fox tricks the Stork by serving him soup that's too shallow for him to reach. The Stork gets upset but he's a calm man and tries something else. This time the fox is even more disappointed, but the Stork keeps his cool and serves him a smelly fish. The fox loses his temper, but the Stork is calm and serves him a jar of a food that smells delicious, but the fox can't reach it. This leads the fox to lose his temper as well.5</td><td></td><td></td><td></td></tr><tr><td>Precision scores 66.5 78.5</td><td></td><td>74.5</td></tr><tr><td>Similarity scores 67.0</td><td>69.0</td><td>57.0</td></tr><tr><td rowspan="3">Gemma 7B (aligned on GPT4o generated 256k dataset) A fox invited a stork to dinner, serving soup in a shallow dish the stork could not reach. The stork later invited the fox to dinner, serving fish in a narrow jar the fox could not reach. The stork's calm attitude reminded the fox to be careful with tricks.</td><td></td><td></td><td></td></tr><tr><td>Precision scores 84.5</td><td>93.5</td><td>85.5</td></tr><tr><td>Similarity 74.2</td><td>scores 86.7</td><td>67.5</td></tr><tr><td rowspan="2">Gemma 7B (aligned on Claude 3 Sonnet generated 256k dataset) The Fox tricked the Stork by serving soup in a shallow dish, which the Stork could not reach the food. In retaliation, the Stork served fish in a tall jar with a narrow neck, trapping the Fox from eating the food. The Stork calmly accepted the situation, while the Fox angrily lost his appetite.</td><td></td><td></td><td></td></tr><tr><td>Precision 80.5 71.3</td><td>scores 88.5 Similarity scores 78.5</td><td>73.5 43.5</td></tr><tr><td rowspan="2">Gemma 7B (aligned on Gemini 1.5 Flash generated 256k dataset)</td><td></td><td></td><td></td></tr><tr><td>Precision scores 61.0</td><td>88.5</td><td>68.0</td></tr><tr><td rowspan="2">The Fox tricked the Stork by serving him soup in a shallow dish he couldn't reach, but the Stork got revenge by serving the Fox a fish dinner in a jar the Fox couldn't access. The lesson learned by the Fox is to not play tricks on others unless you are prepared to face the same treatment.</td><td></td><td></td><td>36.5</td></tr><tr><td>Similarity scores 48.0</td><td>77.0</td><td></td></tr></table>{{< /table-caption >}}
> üîº Table 1 presents a comparative analysis of the performance of several service and fine-tuned local LLMs across four downstream tasks, evaluated by three different service LLMs as judges.
> <details>
> <summary>read the caption</summary>
> Table 1: Performance of the service LLMs and local LLMs fine-tuned on 128K synthetic dataset produced by GPT40, evaluated by GPT4o, Claude 3 Sonnet, and Gemini 1.5 Flash as judges on test subsets of coverage dataset. Each entry is presented as mean score / coverage percentage (%) with 50 score. Scores in Red are the best results from service LLMs, while the scores in Blue are the best results from local LLMs. Perf. Matching represents performance matching which is defined as the best performance of the local LLM divided by the service LLM, where the best results are in Pink.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="https://ai-paper-reviewer.com/2408.13467/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/21.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/22.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/23.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/24.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/25.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/26.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/27.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/28.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="https://ai-paper-reviewer.com/2408.13467/29.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}