[{"content": "| Benchmark | Contamination |\n|---|---| \n| cais/mmlu | 1.34% |\n| openai/openai_humaneval | 0.00% |\n| openai/gsm8k | 0.08% |\n| ucinlp/drop | 0.20% |\n| lighteval/MATH | 0.06% |\n| google/IFEval | 0.00% |\n| akariasai/PopQA | 7.21% |\n| tatsu-lab/alpaca_eval | 1.37% |\n| lukaemon/bbh | 0.02% |\n| truthfulqa/truthful_qa | 1.47% |\n| allenai/wildguardmix | 0.06% |\n| allenai/wildjailbreak | 0.00% |\n| TIGER-Lab/MMLU-Pro | 0.93% |\n| Idavidrein/gpqa | 0.00% |\n| lighteval/agi_eval_en | 0.00% |\n| bigcode/bigcodebench | 0.00% |\n| deepmind/math_dataset | 0.00% |", "caption": "Table 1: Contamination of benchmarks in the SFT dataset used allenai/tulu-3-sft-mixture", "description": "\uc774 \ud45c\ub294 SFT \ub370\uc774\ud130\uc14b(allenai/tulu-3-sft-mixture)\uc5d0 \uc0ac\uc6a9\ub41c \ubca4\uce58\ub9c8\ud06c\ub4e4\uc758 \uc624\uc5fc\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\uc5fc\ub960\uc774\ub780, \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc5d0 \ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc758 \ub0b4\uc6a9\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \ube44\uc728\uc744 \uc758\ubbf8\ud558\uba70, \uc774\ub294 \ubaa8\ub378 \ud3c9\uac00\uc758 \uc2e0\ub8b0\ub3c4\ub97c \ub5a8\uc5b4\ub728\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \ub300\ubd80\ubd84\uc758 \ubca4\uce58\ub9c8\ud06c\ub294 1.5% \ubbf8\ub9cc\uc758 \ub0ae\uc740 \uc624\uc5fc\ub960\uc744 \ubcf4\uc774\uace0 \uc788\uc73c\uba70, GSM8K, IFEval, AGI Eval\uacfc \uac19\uc740 \uc8fc\uc694 \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c\ub294 \uc624\uc5fc\ub960\uc774 \uac70\uc758 0\uc5d0 \uac00\uae5d\uc2b5\ub2c8\ub2e4.", "section": "3.1 Dataset"}, {"content": "| Hyperparameter | SmolTulu | SmolTulu | Tulu 3 | Tulu 3 |\n|---|---|---|---|---| \n|  | **SFT-1130** | **SFT-1207** | **SFT 8b** | **SFT 70b** |\n| Learning Rate (LR) | 9.0e-5 | 3.1e-6 | 5.0e-6 | 2.0e-6 |\n| Batch Size (BS) | 8 | 32 | 128 | 128 |\n| LR/BS x 10^6 | 11.25 | 0.097 | 0.039 | 0.016 |", "caption": "Table 2: SFT hyperparameter selection", "description": "\uc774 \ud45c\ub294 \uc9c0\ub3c4 \ubbf8\uc138 \uc870\uc815(SFT) \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378(SmolTulu, Tulu 3)\uc5d0 \ub300\ud55c \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30 \ubc0f \ud559\uc2b5\ub960 \ub300 \ubc30\uce58 \ud06c\uae30 \ube44\uc728\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. SmolTulu \ubaa8\ub378\uc740 \ub354 \ud070 \ud559\uc2b5\ub960 \ub300 \ubc30\uce58 \ud06c\uae30 \ube44\uc728\uc744 \uc0ac\uc6a9\ud558\ub294 \ubc18\uba74 Tulu 3 \ubaa8\ub378\uc740 \ub354 \uc791\uc740 \ube44\uc728\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ube44\uc728\uc740 \ubaa8\ub378 \ud06c\uae30 \ubc0f \uc791\uc5c5 \uc720\ud615\uc5d0 \ub530\ub77c \ucd5c\uc801\uc758 \ud559\uc2b5 \uc5ed\ud559\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 Supervised Finetuning"}, {"content": "| Metric | SmolTulu<br>SFT-1130 | SmolTulu<br>SFT-1207 | SmolLM2<br>1.7B-Instruct |\n|---|---|---|---| \n| ARC (Average) | 51.0 | **55.6** | 51.7 |\n| BBH (3-shot) | **34.7** | 34.0 | 32.2 |\n| GSM8K (5-shot) | **49.0** | 42.8 | 48.2 |\n| HellaSwag | 61.5 | **67.5** | 66.1 |\n| IFEval (Average) | **61.0** | 47.8 | 56.7 |\n| MMLU-Pro (MCF) | 17.6 | 17.9 | **19.3** |\n| PIQA | 72.7 | **76.9** | 74.4 |", "caption": "Table 3: Performance comparison of SFT models", "description": "SFT \ubaa8\ub378 \uc131\ub2a5 \ube44\uad50\ud45c: SmolTulu SFT-1130, SmolTulu SFT-1207, SmolLM2 1.7B-Instruct \ubaa8\ub378\uc758 ARC, BBH, GSM8K, HellaSwag, IFEval, MMLU-Pro, PIQA \ubca4\uce58\ub9c8\ud06c \uc810\uc218 \ube44\uad50", "section": "3 Supervised Finetuning"}, {"content": "| Benchmark | Contamination |\n|---|---| \n| cais/mmlu | 0.69% |\n| openai/openai_humaneval | 0.00% |\n| openai/gsm8k | 0.00% |\n| ucinlp/drop | 0.07% |\n| lighteval/MATH | 0.02% |\n| google/IFEval | 0.00% |\n| akariasai/PopQA | 2.72% |\n| tatsu-lab/alpaca_eval | 1.24% |\n| lukaemon/bbh | 0.00% |\n| truthfulqa/truthful_qa | 0.61% |\n| allenai/wildguardmix | 0.06% |\n| allenai/wildjailbreak | 0.00% |\n| TIGER-Lab/MMLU-Pro | 0.36% |\n| Idavidrein/gpqa | 0.00% |\n| lighteval/agi_eval_en | 0.00% |\n| bigcode/bigcodebench | 0.00% |\n| deepmind/math_dataset | 0.00% |", "caption": "Table 4: Contamination of benchmarks in the DPO dataset used allenai/llama-3.1-tulu-3-8b-preference-mixture", "description": "\uc774 \ud45c\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c \uc5b8\uc5b4 \ubaa8\ub378(llama-3.1-tulu-3-8b-preference-mixture)\uc744 \ubbf8\uc138 \uc870\uc815\ud558\ub294 \ub370 \uc0ac\uc6a9\ub41c DPO \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ubca4\uce58\ub9c8\ud06c\uc758 \uc624\uc5fc \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \ubca4\uce58\ub9c8\ud06c\ub294 1% \ubbf8\ub9cc\uc758 \ub0ae\uc740 \uc624\uc5fc\ub960\uc744 \ubcf4\uc774\uba70, GSM8K, IFEval, BBH\uc640 \uac19\uc740 \ud575\uc2ec \ubca4\uce58\ub9c8\ud06c\ub294 \uc624\uc5fc\uc774 \uc804\ud600 \uc5c6\uc2b5\ub2c8\ub2e4. PopQA\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc624\uc5fc\ub960\uc778 2.72%\uac00 \uad00\ucc30\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "4. Direct Preference Optimization"}, {"content": "| Hyperparameter | SmolTulu<br>DPO-1130 | SmolTulu<br>DPO-1207 | Tulu 3<br>DPO 8b | Tulu 3<br>DPO 70b |\n|---|---|---|---|---| \n| Learning Rate (LR) | $8.0 \\times 10^{-7}$ | $5 \\times 10^{-7}$ | $5.0 \\times 10^{-7}$ | $2.0 \\times 10^{-7}$ |\n| Batch Size (BS) | 12 | 32 | 128 | 128 |\n| $\\frac{LR}{BS} \\times 10^{7}$ | 0.667 | 0.156 | 0.039 | 0.016 |", "caption": "Table 5: DPO hyperparameter selection", "description": "\uc774 \ud45c\ub294 SmolTulu, Tulu 3 \ubaa8\ub378\uc758 DPO \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30, \uadf8\ub9ac\uace0 \uadf8 \ube44\uc728\uc774 \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ub2e4\ub978\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.2 Training"}, {"content": "| Metric | SmolTulu<br>DPO-1130 | SmolTulu<br>DPO-1207 | SmolLM2<br>1.7B-Instruct |\n|---|---|---|---| \n| ARC (Average) | 51.5 | **57.1** | 51.7 |\n| BBH (3-shot) | **33.8** | **34.2** | 32.2 |\n| GSM8K (5-shot) | **51.6** | 44.7 | 48.2 |\n| HellaSwag | 61.1 | 64.2 | **66.1** |\n| IFEval (Average) | **67.7** | 56.6 | 56.7 |\n| MMLU-Pro (MCF) | 17.4 | 19.1 | **19.3** |\n| PIQA | 72.2 | **76.4** | 74.4 |", "caption": "Table 6: Performance comparison of DPO models", "description": "\uc774 \ud45c\ub294 Direct Preference Optimization(DPO) \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SmolTulu DPO-1130\uacfc SmolTulu DPO-1207 \ub450 \uac00\uc9c0 DPO \ubaa8\ub378\uc758 \uc131\ub2a5\uc744  SmolLM2 1.7B-Instruct \ubaa8\ub378\uacfc \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ube44\uad50\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. SmolTulu DPO-1130\uc740 IFEval\uacfc GSM8K\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ubc18\uba74 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc740 ARC\uc640 PIQA\uc5d0\uc11c \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 Direct Preference Optimization"}, {"content": "| Hyperparameter | SmolTulu | SmolTulu | Tulu 3 |\n|---|---|---|---| \n|  | **RM-1130** | **RM-1207** | **DPO 8b** |\n| Learning Rate (LR) | 4.0 \u00d7 10\u207b\u2075 | 7.5 \u00d7 10\u207b\u2077 | 5.0 \u00d7 10\u207b\u2077 |\n| Batch Size (BS) | 4 | 8 | 128 |\n| LR/BS \u00d7 10\u2077 | 100 | 0.938 | 0.039 |", "caption": "Table 7: Reward model hyperparameter selection", "description": "\uc774 \ud45c\ub294 \ubcf4\uc0c1 \ubaa8\ub378(Reward Model, RM) \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SmolTulu RM-1130, SmolTulu RM-1207, \uadf8\ub9ac\uace0 Tulu 3 DPO 8b \ubaa8\ub378\uc758 \ud559\uc2b5\ub960(Learning Rate), \ubc30\uce58 \ud06c\uae30(Batch Size), \uadf8\ub9ac\uace0 \ud559\uc2b5\ub960\uacfc \ubc30\uce58 \ud06c\uae30\uc758 \ube44\uc728(LR/BS)\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. SmolTulu \ubaa8\ub378\ub4e4\uc740 Tulu 3 \ubaa8\ub378\uc5d0 \ube44\ud574 \ub354 \ub192\uc740 LR/BS \ube44\uc728\uc744 \uc0ac\uc6a9\ud55c \uac83\uc774 \ud2b9\uc9d5\uc785\ub2c8\ub2e4.", "section": "5 Reward Modelling"}, {"content": "| Metric | SmolTulu<br>RM-1130 | SmolTulu<br>RM-1207 | Tulu 3<br>8b RM |\n|---|---|---|---| \n| RB Chat | *94.13* | 83.52 | **96.27** |\n| RB Chat Hard | 43.64 | *44.74* | **55.92** |\n| RB Safety | *75.54* | 64.59 | **84.05** |\n| RB Reasoning | *68.01* | 54.71 | **76.50** |\n| RB Average | *72.43* | 58.59 | **81.34** |\n| UFB | *73.17* | 61.66 | **77.34** |", "caption": "Table 8: Performance comparison of reward models, where UFB is the test_prefs split of allenai/ultrafeedback_binarized_cleaned and RB is RewardBench.", "description": "\uc774 \ud45c\ub294 \ubcf4\uc0c1 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. UFB\ub294 allenai/ultrafeedback_binarized_cleaned\uc758 test_prefs \ubd84\ud560\uc774\uace0 RB\ub294 RewardBench\uc785\ub2c8\ub2e4. SmolTulu RM-1130\uc740 \ud45c\uc900 \ucc44\ud305 \ud3c9\uac00\uc5d0\uc11c 94.13%, \uc548\uc804 \ud3c9\uac00\uc5d0\uc11c 75.54%\ub97c \ub2ec\uc131\ud558\ub294 \ub4f1 \ub2e4\uc591\ud55c \uc9c0\ud45c\uc5d0\uc11c RewardBench\uc5d0\uc11c \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uac15\ub825\ud55c \uc0c1\ub300\uc801 \uc131\ub2a5 \ud328\ud134\uc740 \ub2e4\ub978 \uc9c0\ud45c\uc5d0\ub3c4 \uc801\uc6a9\ub418\uba70, SmolTulu RM-1130\uc740 UltraFeedback \ubca4\uce58\ub9c8\ud06c \ud14c\uc2a4\ud2b8 \uc120\ud638\ub3c4\uc5d0\uc11c 73.17%\uc758 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud558\uc5ec \ub9e4\uac1c\ubcc0\uc218\uc758 \uc57d 21%\ub9cc \uc0ac\uc6a9\ud568\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 Tulu 3\uc758 77.34%\uc5d0 \ubd88\uacfc 4.17% \ud3ec\uc778\ud2b8 \ucc28\uc774\ub85c \ub4a4\ucc98\uc84c\uc2b5\ub2c8\ub2e4. (Shallue et al., 2019)\uc758 \ud504\ub808\uc784\uc6cc\ud06c\uc5d0 \ub530\ub974\uba74, \uc774\ub7ec\ud55c \uacb0\uacfc\ub294 \ud2b9\ud788 \uc801\uc808\ud558\uac8c \uc870  \ub41c \ucd5c\uc801\ud654 \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud560 \ub54c \ubcf4\uc0c1 \ubaa8\ub378\ub9c1\uc774 \uc774\uc804\uc5d0 \uac00\uc815\ud588\ub358 \uac83\ubcf4\ub2e4 \ub354 \uc791\uc740 \uc544\ud0a4\ud14d\ucc98\ub85c \ub354 \uc6b0\uc544\ud558\uac8c \ud655\uc7a5\ub420 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. RM-1130\uacfc RM-1207(RB\uc5d0\uc11c 72.43% \ub300 58.59%) \uac04\uc758 \uc0c1\ub2f9\ud55c \uc131\ub2a5 \uaca9\ucc28\ub294 \uc18c\uaddc\ubaa8 \ubaa8\ub378\uc5d0\uc11c \ud559\uc2b5\ub960 \ub300 \ubc30\uce58 \ud06c\uae30 \ube44\uc728\uc758 \uc911\uc694\uc131\uc5d0 \ub300\ud55c \uc774\uc804 \uacb0\uacfc\ub97c \uac15\ud654\ud569\ub2c8\ub2e4. RM-1130\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub354 \ub192\uc740 \ube44\uc728\uc740 \ud2b9\ud788 \uc120\ud638\ub3c4 \uad00\uacc4\ub97c \ud559\uc2b5\ud558\ub294 \uc791\uc5c5\uc5d0\uc11c \ubcf4\uc0c1 \ubaa8\ub378\ub9c1\uc5d0 \uc911\uc694\ud55c \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c \ub354 \ud070 \uc608\uc2dc\ub2f9 \uc5c5\ub370\uc774\ud2b8\uc640 \ub354 \ube48\ubc88\ud55c \uadf8\ub77c\ub370\uc774\uc158 \uacc4\uc0b0\uc758 \uc774\uc810\uc744 \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc774\ub7ec\ud55c \uad00\uacc4\uc758 \uc815\ud655\ud55c \ud2b9\uc131\uc744 \ud655\ub9bd\ud558\ub824\uba74 \ub354 \uad11\ubc94\uc704\ud55c \uc808\uc81c \uc5f0\uad6c\uac00 \ud544\uc694\ud558\uba70, \uc774\ub294 \ub354 \ud070 \uacc4\uc0b0 \ub9ac\uc18c\uc2a4\ub97c \uc0ac\uc6a9\ud55c \ud5a5\ud6c4 \uc791\uc5c5\uc73c\ub85c \ub0a8\uaca8\ub461\ub2c8\ub2e4.", "section": "5 Reward Modelling"}, {"content": "| Metric | SmolTulu<br>DPO-1130 | SmolTulu<br>DPO-1207 | SmolTulu<br>SFT-1130 | SmolTulu<br>SFT-1207 | SmolLM2<br>1.7B-Instruct | Llama-3.2<br>1B-Instruct | Qwen2.5<br>1.5B-Instruct |\n|---|---|---|---|---|---|---|---|\n| ARC (Average) | 51.5 | **57.1** | 51.0 | 55.6 | 51.7 | 41.6 | 46.2 |\n| BBH (3-shot) | 33.8 | 34.2 | 34.7 | 34.0 | 32.2 | 27.6 | **35.3** |\n| GSM8K (5-shot) | **51.6** | 44.7 | 49.0 | 42.8 | 48.2 | 26.8 | 42.8 |\n| HellaSwag | 61.1 | 64.2 | 61.5 | **67.5** | 66.1 | 56.1 | 60.9 |\n| IFEval (Average) | **67.7** | 56.6 | 61.0 | 47.8 | 56.7 | 53.5 | 47.4 |\n| MMLU-Pro (MCF) | 17.4 | 19.1 | 17.6 | 17.9 | 19.3 | 12.7 | **24.2** |\n| PIQA | 72.2 | 76.4 | 72.7 | **76.9** | 74.4 | 72.3 | 73.2 |", "caption": "Table 9: A comparison against a wider selection of models", "description": "\ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uacfc SmolTulu\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. SmolTulu DPO-1130, SmolTulu DPO-1207, SmolTulu SFT-1130, SmolTulu SFT-1207, SmolLM2 1.7B-Instruct, Llama-3.2 1B-Instruct, Qwen2.5 1.5B-Instruct \ubaa8\ub378\ub4e4\uc758 ARC, BBH, GSM8K, HellaSwag, IFEval, MMLU-Pro, PIQA \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec SmolTulu\uc758 \uc131\ub2a5 \uc6b0\uc704\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "8. Conclusion"}, {"content": "| Language | Presence (%) |\n|---|---| \n| English | 83.13 |\n| Hindi | 3.79 |\n| Swahili | 2.02 |\n| Russian | 2.00 |\n| Spanish | 1.15 |\n| Arabic | 0.98 |\n| Chinese | 0.94 |\n| Turkish | 0.87 |\n| Urdu | 0.78 |\n| Portuguese | 0.77 |\n| Vietnamese | 0.64 |\n| Japanese | 0.63 |\n| French | 0.66 |\n| Bulgarian | 0.33 |\n| Italian | 0.32 |\n| Dutch | 0.31 |\n| Polish | 0.25 |\n| German | 0.23 |\n| Thai | 0.10 |\n| Greek | 0.09 |", "caption": "Table 10: Language distribution in SFT dataset.", "description": "SFT \ub370\uc774\ud130\uc14b\uc5d0 \uc0ac\uc6a9\ub41c allenai/tulu-3-sft-mixture\uc758 \uc5b8\uc5b4 \ubd84\ud3ec\ub97c \ub098\ud0c0\ub0b8 \ud45c\uc785\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc601\uc5b4\uac00 83.13%\ub85c \uac00\uc7a5 \ub9ce\uc774 \uc0ac\uc6a9\ub418\uc5c8\uace0, \uadf8 \ub4a4\ub97c \ud78c\ub514\uc5b4(3.79%), \uc2a4\uc640\ud790\ub9ac\uc5b4(2.02%), \ub7ec\uc2dc\uc544\uc5b4(2.00%) \ub4f1\uc774 \ucc28\uc9c0\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Supervised Finetuning"}, {"content": "| Language | Presence (%) |\n|---|---| \n| English | 86.24 |\n| Hindi | 2.23 |\n| Russian | 2.03 |\n| French | 1.42 |\n| Spanish | 1.40 |\n| Chinese | 1.37 |\n| Urdu | 0.68 |\n| Swahili | 0.65 |\n| German | 0.58 |\n| Japanese | 0.57 |\n| Portuguese | 0.54 |\n| Arabic | 0.51 |\n| Turkish | 0.42 |\n| Vietnamese | 0.33 |\n| Italian | 0.32 |\n| Polish | 0.22 |\n| Dutch | 0.18 |\n| Bulgarian | 0.18 |\n| Thai | 0.10 |\n| Greek | 0.04 |", "caption": "Table 11: Language distribution in DPO / RM dataset.", "description": "\uc774 \ud45c\ub294 DPO(Direct Preference Optimization) \ubc0f RM(Reward Modeling) \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac01 \uc5b8\uc5b4\uac00 \ucc28\uc9c0\ud558\ub294 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \uc601\uc5b4\uac00 \uac00\uc7a5 \ud070 \ube44\uc911\uc744 \ucc28\uc9c0\ud558\uace0 \uc788\uc73c\uba70, \uadf8 \uc678 \ub2e4\uc591\ud55c \uc5b8\uc5b4\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 Direct Preference Optimization"}, {"content": "| Language | Presence (%) |\n|---|---| \n| English | 94.80 |\n| French | 1.29 |\n| Spanish | 1.04 |\n| Chinese | 0.66 |\n| German | 0.55 |\n| Russian | 0.48 |\n| Japanese | 0.40 |\n| Hindi | 0.23 |\n| Polish | 0.10 |\n| Portuguese | 0.10 |\n| Dutch | 0.08 |\n| Urdu | 0.07 |\n| Bulgarian | 0.07 |\n| Italian | 0.05 |\n| Turkish | 0.03 |\n| Arabic | 0.03 |\n| Vietnamese | 0.02 |\n| Swahili | 0.00 |", "caption": "Table 12: Language distribution in RLVR dataset.", "description": "RLVR \ub370\uc774\ud130\uc14b\uc758 \uc5b8\uc5b4 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4. \uc8fc\ub85c \uc601\uc5b4\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc73c\uba70, \ud504\ub791\uc2a4\uc5b4, \uc2a4\ud398\uc778\uc5b4, \uc911\uad6d\uc5b4, \ub3c5\uc77c\uc5b4, \ub7ec\uc2dc\uc544\uc5b4, \uc77c\ubcf8\uc5b4 \ub4f1 \ub2e4\uc591\ud55c \uc5b8\uc5b4\uac00 \uc18c\ub7c9 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Reward Modelling"}, {"content": "| Benchmark | Contamination |\n|---|---| \n| cais/mmlu | 0.65% |\n| openai/openai_humaneval | 0.00% |\n| openai/gsm8k | 0.00% |\n| ucinlp/drop | 0.00% |\n| lighteval/MATH | 0.24% |\n| google/IFEval | 0.00% |\n| akariasai/PopQA | 0.45% |\n| tatsu-lab/alpaca_eval | 0.12% |\n| lukaemon/bbh | 0.00% |\n| truthfulqa/truthful_qa | 0.12% |\n| allenai/wildguardmix | 0.00% |\n| allenai/wildjailbreak | 0.00% |\n| TIGER-Lab/MMLU-Pro | 0.66% |\n| Idavidrein/gpqa | 0.00% |\n| lighteval/agi_eval_en | 0.00% |\n| bigcode/bigcodebench | 0.00% |\n| deepmind/math_dataset | 0.00% |", "caption": "Table 13: Contamination of benchmarks in the RLVR dataset allenai/RLVR-GSM-MATH-IF-Mixed-Constraints", "description": "RLVR \ub370\uc774\ud130\uc14b(allenai/RLVR-GSM-MATH-IF-Mixed-Constraints)\uc758 \ubca4\uce58\ub9c8\ud06c\ubcc4 \uc624\uc5fc\ub3c4\ub97c \ub098\ud0c0\ub0b8 \ud45c\uc785\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc624\uc5fc\ub3c4\ub294 1% \ubbf8\ub9cc\uc73c\ub85c \ub0ae\uac8c \ub098\ud0c0\ub0ac\uc73c\uba70, GSM8K, IFEval, BBH\uc640 \uac19\uc740 \uc911\uc694 \ubca4\uce58\ub9c8\ud06c\ub294 \uc624\uc5fc\ub3c4 0%\ub97c \uae30\ub85d\ud588\uc2b5\ub2c8\ub2e4.", "section": "5. Reward Modelling"}]