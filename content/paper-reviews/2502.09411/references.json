{"references": [{"fullname_first_author": "T. B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-05-14", "reason": "This paper introduced the concept of in-context learning for large language models, a technique also explored for image generation in this work."}, {"fullname_first_author": "P. Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks", "publication_date": "2020-00-00", "reason": "This foundational paper on Retrieval Augmented Generation (RAG) inspired the core methodology of ImageRAG, which adapts RAG principles for image generation."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduced diffusion models, which are the basis for many modern high-quality image generation models and are used as the base model for ImageRAG."}, {"fullname_first_author": "D. Podell", "paper_title": "SDXL: Improving latent diffusion models for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "This paper describes SDXL, one of the powerful image generation models used in the experiments, showcasing its effectiveness and acting as a strong baseline for comparison."}, {"fullname_first_author": "S. Xiao", "paper_title": "Omnigen: Unified image generation", "publication_date": "2024-00-00", "reason": "This paper details Omnigen, another state-of-the-art image generation model used for ImageRAG, offering diverse capabilities and acting as a key model in ImageRAG\u2019s experimental evaluation."}]}