{"references": [{"fullname_first_author": "Carl Doersch", "paper_title": "TAP-vid: A benchmark for tracking any point in a video", "publication_date": "2022-12-31", "reason": "This paper introduces a benchmark dataset crucial for evaluating long-term dense point tracking methods, which is the primary focus of the current research."}, {"fullname_first_author": "Thomas Brox", "paper_title": "High accuracy optical flow estimation based on a theory for warping", "publication_date": "2004-05-14", "reason": "This foundational paper proposes a high-accuracy optical flow estimation method which is a key component used by many of the cited papers in the current research."}, {"fullname_first_author": "Thomas Brox", "paper_title": "Large displacement optical flow", "publication_date": "2009-06-20", "reason": "This paper addresses the challenge of estimating optical flow across large displacements, which is particularly important for long-term tracking of points."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-04-07", "reason": "This paper presents a powerful self-supervised approach for learning visual features, which enhances the feature extraction in the current work"}, {"fullname_first_author": "Zachary Teed", "paper_title": "RAFT: Recurrent all-pairs field transforms for optical flow", "publication_date": "2020-08-28", "reason": "This work provides a highly accurate and widely used deep learning model for optical flow estimation, which is the backbone method for short-term point tracking."}]}