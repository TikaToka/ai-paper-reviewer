[{"content": "| **Attention** | **Window Size** | **Dense Block** | **Mixed Block** |\n|---|---|---|---|\n| Tiled NATTEN | (11,11,11) | 0.06% | 7.17% |\n| STA | (12, 12, 12) | 1.56% | 0.0% |\n| STA | (20, 20, 20) | 7.23% | 0.0% |", "caption": "Table 1: Ratio of dense and mixed blocks for tiled NATTEN and STA\u00a0 with tile size (4,4,4) and video size (48,48,48). STA\u00a0generate only dense blocks, which is more computationally friendly than mixed blocks in GPU.", "description": "\uc774 \ud45c\ub294 \ud0c0\uc77c \ud06c\uae30\uac00 (4,4,4)\uc774\uace0 \ube44\ub514\uc624 \ud06c\uae30\uac00 (48,48,48)\uc77c \ub54c, Tiled NATTEN\uacfc STA\uc758 \uc870\ubc00 \ube14\ub85d\uacfc \ud63c\ud569 \ube14\ub85d\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Tiled NATTEN\uc740 \uc870\ubc00 \ube14\ub85d\uacfc \ud63c\ud569 \ube14\ub85d\uc774 \uc11e\uc5ec\uc788\uc9c0\ub9cc, STA\ub294 GPU\uc5d0\uc11c \uacc4\uc0b0 \ud6a8\uc728\uc774 \ub354 \uc88b\uc740 \uc870\ubc00 \ube14\ub85d\ub9cc \uc0dd\uc131\ud569\ub2c8\ub2e4. \ud63c\ud569 \ube14\ub85d\uc740 GPU \uc5f0\uc0b0\uc5d0 \ube44\ud6a8\uc728\uc801\uc774\uae30 \ub54c\ubb38\uc5d0, STA\uc758 \uc870\ubc00 \ube14\ub85d\ub9cc \uc0dd\uc131\ud558\ub294 \ud2b9\uc9d5\uc740 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud569\ub2c8\ub2e4.  \uc989, \uc774 \ud45c\ub294 STA\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc8fc\uc694 \uadfc\uac70\uac00 \ub429\ub2c8\ub2e4.", "section": "3. Methods"}, {"content": "| Methods | Implementation | Config | Sparsity | TFLOPS | Latency(ms) | MFU | Kernel Efficiency | Speedup |\n|---|---|---|---|---|---|---|---|---|\n| FA 3 | ThunderKittens | - | 0.00% | 164.03 | 265.28 | 62.49% | 100.00% | 1.00\u00d7 |\n| FA 3 | CUDA | - | 0.00% | 164.03 | 256.59 | 64.61% | 103.39% | 1.03\u00d7 |\n| CLEAR | FlexAttention | r=16 | 90.46% | 15.65 | 307.44 | 5.15% | 8.24% | 0.86\u00d7 |\n| NATTEN | FlexAttention | w=(19,25,25) | 89.69% | 16.91 | 313.92 | 5.44% | 8.71% | 0.85\u00d7 |\n| Tiled NATTEN | CUDA | w=(19,25,25) | 89.69% | 16.91 | 458.36 | 3.73% | 5.97% | 0.58\u00d7 |\n| Tiled NATTEN | FlexAttention | w=(19,25,25) | 89.69% | 16.91 | 208.36 | 8.20% | 13.12% | 1.27\u00d7 |\n| Swin | FlexAttention | w=(24,32,32) | 87.42% | 20.64 | 47.90 | 43.55% | 69.69% | 5.54\u00d7 |\n| STA | FlexAttention | w=(18,24,24) | 91.00% | 14.76 | 36.36 | 41.03% | 65.66% | 7.30\u00d7 |\n| STA | ThunderKittens | w=(30,40,40) | 58.33% | 68.35 | 111.73 | 61.82% | 98.93% | 2.37\u00d7 |\n| STA | ThunderKittens | w=(18,24,24) | 91.00% | 14.76 | 25.38 | 58.79% | 94.09% | 10.45\u00d7 |", "caption": "Table 2: Forward speed of sparse attention kernels in a setup aligned with HunyuanVideo\u2019s inference configuration (bf16, 720P, 5s, 115.2K seq_len, dh\u2062e\u2062a\u2062dsubscript\ud835\udc51\u210e\ud835\udc52\ud835\udc4e\ud835\udc51d_{head}italic_d start_POSTSUBSCRIPT italic_h italic_e italic_a italic_d end_POSTSUBSCRIPT = 128, # heads = 24). Config controls the window size of each sparse attention.", "description": "\ud45c 2\ub294 HunyuanVideo \ucd94\ub860 \uc124\uc815(bf16, 720P, 5\ucd08, 115.2K seq_len, head \ucc28\uc6d0 = 128, head \uc218 = 24)\uacfc \uc77c\uce58\ud558\ub3c4\ub85d \uad6c\uc131\ub41c \ud658\uacbd\uc5d0\uc11c \uc5ec\ub7ec \uac00\uc9c0 \ud76c\uc18c \uc5b4\ud150\uc158 \ucee4\ub110\uc758 \uc21c\uc804\ud30c \uc18d\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud76c\uc18c \uc5b4\ud150\uc158\uc758 \ucc3d \ud06c\uae30\ub294 'Config' \uc5f4\uc5d0\uc11c \uc81c\uc5b4\ub429\ub2c8\ub2e4.  \ud45c\ub294 \uac01 \ubc29\ubc95\uc758 \uad6c\ud604, \uad6c\uc131, \ud76c\uc18c\uc131, TFLOPS, \uc9c0\uc5f0 \uc2dc\uac04(\ubc00\ub9ac\ucd08), MFU(Memory Footprint Utilization), \ucee4\ub110 \ud6a8\uc728\uc131, \uc18d\ub3c4 \ud5a5\uc0c1 \ubc30\uc218\ub97c \ube44\uad50\ud558\uc5ec,  \ub2e4\uc591\ud55c \ud76c\uc18c \uc5b4\ud150\uc158 \uae30\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | SSIM \u2191 | PSNR \u2191 | CD-FVD \u2193 | Latency | Speedup |\n|---|---|---|---|---|---| \n| **steps = 50** |  |  |  |  |  |\n| \u0394-DiT | 72.86% | 18.09 | 122.74 | 693s | 1.36 \u00d7 |\n| STA | 76.21% | 19.94 | 97.03 | 695s | 1.36 \u00d7 |\n| **steps = 25** |  |  |  |  |  |\n| \u0394-DiT | 77.91% | 19.86 | 196.25 | 352s | 1.34 \u00d7 |\n| STA | 82.47% | 22.53 | 95.86 | 348s | 1.36 \u00d7 |\n| **steps = 10** |  |  |  |  |  |\n| \u0394-DiT | 83.19% | 21.20 | 201.24 | 144s | 1.32 \u00d7 |\n| STA | 87.15% | 24.04 | 80.41 | 139s | 1.36 \u00d7 |", "caption": "Table 3: Training-free performance with varying sampling steps. \u0394\u0394\\Deltaroman_\u0394-DiT shows consistently worse quality compared to STA, and that gap widens as the number of inference steps decrease.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \uc0d8\ud50c\ub9c1 \ub2e8\uacc4\uc5d0\uc11c \ud559\uc2b5 \uc5c6\uc774 \uc218\ud589\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  A-DiT \ubaa8\ub378\uc740 STA \ubaa8\ub378\uc5d0 \ube44\ud574 \uc77c\uad00\ub418\uac8c \ub0ae\uc740 \ud654\uc9c8\uc744 \ubcf4\uc774\uba70, \ucd94\ub860 \ub2e8\uacc4\uac00 \uac10\uc18c\ud560\uc218\ub85d \uadf8 \ucc28\uc774\uac00 \ub354\uc6b1 \ucee4\uc9d1\ub2c8\ub2e4.  \uc989, \ub3d9\uc77c\ud55c \uacc4\uc0b0 \ube44\uc6a9\uc73c\ub85c A-DiT\ubcf4\ub2e4 STA\uac00 \ub354 \uc88b\uc740 \ud654\uc9c8\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ud45c\uc5d0\ub294 SSIM, PSNR, CD-FVD \uc9c0\ud45c\uc640 \ucd94\ub860 \uc2dc\uac04, \uc18d\ub3c4 \ud5a5\uc0c1 \ube44\uc728\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4 \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc \ud6a8\uc728\uc131\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4.3 Training-free Results"}, {"content": "| Methods | Config | VBench Quality | VBench Semantic | VBench Total | Attn Sparsity | PFLOPS | Latency | Speedup |\n|---|---|---|---|---|---|---|---|---|\n| FA2 | \u2013 | 85.34% | 72.17% | 82.71% | 0.00% | 574.16 | 1496s | 0.63\u00d7 |\n| FA3 | \u2013 | 85.34% | 72.17% | 82.71% | 0.00% | 574.16 | 945s | 1.00\u00d7 |\n| *w.o training* |  |  |  |  |  |  |  |  |\n| CLEAR | r=32 | 84.41% | 74.20% | 82.37% | 56.23% | 280.90 | 2567s | 0.37\u00d7 |\n| Tiled NATTEN | w=(30,41,41) | 84.61% | 75.00% | 82.69% | 58.33% | 269.92 | 1858s | 0.51\u00d7 |\n| Swin | w=(48,64,64) | 80.91% | 71.35% | 79.00% | 55.81% | 283.11 | 762s | 1.24\u00d7 |\n| Swin | w=(30,40,40) | 78.84% | 72.28% | 77.53% | 76.49% | 175.20 | 497s | 1.90\u00d7 |\n| STA | w=(30,40,40) | 84.63% | 73.83% | 82.46% | 58.33% | 269.92 | 527s | 1.79\u00d7 |\n| STA | w=(18,24,24) | 81.47% | 77.03% | 80.58% | 91.00% | 99.54 | 268s | 3.53\u00d7 |\n| *w. training* |  |  |  |  |  |  |  |  |\n| Swin | w=(30,40,40) | 77.50% | 67.39% | 75.48% | 55.81% | 283.08 | 497s | 1.90\u00d7 |\n| STA | w=(30,24,40) | 85.37% | 73.52% | 83.00% | 75.00% | 182.99 | 388s | 2.44\u00d7 |\n| STA | w=(18,24,24) | 84.76% | 74.05% | 82.62% | 91.00% | 99.54 | 268s | 3.53\u00d7 |", "caption": "Table 4: Performance on VBench across different sparse attention patterns. STA\u00a0achieves both high-quality video generation and significant speedup, while CLEAR and Tiled NATTEN suffer from efficiency issues and Swin suffers from quality degradation.", "description": "\ud45c 4\ub294 \ub2e4\uc591\ud55c \ud76c\uc18c \uc5b4\ud150\uc158 \ud328\ud134\uc5d0 \ub300\ud55c VBench \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 SLIDING TILE ATTENTION (STA) \uc54c\uace0\ub9ac\uc998\uc774 \uace0\ud488\uc9c8\uc758 \ube44\ub514\uc624 \uc0dd\uc131\uacfc \uc0c1\ub2f9\ud55c \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ub3d9\uc2dc\uc5d0 \ub2ec\uc131\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc18\uba74\uc5d0 CLEAR \ubc0f Tiled NATTEN \uc54c\uace0\ub9ac\uc998\uc740 \ud6a8\uc728\uc131 \ubb38\uc81c\ub97c, Swin \uc54c\uace0\ub9ac\uc998\uc740 \ud654\uc9c8 \uc800\ud558 \ubb38\uc81c\ub97c \uacaa\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.  \ubcf4\ub2e4 \uc790\uc138\ud788 \uc0b4\ud3b4\ubcf4\uba74, \uac01 \uc54c\uace0\ub9ac\uc998\uc758 VBench \uc810\uc218 (\uc804\ubc18\uc801\uc778 \ud654\uc9c8, \uc758\ubbf8\uc801 \uc77c\uad00\uc131, \uc138\ubd80 \ubb18\uc0ac \ub4f1), \uc5b4\ud150\uc158 \ud76c\uc18c\uc131 \ube44\uc728, \ucc98\ub9ac\ub7c9(PFLOPS), \uc9c0\uc5f0 \uc2dc\uac04(Latency), \uc18d\ub3c4 \ud5a5\uc0c1 \ube44\uc728(Speedup) \ub4f1\uc774 \uc0c1\uc138\ud788 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \uc7a5\ub2e8\uc810\uacfc \uc0c1\ub300\uc801 \uc131\ub2a5\uc744 \uc885\ud569\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Methods | SSIM | PSNR | Sparsity | Latency | Speedup |\n|---|---|---|---|---|---| \n| **1K \u2192 2K** |  |  |  |  |  |\n| CLEAR r=16 | 0.9291 | 28.1142 | 96.12% | 13s | 1.54\u00d7 |\n| CLEAR r=32 | 0.9443 | 29.6722 | 85.94% | 15s | 1.33\u00d7 |\n| STA w=(48,72) | 0.9357 | 29.1086 | 81.25% | 14s | 1.43\u00d7 |\n| **2K \u2192 4K** |  |  |  |  |  |\n| CLEAR r=16 | 0.9394 | 29.0463 | 98.98% | 67s | 2.90\u00d7 |\n| CLEAR r=32 | 0.9455 | 30.0742 | 96.08% | 92s | 2.11\u00d7 |\n| STA w=(48,72) | 0.9470 | 30.1939 | 95.31% | 57s | 3.40\u00d7 |", "caption": "Table 5: Image superresolution results with FLUX\u00a0(Black-Forest, 2023) on 1000 captions randomly sampled from COCO-2014\u00a0(Lin et\u00a0al., 2015) validation dataset.", "description": "\uc774 \ud45c\ub294 FLUX (Black-Forest, 2023) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec COCO-2014 (Lin et al., 2015) \uac80\uc99d \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \ucd94\ucd9c\ud55c 1000\uac1c\uc758 \ucea1\uc158\uc5d0 \ub300\ud55c \uc774\ubbf8\uc9c0 \ucd08\ud574\uc0c1\ub3c4 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  1K\uc5d0\uc11c 2K, 2K\uc5d0\uc11c 4K\ub85c\uc758 \uc774\ubbf8\uc9c0 \uc5c5\uc2a4\ucf00\uc77c\ub9c1 \uacb0\uacfc\uc5d0 \ub300\ud574 SSIM, PSNR, \uadf8\ub9ac\uace0 \ucc98\ub9ac \uc18d\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc5f0\uc0b0\ub7c9 \ud6a8\uc728\uc131(Sparsity) \ubc0f \ucc98\ub9ac \uc2dc\uac04(Latency)\uc744 \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec, \ucd08\ud574\uc0c1\ub3c4 \uc131\ub2a5\uacfc \ucc98\ub9ac \uc18d\ub3c4 \uac04\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.  CLEAR\uc640 STA \uae30\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec,  \uac01 \uae30\ubc95\uc758 \ud6a8\uc728\uc131 \ubc0f \uc131\ub2a5 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Methods | Implementation | Config | Sparsity | TFLOPS | Latency(ms) | MFU | Kernel Efficiency | Speedup |\n|---|---|---|---|---|---|---|---|---|\n| FA 3 | ThunderKittens | - | 0.00% | 164.03 | 265.28 | 62.49% | 100.00% | 1.00\u00d7 |\n| FA 3 | CUDA | - | 0.00% | 164.03 | 256.59 | 64.61% | 103.39% | 1.03\u00d7 |\n| CLEAR | FlexAttention | r=32 | 56.23% | 71.80 | 675.05 | 10.75% | 17.20% | 0.39\u00d7 |\n| NATTEN | FlexAttention | w=(30,41,41) | 56.22% | 71.81 | 804.62 | 9.02% | 14.43% | 0.33\u00d7 |\n| Tiled NATTEN | CUDA | w=(29,41,41) | 57.68% | 69.41 | 173.57 | 4.04% | 6.47% | 0.15x |\n| Tiled NATTEN | FlexAttention | w=(30,41,41) | 56.22% | 71.81 | 409.89 | 17.70% | 28.33% | 0.65\u00d7 |\n| Swin | FlexAttention | w=(48,64,64) | 55.81% | 72.49 | 127.51 | 57.46% | 91.95% | 2.08\u00d7 |\n| STA | FlexAttention | w=(30,40,40) | 58.33% | 68.35 | 174.17 | 39.66% | 63.46% | 1.52\u00d7 |\n| STA | ThunderKittens | w=(30,40,40) | 58.33% | 68.35 | 111.73 | 61.82% | 98.93% | 2.37\u00d7 |", "caption": "Table 6: Speedup with sparse attention kernels on H100.", "description": "\ud45c 6\uc740 H100 GPU \uc0c1\uc5d0\uc11c \ub2e4\uc591\ud55c \ud76c\uc18c \uc5b4\ud150\uc158 \ucee4\ub110\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95(FA3, CLEAR, NATTEN, Tiled NATTEN, Swin, STA)\uc5d0 \ub300\ud55c \uad6c\ud604 \ubc29\uc2dd, \uad6c\uc131, \ud76c\uc18c\uc131, TFLOPS, \uc9c0\uc5f0 \uc2dc\uac04(\ubc00\ub9ac\ucd08), MFU(Memory Footprint Utilization), \ucee4\ub110 \ud6a8\uc728\uc131, \uadf8\ub9ac\uace0 \uae30\uc900(FA3) \ub300\ube44 \uc18d\ub3c4 \ud5a5\uc0c1 \ubc30\uc218\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc2dc\ub41c \ub2e4\uc591\ud55c \ud76c\uc18c \uc5b4\ud150\uc158 \ubc29\ubc95\ub4e4\uc758 \ud6a8\uc728\uc131\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4. \ud2b9\ud788, STA(Sliding Tile Attention)\uac00 \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc5d0 \ube44\ud574 \ud6e8\uc52c \ub192\uc740 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ub2ec\uc131\ud588\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1 SLIDING TILE ATTENTION\uc758 \ud6a8\uc728\uc131"}, {"content": "| Model | Appearance | Style | Subject | Consistency | Background | Consistency | Temporal | Flickering | Motion | Smoothness | Dynamic | Degree | Aesthetic | Quality | Imaging | Quality | Overall | Consistency |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| FA3 | 18.43% | 94.22% | 96.74% | 99.21% | 99.15% | 75.00% | 64.63% | 67.97% | 25.96% |\n| *w.o training* |  |  |  |  |  |  |  |  |  |\n| CLEAR | 18.73% | 93.63% | 96.51% | 98.99% | 99.01% | 68.06% | 63.75% | 68.35% | 26.23% |\n| Tiled NATTEN | 18.79% | 94.59% | 96.61% | 98.75% | 98.85% | 70.83% | 63.79% | 68.16% | 26.53% |\n| Swin w=(48,64,64) | 20.85% | 91.74% | 95.48% | 98.67% | 97.77% | 77.78% | 51.01% | 62.22% | 25.27% |\n| Swin w=(30,40,40) | 20.62% | 90.33% | 93.09% | 98.78% | 96.53% | 75.00% | 48.10% | 61.89% | 25.62% |\n| STA w=(30,40,40) | 18.79% | 94.75% | 96.50% | 98.82% | 98.83% | 69.44% | 64.18% | 68.39% | 26.47% |\n| STA w=(18,24,24) | 21.25% | 89.66% | 91.64% | 98.46% | 97.27% | 83.33% | 59.75% | 64.23% | 26.61% |\n| *w. training* |  |  |  |  |  |  |  |  |  |\n| Swin w=(30,40,40) | 20.07% | 89.78% | 94.93% | 98.86% | 96.64% | 70.83% | 44.91% | 55.99% | 26.00% |\n| STA w=(30,24,40) | 18.90% | 94.90% | 97.60% | 99.68% | 99.23% | 73.61% | 63.77% | 66.21% | 26.58% |\n| STA w=(18,24,24) | 18.90% | 94.64% | 96.76% | 99.22% | 99.11% | 69.44% | 64.52% | 66.67% | 26.09% |", "caption": "Table 7: Model Performance Comparison - Part 1", "description": "\ud45c 7\uc740 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd1d 8\uac00\uc9c0 \uc9c0\ud45c(Appearance Style, Temporal Consistency, Motion Consistency, Dynamic, Aesthetic, Imaging Quality, Overall Quality, Consistency) \ub85c \ube44\ub514\uc624 \ud488\uc9c8\uc744 \ud3c9\uac00\ud558\uc5ec,  \uac01 \ubaa8\ub378(FA3, CLEAR, Tiled NATTEN, Swin Transformer (\ub450 \uac00\uc9c0 \uc124\uc815), STA (\ub450 \uac00\uc9c0 \uc124\uc815))\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \uc81c\uc2dc\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, STA \ubaa8\ub378\uc774 \ud6c8\ub828 \uc5c6\uc774\ub3c4 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc5d0 \ube44\ud574 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\uba70,  \ud6c8\ub828\uc744 \uac70\uce5c STA\ub294 \ub354\uc6b1 \ud5a5\uc0c1\ub41c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \uc885\ud569\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uc5ec \ubaa8\ub378 \uc120\ud0dd \ubc0f \uac1c\uc120 \ubc29\ud5a5\uc744 \uc81c\uc2dc\ud558\ub294\ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4.2 Human Evaluations"}, {"content": "| Model | Object Classification | Multiple Objects | Human Action | Color | Spatial Relationship | Scene | Scene Quality Score | Semantic Score | Final Score |\n|---|---|---|---|---|---|---|---|---|---| \n| FA3 | 85.76% | 70.12% | 90.00% | 88.66% | 71.28% | 35.25% | 85.34% | 72.17% | 82.71% |\n| *w.o training* |  |  |  |  |  |  |  |  |  |\n| CLEAR | 88.13% | 77.97% | 88.00% | 91.10% | 77.49% | 32.85% | 84.41% | 74.20% | 82.37% |\n| Tiled NATTEN | 83.54% | 72.18% | 94.00% | 92.28% | 81.21% | 37.94% | 84.61% | 75.00% | 82.69% |\n| Swin w=(48,64,64) | 78.16% | 58.54% | 87.00% | 93.68% | 77.45% | 37.79% | 80.91% | 71.35% | 79.00% |\n| Swin w=(30,40,40) | 79.19% | 60.44% | 88.00% | 93.68% | 77.24% | 35.54% | 78.84% | 72.28% | 77.53% |\n| STA w=(30,40,40) | 80.54% | 71.19% | 93.00% | 89.81% | 79.25% | 36.77% | 84.63% | 73.83% | 82.47% |\n| STA w=(18,24,24) | 88.13% | 75.46% | 91.00% | 91.61% | 82.52% | 42.15% | 81.47% | 77.03% | 80.58% |\n| *w. training* |  |  |  |  |  |  |  |  |  |\n| Swin w=(30,40,40) | 77.14% | 48.86% | 73.00% | 87.00% | 63.38% | 39.03% | 77.50% | 67.39% | 75.48% |\n| STA w=(30,24,40) | 91.77% | 68.45% | 86.00% | 89.59% | 72.76% | 39.53% | 85.37% | 73.52% | 83.00% |\n| STA w=(18,24,24) | 92.96% | 74.16% | 93.00% | 84.50% | 73.41% | 38.23% | 84.76% | 74.05% | 82.62% |", "caption": "Table 8: Model Performance Comparison - Part 2", "description": "\ud45c 8\uc740 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc758 2\ubd80\uc785\ub2c8\ub2e4.  \uc815\ud655\ud788\ub294, \ube44\ub514\uc624\uc758 \uc2dc\uac01\uc801 \ud488\uc9c8, \uc2dc\ub9e8\ud2f1 \uc77c\uad00\uc131, \uadf8\ub9ac\uace0 \ud2b9\uc9d5(\uac1d\uccb4, \uc778\ubb3c, \uc561\uc158, \uacf5\uac04\uc801 \uad00\uacc4, \uc0c9\uc0c1, \uc7a5\uba74 \ub4f1)\ubcc4\ub85c \uc138\ubd84\ud654\ud558\uc5ec \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud6c8\ub828 \uc804(training-free)\uacfc \ud6c8\ub828 \ud6c4(with training) \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\uc5ec, \ub2e4\uc591\ud55c \uc2a4\ud30c\uc2a4 \uc5b4\ud150\uc158 \uae30\ubc95(\uc608: STA, Swin, CLEAR)\ub4e4\uc758 \uc131\ub2a5\uc744 \uc0c1\ud638 \ube44\uad50\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ucc99\ub3c4\ubcc4 \uc810\uc218\ub97c \ud1b5\ud574 \uc5b4\ub5a4 \uae30\ubc95\uc774 \uc5b4\ub5a4 \uce21\uba74\uc5d0\uc11c \uac15\uc810\uc744 \ubcf4\uc774\ub294\uc9c0, \uadf8\ub9ac\uace0 \ud6c8\ub828\uc758 \ud6a8\uacfc\uac00 \uc5b4\ub5bb\uac8c \ub098\ud0c0\ub098\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}]