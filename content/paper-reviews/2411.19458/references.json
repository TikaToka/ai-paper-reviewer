{"references": [{"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2023-04-07", "reason": "This paper introduces DINOv2, a self-supervised vision transformer that serves as the foundation model for the proposed method and demonstrates superior performance in 3D correspondence understanding."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-01", "reason": "This paper introduces the DINO self-supervised learning approach which is highly relevant to the paper\u2019s method and helps achieve state-of-the-art results on various downstream tasks."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-06-01", "reason": "This paper introduces MAE (Masked Autoencoder), another important self-supervised vision model compared in the paper that achieves improved performance on downstream tasks."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP (Contrastive Language\u2013Image Pre-training), a vision model that demonstrates higher feature similarities between views from the same scene, useful for 3D reconstruction."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "DeiT III: Revenge of the ViT", "publication_date": "2022-10-01", "reason": "This paper introduces DeiT III (Vision Transformer), a vision transformer architecture that is evaluated and compared with other models for 3D correspondence understanding."}]}