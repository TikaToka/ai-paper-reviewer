[{"content": "| Environment | Action | Definition |\n|---|---|---|\n| **Shared** | Click(x, y) | Clicks at coordinates (x, y). |\n|  | Drag(x1, y1, x2, y2) | Drags from (x1, y1) to (x2, y2). |\n|  | Scroll(x, y, direction) | Scrolls at (x, y) in the given direction. |\n|  | Type(content) | Types the specified content. |\n|  | Wait() | Pauses for a brief moment. |\n|  | Finished() | Marks the task as complete. |\n|  | CallUser() | Requests user intervention. |\n| **Desktop** | Hotkey(key) | Presses the specified hotkey. |\n|  | LeftDouble(x, y) | Double-clicks at (x, y). |\n|  | RightSingle(x, y) | Right-clicks at (x, y). |\n| **Mobile** | LongPress(x, y) | Long presses at (x, y). |\n|  | PressBack() | Presses the \u201cback\u201d button. |\n|  | PressHome() | Presses the \u201chome\u201d button. |\n|  | PressEnter() | Presses the \u201center\u201d key. |", "caption": "Table 3: Results on GUI Perception benchmarks.", "description": "\ud45c 3\uc740 \ub17c\ubb38\uc5d0\uc11c \ub2e4\ub8e8\ub294 GUI \uc9c0\uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VisualWebBench, WebSRC, ScreenQA-short \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c UI-TARS \ubaa8\ub378(UI-TARS-2B, UI-TARS-7B, UI-TARS-72B)\uacfc \uae30\ud0c0 \ubaa8\ub378(Qwen2-VL-7B, Qwen-VL-Max, Gemini-1.5-Pro, UIX-Qwen2-7B, Claude-3.5-Sonnet, GPT-40)\uc758 \uc131\ub2a5\uc744 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubca4\uce58\ub9c8\ud06c\ub294 GUI \uc774\ud574 \ub2a5\ub825\uc758 \ub2e4\ub978 \uce21\uba74\uc744 \ud3c9\uac00\ud558\uba70, UI-TARS \ubaa8\ub378\uc740 \ubaa8\ub4e0 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.1 \uc9c0\uac01 \ub2a5\ub825 \ud3c9\uac00"}, {"content": "| Data Type | Grounding | Grounding | MultiStep | MultiStep |\n|---|---|---|---|---|\n|  | Ele. | Ele./Image | Trace | avg steps |\n| **Open Source** | **Web** | 14.8M | 6.7 | 6.4k | 7.1 |\n|  | **Mobile** | 2.5M | 4.6 | 145k | 9.6 |\n|  | **Desktop** | 1.1M | 6.2 | 0 | 0 |\n| **Ours** |  | * | 7.5 | * | 14.9 |", "caption": "Table 4: Comparison of various models on ScreenSpot-Pro.", "description": "\ud45c 4\ub294 ScreenSpot-Pro \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. ScreenSpot-Pro\ub294 \uace0\ud574\uc0c1\ub3c4\uc758 \uc804\ubb38\uc801\uc778 \ub370\uc2a4\ud06c\ud0d1 \ud658\uacbd\uc5d0\uc11c \uc218\uc9d1\ub41c \uc2e4\uc81c \uc791\uc5c5\uc744 \uae30\ubc18\uc73c\ub85c \ud558\ub294 \ubca4\uce58\ub9c8\ud06c\ub85c, \ubaa8\ub378\uc758 GUI \uc774\ud574 \ub2a5\ub825\uc744 \uc5c4\uaca9\ud558\uac8c \ud3c9\uac00\ud569\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uc9c0\ud45c\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, UI-TARS \ubaa8\ub378\uc774 \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\ubcf4\ub2e4 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.2 Grounding Capability Evaluation"}, {"content": "| Model | VisualWebBench | WebSRC | ScreenQA-short |\n|---|---|---|---|\n| Qwen2-VL-7B [2024c] | 73.3 | 81.8 | 84.9 |\n| Qwen-VL-Max [2023b] | 74.1 | 91.1 | 78.6 |\n| Gemini-1.5-Pro [2024] | 75.4 | 88.9 | 82.2 |\n| UIX-Qwen2-7B [2024d] | 75.9 | 82.9 | 78.8 |\n| Claude-3.5-Sonnet [2024a] | 78.2 | 90.4 | 83.1 |\n| GPT-4o [2024] | 78.5 | 87.7 | 82.3 |\n| **UI-TARS-2B** | 72.9 | 89.2 | 86.4 |\n| **UI-TARS-7B** | 79.7 | **93.6** | 87.7 |\n| **UI-TARS-72B** | **82.8** | 89.3 | **88.6** |", "caption": "Table 5: Comparison of various planners and grounding methods on ScreenSpot.", "description": "\ud45c 5\ub294 ScreenSpot \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \uacc4\ud68d \uc0dd\uc131\uae30\uc640 \uadf8\ub77c\uc6b4\ub529 \uae30\ubc95\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ScreenSpot\uc740 \ub2e4\uc591\ud55c \ud50c\ub7ab\ud3fc(\ubaa8\ubc14\uc77c, \ub370\uc2a4\ud06c\ud0d1, \uc6f9)\uc5d0\uc11c GUI \uc694\uc18c\ub4e4\uc758 \uc704\uce58\ub97c \uc815\ud655\ud558\uac8c \ud30c\uc545\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\uc11c\ub294 \uac01 \uacc4\ud68d \uc0dd\uc131\uae30\uc640 \uadf8\ub77c\uc6b4\ub529 \ubc29\ubc95\uc5d0 \ub530\ub77c \ubaa8\ubc14\uc77c, \ub370\uc2a4\ud06c\ud0d1, \uc6f9 \ud658\uacbd\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744  \ud14d\uc2a4\ud2b8, \uc544\uc774\ucf58/\uc704\uc82f \uae30\uc900\uc73c\ub85c \ub098\ub204\uc5b4 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud3c9\uade0\uac12\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uc5ec\ub7ec\uac00\uc9c0 \uc811\uadfc\ubc95\ub4e4\uc758 \uc0c1\ub300\uc801\uc778 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ube44\uad50\ud558\uc5ec GUI \uc5d0\uc774\uc804\ud2b8 \uac1c\ubc1c\uc5d0 \uc788\uc5b4 \uc5b4\ub5a4 \ubc29\ubc95\uc774 \ub354 \ud6a8\uacfc\uc801\uc778\uc9c0 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5.3 \uc624\ud504\ub77c\uc778 \uc5d0\uc774\uc804\ud2b8 \uc131\ub2a5 \ud3c9\uac00"}, {"content": "Agent Model|Development|Development|Development|Creative|Creative|Creative|CAD|CAD|CAD|Scientific|Scientific|Scientific|Office|Office|Office|OS|OS|OS|Avg\n---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---\nQwenVL-7B (Bai et al., 2023b)|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.7|0.0|0.4|0.0|0.0|0.0|0.1|0.1\nGPT-4o (Hurst et al., 2024)|1.3|0.0|0.7|1.0|0.0|0.6|2.0|0.0|1.5|2.1|0.0|1.2|1.1|0.0|0.9|0.8\nSeeClick (Cheng et al., 2024)|0.6|0.0|0.3|1.0|0.0|0.6|2.5|0.0|1.9|3.5|0.0|2.0|1.1|0.0|0.9|1.1\nQwen2-VL-7B (Wang et al., 2024c)|2.6|0.0|1.3|1.5|0.0|0.9|0.5|0.0|0.4|6.3|0.0|3.5|3.4|1.9|3.0|1.6\nOS-Atlas-4B (Wu et al., 2024b)|7.1|0.0|3.7|3.0|1.4|2.3|2.0|0.0|1.5|9.0|5.5|7.5|5.1|3.8|4.8|3.7\nShowUI-2B (Lin et al., 2024b)|16.9|1.4|9.4|9.1|0.0|5.3|2.5|0.0|1.9|13.2|7.3|10.6|15.3|7.5|13.5|7.7\nCogAgent-18B (Hong et al., 2024)|14.9|0.7|8.0|9.6|0.0|5.6|7.1|3.1|6.1|22.2|1.8|13.4|13.0|0.0|10.0|7.7\nAria-UI (Yang et al., 2024a)|16.2|0.0|8.4|23.7|2.1|14.7|7.6|1.6|6.1|27.1|6.4|18.1|20.3|1.9|16.1|11.3\nUGround-7B (Gou et al., 2024a)|26.6|2.1|14.7|27.3|2.8|17.0|14.2|1.6|11.1|31.9|2.7|19.3|31.6|11.3|27.0|16.5\nClaude Computer Use (Anthropic, 2024b)|22.0|3.9|12.6|25.9|3.4|16.8|14.5|3.7|11.9|33.9|15.8|25.8|30.1|16.3|26.9|17.1\nOS-Atlas-7B (Wu et al., 2024b)|33.1|1.4|17.7|28.8|2.8|17.9|12.2|4.7|10.3|37.5|7.3|24.4|33.9|5.7|27.4|18.9\nUGround-V1-7B (Gou et al., 2024a)|-| -|-|35.5|-|-|27.8|-|13.5|-|-|38.8|-|-|26.1|-|-|31.1\nUI-TARS-2B|47.4|4.1|26.4|42.9|6.3|27.6|17.8|4.7|14.6|56.9|17.3|39.8|50.3|17.0|42.6|27.7\nUI-TARS-7B|58.4|12.4|36.1|50.0|9.1|32.8|20.8|9.4|18.0|63.9|31.8|50.0|63.3|20.8|53.5|35.7\nUI-TARS-72B|63.0|17.3|40.8|57.1|15.4|39.6|18.8|12.5|17.2|64.6|20.9|45.7|63.3|26.4|54.8|38.1", "caption": "Table 6: Comparison of various planners and grounding methods on ScreenSpot-V2.", "description": "\ud45c 6\uc740 ScreenSpot-V2 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \uacc4\ud68d \ubc0f \uc811\uc9c0 \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ScreenSpot-V2\ub294 \ub2e4\uc591\ud55c \ud574\uc0c1\ub3c4\uc758 \uc804\ubb38\uc801\uc778 \ub370\uc2a4\ud06c\ud0d1 \ud658\uacbd\uc5d0\uc11c \uc218\uc9d1\ub41c \uc2e4\uc81c \uc791\uc5c5\uc744 \uae30\ubc18\uc73c\ub85c \ud569\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ubaa8\ubc14\uc77c, \ub370\uc2a4\ud06c\ud0d1, \uc6f9 \ud658\uacbd\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uac01 \ubc29\ubc95\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud3c9\uade0 \uc815\ud655\ub3c4\uc640 \uc131\uacf5\ub960\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \uacc4\ud68d \ubc0f \uc811\uc9c0 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uace0, ScreenSpot-V2\uc640 \uac19\uc740 \uc2e4\uc81c \ud658\uacbd\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \uc815\ud655\ud558\uac8c \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.2 \uae30\ub2a5 \ud3c9\uac00"}, {"content": "---|---|---|---|---|---|---|---|---\n**Method**||**Mobile**| |**Desktop**| |**Web**| |**Avg**|\n| | |**Text**|**Icon/Widget**|**Text**|**Icon/Widget**|**Text**|**Icon/Widget**| |\n**Agent Framework**| | | | | | | | |\nGPT-4 (OpenAI, 2023b) | SeeClick (Cheng et al., 2024) | 76.6 | 55.5 | 68.0 | 28.6 | 40.9 | 23.3 | 48.8\nOmniParser (Lu et al., 2024b) | 93.9 | 57.0 | 91.3 | 63.6 | 81.3 | 51.0 | 73.0\nUGround-7B (Gou et al., 2024a) | 90.1 | 70.3 | 87.1 | 55.7 | 85.7 | 64.6 | 75.6\nGPT-4o (Hurst et al., 2024) | SeeClick (Cheng et al., 2024) | 81.0 | 59.8 | 69.6 | 33.6 | 43.9 | 26.2 | 52.3\nUGround-7B (Gou et al., 2024a) | 93.4 | 76.9 | 92.8 | 67.9 | 88.7 | 68.9 | 81.4\n**Agent Model**| | | | | | | | |\nGPT-4 (OpenAI, 2023b) | 22.6 | 24.5 | 20.2 | 11.8 | 9.2 | 8.8 | 16.2\nGPT-4o (Hurst et al., 2024) | 20.2 | 24.9 | 21.1 | 23.6 | 12.2 | 7.8 | 18.3\nCogAgent (Hong et al., 2024) | 67.0 | 24.0 | 74.2 | 20.0 | 70.4 | 28.6 | 47.4\nCogAgent-9B-20241220 (Hong et al., 2024) | - | - | - | - | - | - | 85.4\nSeeClick (Cheng et al., 2024) | 78.0 | 52.0 | 72.2 | 30.0 | 55.7 | 32.5 | 53.4\nQwen2-VL (Wang et al., 2024c) | 75.5 | 60.7 | 76.3 | 54.3 | 35.2 | 25.7 | 55.3\nUGround-7B (Gou et al., 2024a) | 82.8 | 60.3 | 82.5 | 63.6 | 80.4 | 70.4 | 73.3\nAguvis-G-7B (Xu et al., 2024) | 88.3 | 78.2 | 88.1 | 70.7 | 85.7 | 74.8 | 81.8\nOS-Atlas-7B (Wu et al., 2024b) | 93.0 | 72.9 | 91.8 | 62.9 | 90.9 | 74.3 | 82.5\nClaude Computer Use (Anthropic, 2024b) | - | - | - | - | - | - | 83.0\nGemini 2.0 (Project Mariner) (GoogleDeepmind, 2024) | - | - | - | - | - | - | 84.0\nAguvis-7B (Xu et al., 2024) | **95.6** | 77.7 | 93.8 | 67.1 | 88.3 | 75.2 | 84.4\nAguvis-72B (Xu et al., 2024) | 94.5 | **85.2** | 95.4 | 77.9 | **91.3** | **85.9** | 89.2\nUI-TARS-2B | 93.0 | 75.5 | 90.7 | 68.6 | 84.3 | 74.8 | 82.3\nUI-TARS-7B | 94.5 | **85.2** | **95.9** | 85.7 | 90.0 | 83.5 | **89.5**\nUI-TARS-72B | 94.9 | 82.5 | 89.7 | **88.6** | 88.7 | 85.0 | 88.4", "caption": "Table 7: Performance comparison on Multimodal Mind2Web across different settings. We report element accuracy (Ele.Acc), operation F1 (Op.F1), and step success rate (Step SR).", "description": "\ud45c 7\uc740 \ub2e4\uc591\ud55c \uc124\uc815\uc5d0\uc11c Multimodal Mind2Web\uc5d0 \ub300\ud55c \uc5ec\ub7ec \uc5d0\uc774\uc804\ud2b8 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc694\uc18c \uc815\ud655\ub3c4(Ele.Acc), \uc5f0\uc0b0 F1 \uc810\uc218(Op.F1), \ub2e8\uacc4 \uc131\uacf5\ub960(Step SR) \uc138 \uac00\uc9c0 \uc9c0\ud45c\ub97c \ubcf4\uace0\ud558\uc5ec \ubaa8\ub378\uc758 \uc6f9 \uae30\ubc18 \ud658\uacbd\uc5d0\uc11c\uc758 \uc791\uc5c5 \uc218\ud589 \ub2a5\ub825\uc744 \uc885\ud569\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4.  \ub2e8\uacc4 \uc131\uacf5\ub960\uc740 \ubaa8\ub378\uc774 \uc791\uc5c5\uc758 \uac01 \ub2e8\uacc4\ub97c \uc131\uacf5\uc801\uc73c\ub85c \uc644\ub8cc\ud588\ub294\uc9c0 \uc5ec\ubd80\ub97c \ub098\ud0c0\ub0b4\ub294 \ubc18\uba74, \uc694\uc18c \uc815\ud655\ub3c4\uc640 \uc5f0\uc0b0 F1 \uc810\uc218\ub294 \ubaa8\ub378\uc774 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub294 \ub370 \ud544\uc694\ud55c \uc694\uc18c\ub4e4\uc744 \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc778\uc2dd\ud558\uace0 \uc870\uc791\ud558\ub294\uc9c0 \uce21\uc815\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc0c1\ub300\uc801 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5 \uc2e4\ud5d8"}, {"content": "| Method |  | Mobile |  | Desktop |  | Web |  | Avg | \n|---|---|---|---|---|---|---|---|---|\n| **Agent Framework** |  |  |  |  |  |  |  |  | \n| GPT-4o (Hurst et al., 2024) | SeeClick (Cheng et al., 2024) | 85.2 | 58.8 | 79.9 | 37.1 | 72.7 | 30.1 | 63.6 | \n| OS-Atlas-4B (Wu et al., 2024b) | 95.5 | 75.8 | 79.4 | 49.3 | 90.2 | 66.5 | 79.1 | \n| OS-Atlas-7B (Wu et al., 2024b) | 96.2 | 83.4 | 89.7 | 69.3 | 94.0 | 79.8 | 87.1 | \n| **Agent Model** |  |  |  |  |  |  |  |  | \n| SeeClick (Cheng et al., 2024) | 78.4 | 50.7 | 70.1 | 29.3 | 55.2 | 32.5 | 55.1 | \n| OS-Atlas-4B (Wu et al., 2024b) | 87.2 | 59.7 | 72.7 | 46.4 | 85.9 | 63.1 | 71.9 | \n| OS-Atlas-7B (Wu et al., 2024b) | 95.2 | 75.8 | 90.7 | 63.6 | 90.6 | 77.3 | 84.1 | \n| UI-TARS-2B | 95.2 | 79.1 | 90.7 | 68.6 | 87.2 | 78.3 | 84.7 | \n| UI-TARS-7B | **96.9** | **89.1** | **95.4** | 85.0 | 93.6 | 85.2 | **91.6** | \n| UI-TARS-72B | 94.8 | 86.3 | 91.2 | **87.9** | 91.5 | **87.7** | 90.3 | ", "caption": "Table 8: Results on mobile tasks (AndroidControl and GUI Odyssey). For AndroidControl, we report two settings (Low and High).", "description": "\ud45c 8\uc740 \ubaa8\ubc14\uc77c \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. AndroidControl\uc758 \uacbd\uc6b0 \ub09c\uc774\ub3c4\uac00 \ub0ae\uc740(Low) \uc124\uc815\uacfc \ub192\uc740(High) \uc124\uc815\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubaa8\ub450 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  AndroidControl\uc740 \ubaa8\ubc14\uc77c \ud658\uacbd\uc5d0\uc11c \ub2e4\uc591\ud55c \uc218\uc900\uc758 \ubcf5\uc7a1\uc131\uc744 \uac00\uc9c4 \uc5ec\ub7ec \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\uace0, GUI Odyssey\ub294 \uc5ec\ub7ec \uc571\uc744 \uac70\uce58\ub294 \ubcf5\uc7a1\ud55c \ud0d0\uc0c9 \uc791\uc5c5\uc744 \uc911\uc810\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4. \uac01 \uc791\uc5c5 \uc720\ud615\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\uc640 \uc131\uacf5\ub960\uc744 \ube44\uad50\ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "5 \uc2e4\ud5d8"}, {"content": "Method | Cross-Task |  |  | Cross-Website |  |  | Cross-Domain |  |  |  \n---|---|---|---|---|---|---|---|---|---|---\n| Ele.Acc | Op.F1 | Step SR | Ele.Acc | Op.F1 | Step SR | Ele.Acc | Op.F1 | Step SR |  |  \n| **Agent Framework** |  |  |  |  |  |  |  |  |  |  \n| GPT-4o [2024] | SeeClick [2024] | 32.1 | - | - | 33.1 | - | - | 33.5 | - | - \n| GPT-4o [2024] | UGround [2024a] | 47.7 | - | - | 46.0 | - | - | 46.6 | - | - \n| GPT-4o [2024] | Aria-UI [2024a] | 57.6 | - | - | 57.7 | - | - | 61.4 | - | - \n| GPT-4V [2023a] | OmniParser [2024b] | 42.4 | 87.6 | 39.4 | 41.0 | 84.8 | 36.5 | 45.5 | 85.7 | 42.0 \n| **Agent Model** |  |  |  |  |  |  |  |  |  |  \n| GPT-4o [2024] |  | 5.7 | 77.2 | 4.3 | 5.7 | 79.0 | 3.9 | 5.5 | 86.4 | 4.5 \n| GPT-4(SOM) [2023] |  | 29.6 | - | 20.3 | 20.1 | - | 13.9 | 27.0 | - | 23.7 \n| GPT-3.5(Text-only) [2022] |  | 19.4 | 59.2 | 16.8 | 14.9 | 56.5 | 14.1 | 25.2 | 57.9 | 24.1 \n| GPT-4(Text-only) [2023] |  | 40.8 | 63.1 | 32.3 | 30.2 | 61.0 | 27.0 | 35.4 | 61.9 | 29.7 \n| Claude [2024b] |  | 62.7 | 84.7 | 53.5 | 59.5 | 79.6 | 47.7 | 64.5 | 85.4 | 56.4 \n| Aguvis-7B [2024] |  | 64.2 | 89.8 | 60.4 | 60.7 | 88.1 | 54.6 | 60.4 | 89.2 | 56.6 \n| CogAgent [2024] |  | - | - | - | - | 62.3 | - | - | 54 | - | 59.4 \n| Aguvis-72B [2024] |  | 69.5 | 90.8 | 64.0 | 62.6 | 88.6 | 56.5 | 63.5 | 88.5 | 58.2 \n| UI-TARS-2B |  | 62.3 | 90.0 | 56.3 | 58.5 | 87.2 | 50.8 | 58.8 | 89.6 | 52.3 \n| UI-TARS-7B |  | 73.1 | 92.2 | 67.1 | 68.2 | 90.9 | 61.7 | 66.6 | 90.9 | 60.5 \n| UI-TARS-72B |  | **74.7** | **92.5** | **68.6** | **72.4** | **91.2** | **63.5** | **68.9** | **91.8** | **62.1**", "caption": "Table 9: Results on online benchmarks. We evaluate performance under the screenshot-only setting on OSWorld, limiting the maximum number of steps to 15.", "description": "\ud45c 9\ub294 \uc628\ub77c\uc778 \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OSWorld\uc5d0 \ub300\ud55c \uc2a4\ud06c\ub9b0\uc0f7 \uc804\uc6a9 \uc124\uc815\uc5d0\uc11c \ud3c9\uac00\ub97c \uc218\ud589\ud588\uc73c\uba70, \ucd5c\ub300 \ub2e8\uacc4 \uc218\ub97c 15\ub2e8\uacc4\ub85c \uc81c\ud55c\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \uc5d0\uc774\uc804\ud2b8 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \ud2b9\ud788, \uc2dc\uc2a4\ud15c 1(\uc0ac\uace0 \uc5c6\uc74c)\uacfc \uc2dc\uc2a4\ud15c 2(\uc0ac\uace0 \ud3ec\ud568) \ucd94\ub860\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uc5ec \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\uace0, \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c \ud658\uacbd\uc5d0\uc11c\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc740 OSWorld \ubc0f AndroidWorld \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc131\ub2a5\uc744 \ud3c9\uac00\ubc1b\uc558\uc73c\uba70, \ub2e8\uacc4 \uc131\uacf5\ub960\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc9c0\ud45c\uac00 \uc0ac\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "5 \uc2e4\ud5d8"}]