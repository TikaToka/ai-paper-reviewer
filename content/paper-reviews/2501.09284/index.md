---
title: "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation"
summary: "SEAL: LoRA ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ í˜ì‹ ì ì¸ ì›Œí„°ë§ˆí‚¹ ê¸°ë²•"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Machine Learning", "Deep Learning", "ğŸ¢ Department of Artificial Intelligence, Yonsei University",]
showSummary: true
date: 2025-01-16
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2501.09284 {{< /keyword >}}
{{< keyword icon="writer" >}} Giyeong Oh et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-01-21 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2501.09284" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2501.09284" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/seal-entangled-white-box-watermarks-on-low" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ìµœê·¼ **ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì˜ íŠ¹ì • ì‘ì—… ë²„ì „ì„ íš¨ìœ¨ì ìœ¼ë¡œ í›ˆë ¨ ë° ê³µìœ **í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ **LoRA(Low-Rank Adaptation)**ê°€ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ **LoRA ê°€ì¤‘ì¹˜ì˜ ì €ì‘ê¶Œ ë³´í˜¸** ë¬¸ì œëŠ” ì—¬ì „íˆ ë¯¸í•´ê²° ê³¼ì œë¡œ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì›Œí„°ë§ˆí‚¹ ê¸°ë°˜ ê¸°ë²•ì„ í†µí•œ LoRA ê°€ì¤‘ì¹˜ì˜ ì €ì‘ê¶Œ ë³´í˜¸ëŠ” ì¶©ë¶„íˆ ì—°êµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **LoRA ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ë³´ì•ˆ ì›Œí„°ë§ˆí‚¹ ê¸°ë²•ì¸ SEAL(SEcure wAtermarking on LoRA weights)**ì„ ì œì•ˆí•©ë‹ˆë‹¤. SEALì€ **í›ˆë ¨ ê³¼ì •ì—ì„œ í›ˆë ¨ ë¶ˆê°€ëŠ¥í•œ ë¹„ë°€ í–‰ë ¬(passport)ì„ í›ˆë ¨ ê°€ëŠ¥í•œ LoRA ê°€ì¤‘ì¹˜ ì‚¬ì´ì— ì‚½ì…**í•˜ì—¬ ì €ì‘ê¶Œì„ ì£¼ì¥í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  **passportëŠ” LoRA ê°€ì¤‘ì¹˜ì™€ ì–½íˆê²Œ ë˜ë©°**, ì¶”ê°€ì ì¸ ì†ì‹¤ ì—†ì´ë„ **í›ˆë ¨ í›„ passportë¥¼ ìˆ¨ê¸´ ë¯¸ì„¸ ì¡°ì •ëœ ê°€ì¤‘ì¹˜ë¥¼ ë°°í¬**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SEALì€ **commonsense reasoning, textual/visual instruction tuning, text-to-image synthesis ì‘ì—…ì—ì„œ ì„±ëŠ¥ ì €í•˜ ì—†ì´** ê²¬ê³ í•˜ê²Œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LoRA ëª¨ë¸ì˜ ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì›Œí„°ë§ˆí‚¹ ê¸°ë²• SEAL ì œì‹œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ê¸°ì¡´ LoRAì˜ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ì €ì‘ê¶Œ ë³´í˜¸ ê°€ëŠ¥ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ì œê±°, í˜¼ë€, ëª¨í˜¸ì„± ê³µê²©ì— ëŒ€í•œ ê°•ë ¥í•œ ê²¬ê³ ì„± {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **LoRA(Low-Rank Adaptation)**ì˜ ì €ì‘ê¶Œ ë³´í˜¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì¸ **SEAL(SEcure wAtermarking on LoRA weights)**ì„ ì œì‹œí•˜ì—¬, ì—°êµ¬ìë“¤ì´ íš¨ìœ¨ì ìœ¼ë¡œ **ëª¨ë¸ì˜ ì§€ì  ì¬ì‚°ê¶Œì„ ë³´í˜¸**í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.  **LoRAì˜ ê²½ëŸ‰ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€**í•˜ë©´ì„œ **ì €ì‘ê¶Œ ì¹¨í•´ì— ëŒ€í•œ ê°•ë ¥í•œ ë°©ì–´**ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨, **AI ëª¨ë¸ ê³µìœ  ë° ìƒìš©í™”**ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ë‹¤ì–‘í•œ ê³µê²© ìœ í˜•ì— ëŒ€í•œ ê²¬ê³ ì„±ì„ ê²€ì¦**í•˜ì—¬ ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìœ¼ë©°, **í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œ**í•˜ì—¬ LoRAì˜ ë³´ì•ˆ ë° ì €ì‘ê¶Œ ë³´í˜¸ ê¸°ìˆ  ë°œì „ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2501.09284/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” LoRA ì €ì‘ê¶Œ ë³´í˜¸ ê¸°ë²•ì¸ SEALì˜ ê°œë…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë¨¼ì € LoRA ê°€ì¤‘ì¹˜ Aì™€ B, ê·¸ë¦¬ê³  ë¹„í›ˆë ¨ ê°€ëŠ¥í•œ ì›Œí„°ë§ˆí¬(Passport)ì¸ Cì™€ Cpë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.  í›ˆë ¨ ì¤‘ì—, ì›Œí„°ë§ˆí¬ Cì™€ CpëŠ” Bì™€ A ì‚¬ì´ì— ì‚½ì…ë˜ì–´ ëª¨ë¸ì´ ì´ë“¤ì„ ì˜ì¡´í•˜ë„ë¡ ë§Œë“¤ê³ , ê²°ê³¼ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ì™€ ì›Œí„°ë§ˆí¬ë¥¼ ì„œë¡œ ì–½ì–´ë§¤ê²Œ ë©ë‹ˆë‹¤.  í›ˆë ¨ í›„ì—ëŠ” ì›Œí„°ë§ˆí¬ Cê°€ f(C) = (C1, C2) í•¨ìˆ˜ë¥¼ í†µí•´ ë¶„í•´ë˜ì–´ Bì™€ Aì— í†µí•©ë˜ì–´ ì¼ë°˜ì ì¸ LoRA ê°€ì¤‘ì¹˜ B'ì™€ A'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  í•œí¸, ì†Œìœ ê¶Œ í™•ì¸ì„ ìœ„í•´ CpëŠ” ê°œì¸ì ìœ¼ë¡œ ë³´ê´€ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Overview of SEAL. (1) We begin with LoRAâ€™s weights Ağ´{A}italic_A and Bğµ{B}italic_B, plus non-trainable passports C,Cpğ¶subscriptğ¶ğ‘{C},{C}_{p}italic_C , italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT. (2) During training, Cğ¶{C}italic_C and Cpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT are inserted between Bğµ{B}italic_B and Ağ´{A}italic_A, forcing the model to rely on them and thus entangling the weights with the passports. (3) Afterward, Cğ¶{C}italic_C is factorized via fâ¢(C)=(C1,C2)ğ‘“ğ¶subscriptğ¶1subscriptğ¶2f({C})=({C}_{1},{C}_{2})italic_f ( italic_C ) = ( italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) and merged into Bğµ{B}italic_B and Ağ´{A}italic_A, resulting in standard-looking LoRA weights Bâ€²superscriptğµâ€²{B}^{\prime}italic_B start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT and Aâ€²superscriptğ´â€²{A}^{\prime}italic_A start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT. Meanwhile, Cpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT remains private for ownership verification.
> </details>





{{< table-caption >}}
| Method | BoolQ | PIQA | SIQA | HellaSwag | Wino. | ARC-e | ARC-c | OBQA | Avg. â†‘ |
|---|---|---|---|---|---|---|---|---|---| 
| LLaMA-2-7B | LoRA | 73.75 | 82.99 | 79.85 | 86.14 | 85.06 | 86.15 | 73.63 | 81.67 Â± 1.03 |
|  | SEAL (Ours) | 72.70 | 85.27 | 81.27 | 90.15 | 85.79 | 87.07 | 74.60 | 82.73 Â± 0.14 |
|  | SEALâ€  (Ours) | 73.19 | 86.31 | 81.95 | 91.21 | 86.69 | 88.55 | 75.51 | **83.78** Â± 0.27 |
| LLaMA-2-13B | LoRA | 75.57 | 86.98 | 81.39 | 91.82 | 88.53 | 90.08 | 78.78 | 84.98 Â± 0.17 |
|  | SEAL (Ours) | 75.34 | 87.41 | 83.28 | 93.33 | 88.42 | 90.68 | 79.61 | 85.60 Â± 0.34 |
|  | SEALâ€  (Ours) | 75.67 | 88.63 | 83.21 | 93.95 | 89.29 | 91.72 | 81.46 | **86.56** Â± 0.10 |
| LLaMA-3-8B | LoRA | 74.76 | 88.22 | 80.96 | 92.00 | 86.08 | 90.09 | 82.41 | 85.10 Â± 1.39 |
|  | SEAL (Ours) | 73.88 | 88.23 | 82.29 | 94.84 | 88.35 | 91.67 | 82.00 | 85.94 Â± 0.29 |
|  | SEALâ€  (Ours) | 75.78 | 90.37 | 83.25 | 96.05 | 89.92 | 93.49 | 84.73 | **88.02** Â± 0.11 |
| Gemma-2B | LoRA | 67.05 | 83.19 | 77.26 | 87.07 | 79.74 | 83.91 | 69.34 | 78.43 Â± 0.32 |
|  | SEAL (Ours) | 66.56 | 81.79 | 77.65 | 84.82 | 79.16 | 82.79 | 68.40 | 77.55 Â± 0.04 |
|  | SEALâ€  (Ours) | 66.70 | 82.50 | 78.88 | 87.57 | 80.19 | 83.81 | 69.97 | **78.68** Â± 0.11 |
| Mistral-7B-v0.1 | LoRA | 75.92 | 90.72 | 81.78 | 94.68 | 88.69 | 93.10 | 83.36 | 87.07 Â± 0.27 |
|  | SEAL (Ours) | 73.08 | 87.52 | 81.92 | 91.23 | 87.97 | 90.19 | 78.70 | 84.84 Â± 0.44 |
|  | SEALâ€  (Ours) | 76.92 | 90.42 | 82.51 | 94.57 | 90.08 | 93.31 | 83.25 | **87.85** Â± 0.02 |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ì„¸ ê°€ì§€ ìƒì‹ ì¶”ë¡  ì‘ì—…(BoolQ, PIQA, SIQA, HellaSwag, Winograd Schema Challenge, ARC-e, ARC-c, OBQA)ì— ëŒ€í•œ ì„¸ ê°€ì§€ ëª¨ë¸(LLaMA-2-7B, LLaMA-2-13B, LLaMA-3-8B)ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì‘ì—…ì— ëŒ€í•´ LoRAì™€ SEALì˜ í‰ê·  ì •í™•ë„ë¥¼ ì„¸ ë²ˆì˜ ë…ë¦½ì ì¸ ì‹¤í–‰ìœ¼ë¡œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ëª¨ë¸ê³¼ ë°©ë²•ì— ëŒ€í•œ í‰ê·  ì ìˆ˜ì™€ í‘œì¤€ í¸ì°¨ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. SEALâ€ ëŠ” ì •ê·œ ë¶„í¬ì—ì„œ ìƒì„±ëœ ìƒìˆ˜ í–‰ë ¬ Cë¥¼ ì‚¬ìš©í•˜ëŠ” SEAL ë³€í˜•ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Commonsense Reasoning Performance (3-run Avg.). Scores are averaged over three random seeds, with standard deviation shown in a smaller font for the last column. SEALâ€  denotes using a constant matrix Cğ¶Citalic_C from normal distribution.
> </details>





### In-depth insights


#### LoRA Watermarking
LoRA(Low-Rank Adaptation)ëŠ” ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, ìµœê·¼ ê¸‰ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.  **LoRA ì›Œí„°ë§ˆí‚¹**ì€ ì´ëŸ¬í•œ LoRAì˜ íš¨ìœ¨ì„±ê³¼ ê°„í¸ì„±ì„ í™œìš©í•˜ì—¬ ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ê°•í™”í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì›Œí„°ë§ˆí‚¹ ê¸°ë²•ë“¤ì€ ëª¨ë¸ì˜ êµ¬ì¡°ì— ì¢…ì†ì ì¸ ë°˜ë©´, **LoRA ì›Œí„°ë§ˆí‚¹ì€ ëª¨ë¸ì˜ êµ¬ì¡°ì— êµ¬ì• ë°›ì§€ ì•Šê³  ì›Œí„°ë§ˆí¬ë¥¼ ì‚½ì…í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì **ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ëª¨ë¸ì— ì ìš© ê°€ëŠ¥í•˜ë©°, íŠ¹íˆ LoRA ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í™˜ê²½ì—ì„œ ì €ì‘ê¶Œ ë³´í˜¸ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **í•µì‹¬ì€ í›ˆë ¨ ê³¼ì •ì—ì„œ LoRA ê°€ì¤‘ì¹˜ ì‚¬ì´ì— ë¹„í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤íŠ¸ë¦­ìŠ¤(íŒ¨ìŠ¤í¬íŠ¸)ë¥¼ ì‚½ì…í•˜ì—¬ ê°€ì¤‘ì¹˜ì™€ íŒ¨ìŠ¤í¬íŠ¸ë¥¼ ì–½íˆê²Œ í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.  ì´ë ‡ê²Œ ìƒì„±ëœ ë¯¸ì„¸ ì¡°ì •ëœ ê°€ì¤‘ì¹˜ëŠ” ì¼ë°˜ì ì¸ LoRA ê°€ì¤‘ì¹˜ì™€ êµ¬ë³„ë˜ì§€ ì•Šì§€ë§Œ,  **íŒ¨ìŠ¤í¬íŠ¸ëŠ” ì €ì‘ê¶Œ í™•ì¸ì„ ìœ„í•œ ë¹„ë°€í‚¤**ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ê³µê²©(ì œê±°, ë‚œë…í™”, ëª¨í˜¸í™”)ì— ëŒ€í•œ ê°•ë ¥í•œ ì €í•­ì„±**ì„ ë³´ì´ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì„±ëŠ¥ ì €í•˜ ì—†ì´ ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì´ LoRA ì›Œí„°ë§ˆí‚¹ì˜ í•µì‹¬ ëª©í‘œì…ë‹ˆë‹¤.  í–¥í›„ ì—°êµ¬ëŠ” **ë‹¤ì–‘í•œ LoRA ë³€í˜• ë° ë‹¤ë¥¸ PEFT(Parameter-Efficient Fine-Tuning) ê¸°ë²•ì— ëŒ€í•œ ì ìš© ê°€ëŠ¥ì„±**ì„ í™•ëŒ€í•˜ê³ ,  ë”ìš± ê°•ë ¥í•˜ê³  ì•ˆì „í•œ ì›Œí„°ë§ˆí‚¹ ê¸°ë²•ì„ ê°œë°œí•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶°ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.

#### SEAL's Robustness
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ SEAL ì•Œê³ ë¦¬ì¦˜ì˜ ê°•ê±´ì„±ì€ ë‹¤ì–‘í•œ ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ì €í•­ë ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. **ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ì €ì‘ê¶Œ ì¹¨í•´ ê³µê²©ì— ëŒ€í•œ ë°©ì–´ ëŠ¥ë ¥**ì…ë‹ˆë‹¤.  ë…¼ë¬¸ì—ì„œëŠ” ì œê±°, ë‚œë…í™”, ëª¨í˜¸ì„± ê³µê²©ì´ë¼ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ê³µê²© ìœ í˜•ì— ëŒ€í•œ SEALì˜ ê°•ê±´ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. **íŠ¹íˆ, ì €ì‘ê¶Œìë§Œì´ ì•”í˜¸í™”ëœ íŒ¨ìŠ¤í¬íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤ëŠ” ì ê³¼, íŒ¨ìŠ¤í¬íŠ¸ ì œê±° ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ì‹¬ê°í•˜ê²Œ ì €í•˜ëœë‹¤ëŠ” ì ì€ SEALì˜ ê°•ë ¥í•œ ì €ì‘ê¶Œ ë³´í˜¸ ê¸°ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” í•µì‹¬ ì¦ê±°**ì…ë‹ˆë‹¤.  ë˜í•œ, ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ì‘ì—…ì— ê±¸ì³ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìœ¼ë©°, ì´ëŠ” ì‹¤ì œ ì‘ìš© í™˜ê²½ì—ì„œì˜ ì‹¤ìš©ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  **ë‹¤ë§Œ, ëª¨ë“  ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ì´ ì™„ë²½í•˜ì§€ ì•Šë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬, ì§€ì†ì ì¸ ì—°êµ¬ì™€ í‰ê°€ë¥¼ í†µí•´ SEALì˜ ê°•ê±´ì„±ì„ ë”ìš± í–¥ìƒì‹œì¼œì•¼ í•¨ì„ ì‹œì‚¬**í•©ë‹ˆë‹¤.  ê²°ë¡ ì ìœ¼ë¡œ, **SEALì€ LoRA ê°€ì¤‘ì¹˜ ë³´í˜¸ì— ìˆì–´ ê°•ë ¥í•˜ê³  ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µ**í•˜ì§€ë§Œ,  **ì§€ì†ì ì¸ ê°œì„ ê³¼ ê²€ì¦ì´ í•„ìš”**í•©ë‹ˆë‹¤.

#### Passport-based Method
íŒ¨ìŠ¤í¬íŠ¸ ê¸°ë°˜ ë°©ë²•ì€ **DNN ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹**ì„ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê°€ì¤‘ì¹˜ ë˜ëŠ” í™œì„±í™” ê¸°ë°˜ ë°©ë²•ê³¼ ë‹¬ë¦¬, íŒ¨ìŠ¤í¬íŠ¸ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì§ì ‘ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” **ìˆ¨ê²¨ì§„ ë§¤ê°œë³€ìˆ˜** ì—­í• ì„ í•©ë‹ˆë‹¤.  **ì˜¬ë°”ë¥¸ íŒ¨ìŠ¤í¬íŠ¸ë¥¼ ì‚¬ìš©í•  ë•Œë§Œ ì •ìƒì ì¸ ì„±ëŠ¥ì„ ìœ ì§€**í•˜ê³ , ì˜ëª»ëœ íŒ¨ìŠ¤í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ì´ëŠ” **ì €ì‘ê¶Œìì˜ ì‹ ì›ì„ ê²€ì¦í•˜ëŠ” íš¨ê³¼ì ì¸ ë°©ë²•**ì´ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ, íŒ¨ìŠ¤í¬íŠ¸ ìì²´ê°€ ë³€ì¡°ë  ìœ„í—˜ì„±ì´ ìˆìœ¼ë©°, ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ ë³´ì•ˆ ì¡°ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë˜í•œ, íŒ¨ìŠ¤í¬íŠ¸ì˜ í¬ê¸° ë° ë³µì¡ë„ê°€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. **ëª¨ë¸ì˜ ì„±ëŠ¥ ì €í•˜ ì—†ì´ íš¨ê³¼ì ìœ¼ë¡œ ì €ì‘ê¶Œì„ ë³´í˜¸**í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°,  í–¥í›„ ì—°êµ¬ì—ì„œëŠ” íŒ¨ìŠ¤í¬íŠ¸ì˜ ì•ˆì „ì„± ë° íš¨ìœ¨ì„±ì„ ë”ìš± ë†’ì´ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê¸°ìˆ ë“¤ì´ ì—°êµ¬ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Experimental Design
ë³¸ ë…¼ë¬¸ì˜ "ì‹¤í—˜ ì„¤ê³„" ë¶€ë¶„ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. **ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ì‘ì—…ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í‰ê°€**ê°€ ì´ë£¨ì–´ì¡Œìœ¼ë©°, **ì¼ë°˜ì ì¸ ì‚¬ê³  ëŠ¥ë ¥, ì§€ì‹œì–´ ë¯¸ì„¸ ì¡°ì •, í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í•©ì„±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…**ì—ì„œ ì„±ëŠ¥ì„ í‰ê°€í•˜ì—¬ **SEALì˜ ë²”ìš©ì„±**ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ê¸°ì¡´ LoRAì™€ì˜ ì„±ëŠ¥ ë¹„êµ**ë¥¼ í†µí•´ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ì €ì‘ê¶Œ ë³´í˜¸ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. **ì œê±°, ë‚œë…í™”, ëª¨í˜¸ì„± ê³µê²©ì— ëŒ€í•œ ê²¬ê³ ì„± í‰ê°€**ëŠ” ì‹¤í—˜ ì„¤ê³„ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì´ë©°, ì´ë¥¼ í†µí•´ SEALì˜ ê°•ë ¥í•œ ì €ì‘ê¶Œ ë³´í˜¸ ì„±ëŠ¥ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ í¬ê´„ì ì¸ ê²€ì¦**ì„ í†µí•´ ì‹¤í—˜ì˜ ì‹ ë¢°ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤. **ì •ëŸ‰ì  ë° ì •ì„±ì  ë¶„ì„**ì„ ë³‘í–‰í•˜ì—¬ ê²°ê³¼ì˜ ê°ê´€ì„±ê³¼ ëª…í™•ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.  **ë‹¨ìˆœí•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ì €ì‘ê¶Œ ë³´í˜¸ ê¸°ë²•**ì„ ì œì‹œí•˜ê³ , ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ **ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦**í•˜ì—¬ ì—°êµ¬ì˜ ì‹ ë¢°ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.

#### Future Directions
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ SEAL ë°©ë²•ì˜ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•´ ì‹¬ë„ìˆê²Œ ê³ ì°°í•´ë³´ë©´, **ë‹¤ì–‘í•œ PEFT(Parameter-Efficient Fine-Tuning) ê¸°ë²•ë“¤ê³¼ì˜ í˜¸í™˜ì„± í™•ì¥**ì´ ì¤‘ìš”í•œ ê³¼ì œì…ë‹ˆë‹¤.  LoRA ì™¸ ë‹¤ë¥¸ ê¸°ë²•ë“¤(ì˜ˆ: Adapter, Kronecker product ê¸°ë°˜ ë°©ë²•)ì—ë„ SEALì„ ì ìš©í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ, **ì›Œí„°ë§ˆí‚¹ì˜ ì•ˆì „ì„± ê°•í™”**ë¥¼ ìœ„í•´,  **ë‹¤ì¤‘ ì›Œí„°ë§ˆí¬**, **ë°ì´í„° ê¸°ë°˜ ë§¤í•‘**, **ë¹„ì„ í˜• ì—°ì‚°** ë“±ì„ í™œìš©í•œ ê³ ê¸‰ ê¸°ë²•ë“¤ì„ ì—°êµ¬í•˜ì—¬ ê°•ê±´ì„±ì„ ë”ìš± ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜**ì„ ê°•í™”í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. íŠ¹íˆ, ì›Œí„°ë§ˆí¬ ì œê±°, ë‚œë…í™”, ëª¨í˜¸í™” ê³µê²©ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ê¸°ìˆ  ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤.  **ì‹¤ì œ ìƒìš© í™˜ê²½ì—ì„œì˜ ì ìš© ë° í‰ê°€**ë¥¼ í†µí•´ ì‹¤ìš©ì„±ì„ ê²€ì¦í•˜ëŠ” ì—°êµ¬ë„ ì¤‘ìš”í•œ ë¯¸ë˜ ê³¼ì œì…ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **ìœ¤ë¦¬ì , ë²•ì  ì¸¡ë©´ì˜ ê³ ë ¤**ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.  ì›Œí„°ë§ˆí‚¹ ê¸°ìˆ ì˜ ì•…ìš© ê°€ëŠ¥ì„±ì„ ì¤„ì´ê³ , ì €ì‘ê¶Œ ë³´í˜¸ì™€ ê¸°ìˆ  ë°œì „ì˜ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë°©í–¥ìœ¼ë¡œ ì—°êµ¬ê°€ ì§„í–‰ë˜ì–´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤. 


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2501.09284/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” LoRAì™€ SEALì˜ íŠ¹ì§•ê°’ ë¶„í¬ë¥¼ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.  LoRA(íŒŒë€ìƒ‰)ì™€ SEAL(ì£¼í™©ìƒ‰) ëª¨ë¸ì„ Llama-2, Mistral, Gemma ëª¨ë¸ì— ì ìš©í•˜ì—¬ í•™ìŠµí•œ í›„, ê° ëª¨ë¸ì˜ ìƒìœ„ 32ê°œ íŠ¹ì´ê°’ì˜ ìŒì˜ ë¡œê·¸ ê°’ì„ ëˆ„ì ë¶„í¬í•¨ìˆ˜(CDF) í˜•íƒœë¡œ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤. ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ SEALì´ LoRAì— ë¹„í•´ í•™ìŠµëœ íŠ¹ì§• ê³µê°„ì´ ì—¬ëŸ¬ íŠ¹ì´ê°’ì— ë” ê³ ë¥´ê²Œ ë¶„í¬ë˜ì–´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” íŠ¹ì • íŠ¹ì´ê°’ì„ ì œê±°í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ê³µê²©ì— ëŒ€í•œ SEALì˜ ê°•ê±´ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2:  Negative log singular value (CDF), collection of top-32 singular values. LoRA (blue) vs.Â SEAL (orange) across Llama-2, Mistral, and Gemma models.
> </details>



![](https://arxiv.org/html/2501.09284/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ê°€ì§€ì¹˜ê¸° ê³µê²©ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°€ë¡œì¶•ì€ L1 ê·œë²”ì„ ê¸°ì¤€ìœ¼ë¡œ  â„•(ğµâ€²,ğ´â€²) ì—ì„œ ê°€ì¥ ì‘ì€ íŒŒë¼ë¯¸í„°ì˜ ì œë¡œí™” ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚´ê³ , ì™¼ìª½ ì„¸ë¡œì¶•ì€ ìƒì‹ ì¶”ë¡  ì‘ì—…ì— ëŒ€í•œ ì¶©ì‹¤ë„ ì ìˆ˜ë¥¼, ì˜¤ë¥¸ìª½ ì„¸ë¡œì¶•ì€ ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œì˜ âˆ’log(pê°’)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. âˆ’log(pê°’)ì´ 3.3ë³´ë‹¤ í¬ë©´(ì¦‰, pê°’ < 5Ã—10â»â´), ì›Œí„°ë§ˆí¬ íƒì§€ë¥¼ ì„±ê³µí•œ ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. ê·¸ë˜í”„ëŠ” ì œë¡œí™” ë¹„ìœ¨ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì¶©ì‹¤ë„ ì ìˆ˜ê°€ ê°ì†Œí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” 99.9%ì˜ ê°€ì¤‘ì¹˜ê°€ ì œë¡œí™”ë  ë•Œê¹Œì§€ ì›Œí„°ë§ˆí¬ê°€ íƒì§€ ê°€ëŠ¥í•¨ì„ ë‚˜íƒ€ë‚´ë©°, ì´ëŠ” í˜¸ìŠ¤íŠ¸ ì‘ì—…ì˜ ì„±ëŠ¥ì„ í¬ê²Œ ì €í•˜ì‹œí‚µë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Pruning Attack. The x-axis represents the zeroing ratio of the smallest parameters of â„•â¢(Bâ€²,Aâ€²)â„•superscriptğµâ€²superscriptğ´â€²\mathbb{N}(B^{\prime},A^{\prime})blackboard_N ( italic_B start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) based on their L1 norms, the left y-axis shows the fidelity score on commonsense reasoning tasks, and the right y-axis displays the  âˆ’logâ¡(p-value)p-value-\log(\text{p-value})- roman_log ( p-value ) on a log scale. If  âˆ’logâ¡(p-value)p-value-\log(\text{p-value})- roman_log ( p-value ) is above 3.3 (i.e., p-value <5Ã—10âˆ’4absent5superscript104<5\times 10^{-4}< 5 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT), detecting the watermark succeeds. The graphs show that as the zeroing ratio increases, the fidelity score decreases. This indicates the watermark remains detectable until 99.9% of the weights are zeroed, which significantly degrades the host taskâ€™s performance.
> </details>



![](https://arxiv.org/html/2501.09284/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ì ëŒ€ì  í™˜ê²½ì—ì„œì˜ SEALì˜ ê°•ê±´ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  xì¶•ì€ ìœ„ì¡°ëœ ë¹„ë°€í‚¤(passport) C~p-adv ì™€ ì‹¤ì œ ë¹„ë°€í‚¤(passport) Cp ì˜ ìœ ì‚¬ë„(1-Î³)ë¥¼ ë‚˜íƒ€ë‚´ê³ , yì¶•ì€ ì¼ë°˜ì ì¸ ìƒì‹ ì¶”ë¡  ì‘ì—…ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Î³ê°€ 0.6ë³´ë‹¤ í´ ê²½ìš°, ê²€ì¦ ê³¼ì •ì˜ ì„ê³„ê°’(ÏµT)ë³´ë‹¤ ì •í™•ë„ ì°¨ì´ê°€ í˜„ì €í•˜ê²Œ ë‚®ì•„ì ¸, ê³µê²©ìê°€ ìœ„ì¡°ëœ ë¹„ë°€í‚¤ë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„,  ê²€ì¦ ê³¼ì •ì„ í†µê³¼í•˜ì§€ ëª»í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ SEALì´ ì ëŒ€ì  ê³µê²©ì— ê°•ì¸í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Ambiguity Attacks. Fidelity score, MT(â„•(A,B,Ct)M_{T}(\mathbb{N}(A,B,C_{t})italic_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( blackboard_N ( italic_A , italic_B , italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ), as average accuracy on Commonsense Reasoning tasks, Tğ‘‡Titalic_T, with the passport Ctsubscriptğ¶ğ‘¡C_{t}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, which is the inference time passport. The x-axis represents the dissimilarity, Î³ğ›¾\gammaitalic_Î³, where Ct=(1âˆ’Î³)â¢Cp+Î³â¢C~pâ¢-advsubscriptğ¶ğ‘¡1ğ›¾subscriptğ¶ğ‘ğ›¾subscript~ğ¶ğ‘-advC_{t}=(1-\gamma)C_{p}+\gamma\widetilde{C}_{p\text{-adv}}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( 1 - italic_Î³ ) italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_Î³ over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPT. Cpsubscriptğ¶ğ‘{C}_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is the concealed passport, and C~pâ¢-advsubscript~ğ¶ğ‘-adv\widetilde{C}_{p\text{-adv}}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_p -adv end_POSTSUBSCRIPT is the adversaryâ€™ matrix. When Î³>0.6ğ›¾0.6\gamma>0.6italic_Î³ > 0.6, the difference between fidelity scores significantly drops below the threshold of the verification process, ÏµTsubscriptitalic-Ïµğ‘‡\epsilon_{T}italic_Ïµ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, as shown in Table 5.
> </details>



![](https://arxiv.org/html/2501.09284/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ LoRAì™€ SEALì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•´, ë¯¸ì„¸ì¡°ì •ëœ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸(rank=32ì¸ N(Â·)ì— ëŒ€í•´)ì˜ ìƒìœ„ 32ê°œ íŠ¹ì´ê°’ Ïƒì—ì„œ ì–»ì€ -log(Ïƒ)ì˜ ë¶„í¬ë¥¼ ì»¤ë„ ë°€ë„ ì¶”ì •(KDE)ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”í•œ ê²ƒì…ë‹ˆë‹¤.  LoRAì™€ SEAL ëª¨ë‘ì—ì„œ ì–»ì€ -log(Ïƒ)ì˜ ë¶„í¬ë¥¼ ë¹„êµí•˜ì—¬ ë‘ ëª¨ë¸ì˜ íŠ¹ì´ê°’ ë¶„í¬ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ SEALì´ LoRAë³´ë‹¤ ë” ë„“ì€ íŠ¹ì´ê°’ ë¶„í¬ë¥¼ ê°€ì§€ë©°, ë”°ë¼ì„œ ì›Œí„°ë§ˆí‚¹ ì œê±° ê³µê²©ì— ëŒ€í•´ ë” ê°•ì¸í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: KDE of âˆ’logâ¡(Ïƒ)ğœ-\log(\sigma)- roman_log ( italic_Ïƒ ) for LoRA vs.Â SEAL. We extract the top-32 singular values Ïƒğœ\sigmaitalic_Ïƒ from each module of the finetuned Î”â¢WÎ”ğ‘Š\Delta Wroman_Î” italic_W (for rank=32 â„•â¢(â‹…)â„•â‹…\mathbb{N}(\cdot)blackboard_N ( â‹… )) and plot âˆ’logâ¡(Ïƒ)ğœ-\log(\sigma)- roman_log ( italic_Ïƒ ) via a kernel density estimate (KDE).
> </details>



![](https://arxiv.org/html/2501.09284/x6.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ LoRAì™€ SEALì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ë¥¼ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤.  ì„¸ ê°œì˜ í–‰ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì²« ë²ˆì§¸ í–‰ì€ ì°¸ì¡° ì´ë¯¸ì§€, ë‘ ë²ˆì§¸ í–‰ì€ LoRAë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•œ ì´ë¯¸ì§€, ì„¸ ë²ˆì§¸ í–‰ì€ SEALì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•œ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° í–‰ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ê°€ ë‚˜ë€íˆ ë°°ì¹˜ë˜ì–´ ë‹¤ì–‘í•œ ëŒ€ìƒì— ëŒ€í•œ ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ LoRAì™€ SEALì´ ìƒì„±í•œ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìœ ì‚¬ì„±ê³¼ ì°¨ì´ì ì„ ê´€ì°°í•˜ê³ , SEALì´ ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Comparison of LoRA and SEAL in Text-to-Image Synthesis
> </details>



![](https://arxiv.org/html/2501.09284/x7.png)

> ğŸ”¼  ê·¸ë¦¼ 8ì€ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” SEAL ë°©ë²•ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œì¸ ë¹„í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜(Passport)ì˜ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì™¼ìª½ì€ YouTube ë™ì˜ìƒ(https://www.youtube.com/watch?v=2zHHkSu1br4)ì˜ ì¼ë¶€ë¥¼ ì˜ë¼ë‚´ê³  í¬ê¸° ì¡°ì ˆí•˜ì—¬ 32x32 í‘ë°± ë¹„íŠ¸ë§µìœ¼ë¡œ ë§Œë“  Passport (C)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ì€ LLaMA-2-7B ëª¨ë¸ì—ì„œ SEAL ê°€ì¤‘ì¹˜ì˜ 10%ë¥¼ ì œê±°í–ˆì„ ë•Œ ë¶€ë¶„ì ìœ¼ë¡œ ë³µêµ¬ëœ Passport (C)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ì €í•´ìƒë„ ë¹„íŠ¸ë§µ ì´ë¯¸ì§€ê°€ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ê³µê°„ì— ì–´ë–»ê²Œ í†µí•©ë  ìˆ˜ ìˆê³ , ì†Œìœ ê¶Œ í™•ì¸ì„ ìœ„í•´ ì¶”ì¶œë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Passport Example. Left: A 32Ã—\timesÃ—32 grayscale bitmap (cropped and downsampled from a YouTube clip333https://www.youtube.com/watch?v=2zHHkSu1br4) serves as our non-trainable passport Cğ¶Citalic_C. Right: The passport partially recovered (from 10% zeroed SEAL weight on LLaMA-2-7B).
> </details>



![](https://arxiv.org/html/2501.09284/x8.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì›Œí„°ë§ˆí¬ ë§¤íŠ¸ë¦­ìŠ¤ Cì˜ í‘œì¤€ í¸ì°¨(std)ê°€ SEAL ê°€ì¤‘ì¹˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  std = Ïƒë¡œ í‘œì‹œëœ ì¶œë ¥ì€ C ~ N(0, ÏƒÂ²)ê°€ ì—†ëŠ” SEAL ê°€ì¤‘ì¹˜(ì¦‰, N(B, A, Ã˜))ë§Œì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ê²ƒì…ë‹ˆë‹¤.  'Vanilla SD 1.5'ëŠ” ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•œ Vanilla Stable Diffusion 1.5ì˜ ì¶œë ¥ì…ë‹ˆë‹¤.  ë‹¤ì–‘í•œ í‘œì¤€ í¸ì°¨ ê°’(Ïƒ)ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ë©°, í‘œì¤€ í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡(0.01) ì›ë³¸ ëª¨ë¸ê³¼ì˜ ì°¨ì´ê°€ ì»¤ì§€ê³ , í‘œì¤€ í¸ì°¨ê°€ í´ìˆ˜ë¡(10.0 ë˜ëŠ” 100.0) ì°¨ì´ê°€ ì‘ì•„ì§ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, Cê°€ ì—†ì„ ë•Œ, ì‘ì€ í‘œì¤€ í¸ì°¨ëŠ” ê³ ì£¼íŒŒ ì•„í‹°íŒ©íŠ¸ë¥¼ ìœ ë°œí•˜ê³ , í° í‘œì¤€ í¸ì°¨ëŠ” ì›ë³¸ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: Effect of passport Cğ¶Citalic_C standard deviation (std) on SEAL weight. std = Ïƒğœ\sigmaitalic_Ïƒ: Outputs are using only SEAL weight without Câˆ¼ğ’©â¢(0,Ïƒ2)similar-toğ¶ğ’©0superscriptğœ2C\sim\mathcal{N}(0,\sigma^{2})italic_C âˆ¼ caligraphic_N ( 0 , italic_Ïƒ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), â„•â¢(B,A,âˆ…)â„•ğµğ´\mathbb{N}(B,A,\emptyset)blackboard_N ( italic_B , italic_A , âˆ… ). Vanilla SD 1.5: output from vanila Stable Diffusion 1.5 with same prompt.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Task | Inst. Tune |  | Text-to-Image | 
|---|---|---|---|---|
|  | Textual | Visual | CLIP-T | CLIP-I | DINO. |
| Metric â†‘ | MT-B | Acc. |  |  |  |
| LoRA | **5.83** | **66.9** | **0.20** | **0.80** | **0.68** |
| SEAL | 5.81 | 63.1 | **0.20** | **0.80** | 0.67 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œì˜ ì¶©ì‹¤ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì§€ì‹œì–´ ë¯¸ì„¸ ì¡°ì •(Instruction Tuning), MT-Bench(MT-B) ë° í…ìŠ¤íŠ¸-ì´ë¯¸ì§€(t2i) ì‘ì—…ì´ í¬í•¨ë©ë‹ˆë‹¤. ì‹œê°ì  ì§€ì‹œì–´ ë¯¸ì„¸ ì¡°ì • ì ìˆ˜ëŠ” 7ê°€ì§€ ë¹„ì „-ì–¸ì–´ ì‘ì—…ì— ëŒ€í•œ í‰ê·  ì ìˆ˜ì…ë‹ˆë‹¤(ë¶€ë¡ ì°¸ì¡°). CLIP-Iì™€ DINOëŠ” ì£¼ì œ ì¶©ì‹¤ë„ ì ìˆ˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ë°˜ë©´, CLIP-TëŠ” í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤ë„ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2:  Fidelity across various tasks involves Inst. Tune (instruction tuning), MT-B (MT-Bench) and t2i task. Visual Inst. Tune score averages over seven vision-language tasks (see Appendix). CLIP-I and DINO demonstrate subject fidelity scores, while CLIP-T shows prompt fidelity scores.
> </details>

{{< table-caption >}}
| Method | Wall Time (h) | Avg. |
|---|---|---|
| LoRA | 12.0 | 81.67 Â± 1.03 |
| DoRA | 18.5 | 81.98 Â± 0.26 |
| SEAL | 19.6 | **83.78** Â± 0.27 |
| SEAL + DoRA | 27.8 | 81.88 Â± 1.08 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 3ì€ Llama-2-7B ëª¨ë¸ì— ëŒ€í•´ LoRA, DoRA ë° SEALì˜ ì¼ë°˜ì ì¸ ìƒì‹ ì¶”ë¡  ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. SEAL+DoRAëŠ” DoRA ë³€í˜•ì— SEAL ê¸°ë²•ì„ ì ìš©í•œ ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ˆë§¤ê°œë³€ìˆ˜ ì„¤ì •ì€ ë¶€ë¡ Fì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì • ë°©ë²•(PEFT)ì˜ ìƒì‹ ì¶”ë¡  ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ SEALì˜ íš¨ê³¼ì™€ DoRAì™€ì˜ í˜¸í™˜ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Average Commonsense Reasoning Performance on Llama-2-7B for LoRA, DoRA, and SEAL. The notation SEAL+DoRA signifies that the SEAL approach has been applied in conjunction with the DoRA variant. Hyperparameter settings are in AppendixÂ F.
> </details>

{{< table-caption >}}
| Tasks | Acc. | MT-B | p-value |
|---|---|---|---|
| C<sub>3e</sub> | 83.1 | - | - |
| I<sub>3e</sub> | - | 5.81 | - |
| I<sub>3e</sub>â†’C<sub>1e</sub> | 60.2 | 4.94 | 1.71e-1171 |
| C<sub>3e</sub>â†’I<sub>1e</sub> | 0.24 | 3.56 | 2.81e-178 |
| C<sub>3e</sub>â†’C<sub>1e</sub> | 82.9 | - | 3.86e-3111 |
| I<sub>3e</sub>â†’I<sub>1e</sub> | - | 3.78 | 9.08e-06 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” SEALì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¯¸ì„¸ ì¡°ì • ê³µê²© ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê°™ê±°ë‚˜ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì—ì„œ ë¯¸ì„¸ ì¡°ì •ì„ ìˆ˜í–‰í•œ í›„,  ì›Œí„°ë§ˆí¬(íŒ¨ìŠ¤í¬íŠ¸)ì˜ ê²€ì¶œ ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.  ì‹¤í—˜ì€ ì¼ë°˜ì ì¸ ì¶”ë¡  ì‘ì—…(Commonsense Reasoning)ê³¼ Alpaca ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ì§€ì‹œ ì¡°ì •(Instruction Tuning) ë‘ ê°€ì§€ ì‘ì—…ì— ëŒ€í•´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. í‘œì—ëŠ” ê° ì‘ì—…ì— ëŒ€í•œ ì •í™•ë„(Accuracy)ì™€ MT-B ì ìˆ˜, ê·¸ë¦¬ê³  ì›Œí„°ë§ˆí¬ ê²€ì¶œì˜ p-ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. p-ê°’ì´ ì‘ì„ìˆ˜ë¡ ì›Œí„°ë§ˆí¬ê°€ ì„±ê³µì ìœ¼ë¡œ ê²€ì¶œë˜ì—ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ë¯¸ì„¸ì¡°ì • ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ SEALì˜ ì›Œí„°ë§ˆí‚¹ì˜ ê°•ê±´ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Finetuning Attack. The detectability of passport on SEAL across either the same or different datasets.
> </details>

{{< table-caption >}}
| Model | $C_{t}=C$ | $C_{t}=C_{p}$ | $\
ewline \\\epsilon_{T}$ |
|---|---|---|---| 
| LLaMA-2-7B | 82.2 | 82.7 | 0.5 |
| Mistral-7B-v0.1 | 84.2 | 87.9 | 3.7 |
| Gemma-2B | 76.3 | 76.6 | 0.3 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë‹¤ì–‘í•œ ìƒì‹ ì¶”ë¡  ì‘ì—…ì—ì„œ ë‘ ê°œì˜ íŒ¨ìŠ¤í¬íŠ¸ì— ëŒ€í•œ ì¶©ì‹¤ë„ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° íŒ¨ìŠ¤í¬íŠ¸ì— ëŒ€í•œ í‰ê·  ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì¸ ğ‘€<sub>ğ‘‡</sub>(ğ‘(ğµ,ğ´,ğ¶))ê°€ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, ğ‘€<sub>ğ‘‡</sub>ëŠ” ì‘ì—…ë³„ ì§€í‘œ, ğ‘(ğµ,ğ´,ğ¶)ëŠ” LoRA ëª¨ë¸ì˜ ì ì‘ ê³„ì¸µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  í‘œëŠ” LoRA ëª¨ë¸ì˜ í›ˆë ¨ ê³¼ì •ì—ì„œ ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ íŒ¨ìŠ¤í¬íŠ¸(Cì™€ Cp)ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•˜ê²Œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•œ SEAL ì•Œê³ ë¦¬ì¦˜ì˜ ê°•ë ¥í•¨ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì§€í‘œì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Fidelity performance, MTsubscriptğ‘€ğ‘‡M_{T}italic_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, table for each passport on commonsense reasoning task, Tğ‘‡Titalic_T.
> </details>

{{< table-caption >}}
Symbol|Description
---|---|---
W|Pretrained model weight (size $b \times a$) on which LoRA is applied.
B,A|LoRAâ€™s trainable _up_ and _down_ blocks, where $B \in \mathbb{R}^{b \times r}$, $A \in \mathbb{R}^{r \times a}$, and $r \ll \min(b,a)$.
B',A'|Publicly released LoRA weights _after_ distributing the passport C (see Def. 3.2). These have the same shape as B,A.
Î”W|The weight offset from LoRA (or SEAL). For instance, $\Delta W = B \, C \, A$ or $B \, A$ depending on context.
$\mathbb{N}(\cdot)$|The adaptation layer operator; e.g., $\mathbb{N}(B,A)$ for standard LoRA, or $\mathbb{N}(B,A,C)$ for SEAL.
C,$C_p$|Non-trainable _passports_ in SEAL. C is the main passport hidden into B',A'; $C_p$ is an additional passport for ownership verification. Both are in $\mathbb{R}^{r \times r}$.
$\widetilde{B}, \widetilde{A}, \widetilde{C} \,(\widetilde{C}_{p\text{-adv}})$|An _adversarial factorization_ of publicly released weights (B',A') that an attacker attempts to construct; e.g. $\widetilde{B}\,\widetilde{C}\,\widetilde{A} = B'A'$. In some scenarios, an attacker may generate $\widetilde{C}_{p\text{-adv}}$ to forge an additional passport. These have the same shape as B,A,C respectively.
C_t|A _runtime passport_ (e.g., used in inference or verification) for given B,A.
f(\cdot)|Decomposition function that takes C and returns two factors ($C_1, C_2$) such that $C_1C_2 = C$. For example, $f_{svd}$ uses Singular Value Decomposition (SVD).
T|The _host task_ (e.g., instruction following, QA), to which LoRA (SEAL) is adapted.
M_T(\cdot)|A _fidelity score_ or performance metric (e.g., accuracy) of the adaptation layer on task T.
V(\cdot)|The verification process (function) that checks authenticity of passports (Sec. 3.6.3). It outputs `True` or `False`.
Ïµ_T|A threshold used in the verification stage to decide ownership claims.{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” SEAL(SEcure wAtermarking on LoRA weights) ë°©ë²•ì— ì‚¬ìš©ëœ ì£¼ìš” ê¸°í˜¸ì™€ ì •ì˜ë¥¼ ì„¤ëª…í•˜ëŠ” í‘œì…ë‹ˆë‹¤.  ê° ê¸°í˜¸ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜, LoRA(Low-Rank Adaptation) ê³„ì¸µ, ì›Œí„°ë§ˆí‚¹ì„ ìœ„í•œ íŒ¨ìŠ¤í¬íŠ¸ í–‰ë ¬ ë“±ì„ ë‚˜íƒ€ë‚´ë©°, ê° ê¸°í˜¸ì˜ ì˜ë¯¸ì™€ í¬ê¸°, ê·¸ë¦¬ê³  SEAL ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ë°©ì‹ì„ ì´í•´í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.  ë³¸ í‘œëŠ” SEAL ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ê°œë…ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Notation table for SEAL. Key symbols and their definitions.
> </details>

{{< table-caption >}}
| Models | Gemma-2B |  | Mistral-7B-v0.1 |  | LLaMA-2-7B |  | LLaMA-2-13B |  | LLaMA-3-8B |  |
|---|---|---|---|---|---|---|---|---|---|---|
| Method | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL |
| r | 32 |  |  |  |  |  |  |  |  |  |
| alpha | 32 |  |  |  |  |  |  |  |  |  |
| Dropout | 0.05 |  |  |  |  |  |  |  |  |  |
| LR | 2e-4 | 2e-5 | 2e-5 | 2e-5 | 2e-4 | 2e-5 | 2e-4 | 2e-5 | 2e-4 | 2e-5 |
| Optimizer | AdamW (Loshchilov & Hutter, 2019) |  |  |  |  |  |  |  |  |  |
| LR scheduler | Linear |  |  |  |  |  |  |  |  |  |
| Weight Decay | 0 |  |  |  |  |  |  |  |  |  |
| Warmup Steps | 100 |  |  |  |  |  |  |  |  |  |
| Total Batch size | 16 |  |  |  |  |  |  |  |  |  |
| Epoch | 3 |  |  |  |  |  |  |  |  |  |
| Target Modules | Query Key Value UpProj DownProj |  |  |  |  |  |  |  |  |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ Gemma-2B, Mistral-7B-v0.1, LLaMA-2-7B/13B, LLaMA-3-8B ëª¨ë¸ì—ì„œ ìƒì‹ ì¶”ë¡  ì‘ì—…ì— ëŒ€í•´ SEALê³¼ LoRAì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ì‹¤í—˜ì€ LLaMA-2-13Bì˜ ê²½ìš° 4x A100 80GB, ë‹¤ë¥¸ ëª¨ë¸ì˜ ê²½ìš° 4x RTX 3090ì„ ì‚¬ìš©í•˜ì—¬ ì•½ 15ì‹œê°„ ë™ì•ˆ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ëª¨ë¸ê³¼ ë°©ë²•(LoRA, SEAL)ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’(ì˜ˆ: rank(r), alpha, dropout ë¹„ìœ¨, í•™ìŠµë¥ (LR), ìµœì í™”ê¸°, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›œì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜, ëŒ€ìƒ ëª¨ë“ˆ)ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ë°©ë²•ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë¹„êµí•˜ì—¬ ì‹¤í—˜ì˜ ì¬í˜„ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Hyperparameter configurations of SEAL and LoRA for Gemma-2B, Mistral-7B-v0.1, LLaMA2-7B/13B, and LLaMA3-8B on the commonsense reasoning. All experiments are done with 4x A100 80GB (for LLaMA-2-13B) and 4x RTX 3090 (for the other models) with approximately 15 hours.
> </details>

{{< table-caption >}}
| Model | Method |  | 
|---|---|---|
| LLaMA-2-7B | LoRA | SEAL |
| r | 32 |  32 |
| alpha | 32 |  |
| Dropout | 0.0 |  |
| LR | 2e-5 |  |
| LR scheduler | Cosine |  |
| Optimizer | AdamW |  |
| Weight Decay | 0 |  |
| Total Batch size | 8 |  |
| Epoch | 3 |  |
| Target Modules | All w/o LM HEAD |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ ì§€ì‹œ ì¡°ì •(Instruction Tuning)ì„ ìœ„í•œ SEAL ë° LoRAì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ì‹¤í—˜ì€ 1x A100 80GB GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ì•½ 2ì‹œê°„ ë™ì•ˆ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. LM HEADë¥¼ ì œì™¸í•œ ëª¨ë“  ëª¨ë“ˆ(Query, Key, Value, Out, UpProj, DownProj, GateProj)ì— ëŒ€í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ì„¤ì •ë©ë‹ˆë‹¤.  í‘œì—ëŠ” LoRAì™€ SEAL ëª¨ë‘ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì´ ê° ì—´ì— ë‚˜ì—´ë˜ì–´ ìˆìœ¼ë©°, rank, alpha, dropout, í•™ìŠµë¥ (LR), ìµœì í™” ì•Œê³ ë¦¬ì¦˜, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›œì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜ ë“±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Hyperparameter configurations of SEAL and LoRA for Instruction Tuning. All experiments are done with 1x A100 80GB for approximately 2 hours. All w/o LM HEAD are Query, Key, Value, Out, UpProj, DownProj, GateProj.
> </details>

{{< table-caption >}}
| Method | # Params (%) | VQAv2 | GQA | VisWiz | SQA | VQAT | POPE | MMBench | Avg |
|---|---|---|---|---|---|---|---|---|---| 
| FT | 100 | 78.5 | 61.9 | 50.0 | 66.8 | 58.2 | 85.9 | 64.3 | 66.5 |
| LoRA | 4.61 | 79.1 | 62.9 | 47.8 | 68.4 | 58.2 | 86.4 | 66.1 | **66.9** |
| SEAL | 4.61 | 75.4 | 58.3 | 41.6 | 66.9 | 52.9 | 86.0 | 60.5 | 63.1 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” 7ê°€ì§€ ì‹œê°ì  ì§€ì‹œ ì¡°ì • ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì„¸ ê°€ì§€ ë°©ë²•(FT, LoRA, SEAL)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤.  ê° ë°©ë²•ì— ëŒ€í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜, VQAv2, GQA, VisWiz, SQA, VQAT, POPE ë° MMBench ë²¤ì¹˜ë§ˆí¬ì˜ ì •í™•ë„ ì ìˆ˜, ê·¸ë¦¬ê³  í‰ê·  ì •í™•ë„ ì ìˆ˜ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” SEALì´ LoRAì™€ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œë„ ìš°ìˆ˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Performance comparison of different methods across seven visual instruction tuning benchmarks
> </details>

{{< table-caption >}}
| Model | LLaVA-1.5-7B |
|---|---| 
| Method | LoRA | SEAL |
| r | 128 |
| alpha | 128 |
| LR | 2e-4 | 2e-5 |
| LR scheduler | Linear |
| Optimizer | AdamW |
| Weight Decay | 0 |
| Warmup Ratio | 0.03 |
| Total Batch size | 64 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 10ì€ ì‹œê°ì  ì§€ì‹œ ì¡°ì •ì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì‹¤í—˜ì€ 4ê°œì˜ A100 80GB GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ì•½ 24ì‹œê°„ ë™ì•ˆ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” LoRAì™€ SEAL ë°©ë²• ëª¨ë‘ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°(rank, alpha, í•™ìŠµë¥ , ìµœì í™” ì•Œê³ ë¦¬ì¦˜, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›œì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í­, ëŒ€ìƒ ëª¨ë“ˆ)ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ ì„¤ì •ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ì¬í˜„ì„±ì„ ë†’ì´ê³ , ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì´ ë™ì¼í•œ ì‹¤í—˜ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Hyperparameters for visual instruction tuning. All experiments were performed with 4x A100 80GB with approximately 24 hours
> </details>

{{< table-caption >}}
| Prompts for Non-Live Objects | Prompts for Live Subjects |
|---|---| 
| a {} in the jungle | a {} in the jungle |
| a {} in the snow | a {} in the snow |
| a {} on the beach | a {} on the beach |
| a {} on a cobblestone street | a {} on a cobblestone street |
| a {} on top of pink fabric | a {} on top of pink fabric |
| a {} on top of a wooden floor | a {} on top of a wooden floor |
| a {} with a city in the background | a {} with a city in the background |
| a {} with a mountain in the background | a {} with a mountain in the background |
| a {} with a blue house in the background | a {} with a blue house in the background |
| a {} on top of a purple rug in a forest | a {} on top of a purple rug in a forest |
| a {} with a wheat field in the background | a {} wearing a red hat |
| a {} with a tree and autumn leaves in the background | a {} wearing a santa hat |
| a {} with the Eiffel Tower in the background | a {} wearing a rainbow scarf |
| a {} floating on top of water | a {} wearing a black top hat and a monocle |
| a {} floating in an ocean of milk | a {} in a chef outfit |
| a {} on top of green grass with sunflowers around it | a {} in a firefighter outfit |
| a {} on top of a mirror | a {} in a police outfit |
| a {} on top of the sidewalk in a crowded street | a {} wearing pink glasses |
| a {} on top of a dirt road | a {} wearing a yellow shirt |
| a {} on top of a white rug | a {} in a purple wizard outfit |
| a red {} | a red {} |
| a purple {} | a purple {} |
| a shiny {} | a shiny {} |
| a wet {} | a wet {} |
| a cube shaped {} | a cube shaped {} |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 4.5ì ˆ 'Text-to-Image Synthesis'ì—ì„œ ì‚¬ìš©ëœ DreamBooth ë°ì´í„°ì…‹ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤.  DreamBooth ë°ì´í„°ì…‹ì€ 15ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ì¢…ë¥˜ì— ì†í•˜ëŠ” 30ê°œì˜ ê°œë³„ ê°ì²´(ë¬´ìƒë¬¼ ë° ìƒë¬¼)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê° ê°ì²´ëŠ” 4~6ê°œì˜ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.  í‘œëŠ” ë¬´ìƒë¬¼ ê°ì²´ì™€ ìƒë¬¼ ê°ì²´ ê°ê°ì— ëŒ€í•´ ì‚¬ìš©ëœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê°ì²´ ìœ í˜•ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë°°ê²½, ìœ„ì¹˜, ê·¸ë¦¬ê³  ì¶”ê°€ì ì¸ ì†ì„±(ì˜ˆ: ìƒ‰ìƒ, í˜•íƒœ)ì„ í¬í•¨í•˜ëŠ” ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ê°€ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ëŸ¬í•œ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ê°ì ìœ¼ë¡œ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.  ì¦‰, ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ ì£¼ì–´ì§„ ê°ì²´ë¥¼ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œë„ ì •í™•í•˜ê²Œ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: DreamBooth text prompts used for evaluation of inanimate objects and live subjects.
> </details>

{{< table-caption >}}
| Model | Method |  | 
|---|---|---|
| Stable Diffusion 1.5 | LoRA | SEAL |
| r | 32 | 32 |
| alpha | 32 | 32 |
| Dropout | 0.0 | 0.0 |
| LR | 5e-5 | 1e-5 |
| LR scheduler | Constant | Constant |
| Optimizer | AdamW | AdamW |
| Weight Decay | 1e-2 | 1e-2 |
| Total Batch size | 32 | 32 |
| Steps | 300 | 300 |
| Target Modules | Q K V Out AddK AddV | Q K V Out AddK AddV |{{< /table-caption >}}
> ğŸ”¼ í‘œ 12ëŠ” LoRAì™€ SEALì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í•©ì„± ì‹¤í—˜ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  4ê°œì˜ RTX 4090 GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì£¼ì œë‹¹ ì•½ 15ë¶„ ë™ì•ˆ ì‹¤í—˜ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” LoRAì™€ SEAL ë°©ë²• ëª¨ë‘ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’(rank, alpha, dropout ë¹„ìœ¨, í•™ìŠµë¥ , í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ìµœì í™” ì•Œê³ ë¦¬ì¦˜, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›œì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜, ëŒ€ìƒ ëª¨ë“ˆ)ì´ ìì„¸íˆ ë‚˜ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LoRAì™€ SEALì˜ ì„±ëŠ¥ ë¹„êµ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì˜ ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: Hyperparameter configurations of SEAL and LoRA for Text-to-Image Synthesis. All experiments are done with 4x RTX 4090 with approximately 15 minutes per subject.
> </details>

{{< table-caption >}}
| Model | LLaMA-2-7B |
|---|---| 
| Method | LoRA |
| r | 32 |
| alpha | 32 |
| LR | 2e-5 |
| Optimizer | AdamW |
| LR scheduler | Linear |
| Weight Decay | 0 |
| Warmup Steps | 100 |
| Batch size | 16 |
| Epoch | 1 |
| Target Modules | Query Key Value UpProj DownProj |{{< /table-caption >}}
> ğŸ”¼ í‘œ 13ì€ SEAL ëª¨ë¸ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì • ê³µê²©ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  3 ì—í­ ë™ì•ˆ í›ˆë ¨ëœ SEAL ê°€ì¤‘ì¹˜  â„•(ğµâ€²,ğ´â€²)â„•superscriptğµâ€²superscriptğ´â€² mathbb{N}(B^{ abla},A^{ abla}) ì— ëŒ€í•´ ë¯¸ì„¸ ì¡°ì • í›ˆë ¨ì„ ì¬ê°œí•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë¹„ì„ í˜• ë§¤í•‘ í•¨ìˆ˜  ğ‘“ğ‘ ğ‘£ğ‘‘ë¥¼ í†µí•´ íŒ¨ìŠ¤í¬íŠ¸  ğ¶ê°€  ğµì™€  ğ´ì— ë¶„í¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  í‘œëŠ” ë¯¸ì„¸ ì¡°ì • ê³µê²©ì— ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ğ‘Ÿ, Î±, ë“œë¡­ì•„ì›ƒ, í•™ìŠµë¥ , ìµœì í™” ì•Œê³ ë¦¬ì¦˜, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›Œë°ì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í­, ëŒ€ìƒ ëª¨ë“ˆ)ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  LLaMA-2-7B ëª¨ë¸ì— ëŒ€í•œ ì„¤ì •ì´ ì œê³µë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Hyperparameter configurations of Finetruning Attack on SEAL which trains on 3-epoch. We resume training on â„•â¢(Bâ€²,Aâ€²)â„•superscriptğµâ€²superscriptğ´â€²\mathbb{N}(B^{\prime},A^{\prime})blackboard_N ( italic_B start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ), which passport Cğ¶Citalic_C is distributed in B,Ağµğ´B,Aitalic_B , italic_A via fsâ¢vâ¢dsubscriptğ‘“ğ‘ ğ‘£ğ‘‘f_{svd}italic_f start_POSTSUBSCRIPT italic_s italic_v italic_d end_POSTSUBSCRIPT.
> </details>

{{< table-caption >}}
| Model | Method | LRa | SEAL | DoRA | SEAL+DoRA |
|---|---|---|---|---|---| 
| LLaMA-2-7B | LoRA | 2e-4 | 2e-5 | 2e-4 | 2e-5 |
| r |  | 32 |  |  |  |
| alpha |  | 32 |  |  |  |
| Dropout |  | 0.05 |  |  |  |
| LR |  | 2e-4 | 2e-5 | 2e-4 | 2e-5 |
| Optimizer |  | AdamW |  |  |  |
| LR scheduler |  | Linear |  |  |  |
| Weight Decay |  | 0 |  |  |  |
| Warmup Steps |  | 100 |  |  |  |
| Total Batch size |  | 16 |  |  |  |
| Epoch |  | 3 |  |  |  |
| Target Modules |  | Query Key Value UpProj DownProj |  |  |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 14ëŠ” DoRAì™€ í†µí•©ëœ LoRA ë° SEALì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ëª¨ë¸ì€ LLaMA-2-7Bë¥¼ ì‚¬ìš©í•˜ë©°, ê° ë°©ë²•(LoRA, SEAL, DoRA, SEAL+DoRA)ì— ëŒ€í•œ rank(r), alpha, dropout ë¹„ìœ¨, í•™ìŠµë¥ (LR), ì˜µí‹°ë§ˆì´ì €, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ê°€ì¤‘ì¹˜ ê°ì‡ , ì›œì—… ë‹¨ê³„, ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜, ê·¸ë¦¬ê³  ëª©í‘œ ëª¨ë“ˆ(Query Key Value UpProj DownProj) ë“±ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ í‘œëŠ” DoRAë¼ëŠ” LoRAì˜ ë³€í˜• ëª¨ë¸ê³¼ SEALì„ ê²°í•©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ ì‹¤í—˜ ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Hyperparameter configurations of Integrating with DoRA.
> </details>

{{< table-caption >}}
| Rank | BoolQ | PIQA | SIQA | HellaSwag | Wino. | ARC-c | ARC-e | OBQA | Avg. |
|---|---|---|---|---|---|---|---|---|---| 
| 4 | 65.05 | 78.18 | 75.64 | 76.16 | 73.56 | 65.02 | 81.65 | 74.80 | 73.76 |
| 8 | 64.83 | 81.23 | 77.02 | 83.92 | 77.35 | 68.43 | 83.00 | 79.20 | 76.87 |
| 16 | 66.24 | 82.32 | 77.94 | 86.10 | 79.24 | 67.32 | 83.12 | 78.60 | **77.61** |
| 32 | 66.45 | 82.16 | 78.20 | 83.72 | 79.95 | 68.09 | 82.62 | 79.40 | 77.57 |
| LoRA<sub>r=32</sub> | 65.96 | 78.62 | 75.23 | 79.20 | 76.64 | 79.13 | 62.80 | 72.40 | 73.75 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 15ëŠ” ë‹¤ì–‘í•œ ìˆœìœ„ ì„¤ì •ì—ì„œ ìƒì‹ ì¶”ë¡  ì‘ì—…ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œì—ëŠ” LoRA r=32ì™€ SEAL r=32ë¿ë§Œ ì•„ë‹ˆë¼ SEALì˜ ìˆœìœ„ êµ¬ì„±(4, 8, 16)ì— ëŒ€í•œ ê²°ê³¼ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ë‹¤ì–‘í•œ ì°¨ì›ì˜ ì €ì°¨ì› ì ì‘(LoRA) ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ í‘œì…ë‹ˆë‹¤.  ê° ìˆœìœ„ ì„¤ì •(4, 8, 16)ì—ì„œ SEALì˜ ì„±ëŠ¥ê³¼ ê¸°ì¤€ LoRA ëª¨ë¸(r=32)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬,  SEALì˜ ì„±ëŠ¥ì´ ìˆœìœ„ì— í¬ê²Œ ì˜í–¥ë°›ì§€ ì•Šê³  ì•ˆì •ì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 15: Accuracy across various rank settings on commonsense reasoning tasks. The table includes results for rank configurations (4, 8, 16) of SEAL, as well as LoRA r=32 and SEAL r=32.
> </details>

{{< table-caption >}}
| Ref. | Metric â†‘ | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C |
|---|---|---|---|---|---|---|
|  |  | 0.01 | 0.1 | 1.0 | 10.0 | 100.0 |
| Obj.1 | SSIM | 0.104 | 0.691 | 0.936 | 0.987 | 0.998 |
|  | PSNR | 7.80 | 19.02 | 30.87 | 43.64 | 53.16 |
| Obj.2 | SSIM | 0.102 | 0.652 | 0.941 | 0.993 | 0.998 |
|  | PSNR | 7.91 | 18.51 | 33.15 | 47.24 | 54.21 |
| Obj.3 | SSIM | 0.115 | 0.651 | 0.959 | 0.992 | 0.998 |
|  | PSNR | 8.08 | 18.39 | 32.92 | 45.39 | 53.58 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 16ì€ ì›Œí„°ë§ˆí¬ Cê°€ ì—†ëŠ” ìƒíƒœ(ì¦‰, C~N(0,ÏƒÂ²)ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì— ëŒ€í•œ PSNR ë° SSIM ê°’ì„ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤. ì¦‰, Cê°€ ì—†ëŠ” í›ˆë ¨ëœ SEAL ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ N(B,A,âˆ…)ì— ëŒ€í•œ PSNRê³¼ SSIMê°’ì„ í‘œì— ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.  ë‹¤ì–‘í•œ í‘œì¤€í¸ì°¨(std) ê°’ì„ ê°€ì§„ íŒ¨ìŠ¤í¬íŠ¸ Cë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ì™€ Vanilla SD 1.5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì´ë¯¸ì§€ ê°„ì˜ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ëŒ€ìƒ ì´ë¯¸ì§€ëŠ” ê³ ì–‘ì´(Obj. 1), ë°°ë‚­ì„ ë©˜ ê°•ì•„ì§€(Obj. 2), ì˜¤ë¦¬ ì¸í˜•(Obj. 3)ì…ë‹ˆë‹¤. ëŒ€ìƒ ì´ë¯¸ì§€ ì´ë¦„ì€ Ruiz et al.(2023)ì˜ ë…¼ë¬¸ì—ì„œ ë”°ì˜¨ ê²ƒì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 16: Comparision of PSNR and SSIM values for images generated without Câˆ¼ğ’©â¢(0,Ïƒ2)similar-toğ¶ğ’©0superscriptğœ2C\sim\mathcal{N}(0,\sigma^{2})italic_C âˆ¼ caligraphic_N ( 0 , italic_Ïƒ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), using only â„•â¢(B,A,âˆ…)â„•ğµğ´\mathbb{N}(B,A,\emptyset)blackboard_N ( italic_B , italic_A , âˆ… ), under varying standard deviations of the passport Cğ¶Citalic_C, with images generated under vanilla SD 1.5 model. Obj.Â 1: Cat, ObjectÂ 2: Backpack dog, Obj.Â 3: Ducky toy. Object names are same asÂ (Ruiz etÂ al., 2023)
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}