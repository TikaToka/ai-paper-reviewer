[{"content": "| Method | BoolQ | PIQA | SIQA | HellaSwag | Wino. | ARC-e | ARC-c | OBQA | Avg. \u2191 |\n|---|---|---|---|---|---|---|---|---|---| \n| LLaMA-2-7B | LoRA | 73.75 | 82.99 | 79.85 | 86.14 | 85.06 | 86.15 | 73.63 | 81.67 \u00b1 1.03 |\n|  | SEAL (Ours) | 72.70 | 85.27 | 81.27 | 90.15 | 85.79 | 87.07 | 74.60 | 82.73 \u00b1 0.14 |\n|  | SEAL\u2020 (Ours) | 73.19 | 86.31 | 81.95 | 91.21 | 86.69 | 88.55 | 75.51 | **83.78** \u00b1 0.27 |\n| LLaMA-2-13B | LoRA | 75.57 | 86.98 | 81.39 | 91.82 | 88.53 | 90.08 | 78.78 | 84.98 \u00b1 0.17 |\n|  | SEAL (Ours) | 75.34 | 87.41 | 83.28 | 93.33 | 88.42 | 90.68 | 79.61 | 85.60 \u00b1 0.34 |\n|  | SEAL\u2020 (Ours) | 75.67 | 88.63 | 83.21 | 93.95 | 89.29 | 91.72 | 81.46 | **86.56** \u00b1 0.10 |\n| LLaMA-3-8B | LoRA | 74.76 | 88.22 | 80.96 | 92.00 | 86.08 | 90.09 | 82.41 | 85.10 \u00b1 1.39 |\n|  | SEAL (Ours) | 73.88 | 88.23 | 82.29 | 94.84 | 88.35 | 91.67 | 82.00 | 85.94 \u00b1 0.29 |\n|  | SEAL\u2020 (Ours) | 75.78 | 90.37 | 83.25 | 96.05 | 89.92 | 93.49 | 84.73 | **88.02** \u00b1 0.11 |\n| Gemma-2B | LoRA | 67.05 | 83.19 | 77.26 | 87.07 | 79.74 | 83.91 | 69.34 | 78.43 \u00b1 0.32 |\n|  | SEAL (Ours) | 66.56 | 81.79 | 77.65 | 84.82 | 79.16 | 82.79 | 68.40 | 77.55 \u00b1 0.04 |\n|  | SEAL\u2020 (Ours) | 66.70 | 82.50 | 78.88 | 87.57 | 80.19 | 83.81 | 69.97 | **78.68** \u00b1 0.11 |\n| Mistral-7B-v0.1 | LoRA | 75.92 | 90.72 | 81.78 | 94.68 | 88.69 | 93.10 | 83.36 | 87.07 \u00b1 0.27 |\n|  | SEAL (Ours) | 73.08 | 87.52 | 81.92 | 91.23 | 87.97 | 90.19 | 78.70 | 84.84 \u00b1 0.44 |\n|  | SEAL\u2020 (Ours) | 76.92 | 90.42 | 82.51 | 94.57 | 90.08 | 93.31 | 83.25 | **87.85** \u00b1 0.02 |", "caption": "Table 1: Commonsense Reasoning Performance (3-run Avg.). Scores are averaged over three random seeds, with standard deviation shown in a smaller font for the last column. SEAL\u2020 denotes using a constant matrix C\ud835\udc36Citalic_C from normal distribution.", "description": "\ud45c 1\uc740 \uc138 \uac00\uc9c0 \uc0c1\uc2dd \ucd94\ub860 \uc791\uc5c5(BoolQ, PIQA, SIQA, HellaSwag, Winograd Schema Challenge, ARC-e, ARC-c, OBQA)\uc5d0 \ub300\ud55c \uc138 \uac00\uc9c0 \ubaa8\ub378(LLaMA-2-7B, LLaMA-2-13B, LLaMA-3-8B)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc791\uc5c5\uc5d0 \ub300\ud574 LoRA\uc640 SEAL\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \uc138 \ubc88\uc758 \ub3c5\ub9bd\uc801\uc778 \uc2e4\ud589\uc73c\ub85c \uacc4\uc0b0\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uacfc \ubc29\ubc95\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218\uc640 \ud45c\uc900 \ud3b8\ucc28\uac00 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. SEAL\u2020\ub294 \uc815\uaddc \ubd84\ud3ec\uc5d0\uc11c \uc0dd\uc131\ub41c \uc0c1\uc218 \ud589\ub82c C\ub97c \uc0ac\uc6a9\ud558\ub294 SEAL \ubcc0\ud615\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Task | Inst. Tune |  | Text-to-Image | \n|---|---|---|---|---|\n|  | Textual | Visual | CLIP-T | CLIP-I | DINO. |\n| Metric \u2191 | MT-B | Acc. |  |  |  |\n| LoRA | **5.83** | **66.9** | **0.20** | **0.80** | **0.68** |\n| SEAL | 5.81 | 63.1 | **0.20** | **0.80** | 0.67 |", "caption": "Table 2:  Fidelity across various tasks involves Inst. Tune (instruction tuning), MT-B (MT-Bench) and t2i task. Visual Inst. Tune score averages over seven vision-language tasks (see Appendix). CLIP-I and DINO demonstrate subject fidelity scores, while CLIP-T shows prompt fidelity scores.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0\uc11c\uc758 \ucda9\uc2e4\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 \uc9c0\uc2dc\uc5b4 \ubbf8\uc138 \uc870\uc815(Instruction Tuning), MT-Bench(MT-B) \ubc0f \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0(t2i) \uc791\uc5c5\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc2dc\uac01\uc801 \uc9c0\uc2dc\uc5b4 \ubbf8\uc138 \uc870\uc815 \uc810\uc218\ub294 7\uac00\uc9c0 \ube44\uc804-\uc5b8\uc5b4 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218\uc785\ub2c8\ub2e4(\ubd80\ub85d \ucc38\uc870). CLIP-I\uc640 DINO\ub294 \uc8fc\uc81c \ucda9\uc2e4\ub3c4 \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ubc18\uba74, CLIP-T\ub294 \ud504\ub86c\ud504\ud2b8 \ucda9\uc2e4\ub3c4 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | Wall Time (h) | Avg. |\n|---|---|---|\n| LoRA | 12.0 | 81.67 \u00b1 1.03 |\n| DoRA | 18.5 | 81.98 \u00b1 0.26 |\n| SEAL | 19.6 | **83.78** \u00b1 0.27 |\n| SEAL + DoRA | 27.8 | 81.88 \u00b1 1.08 |", "caption": "Table 3: Average Commonsense Reasoning Performance on Llama-2-7B for LoRA, DoRA, and SEAL.\nThe notation SEAL+DoRA signifies that the SEAL approach has been applied in conjunction with the DoRA variant.\nHyperparameter settings are in Appendix\u00a0F.", "description": "\ud45c 3\uc740 Llama-2-7B \ubaa8\ub378\uc5d0 \ub300\ud574 LoRA, DoRA \ubc0f SEAL\uc758 \uc77c\ubc18\uc801\uc778 \uc0c1\uc2dd \ucd94\ub860 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SEAL+DoRA\ub294 DoRA \ubcc0\ud615\uc5d0 SEAL \uae30\ubc95\uc744 \uc801\uc6a9\ud55c \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ucd08\ub9e4\uac1c\ubcc0\uc218 \uc124\uc815\uc740 \ubd80\ub85d F\uc5d0 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ub9e4\uac1c\ubcc0\uc218 \ud6a8\uc728\uc801\uc778 \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95(PEFT)\uc758 \uc0c1\uc2dd \ucd94\ub860 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec SEAL\uc758 \ud6a8\uacfc\uc640 DoRA\uc640\uc758 \ud638\ud658\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.6. LoRA \ubcc0\ud615\uacfc\uc758 \ud1b5\ud569"}, {"content": "| Tasks | Acc. | MT-B | p-value |\n|---|---|---|---|\n| C<sub>3e</sub> | 83.1 | - | - |\n| I<sub>3e</sub> | - | 5.81 | - |\n| I<sub>3e</sub>\u2192C<sub>1e</sub> | 60.2 | 4.94 | 1.71e-1171 |\n| C<sub>3e</sub>\u2192I<sub>1e</sub> | 0.24 | 3.56 | 2.81e-178 |\n| C<sub>3e</sub>\u2192C<sub>1e</sub> | 82.9 | - | 3.86e-3111 |\n| I<sub>3e</sub>\u2192I<sub>1e</sub> | - | 3.78 | 9.08e-06 |", "caption": "Table 4: Finetuning Attack. The detectability of passport on SEAL across either the same or different datasets.", "description": "\ud45c 4\ub294 SEAL\uc758 \uacac\uace0\uc131\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ubbf8\uc138 \uc870\uc815 \uacf5\uaca9 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac19\uac70\ub098 \ub2e4\ub978 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubbf8\uc138 \uc870\uc815\uc744 \uc218\ud589\ud55c \ud6c4,  \uc6cc\ud130\ub9c8\ud06c(\ud328\uc2a4\ud3ec\ud2b8)\uc758 \uac80\ucd9c \uac00\ub2a5\uc131\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uc2e4\ud5d8\uc740 \uc77c\ubc18\uc801\uc778 \ucd94\ub860 \uc791\uc5c5(Commonsense Reasoning)\uacfc Alpaca \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uc9c0\uc2dc \uc870\uc815(Instruction Tuning) \ub450 \uac00\uc9c0 \uc791\uc5c5\uc5d0 \ub300\ud574 \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4(Accuracy)\uc640 MT-B \uc810\uc218, \uadf8\ub9ac\uace0 \uc6cc\ud130\ub9c8\ud06c \uac80\ucd9c\uc758 p-\uac12\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. p-\uac12\uc774 \uc791\uc744\uc218\ub85d \uc6cc\ud130\ub9c8\ud06c\uac00 \uc131\uacf5\uc801\uc73c\ub85c \uac80\ucd9c\ub418\uc5c8\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubbf8\uc138\uc870\uc815 \uacf5\uaca9 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c SEAL\uc758 \uc6cc\ud130\ub9c8\ud0b9\uc758 \uac15\uac74\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Robustness Against Attacks"}, {"content": "| Model | $C_{t}=C$ | $C_{t}=C_{p}$ | $\\\newline \\\\\\epsilon_{T}$ |\n|---|---|---|---| \n| LLaMA-2-7B | 82.2 | 82.7 | 0.5 |\n| Mistral-7B-v0.1 | 84.2 | 87.9 | 3.7 |\n| Gemma-2B | 76.3 | 76.6 | 0.3 |", "caption": "Table 5: Fidelity performance, MTsubscript\ud835\udc40\ud835\udc47M_{T}italic_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, table for each passport on commonsense reasoning task, T\ud835\udc47Titalic_T.", "description": "\ud45c 5\ub294 \ub2e4\uc591\ud55c \uc0c1\uc2dd \ucd94\ub860 \uc791\uc5c5\uc5d0\uc11c \ub450 \uac1c\uc758 \ud328\uc2a4\ud3ec\ud2b8\uc5d0 \ub300\ud55c \ucda9\uc2e4\ub3c4 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud328\uc2a4\ud3ec\ud2b8\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uc778 \ud835\udc40<sub>\ud835\udc47</sub>(\ud835\udc41(\ud835\udc35,\ud835\udc34,\ud835\udc36))\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \ud835\udc40<sub>\ud835\udc47</sub>\ub294 \uc791\uc5c5\ubcc4 \uc9c0\ud45c, \ud835\udc41(\ud835\udc35,\ud835\udc34,\ud835\udc36)\ub294 LoRA \ubaa8\ub378\uc758 \uc801\uc751 \uacc4\uce35\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ud45c\ub294 LoRA \ubaa8\ub378\uc758 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ub450 \uac1c\uc758 \uc11c\ub85c \ub2e4\ub978 \ud328\uc2a4\ud3ec\ud2b8(C\uc640 Cp)\uac00 \uc5bc\ub9c8\ub098 \uc720\uc0ac\ud558\uac8c \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \uc800\uc791\uad8c \ubcf4\ud638\ub97c \uc704\ud55c SEAL \uc54c\uace0\ub9ac\uc998\uc758 \uac15\ub825\ud568\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uc9c0\ud45c\uc785\ub2c8\ub2e4.", "section": "3.6 Passport-based Ownership Verification"}, {"content": "Symbol|Description\n---|---|---\nW|Pretrained model weight (size $b \\times a$) on which LoRA is applied.\nB,A|LoRA\u2019s trainable _up_ and _down_ blocks, where $B \\in \\mathbb{R}^{b \\times r}$, $A \\in \\mathbb{R}^{r \\times a}$, and $r \\ll \\min(b,a)$.\nB',A'|Publicly released LoRA weights _after_ distributing the passport C (see Def. 3.2). These have the same shape as B,A.\n\u0394W|The weight offset from LoRA (or SEAL). For instance, $\\Delta W = B \\, C \\, A$ or $B \\, A$ depending on context.\n$\\mathbb{N}(\\cdot)$|The adaptation layer operator; e.g., $\\mathbb{N}(B,A)$ for standard LoRA, or $\\mathbb{N}(B,A,C)$ for SEAL.\nC,$C_p$|Non-trainable _passports_ in SEAL. C is the main passport hidden into B',A'; $C_p$ is an additional passport for ownership verification. Both are in $\\mathbb{R}^{r \\times r}$.\n$\\widetilde{B}, \\widetilde{A}, \\widetilde{C} \\,(\\widetilde{C}_{p\\text{-adv}})$|An _adversarial factorization_ of publicly released weights (B',A') that an attacker attempts to construct; e.g. $\\widetilde{B}\\,\\widetilde{C}\\,\\widetilde{A} = B'A'$. In some scenarios, an attacker may generate $\\widetilde{C}_{p\\text{-adv}}$ to forge an additional passport. These have the same shape as B,A,C respectively.\nC_t|A _runtime passport_ (e.g., used in inference or verification) for given B,A.\nf(\\cdot)|Decomposition function that takes C and returns two factors ($C_1, C_2$) such that $C_1C_2 = C$. For example, $f_{svd}$ uses Singular Value Decomposition (SVD).\nT|The _host task_ (e.g., instruction following, QA), to which LoRA (SEAL) is adapted.\nM_T(\\cdot)|A _fidelity score_ or performance metric (e.g., accuracy) of the adaptation layer on task T.\nV(\\cdot)|The verification process (function) that checks authenticity of passports (Sec. 3.6.3). It outputs `True` or `False`.\n\u03f5_T|A threshold used in the verification stage to decide ownership claims.", "caption": "Table 6: Notation table for SEAL. Key symbols and their definitions.", "description": "\ud45c 6\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 SEAL(SEcure wAtermarking on LoRA weights) \ubc29\ubc95\uc5d0 \uc0ac\uc6a9\ub41c \uc8fc\uc694 \uae30\ud638\uc640 \uc815\uc758\ub97c \uc124\uba85\ud558\ub294 \ud45c\uc785\ub2c8\ub2e4.  \uac01 \uae30\ud638\ub294 \ubaa8\ub378 \uac00\uc911\uce58, LoRA(Low-Rank Adaptation) \uacc4\uce35, \uc6cc\ud130\ub9c8\ud0b9\uc744 \uc704\ud55c \ud328\uc2a4\ud3ec\ud2b8 \ud589\ub82c \ub4f1\uc744 \ub098\ud0c0\ub0b4\uba70, \uac01 \uae30\ud638\uc758 \uc758\ubbf8\uc640 \ud06c\uae30, \uadf8\ub9ac\uace0 SEAL \uc54c\uace0\ub9ac\uc998 \ub3d9\uc791 \ubc29\uc2dd\uc744 \uc774\ud574\ud558\ub294 \ub370 \ud544\uc218\uc801\uc778 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 SEAL \uc54c\uace0\ub9ac\uc998\uc758 \ud575\uc2ec \uac1c\ub150\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "3. SEAL: The Watermarking Scheme"}, {"content": "| Models | Gemma-2B |  | Mistral-7B-v0.1 |  | LLaMA-2-7B |  | LLaMA-2-13B |  | LLaMA-3-8B |  |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Method | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL | LoRA | SEAL |\n| r | 32 |  |  |  |  |  |  |  |  |  |\n| alpha | 32 |  |  |  |  |  |  |  |  |  |\n| Dropout | 0.05 |  |  |  |  |  |  |  |  |  |\n| LR | 2e-4 | 2e-5 | 2e-5 | 2e-5 | 2e-4 | 2e-5 | 2e-4 | 2e-5 | 2e-4 | 2e-5 |\n| Optimizer | AdamW (Loshchilov & Hutter, 2019) |  |  |  |  |  |  |  |  |  |\n| LR scheduler | Linear |  |  |  |  |  |  |  |  |  |\n| Weight Decay | 0 |  |  |  |  |  |  |  |  |  |\n| Warmup Steps | 100 |  |  |  |  |  |  |  |  |  |\n| Total Batch size | 16 |  |  |  |  |  |  |  |  |  |\n| Epoch | 3 |  |  |  |  |  |  |  |  |  |\n| Target Modules | Query Key Value UpProj DownProj |  |  |  |  |  |  |  |  |  |", "caption": "Table 7: Hyperparameter configurations of SEAL and LoRA for Gemma-2B, Mistral-7B-v0.1, LLaMA2-7B/13B, and LLaMA3-8B on the commonsense reasoning. All experiments are done with 4x A100 80GB (for LLaMA-2-13B) and 4x RTX 3090 (for the other models) with approximately 15 hours.", "description": "\ud45c 7\uc740 Gemma-2B, Mistral-7B-v0.1, LLaMA-2-7B/13B, LLaMA-3-8B \ubaa8\ub378\uc5d0\uc11c \uc0c1\uc2dd \ucd94\ub860 \uc791\uc5c5\uc5d0 \ub300\ud574 SEAL\uacfc LoRA\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \uc2e4\ud5d8\uc740 LLaMA-2-13B\uc758 \uacbd\uc6b0 4x A100 80GB, \ub2e4\ub978 \ubaa8\ub378\uc758 \uacbd\uc6b0 4x RTX 3090\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc57d 15\uc2dc\uac04 \ub3d9\uc548 \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uacfc \ubc29\ubc95(LoRA, SEAL)\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12(\uc608: rank(r), alpha, dropout \ube44\uc728, \ud559\uc2b5\ub960(LR), \ucd5c\uc801\ud654\uae30, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uac00\uc911\uce58 \uac10\uc1e0, \uc6dc\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ec\ud06c \uc218, \ub300\uc0c1 \ubaa8\ub4c8)\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uacfc \ubc29\ubc95\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ube44\uad50\ud558\uc5ec \uc2e4\ud5d8\uc758 \uc7ac\ud604\uc131\uacfc \uc2e0\ub8b0\uc131\uc744 \ub192\uc774\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Method |  | \n|---|---|---|\n| LLaMA-2-7B | LoRA | SEAL |\n| r | 32 |  32 |\n| alpha | 32 |  |\n| Dropout | 0.0 |  |\n| LR | 2e-5 |  |\n| LR scheduler | Cosine |  |\n| Optimizer | AdamW |  |\n| Weight Decay | 0 |  |\n| Total Batch size | 8 |  |\n| Epoch | 3 |  |\n| Target Modules | All w/o LM HEAD |  |", "caption": "Table 8: Hyperparameter configurations of SEAL and LoRA for Instruction Tuning. All experiments are done with 1x A100 80GB for approximately 2 hours. All w/o LM HEAD are Query, Key, Value, Out, UpProj, DownProj, GateProj.", "description": "\ud45c 8\uc740 \uc9c0\uc2dc \uc870\uc815(Instruction Tuning)\uc744 \uc704\ud55c SEAL \ubc0f LoRA\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \uc2e4\ud5d8\uc740 1x A100 80GB GPU\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc57d 2\uc2dc\uac04 \ub3d9\uc548 \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. LM HEAD\ub97c \uc81c\uc678\ud55c \ubaa8\ub4e0 \ubaa8\ub4c8(Query, Key, Value, Out, UpProj, DownProj, GateProj)\uc5d0 \ub300\ud574 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uac00 \uc124\uc815\ub429\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 LoRA\uc640 SEAL \ubaa8\ub450\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc774 \uac01 \uc5f4\uc5d0 \ub098\uc5f4\ub418\uc5b4 \uc788\uc73c\uba70, rank, alpha, dropout, \ud559\uc2b5\ub960(LR), \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uac00\uc911\uce58 \uac10\uc1e0, \uc6dc\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ec\ud06c \uc218 \ub4f1\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | # Params (%) | VQAv2 | GQA | VisWiz | SQA | VQAT | POPE | MMBench | Avg |\n|---|---|---|---|---|---|---|---|---|---| \n| FT | 100 | 78.5 | 61.9 | 50.0 | 66.8 | 58.2 | 85.9 | 64.3 | 66.5 |\n| LoRA | 4.61 | 79.1 | 62.9 | 47.8 | 68.4 | 58.2 | 86.4 | 66.1 | **66.9** |\n| SEAL | 4.61 | 75.4 | 58.3 | 41.6 | 66.9 | 52.9 | 86.0 | 60.5 | 63.1 |", "caption": "Table 9: Performance comparison of different methods across seven visual instruction tuning benchmarks", "description": "\ud45c 9\ub294 7\uac00\uc9c0 \uc2dc\uac01\uc801 \uc9c0\uc2dc \uc870\uc815 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc138 \uac00\uc9c0 \ubc29\ubc95(FT, LoRA, SEAL)\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc5d0 \ub300\ud55c \ub9e4\uac1c\ubcc0\uc218 \uc218, VQAv2, GQA, VisWiz, SQA, VQAT, POPE \ubc0f MMBench \ubca4\uce58\ub9c8\ud06c\uc758 \uc815\ud655\ub3c4 \uc810\uc218, \uadf8\ub9ac\uace0 \ud3c9\uade0 \uc815\ud655\ub3c4 \uc810\uc218\uac00 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 SEAL\uc774 LoRA\uc640 \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \ud30c\ub77c\ubbf8\ud130 \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c\ub3c4 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc2dc\uac01\uc801 \uc9c0\uc2dc \uc870\uc815"}, {"content": "| Model | LLaVA-1.5-7B |\n|---|---| \n| Method | LoRA | SEAL |\n| r | 128 |\n| alpha | 128 |\n| LR | 2e-4 | 2e-5 |\n| LR scheduler | Linear |\n| Optimizer | AdamW |\n| Weight Decay | 0 |\n| Warmup Ratio | 0.03 |\n| Total Batch size | 64 |", "caption": "Table 10: Hyperparameters for visual instruction tuning. All experiments were performed with 4x A100 80GB with approximately 24 hours", "description": "\ud45c 10\uc740 \uc2dc\uac01\uc801 \uc9c0\uc2dc \uc870\uc815\uc744 \uc704\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc2e4\ud5d8\uc740 4\uac1c\uc758 A100 80GB GPU\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc57d 24\uc2dc\uac04 \ub3d9\uc548 \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 LoRA\uc640 SEAL \ubc29\ubc95 \ubaa8\ub450\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(rank, alpha, \ud559\uc2b5\ub960, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uac00\uc911\uce58 \uac10\uc1e0, \uc6dc\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ed, \ub300\uc0c1 \ubaa8\ub4c8)\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uc124\uc815\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uc5ec \uc7ac\ud604\uc131\uc744 \ub192\uc774\uace0, \ub2e4\ub978 \uc5f0\uad6c\uc790\ub4e4\uc774 \ub3d9\uc77c\ud55c \uc2e4\ud5d8 \ud658\uacbd\uc744 \uad6c\ucd95\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Prompts for Non-Live Objects | Prompts for Live Subjects |\n|---|---| \n| a {} in the jungle | a {} in the jungle |\n| a {} in the snow | a {} in the snow |\n| a {} on the beach | a {} on the beach |\n| a {} on a cobblestone street | a {} on a cobblestone street |\n| a {} on top of pink fabric | a {} on top of pink fabric |\n| a {} on top of a wooden floor | a {} on top of a wooden floor |\n| a {} with a city in the background | a {} with a city in the background |\n| a {} with a mountain in the background | a {} with a mountain in the background |\n| a {} with a blue house in the background | a {} with a blue house in the background |\n| a {} on top of a purple rug in a forest | a {} on top of a purple rug in a forest |\n| a {} with a wheat field in the background | a {} wearing a red hat |\n| a {} with a tree and autumn leaves in the background | a {} wearing a santa hat |\n| a {} with the Eiffel Tower in the background | a {} wearing a rainbow scarf |\n| a {} floating on top of water | a {} wearing a black top hat and a monocle |\n| a {} floating in an ocean of milk | a {} in a chef outfit |\n| a {} on top of green grass with sunflowers around it | a {} in a firefighter outfit |\n| a {} on top of a mirror | a {} in a police outfit |\n| a {} on top of the sidewalk in a crowded street | a {} wearing pink glasses |\n| a {} on top of a dirt road | a {} wearing a yellow shirt |\n| a {} on top of a white rug | a {} in a purple wizard outfit |\n| a red {} | a red {} |\n| a purple {} | a purple {} |\n| a shiny {} | a shiny {} |\n| a wet {} | a wet {} |\n| a cube shaped {} | a cube shaped {} |", "caption": "Table 11: DreamBooth text prompts used for evaluation of inanimate objects and live subjects.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 4.5\uc808 \"Text-to-Image Synthesis\"\uc5d0\uc11c \uc0ac\uc6a9\ub41c DreamBooth \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc124\uba85\uc785\ub2c8\ub2e4.  DreamBooth \ub370\uc774\ud130\uc14b\uc740 15\uac1c\uc758 \uc11c\ub85c \ub2e4\ub978 \uc885\ub958\uc5d0 \uc18d\ud558\ub294 30\uac1c\uc758 \uac1c\ubcc4 \uac1d\uccb4(\ubb34\uc0dd\ubb3c \ubc0f \uc0dd\ubb3c)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uac01 \uac1d\uccb4\ub294 4~6\uac1c\uc758 \uc774\ubbf8\uc9c0\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \ud45c\ub294 \ubb34\uc0dd\ubb3c \uac1d\uccb4\uc640 \uc0dd\ubb3c \uac1d\uccb4 \uac01\uac01\uc5d0 \ub300\ud574 \uc0ac\uc6a9\ub41c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uac1d\uccb4 \uc720\ud615\uc5d0 \ub300\ud574 \ub2e4\uc591\ud55c \ubc30\uacbd, \uc704\uce58, \uadf8\ub9ac\uace0 \ucd94\uac00\uc801\uc778 \uc18d\uc131(\uc608: \uc0c9\uc0c1, \ud615\ud0dc)\uc744 \ud3ec\ud568\ud558\ub294 \uc5ec\ub7ec \ud504\ub86c\ud504\ud2b8\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \ub2e4\uc591\ud55c \ud504\ub86c\ud504\ud2b8\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uac01\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc989, \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubaa8\ub378\uc774 \uc8fc\uc5b4\uc9c4 \uac1d\uccb4\ub97c \ub2e4\uc591\ud55c \uc0c1\ud669\uc5d0\uc11c\ub3c4 \uc815\ud655\ud558\uac8c \uc0dd\uc131\ud560 \uc218 \uc788\ub294\uc9c0\ub97c \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ub2e4\uc591\ud55c \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments > 4.5. Text-to-Image Synthesis"}, {"content": "| Model | Method |  | \n|---|---|---|\n| Stable Diffusion 1.5 | LoRA | SEAL |\n| r | 32 | 32 |\n| alpha | 32 | 32 |\n| Dropout | 0.0 | 0.0 |\n| LR | 5e-5 | 1e-5 |\n| LR scheduler | Constant | Constant |\n| Optimizer | AdamW | AdamW |\n| Weight Decay | 1e-2 | 1e-2 |\n| Total Batch size | 32 | 32 |\n| Steps | 300 | 300 |\n| Target Modules | Q K V Out AddK AddV | Q K V Out AddK AddV |", "caption": "Table 12: Hyperparameter configurations of SEAL and LoRA for Text-to-Image Synthesis. All experiments are done with 4x RTX 4090 with approximately 15 minutes per subject.", "description": "\ud45c 12\ub294 LoRA\uc640 SEAL\uc744 \uc0ac\uc6a9\ud55c \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \ud569\uc131 \uc2e4\ud5d8\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  4\uac1c\uc758 RTX 4090 GPU\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac01 \uc8fc\uc81c\ub2f9 \uc57d 15\ubd84 \ub3d9\uc548 \uc2e4\ud5d8\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 LoRA\uc640 SEAL \ubc29\ubc95 \ubaa8\ub450\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12(rank, alpha, dropout \ube44\uc728, \ud559\uc2b5\ub960, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \uac00\uc911\uce58 \uac10\uc1e0, \uc6dc\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ec\ud06c \uc218, \ub300\uc0c1 \ubaa8\ub4c8)\uc774 \uc790\uc138\ud788 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 LoRA\uc640 SEAL\uc758 \uc131\ub2a5 \ube44\uad50 \ubc0f \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc870\uc815\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | LLaMA-2-7B |\n|---|---| \n| Method | LoRA |\n| r | 32 |\n| alpha | 32 |\n| LR | 2e-5 |\n| Optimizer | AdamW |\n| LR scheduler | Linear |\n| Weight Decay | 0 |\n| Warmup Steps | 100 |\n| Batch size | 16 |\n| Epoch | 1 |\n| Target Modules | Query Key Value UpProj DownProj |", "caption": "Table 13: Hyperparameter configurations of Finetruning Attack on SEAL which trains on 3-epoch. We resume training on \u2115\u2062(B\u2032,A\u2032)\u2115superscript\ud835\udc35\u2032superscript\ud835\udc34\u2032\\mathbb{N}(B^{\\prime},A^{\\prime})blackboard_N ( italic_B start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT ), which passport C\ud835\udc36Citalic_C is distributed in B,A\ud835\udc35\ud835\udc34B,Aitalic_B , italic_A via fs\u2062v\u2062dsubscript\ud835\udc53\ud835\udc60\ud835\udc63\ud835\udc51f_{svd}italic_f start_POSTSUBSCRIPT italic_s italic_v italic_d end_POSTSUBSCRIPT.", "description": "\ud45c 13\uc740 SEAL \ubaa8\ub378\uc5d0 \ub300\ud55c \ubbf8\uc138 \uc870\uc815 \uacf5\uaca9\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  3 \uc5d0\ud3ed \ub3d9\uc548 \ud6c8\ub828\ub41c SEAL \uac00\uc911\uce58  \u2115(\ud835\udc35\u2032,\ud835\udc34\u2032)\u2115superscript\ud835\udc35\u2032superscript\ud835\udc34\u2032\nmathbb{N}(B^{\nabla},A^{\nabla})\n\uc5d0 \ub300\ud574 \ubbf8\uc138 \uc870\uc815 \ud6c8\ub828\uc744 \uc7ac\uac1c\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc11c \ube44\uc120\ud615 \ub9e4\ud551 \ud568\uc218  \ud835\udc53\ud835\udc60\ud835\udc63\ud835\udc51\ub97c \ud1b5\ud574 \ud328\uc2a4\ud3ec\ud2b8  \ud835\udc36\uac00  \ud835\udc35\uc640  \ud835\udc34\uc5d0 \ubd84\ud3ec\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\ub294 \ubbf8\uc138 \uc870\uc815 \uacf5\uaca9\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 (\ud835\udc5f, \u03b1, \ub4dc\ub86d\uc544\uc6c3, \ud559\uc2b5\ub960, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uac00\uc911\uce58 \uac10\uc1e0, \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ed, \ub300\uc0c1 \ubaa8\ub4c8)\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaMA-2-7B \ubaa8\ub378\uc5d0 \ub300\ud55c \uc124\uc815\uc774 \uc81c\uacf5\ub429\ub2c8\ub2e4.", "section": "4.7. Pruning Attack"}, {"content": "| Model | Method | LRa | SEAL | DoRA | SEAL+DoRA |\n|---|---|---|---|---|---| \n| LLaMA-2-7B | LoRA | 2e-4 | 2e-5 | 2e-4 | 2e-5 |\n| r |  | 32 |  |  |  |\n| alpha |  | 32 |  |  |  |\n| Dropout |  | 0.05 |  |  |  |\n| LR |  | 2e-4 | 2e-5 | 2e-4 | 2e-5 |\n| Optimizer |  | AdamW |  |  |  |\n| LR scheduler |  | Linear |  |  |  |\n| Weight Decay |  | 0 |  |  |  |\n| Warmup Steps |  | 100 |  |  |  |\n| Total Batch size |  | 16 |  |  |  |\n| Epoch |  | 3 |  |  |  |\n| Target Modules |  | Query Key Value UpProj DownProj |  |  |  |", "caption": "Table 14: Hyperparameter configurations of Integrating with DoRA.", "description": "\ud45c 14\ub294 DoRA\uc640 \ud1b5\ud569\ub41c LoRA \ubc0f SEAL\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378\uc740 LLaMA-2-7B\ub97c \uc0ac\uc6a9\ud558\uba70, \uac01 \ubc29\ubc95(LoRA, SEAL, DoRA, SEAL+DoRA)\uc5d0 \ub300\ud55c rank(r), alpha, dropout \ube44\uc728, \ud559\uc2b5\ub960(LR), \uc635\ud2f0\ub9c8\uc774\uc800, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uac00\uc911\uce58 \uac10\uc1e0, \uc6dc\uc5c5 \ub2e8\uacc4, \ubc30\uce58 \ud06c\uae30, \uc5d0\ud3ec\ud06c \uc218, \uadf8\ub9ac\uace0 \ubaa9\ud45c \ubaa8\ub4c8(Query Key Value UpProj DownProj) \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 DoRA\ub77c\ub294 LoRA\uc758 \ubcc0\ud615 \ubaa8\ub378\uacfc SEAL\uc744 \uacb0\ud569\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \uc704\ud55c \uc2e4\ud5d8 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.6. LoRA \ubcc0\ud615 \ubaa8\ub378\uacfc\uc758 \ud1b5\ud569"}, {"content": "| Rank | BoolQ | PIQA | SIQA | HellaSwag | Wino. | ARC-c | ARC-e | OBQA | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| 4 | 65.05 | 78.18 | 75.64 | 76.16 | 73.56 | 65.02 | 81.65 | 74.80 | 73.76 |\n| 8 | 64.83 | 81.23 | 77.02 | 83.92 | 77.35 | 68.43 | 83.00 | 79.20 | 76.87 |\n| 16 | 66.24 | 82.32 | 77.94 | 86.10 | 79.24 | 67.32 | 83.12 | 78.60 | **77.61** |\n| 32 | 66.45 | 82.16 | 78.20 | 83.72 | 79.95 | 68.09 | 82.62 | 79.40 | 77.57 |\n| LoRA<sub>r=32</sub> | 65.96 | 78.62 | 75.23 | 79.20 | 76.64 | 79.13 | 62.80 | 72.40 | 73.75 |", "caption": "Table 15: Accuracy across various rank settings on commonsense reasoning tasks. The table includes results for rank configurations (4, 8, 16) of SEAL, as well as LoRA r=32 and SEAL r=32.", "description": "\ud45c 15\ub294 \ub2e4\uc591\ud55c \uc21c\uc704 \uc124\uc815\uc5d0\uc11c \uc0c1\uc2dd \ucd94\ub860 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\ub294 LoRA r=32\uc640 SEAL r=32\ubfd0\ub9cc \uc544\ub2c8\ub77c SEAL\uc758 \uc21c\uc704 \uad6c\uc131(4, 8, 16)\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ucc28\uc6d0\uc758 \uc800\ucc28\uc6d0 \uc801\uc751(LoRA) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  \uac01 \uc21c\uc704 \uc124\uc815(4, 8, 16)\uc5d0\uc11c SEAL\uc758 \uc131\ub2a5\uacfc \uae30\uc900 LoRA \ubaa8\ub378(r=32)\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec,  SEAL\uc758 \uc131\ub2a5\uc774 \uc21c\uc704\uc5d0 \ud06c\uac8c \uc601\ud5a5\ubc1b\uc9c0 \uc54a\uace0 \uc548\uc815\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "G.2 Rank Ablation"}, {"content": "| Ref. | Metric \u2191 | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C | Standard Deviation of C |\n|---|---|---|---|---|---|---|\n|  |  | 0.01 | 0.1 | 1.0 | 10.0 | 100.0 |\n| Obj.1 | SSIM | 0.104 | 0.691 | 0.936 | 0.987 | 0.998 |\n|  | PSNR | 7.80 | 19.02 | 30.87 | 43.64 | 53.16 |\n| Obj.2 | SSIM | 0.102 | 0.652 | 0.941 | 0.993 | 0.998 |\n|  | PSNR | 7.91 | 18.51 | 33.15 | 47.24 | 54.21 |\n| Obj.3 | SSIM | 0.115 | 0.651 | 0.959 | 0.992 | 0.998 |\n|  | PSNR | 8.08 | 18.39 | 32.92 | 45.39 | 53.58 |", "caption": "Table 16: Comparision of PSNR and SSIM values for images generated without C\u223c\ud835\udca9\u2062(0,\u03c32)similar-to\ud835\udc36\ud835\udca90superscript\ud835\udf0e2C\\sim\\mathcal{N}(0,\\sigma^{2})italic_C \u223c caligraphic_N ( 0 , italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), using only \u2115\u2062(B,A,\u2205)\u2115\ud835\udc35\ud835\udc34\\mathbb{N}(B,A,\\emptyset)blackboard_N ( italic_B , italic_A , \u2205 ),\nunder varying standard deviations of the passport C\ud835\udc36Citalic_C, with images generated under vanilla SD 1.5 model.\nObj.\u00a01: Cat, Object\u00a02: Backpack dog, Obj.\u00a03: Ducky toy. Object names are same as\u00a0(Ruiz et\u00a0al., 2023)", "description": "\ud45c 16\uc740 \uc6cc\ud130\ub9c8\ud06c C\uac00 \uc5c6\ub294 \uc0c1\ud0dc(\uc989, C~N(0,\u03c3\u00b2)\uc5d0\uc11c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c PSNR \ubc0f SSIM \uac12\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc989, C\uac00 \uc5c6\ub294 \ud6c8\ub828\ub41c SEAL \uac00\uc911\uce58\ub9cc \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0 N(B,A,\u2205)\uc5d0 \ub300\ud55c PSNR\uacfc SSIM\uac12\uc744 \ud45c\uc5d0 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud45c\uc900\ud3b8\ucc28(std) \uac12\uc744 \uac00\uc9c4 \ud328\uc2a4\ud3ec\ud2b8 C\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc640 Vanilla SD 1.5 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0 \uac04\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub300\uc0c1 \uc774\ubbf8\uc9c0\ub294 \uace0\uc591\uc774(Obj. 1), \ubc30\ub0ad\uc744 \uba58 \uac15\uc544\uc9c0(Obj. 2), \uc624\ub9ac \uc778\ud615(Obj. 3)\uc785\ub2c8\ub2e4. \ub300\uc0c1 \uc774\ubbf8\uc9c0 \uc774\ub984\uc740 Ruiz et al.(2023)\uc758 \ub17c\ubb38\uc5d0\uc11c \ub530\uc628 \uac83\uc785\ub2c8\ub2e4.", "section": "G.3. Impact of the Size of Passport C"}]