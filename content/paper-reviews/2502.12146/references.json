{"references": [{"fullname_first_author": "Black, K.", "paper_title": "Training diffusion models with reinforcement learning", "publication_date": "2024-00-00", "reason": "This paper is foundational for RL-based diffusion model fine-tuning, a key approach that Diffusion-Sharpening builds upon and improves."}, {"fullname_first_author": "Wallace, B.", "paper_title": "Diffusion model alignment using direct preference optimization", "publication_date": "2024-00-00", "reason": "This paper introduces Diffusion-DPO, a state-of-the-art RL fine-tuning method for diffusion models, which Diffusion-Sharpening directly compares against and surpasses in efficiency and performance."}, {"fullname_first_author": "Yeh, P.-H.", "paper_title": "Training-free diffusion model alignment with sampling demons", "publication_date": "2024-00-00", "reason": "This paper presents Demon, a sampling trajectory optimization method that Diffusion-Sharpening improves upon by reducing significant computational overhead."}, {"fullname_first_author": "Kim, J.", "paper_title": "Free2Guide: Gradient-free path integral control for enhancing text-to-video generation with large vision-language models", "publication_date": "2024-00-00", "reason": "This paper proposes Free2Guide, another sampling trajectory optimization method, which is compared to Diffusion-Sharpening to demonstrate the efficiency and effectiveness of the proposed method."}, {"fullname_first_author": "Ma, N.", "paper_title": "Inference-time scaling for diffusion models beyond scaling denoising steps", "publication_date": "2025-00-00", "reason": "This paper introduces Inference Scaling, a method to improve inference efficiency in diffusion models, which is compared to Diffusion-Sharpening to highlight its superior inference efficiency while maintaining comparable performance."}]}