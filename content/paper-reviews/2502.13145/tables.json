[{"content": "| Method | Recipe | Complexity | # P. | # T.P. | MME | MMB | POPE | SEED | MMMU | MM-Vet | TQA | SQA-I | GQA |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| **Encoder-based VLMs** |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| OpenFlamingo (Awadalla et al., 2023) | PT, SFT | Quadratic | 9B | 96.6% | - | 4.6 | - | - | - | - | 33.6 | - | - |\n| MiniGPT-4 (Zhu et al., 2023) | PT, SFT | Quadratic | 13B | 94.8% | 581.7 | 23.0 | - | - | - | 22.1 | - | - | 32.2 |\n| Qwen-VL (Bai et al., 2023b) | PT, SFT | Quadratic | 7B | 100.0% | - | 38.2 | - | 56.3 | - | - | 63.8 | 67.1 | 59.3 |\n| LLaVA-Phi (Zhu et al., 2024) | PT, SFT | Quadratic | 3B | 90.0% | 1335.1 | 59.8 | 85.0 | - | - | 28.9 | 48.6 | 68.4 | - |\n| MobileVLM-3B (Chu et al., 2023) | PT, SFT | Quadratic | 3B | 90.0% | 1288.9 | 59.6 | 84.9 | - | - | - | 47.5 | 61.0 | 59.0 |\n| VisualRWKV (Hou et al., 2024) | PT, SFT | **Linear** | 3B | 90.0% | 1369.2 | 59.5 | 83.1 | - | - | - | 48.7 | 65.3 | 59.6 |\n| VL-Mamba (Qiao et al., 2024) | PT, SFT | **Linear** | 3B | 90.0% | 1369.6 | 57.0 | 84.4 | - | - | 32.6 | 48.9 | 65.4 | 56.2 |\n| Cobra (Zhao et al., 2024) | PT, SFT | **Linear** | 3.5B | 82.6% | - | - | **88.4** | - | - | - | 58.2 | - | **62.3** |\n| **Decoder-only VLMs** |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Fuyu-8B (HD) (Bavishi et al., 2023) | PT, SFT | Quadratic | 8B | 100.0% | 728.6 | 10.7 | 74.1 | - | - | 21.4 | - | - | - |\n| SOLO (Chen et al., 2024a) | PT, SFT | Quadratic | 7B | 100.0% | 1001.3 | - | - | 64.4 | - | - | - | 73.3 | - |\n| Chameleon-7B (Team, 2024) | PT, SFT | Quadratic | 7B | 100.0% | 170 | 31.1 | - | 30.6 | 25.4 | 8.3 | 4.8 | 47.2 | - |\n| EVE-7B (Diao et al., 2024) | PT, SFT | Quadratic | 7B | 100.0% | 1217.3 | 49.5 | 83.6 | 61.3 | 32.3 | 25.6 | 51.9 | 63.0 | 60.8 |\n| Emu3 (Wang et al., 2024b) | PT, SFT | Quadratic | 8B | 100.0% | - | 58.5 | 85.2 | 68.2 | 31.6 | 37.2 | 64.7 | 89.2 | 60.3 |\n| HoVLE (Tao et al., 2024) | DT, PT, SFT | Quadratic | **2.6B** | 100.0% | **1433.5** | **71.9** | 87.6 | **70.7** | **33.7** | **44.3** | **66.0** | **94.8** | 60.9 |\n| mmMamba | **DT** | **Linear** | **2.7B** | **14.7%** | 1303.5 | 57.2 | 85.2 | 62.9 | 30.7 | 31.1 | 47.7 | 79.2 | 57.4 |\n| mmMamba | **DT** | **Hybrid** | **2.7B** | **11.2%** | 1371.1 | 63.7 | 86.7 | 66.3 | 32.3 | 36.9 | 55.1 | 86.9 | 59.3 |", "caption": "Table 1: Comparison with existing VLMs on general VLM benchmarks. \u201cRecipe\u201d denotes the adopted training recipe. \u201cPT\u201d, \u201cSFT\u201d, and \u201cDT\u201d denote the pre-training, supervised fine-tuning, and distillation training, respectively. \u201cComplexity\u201d denotes the model computation complexity with respect to the number of tokens. \u201c# P.\u201d denotes the number of total parameters. \u201c# T.P.\u201d denotes the percentage of trainable parameters (trainable paramterstotal parameterstrainable paramterstotal parameters\\frac{\\text{trainable paramters}}{\\text{total parameters}}divide start_ARG trainable paramters end_ARG start_ARG total parameters end_ARG). The best performance is highlighted in bold and the second-best result is underlined.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378(VLMs)\ub4e4\uacfc \uc81c\uc548\ub41c mmMamba \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc77c\ubc18\uc801\uc778 VLM \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud559\uc2b5 \ubc29\uc2dd(Recipe)\uc744 \ub098\ud0c0\ub0b4\ub294 \uc57d\uc5b4(PT: \uc0ac\uc804\ud559\uc2b5, SFT: \uc9c0\ub3c4 \ud559\uc2b5 \ubbf8\uc138 \uc870\uc815, DT: \uc99d\ub958 \ud559\uc2b5)\uc640 \ubaa8\ub378\uc758 \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4(Complexity, \ud1a0\ud070 \uc218\uc5d0 \ub530\ub978 \ubcf5\uc7a1\ub3c4), \ucd1d \ud30c\ub77c\ubbf8\ud130 \uc218(# P.), \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130 \ube44\uc728(# T.P.)\uc774 \ud568\uaed8 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  \uc131\ub2a5\uc740 \uc5ec\ub7ec VLM \ubca4\uce58\ub9c8\ud06c(MME, MMB, POPE, SEED, MMMU, MM-Vet, TQA, SQA-I, GQA)\uc5d0 \ub300\ud55c \uacb0\uacfc\ub85c \ub098\ud0c0\ub098\uba70, \ucd5c\uace0 \uc131\ub2a5\uc740 \uad75\uc740 \uae00\uc528\uccb4\ub85c, \ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uc131\ub2a5\uc740 \ubc11\uc904\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 mmMamba \ubaa8\ub378\uc774 \uae30\uc874 \ubaa8\ub378\ub4e4\uc5d0 \ube44\ud574 \uc5bc\ub9c8\ub098 \ud6a8\uc728\uc801\uc774\uace0 \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uacb0\uacfc"}, {"content": "| Model | LLM Backbone | Vision Encoder | Total Params | Visual Tokens | Output Tokens | Speed (tokens/s) | Total (s) |\n|---|---|---|---|---|---|---|---| \n| LLaVA-Phi | Phi-2.7B | CLIP ViT-L/14 | 3.1B | 576 | 256 | 26.92 | 9.51 |\n| MobileVLM-3B | LLaMA-2.7B | CLIP ViT-L/14 | 3.1B | 144 | 256 | 35.26 | 7.26 |\n| HoVLE | 32-layer Transformer |  | 2.6B | 768 | 256 | 33.03 | 7.75 |\n| Cobra-3.5B | Mamba-2.8B | DINOv2 + SigLIP ViT-SO | 3.5B | 729 | 256 | 99.22 | 2.58 |\n| VisualRWKV-3B | RWKV6-3B | CLIP ViT-L/14 | 3.4B | 577 | 256 | 41.34 | 6.19 |\n| mmMamba-linear | 32-layer Mamba2 |  | 2.7B | 768 | 256 | 132.43 | 1.93 |\n| mmMamba-hybrid | 24-layer Mamba2 + 8-layer Transformer |  | 2.7B | 768 | 256 | 134.77 | 1.90 |", "caption": "Table 2: Inference efficiency comparison under same multimodal prompt and fixed decode length. We compare with VLMs of the similar parameter scale (3B) across encoder-based, decoder-only, quadratic-complexity, and linear-complexity. The results highlight the speed advantage of mmMamba-linear/hybrid. The benchmark recipe directly follows Cobra, and we report the results on the same single NVIDIA RTX 4090 GPU. Note that \u201cTotal Time\u201d includes the time of both prefilling and decoding, and \u201cSpeed\u201d = \u201cOutput Tokens\u201d / \u201cTotal Time\u201d.", "description": "\ud45c 2\ub294 \ub3d9\uc77c\ud55c \ub2e4\uc911 \ubaa8\ub4dc \ud504\ub86c\ud504\ud2b8\uc640 \uace0\uc815\ub41c \ub514\ucf54\ub529 \uae38\uc774\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd94\ub860 \ud6a8\uc728\uc131\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc778\ucf54\ub354 \uae30\ubc18, \ub514\ucf54\ub354 \uc804\uc6a9, 2\ucc28 \ubcf5\uc7a1\ub3c4 \ubc0f \uc120\ud615 \ubcf5\uc7a1\ub3c4\ub97c \uac00\uc9c4 \ube44\uc2b7\ud55c \ub9e4\uac1c\ubcc0\uc218 \ud06c\uae30(3B)\uc758 VLM\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4. \uacb0\uacfc\ub294 mmMamba-linear/hybrid\uc758 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubca4\uce58\ub9c8\ud06c \ub808\uc2dc\ud53c\ub294 Cobra\ub97c \ub530\ub974\uba70, \ub2e8\uc77c NVIDIA RTX 4090 GPU\uc5d0\uc11c \uacb0\uacfc\ub97c \ubcf4\uace0\ud569\ub2c8\ub2e4. \ucd1d \uc2dc\uac04\uc5d0\ub294 \ud504\ub9ac\ud544\ub9c1 \ubc0f \ub514\ucf54\ub529 \uc2dc\uac04\uc774 \ubaa8\ub450 \ud3ec\ud568\ub418\uba70, \uc18d\ub3c4\ub294 \ucd9c\ub825 \ud1a0\ud070 \uc218 / \ucd1d \uc2dc\uac04\uc73c\ub85c \uacc4\uc0b0\ub429\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| ID | Stage1 | Stage2 | Stage3 | MME | POPE | TextVQA | SQA-I |\n|---|---|---|---|---|---|---|---| \n| 1 |  |  |  | NAN | NAN | NAN | NAN |\n| 2 | \u2713 |  |  | 969.8 | 70.6 | 13.47 | 40.8 |\n| 3 |  | \u2713 |  | 1007.1 | 72.9 | 25.5 | 52.1 |\n| 4 |  |  | \u2713 | 1188.4 | 83.0 | 40.0 | 63.4 |\n| 5 | \u2713 | \u2713 |  | 1108.9 | 75.3 | 28.0 | 59.3 |\n| 6 | \u2713 |  | \u2713 | 1263.1 | 84.0 | 42.5 | 77.1 |\n| 7 |  | \u2713 | \u2713 | 1255.5 | 83.5 | 41.1 | 72.1 |\n| 8 | \u2713 | \u2713 | \u2713 | 1303.5 | 85.2 | 47.7 | 79.2 |", "caption": "Table 3: Ablation for training stages.", "description": "\ud45c 3\uc740 \ub17c\ubb38\uc758 \ub2e4\ub2e8\uacc4 \uc99d\ub958 \ud559\uc2b5 \uacfc\uc815\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub2e8\uacc4(Stage-1, Stage-2, Stage-3)\ub97c \uc81c\uc678\ud588\uc744 \ub54c, MME, POPE, TextVQA, SQA-I \uc9c0\ud45c\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uac01 \ub2e8\uacc4\uc758 \uc911\uc694\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Stage-1\uc740 \uc0c8\ub85c \ub3c4\uc785\ub41c SSM \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \uacc4\uce35\ubcc4 \uc99d\ub958, Stage-2\ub294 \uc804\uccb4 Mamba-2 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \uacc4\uce35\ubcc4 \uc99d\ub958, Stage-3\uc740 \ucd5c\uc885 \ucd9c\ub825\uc5d0 \ub300\ud55c \uc885\ub2e8\uac04 \uc99d\ub958\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uacb0\uacfc\ub294 \uac01 \ub2e8\uacc4\uac00 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud558\ub294 \uc815\ub3c4\uc640 \uc804\uccb4\uc801\uc778 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. Experiment"}, {"content": "| Init Strategy | MME | POPE | TextVQA | SQA-I |\n|---|---|---|---|---|\n| from scratch | 1214.0 | 83.1 | 40.0 | 67.4 |\n| inherit \\boldsymbol{W}_{Q,K,V} | 1222.6 | 84.0 | 41.9 | 73.3 |\n| inherit \\boldsymbol{W}_{Q,K,V} + mimic | 1303.5 | 85.2 | 47.7 | 79.2 |", "caption": "Table 4: Ablation for parameter initialization.", "description": "\uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 \ucd08\uae30\ud654 \ubc29\ubc95\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \"from scratch\" \uc804\ub7b5\uc740 \ub9e4\uac1c\ubcc0\uc218\ub97c \ubb34\uc791\uc704\ub85c \ucd08\uae30\ud654\ud558\ub294 \ubc18\uba74, \"WQ,K,V \uc0c1\uc18d\" \uc804\ub7b5\uc740 Transformer \ub808\uc774\uc5b4\uc758 WQ, WK, WV \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0c1\uc18d\ud558\uace0, \uc81c\uc548\ub41c \ubc29\ubc95\uc740 \ucd94\uac00\uc801\uc778 \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd08\uae30\ud654\ud558\uc5ec Transformer\uc758 \ub3d9\uc791\uc744 \ubaa8\ubc29\ud569\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c, \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \ub2e4\ub978 \ucd08\uae30\ud654 \uc804\ub7b5\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Method"}, {"content": "| Attention Layers | MME | POPE | TextVQA | SQA-I |\n|---|---|---|---|---|\n| 0 | 1303.5 | 85.2 | 47.7 | 79.2 |\n| 1 | 1304.3 | 85.5 | 48.0 | 79.3 |\n| 2 | 1318.4 | 86.3 | 48.4 | 79.9 |\n| 4 | 1329.1 | 86.8 | 51.5 | 82.8 |\n| 8 | 1371.1 | 86.7 | 55.1 | 86.9 |\n| 32 | 1433.5 | 87.6 | 66.0 | 94.8 |", "caption": "Table 5: Ablation for the number of interleaved attention layers. \u201c0\u201d denotes mmMamba-pure, \u201c8\u201d denotes mmMamba-hybrid, \u201c32\u201d denotes the full Transformer model HoVLE.", "description": "\ud45c 5\ub294 mmMamba \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158 \ub808\uc774\uc5b4 \uac1c\uc218\uc758 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  mmMamba-pure\ub294 \uc21c\uc218\ud558\uac8c Mamba-2 \ub808\uc774\uc5b4\ub9cc \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc774\uace0, mmMamba-hybrid\ub294 Transformer \ub808\uc774\uc5b4\uc640 Mamba-2 \ub808\uc774\uc5b4\ub97c \uc11e\uc5b4 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, HoVLE\ub294 \ube44\uad50\ub97c \uc704\ud55c \uae30\uc900 \ubaa8\ub378\ub85c\uc11c \uc21c\uc218 Transformer \ub808\uc774\uc5b4\ub9cc \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4.  \ub808\uc774\uc5b4 \uac1c\uc218\ub97c \ubcc0\ud654\uc2dc\ud0a4\uba74\uc11c \uac01 \ubaa8\ub378\uc758 MME, POPE, TextVQA, SQA-I \uc9c0\ud45c\ub97c \uce21\uc815\ud558\uc5ec mmMamba\uc758 \ud558\uc774\ube0c\ub9ac\ub4dc \uad6c\uc870\uac00 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.  0\uc740 \uc21c\uc218 Mamba-2 \ub808\uc774\uc5b4, 8\uc740 \ud558\uc774\ube0c\ub9ac\ub4dc \uad6c\uc870 (Transformer\uc640 Mamba-2 \ub808\uc774\uc5b4 \ud63c\ud569), 32\ub294 \uc21c\uc218 Transformer \ub808\uc774\uc5b4(HoVLE)\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "5. Experiment"}, {"content": "| Hybrid strategy | MME | POPE | TextVQA | SQA-I |\n|---|---|---|---|---|\n| Tail-stacked | 1305.5 | 85.9 | 53.7 | 79.4 |\n| Head-stacked | 1329.4 | 85.9 | 55.0 | 80.8 |\n| Tail-interleaved | 1308.3 | 86.1 | 55.0 | 86.5 |\n| Head-interleaved | 1371.1 | 86.7 | 55.1 | 86.9 |", "caption": "Table 6: Ablation for hybrid strategy.", "description": "\ud45c 6\uc740 mmMamba \ubaa8\ub378\uc758 \ud558\uc774\ube0c\ub9ac\ub4dc \uad6c\uc870\uc5d0 \ub300\ud55c \ucd94\uac00 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  mmMamba\ub294 Transformer \uacc4\uce35\uacfc Mamba-2 \uacc4\uce35\uc744 \ud63c\ud569\ud558\uc5ec \uc0ac\uc6a9\ud558\ub294 \ud558\uc774\ube0c\ub9ac\ub4dc \uc544\ud0a4\ud14d\ucc98\ub97c \uac00\uc9c0\uace0 \uc788\ub294\ub370, \uc774 \ud45c\ub294 Transformer \uacc4\uce35\uc758 \ubc30\uce58 \uc804\ub7b5(Tail-stacked, Head-stacked, Tail-interleaved, Head-interleaved)\uc744 \ub2e4\ub974\uac8c \ud558\uc5ec \uc131\ub2a5 \ubcc0\ud654\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \uc804\ub7b5\uc5d0 \ub530\ub978 MME, POPE, TextVQA, SQA-I \uc9c0\ud45c\uc758 \uc131\ub2a5 \uc218\uce58\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc5b4\ub5a4 \uc804\ub7b5\uc774 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778\uc9c0, \uadf8\ub9ac\uace0 \ud558\uc774\ube0c\ub9ac\ub4dc \uc544\ud0a4\ud14d\ucc98\uc758 \uc720\uc5f0\uc131\uacfc \uc131\ub2a5-\ud6a8\uc728 \uade0\ud615\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. Experiment"}]