[{"content": "| Property | Amount |\n|---|---| \n| Questions | 100 |\n| Subquestions | 334 |\n| Subquestions per question | 3.3 |\n| Single-image questions | 93 |\n| Multi-image questions | 7 |\n| Synthetic image questions | 31 |\n| Natural image questions | 69 |", "caption": "Table 1: ZeroBench statistics.", "description": "\ud45c 1\uc740 ZeroBench \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4 \uc815\ubcf4\ub97c \uc694\uc57d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \uc9c8\ubb38\uacfc \ud558\uc704 \uc9c8\ubb38\uc758 \uc218, \uac01 \uc9c8\ubb38 \uc720\ud615(\ub2e8\uc77c \uc774\ubbf8\uc9c0, \ub2e4\uc911 \uc774\ubbf8\uc9c0)\uc758 \ubd84\ud3ec, \ud569\uc131 \uc774\ubbf8\uc9c0\uc640 \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc758 \ube44\uc728 \ub4f1\uc744 \ubcf4\uc5ec\uc8fc\uc5b4 ZeroBench \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "3. ZeroBench"}, {"content": "| Main questions (100) | Subquestions (334) |  |  |  |  |  |\n|---|---|---|---|---|---|---|\n|  | k/k [%] (n) | pass@k [%] (n) |  |  | pass@k [%] (SE<sub>CLT</sub>) | Num. correct |\n|---|---|---|---|---|---|---|\n| **Models** | k=5 | k=1 | k=5 |  | k=1 | k=1 |\n| **Reasoning LMMs** |  |  |  |  |  |  |\n| o1 pro<sup>\u22c4</sup> | 0.0 (0) | 0.0 (0) | - |  | 22.40 (2.48) | 75 |\n| o1<sup>\u22c4</sup> | 0.0 (0) | 0.0 (0) | 0.0 (0) |  | 19.93 (2.37) | 68 |\n| Gemini 2 Flash Thinking | 0.0 (0) | 0.0 (0) | **7.0 (7)** |  | 19.67 (2.67) | 67 |\n| QVQ | 0.0 (0) | 0.0 (0) | 3.0 (3) |  | 19.78 (2.42) | 66 |\n| **Proprietary LMMs** |  |  |  |  |  |  |\n| GPT-4o | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 21.18 (2.46) | 71 |\n| GPT-4o mini | 0.0 (0) | 0.0 (0) | 2.0 (2) |  | 16.98 (2.50) | 55 |\n| Gemini 2 Flash | 0.0 (0) | 0.0 (0) | 3.0 (3) |  | 22.47 (2.80) | 74 |\n| Gemini 1.5 Pro | 0.0 (0) | 0.0 (0) | 2.0 (2) |  | 20.25 (2.55) | 70 |\n| Gemini 1.5 Flash | 0.0 (0) | 0.0 (0) | 2.0 (2) |  | 18.02 (2.47) | 63 |\n| Gemini 1 Pro Vision | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 12.17 (2.19) | 44 |\n| Claude 3.5 Sonnet v2 | 0.0 (0) | 0.0 (0) | 2.0 (2) |  | **24.30 (2.73)** | **81** |\n| Claude 3.5 Sonnet | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 19.73 (2.49) | 68 |\n| Claude 3 Opus | 0.0 (0) | 0.0 (0) | 0.0 (0) |  | 14.50 (2.27) | 46 |\n| Claude 3 Sonnet | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 16.25 (2.33) | 49 |\n| Claude 3 Haiku | 0.0 (0) | 0.0 (0) | 0.0 (0) |  | 12.12 (2.11) | 40 |\n| Reka Edge | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 3.38 (0.97) | 12 |\n| **Open-weight LMMs** |  |  |  |  |  |  |\n| Llama 3.2 90B | 0.0 (0) | 0.0 (0) | 0.0 (0) |  | 13.07 (1.97) | 47 |\n| Qwen2-VL-72B-Instruct | 0.0 (0) | 0.0 (0) | 2.0 (2) |  | 11.90 (2.24) | 37 |\n| NVLM-D-72B | 0.0 (0) | 0.0 (0) | 1.0 (1) |  | 13.78 (2.32) | 46 |\n| Pixtral-Large | 0.0 (0) | 0.0 (0) | 3.0 (3) |  | 13.50 (2.01) | 49 |", "caption": "Table 2: Overall results on ZeroBench. We report pass@1 using greedy decoding and k/k reliability and pass@5 using stochastic decoding. For a set of k sampled responses, pass@k is evaluated as correct if at least one response is correct; k/k reliability is evaluated as correct if all responses are correct; \u22c4all responses are sampled using default model settings.", "description": "\ud45c 2\ub294 ZeroBench\uc5d0 \ub300\ud55c 20\uac1c\uc758 \ucd5c\ucca8\ub2e8 \ub2e4\uc911 \ubaa8\ub4dc \uc5b8\uc5b4 \ubaa8\ub378(LMM)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  greedy decoding\uc744 \uc0ac\uc6a9\ud55c pass@1 \uc815\ud655\ub3c4\uc640 k/k \uc2e0\ub8b0\ub3c4, \uadf8\ub9ac\uace0 stochastic decoding\uc744 \uc0ac\uc6a9\ud55c pass@5 \uc815\ud655\ub3c4\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4. k\uac1c\uc758 \uc0d8\ud50c \uc751\ub2f5\uc5d0 \ub300\ud574 pass@k\ub294 \uc801\uc5b4\ub3c4 \ud558\ub098\uc758 \uc751\ub2f5\uc774 \uc815\ud655\ud558\uba74 \uc815\ub2f5\uc73c\ub85c \ud3c9\uac00\ub418\uace0, k/k \uc2e0\ub8b0\ub3c4\ub294 \ubaa8\ub4e0 \uc751\ub2f5\uc774 \uc815\ud655\ud574\uc57c \uc815\ub2f5\uc73c\ub85c \ud3c9\uac00\ub429\ub2c8\ub2e4. \ubaa8\ub4e0 \uc751\ub2f5\uc740 \ubaa8\ub378\uc758 \uae30\ubcf8 \uc124\uc815\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub429\ub2c8\ub2e4. \ud45c\ub294 \uac01 \ubaa8\ub378\uc758 \uc8fc\uc694 \uc9c8\ubb38\uacfc \ud558\uc704 \uc9c8\ubb38\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uace0,  \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.1 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Model | #tkns (Main questions) | Cost ($)<sup>\u2217</sup> (Main questions) | #tkns (Subquestions) | Cost ($)<sup>\u2217</sup> (Subquestions) |\n|---|---|---|---|---|\n| **Avg. per question** |  |  |  |  |\n|  | **Main questions** |  | **Subquestions** |  |\n| **Reasoning LMMs** |  |  |  |  |\n| o1 pro<sup>\u22c4</sup> | - | - | - |  |\n| o1<sup>\u22c4</sup> | 7345 | 0.463 | 3749 | 0.236 |\n| Gemini 2 Flash Thinking<sup>\u2217\u2217</sup> | 520 | - | 228 | - |\n| QVQ | 2794 | 0.003 | 1741 | 0.002 |\n| **Proprietary LMMs** |  |  |  |  |\n| GPT-4o | 452 | 0.005 | 228 | 0.002 |\n| GPT-4o mini | 896 | <0.001 | 214 | <0.001 |\n| Gemini 2 Flash | 1267 | 0.013 | 490 | 0.005 |\n| Gemini 1.5 Pro | 266 | 0.002 | 114 | <0.001 |\n| Gemini 1.5 Flash | 276 | <0.001 | 122 | <0.001 |\n| Gemini 1 Pro Vision | 211 | <0.001 | 99 | <0.001 |\n| Claude 3.5 Sonnet v2 | 254 | 0.004 | 163 | 0.003 |\n| Claude 3.5 Sonnet | 294 | 0.005 | 217 | 0.003 |\n| Claude 3 Opus | 267 | 0.021 | 168 | 0.013 |\n| Claude 3 Sonnet | 279 | 0.004 | 175 | 0.003 |\n| Claude 3 Haiku | 315 | <0.001 | 132 | <0.001 |\n| Reka Edge<sup>\u2217\u2217</sup> | 514 | - | 189 | - |\n| **Open-weight LMMs** |  |  |  |  |\n| Llama 3.2 90B | 663 | 0.001 | 264 | <0.001 |\n| Qwen2-VL-72B-Instruct | 457 | 0.001 | 476 | <0.001 |\n| NVLM-D-72B<sup>\u2217\u2217</sup> | 389 | - | 151 | - |\n| Pixtral-Large | 553 | <0.001 | 279 | <0.001 |", "caption": "Table 3: Average per question cost and number of completion tokens generated during greedy decoding. \u2217calculated based on AI/ML API pricing (API, 2025); \u2217\u2217cost data unavailable; \u22c4responses sampled using default model settings.", "description": "\ud45c 3\uc740 \uac01 \uc9c8\ubb38\ub2f9 \ud3c9\uade0 \ube44\uc6a9\uacfc \ud0d0\uc695\uc801 \ub514\ucf54\ub529 \uc911\uc5d0 \uc0dd\uc131\ub41c \uc644\ub8cc \ud1a0\ud070 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\uc6a9\uc740 AI/ML API \uac00\uaca9 \ucc45\uc815(API, 2025)\uc744 \uae30\ubc18\uc73c\ub85c \uacc4\uc0b0\ub418\uc5c8\uc73c\uba70, \uc77c\ubd80 \ubaa8\ub378\uc758 \uacbd\uc6b0 \ube44\uc6a9 \ub370\uc774\ud130\ub97c \uad6c\ud560 \uc218 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.  \ubaa8\ub4e0 \uc751\ub2f5\uc740 \ubaa8\ub378\uc758 \uae30\ubcf8 \uc124\uc815\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0d8\ud50c\ub9c1\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc989, \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc9c8\ubb38\uc5d0 \ub300\ud55c \uc751\ub2f5\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \ub4dc\ub294 \ube44\uc6a9\uacfc \uacc4\uc0b0\ub7c9\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud0d0\uc695\uc801 \ub514\ucf54\ub529 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud588\uace0, \ubaa8\ub378\uc758 \uae30\ubcf8 \uc124\uc815\uc744 \uc0ac\uc6a9\ud588\uae30 \ub54c\ubb38\uc5d0, \uac01 \ubaa8\ub378\uc758 \uc751\ub2f5 \uc0dd\uc131 \ud6a8\uc728\uc131\uc744 \ube44\uad50\ud558\ub294 \ub370 \uc720\uc6a9\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5.2 Completion Tokens"}, {"content": "| Model | Greedy Decoding | Stochastic Decoding | Max. Completion Tokens. |\n|---|---|---|---| \n| o1 pro | - | - | - |\n| o1 | seed=42, reasoning_effort=\u2018medium\u2019 | seed=42, reasoning_effort=\u2018medium\u2019 | 100k |\n| GPT-4o | temperature=0, seed=42 | temperature=0.7, top_p=0.95, seed=42 | 16k |\n| GPT-4o mini | temperature=0, seed=42 | temperature=0.7, top_p=0.95, seed=42 | 16k |\n| Gemini 2 Flash Thinking | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 65k |\n| Gemini 2 Flash | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Gemini 1.5 Pro | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Gemini 1.5 Flash | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Gemini 1 Pro Vision | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 2k |\n| Claude 3.5 Sonnet v2 | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Claude 3.5 Sonnet | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Claude 3 Opus | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 4k |\n| Claude 3 Sonnet | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 4k |\n| Claude 3 Haiku | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 4k |\n| Pixtral-Large | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 32k |\n| Reka Edge | temperature=0, top_k=1, seed=42 | temperature=0.7, top_p=0.95 | 32k |\n| QVQ | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 32k |\n| Llama 3.2 90B | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 8k |\n| Qwen2-VL-72B-Instruct | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 32k |\n| NVLM-D-72 B | temperature=0, top_k=1 | temperature=0.7, top_p=0.95 | 32k |", "caption": "Table 4: Hyperparameters used in each decoding setting. Note, o1 pro was accessed through the ChatGPT interface preventing hyperparameter configuration.", "description": "\ud45c 4\ub294 \uac01 \ub514\ucf54\ub529 \uc124\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Greedy \ub514\ucf54\ub529\uacfc Stochastic \ub514\ucf54\ub529\uc5d0 \uc0ac\uc6a9\ub41c temperature, top_k, top_p, seed \uac12 \ub4f1\uc774 \ubaa8\ub378\ubcc4\ub85c \uc790\uc138\ud788 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. ChatGPT \uc778\ud130\ud398\uc774\uc2a4\ub97c \ud1b5\ud574 \uc811\uadfc\ud588\uae30 \ub54c\ubb38\uc5d0 o1 pro \ubaa8\ub378\uc758 \uacbd\uc6b0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc774 \ubd88\uac00\ub2a5\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\ub294 \ubaa8\ub378\uc758 \ub514\ucf54\ub529 \ubc29\uc2dd\uacfc \uad00\ub828 \uc124\uc815\uc5d0 \ub300\ud55c \uc0c1\uc138 \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uc5ec \uc2e4\ud5d8\uc758 \uc7ac\ud604\uc131\uc744 \ub192\uc774\uace0, \uacb0\uacfc \ud574\uc11d\uc5d0 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4. Experimental Setup"}]