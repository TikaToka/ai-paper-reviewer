[{"content": "| Method | Iter. 1 | Iter. 2 | Iter. 3 |\n|---|---|---|---|\n| w/o reflect | 58.2 | 74.4 | **77.8** |\n| w/o reflect@test | 64.4 | 76.0 | **82.2** |\n| reflect w/ diffusion | 66.2 | 75.8 | **82.4** |\n| reflect w/ sim | 66.8 | 75.4 | **85.4** |", "caption": "Table 1: Post-training performance Success rates (%) of post-training variants over the number of iterations.", "description": "\uc774 \ud45c\ub294 \ubcf8 \ub17c\ubb38\uc758 \ubc18\ubcf5\uc801\uc778 \ud559\uc2b5(post-training) \uacfc\uc815\uc5d0\uc11c, \ub2e4\uc591\ud55c \ubcc0\ud615 \ubaa8\ub378\ub4e4\uc758 \uc131\uacf5\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ubaa8\ub378 \ubcc0\ud615(\ubc18\uc0ac \uba54\ucee4\ub2c8\uc998 \uc5c6\uc74c, \ubc18\uc0ac \uba54\ucee4\ub2c8\uc998 \uc0ac\uc6a9(\ud655\uc0b0 \uc5ed\ud559 \ubaa8\ub378 \ud3ec\ud568),  \ubc18\uc0ac \uba54\ucee4\ub2c8\uc998 \uc0ac\uc6a9(\uc2dc\ubbac\ub808\uc774\ud130 \ud3ec\ud568)) \uc5d0 \ub300\ud574, \ubc18\ubcf5 \ud69f\uc218(Iter)\uc5d0 \ub530\ub978 \uc131\uacf5\ub960(%) \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uc5b4,  \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ub300\ud55c  \ubc18\uc0ac \uba54\ucee4\ub2c8\uc998\uc758 \ud6a8\uacfc\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uac01 \ubc18\ubcf5 \ud69f\uc218\ub9c8\ub2e4\uc758 \uc131\uacf5\ub960\uc744 \uc81c\uc2dc\ud558\uc5ec,  \ud559\uc2b5\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \uc131\uacf5\ub960\uc774 \uc5b4\ub5bb\uac8c \uc99d\uac00\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Method | Inference time (s) |\n|---|---| \n| Ours w/o reflect@test | 0.45 |\n| Ours w/ diffusion | 11.10 |\n| Ours w/ sim | 6.05 |\n| MCTS | 391.42 |", "caption": "Table 2: Inference computation cost. Inference wall clock time per step. MCTS result is averaged over 100 tasks and 1 seed; the others are averaged over 100 tasks and 5 seeds. All experiments are done on a single A100 GPU.", "description": "\ud45c 2\ub294 \ucd94\ub860 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc5d0 \ub530\ub978 \ub2e8\uacc4\ubcc4 \ucd94\ub860\uc5d0 \uac78\ub9ac\ub294 \uc2dc\uac04\uc744 \uce21\uc815\ud558\uc600\uc2b5\ub2c8\ub2e4. MCTS \uacb0\uacfc\ub294 100\uac1c\uc758 \uc791\uc5c5\uacfc 1\uac1c\uc758 \uc2dc\ub4dc\uc5d0 \ub300\ud574 \ud3c9\uade0\uc744 \ub0b8 \uac83\uc774\uace0, \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc740 100\uac1c\uc758 \uc791\uc5c5\uacfc 5\uac1c\uc758 \uc2dc\ub4dc\uc5d0 \ub300\ud574 \ud3c9\uade0\uc744 \ub0b8 \uac83\uc785\ub2c8\ub2e4. \ubaa8\ub4e0 \uc2e4\ud5d8\uc740 \ub2e8\uc77c A100 GPU\uc5d0\uc11c \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc989, \ubcf8 \ud45c\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \uae30\uc874 \ubc29\ubc95\ub4e4\uc758 \ucd94\ub860 \uc18d\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Res | LoRA | Training | Batch | Optimizer | Warmup | Learning rate | Weight | LR | \n|---|---|---|---|---|---|---|---|---|\n| 336px | 128 | 1 | 128 | AdamW | 0.03 | 5e-5 | 0.0 | Cosine |", "caption": "Table 3: Training parameters of VLM.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 4.1\uc808\uc778 \"Interactive VLM Policy Post-Training\" \uc5d0\uc11c Vision-Language Model (VLM)\uc758 \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VLM\uc740 \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub294 \ubaa8\ub378\uc774\uba70, \uc774 \ud45c\ub294 VLM\uc758 \ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc744 \uc704\ud574 LoRA(Low-Rank Adaptation) \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc77c\ubd80 \ub808\uc774\uc5b4\ub9cc \ubbf8\uc138\uc870\uc815(fine-tuning) \ud588\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294 LoRA \ub808\uc774\uc5b4\uc758 Rank, \ud559\uc2b5 \uc5d0\ud3ed \uc218, \ubc30\uce58 \ud06c\uae30, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \uc6dc\uc5c5 \uc5d0\ud3ed, \ud559\uc2b5\ub960, \uac00\uc911\uce58 \uac10\uc1e0, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec \ub4f1\uc758 \uc138\ubd80 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  336\ud53d\uc140 \ud574\uc0c1\ub3c4\uc758 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud588\uace0, LoRA \ub808\uc774\uc5b4\uc758 Rank\ub294 128\ub85c \uc124\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4. AdamW \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud588\uace0, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec\ub294 Cosine \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.", "section": "4. Reflective Planning with Vision Language Models"}, {"content": "| Model | Res | Training Steps | Batch Size | Optimizer | Warmup Steps | Learning Rate | Weight Decay | Beta1, Beta2 | Grad Norm | LR Schedule |\n|---|---|---|---|---|---|---|---|---|---|---|\n| UNet | 512px | 20K | 640 | AdamW | 2K | 1e-4 | 0.01 | 0.9, 0.999 | 1.0 | Cosine |\n| Decoder | 512px | 4K | 160 | AdamW | 1K | 1e-7 | 0.01 | 0.9, 0.999 | 1.0 | Cosine |", "caption": "Table 4: Training parameters of Diffusion Dynamics Models.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 4.2\uc808 \"\ud655\uc0b0 \uc5ed\ud559 \ubaa8\ub378\"\uc5d0\uc11c \ud655\uc0b0 \uc5ed\ud559 \ubaa8\ub378(Diffusion Dynamics Model)\uc758 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378\uc758 \ud574\uc0c1\ub3c4(Res), \ucd5c\uc801\ud654 \uae30\ubc95(Optimizer), \ud559\uc2b5 \ubc18\ubcf5 \ud69f\uc218(Training Steps), \ubc30\uce58 \ud06c\uae30(Batch Size), \uc6dc\uc5c5 \uc5d0\ud3ed(Warmup Epoch), \ud559\uc2b5\ub960(Learning Rate), \uac00\uc911\uce58 \uac10\uc1e0(Weight Decay), \ubca0\ud0c01(Beta1), \ubca0\ud0c02(Beta2), \uadf8\ub808\uc774\ub514\uc5b8\ud2b8 \uc815\uaddc\ud654(Grad Norm), \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec(LR Schedule) \ub4f1\uc758 \uc138\ubd80\uc801\uc778 \ud559\uc2b5 \uc124\uc815\uac12\uc744 \ubcf4\uc5ec\uc8fc\uc5b4, \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ubaa8\ub378\uc758 \ud559\uc2b5 \uacfc\uc815\uc744 \uc790\uc138\ud788 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788, UNet\uacfc \ub514\ucf54\ub354(Decoder)\uc758 \uc124\uc815\uc774 \uac01\uac01 \ub2e4\ub974\uac8c \uc81c\uc2dc\ub418\uc5b4, \ubaa8\ub378 \uad6c\uc870\uc758 \ud2b9\uc9d5\uc744 \ud30c\uc545\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4. Diffusion Dynamics Model"}, {"content": "| Model | Success Trajectory ID / Planing Steps | Max Steps | Min Steps | Avg Steps |\n|---|---|---|---|---|\n| Gemini-2.0 | 5/6, 12/4, 16/18, 47/11, 60/4, 86/6 | 18 | 4 | 8.2 |\n| Gemini-2.0-Thinking | 5/6, 12/4, 40/20, 47/16, 50/8, 60/8, 86/10, 90/11 | 20 | 4 | 10.4 |\n| GPT-4o | 12/15, 16/5, 19/4, 47/10, 60/4, 90/6 | 15 | 4 | 7.3 |\n| GPT-o1 | 12/9, 16/6, 17/15, 47/8, 50/16, 58/18, 60/14, 62/33, 66/6, 67/12, 72/32, 77/9, 85/9, 86/6, 90/4 | 33 | 4 | 13.1 |", "caption": "Table 5: Detailed evaluation results of zero-shot VLMs.", "description": "\ud45c 5\ub294 \uc601\ubb38 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub2e4\uc591\ud55c \uc601\uc0c1-\uc5b8\uc5b4 \ubaa8\ub378(VLMs)\uc758 \uc81c\ub85c\uc0f7(zero-shot) \uc131\ub2a5 \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378(Gemini-2.0, Gemini-2.0-Thinking, GPT-40, GPT-01)\uc5d0 \ub300\ud574 \uc131\uacf5\uc801\uc778 \uc791\uc5c5 \uc218\ud589 \ud69f\uc218\uc640 \uadf8\uc5d0 \ub530\ub978 \uacc4\ud68d \ub2e8\uacc4 \uc218\ub97c \uc790\uc138\ud788 \uc81c\uc2dc\ud558\uc5ec \ubaa8\ub378\ubcc4 \uc131\ub2a5 \ucc28\uc774\ub97c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc131\uacf5\ub960, \uacc4\ud68d \ub2e8\uacc4\uc758 \ucd5c\ub300\uac12, \ucd5c\uc18c\uac12, \ud3c9\uade0\uac12 \ub4f1\uc758 \ub2e4\uc591\ud55c \uc9c0\ud45c\ub97c \ud1b5\ud574 \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubcf4\ub2e4 \uba85\ud655\ud558\uac8c \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \uc0c1\uc138\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "6. Experiments"}]