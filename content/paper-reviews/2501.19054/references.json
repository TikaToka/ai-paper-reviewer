{"references": [{"fullname_first_author": "Brown, T. B.", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-07-00", "reason": "This paper is foundational to the use of LLMs as the backbone for text-to-CAD generation, demonstrating the effectiveness of LLMs in few-shot learning settings."}, {"fullname_first_author": "Khan, M. S.", "paper_title": "Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts", "publication_date": "2024-09-00", "reason": "This paper is a direct precursor to the current work, introducing a text-based approach to CAD generation that is further improved upon by the authors."}, {"fullname_first_author": "Xu, X.", "paper_title": "Hierarchical Neural Coding for Controllable CAD Model Generation", "publication_date": "2023-06-00", "reason": "This paper contributes the dataset used in the current work, providing the ground truth data necessary for training the model."}, {"fullname_first_author": "Radford, A.", "paper_title": "Learning Transferable Visual Models from Natural Language Supervision", "publication_date": "2021-03-00", "reason": "This paper provides the foundation for the use of vision-language models (VLMs) to score CAD designs, a crucial component of the proposed visual feedback stage."}, {"fullname_first_author": "Rafailov, R.", "paper_title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "publication_date": "2024-05-00", "reason": "This paper introduces direct preference optimization (DPO), a key technique used to address the non-differentiable rendering pathway in the visual feedback stage."}]}