[{"content": "| Model | Eurus-2-7B-PRIME | Qwen2.5-Math-7B-Instruct |\n|---|---|---|\n| Base Model | Qwen2.5-Math-7B | Qwen2.5-Math-7B |\n| SFT Data | 230K (open-source) | 2.5M (open-source & in-house) |\n| RM Data | 0 | 618K (in-house) |\n| RM | Eurus-2-7B-SFT | Qwen2.5-Math-RM (72B) |\n| RL Data | 150K queries \u00d7 4 samples | 66K queries \u00d7 32 samples |", "caption": "Table 1: The comparison of resource requirements between Eurus-2-7B-PRIME and Qwen2.5-Math-7B-Instruct.", "description": "\ud45c 1\uc740 Eurus-2-7B-PRIME\uacfc Qwen2.5-Math-7B-Instruct \ubaa8\ub378 \ud559\uc2b5\uc5d0 \ud544\uc694\ud55c \uc790\uc6d0(\uae30\ubc18 \ubaa8\ub378, SFT \ub370\uc774\ud130, RM \ub370\uc774\ud130, RM, RL \ub370\uc774\ud130)\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  Eurus-2-7B-PRIME \ubaa8\ub378\uc740 Qwen2.5-Math-7B \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c \ud558\uba70, \uc0c1\ub300\uc801\uc73c\ub85c \uc801\uc740 \uc591\uc758 SFT \ub370\uc774\ud130\uc640 RL \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9\ud558\uc5ec Qwen2.5-Math-7B-Instruct \ubaa8\ub378\ubcf4\ub2e4 \ud6e8\uc52c \ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc774 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, PRIME\uc740 \ubcc4\ub3c4\uc758 RM \ud559\uc2b5 \ub2e8\uacc4\uac00 \ud544\uc694 \uc5c6\uc5b4 \uac1c\ubc1c \uc624\ubc84\ud5e4\ub4dc\ub97c \ud06c\uac8c \uc904\uc77c \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "1 INTRODUCTION"}, {"content": "| Method | Step | AIME 2024 | AMC | MATH-500 | MinervaMath | OlympiadBench | LeetCode | LiveCodeBench | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| **GPT-4o** | - | 9.3 | 45.8 | 76.4 | 36.8 | 43.3 | 58.9 | 48.8 | 45.6 |\n| **Llama-3.1-70B-Inst.** | - | 20.0 | 37.3 | 65.0 | 37.1 | 30.5 | 35.0 | 34.4 | 37.0 |\n| **Qwen2.5-Math-7B-Inst.** | - | 13.3 | 50.6 | 79.8 | 34.6 | 40.7 | 11.7 | 11.3 | 34.6 |\n| **Eurus-2-7B-SFT** | 0 | 3.3 | 30.1 | 66.2 | 32.7 | 29.8 | 21.7 | 17.8 | 28.8 |\n| **RLOO w/ OV Only** | 240 | 20.0 | 47.0 | 73.2 | 36.4 | 35.4 | 28.3 | 26.7 | 36.9 |\n|  | 80 | 20.0 | 41.0 | 68.2 | 38.2 | 37.0 | 26.7 | 26.6 | 36.8 |\n|  | 160 | 13.3 | 42.2 | 72.0 | 37.1 | 38.7 | 26.7 | 25.6 | 36.5 |\n|  | 240 | 20.0 | 50.6 | 78.2 | 39.3 | 40.3 | 31.1 | 27.5 | 41.0 |\n|  | 320 | 16.7 | 51.8 | 77.8 | 39.7 | 41.5 | 36.1 | 28.5 | 41.7 |\n| **Eurus-2-7B-PRIME** | 592 | 26.7 | 57.8 | 79.2 | 38.6 | 42.1 | 33.3 | 28.6 | 43.9 |", "caption": "Table 2: Detailed results of PRIME and RLOO w/ outcome verifier (OV). At the same 240 steps, the model trained by PRIME is generally better than the model trained by outcome rewards.", "description": "\ud45c 2\ub294 PRIME\uacfc \uacb0\uacfc \uac80\uc99d\uc790(OV)\ub97c \uc0ac\uc6a9\ud55c RLOO\uc758 \uc0c1\uc138 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc77c\ud55c 240\ub2e8\uacc4\uc5d0\uc11c PRIME\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc774 \uacb0\uacfc \ubcf4\uc0c1\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\ubcf4\ub2e4 \uc804\ubc18\uc801\uc73c\ub85c \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc218\ud559 \uad00\ub828 \ubca4\uce58\ub9c8\ud06c(AIME 2024, AMC, MATH-500, Minerva Math, OlympiadBench, LeetCode, LiveCodeBench)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4(%)\ub97c \ube44\uad50\ud558\uc5ec PRIME\uc758 \ud6a8\uc728\uc131\uacfc \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Method | Step | AIME 2024 | AMC | MATH-500 | MinervaMath | OlympiadBench | LeetCode | LiveCodeBench | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| **RLOO** | 240 | 20.0 | 47.0 | 73.2 | 36.4 | 35.4 | 28.3 | 26.7 | 36.9 |\n| **RLOO w/ PRIME** | 240 | 20.0 | 50.6 | 78.2 | 39.3 | 40.3 | 31.1 | 27.5 | 41.0 |\n| **REINFORCE** | 240 | 6.7 | 47.0 | 72.6 | 36.0 | 37.2 | 27.2 | 25.0 | 36.0 |\n| **REINFORCE w/ PRIME** | 240 | 6.7 | 50.0 | 76.4 | 36.8 | 39.1 | 27.8 | 27.5 | 37.8 |\n| **GRPO** | 240 | 10.0 | 44.6 | 73.2 | 37.5 | 36.6 | 25.0 | 25.8 | 36.1 |\n| **GRPO w/ PRIME** | 240 | 16.7 | 47.0 | 75.0 | 34.9 | 38.2 | 28.9 | 23.9 | 37.8 |\n| **PPO** | 240 | 10.0 | 41.0 | 73.6 | 36.0 | 36.3 | 28.3 | 25.7 | 35.8 |\n| **PRIME as Value Model** | 240 | 16.7 | 44.6 | 72.6 | 34.6 | 35.7 | 27.8 | 24.6 | 36.6 |\n| **PPO w/ PRIME** | 240 | 13.3 | 50.6 | 77.4 | 37.1 | 40.6 | 30.0 | 26.7 | 39.4 |", "caption": "Table 3: Testset results of different RL algorithms.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc5d0 \ub300\ud55c \ud14c\uc2a4\ud2b8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  PRIME(Process Reinforcement through IMplicit rEwards) \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 REINFORCE, GRPO, PPO \uc54c\uace0\ub9ac\uc998\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uacfc \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \uc131\ub2a5\uc740 AIME 2024, AMC, MATH-500, Minerva Math, OlympiadBench, LeetCode, LiveCodeBench \ub4f1 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ud3c9\uac00\ub429\ub2c8\ub2e4.  \ud45c\ub294 \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uba70, PRIME\uc774 \ub2e4\ub978 \uc54c\uace0\ub9ac\uc998\uc5d0 \ube44\ud574 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uac00\uc838\uc654\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Action Name | Description |\n|---|---| \n| **ASSESS** | Analyze current situation, identify key elements and goals |\n| **ADVANCE** | Move forward with reasoning - calculate, conclude, or form hypothesis |\n| **VERIFY** | Check accuracy of current approach, look for errors |\n| **SIMPLIFY** | Break complex problems into simpler parts |\n| **SYNTHESIZE** | Combine multiple pieces of information into complete solution |\n| **PIVOT** | Change strategy when current approach isn\u2019t working |\n| **OUTPUT** | Summarize thought process and present final answer |", "caption": "Table 4: Actions in action-centric chain-of-thought reasoning framework.", "description": "\uc774 \ud45c\ub294 \ud589\ub3d9 \uc911\uc2ec\uc801 \uc0ac\uace0 \uacfc\uc815 \ucd94\ub860 \ud504\ub808\uc784\uc6cc\ud06c\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \ud589\ub3d9\ub4e4\uc744 \uc124\uba85\ud569\ub2c8\ub2e4. \uac01 \ud589\ub3d9\uc740 \ucd94\ub860 \uacfc\uc815\uc758 \ud2b9\uc815 \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0b4\uba70, \ubb38\uc81c \ud574\uacb0 \uacfc\uc815 \uc804\ubc18\uc5d0 \uac78\uccd0 \ubb38\uc81c \ud3c9\uac00, \ud574\uacb0 \ubc29\uc548 \ubaa8\uc0c9, \uc815\ud655\uc131 \uac80\uc99d, \ubb38\uc81c \ub2e8\uc21c\ud654, \uc815\ubcf4 \ud1b5\ud569, \uc804\ub7b5 \uc218\uc815, \ucd5c\uc885 \ub2f5\ubcc0 \uc81c\uc2dc \ub4f1\uc758 \uc5ed\ud560\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.", "section": "4.1 IMITATION WARMUP"}, {"content": "| Task | Dataset | Size | Avg. Response Length | Source |\n|---|---|---|---|---|\n| Math | MathInstruct-MATH (Yue et al., 2023) | 12715 | 964.01 | https://huggingface.co/datasets/TIGER-Lab/MathInstruct |\n|  | OpenMathIns-2-Aug_Math (Toshniwal et al., 2024) | 15086 | 1202.25 | https://huggingface.co/datasets/nvidia/OpenMathInstruct-2 |\n|  | Numina (Li et al., 2024) | 55845 | 1331.61 | https://huggingface.co/datasets/AI-MO/NuminaMath-CoT |\n|  | Reasoning-001 (SkunkworksAI, 2024) | 29831 | 1316.49 | https://huggingface.co/datasets/SkunkworksAI/reasoning-0.01 |\n| Coding | Code-Feedback (Zheng et al., 2024) | 27663 | 1805.16 | https://huggingface.co/datasets/m-a-p/Code-Feedback |\n|  | Magicoder (Wei et al., 2024) | 24480 | 1828.72 | https://huggingface.co/datasets/ise-uiuc/Magicoder-Evol-Instruct-110K |\n|  | Magicoder-OSS (Wei et al., 2024) | 28980 | 1850.05 | https://huggingface.co/datasets/ise-uiuc/Magicoder-OSS-Instruct-75K |\n| Biomedicine | UltraMedical_mc (Zhang et al., 2024) | 35163 | 891.06 | https://huggingface.co/datasets/TsinghuaC3I/UltraMedical |\n| Total / Avg. | - | 229763 | 1390.75 | - |", "caption": "Table 5: Data statistics of SFT data.", "description": "\ubcf8 \ud45c\ub294 \ub17c\ubb38\uc758 SFT(Supervised Fine-Tuning) \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b\uc758 \uc774\ub984, \ud06c\uae30, \ud3c9\uade0 \uc751\ub2f5 \uae38\uc774, \ucd9c\ucc98, \uadf8\ub9ac\uace0 \ub370\uc774\ud130\uc14b\uc774 \uc218\ud589\ud558\ub294 \uc791\uc5c5(\uc218\ud559, \ucf54\ub529, \uc0dd\uc758\ud559)\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.  SFT \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \uacf5\uac1c \ub370\uc774\ud130\uc14b\uc744 \uacb0\ud569\ud558\uc5ec \uad6c\uc131\ub418\uc5c8\uc73c\uba70, \ucd1d 229,763\uac1c\uc758 \ub370\uc774\ud130\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud3c9\uade0 \uc751\ub2f5 \uae38\uc774\ub294 1390 \ud1a0\ud070\uc785\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ucd9c\ucc98 URL\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 Imitation Warmup"}, {"content": "| Dataset | Generator Model | Num. Inst | Resp/Inst | Step-level/Response-level |\n|---|---|---|---|---|\n| UltraInteract | Llama-3.1-8B-Inst | 20177 | 8 | Response-level |\n|  | Llama-3.1-8B-Base | 13570 | 8 | Response-level |\n|  | Qwen2.5-72B-Inst | 4758 | 8 | Response-level |\n|  | Qwen2.5-Math-7B-Base | 25713 | 8 | Response-level |\n| Numina-SynMath | Llama-3.1-8B-Inst | 4783 | 8 | Response-level |\n|  | Qwen2.5-Math-7B-Base | 5806 | 8 | Response-level |\n| Numina-Olympiads | Llama-3.1-8B-Inst | 2909 | 8 | Response-level |\n|  | Qwen2.5-Math-7B-Base | 4739 | 8 | Response-level |", "caption": "Table 6: Data statistics of EurusPRM training dataset.", "description": "\ud45c 6\uc740 EurusPRM\uc774\ub77c\ub294 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  EurusPRM \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubaa8\ub378(Llama-3.1-8B-Inst, Llama-3.1-8B-Base, Qwen2.5-72B-Inst, Qwen2.5-Math-7B-Base)\ub85c \uc0dd\uc131\ub418\uc5c8\uc73c\uba70, \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30(Num. Inst), \uac01 \uc778\uc2a4\ud134\uc2a4 \ub2f9 \uc751\ub2f5 \uac1c\uc218(Resp/Inst), \uadf8\ub9ac\uace0 \ud3c9\uac00 \ubc29\uc2dd\uc774 \uc2a4\ud15d \ub808\ubca8\uc778\uc9c0 \uc751\ub2f5 \ub808\ubca8\uc778\uc9c0(Step-level/Response-level) \ub4f1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b\uc740 \uc5ec\ub7ec \ub2e4\ub978 \uc18c\uc2a4 (UltraInteract, Numina-SynMath, Numina-Olympiads)\uc5d0\uc11c \uc218\uc9d1\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 EurusPRM \ubaa8\ub378\uc758 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \ud2b9\uc131\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "B.5 PRM DATA"}]