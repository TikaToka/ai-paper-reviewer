[{"figure_path": "https://arxiv.org/html/2502.09838/x2.png", "caption": "Figure 1: HealthGPT enables medical multi-modal comprehension and generation, outperforming both state-of-the-art unified visual models and medical-specific models across various tasks. This highlights its superior capability in tackling complex tasks in healthcare applications. Comp.Perf. and Gen.Perf. denote the results of comprehension and generation.", "description": "\uadf8\ub9bc 1\uc740 HealthGPT\uac00 \ub2e4\uc591\ud55c \uc758\ub8cc \uad00\ub828 \uacfc\uc81c\uc5d0\uc11c \ucd5c\ucca8\ub2e8 \ud1b5\ud569 \ube44\uc8fc\uc5bc \ubaa8\ub378 \ubc0f \uc758\ub8cc \ud2b9\ud654 \ubaa8\ub378\uc744 \ub2a5\uac00\ud558\ub294 \uc758\ub8cc \ub2e4\uc911 \ubaa8\ub4dc \uc774\ud574 \ubc0f \uc0dd\uc131 \uae30\ub2a5\uc744 \uc9c0\uc6d0\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf5\uc7a1\ud55c \uc758\ub8cc \uad00\ub828 \uacfc\uc81c\ub97c \ud574\uacb0\ud558\ub294 HealthGPT\uc758 \ub6f0\uc5b4\ub09c \ub2a5\ub825\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. Comp.Perf. \uc640 Gen.Perf. \ub294 \uac01\uac01 \uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.09838/extracted/6211206/fig/HealthGPT_Framework.png", "caption": "Figure 2: With a fixed amount of comprehension (generation) data, increasing the proportion of the other type leads to significant performance degradation.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc774\ud574(generation) \ub370\uc774\ud130\uc758 \uc591\uc744 \uace0\uc815\ud558\uace0 \ub2e4\ub978 \uc720\ud615\uc758 \ub370\uc774\ud130 \ube44\uc728\uc744 \ub192\uc77c \uacbd\uc6b0 \uc131\ub2a5\uc774 \ud06c\uac8c \uc800\ud558\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989,  \uc774\ud574\uc640 \uc0dd\uc131 \uc791\uc5c5\uc744 \ub3d9\uc2dc\uc5d0 \ud559\uc2b5\uc2dc\ud0a4\ub294 \ubaa8\ub378\uc5d0\uc11c \ud55c\ucabd \ub370\uc774\ud130\ub9cc \ub9ce\uc774 \uc0ac\uc6a9\ud558\uba74 \ub2e4\ub978 \ucabd \uc791\uc5c5\uc758 \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc9c4\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \ud604\uc0c1\uc740 \uc790\ub3d9 \ud68c\uadc0 \ubc29\uc2dd\uc758 \ub2e4\uc911 \ubaa8\ub4dc \ud559\uc2b5\uc5d0\uc11c \uc774\ud574\uc640 \uc0dd\uc131 \uc791\uc5c5 \uac04\uc758 \ubd88\uc77c\uce58\ub85c \uc778\ud574 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \uc774\ud574 \uc791\uc5c5\uc740 \uc2dc\uac01\uc801 \uc138\ubd80 \uc0ac\ud56d\uc744 \ubb34\uc2dc\ud558\uace0 \ucd94\uc0c1\uc801\uc778 \uc815\ubcf4\uc5d0 \uc9d1\uc911\ud558\ub294 \ubc18\uba74, \uc0dd\uc131 \uc791\uc5c5\uc740 \uc138\ubd80\uc801\uc778 \uc2dc\uac01 \uc815\ubcf4\ub97c \uc720\uc9c0\ud574\uc57c \ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.09838/x3.png", "caption": "Figure 3: The HealthGPT architecture integrates hierarchical visual perception and H-LoRA, employing a task-specific hard router to select visual features and H-LoRA plugins, ultimately generating outputs with an autoregressive manner.", "description": "\uadf8\ub9bc 3\uc740 HealthGPT\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. HealthGPT\ub294 \uacc4\uce35\uc801 \uc2dc\uac01\uc801 \uc9c0\uac01(hierarchical visual perception)\uacfc \uc774\uc885 \uc800\uc21c\uc704 \uc801\uc751(H-LORA)\uc744 \ud1b5\ud569\ud558\uc5ec, \uc791\uc5c5\ubcc4 \ud558\ub4dc \ub77c\uc6b0\ud130(task-specific hard router)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uac01\uc801 \ud2b9\uc9d5\uacfc H-LORA \ud50c\ub7ec\uadf8\uc778\uc744 \uc120\ud0dd\ud558\uace0, \ucd5c\uc885\uc801\uc73c\ub85c \uc790\uae30\ud68c\uadc0 \ubc29\uc2dd(autoregressive manner)\uc73c\ub85c \ucd9c\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uacc4\uce35\uc801 \uc2dc\uac01\uc801 \uc9c0\uac01\uc740 ViT(Vision Transformer)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \uc5ec\ub7ec \uacc4\uce35\uc758 \uc2dc\uac01\uc801 \ud1a0\ud070(visual tokens)\uc73c\ub85c \ubcc0\ud658\ud558\uc5ec, \uc774\ud574(comprehension) \uc791\uc5c5\uc5d0\ub294 \ucd94\uc0c1\uc801\uc778 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744, \uc0dd\uc131(generation) \uc791\uc5c5\uc5d0\ub294 \uad6c\uccb4\uc801\uc778 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.  H-LORA\ub294 \uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc9c0\uc2dd\uc744 \ubcc4\ub3c4\uc758 \ubaa8\ub4c8\uc5d0 \uc800\uc7a5\ud558\uace0, \uc791\uc5c5\uc5d0 \uad00\ub828\ub41c \uc9c0\uc2dd\uc744 \ucd94\ucd9c\ud558\uae30 \uc704\ud574 \ub3d9\uc801\uc73c\ub85c \ub77c\uc6b0\ud305\ud569\ub2c8\ub2e4.  \uc790\ub3d9 \ud68c\uadc0\uc801 \ubc29\uc2dd\uc740 \uc785\ub825\uc744 \uc21c\ucc28\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uc5ec \ucd9c\ub825\uc744 \uc0dd\uc131\ud558\ub294 \ubc29\uc2dd\uc744 \uc758\ubbf8\ud558\uba70, \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc758 \uacbd\uc6b0 VQGAN(Vector Quantized-GAN) \ub514\ucf54\ub354\uac00 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 HealthGPT\uc758 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\uc640 \uadf8\ub4e4\uc758 \uc0c1\ud638\uc791\uc6a9\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uc5b4, \ubaa8\ub378\uc758 \uc791\ub3d9 \uc6d0\ub9ac\ub97c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4 HealthGPT"}, {"figure_path": "https://arxiv.org/html/2502.09838/x4.png", "caption": "Figure 4: Data statistics of VL-Health.", "description": "\uadf8\ub9bc 4\ub294 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c VL-Health \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  (a)\ub294 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \uc720\ud615 (\uc608: \uc548\uc800 \uc0ac\uc9c4, OCT, \uc5d1\uc2a4\ub808\uc774, \ud604\ubbf8\uacbd \uc0ac\uc9c4, \ucd08\uc74c\ud30c, CT, MRI)\ubcc4 \ub370\uc774\ud130 \uc218\ub97c \ub098\ud0c0\ub0b4\ub294 \ub9c9\ub300 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uac01 \uc720\ud615\uc5d0 \ub300\ud574, \uc774\ud574(comprehension)\uc640 \uc0dd\uc131(generation) \uc791\uc5c5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uc218\ub7c9\uc774 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. (b)\ub294 \uac01 \uc791\uc5c5 \uc720\ud615(\uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5)\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \uc6d0\ubcf8\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub9c9\ub300 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc740 \ud2b9\uc815 \uc791\uc5c5\uc5d0 \ucd08\uc810\uc744 \ub9de\ucdb0 \uad6c\uc131\ub418\uc5c8\uc73c\uba70, VL-Health \ub370\uc774\ud130\uc14b\uc774 \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5 \ubaa8\ub450\ub97c \uc704\ud55c \ub2e4\uc591\ud558\uace0 \ud3ec\uad04\uc801\uc778 \ub370\uc774\ud130\ub97c \uc81c\uacf5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 Training Pipeline"}, {"figure_path": "https://arxiv.org/html/2502.09838/x5.png", "caption": "Figure 5: Performance comparison of LoRA, MoELoRA, and H-LoRA under different rank settings.", "description": "\uadf8\ub9bc 5\ub294 \ub2e4\uc591\ud55c \uc21c\uc704 \uc124\uc815\uc5d0\uc11c LoRA, MoELoRA \ubc0f H-LoRA\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc11c\ub85c \ub2e4\ub978 \uc21c\uc704 \ud06c\uae30\uc5d0\uc11c \uc138 \uac00\uc9c0 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uadf8\ub798\ud504\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc744 \uac83\uc73c\ub85c \uc608\uc0c1\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 H-LoRA\uac00 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \ub450 \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 \ud6c8\ub828 \ud30c\uc774\ud504\ub77c\uc778"}, {"figure_path": "https://arxiv.org/html/2502.09838/x6.png", "caption": "Figure 6:  The loss visualization (a) and performance comparison (b) with respect to different visual perceptions.", "description": "\uadf8\ub9bc 6\uc740 \uc11c\ub85c \ub2e4\ub978 \uc2dc\uac01\uc801 \uc778\uc2dd\uc5d0 \ub530\ub978 \uc190\uc2e4 \uc2dc\uac01\ud654(a)\uc640 \uc131\ub2a5 \ube44\uad50(b)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc190\uc2e4 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc774\uace0, (b)\ub294 \ud574\ub2f9 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574, \uacfc\uc81c(\uc774\ud574 \ub610\ub294 \uc0dd\uc131)\uc5d0 \ub530\ub77c \uc11c\ub85c \ub2e4\ub978 \uacc4\uce35\uc758 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \ud6a8\uc728\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ucd94\uc0c1\uc801\uc778 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc740 \uc774\ud574 \uacfc\uc81c\uc5d0, \uad6c\uccb4\uc801\uc778 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc740 \uc0dd\uc131 \uacfc\uc81c\uc5d0 \ub354 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \uacc4\uce35\uc801 \uc2dc\uac01\uc801 \uc778\uc2dd"}, {"figure_path": "https://arxiv.org/html/2502.09838/x7.png", "caption": "Figure 7: Case study of report-to-CXR under different instructions. (a) shows a normal CXR image for comparison. (b) and (c) illustrate generated cases with varying severity and affected regions. The graffiti areas indicate abnormal conditions.", "description": "\uadf8\ub9bc 7\uc740 \uc11c\ub85c \ub2e4\ub978 \uc9c0\uc2dc\uc5b4\uc5d0 \ub530\ub978 \ubcf4\uace0\uc11c-\ud749\ubd80 X\uc120 \uc0ac\uc9c4 \ubcc0\ud658 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc815\uc0c1\uc801\uc778 \ud749\ubd80 X\uc120 \uc0ac\uc9c4\uc744 \ube44\uad50\ub97c \uc704\ud574 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\uc640 (c)\ub294 \uc2ec\uac01\ub3c4\uc640 \uc601\ud5a5\uc744 \ubc1b\ub294 \ubd80\uc704\uac00 \ub2e4\ub978 \uc0dd\uc131\ub41c \uc0ac\ub840\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub099\uc11c\ub85c \ud45c\uc2dc\ub41c \ubd80\ubd84\uc740 \ube44\uc815\uc0c1\uc801\uc778 \uc0c1\ud0dc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 HealthGPT \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc218\uc900\uc758 \ud3d0\ub834\uc744 \uac00\uc9c4 \ud658\uc790\uc758 \ud749\ubd80 X\uc120 \uc0ac\uc9c4\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\ub294 \uc815\uc0c1\uc801\uc778 \ud749\ubd80 X\uc120 \uc0ac\uc9c4\uacfc \ube44\uad50\ud558\uc5ec \ud3d0\ub834\uc758 \uc2ec\uac01\ub3c4\uc640 \uc704\uce58\ub97c \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 Training Pipeline"}, {"figure_path": "https://arxiv.org/html/2502.09838/x8.png", "caption": "Figure 8: VL-Health dataset collection distribution.", "description": "\uadf8\ub9bc 8\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c VL-Health \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \uc9c8\uc758\uc751\ub2f5(VQA) \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc218\uc9d1\ub41c \uc774\ubbf8\uc9c0\uc640 \uc9c8\ubb38-\ub2f5\ubcc0 \uc30d\uc758 \uac1c\uc218\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ub9c9\ub300 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uc5ec\uae30\uc5d0\ub294 VQA-RAD, SLAKE, PathVQA, MIMIC-CXR-VQA, LLaVA-Med, PubMedVision \ub4f1 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uac01 \ub9c9\ub300\ub294 \ud2b9\uc815 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc774\ubbf8\uc9c0 \ub610\ub294 \uc9c8\ubb38-\ub2f5\ubcc0 \uc30d\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. (b)\ub294 \ucd08\ud574\uc0c1\ub3c4, \ubcc0\ud658, \uc7ac\uad6c\uc131 \uc791\uc5c5\uc744 \uc704\ud574 \uc0ac\uc6a9\ub41c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc758 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IXI, MIMIC-CHEST-XRAY, LLaVA-558k, SynthRAD2023 \ub4f1\uc758 \ub370\uc774\ud130\uc14b\uc774 \uc0ac\uc6a9\ub418\uc5c8\uc73c\uba70, \uac01 \ub9c9\ub300\ub294 \ud2b9\uc815 \uc791\uc5c5\uacfc \uad00\ub828\ub41c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 VL-Health \ub370\uc774\ud130\uc14b\uc774 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \ub370\uc774\ud130\uc640 \uc791\uc5c5\uc744 \ud3ec\uad04\uc801\uc73c\ub85c \ub2e4\ub8e8\uace0 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "A.3 VL-Health"}, {"figure_path": "https://arxiv.org/html/2502.09838/x9.png", "caption": "Figure 9: Performance changes before and after the stage-2.", "description": "\uadf8\ub9bc 9\ub294 HealthGPT \ubaa8\ub378 \ud559\uc2b5\uc758 \uc138 \ub2e8\uacc4 \uc911 \ub450 \ubc88\uc9f8 \ub2e8\uacc4(Heterogeneous H-LoRA Plugin Adaptation) \uc804\ud6c4\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \ubc88\uc9f8 \ub2e8\uacc4\ub294 \uc11c\ub85c \ub2e4\ub978 \uc791\uc5c5(\uc774\ubbf8\uc9c0 \uc774\ud574 \ubc0f \uc0dd\uc131)\uc744 \uc704\ud55c H-LORA \ud50c\ub7ec\uadf8\uc778\uc744 \ud1b5\ud569\ud558\uc5ec \ubaa8\ub378\uc758 \uae30\ubc18\uc744 \uac15\ud654\ud558\ub294 \ub2e8\uacc4\uc785\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \uc774\ubbf8\uc9c0 \uc774\ud574(Comp.) \ubc0f \uc774\ubbf8\uc9c0 \uc0dd\uc131(Gen.) \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\uba70, \ub450 \ubc88\uc9f8 \ub2e8\uacc4\ub97c \uac70\uce5c \ud6c4 \ub450 \uc791\uc5c5 \ubaa8\ub450\uc5d0\uc11c \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ud2b9\ud788,  \uc774 \ub2e8\uacc4\ub294 \uc791\uc5c5 \uac04\uc758 \ucda9\ub3cc\uc744 \uc644\ud654\ud558\uc5ec \uc548\uc815\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uac00\uc838\uc628\ub2e4\ub294 \uc810\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "C.3 Heterogeneous Knowledge Fusion on Performance"}, {"figure_path": "https://arxiv.org/html/2502.09838/extracted/6211206/fig/MT.png", "caption": "Figure 10: (a) Proportion of model responses selected as the best in human evaluation. (b) Human Evaluation Dataset.", "description": "\uadf8\ub9bc 10\uc740 \uc778\uac04 \ud3c9\uac00\uc790\ub4e4\uc774 \uac01 \ubaa8\ub378\uc758 \uc751\ub2f5 \uc911 \uac00\uc7a5 \uc6b0\uc218\ud55c \uc751\ub2f5\uc73c\ub85c \uc120\ud0dd\ud55c \ube44\uc728\uacfc, \uc778\uac04 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uc751\ub2f5\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00\uc790\ub4e4\uc758 \uc120\ud638\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ube44\uc728 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc751\ub2f5\uc5d0 \ub300\ud574 \ud3c9\uac00\uc790\ub4e4\uc774 \uac00\uc7a5 \uc6b0\uc218\ud55c \uc751\ub2f5\uc73c\ub85c \uc5bc\ub9c8\ub098 \uc790\uc8fc \uc120\ud0dd\ud588\ub294\uc9c0\ub97c \ubc31\ubd84\uc728\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. (b)\ub294 \uc774\ub7ec\ud55c \uc778\uac04 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc124\uba85\uc785\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ubcf8 \uc5f0\uad6c\uc758 \uacb0\uacfc\uac00 \uc2e4\uc81c \uc758\ub8cc \uc804\ubb38\uac00\ub4e4\uc758 \ud310\ub2e8\uacfc \uc5bc\ub9c8\ub098 \uc77c\uce58\ud558\ub294\uc9c0 \ud655\uc778\ud558\uace0, \ubaa8\ub378 \uc131\ub2a5\uc758 \uc2e0\ub8b0\ub3c4\ub97c \ub192\uc785\ub2c8\ub2e4.", "section": "C.4 \uc778\uac04 \ud3c9\uac00"}, {"figure_path": "https://arxiv.org/html/2502.09838/extracted/6211206/fig/SR_CASE.png", "caption": "Figure 11: Case of modality transfer.", "description": "\uadf8\ub9bc 11\uc740 \uc758\ub8cc \uc601\uc0c1 \ubcc0\ud658(modality transfer)\uc758 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CT \uc601\uc0c1\uc744 MRI \uc601\uc0c1\uc73c\ub85c, MRI \uc601\uc0c1\uc744 CT \uc601\uc0c1\uc73c\ub85c \ubcc0\ud658\ud558\ub294 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uc774\ubbf8\uc9c0 \uc30d\uc774 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \uc774\ubbf8\uc9c0 \uc30d\uc5d0\ub294 \uc6d0\ubcf8 \uc601\uc0c1(GT), HealthGPT \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc601\uc0c1(Pred), \uadf8\ub9ac\uace0 \ub450 \uc601\uc0c1\uc758 \ucc28\uc774\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud560 \uc218 \uc788\ub3c4\ub85d \ubc30\uce58\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 HealthGPT \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc601\uc5ed(\ub1cc, \uace8\ubc18 \ub4f1)\uc5d0\uc11c  CT\uc640 MRI \uc601\uc0c1 \uac04\uc758 \ubcc0\ud658\uc744 \uc815\ud655\ud558\uac8c \uc218\ud589\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc99d\uac70\uc785\ub2c8\ub2e4.  \uac01 \uc601\uc0c1\uc758 \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uae4c\uc9c0 \uc815\ud655\ud558\uac8c \ubcc0\ud658\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc73c\uba70, HealthGPT \ubaa8\ub378\uc758 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}]