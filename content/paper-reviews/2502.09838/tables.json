[{"content": "| Type | Model | # Params | Medical LVLM | VQA-RAD \u2191 |  | SLAKE \u2191 |  | PathVQA \u2191 |  | MMMU -Med \u2191 | OMVQA \u2191 | Avg. \u2191 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Comp. Only | Med-Flamingo | 8.3B | \u2713 | 58.6 | 43.0 | 47.0 | 25.5 | 61.9 | 31.3 | 28.7 | 34.9 | 41.4 |\n|  | LLaVA-Med | 7B | \u2713 | 60.2 | 48.1 | 58.4 | 44.8 | 62.3 | 35.7 | 30.0 | 41.3 | 47.6 |\n|  | HuatuoGPT-Vision | 7B | \u2713 | 66.9 | 53.0 | 59.8 | 49.1 | 52.9 | 32.0 | 42.0 | 50.0 | 50.7 |\n|  | BLIP-2 | 6.7B | \u2717 | 43.4 | 36.8 | 41.6 | 35.3 | 48.5 | 28.8 | 27.3 | 26.9 | 36.1 |\n|  | LLaVA-v1.5 | 7B | \u2717 | 51.8 | 42.8 | 37.1 | 37.7 | 53.5 | 31.4 | 32.7 | 44.7 | 41.5 |\n|  | InstructBLIP | 7B | \u2717 | 61.0 | 44.8 | 66.8 | 43.3 | 56.0 | 32.3 | 25.3 | 29.0 | 44.8 |\n|  | Yi-VL | 6B | \u2717 | 52.6 | 42.1 | 52.4 | 38.4 | 54.9 | 30.9 | 38.0 | 50.2 | 44.9 |\n|  | InternVL2 | 8B | \u2717 | 64.9 | 49.0 | 66.6 | 50.1 | 60.0 | 31.9 | 43.3 | 54.5 | 52.5 |\n|  | Llama-3.2 | 11B | \u2717 | 68.9 | 45.5 | 72.4 | 52.1 | 62.8 | 33.6 | 39.3 | 63.2 | 54.7 |\n| Comp. & Gen. | Show-o | 1.3B | \u2717 | 50.6 | 33.9 | 31.5 | 17.9 | 52.9 | 28.2 | 22.7 | 45.7 | 42.6 |\n|  | Unified-IO 2 | 7B | \u2717 | 46.2 | 32.6 | 35.9 | 21.9 | 52.5 | 27.0 | 25.3 | 33.0 | 33.8 |\n|  | Janus | 1.3B | \u2717 | 70.9 | 52.8 | 34.7 | 26.9 | 51.9 | 27.9 | 30.0 | 26.8 | 33.5 |\n|  | HealthGPT-M3 | 3.8B | \u2713 | 73.7 | 55.9 | 74.6 | 56.4 | 78.7 | 39.7 | 43.3 | 68.5 | 61.3 |\n|  | HealthGPT-L14 | 14B | \u2713 | 77.7 | 58.3 | 76.4 | 64.5 | 85.9 | 44.4 | 49.2 | 74.4 | 66.4 |", "caption": "Table 1: Comparison of HealthGPT with other LVLMs and unified multi-modal models on medical visual comprehension tasks. Bold and underlined text indicates the best performance and second-best performance, respectively.", "description": "\ud45c 1\uc740 \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \uc791\uc5c5\uc5d0\uc11c HealthGPT\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \ub300\uaddc\ubaa8 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378(LVLM) \ubc0f \ud1b5\ud569 \ub2e4\uc911 \ubaa8\ub4dc \ubaa8\ub378\uacfc \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \uc791\uc5c5(VQA-RAD, SLAKE, PathVQA, MMMU-Med, OMVQA)\uc5d0\uc11c \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec HealthGPT\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad75\uc740 \ubc11\uc904\uc740 \ucd5c\uace0 \uc131\ub2a5\uacfc \ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc758\ub8cc \uc601\uc0c1 \uc9c8\ubb38 \ub2f5\ubcc0, \uc758\ub8cc \ubcf4\uace0\uc11c \uc0dd\uc131\uacfc \uac19\uc740 \ud2b9\uc815 \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \uacfc\uc81c\uc5d0\uc11c HealthGPT\uac00 \ub2e4\ub978 \ubaa8\ub378\ubcf4\ub2e4 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Model | CT to MRI (Brain) |  |  | CT to MRI (Pelvis) |  |  | MRI to CT (Brain) |  |  | MRI to CT (Pelvis) |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 |\n| pix2pix | 71.09 | 32.65 | 36.85 | 59.17 | 31.02 | 51.91 | 78.79 | 33.85 | 28.33 | 72.31 | 32.98 | 36.19 |\n| CycleGAN | 54.76 | 32.23 | 40.56 | 54.54 | 30.77 | 55.00 | 63.75 | 31.02 | 52.78 | 50.54 | 29.89 | 67.78 |\n| BBDM | 71.69 | 32.91 | 34.44 | 57.37 | 31.37 | 48.06 | 86.40 | 34.12 | 26.61 | 79.26 | 33.15 | 33.60 |\n| Vmanba | 69.54 | 32.67 | 36.42 | 63.01 | 31.47 | 46.99 | 79.63 | 34.12 | 26.49 | 77.45 | 33.53 | 31.85 |\n| DiffMa | 71.47 | 32.74 | 35.77 | 62.56 | 31.43 | 47.38 | 79.00 | 34.13 | 26.45 | 78.53 | 33.68 | 30.51 |\n| HealthGPT-M3 | 79.38 | 33.03 | 33.48 | 71.81 | 31.83 | 43.45 | 85.06 | 34.40 | 25.49 | 84.23 | 34.29 | 27.99 |\n| HealthGPT-L14 | 79.73 | 33.10 | 32.96 | 71.92 | 31.87 | 43.09 | 85.31 | 34.29 | 26.20 | 84.96 | 34.14 | 28.13 |", "caption": "Table 2: The experimental results for the four modality conversion tasks.", "description": "\ud45c 2\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub124 \uac00\uc9c0 \uc758\ub8cc \uc601\uc0c1 \ubcc0\ud658 \uc791\uc5c5(CT\uc5d0\uc11c MRI\ub85c, MRI\uc5d0\uc11c CT\ub85c\uc758 \ubcc0\ud658, \uac01\uac01 \ub1cc\uc640 \uace8\ubc18 \uc601\uc5ed)\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc791\uc5c5\uc5d0 \ub300\ud574 SSIM, PSNR, MSE \uc9c0\ud45c\uac00 \uc81c\uc2dc\ub418\uc5b4 \ubaa8\ub378 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc601\uc0c1 \ubcc0\ud658 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\uba70, HealthGPT \ubaa8\ub378\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadfc\uac70\uac00 \ub429\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Model | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | LPIPS \u2193 |\n|---|---|---|---|---|\n| SRGAN | 71.34 | 32.01 | 41.27 | 24.50 |\n| DASR | 71.57 | 32.34 | 38.25 | 19.17 |\n| Real-ESRGAN | 67.30 | 31.87 | 42.57 | 20.64 |\n| LIIF | 73.27 | 32.13 | 40.14 | 22.93 |\n| BSRGAN | 69.97 | 31.97 | 41.52 | 28.72 |\n| HealthGPT-M3 | 78.19 | 32.76 | 34.47 | 12.02 |\n| HealthGPT-L14 | 77.94 | 32.71 | 35.19 | 12.43 |", "caption": "Table 3: Comparison results of super-resolution task.", "description": "\ud45c 3\uc740 \ucd08\uace0\ud574\uc0c1\ub3c4 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  SRGAN, DASR, Real-ESRGAN, LIIF, BSRGAN \ubc0f HealthGPT \ubaa8\ub378\uc758 SSIM, PSNR, MSE \ubc0f LPIPS \uc9c0\ud45c\ub97c \ube44\uad50\ud558\uc5ec HealthGPT \ubaa8\ub378\uc774 \ub2e4\ub978 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, HealthGPT-M3 \uc640 HealthGPT-L14 \ubaa8\ub378\uc740 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc5d0 \ube44\ud574 MSE\uac00 \ud604\uc800\ud558\uac8c \ub0ae\uace0 SSIM\uacfc PSNR\uc774 \ub192\uc544 \uc774\ubbf8\uc9c0 \ud488\uc9c8 \uac1c\uc120\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Model | VQA-RAD | VQA-RAD | SLAKE | SLAKE | PathVQA | PathVQA | MMMU-Med | OMVQA | RECOM | MTRANS | SR | Training Time |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| HealthGPT w/ +LoRA | 71.3 | **57.2** | **70.0** | **53.4** | **76.4** | **38.6** | **41.30** | **65.10** | 62.67 | **59.99** | 65.88 | **1.00 \u00d7** |\n| HealthGPT w/ +MoELoRA | **72.5** | **57.2** | 66.4 | 52.4 | 73.2 | 36.0 | 39.30 | 64.90 | **67.31** | 59.76 | **65.91** | **1.49 \u00d7** |\n| HealthGPT w/ +H-LoRA | **73.7** | **55.9** | **74.6** | **56.4** | **78.7** | **39.7** | **43.30** | **68.50** | 67.69 | **60.30** | **66.14** | **1.00 \u00d7** |", "caption": "Table 4: We present the performance and speed differences of LoRA, MoELoRA (n=4), and H-LoRA (n=4) on medical visual comprehension and generation tasks.", "description": "\ud45c 4\ub294 \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5\uc5d0\uc11c LoRA, MoELORA(n=4), H-LoRA(n=4)\uc758 \uc131\ub2a5 \ubc0f \uc18d\ub3c4 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc758\ub8cc \uc601\uc0c1 \uc774\ud574(VQA-RAD, SLAKE, PathVQA, OMVQA, MMMU)\uc640 \uc0dd\uc131(RECOM, MTRANS, SR) \uc791\uc5c5 \ubaa8\ub450\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc LoRA \uae30\ubc18 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \ud544\uc694\ud55c \uc2dc\uac04\uc774 \ube44\uad50\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub97c \ud1b5\ud574 H-LoRA\uac00 \ub2e4\ub978 LoRA \uae30\ubc18 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ud6a8\uc728\uc801\uc778 \ub3d9\uc2dc\uc5d0 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 Training Pipeline"}, {"content": "| Training Strategy | VQA-RAD | VQA-RAD | SLAKE | SLAKE | PathVQA | PathVQA | Comp. | Gen. | CT | CT | MRI | MRI |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | close | all | close | all | close | all | MMMU-Med | OMVQA | Brain | Pelvis | Brain | Pelvis |\n| Mixed-Training | 56.6 | 37.9 | 45.0 | 32.9 | 65.7 | 33.6 | **44.0** | 48.9 | 65.64 | 62.75 | 56.61 | 50.77 |\n| HealthGPT w/ 3-stage-Training | **72.5** | **55.2** | **77.9** | **59.6** | **79.7** | **49.0** | 42.7 | **68.5** | **70.84** | **72.99** | **65.26** | **61.33** |", "caption": "Table 5: Comparison between the H-LoRA-based Three-Stage Learning Strategy and the mixed-training approach.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 H-LoRA \uae30\ubc18 3\ub2e8\uacc4 \ud559\uc2b5 \uc804\ub7b5\uacfc \ud63c\ud569 \ud559\uc2b5 \ubc29\uc2dd\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \uc774\ud574 \ubc0f \uc0dd\uc131 \uc791\uc5c5(VQA-RAD, SLAKE, PathVQA, MMMU-Med, OMVQA, CT, MRI \ub4f1)\uc5d0 \ub300\ud55c \ub450 \uac00\uc9c0 \ud559\uc2b5 \ubc29\ubc95\uc758 \uc131\ub2a5 \uc9c0\ud45c(\uc608: \uc815\ud655\ub3c4, F1 \uc810\uc218 \ub4f1)\ub97c \ube44\uad50\ud558\uc5ec \uac01 \ubc29\ubc95\uc758 \ud6a8\uc728\uc131\uacfc \uc7a5\ub2e8\uc810\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  3\ub2e8\uacc4 \ud559\uc2b5 \uc804\ub7b5\uc774 \ud63c\ud569 \ud559\uc2b5 \ubc29\uc2dd\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0, \uadf8\ub9ac\uace0 \uc5b4\ub5a4 \uc791\uc5c5\uc5d0\uc11c \ub354 \ud070 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc774\ub294\uc9c0 \ub4f1\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 Training Pipeline"}, {"content": "| Model | ViT | Adapter | MLP-dims | Model dims | LLM | Params | Vocab Size | H-LoRA Rank |\n|---|---|---|---|---|---|---|---|---|\n| HealthGPT-M3 | CLIP-L/14 | 2-layer MLP | 1024 | 3072 | Phi-3-mini | 3.8B | 40206 | 16(Comp.), 64(Gen.) |\n| HealthGPT-L14 | CLIP-L/14 | 2-layer MLP | 1024 | 5120 | Phi-4 | 14B | 108547 | 8(Comp.), 32(Gen.) |", "caption": "Table 6: Overview of the Components of HealthGPT.", "description": "\ud45c 6\uc740 HealthGPT \ubaa8\ub378\uc758 \uad6c\uc131 \uc694\uc18c\uc5d0 \ub300\ud55c \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  HealthGPT \ubaa8\ub378\uc740 \ud06c\uac8c Vision Transformer (ViT), Adapter, Multi-Layer Perceptron (MLP), \uadf8\ub9ac\uace0 Large Language Model (LLM) \uc758 \ub124 \uac00\uc9c0 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uad6c\uc131 \uc694\uc18c\ub294 \ubaa8\ub378\uc758 \uc785\ub825\uc744 \ucc98\ub9ac\ud558\uace0 \ucd5c\uc885 \ucd9c\ub825\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \uc774 \ud45c\uc5d0\uc11c\ub294 \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uc720\ud615, \ucc28\uc6d0, \ud30c\ub77c\ubbf8\ud130 \uc218, \uc5b4\ud718 \ud06c\uae30 \ub4f1 \uc138\ubd80 \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uc5ec HealthGPT \ubaa8\ub378\uc758 \uad6c\uc870\ub97c \ubcf4\ub2e4 \uba85\ud655\ud558\uac8c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ud2b9\ud788 HealthGPT \ubaa8\ub378\uc758 \ub450 \uac00\uc9c0 \ubc84\uc804\uc778 HealthGPT-M3\uacfc HealthGPT-L14\uc758 \uc0ac\uc591 \ucc28\uc774\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 HealthGPT"}, {"content": "|                       | HealthGPT-M3                      |                       | HealthGPT-L14                      |\n| :-------------------- | :---------------------------------- | :-------------------- | :---------------------------------- |\n|                       | Stage-1             | Stage-2             | Stage-3             | Stage-1             | Stage-2             | Stage-3             |\n|                       | Comp. | Gen. | Comp. | Gen. | Comp. | Gen. | Comp. | Gen. | Comp. | Gen. | Comp. | Gen. |\n| Hyperparameter         |                       |                       |                       |                       |                       |                       |\n| Optimizer             | AdamW                 | AdamW                 | AdamW                 | AdamW                 | AdamW                 | AdamW                 |\n| Adapter LR           | 1e-3                  | 2e-5                  | 2e-5                  | 2e-5                  | 2e-5                  | 2e-5                  |\n| Learning Rate        | /                     | 2e-4                  | 2e-4                  | 2e-4                  | /                     | 1e-4                  | 2e-4                  | 2e-4                  |\n| Global Batch Size    | 256                   | 64                    | 32                    | 128                   | 64                    | 256                   | 64                    | 32                    | 128                   | 64                    |\n| Weight Decay         | 0                     | 0                     | 0                     | 0                     | 0                     | 0                     |\n| Dropout Rate         | 0                     | 0.05                  | 0.05                  | 0.05                  | 0                     | 0.05                  | 0.05                  | 0.05                  |\n| LR Scheduler         | Warm Up               | Constant               | Warm Up               | Warm Up               | Constant               | Warm Up               |\n| Max Sequence Length   | 2048                  | 2048                  | 2048                  | 2048                  | 2048                  | 2048                  |", "caption": "Table 7: Overview of Hyperparameter Configurations.", "description": "\ud45c 7\uc740 HealthGPT \ubaa8\ub378\uc758 \uc138 \uac00\uc9c0 \ub2e8\uacc4\ubcc4 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub2e8\uacc4(1\ub2e8\uacc4, 2\ub2e8\uacc4, 3\ub2e8\uacc4)\ubcc4\ub85c \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \uc5b4\ub311\ud130 \ud559\uc2b5\ub960, \ud559\uc2b5\ub960, \uc804\uc5ed \ubc30\uce58 \ud06c\uae30, \uac00\uc911\uce58 \uac10\uc1e0, \ub4dc\ub86d\uc544\uc6c3 \ube44\uc728, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774, \uc6dc\uc5c5 \ub2e8\uacc4 \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc744 \uc81c\uc2dc\ud558\uc5ec \ubaa8\ub378 \ud559\uc2b5\uc758 \ud6a8\uc728\uc131\uacfc \ucd5c\uc885 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc790\uc138\ud788 \uc124\uba85\ud569\ub2c8\ub2e4. HealthGPT-M3\uacfc HealthGPT-L14 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc124\uc815\uc744 \uac01\uac01 \uad6c\ubd84\ud558\uc5ec \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc774 \ud2b9\uc9d5\uc785\ub2c8\ub2e4.  \ud2b9\ud788, \uac01 \ub2e8\uacc4\ubcc4 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc774 \ub2e4\ub974\uac8c \uc81c\uc2dc\ub41c \uc774\uc720\ub3c4 \ud568\uaed8 \uc124\uba85\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "A.2 Training Details"}, {"content": "| Medical Task | Stage-1 | Stage-2 |\n|---|---|---|\n| Comp. | LLaVA-558k, PubMedVision-PT | Mixed-47k |\n| Gen. | LLaVA-558k | Mixed-47k |\n| Medical Task | Stage-3 |\n|---|---| \n| Comp. | LLaVA_Med, MIMIC_CXR_VQA, PubMedVision-FT, LLaVA-665k, PathVQA, SLAKE, VQA-RAD |\n| Gen. | IXI, SynthRAD2023, MIMIC-CHEST-XRAY |", "caption": "Table 8: Data distribution of VL-Health in three-stage learning strategy.", "description": "\ud45c 8\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c VL-Health \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \ub2e8\uacc4 \ud559\uc2b5 \uc804\ub7b5(three-stage learning strategy)\uc5d0 \ub530\ub77c \ub370\uc774\ud130\uc14b\uc774 \uc5b4\ub5bb\uac8c \ub098\ub258\uc5b4 \uc0ac\uc6a9\ub418\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  1\ub2e8\uacc4\uc5d0\uc11c\ub294 LLaVA-558k\uc640 PubMedVision-PT \ub370\uc774\ud130\uc14b\uc774 \ubaa8\ub450 \uc0ac\uc6a9\ub418\uace0, 2\ub2e8\uacc4\uc5d0\uc11c\ub294 LLaVA-558k\uac00 \uc0dd\uc131 \ud0dc\uc2a4\ud06c\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. 3\ub2e8\uacc4\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \ub370\uc774\ud130\uc14b(LLaVA Med, MIMIC-CXR-VQA, PubMedVision-FT, LLaVA-665k, PathVQA, SLAKE, VQA-RAD)\uc774 \uc774\ud574(comprehension) \ud0dc\uc2a4\ud06c\uc5d0, IXI, SynthRAD2023, MIMIC-CHEST-XRAY \ub370\uc774\ud130\uc14b\uc774 \uc0dd\uc131(generation) \ud0dc\uc2a4\ud06c\uc5d0 \uc0ac\uc6a9\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uac01 \ub2e8\uacc4\ubcc4\ub85c \uc0ac\uc6a9\ub418\ub294 \ub370\uc774\ud130\uc14b\uacfc \ud0dc\uc2a4\ud06c(\uc774\ud574/\uc0dd\uc131) \uc720\ud615\uc744 \uba85\ud655\ud788 \uc81c\uc2dc\ud558\uc5ec \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc131\uacfc \ud559\uc2b5 \uc804\ub7b5\uc744 \uc27d\uac8c \uc774\ud574\ud558\ub3c4\ub85d \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "A Implementation Details"}, {"content": "| Type | Model | # Params | Medical LVLM | CT | X-ray | FDM | MiS | OCT | MRI | USS | Avg. |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Comp. Only | Med-Flamingo | 8.3B | \u2713 | 30.1 | 33.9 | 25.5 | 37.0 | 60.0 | 27.6 | 30.4 | 34.9 |\n|  | LLaVA-Med | 7B | \u2713 | 28.4 | 32.8 | 42.7 | 31.6 | 55.3 | 45.0 | 53.6 | 41.3 |\n|  | HuatuoGPT-Vision | 7B | \u2713 | 35.3 | 41.5 | 51.4 | 62.3 | 59.3 | 40.4 | 60.1 | 50.0 |\n|  | BLIP-2 | 6.7B | \u2717 | 26.6 | 29.1 | 22.3 | 36.9 | 29.1 | 22.7 | 21.4 | 26.9 |\n|  | LLaVA-v1.5 | 7B | \u2717 | 28.0 | 55.7 | 35.5 | 42.1 | 49.2 | 52.9 | 49.7 | 44.7 |\n|  | InstructBLIP | 7B | \u2717 | 20.1 | 22.2 | 34.1 | 30.6 | 38.6 | 31.9 | 25.5 | 29.0 |\n|  | Yi-VL | 6B | \u2717 | 51.2 | 47.1 | 27.7 | 62.6 | 67.6 | 55.0 | 40.3 | 50.2 |\n|  | InternVL2 | 8B | \u2717 | 40.2 | 57.9 | 53.2 | 64.0 | 59.1 | 58.1 | 49.1 | 54.5 |\n|  | Llama-3.2 | 11B | \u2717 | 37.6 | 55.2 | 71.4 | 82.1 | 62.5 | 65.2 | 68.6 | 63.2 |\n| Comp. & Gen. | Show-o | 1.3B | \u2717 | 29.0 | 50.4 | 30.9 | 22.0 | 30.8 | 34.2 | 33.8 | 33.0 |\n|  | Unified-IO 2 | 7B | \u2717 | 10.8 | 37.7 | 12.3 | 25.3 | 32.6 | 30.9 | 37.7 | 26.8 |\n|  | Janus | 1.3B | \u2717 | 24.9 | 54.8 | 35.9 | 62.7 | 54.2 | 50.7 | 36.8 | 45.7 |\n|  | HealthGPT-M3 | 3.8B | \u2713 | 35.3 | 81.9 | 54.6 | 88.2 | 89.3 | 78.5 | 51.4 | 68.5 |\n|  | HealthGPT-L14 | 14B | \u2713 | 39.0 | 86.6 | 64.1 | 88.6 | 99.7 | 80.9 | 62.2 | 74.4 |", "caption": "Table 9: Performance comparison of OmniMedVQA Benchmark.", "description": "\ud45c 9\ub294 OmniMedVQA \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  OmniMedVQA\ub294 \ub2e4\uc591\ud55c \uc758\ub8cc \uc601\uc0c1 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc218\uc9d1\ub41c \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc758\ub8cc \uc774\ubbf8\uc9c0\uc640 \uc9c8\ubb38 \ub2f5\ubcc0 \uc30d\uc73c\ub85c \uad6c\uc131\ub41c \ub300\uaddc\ubaa8 \uc758\ub8cc \uc601\uc0c1 \uc9c8\uc758\uc751\ub2f5 \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(Med-Flamingo, LLaVA-Med, HuatuoGPT-Vision, BLIP-2, LLaVA-v1.5, InstructBLIP, Yi-VL, InternVL2, Llama-3.2, Show-o, Unified-IO 2, Janus, HealthGPT-M3, HealthGPT-L14)\uc758 OmniMedVQA \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uac01 \ubaa8\ub378\uc758 \uc7a5\ub2e8\uc810\uacfc \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc218, \uc9c0\uc6d0\ud558\ub294 \uc758\ub8cc \uc601\uc0c1 \ubaa8\ub2ec\ub9ac\ud2f0(CT, X-ray, FDM, MIS, OCT, MRI, USS), \uadf8\ub9ac\uace0 \uac01 \ubaa8\ub2ec\ub9ac\ud2f0\ubcc4 \uc131\ub2a5 \uc810\uc218(\ud3c9\uade0 \uc810\uc218 \ud3ec\ud568)\ub97c \ube44\uad50\ud558\uc5ec HealthGPT \ubaa8\ub378\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4. \ud2b9\ud788, HealthGPT-M3\uacfc HealthGPT-L14 \ubaa8\ub378\uc758 \ub192\uc740 \uc815\ud655\ub3c4\uac00 \uac15\uc870\ub429\ub2c8\ub2e4.", "section": "C.1 OmniMedVQA \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc"}, {"content": "| Model | Comp. | Gen. | Time (n=2) | Comp. | Gen. | Time (n=4) | Comp. | Gen. | Time (n=8) | Comp. | Gen. | Time (n=32) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| +MoELoRA | 50.3 | 62.98 | 1.22\u00d7 | 50.0 | 64.33 | 1.49\u00d7 | 50.8 | 63.71 | 2.09\u00d7 | / | / | 5.81\u00d7 |\n| HealthGPT w/ +H-LoRA | 51.5 | 63.48 | 0.99\u00d7 | 52.8 | 64.71 | 1.00\u00d7 | 53.6 | 64.98 | 0.99\u00d7 | 53.5 | 64.74 | 1.01\u00d7 |", "caption": "Table 10: We explored the performance of MoELoRA and H-LoRA with different numbers of LoRA experts. At n=32\ud835\udc5b32n=32italic_n = 32, MoELoRA was unable to complete training.", "description": "\uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc218\uc758 LoRA \uc804\ubb38\uac00\ub97c \uc0ac\uc6a9\ud558\uc5ec MoELoRA\uc640 H-LoRA\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LoRA \uc804\ubb38\uac00\uc758 \uc218(n)\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c MoELoRA\uc758 \ud6c8\ub828 \uc2dc\uac04\uc774 \ud06c\uac8c \uc99d\uac00\ud558\ub294 \ubc18\uba74, H-LORA\ub294 \ucd94\uac00\uc801\uc778 \ud6c8\ub828 \uc2dc\uac04 \uc9c0\uc5f0 \uc5c6\uc774 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, n=32\uc77c \ub54c MoELoRA\ub294 \ud6c8\ub828\uc744 \uc644\ub8cc\ud560 \uc218 \uc5c6\uc5c8\ub358 \ubc18\uba74, H-LORA\ub294 \ud6c8\ub828\uc744 \uc644\ub8cc\ud558\uace0 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubd80\ub85d B\uc808\uc5d0\uc11c \ubd84\uc11d\ud55c \ub0b4\uc6a9\uacfc \uc77c\uce58\ud558\uba70, \ub300\uaddc\ubaa8 \uc791\uc5c5\uc5d0\uc11c H-LORA\uc758 \ud6a8\uc728\uc131\uc744 \uc785\uc99d\ud569\ub2c8\ub2e4.", "section": "C.2 LoRA \uc804\ubb38\uac00 \uc218\uc758 \uc548\uc815\uc131 \ubd84\uc11d"}, {"content": "| Model | CT(Brain) |  |  | CT(Pelvis) |  |  | MRI (Brain) |  |  | MRI(Pelvis) |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 | SSIM \u2191 | PSNR \u2191 | MSE \u2193 |\n| SEED-X | 20.18 | 27.66 | 112.11 | 21.53 | 28.02 | 102.87 | 4.90 | 27.62 | 112.86 | 6.31 | 27.89 | 106.21 |\n| Unified-IO 2 | 83.93 | 36.09 | 17.95 | 85.36 | 35.10 | 25.46 | 87.50 | 34.25 | 25.47 | 86.31 | 33.53 | 29.80 |\n| HealthGPT-M3 | 91.73 | 36.42 | 15.46 | 94.26 | 37.30 | 12.53 | 88.76 | 33.97 | 27.05 | 84.40 | 33.11 | 32.62 |", "caption": "Table 11: The experimental results for the four reconstruction tasks.", "description": "\ud45c 11\uc740 \ub1cc\uc640 \uace8\ubc18 \uc601\uc5ed\uc5d0 \ub300\ud55c CT\uc5d0\uc11c MRI\ub85c, MRI\uc5d0\uc11c CT\ub85c\uc758 \ubcc0\ud658 \uc791\uc5c5\uc744 \ud3ec\ud568\ud55c \ub124 \uac00\uc9c0 \ubaa8\ub2ec\ub9ac\ud2f0 \ubcc0\ud658 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc791\uc5c5\uc5d0 \ub300\ud574 SSIM, PSNR, MSE \uc9c0\ud45c\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, HealthGPT-M3 \ubaa8\ub378\uacfc \ub2e4\ub978 \uae30\uc874 \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec HealthGPT \ubaa8\ub378\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub1cc\uc640 \uace8\ubc18 \uc601\uc5ed\uc744 \uad6c\ubd84\ud558\uc5ec \uc81c\uc2dc\ud568\uc73c\ub85c\uc368 \ud574\ub2f9 \ubaa8\ub378\uc758 \uc2e0\uccb4 \ubd80\uc704\ubcc4 \uc131\ub2a5 \ucc28\uc774\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}]