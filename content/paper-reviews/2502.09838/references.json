{"references": [{"fullname_first_author": "Abdin, M.", "paper_title": "Phi-4 technical report", "publication_date": "2024-12-01", "reason": "This paper introduces the Phi-4 model, a large language model used as the base for HealthGPT-L14, a key model in the experiments."}, {"fullname_first_author": "Chen, J.", "paper_title": "Huatuogpt-vision, towards injecting medical visual knowledge into multimodal llms at scale", "publication_date": "2024-06-01", "reason": "This paper introduces HuatuoGPT-Vision, a key competitor model in the medical vision-language model space, allowing for comparison with HealthGPT."}, {"fullname_first_author": "Liu, B.", "paper_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "publication_date": "2023-00-00", "reason": "BLIP-2 is another key competitor model and is frequently compared to HealthGPT in the experimental results."}, {"fullname_first_author": "Li, C.", "paper_title": "LLaVA-Med: Training a large language-and-vision assistant for biomedicine in one day", "publication_date": "2024-00-00", "reason": "LLaVA-Med is a key competitor model and is frequently compared against HealthGPT in the experimental results."}, {"fullname_first_author": "Ge, Y.", "paper_title": "Planting a seed of vision in large language model", "publication_date": "2023-07-01", "reason": "This paper introduces SEED, a key competitor model that is compared to HealthGPT as a unified visual comprehension and generation model."}]}