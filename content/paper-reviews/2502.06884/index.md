---
title: "Learning Conformal Abstention Policies for Adaptive Risk Management in Large Language and Vision-Language Models"
summary: "대규모 언어 및 비전-언어 모델의 위험을 줄이는 학습 가능한 컨포멀 거부 정책 제시!"
categories: ["AI Generated", "🤗 Daily Papers"]
tags: ["Multimodal Learning", "Vision-Language Models", "🏢 University of Illinois at Chicago",]
showSummary: true
date: 2025-02-08
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.06884 {{< /keyword >}}
{{< keyword icon="writer" >}} Sina Tayebati et el. {{< /keyword >}}
 
{{< keyword >}} 🤗 2025-02-12 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.06884" target="_self" >}}
↗ arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.06884" target="_self" >}}
↗ Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/learning-conformal-abstention-policies-for" target="_self" >}}
↗ Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

대규모 언어 모델(LLM)과 비전-언어 모델(VLM)은 의료 진단, 자율 주행 등 안전이 중요한 분야에서 점점 더 많이 사용되고 있지만, **결정 과정의 불투명성으로 인해 위험 평가 및 신뢰성 확보가 어렵습니다.** 기존의 불확실성 정량화 방법은 정적 임계값에 의존하여, 작업 복잡성과 데이터 분포 변화에 적응하지 못하는 한계가 있습니다. 이는 정확도, 적용 범위, 정보성 사이의 최적화된 절충을 이루지 못하게 합니다.

본 연구는 **강화 학습(RL)과 컨포멀 예측(CP)을 통합하여 이러한 문제를 해결하는 새로운 프레임워크인 학습 가능한 컨포멀 거부 정책(CAP)**을 제안합니다. CAP는 CP 임계값을 적응형 행동으로 취급하여, 예측 집합 크기를 최소화하면서 신뢰할 수 있는 적용 범위를 유지하는 것을 목표로 여러 목표를 동시에 최적화합니다. 다양한 LLM/VLM 벤치마크에 대한 광범위한 평가 결과, CAP은 기존 방법보다 정확도를 최대 3.2% 향상시키고, 환각 감지에 대한 AUROC를 22.19% 향상시키며, 불확실성 기반 선택적 생성(AUARC)을 21.17% 향상시키고, 보정 오차를 70~85% 감소시키는 것으로 나타났습니다. 이러한 개선은 여러 모델과 데이터셋에서 일관되게 90%의 적용 범위 목표를 달성하면서 이루어졌습니다.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} 학습 가능한 컨포멀 거부 정책(CAP)을 통해 대규모 언어 및 비전-언어 모델의 예측 불확실성을 효과적으로 관리할 수 있음 {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} CAP은 다양한 모델과 데이터셋에서 정확도, 적용 범위, 정보성을 개선하여 기존 방법보다 우수한 성능을 보임 {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} CAP은 안전 중요 응용 분야에서 모델의 신뢰도 향상에 기여하며, 강화 학습과 컨포멀 예측을 통합하는 새로운 접근법을 제시함 {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
본 논문은 **신뢰할 수 있는 예측과 위험 관리가 중요한 대규모 언어 및 비전-언어 모델의 안전한 활용**에 대한 새로운 접근법을 제시하여, 관련 분야 연구자들에게 중요한 의미를 가집니다. **학습 가능한 컨포멀 거부 정책(CAP)**은 불확실성을 효과적으로 정량화하고 관리하며, 다양한 모델과 데이터셋에서 성능을 향상시키는 것으로 입증되었습니다. 이는 **안전 중요 응용 분야에서의 모델 신뢰도 향상**에 기여하며, 향후 연구 방향을 제시합니다. 특히 **강화 학습과 컨포멀 예측을 통합**하는 독창적인 방법론은 다른 분야에도 적용 가능한 잠재력을 가지고 있습니다.

------
#### Visual Insights





{{< table-caption >}}
| Models | Method | MMB | OOD | SQA | SB | AI2D | Avg. | MMB | OOD | SQA | SB | AI2D | Avg. |
|---|---|---|---|---|---|---|---|---|---|---|---|---|
| **VLMs** |  | **AUROC ↑ (Hallucination Detection)** |  |  |  |  |  | **AUARC ↑ (Uncertainty guided selective generation)** |  |  |  |  |  |
| **LLaVA-v1.6-34B** | APS | 0.7173 | 0.6962 | 0.7244 | 0.5566 | 0.8404 | 0.7070 | 0.9583 | 0.9138 | 0.9275 | 0.9155 | 0.9283 | 0.9287 |
|  | LAC | 0.7837 | 0.7003 | 0.8000 | 0.5626 | 0.8476 | 0.7388 | 0.9412 | 0.9021 | 0.9099 | 0.8830 | 0.9192 | 0.9111 |
|  | Ours | **0.8041** | **0.7849** | **0.8606** | **0.6512** | **0.8989** | **0.8000** | **0.9791** | **0.9717** | **0.9813** | **0.9441** | **0.9913** | **0.9735** |
| **LLaVA-v1.6-13B** | APS | 0.4930 | 0.5901 | 0.5281 | 0.4854 | 0.7775 | 0.5748 | 0.9566 | 0.8759 | 0.9444 | 0.9307 | 0.9142 | 0.9244 |
|  | LAC | 0.6835 | 0.5919 | 0.5990 | 0.5038 | 0.7475 | 0.6251 | 0.9258 | 0.8512 | 0.8945 | 0.8791 | 0.8956 | 0.8892 |
|  | Ours | **0.6382** | **0.7070** | **0.6663** | **0.6103** | **0.8083** | **0.6860** | **0.9761** | **0.9592** | **0.9565** | **0.9343** | **0.9838** | **0.9620** |
| **LLaVA-v1.6-7B** | APS | 0.6961 | 0.3424 | 0.6093 | 0.5699 | 0.8247 | 0.6085 | 0.9575 | 0.8712 | 0.9147 | 0.9239 | 0.8952 | 0.9125 |
|  | LAC | 0.6849 | 0.4836 | 0.5555 | 0.4988 | 0.6930 | 0.5832 | 0.9212 | 0.8125 | 0.8671 | 0.8730 | 0.8691 | 0.8686 |
|  | Ours | **0.7049** | **0.5643** | **0.6165** | **0.5919** | **0.7626** | **0.6480** | **0.9662** | **0.9253** | **0.9399** | **0.9353** | **0.9725** | **0.9478** |
| **LLMs** |  |  |  |  |  |  |  |  |  |  |  |  |  |
| **Yi-34B** | APS | 0.9109 | 0.5089 | 0.8370 | 0.5643 | 0.5883 | 0.6819 | 0.9735 | 0.7334 | 0.9373 | 0.7864 | 0.8806 | 0.8622 |
|  | LAC | 0.9487 | 0.5650 | 0.9287 | 0.4181 | 0.6832 | 0.7087 | 0.9700 | 0.7140 | 0.9336 | 0.7529 | 0.8590 | 0.8459 |
|  | Ours | **0.9726** | **0.7011** | **0.9649** | **0.6209** | **0.7425** | **0.8004** | **0.9973** | **0.9554** | **0.9963** | **0.9343** | **0.9669** | **0.9700** |
| **Qwen-14B** | APS | 0.8442 | 0.5296 | 0.7852 | 0.2611 | 0.6426 | 0.6125 | 0.9828 | 0.8326 | 0.9732 | 0.6266 | 0.8554 | 0.8541 |
|  | LAC | 0.9182 | 0.4799 | 0.9132 | 0.1269 | 0.5445 | 0.5965 | 0.9748 | 0.8015 | 0.9657 | 0.5737 | 0.8216 | 0.8275 |
|  | Ours | **0.9397** | **0.6175** | **0.9286** | **0.3510** | **0.6450** | **0.6964** | **0.9924** | **0.9323** | **0.9923** | **0.7146** | **0.9494** | **0.9162** |
| **Qwen-7B** | APS | 0.5638 | 0.3437 | 0.6107 | 0.2612 | 0.4829 | 0.4525 | 0.6853 | 0.7645 | 0.9000 | 0.5113 | 0.7459 | 0.7214 |
|  | LAC | 0.4646 | 0.3542 | 0.7777 | 0.1654 | 0.4643 | 0.4452 | 0.6603 | 0.7275 | 0.8825 | 0.4754 | 0.7133 | 0.6918 |
|  | Ours | **0.6380** | **0.4958** | **0.8037** | **0.4429** | **0.6053** | **0.5971** | **0.9325** | **0.9213** | **0.9831** | **0.6817** | **0.9450** | **0.8927** |{{< /table-caption >}}

> 🔼 본 표는 제안된 적응형 준거 예측 정책(CAP)의 성능을 기존 방법인 최소 모호 분류기(LAC)와 적응형 예측 집합(APS)과 비교 분석한 결과를 보여줍니다.  비교 대상 모델은 비전-언어 모델(VLM)과 대형 언어 모델(LLM)을 포함하며, 다양한 데이터셋에서 AUROC(환각 검출)와 AUARC(불확실성 기반 선택적 생성) 지표를 사용하여 평가하였습니다.  최고 성능은 굵은 글씨체로 표시되어 있습니다.  이 표는 CAP이 다양한 모델과 데이터셋에서 우수한 성능을 보임을 보여주는 실험 결과를 요약한 것입니다.  특히 환각 검출과 불확실성 기반 선택적 생성에 대한 성능 향상을 강조합니다.
> <details>
> <summary>read the caption</summary>
> TABLE I: Comparison of CAP (Ours) with Least Ambiguous Classifiers (LAC) [5] and Adaptive Prediction Sets (APS) [6]. Models include VLMs and LLMs, assessed across datasets using AUROC (Hallucination Detection) and AUARC (Uncertainty-Guided Selective Generation). Best values are in bold.
> </details>





### In-depth insights


#### Adaptive Risk
본 논문에서 제시된 적응형 위험 관리 프레임워크는 **예측 신뢰도에 따라 역동적으로 변하는 임계값을 사용하여** 큰 언어 모델과 비전-언어 모델의 위험을 관리하는 방법을 제시합니다.  **강화 학습을 통해 최적화된 CP(Conformal Prediction) 기반의 학습 가능한 거부 정책**은 정확성, 적용 범위, 정보성 사이의 균형을 맞추어, 과도한 거부나 예측 실패를 줄입니다.  **다양한 모델과 데이터셋에서의 실험 결과는** 기존 방법보다 정확도가 향상되고, 오류율이 감소하며, 보정 오류가 개선됨을 보여줍니다.  즉, **동적 임계값 설정을 통해 위험 관리를 최적화**함으로써 안전 중요도가 높은 응용 분야에 대한 신뢰성 있는 의사결정을 지원합니다.

#### Conformal RL
**컨포멀 RL**은 컨포멀 예측의 강건성과 강화학습의 적응력을 결합한 새로운 접근 방식입니다. 이는 불확실성이 높은 상황에서도 모델의 신뢰성을 높이고, **동적으로 변화하는 환경에 적응**할 수 있는 의사결정 시스템을 구축하는 데 유용합니다. 기존의 컨포멀 예측은 고정된 임계값을 사용하여 예측의 신뢰도를 평가하지만, 컨포멀 RL은 **강화학습 에이전트**를 통해 이러한 임계값을 **동적으로 조정**하여 더욱 정확하고 효율적인 의사결정을 가능하게 합니다. 이는 특히 **자율주행, 의료 진단 등 안전이 중요한 분야**에서 매우 유용하며, **다양한 모델과 데이터셋에 적용 가능**하다는 장점이 있습니다. 하지만, 컨포멀 RL은 강화학습 알고리즘의 복잡성과 컨포멀 예측의 이론적 제약으로 인해 **최적화 과정이 어렵고, 계산 비용이 높을 수 있다**는 단점도 존재합니다. 따라서, 향후 연구에서는 이러한 한계를 극복하고 컨포멀 RL의 효율성과 적용 범위를 확장하는 데 초점을 맞춰야 할 것입니다.

#### VLM/LLM UQ
본 논문에서 다루는 VLM/LLM UQ(불확실성 정량화)는 대규모 언어 모델 및 비전-언어 모델의 예측 신뢰도를 평가하고 불확실성이 높을 때 판단을 보류하는 기능을 가능하게 합니다.  **기존의 정적 임계값에 의존하는 CP(Conformal Prediction)의 한계를 극복하기 위해 강화 학습을 통합하여 동적으로 임계값을 조정하는 학습 가능한 콘포멀 포기 정책(CAP)을 제안**합니다. 이는 정확도, 적용 범위 및 정보성 간의 최적의 절충안을 제공합니다.  **다양한 벤치마크에 대한 광범위한 평가를 통해 CAP가 정확도와 신뢰도를 향상시키고 위험 관리를 개선**함을 보여줍니다. 특히, 환각 감지 성능 향상, 불확실성 기반 선택적 생성 향상 및 보정 오류 감소 등의 성과가 눈에 띕니다.  **이는 안전이 중요한 응용 분야에서 신뢰할 수 있는 의사 결정을 위한 효과적이고 유연한 솔루션**임을 시사합니다. 하지만, **강화학습과 CP의 통합은 과적합, 편향된 포기 전략 또는 CP의 이론적 보장 왜곡 가능성**을 내포하고 있으므로, 데이터 분포 변화나 제한된 보정 데이터에 대한 추가적인 고려가 필요합니다.

#### Abstention Policy
본 논문에서 제안하는 **학습 가능한 적응적 어텐션 정책**은 불확실성이 높은 상황에서 모델이 예측을 보류하는 전략을 다룹니다. 기존의 정적 임계값 기반 방법과 달리, 강화 학습을 통해 역동적으로 임계값을 조정하여 정확도와 신뢰도 간의 최적의 균형을 찾습니다. **다양한 목표(예측 집합 크기 최소화, 신뢰할 수 있는 적용 범위 유지)**를 동시에 고려하여, 상황에 맞춰 예측, 예측 집합, 또는 보류 중 하나를 선택하는 적응력을 갖습니다. 이러한 접근 방식은 특히 안전이 중요한 분야에서 **위험 관리**에 큰 도움을 줄 수 있으며, 실험 결과를 통해 기존 방법보다 우수한 성능을 보임을 확인했습니다.

#### Future of UQ
**불확실성 정량화(UQ)의 미래는 다양한 분야에서의 잠재력을 고려할 때 매우 흥미롭습니다.**  모델의 예측 신뢰도를 평가하고 위험을 완화하는 데 필수적인 도구로 자리매김했습니다.  **향후 연구는 더욱 정교한 UQ 기법을 개발하는 데 초점을 맞춰야 합니다.** 이는 특히 복잡한 데이터 분포나 고차원 데이터에 대한 적응성을 개선하는 것을 포함합니다. 또한, **다양한 모델과 작업에 대한 UQ 방법의 일반화 가능성을 높이는 것도 중요한 과제입니다.** 실제 응용 분야에서의 신뢰성과 효율성을 개선하기 위해서는 **강건하고 효율적인 UQ 알고리즘 개발이 필요합니다.** 마지막으로, **UQ의 윤리적 및 사회적 함의에 대한 심도있는 고찰이 필요합니다.**  특히, UQ 기술의 오용이나 편향으로 인한 불평등을 방지하는 데 초점을 맞춰야 합니다.  이러한 노력을 통해 UQ는 더욱 안전하고 신뢰할 수 있으며, 공정한 의사결정을 지원하는 데 중요한 역할을 수행할 것입니다.


### More visual insights




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | Method | MMB | OOD | SQA | SB | AI2D | Avg. |
|---|---|---|---|---|---|---|---| 
| **VLMs** | **Method** | **Coverage (%) ↑** | **Coverage (%) ↑** | **Coverage (%) ↑** | **Coverage (%) ↑** | **Coverage (%) ↑** | **Coverage (%) ↑** |
| LLaVA-v1.6-34B | APS | 98.26 | 94.87 | 98.08 | 95.81 | 97.48 | 96.90 |
|  | LAC | 90.73 | 91.42 | 88.67 | 90.23 | 90.21 | 90.25 |
|  | Ours | 93.97 | 93.25 | 93.07 | 91.41 | 95.46 | 93.43 |
| LLaVA-v1.6-13B | APS | 98.99 | 96.20 | 99.29 | 97.36 | 98.86 | 98.14 |
|  | LAC | 90.18 | 91.00 | 89.28 | 89.84 | 90.47 | 90.15 |
|  | Ours | 95.57 | 92.48 | 92.06 | 90.67 | 95.14 | 93.18 |
| LLaVA-v1.6-7B | APS | 98.45 | 97.89 | 97.88 | 96.74 | 96.19 | 97.43 |
|  | LAC | 89.26 | 89.10 | 89.83 | 90.19 | 89.65 | 89.61 |
|  | Ours | 92.96 | 91.63 | 90.49 | 91.23 | 93.41 | 91.94 |
| **LLMs** |  | **HSwg** | **HDial** | **CQA** | **HSum** | **MMLU** | **Avg.** |
| Qwen-7B | APS | 92.12 | 95.24 | 98.92 | 90.18 | 96.24 | 94.54 |
|  | LAC | 89.64 | 90.90 | 90.44 | 90.12 | 90.66 | 90.35 |
|  | Ours | 91.96 | 91.70 | 95.68 | 90.17 | 91.32 | 92.16 |
| Qwen-14B | APS | 99.82 | 94.22 | 99.46 | 90.56 | 95.72 | 95.96 |
|  | LAC | 91.98 | 90.42 | 92.10 | 89.70 | 90.46 | 90.93 |
|  | Ours | 94.88 | 90.96 | 95.66 | 90.32 | 91.62 | 92.68 |
| Yi-34B | APS | 99.88 | 95.24 | 99.68 | 92.08 | 97.30 | 96.84 |
|  | LAC | 93.90 | 90.02 | 94.40 | 89.32 | 89.78 | 91.49 |
|  | Ours | 96.48 | 92.56 | 96.40 | 90.82 | 93.34 | 93.92 |{{< /table-caption >}}
> 🔼 표 II는 제안된 CAP 방법과 기존의 LAC, APS 방법의 적용 결과를 비교하여 제시합니다. 특히, 90%의 적용률을 달성하는 것을 목표로 하며, 표에는 각 모델과 데이터 세트에 대한 적용률이 표시되어 있습니다. CAP 모델은 대부분의 경우 90%의 적용률을 충족하고 있음을 보여주는 것이 핵심입니다.  표에서 밑줄 친 값들은 90% 적용률을 달성한 경우를 나타냅니다.
> <details>
> <summary>read the caption</summary>
> TABLE II: Coverage (%) evaluation: Comparison of CAP (Ours) with LAC [5] and APS [6]. CAP meets the 90% coverage guarantee, underlined, in instances.
> </details>

{{< table-caption >}}
| Models | Method | MMB ↑ | OOD ↑ | SQA ↑ | SB ↑ | AI2D ↑ | Avg. ↑ | MMB ↓ | OOD ↓ | SQA ↓ | SB ↓ | AI2D ↓ | Avg. ↓ |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| **VLMs** |  | **MMB** | **OOD** | **SQA** | **SB** | **AI2D** | **Avg.** | **MMB** | **OOD** | **SQA** | **SB** | **AI2D** | **Avg.** |
| LLaVA-v1.6-34B | APS | 87.73 | 87.42 | 84.38 | 81.72 | 83.22 | 84.89 | 2.6501 | 1.6744 | 2.7269 | 2.6556 | 2.6386 | 2.4691 |
|  | LAC | 86.75 | 86.47 | 83.53 | 81.39 | 82.55 | 84.14 | 1.2499 | 1.3101 | 1.2883 | 1.5854 | 1.4683 | 1.3804 |
|  | Ours | **88.57** | **88.19** | **86.46** | 81.64 | **88.36** | **86.64** | **1.6519** | **1.6210** | **1.8447** | **1.9937** | **2.1755** | **1.8574** |
| LLaVA-v1.6-13B | APS | 82.29 | 80.02 | 78.08 | 77.83 | 80.39 | 79.72 | 3.1275 | 2.6857 | 3.2180 | 3.1280 | 3.0165 | 3.0351 |
|  | LAC | 81.75 | 80.47 | 77.91 | 77.37 | 79.95 | 79.49 | 1.5573 | 1.6842 | 1.6884 | 1.8606 | 1.6505 | 1.6882 |
|  | Ours | **82.66** | **80.79** | **79.08** | 77.50 | **84.87** | **81.38** | **2.6249** | **2.2271** | **2.1796** | **2.2776** | **2.3135** | **2.3245** |
| LLaVA-v1.6-7B | APS | 81.36 | 81.14 | 74.98 | 76.96 | 77.44 | 78.38 | 3.1540 | 2.9613 | 3.0303 | 3.1102 | 2.9752 | 3.0462 |
|  | LAC | 80.60 | 79.89 | 75.03 | 76.65 | 77.03 | 77.84 | 1.5811 | 1.7250 | 1.8690 | 1.9445 | 1.7617 | 1.7763 |
|  | Ours | **82.19** | **81.20** | **75.34** | 76.34 | **81.83** | **79.38** | **1.9890** | **2.2982** | **2.1912** | **2.3464** | **2.3663** | **2.2382** |
| **LLMs** |  | **HSwg** | **HDial** | **CQA** | **HSum** | **MMLU** |  | **HSwg** | **HDial** | **CQA** | **HSum** | **MMLU** |  |
| Yi-34B | APS | 95.21 | 83.99 | 95.74 | 81.20 | 80.64 | 87.76 | 3.0254 | 2.0548 | 2.5868 | 1.8630 | 2.8206 | 2.4701 |
|  | LAC | 93.90 | 83.17 | 94.40 | 80.98 | 80.44 | 86.98 | 1.0000 | 1.3992 | 1.0000 | 1.3934 | 1.5886 | 1.2762 |
|  | Ours | **96.17** | **85.56** | **96.12** | **83.09** | **82.90** | **88.77** | **1.4790** | **2.0714** | **1.5664** | **1.8540** | **2.1220** | **1.8186** |
| Qwen-14B | APS | 93.75 | 81.91 | 93.95 | 62.86 | 74.43 | 81.38 | 3.0120 | 2.4050 | 2.7242 | 2.6036 | 2.9640 | 2.7418 |
|  | LAC | 91.98 | 82.42 | 92.06 | 64.22 | 74.26 | 80.59 | 1.0000 | 1.4634 | 1.0008 | 2.3154 | 2.1026 | 1.5764 |
|  | Ours | **94.02** | **83.09** | **94.32** | 57.59 | **76.13** | **81.03** | **1.3774** | **1.8742** | **1.3270** | **2.3764** | **2.5508** | **1.9012** |
| Qwen-7B | APS | 72.46 | 74.47 | 88.38 | 52.48 | 67.47 | 71.85 | 2.3844 | 2.9366 | 3.1336 | 3.0076 | 3.5344 | 3.1993 |
|  | LAC | 72.12 | 75.63 | 87.65 | 52.91 | 68.07 | 71.68 | 2.0564 | 2.0014 | 1.1790 | 2.9220 | 2.4890 | 2.1296 |
|  | Ours | **73.79** | **75.81** | **90.06** | 47.75 | **72.25** | **71.93** | **2.6116** | **2.8832** | **1.9172** | **2.5734** | **3.1820** | **2.6335** |{{< /table-caption >}}
> 🔼 표 III은 제안된 CAP 방법과 기존의 LAC와 APS 방법을 비교하여 정확도와 예측 집합 크기를 평가한 결과를 보여줍니다.  데이터셋별로 정확도를 비교 분석하여 CAP 방법이 평균적으로 가장 높은 정확도를 달성했음을 보여줍니다.  또한,  LAC의 경우 예측 집합이 너무 작아서 정보 손실이 발생할 수 있고, APS의 경우 예측 집합이 너무 커서 효율성이 떨어지는 문제점을 보완하여, CAP는 적절한 크기의 예측 집합을 유지하며 정확도를 높이는 균형을 이루었음을 강조합니다.  가장 높은 정확도 값은 굵은 글씨체로 표시하고, 적절한 크기의 예측 집합 값은 밑줄로 표시되어 있습니다.
> <details>
> <summary>read the caption</summary>
> TABLE III: Evaluation of accuracy (%) and set sizes: Comparative analysis of CAP (Ours) with standard Least Ambiguous set-valued Classifiers (LAC) [5], and Adaptive Prediction Sets (APS) [6] methods. The table highlights that our proposed method achieves the highest average accuracy across datasets, while maintaining a balance in set sizes that avoids overly narrow or broad predictions observed in the baseline methods. Highest accuracy values are in bold and balanced set size values are underlined.
> </details>

{{< table-caption >}}
| Model | Method | MMB | OOD | SQA | SB | AI2D | Avg. |
|---|---|---|---|---|---|---|---| 
| **VLMs** | **Method** | **ECE** ↓ | **ECE** ↓ | **ECE** ↓ | **ECE** ↓ | **ECE** ↓ | **ECE** ↓ |
| LLaVA-v1.6-34B | APS | 0.1277 | 0.1261 | 0.2082 | 0.1356 | 0.2353 | 0.1666 |
|  | LAC | 0.0738 | 0.1124 | 0.1143 | 0.1312 | 0.1626 | 0.1109 |
|  | Ours | **0.0085** | **0.0302** | **0.0309** | **0.0342** | **0.0385** | **0.0285** |
| LLaVA-v1.6-13B | APS | 0.1593 | 0.2218 | 0.1902 | 0.1607 | 0.2747 | 0.2013 |
|  | LAC | 0.1300 | 0.1698 | 0.1618 | 0.1759 | 0.1908 | 0.1657 |
|  | Ours | **0.0218** | **0.0159** | **0.0445** | **0.0601** | **0.0252** | **0.0335** |
| LLaVA-v1.6-7B | APS | 0.1576 | 0.2439 | 0.2128 | 0.1704 | 0.2641 | 0.2098 |
|  | LAC | 0.1314 | 0.1974 | 0.1865 | 0.1797 | 0.1987 | 0.1787 |
|  | Ours | **0.0419** | **0.0252** | **0.0498** | **0.0581** | **0.0148** | **0.0380** |
| **LLMs** |  | **HSwg** | **HDial** | **CQA** | **HSum** | **MMLU** | **Avg.** |
| Qwen-7B | APS | 0.3470 | 0.2978 | 0.2327 | 0.4099 | 0.4032 | 0.3381 |
|  | LAC | 0.3222 | 0.2680 | 0.1479 | 0.4381 | 0.3474 | 0.3047 |
|  | Ours | **0.0807** | **0.0265** | **0.0772** | **0.1409** | **0.0485** | **0.0748** |
| Qwen-14B | APS | 0.0901 | 0.1972 | 0.0996 | 0.2949 | 0.2729 | 0.1909 |
|  | LAC | 0.0156 | 0.1644 | 0.0278 | 0.3360 | 0.2273 | 0.1542 |
|  | Ours | **0.0134** | **0.0307** | **0.0266** | **0.1271** | **0.0170** | **0.0429** |
| Yi-34B | APS | 0.1111 | 0.3240 | 0.1554 | 0.2163 | 0.2479 | 0.2109 |
|  | LAC | 0.0514 | 0.2718 | 0.1030 | 0.1887 | 0.1727 | 0.1575 |
|  | Ours | **0.0522** | **0.1528** | **0.0990** | **0.0542** | **0.0337** | **0.0784** |{{< /table-caption >}}
> 🔼 표 IV는 제안된 CAP 프레임워크의 예상 보정 오차(ECE)를 기존의 LAC와 APS 방법과 비교 분석한 결과를 보여줍니다.  각 모델의 예측 신뢰도와 실제 정확도 간의 차이를 측정하는 ECE는 모델의 보정 정도를 나타냅니다.  ECE 값이 낮을수록 모델의 보정이 잘 되어 예측 신뢰도가 실제 정확도와 일치한다는 것을 의미합니다. 이 표에서 CAP 방법은 기준 방법들에 비해 유의미하게 낮은 ECE 값을 달성함으로써 더욱 정확한 보정된 예측을 제공함을 보여줍니다.
> <details>
> <summary>read the caption</summary>
> TABLE IV: Evaluation of Expected Calibration Error (ECE): Comparative analysis of the proposed CAP framework (Ours) with standard LAC [5], and APS [6] methods. The results show that the CAP method achieves significantly lower ECE values, in bold, compared to baseline.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}