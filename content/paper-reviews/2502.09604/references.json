{"references": [{"fullname_first_author": "Jiajie Zhang", "paper_title": "LongCite: Enabling LLMs to generate fine-grained citations in long-context QA", "publication_date": "2024-09-02", "reason": "This paper introduces the LongBench-Cite benchmark and the LongCite models, which are extensively used in this paper for evaluation and as a baseline."}, {"fullname_first_author": "Benjamin Cohen-Wang", "paper_title": "ContextCite: Attributing model generation to context", "publication_date": "2024-XX-XX", "reason": "This paper introduces the ContextCite method, which is a key component of the proposed SelfCite framework, providing a self-supervised way to evaluate citation quality."}, {"fullname_first_author": "Yu Meng", "paper_title": "SimPO: Simple preference optimization with a reference-free reward", "publication_date": "2024-XX-XX", "reason": "This paper introduces the SimPO algorithm, which is used in this paper to improve citation quality by preference optimization."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This paper introduces the Llama-3 model family, which serves as the base language model used in this paper's experiments."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-03-02", "reason": "This paper is a foundational work on aligning LLMs to follow instructions, which is relevant to the task of generating high-quality citations."}]}