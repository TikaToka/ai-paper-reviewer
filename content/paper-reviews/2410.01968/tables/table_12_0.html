<br><table id='3' style='font-size:16px'><tr><td>Input: SCAE encoder decoder</td></tr><tr><td>enc and dec, latent parameters of the original motions Pz (2), Pre-trained policy ��� based on SCAE, initial buffer D do</td></tr><tr><td>for k = 1 to K</td></tr><tr><td>Policy Learning:</td></tr><tr><td>for 2 = 1 to M1 do Sample latent targets Zi ~ Pz(z)</td></tr><tr><td>Extract the target states {St-H+1, · · . st} = ft = dec(�(ft,at,bt,⌀t))</td></tr><tr><td>, Rollout robot trajectory Ti ~ p(���, dec,pz)</td></tr><tr><td>Collect the trajectory and latent parameter pairs in the buffer D = {(zi, Ti)|i ~ M1}</td></tr><tr><td>Update robot policy ��� with PPO or another RL algorithm according to the bottom ob- jective in Equation 8</td></tr><tr><td>end for</td></tr><tr><td>Decoder dec Update:</td></tr><tr><td>for i = 1 to M2 do</td></tr><tr><td>Sample latent parameters and robot trajectories from D</td></tr><tr><td></td></tr><tr><td>Update the decoder dec according to the upper objective in Equation 8</td></tr><tr><td>end for end for</td></tr></table>