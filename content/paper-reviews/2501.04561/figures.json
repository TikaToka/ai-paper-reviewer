[{"figure_path": "https://arxiv.org/html/2501.04561/x1.png", "caption": "Figure 1: Overview of the motivation and architecture of OpenOmni. For simplicity, our core architecture is presented without the connectors between modules.", "description": "\uadf8\ub9bc 1\uc740 OpenOmni\uc758 \ub3d9\uae30 \ubd80\uc5ec\uc640 \uc544\ud0a4\ud14d\ucc98\ub97c \uac1c\uad04\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OpenOmni\ub294 \uc5b8\uc5b4\ub97c \uc911\uc2ec\uc73c\ub85c \uc5b8\uc5b4, \ube44\uc804 \ubc0f \uc74c\uc131 \uc804\ubc18\uc5d0 \uac78\uccd0 \uc81c\ub85c\uc0f7 \ub2e4\uc911 \ubaa8\ub4dc \uc815\ub82c\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4. \ub610\ud55c \uc790\uccb4 \uc778\uc2dd \uac10\uc815 \uc74c\uc131 \ud569\uc131\uc744 \uc704\ud55c \uacbd\ub7c9 \ub514\ucf54\ub354\ub97c \uc124\uacc4\ud558\uc5ec \uc2e4\uc2dc\uac04 \uc0c1\ud638 \uc791\uc6a9\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \ub2e8\uc21c\ud654\ub97c \uc704\ud574 \ubaa8\ub4c8 \uac04\uc758 \uc5f0\uacb0 \uc7a5\uce58 \uc5c6\uc774 \ud575\uc2ec \uc544\ud0a4\ud14d\ucc98\ub9cc \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4.  OpenOmni\ub294 \ub450 \ub2e8\uacc4\uc758 \ud6c8\ub828 \ubc29\ubc95(\ub2e4\uc911 \ubaa8\ub4dc \uc815\ub82c \ubc0f \uc74c\uc131 \uc0dd\uc131 \uacb0\ud569)\uc744 \ud1b5\ud574 \ucd5c\ucca8\ub2e8 \ub2e4\uc911 \ubaa8\ub4dc \uac70\ub300 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \uac1c\ubc1c\ud569\ub2c8\ub2e4. \uc815\ub82c \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c \uc74c\uc131 \ubaa8\ub378\uc744 \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \uc791\uc5c5\uc5d0 \ub300\ud574 \ucd94\uac00\ub85c \ud6c8\ub828\ud558\uc5ec \ube44\uc804\uc5d0\uc11c \uc74c\uc131\uc73c\ub85c \uc77c\ubc18\ud654\ud558\uace0, \uc74c\uc131 \uc0dd\uc131 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uacbd\ub7c9 \ub514\ucf54\ub354\ub97c \ud1b5\ud574 \uc2e4\uc2dc\uac04 \uac10\uc815 \uc74c\uc131\uc744 \uc6a9\uc774\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.04561/x2.png", "caption": "Figure 2: Training process of OpenOmni. To facilitate the omnimodal learining and real-time emotional speech generation of OpenOmni, we employ a three-stage training process: (1) Speech-Text Generation: In this stage, we utilize a speech encoder to extract continuous speech features and text features for alignment learning, which enables the large language model to develop speech understanding capabilities. (2) Image-Text Generation: This stage involves the use of an image encoder to extract continuous image features and text features from OpenOmni, facilitating alignment learning that enhances OpenOmni\u2019s image comprehension and instruction-following abilities. Additionally, this process achieves implicit omnimodal alignment, granting the model the capacity for omni-understanding. (3) Speech Generation: In the final stage, we train a lightweight speech decoder using high-quality synthesized speech dialogue data, focusing on optimizing emotional speech preferences directly. This enables OpenOmni to generate real-time self-aware emotional speech.", "description": "\ubcf8 \uadf8\ub9bc\uc740 OpenOmni\uc758 \uc138 \ub2e8\uacc4 \ud559\uc2b5 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 1\ub2e8\uacc4\ub294 \uc74c\uc131-\ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc73c\ub85c, \uc74c\uc131 \uc778\ucf54\ub354\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc74c\uc131 \ud2b9\uc9d5\uacfc \ud14d\uc2a4\ud2b8 \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\uace0 \uc774\ub97c \uc815\ub82c \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud558\uc5ec \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc74c\uc131 \uc774\ud574 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. 2\ub2e8\uacc4\ub294 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc73c\ub85c, \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \ud2b9\uc9d5\uacfc \ud14d\uc2a4\ud2b8 \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\uace0 OpenOmni\uc758 \uc774\ubbf8\uc9c0 \uc774\ud574 \ubc0f \uc9c0\uc2dc \ub530\ub974\uae30 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uc815\ub82c \ud559\uc2b5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc5d0\uc11c \uc554\uc2dc\uc801 \ub2e4\ubaa8\ub2ec \uc815\ub82c\uc774 \uc774\ub8e8\uc5b4\uc838 \ubaa8\ub378\uc758 \ub2e4\ubaa8\ub2ec \uc774\ud574 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. 3\ub2e8\uacc4\ub294 \uc74c\uc131 \uc0dd\uc131\uc73c\ub85c, \uacbd\ub7c9\ud654\ub41c \uc74c\uc131 \ub514\ucf54\ub354\ub97c \uace0\ud488\uc9c8 \ud569\uc131 \uc74c\uc131 \ub300\ud654 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\uc2dc\ud0a4\uace0 \uac10\uc815\uc801 \uc74c\uc131 \uc120\ud638\ub3c4\ub97c \uc9c1\uc811 \ucd5c\uc801\ud654\ud558\uc5ec \uc2e4\uc2dc\uac04 \uc790\uae30 \uc778\uc2dd \uac10\uc815 \uc74c\uc131 \uc0dd\uc131\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2501.04561/x3.png", "caption": "Figure 3: Structure of speech decoder. The speech decoder consists of a mixture of expert module and multiple transformer layers, achieving end-to-end speech unit learning through connectionist temporal classification (CTC) loss.", "description": "\uadf8\ub9bc 3\uc740 OpenOmni \ubaa8\ub378\uc758 \uc74c\uc131 \ub514\ucf54\ub354 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc74c\uc131 \ub514\ucf54\ub354\ub294 \uc804\ubb38\uac00 \ud63c\ud569 \ubaa8\ub4c8(mixture of expert module)\uacfc \uc5ec\ub7ec \uac1c\uc758 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ub808\uc774\uc5b4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uc5f0\uacb0\uc8fc\uc758 \uc2dc\uac04 \ubd84\ub958(connectionist temporal classification, CTC) \uc190\uc2e4 \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \uc74c\uc131 \ub2e8\uc704 \ud559\uc2b5\uc744 \uc885\ub2e8 \uac04(end-to-end)\uc73c\ub85c \uc218\ud589\ud569\ub2c8\ub2e4.  \uc989, \uc785\ub825\uc73c\ub85c\ubd80\ud130 \uc74c\uc131 \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\uace0, \uc774\ub97c \ubc14\ud0d5\uc73c\ub85c \uc9c1\uc811 \uc74c\uc131\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ud558\ub098\uc758 \ub124\ud2b8\uc6cc\ud06c \uc548\uc5d0\uc11c \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud569\ub2c8\ub2e4.", "section": "3.4 \uc74c\uc131 \uc0dd\uc131"}, {"figure_path": "https://arxiv.org/html/2501.04561/extracted/6119121/figs/openomni_add.jpg", "caption": "Figure 4: Overview of Speech Decoder Mode. OpenOmni supports both autoregressive (AR) and non-autoregressive speech (NAR) generation. The NAR mode uses CTC loss modeling and a 6K speech vocabulary size to enable real-time parallel speech decoding generation. The AR mode uses NTP loss modeling and a speech vocabulary size of 16K to support streaming decoding and higher-quality speech generation. In order to make the training of speech generator more stable and easy, we design a text-guided output feature fusion method to ensure the correctness of semantic alignment in speech generation modeling.", "description": "\uadf8\ub9bc 4\ub294 OpenOmni\uc758 \uc74c\uc131 \ub514\ucf54\ub354 \ubaa8\ub4dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OpenOmni\ub294 \uc790\uae30 \ud68c\uadc0(AR) \ubc0f \ube44\uc790\uae30 \ud68c\uadc0(NAR) \uc74c\uc131 \uc0dd\uc131 \ubaa8\ub450\ub97c \uc9c0\uc6d0\ud569\ub2c8\ub2e4. NAR \ubaa8\ub4dc\ub294 CTC \uc190\uc2e4 \ubaa8\ub378\ub9c1\uacfc 6K \ud06c\uae30\uc758 \uc5b4\ud718 \uc9d1\ud569\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2e4\uc2dc\uac04 \ubcd1\ub82c \uc74c\uc131 \ub514\ucf54\ub529 \uc0dd\uc131\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. AR \ubaa8\ub4dc\ub294 NTP \uc190\uc2e4 \ubaa8\ub378\ub9c1\uacfc 16K \ud06c\uae30\uc758 \uc5b4\ud718 \uc9d1\ud569\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2a4\ud2b8\ub9ac\ubc0d \ub514\ucf54\ub529 \ubc0f \ub354 \ub192\uc740 \ud488\uc9c8\uc758 \uc74c\uc131 \uc0dd\uc131\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \uc74c\uc131 \uc0dd\uc131\uae30\uc758 \ud559\uc2b5\uc744 \ub354\uc6b1 \uc548\uc815\uc801\uc774\uace0 \uc6a9\uc774\ud558\uac8c \ud558\uae30 \uc704\ud574, \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc758\ubbf8\uc801 \uc815\ub82c\uc758 \uc815\ud655\uc131\uc744 \ubcf4\uc7a5\ud558\ub294 \ud14d\uc2a4\ud2b8 \uae30\ubc18 \ucd9c\ub825 \ud2b9\uc9d5 \uc735\ud569 \ubc29\uc2dd\uc744 \uc124\uacc4\ud588\uc2b5\ub2c8\ub2e4.", "section": "3.4 \uc74c\uc131 \uc0dd\uc131"}]