<br><table id='5' style='font-size:14px'><tr><td>Method</td><td>Time</td><td colspan="3">Accuracy</td><td>R @1(I⌀U=0.5)</td><td>R @ I⌀U=0.7)</td><td colspan="2">Accuracy</td></tr><tr><td></td><td></td><td>AVSD</td><td>Music-AVQA</td><td>AVQA</td><td colspan="2">Charades-STA</td><td>OCTAV-ST Youcook2</td><td>OCTAV-ST ActivityNet</td></tr><tr><td>PandaGPT (Su et al., 2023)</td><td>X</td><td>26.1†</td><td>33.7</td><td>79.8†</td><td>-</td><td>-</td><td>x</td><td></td></tr><tr><td>Video LLaMA (Cheng et al., 2024)</td><td>X</td><td>36.7†</td><td>36.6</td><td>81.0†</td><td>3.8</td><td>0.9</td><td>x</td><td></td></tr><tr><td>MacawLLM (Lyu et al., 2023)</td><td>X</td><td>34.3†</td><td>31.8</td><td>78.7†</td><td>-</td><td>-</td><td>x</td><td></td></tr><tr><td>AVLLM (Shu et al., 2023)</td><td>X</td><td>52.6†</td><td>45.2</td><td>-</td><td>-</td><td>-</td><td>x</td><td></td></tr><tr><td>AVicuna (Tang et al., 2024)</td><td>V</td><td>53.1†</td><td>49.6</td><td>-</td><td>-</td><td>-</td><td>-</td><td>、</td></tr><tr><td>Video LLaMA 2(Zhang et al., 2023)</td><td>X</td><td>53.3†</td><td>73.6†</td><td></td><td>-</td><td>-</td><td>9.14</td><td>10.55</td></tr><tr><td>GroundingGPT (Li et al⌀, 2024)</td><td></td><td>-</td><td>-</td><td>-</td><td>29.6†</td><td>11.9†</td><td>1.20+(3.87)</td><td>1.57+(7.6)</td></tr><tr><td>OMCAT (RoTE)</td><td>V</td><td>49.4</td><td>73.8�(51.2)</td><td>90.2†</td><td>32.3</td><td>15.9</td><td>16.9† (9.9)</td><td>19.0� (11.2)</td></tr></table>