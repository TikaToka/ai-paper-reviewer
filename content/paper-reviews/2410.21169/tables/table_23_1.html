<table id='3' style='font-size:16px'><tr><td>Dataset</td><td>Instance</td><td>Type</td><td>Language</td><td>Task</td><td>Feature</td></tr><tr><td>ICDAR2013 [349]</td><td>150</td><td>Government Documents</td><td>English</td><td>TD & TSR</td><td>Covers complex structures and cross-page tables</td></tr><tr><td>ICDAR2017 POD [342]</td><td>1548</td><td>Scientific papers</td><td>English</td><td>TD</td><td>Includes shape and formula detec- tion</td></tr><tr><td>ICDAR2019 [350]</td><td>2439</td><td>Multiple Types</td><td>English</td><td>TD & TSR</td><td>Includes historical and modern ta- bles</td></tr><tr><td>TABLE2LATEX-450K [124]</td><td>140000</td><td>Scientific papers</td><td>English</td><td>TSR</td><td></td></tr><tr><td>RVL-CDIP (subset) [351]</td><td>518</td><td>Receipts</td><td>English</td><td>TD</td><td>Derived from RVL-CDIP</td></tr><tr><td>IIIT-AR-13K [352]</td><td>17,000 (not only tables)</td><td>Annual Reports</td><td>Multi-langugae</td><td>TD</td><td>Does not only contain tables</td></tr><tr><td>CamCap [353]</td><td>85</td><td>Table images</td><td>English</td><td>TD & TSR</td><td>Used for evaluating table detection in camera-captured images</td></tr><tr><td>UNLV Table [354]</td><td>2889</td><td>Journals, Newspapers, Business Letters</td><td>English</td><td>TD</td><td></td></tr><tr><td>UW-3 Table [355]</td><td>1,600 (around 120 tables)</td><td>Books, Magazines</td><td>English</td><td>TD</td><td>Manually labeled bounding boxes</td></tr><tr><td>Marmot [356]</td><td>2000</td><td>Conference Papers</td><td>English and Chinese</td><td>TD</td><td>Includes diversified table types; still expanding</td></tr><tr><td>TableBank [357]</td><td>417234</td><td>Multiple Types</td><td>English</td><td>TD & TSR</td><td>Automatically created by weakly su- pervised methods</td></tr><tr><td>DeepFigures [287]</td><td>5,500,000 (tables and figures)</td><td>Scientific papers</td><td>English</td><td>TD</td><td>Supports figure extraction</td></tr><tr><td>PubTabNet [125]</td><td>568000</td><td>Scientific papers</td><td>English</td><td>TSR</td><td>Structure and content recognition of tables</td></tr><tr><td>PubTables-1M [358]</td><td>1000000</td><td>Scientific papers</td><td>English</td><td>TSR [122]</td><td>Evaluates the oversegmentation is- sue</td></tr><tr><td>SciTSR [359]</td><td>15000</td><td>Scientific papers</td><td>English</td><td>TSR</td><td></td></tr><tr><td>FinTable [359]</td><td>112887</td><td>Scientific and Financial Tables</td><td>English</td><td>TD & TSR</td><td>Automatic Annotation methods</td></tr><tr><td>SynthTabNet [360]</td><td>600000</td><td>Multiple Types</td><td>English</td><td>TD & TSR</td><td>Synthetic tables</td></tr><tr><td>Wired Table in the Wild [121]</td><td>14582 (pages)</td><td>Photos, Files, and Web Pages</td><td>English</td><td>TSR</td><td>Deformed and occluded images</td></tr><tr><td>WikiTableSet [361]</td><td>50000000</td><td>Wikipedia</td><td>English, Japanese, French</td><td>TSR</td><td></td></tr><tr><td>STDW [362]</td><td>7000</td><td>Multiple Types</td><td>English</td><td>TD</td><td></td></tr><tr><td>TableGraph-350K [363]</td><td>358,767</td><td>Academic Table</td><td>English</td><td>TSR</td><td>including TableGraph-24K</td></tr><tr><td>TabRecSet [364]</td><td>38100</td><td>Multiple Types</td><td>English and Chinese</td><td>TSR</td><td></td></tr><tr><td>DECO [365]</td><td>1165</td><td>Multiple Types</td><td>English</td><td>TD</td><td>Enron document electronic table files</td></tr><tr><td>iFLYTAB [366]</td><td>17291</td><td>Multiple Types</td><td>Chinese and English</td><td>TD & TSR</td><td>Online and offline tables from vari- ous scenarios</td></tr><tr><td>FinTab [367]</td><td>1,600</td><td>Financial Table</td><td>Chinese</td><td>TSR</td><td></td></tr></table>