<table id='1' style='font-size:14px'><tr><td>Metric</td><td>Definition</td><td>Description</td></tr><tr><td>CER</td><td>S+ D + I CER N</td><td>Measures the character-level discrepancy between recognized and ground truth text, suitable for OCR tasks requiring high precision.</td></tr><tr><td>Edit Distance</td><td>D(i-1,j)+1 D(i,j) = min [ D(i,j -1)+1 D(i - 1, j -1) + Cost(s1 [i], s2[j]) N</td><td>Measures the minimum edit distance needed to convert recognized text into ground truth text.</td></tr><tr><td>BLEU</td><td>BLEU = BP x exp M Wn log Pn ) n=1</td><td>Measures the minimum edit distance needed to convert recognized text into ground truth text.</td></tr><tr><td>METEOR</td><td>METEOR = Fmean x (1 - Penalty)</td><td>Accounts for both precision and recall, and supports stem and synonym matching.</td></tr><tr><td>ROUGE-N</td><td>ï¿½ ngramE Reference min(Countmatch (ngram), Countcandidate (ngram)) ROUGE-N = ngramEReference Countreference (ngram)</td><td>An improved version of BLEU that focuses on recall rather than precision.</td></tr></table>