{"references": [{"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), a foundational model type for the field that is the basis for many of the models used in this paper."}, {"fullname_first_author": "T. Karras", "paper_title": "Elucidating the design space of diffusion-based generative models", "publication_date": "2022-12-01", "reason": "This paper provides a comprehensive overview of the design space and characteristics of diffusion models, which is directly relevant to this paper's exploration of inference-time scaling."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a model used as a verifier in the proposed framework, making it highly relevant to the paper's investigation of inference-time scaling in image generation."}, {"fullname_first_author": "C. Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-12-01", "reason": "This paper introduces DrawBench, one of the datasets used in this paper's experimental evaluation of inference-time scaling, making it a key component of the paper's empirical analysis."}, {"fullname_first_author": "K. Huang", "paper_title": "T2I-CompBench: A comprehensive benchmark for open-world compositional text-to-image generation", "publication_date": "2023-12-01", "reason": "This paper introduces T2I-CompBench, another dataset utilized for the empirical evaluation, significantly contributing to the paper's broader assessment of inference-time scaling across diverse generation tasks."}]}