[{"content": "| Phase | Type | Public Datasets | Public | In-House |\n|---|---|---|---|---|\n| Pretrain | Pure-Text | - | - | 150.7M |\n|  | Caption | [86][67][189][23] | 33.2M | 49.1M |\n|  | Interleaved | [71] | 19.1M | 28.7M |\n|  | OCR | [57] | 12.4M | 7.8M |\n| Total | - | - | 71.3M | 238.2M |", "caption": "Table 1: Detailed statistics of the training data of image pretrain.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \uc774\ubbf8\uc9c0 \uc0ac\uc804 \ud559\uc2b5 \ub370\uc774\ud130 \ud1b5\uacc4\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'Phase', 'Type', 'Public Datasets', 'Public In-House', 'OCR', 'Total'\uc758 \uc5f4\uc774 \uc788\uc73c\uba70, \uac01 \uc5f4\uc740 \uc774\ubbf8\uc9c0 \uc0ac\uc804 \ud559\uc2b5 \ub370\uc774\ud130\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'Phase'\ub294 \ub370\uc774\ud130 \uc218\uc9d1 \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0b4\uace0, 'Type'\uc740 \ub370\uc774\ud130 \uc720\ud615(Pure-Text, Caption, Interleaved)\uc744 \ub098\ud0c0\ub0b4\uba70, 'Public Datasets'\uc640 'Public In-House'\ub294 \uac01\uac01 \uacf5\uac1c \ub370\uc774\ud130\uc14b\uacfc \ub0b4\ubd80 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130 \uc591\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. 'OCR' \uc5f4\uc740 \uad11\ud559 \ubb38\uc790 \uc778\uc2dd(OCR) \ub370\uc774\ud130\uc758 \uc591\uc744 \ubcf4\uc5ec\uc8fc\uba70, 'Total'\uc5f4\uc740 \uac01 \ub2e8\uacc4\uc758 \ucd1d \ub370\uc774\ud130 \uc591\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc758 \uaddc\ubaa8\uc640 \ub2e4\uc591\uc131\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 \uace0\ud488\uc9c8 \ub2e4\uc911 \ubaa8\ub2ec \uc0ac\uc804 \ud559\uc2b5 \ub370\uc774\ud130"}, {"content": "| QA Type | Dataset Name | Public Datasets | Questions |\n|---|---|---|---|\n| Description | Synthetic Data | - | 300K |\n|  | ShareGPT-4o | [29] | 2K |\n|  | Koala | [150] | 30M |\n| QA | Synthetic Data | [80], [82], [157] | 164K |\n|  | VideoChatGPT-Plus | [107] | 318K |\n|  | ShareGemini | [131] | 205K |\n| Total | - | - | 31M |", "caption": "Table 2: Detailed statistics of the training data of video pretrain.", "description": "\uc774 \ud45c\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \ube44\ub514\uc624 \uc0ac\uc804 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc0c1\uc138 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\ub514\uc624 \ub370\uc774\ud130\ub294 \ud06c\uac8c \ube44\ub514\uc624 \ucea1\uc158 \ub370\uc774\ud130\uc640 \ube44\ub514\uc624 \uc9c8\ubb38 \ub2f5\ubcc0(QA) \ub370\uc774\ud130 \ub450 \uac00\uc9c0 \uc720\ud615\uc73c\ub85c \ub098\ub269\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ub370\uc774\ud130 \uc720\ud615\uc5d0 \ub300\ud55c \ub370\uc774\ud130\uc14b \uc774\ub984, \ub370\uc774\ud130 \uc720\ud615(QA \ub610\ub294 \ucea1\uc158), \ub370\uc774\ud130 \uc6d0\ubcf8(\ud37c\ube14\ub9ad \ub610\ub294 \ud569\uc131), \uc9c8\ubb38 \uc218, \uc124\uba85 \uc218 \ub4f1\uc758 \uc815\ubcf4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc804\uccb4 \ube44\ub514\uc624 \uc0ac\uc804 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud569\uacc4 \uc815\ubcf4\ub3c4 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.1 \uace0\ud488\uc9c8 \ub2e4\uc911 \ubaa8\ub2ec \uc0ac\uc804 \ud6c8\ub828 \ub370\uc774\ud130"}, {"content": "| Type | Task | Data Format | Hours (k) |\n|---|---|---|---|\n| Audio Understanding | Automatic Speech Recognition (ASR) | &lt;prompt, audio, transcript&gt; | 185 |\n|  | Audio Query Answer (AQA) | &lt;prompt, audio, response&gt; | 21 |\n|  | Speech-to-Text Translation (S2TT) | &lt;prompt, audio, translated_text&gt; | 15 |\n|  | Audio-Text Interleaved (INTLV) | &lt;audio_1, text_2, audio_3, text_4, ...&gt; | 393 |\n| Audio Generation | Text-to-Speech (TTS) | &lt;text, audio&gt; | 51 |\n|  | Interleaved Text-to-Speech (ITTS) | &lt;text_1, audio_1, text_2, audio_2, ...&gt; | 142 |\n|  | Pure Audio | &lt;audio&gt; | 80 |\n| Total | - | - | 887 |", "caption": "Table 3: Detailed statistics of the training data of audio pretrain.", "description": "\ubcf8 \ud45c\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \uc624\ub514\uc624 \uc804\ucc98\ub9ac \ud559\uc2b5 \ub370\uc774\ud130 \ud1b5\uacc4\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130 \uc720\ud615(\uc790\ub3d9 \uc74c\uc131 \uc778\uc2dd, \uc74c\uc131 \uc9c8\ubb38 \ub2f5\ubcc0, \uc74c\uc131 \ud14d\uc2a4\ud2b8 \ubcc0\ud658, \uc624\ub514\uc624 \ud14d\uc2a4\ud2b8 \uc0bd\uc785, \ud14d\uc2a4\ud2b8 \uc74c\uc131 \ubcc0\ud658, \ud14d\uc2a4\ud2b8 \uc74c\uc131 \uc0bd\uc785, \uc21c\uc218 \uc624\ub514\uc624), \ub370\uc774\ud130 \ud615\uc2dd, \ubc0f \uac01 \ub370\uc774\ud130 \uc720\ud615\uc5d0 \ud574\ub2f9\ud558\ub294 \uc2dc\uac04(\uc2dc\uac04)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c \uc624\ub514\uc624 \ub370\uc774\ud130\uc758 \uc591\uacfc \uc720\ud615\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 \uace0\ud488\uc9c8 \ub2e4\uc911 \ubaa8\ub2ec \uc0ac\uc804 \ud559\uc2b5 \ub370\uc774\ud130"}, {"content": "| Category | Text | Image | Video | Audio | Image-Audio |\n|---|---|---|---|---|---| \n| Quantity | 400K | 16M | 100K | 282K | 60K |", "caption": "Table 4: Omni-modal SFT data statistics for Baichuan-Omni-1.5\u00a0. Here we summarize the category and quantities of our SFT dataset.", "description": "\ubcf8 \ud45c\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \ub2e4\uc911 \ubaa8\ub4dc \uc9c0\ub3c4 \ud559\uc2b5 \ubbf8\uc138 \uc870\uc815(Supervised Fine-Tuning, SFT) \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \uc694\uc57d\ud55c \uac83\uc785\ub2c8\ub2e4.  Baichuan-Omni-1.5 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ub370\uc774\ud130(\ud14d\uc2a4\ud2b8, \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624)\uc640 \uac01 \uc720\ud615\ubcc4 \ub370\uc774\ud130 \uc218\ub7c9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378\uc758 \ub2e4\uc911 \ubaa8\ub4dc \uc774\ud574 \ub2a5\ub825 \ud5a5\uc0c1\uc744 \uc704\ud55c \ub2e4\uc591\ud55c \ub370\uc774\ud130 \uc18c\uc2a4\uc758 \ud65c\uc6a9\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uc815\ubcf4\uc785\ub2c8\ub2e4. \ud45c\ub97c \ud1b5\ud574 \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8\ubfd0 \uc544\ub2c8\ub77c \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624 \ub370\uc774\ud130\ub97c \uad11\ubc94\uc704\ud558\uac8c \ud65c\uc6a9\ud558\uc5ec \ud6c8\ub828\ub418\uc5c8\uc74c\uc744 \uc54c \uc218 \uc788\uc73c\uba70, \uc774\ub294 \ubc94\uc6a9\uc801\uc778 \ub2e4\uc911 \ubaa8\ub4dc \uc774\ud574 \ub2a5\ub825\uc744 \uac16\ucd94\ub3c4\ub85d \ud558\ub294 \ub370 \uae30\uc5ec\ud588\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3 Baichuan-Omni-1.5"}, {"content": "| Scene | Source | Proportion |\n|---|---|---|\n| GeneralQA | Leopard-Instruct [61], LLaVA-OneVision-Data [76], MMInstruct-GPT4V [99], the Cauldron [72], GeoGPT4V-1.0 [15], MMDU [102], Lova3 [188], CaD-Inst [14], VisionArena-Battle [25], Q-Instruct-DB [154], MultipanelVQA [41], ConMe [58], FABAInstruct [90], ScienceQA [128], MapQA [16], Others | 32.26% |\n| OCR | MathWriting [48], WebSight [73], ST-VQA [11], GQA [60], HME100K [169], UberTextQA [10], OCR-VQA [117], TallyQA [2], SlideVQA [139], VizWiz [10], NorHand-v3 [140], LLaVAR [186], Textualization [40], PViT [182], Others | 26.51% |\n| Graphical | DVQA [64], TinyChart [179], Chart2Text [66], ArxivQA [84], ChartLlama [52], InfographicVQA [112], FlowVQA [137], MultiChartQA [194], ChartGemma [111], UniChart [109], TAT-DQA [193], PlotQA [116], FigureQA [65], MMTab [191], Others | 9.04% |\n| Mathematics | MathV-360K [132], Geo170k [46], R-COT [34], A-OKVQA [130], Super-CLEVR [94], CLEVR-Math [96], TabMWP [105], GeoQA+ [5], MAVIS [181], Iconqa [106], UniGeo [17], PUMA_VarsityTutors [195], Others | 10.31% |\n| Spatiotemporal | CCTSDB2021 [177], SODA10M [51], EmbSpatial [36], LLaVA-VSD [62], SpatialSense [163], SpatialMM [133], Whatsup [12], VSR [180], SpatialSense [163], Others | 2.63% |\n| Captioning | TextCaps [134], MMsci [92], Synthetic Data, Others | 8.23% |\n| Medical | PubMed [113], HAM10000 [144], PMC-VQA [184], PathVQA [54], AIROGS [30], MedFMC [147], Kvasir-VQA [47], IU X-ray [33], VQA-RAD [70], DME VQA [141], and other specialized medical datasets | 11.02% |", "caption": "Table 5: Image SFT data for Baichuan-Omni-1.5\u00a0. This table summarizes the image SFT dataset categories, their sources, and proportions for various tasks.", "description": "\ud45c 5\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0 SFT(Supervised Fine-Tuning) \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc694\uc57d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \uc791\uc5c5(\uacfc\uc5c5)\uc5d0 \ub530\ub77c \uc5ec\ub7ec \ubc94\uc8fc\ub85c \ub098\ub258\uba70, \uac01 \ubc94\uc8fc\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \ucd9c\ucc98\uc640 \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucc28\uc9c0\ud558\ub294 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uac01 \uc791\uc5c5 \uc720\ud615(\uc608: \uc77c\ubc18\uc801\uc778 \uc9c8\ubb38\uc751\ub2f5, OCR, \uadf8\ub798\ud504, \uc218\ud559, \uc2dc\uacf5\uac04\uc801 \uc774\ud574, \uc790\ub9c9 \uc0dd\uc131, \uc758\ub8cc)\uc5d0 \ub300\ud574 \uc5b4\ub5a4 \ub370\uc774\ud130\uc14b\ub4e4\uc774 \uc0ac\uc6a9\ub418\uc5c8\uace0, \uac01 \ub370\uc774\ud130\uc14b\uc774 \uc804\uccb4 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc5bc\ub9c8\ub098 \ub9ce\uc740 \ube44\uc911\uc744 \ucc28\uc9c0\ud558\ub294\uc9c0 \ub098\ud0c0\ub0b4\ub294 \ud45c\uc785\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ub370\uc774\ud130 \uc18c\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud3ec\uad04\uc801\uc778 \uc774\ubbf8\uc9c0 \uc774\ud574 \ub2a5\ub825\uc744 \ud655\ubcf4\ud558\uae30 \uc704\ud55c \ub370\uc774\ud130 \uad6c\uc131 \uc804\ub7b5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\ub77c\uace0 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.4 Image Data"}, {"content": "| Model | MMLU (Acc.) | CMMLU (Acc.) | AGIEval (Acc.) | C-Eval (Acc.) | GAOKAO (Acc.) |\n|---|---|---|---|---|---| \n| **Comprehensive Tasks** |  |  |  |  |  |\n| *Proprietary Models* |  |  |  |  |  |\n| GPT-4o | **88.0**<sup>\u2662</sup> | **78.3**<sup>\u2662</sup> | **62.3**<sup>\u2662</sup> | **86.0**<sup>\u2662</sup> | - |\n| GPT-4o-mini | 82.0 | 67.6 | 52.2 | 63.6 | 70.8 |\n| *Open-source Models (Pure text)* |  |  |  |  |  |\n| MAP-Neo (7B) | 58.2 | 55.1 | 33.9 | 57.5 | - |\n| Qwen1.5-Chat (7B) | 61.5 | 68.0 | 39.3 | 68.8 | - |\n| Llama3-Instruct (8B) | 67.1 | 51.7 | 38.4 | 50.7 | - |\n| OLMo (7B) | 28.4 | 25.6 | 19.9 | 27.3 | - |\n| *Open-source Models (Omni-modal)* |  |  |  |  |  |\n| VITA (8x7B) | 71.0<sup>\u2217</sup> | 46.6 | 46.2<sup>\u2217</sup> | 56.7<sup>\u2217</sup> | - |\n| VITA-1.5 (7B) | 71.0 | 75.1 | 47.9 | 65.6 | 57.4 |\n| Baichuan-Omni (7B) | 65.3 | 72.2 | 47.7 | 68.9 | - |\n| MiniCPM-o 2.6 (7B) | 65.3 | 63.3 | 50.9 | 61.5 | 56.3 |\n| **Baichuan-Omni-1.5 (7B)** | **72.2** | **75.5** | **54.4** | **73.1** | **73.5** |", "caption": "Table 6: Results on comprehensive pure text benchmarks. \u2217*\u2217: Officially reported results. \u2662\u2662\\diamondsuit\u2662: Retrieved results from official leaderboard or recent papers. Other unlabeled results are reproduced by ourselves.", "description": "\ud45c 6\uc740 \ub2e4\uc591\ud55c \uc21c\uc218 \ud14d\uc2a4\ud2b8 \ubca4\uce58\ub9c8\ud06c(MMLU, CMMLU, AGIEval, C-Eval, GAOKAO)\uc5d0\uc11c \uc5ec\ub7ec \uc5b8\uc5b4 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub3c5\uc810\uc801 \ubaa8\ub378(GPT-4, GPT-4-mini)\uacfc \uc624\ud508\uc18c\uc2a4 \uc77c\ubc18 \ubaa8\ub378(MAP-Neo, Qwen1.5-Chat, Llama3-Instruct, OLMO), \uadf8\ub9ac\uace0 \uc624\ud508\uc18c\uc2a4 \ub2e4\uc911 \ubaa8\ub4dc \ubaa8\ub378(VITA, Baichuan-Omni, MiniCPM-0 2.6)\uc758 \uc131\ub2a5\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0 \ud45c\uc2dc\ub41c \uad04\ud638 \uc548\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc218\ub294 LLM\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc218\ub97c \ub098\ud0c0\ub0b4\uba70, \ubcc4\ub3c4\ub85c \uba85\uc2dc\ub418\uc9c0 \uc54a\ub294 \ud55c \ubaa8\ub4e0 \uacb0\uacfc\ub294 \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \ub3d9\uc77c\ud55c \uc124\uc815\uc73c\ub85c \uc7ac\ud604\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0 \ud45c\uc2dc\ub41c \uacb0\uacfc \uc911, \u2217 \ud45c\uc2dc\ub294 \uacf5\uc2dd\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uacb0\uacfc\uc774\uba70, \u2662 \ud45c\uc2dc\ub294 \uacf5\uc2dd \ub9ac\ub354\ubcf4\ub4dc \ub610\ub294 \ucd5c\uadfc \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc628 \uacb0\uacfc\uc785\ub2c8\ub2e4. \ub098\uba38\uc9c0 \uacb0\uacfc\ub294 \uc800\uc790\ub4e4\uc774 \uc9c1\uc811 \uc7ac\ud604\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "4.1 \uc21c\uc218 \uc5b8\uc5b4 \uc791\uc5c5 \uc131\ub2a5"}, {"content": "| MMLU |\n|---|---| \n| (Acc.) |", "caption": "Table 7: Results on Multi-choice benchmarks and Yes-or-No benchmarks. \u2217*\u2217: Officially reported results. \u2662\u2662\\diamondsuit\u2662: Retrieved results from official leaderboard or recent papers. Other unlabeled results are reproduced by ourselves.", "description": "\ud45c 7\uc740 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc911 \uc120\ud0dd \ubc0f \uc608/\uc544\ub2c8\uc624 \uc9c8\ubb38\uc5d0 \ub300\ud55c \uc5ec\ub7ec \ub2e4\uc911 \ubaa8\ub4dc \ubc0f \ub2e8\uc77c \ubaa8\ub4dc \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ubaa8\ub378 \uc774\ub984, \ub9e4\uac1c\ubcc0\uc218 \uc218, \uadf8\ub9ac\uace0 MMBench-EN, MMBench-CN, SEED-IMG, MMMU(val), HallucinationBench\uc640 \uac19\uc740 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4(Acc.) \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uacf5\uc2dd\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uacb0\uacfc\ub294 \ubcc4\ud45c(*)\ub85c, \uacf5\uc2dd \ub9ac\ub354\ubcf4\ub4dc \ub610\ub294 \ucd5c\uadfc \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc628 \uacb0\uacfc\ub294 \ub2e4\uc774\uc544\ubaac\ub4dc \uae30\ud638(\u2662)\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \ub098\uba38\uc9c0 \uacb0\uacfc\ub294 \uc5f0\uad6c\ud300\uc774 \uc9c1\uc811 \uc7ac\ud604\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4.2 \uc774\ubbf8\uc9c0 \uc774\ud574 \uc791\uc5c5\uc758 \uc131\ub2a5"}, {"content": "| CMMLU |\n|---|---| \n| (Acc.) |", "caption": "Table 8: Results on image VQA benchmarks. \u2217*\u2217: Officially reported results. \u2662\u2662\\diamondsuit\u2662: Retrieved results from official leaderboard or recent papers. Other unlabeled results are reproduced by ourselves.", "description": "\ud45c 8\uc740 \uc774\ubbf8\uc9c0 VQA(Visual Question Answering) \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(\ub3c5\uc810 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \uc634\ub2c8\ubaa8\ub2ec \ubaa8\ub378)\uc758 \uc131\ub2a5\uc774 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c(RealWorldQA, MathVista-mini, TextVQA, ChartQA, OCRBench)\uc5d0 \ub300\ud574 \uc815\ud655\ub3c4(Acc.)\ub85c \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  * \ud45c\uc2dc\ub294 \uacf5\uc2dd\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uacb0\uacfc\ub97c \ub098\ud0c0\ub0b4\uace0, \u2662 \ud45c\uc2dc\ub294 \uacf5\uc2dd \ub9ac\ub354\ubcf4\ub4dc \ub610\ub294 \ucd5c\uadfc \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc628 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub098\uba38\uc9c0 \uacb0\uacfc\ub294 \ub3d9\uc77c\ud55c \uc124\uc815\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc7ac\ud604\ud55c \uac83\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0 \uc774\ud574 \ub2a5\ub825\uc744 \ub2e4\uc591\ud55c \ucd5c\uc2e0 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ubaa9\uc801\uc774 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 Performance in Image Understanding Tasks"}, {"content": "| AGIEval |\n|---|---| \n|(Acc.)|", "caption": "Table 9: Results on general video VQA benchmarks. max: Maximum number of sampling frames. \u2217*\u2217: Officially reported results. \u2662\u2662\\diamondsuit\u2662: Retrieved results from official leaderboard or recent papers. Other unlabeled results are reproduced by ourselves. Note that we use the \"no subtitles\" evaluation setting in VideoMME.", "description": "\ud45c 9\ub294 \uc77c\ubc18\uc801\uc778 \ube44\ub514\uc624 VQA \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\ub294 \uc5ec\ub7ec \ubaa8\ub378(\ub3c5\uc810 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \uc634\ub2c8\ubaa8\ub2ec \ubaa8\ub378)\uc758 \ube44\ub514\uc624 \uc774\ud574 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c(MVBench, Egoschema, VideoMME, Perception Test)\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub294 \uc815\ud655\ub3c4(%)\ub85c \ud45c\uc2dc\ub418\uba70, 'max' \uc5f4\uc740 \ube44\ub514\uc624\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ub41c \ucd5c\ub300 \ud504\ub808\uc784 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  '\u2217\u2217\u2217' \ud45c\uc2dc\ub294 \uacf5\uc2dd\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uacb0\uacfc\uc774\uba70, '\u2662\u2662\ndiamonds\u2662'\ub294 \uacf5\uc2dd \ub9ac\ub354\ubcf4\ub4dc\ub098 \ucd5c\uadfc \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc628 \uacb0\uacfc\uc774\uace0, \ub098\uba38\uc9c0 \uacb0\uacfc\ub294 \ubcf8 \ub17c\ubb38 \uc800\uc790\ub4e4\uc774 \ub3d9\uc77c\ud55c \uc124\uc815\uc73c\ub85c \uc7ac\ud604\ud55c \uac83\uc785\ub2c8\ub2e4. VideoMME \ubca4\uce58\ub9c8\ud06c\uc758 \uacbd\uc6b0 '\uc790\ub9c9 \uc5c6\uc74c' \uc124\uc815\uc744 \uc0ac\uc6a9\ud588\uc74c\uc744 \uc720\uc758\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4.3 \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5 \uc131\ub2a5"}, {"content": "| C-Eval |\n|---|---| \n| (Acc.) |", "caption": "Table 10: Results on open-ended video VQA benchmarks. max: Maximum number of sampling frames. \u2217*\u2217: Officially reported results. Other unlabeled results are reproduced by ourselves.", "description": "\ud45c 10\uc740 \uac1c\ubc29\ud615 \ube44\ub514\uc624 VQA \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \"max\"\ub294 \uc0d8\ud50c\ub9c1 \ud504\ub808\uc784\uc758 \ucd5c\ub300 \uc218\ub97c \ub098\ud0c0\ub0b4\uace0, \u2217 \ud45c\uc2dc\ub294 \uacf5\uc2dd\uc801\uc73c\ub85c \ubcf4\uace0\ub41c \uacb0\uacfc\ub97c, \ub098\uba38\uc9c0\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc7ac\ud604\ud55c \uacb0\uacfc\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(\ub3c5\uc810 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378, \uc624\ud508\uc18c\uc2a4 \uc634\ub2c8\ubaa8\ub2ec \ubaa8\ub378)\uc758 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud55c \uc5ec\ub7ec \uac1c\ubc29\ud615 \ube44\ub514\uc624 \uc9c8\uc758\uc751\ub2f5 \ubca4\uce58\ub9c8\ud06c(ActivityNet-QA, MSVD-QA)\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc758 \uc815\ud655\ub3c4(Acc.)\uc640 \uc810\uc218(Score)\uac00 \ud504\ub808\uc784 \uc218\uc640 \ud568\uaed8 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378\uc758 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825, \ud2b9\ud788 \uac1c\ubc29\ud615 \uc9c8\ubb38\uc5d0 \ub300\ud55c \uc751\ub2f5 \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4.3 \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5 \uc131\ub2a5"}, {"content": "| GAOKAO |\n|---|---| \n| (Acc.) |", "caption": "Table 11: Results on audio understanding benchmarks. \u2207\u2207\\nabla\u2207: The modalities parameter is set to [\"text\", \"audio\"], evaluation based on the output text. \u2662\u2662\\diamondsuit\u2662: Supports only text-audio interleaved output. \u25a1\u25a1\\square\u25a1: Cascade output method, evaluation based on the output text.", "description": "\ud45c 11\uc740 \uc624\ub514\uc624 \uc774\ud574 \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \ucd9c\ub825 \ubc29\uc2dd(\ud14d\uc2a4\ud2b8 \uae30\ubc18, \ud14d\uc2a4\ud2b8-\uc624\ub514\uc624 \ubcd1\ub82c \ucd9c\ub825, \uce90\uc2a4\ucf00\uc774\ub4dc \ubc29\uc2dd)\uc5d0 \ub530\ub978 \uacb0\uacfc\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  \u2207\u2207\u2207\u2207\ub294 \ubaa8\ub378\uc758 \ubaa8\ub2ec\ub9ac\ud2f0 \ub9e4\uac1c\ubcc0\uc218\ub97c [\"text\", \"audio\"]\ub85c \uc124\uc815\ud558\uace0, \ucd9c\ub825 \ud14d\uc2a4\ud2b8\ub97c \uae30\ubc18\uc73c\ub85c \ud3c9\uac00\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. \u2662\u2662\u2662\u2662\ub294 \ud14d\uc2a4\ud2b8-\uc624\ub514\uc624 \ubcd1\ub82c \ucd9c\ub825\ub9cc \uc9c0\uc6d0\ud558\ub294 \uacbd\uc6b0\uc758 \uacb0\uacfc\uc774\uace0, \u25a1\u25a1\u25a1\u25a1\ub294 \uce90\uc2a4\ucf00\uc774\ub4dc \ubc29\uc2dd(\ud14d\uc2a4\ud2b8\uc640 \uc624\ub514\uc624\uac00 \ubc88\uac08\uc544 \uc0dd\uc131\ub418\ub294 \ubc29\uc2dd)\uc744 \uc0ac\uc6a9\ud558\uace0, \ub9c8\ucc2c\uac00\uc9c0\ub85c \ucd9c\ub825 \ud14d\uc2a4\ud2b8\ub97c \uae30\ubc18\uc73c\ub85c \ud3c9\uac00\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.  \uac01 \ubca4\uce58\ub9c8\ud06c(Reasoning QA, Llama Questions, Web Questions, TriviaQA, AlpacaEval)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4 \uc810\uc218\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 \uc624\ub514\uc624 \uc774\ud574 \uc791\uc5c5 \uc131\ub2a5"}, {"content": "| Model | MMBench-EN (Acc.) | MMBench-CN (Acc.) | SEED-IMG (Acc.) | MMMU (val) (Acc.) | HallusionBench (Acc.) |\n|---|---|---|---|---|---| \n| **Multi-choice & Yes-or-No Question** |  |  |  |  |  |\n| *Proprietary Models* |  |  |  |  |  |\n| GPT-4o | 83.4<sup>\u2662</sup> | 82.1<sup>\u2662</sup> | - | **69.1**<sup>\u2662</sup> | **55.0**<sup>\u2662</sup> |\n| GPT-4o-mini | 77.7 | 76.9 | 72.3 | 59.3 | 45.8 |\n| *Open-source Models (Vision-language)* |  |  |  |  |  |\n| Qwen2 VL (7B) | 81.7 | 81.9 | **76.5** | 52.7 | 50.6<sup>\u2217</sup> |\n| MiniCPM-Llama3-V 2.5 (8B) | 76.7 | 73.3 | 72.4 | 45.8<sup>\u2217</sup> | 42.5 |\n| *Open-source Models (Omni-modal)* |  |  |  |  |  |\n| VITA (8x7B) | 74.7 | 71.4 | 72.6 | 45.3 | 39.7<sup>\u2217</sup> |\n| VITA-1.5 (7B) | 80.8 | 80.2 | 74.2 | 50.8 | 44.8 |\n| Baichuan-Omni (7B) | 76.2 | 74.9 | 74.1 | 47.3 | 47.8 |\n| MiniCPM-o 2.6 (7B) | 83.6 | 81.8 | 75.4 | 51.1 | 50.1 |\n| **Baichuan-Omni-1.5 (7B)** | **85.6** | **83.6** | 75.7 | 53.9 | 49.7 |", "caption": "Table 12: Overall Omni-Undesratnding Results. All the results are reproduced by ourselves. GPT-4o-mini does not support audio input, we use its audio API and transcribe the audio and then input it.", "description": "\ud45c 12\ub294 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0(\uc774\ubbf8\uc9c0, \uc624\ub514\uc624, \ud14d\uc2a4\ud2b8)\ub97c \uacb0\ud569\ud55c \uc885\ud569\uc801\uc778 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. GPT-4o-mini\ub294 \uc624\ub514\uc624 \uc785\ub825\uc744 \uc9c0\uc6d0\ud558\uc9c0 \uc54a\uc73c\ubbc0\ub85c, \uc624\ub514\uc624 API\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc624\ub514\uc624\ub97c \ud14d\uc2a4\ud2b8\ub85c \ubcc0\ud658\ud55c \ud6c4 \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \uac01 \uc5f4\uc740 \uc774\ubbf8\uc9c0\uc640 \uc624\ub514\uc624 \ub610\ub294 \ud14d\uc2a4\ud2b8\uc758 \uc870\ud569\uc744 \uc774\uc6a9\ud55c \ubaa8\ub378 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uba70, \uc774\ubbf8\uc9c0\uc640 \uc624\ub514\uc624 \uc804\uc0ac\ub97c \ubaa8\ub450 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \uc815\ud655\ub3c4(Acc.)\ub85c \uce21\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0 \uc870\ud569\uc5d0 \ub300\ud55c \uac15\uac74\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc911\uc810\uc744 \ub450\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.4 \ub2e4\uc911 \ubaa8\ub2ec \uac10\ub3c5 \ubbf8\uc138 \uc870\uc815"}, {"content": "| MMBench-EN |\n|---|---| \n|(Acc.)|", "caption": "Table 13: Results on medical benchmarks. All the results are reproduced by ourselves.", "description": "\ud45c 13\uc740 \uc758\ub8cc \uad00\ub828 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Baichuan-Omni-1.5 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  GPT-4 mini, VITA-1.5, MiniCPM-o 2.6\uc640 \uac19\uc740 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec Baichuan-Omni-1.5 \uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  GMAI-MMB-VAL \uacfc OpenMM-Medical \ub450 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc758 \uacb0\uacfc\uac00 \uc815\ud655\ub3c4(Accuracy)\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ubaa8\ub4e0 \uacb0\uacfc\ub294 \ub17c\ubb38 \uc800\uc790\ub4e4\uc774 \uc9c1\uc811 \uc7ac\ud604\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4.6 \uc758\ub8cc \uad00\ub828 \uc791\uc5c5\uc5d0\uc11c\uc758 \uc131\ub2a5"}]