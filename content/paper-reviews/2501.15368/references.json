{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report on GPT-4, a leading proprietary multimodal large language model, and provides a benchmark for comparison with open-source models."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "publication_date": "2023-09-16", "reason": "This paper details Qwen, a significant open-source multimodal large language model that serves as a strong competitor and comparison point for the presented Baichuan-Omni-1.5 model."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "VITA-1.5: Towards GPT-4 level real-time vision and speech interaction", "publication_date": "2025-01-27", "reason": "As a leading omni-modal model, VITA-1.5 provides a key comparative point for evaluating the capabilities of Baichuan-Omni-1.5, particularly in terms of real-time interaction across multiple modalities."}, {"fullname_first_author": "Yuan Yao", "paper_title": "MiniCPM-V: A GPT-4V level MLLM on your phone", "publication_date": "2024-08-01", "reason": "MiniCPM-V serves as another significant open-source omni-modal model for comparison against Baichuan-Omni-1.5, especially regarding its performance across various benchmarks and capabilities."}, {"fullname_first_author": "Aiyuan Yang", "paper_title": "Baichuan 2: Open large-scale language models", "publication_date": "2023-09-10", "reason": "This paper introduces Baichuan-2, a foundational model that underpins the development of Baichuan-Omni-1.5, highlighting its importance in the overall architecture and capabilities."}]}