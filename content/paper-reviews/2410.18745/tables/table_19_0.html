<table id='6' style='font-size:16px'><tr><td>Model</td><td>Ltrain</td><td>HF PATH</td><td>Peak Failure Depth</td><td>Acc</td></tr><tr><td>GPT-4-128K</td><td></td><td>-</td><td>0-33.3%</td><td>100.0</td></tr><tr><td>Trained on open-source data</td><td></td><td></td><td></td><td></td></tr><tr><td>TinyLlama-1.3b-1T(ours)</td><td>2k</td><td></td><td>0-33.3%</td><td>56.6</td></tr><tr><td>TinyLlama-1.1b-1T</td><td>2k</td><td>TimyLicon/Tinyliama/LIB-interneciatex-4806-IT</td><td>0-33.3%</td><td>38.0</td></tr><tr><td>TinyLlama-1.1b-3T</td><td>2k</td><td>TheyJlamaYIng liam.I.IB-uternesdinep:14211421</td><td>0-33.3%</td><td>69.8</td></tr><tr><td>Pythia-1.4b</td><td>2k</td><td>EleutherAI/pythia-1.4b</td><td>0-33.3%</td><td>22.5</td></tr><tr><td>OpenLlama-3B</td><td>2k</td><td>openlm-research/open_llama_3b</td><td>0-33.3%</td><td>85.0</td></tr><tr><td>Llama2-7B</td><td>4k</td><td>meta-llama/Llama-2-7b</td><td>0-33.3%</td><td>98.0</td></tr><tr><td>Llama3-8B</td><td>8k</td><td>meta-llama/Llama-3-7b</td><td>0-33.3%</td><td>99.8</td></tr><tr><td>Together-base</td><td>32k</td><td>togethercomputer/Llama-2-7B-32K</td><td>0-33.3%</td><td>63.0</td></tr><tr><td>LWM-base</td><td>32k</td><td>LargeWorldModel/LWM-Text-32K</td><td>0-33.3%</td><td>31.8</td></tr><tr><td>Mistral-base</td><td>32k</td><td>alpindale/Mistral-7B-v0.2-hf</td><td>0-33.3%</td><td>52.8</td></tr><tr><td>Llama3.1-8B</td><td>128k</td><td>meta-Ilama/Meta-Llama-3.1-8B</td><td>0-33.3%</td><td>66.0</td></tr><tr><td>Yarn-base</td><td>128k</td><td>NousResearch/Yam-Llama-2-7b-128k</td><td>0-33.3%</td><td>32.4</td></tr><tr><td>Yi-6b-200k</td><td>200k</td><td>01-ai/Yi-6B-200K</td><td>0-33.3%</td><td>20.8</td></tr><tr><td>Gradient-Llama3-8B</td><td>262k</td><td>graiientaiLlama-3-70B-Instruct-Graien-256k</td><td>0-33.3%</td><td>46.0</td></tr></table>