<table id='0' style='font-size:14px'><tr><td>Dataset</td><td># Pairs</td><td>Avg. # Turns</td><td>Avg. # Tokens (Prompt)</td><td>Avg. # Tokens (Response)</td><td>Completion</td><td>Annotator</td></tr><tr><td>HelpSteer2</td><td>7,221</td><td>3.9</td><td>21.3</td><td>690.0</td><td>Human + 6 LLMsa</td><td>Human</td></tr><tr><td>OffsetBias</td><td>8,504</td><td>2</td><td>69.1</td><td>222.1</td><td>GPT-3.5 + GPT-4 + Claude 3 Opus</td><td>GPT-4</td></tr><tr><td>WildGuardMix</td><td>6,709</td><td>2</td><td>164.3</td><td>349.9</td><td>8 LLMsb</td><td>Human</td></tr><tr><td>Magpie Ultra</td><td>27,785</td><td>2</td><td>76.7</td><td>670.0</td><td>Llama 3.1 405B Instruct</td><td>ArmoRM</td></tr><tr><td>Magpie Pro (Llama 3)</td><td>2,030</td><td>2</td><td>34.2</td><td>621.5</td><td>Llama 3 70B Instruct</td><td>ArmoRM</td></tr><tr><td>Magpie Pro (Llama 3.1)</td><td>29,682</td><td>2</td><td>118.8</td><td>584.3</td><td>Llama 3.1 70B Instruct</td><td>ArmoRM</td></tr><tr><td>Magpie Air</td><td>42</td><td>2</td><td>66.6</td><td>240.0</td><td>Llama 3 8B Instruct</td><td>ArmoRM</td></tr><tr><td>Total</td><td>81,973</td><td>2.2</td><td>96.3</td><td>527.2</td><td>-</td><td>-</td></tr></table>