{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational diffusion model framework used as the basis for many video and motion generation methods discussed in the paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a crucial technique for aligning text and image information, which is a key component of the proposed Move-in-2D approach."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-04-01", "reason": "This paper introduces DINOv2, an important technique for encoding scene image information, which is central to the model's ability to condition generation on visual context."}, {"fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "publication_date": "2022-07-01", "reason": "This paper is highly relevant due to its focus on 3D human motion generation from text, a related task that shares many conceptual overlaps with the proposed work."}, {"fullname_first_author": "Guy Tevet", "paper_title": "Human motion diffusion model", "publication_date": "2023-05-01", "reason": "This paper introduces a diffusion model specifically for human motion generation, which is directly relevant to the proposed method and contributes to the state-of-the-art in this domain."}]}