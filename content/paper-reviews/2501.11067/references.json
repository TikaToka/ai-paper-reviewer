{"references": [{"fullname_first_author": "M. Abbasian", "paper_title": "Conversational health agents: A personalized LLM-powered agent framework", "publication_date": "2023", "reason": "This paper is highly relevant to the research presented in the paper, as it focuses on conversational AI agents, a key topic of the paper, and their application in healthcare, which is directly relevant to the paper\u2019s discussion of real-world applications for conversational AI agents."}, {"fullname_first_author": "L. Alberts", "paper_title": "Curate: Benchmarking personalized alignment of conversational AI assistants", "publication_date": "2025", "reason": "This paper is highly relevant as it introduces a benchmark for evaluating conversational AI agents, a key aspect of the paper\u2019s focus, specifically addressing the challenge of personalized alignment, a crucial component in real-world applications of conversational AI systems."}, {"fullname_first_author": "S. Arcadinho", "paper_title": "Automated test generation to evaluate tool-augmented LLMs as conversational AI agents", "publication_date": "2024", "reason": "This paper is highly relevant to the topic of evaluating conversational AI agents. It focuses on automated test generation, a key aspect of the work presented in this paper, thereby providing a methodological foundation for the development of the IntellAgent framework."}, {"fullname_first_author": "D. Castillo-Bolado", "paper_title": "Beyond prompts: Dynamic conversational benchmarking of large language models", "publication_date": "2024", "reason": "This paper is important to the work presented here because it addresses the limitations of traditional prompt-based evaluations of LLMs and suggests more dynamic methods for evaluating conversational AI agents, aligning with the goals of this paper."}, {"fullname_first_author": "H. Duan", "paper_title": "Botchat: Evaluating LLMs\u2019 capabilities of having multi-turn dialogues", "publication_date": "2023", "reason": "This paper is highly relevant as it tackles the evaluation of LLMs in multi-turn dialogues, which is directly pertinent to the paper\u2019s focus. This paper addresses the complexities of multi-turn interactions and offers insights into evaluating agents that handle multiple rounds of dialogue, aligning directly with the paper\u2019s goal."}]}