[{"figure_path": "https://arxiv.org/html/2501.02955/x1.png", "caption": "Figure 1: State-of-the-art video understanding models struggle with basic motion-level perception. Compared to existing benchmarks, our proposed MotionBench focuses on assessing the model\u2019s Motion level perception capability, which is critical in understanding videos with fast and instant interactions and motions.", "description": "\uadf8\ub9bc 1\uc740 \ucd5c\ucca8\ub2e8 \ube44\ub514\uc624 \uc774\ud574 \ubaa8\ub378\ub4e4\uc774 \uae30\ubcf8\uc801\uc778 \ub3d9\uc791 \uc218\uc900\uc758 \uc778\uc2dd\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\uace0 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 \ubca4\uce58\ub9c8\ud06c\uc640 \ube44\uad50\ud558\uc5ec \uc81c\uc548\ub41c MotionBench\ub294 \ube60\ub974\uace0 \uc989\uac01\uc801\uc778 \uc0c1\ud638 \uc791\uc6a9\uacfc \ub3d9\uc791\uc774 \ud3ec\ud568\ub41c \ube44\ub514\uc624\ub97c \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \ubaa8\ub378\uc758 \ub3d9\uc791 \uc218\uc900 \uc778\uc2dd \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4.  MotionBench\ub294 \ub2e4\uc591\ud55c \ub3d9\uc791 \uad00\ub828 \uc9c8\ubb38 \uc720\ud615\uc744 \ud1b5\ud574 \ubaa8\ub378\uc758 \ubbf8\uc138\ud55c \ub3d9\uc791 \uc218\uc900 \uc778\uc2dd\uc744 \ud3c9\uac00\ud558\uace0, \ub2e4\uc591\ud55c \ucd9c\ucc98\uc5d0\uc11c \uc218\uc9d1\ub41c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\uc81c \uc138\uc0c1\uc758 \ube44\ub514\uc624 \ucf58\ud150\uce20\ub97c \ud3ed\ub113\uac8c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.02955/x2.png", "caption": "Figure 2: \nWe propose MotionBench, a collection of manually curated multi-choice queries with video clips featuring dynamic changes from various scenes such as daily life and medical instructions. We devise six primary tasks to evaluate the capability of motion-level perception. Unlike previous story-level and event-level benchmarks, MotionBench is characterized by a significantly higher annotation density, allowing for the assessment of fine-grained motions.", "description": "\uadf8\ub9bc 2\ub294 MotionBench\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MotionBench\ub294 \uc77c\uc0c1 \uc0dd\ud65c \ubc0f \uc758\ub8cc \uc9c0\uce68\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc7a5\uba74\uc5d0\uc11c \ub3d9\uc801 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ube44\ub514\uc624 \ud074\ub9bd\uacfc \uc218\ub3d9\uc73c\ub85c \ud050\ub808\uc774\uc158\ub41c \ub2e4\uc911 \uc120\ud0dd \uc9c8\ubb38\ub4e4\uc758 \ubaa8\uc74c\uc785\ub2c8\ub2e4. \uc774 \ubca4\uce58\ub9c8\ud06c\ub294 6\uac00\uc9c0 \uc8fc\uc694 \uc791\uc5c5\uc744 \ud1b5\ud574 \ub3d9\uc791 \uc218\uc900 \uc778\uc2dd \uae30\ub2a5\uc744 \ud3c9\uac00\ud558\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\uc804\uc758 \uc2a4\ud1a0\ub9ac \uc218\uc900 \ubc0f \uc774\ubca4\ud2b8 \uc218\uc900 \ubca4\uce58\ub9c8\ud06c\uc640 \ub2ec\ub9ac MotionBench\ub294 \uc0c1\ub2f9\ud788 \ub192\uc740 \uc8fc\uc11d \ubc00\ub3c4\ub97c \ud2b9\uc9d5\uc73c\ub85c \ud558\uba70, \uc138\ubd84\ud654\ub41c \ub3d9\uc791\uc758 \ud3c9\uac00\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x3.png", "caption": "(a) Option distribution", "description": "\uadf8\ub9bc 3(a)\ub294 MotionBench \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c 8052\uac1c\uc758 \uc9c8\ubb38\ub4e4\uc5d0 \ub300\ud55c \ubcf4\uae30(\uc635\uc158)\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc9c8\ubb38\uc740 \ub124 \uac00\uc9c0 \ubcf4\uae30\ub97c \uac00\uc9c0\uace0 \uc788\uc73c\uba70, \uc774 \uadf8\ub9bc\uc740 \uac01 \ubcf4\uae30\uac00 \uc120\ud0dd\ub41c \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc989, \uac01 \ubcf4\uae30\uac00 \uc9c8\ubb38\uc5d0 \ub300\ud574 \uc5bc\ub9c8\ub098 \uc790\uc8fc \uc120\ud0dd\ub418\uc5c8\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \ub9c9\ub300 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. \uc774\ub294 MotionBench \ub370\uc774\ud130\uc14b\uc758 \uade0\ud615\uacfc \ub2e4\uc591\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x4.png", "caption": "(b) Video duration", "description": "\uadf8\ub9bc 3(b)\ub294 MotionBench \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \ube44\ub514\uc624\uc758 \uc9c0\uc18d \uc2dc\uac04 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ube44\ub514\uc624 \uae38\uc774(\ucd08)\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \ud574\ub2f9 \uae38\uc774\ub97c \uac00\uc9c4 \ube44\ub514\uc624\uc758 \uac1c\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc744 \ud1b5\ud574 MotionBench \ub370\uc774\ud130\uc14b\uc758 \ube44\ub514\uc624 \uae38\uc774 \ubd84\ud3ec\ub97c \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \ube44\ub514\uc624\ub294 \uc9e7\uc740 \uae38\uc774(10\ucd08 \ubbf8\ub9cc)\ub97c \uac00\uc9c0\uace0 \uc788\uc73c\uba70, \uae34 \ube44\ub514\uc624\ub294 \uc0c1\ub300\uc801\uc73c\ub85c \uc801\uc740 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x5.png", "caption": "(c) Annotation length", "description": "\uadf8\ub9bc 3(c)\ub294 MotionBench \ub370\uc774\ud130\uc14b\uc5d0 \uc788\ub294 \uac01 \uc9c8\ubb38\uc5d0 \ub300\ud55c \uc5b4\ub178\ud14c\uc774\uc158(\uc8fc\uc11d)\uc758 \uae38\uc774 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac00\ub85c\ucd95\uc740 \uc5b4\ub178\ud14c\uc774\uc158 \uae38\uc774(\ub2e8\uc5b4 \uc218)\uc774\uace0, \uc138\ub85c\ucd95\uc740 \ud574\ub2f9 \uae38\uc774\ub97c \uac00\uc9c4 \uc5b4\ub178\ud14c\uc774\uc158\uc758 \uac1c\uc218\uc785\ub2c8\ub2e4. \uc774 \ubd84\ud3ec\ub97c \ud1b5\ud574 MotionBench \ub370\uc774\ud130\uc14b\uc758 \uc5b4\ub178\ud14c\uc774\uc158 \uae38\uc774\uac00 \uc5b4\ub5bb\uac8c \ubd84\ud3ec\ub418\uc5b4 \uc788\ub294\uc9c0, \uadf8\ub9ac\uace0 \ub300\ubd80\ubd84\uc758 \uc5b4\ub178\ud14c\uc774\uc158\uc774 \uc5b4\ub290 \uc815\ub3c4\uc758 \uae38\uc774\ub97c \uac00\uc9c0\ub294\uc9c0\ub97c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ud3c9\uade0\uc801\uc778 \uc5b4\ub178\ud14c\uc774\uc158 \uae38\uc774\uc640 \ud45c\uc900\ud3b8\ucc28\ub97c \ud1b5\ud574 \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \ub354 \uc798 \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x6.png", "caption": "(d) QA per video", "description": "\uadf8\ub9bc (d)\ub294 MotionBench \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ube44\ub514\uc624\ub2f9 \uc9c8\ubb38-\uc751\ub2f5 \uc30d(QA)\uc758 \uac1c\uc218 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ube44\ub514\uc624\ub2f9 QA \uc30d\uc758 \uac1c\uc218\uc774\uace0, y\ucd95\uc740 \ud574\ub2f9 \uac1c\uc218\ub97c \uac00\uc9c0\ub294 \ube44\ub514\uc624\uc758 \uac1c\uc218\uc785\ub2c8\ub2e4. \uc774\ub294 MotionBench \ub370\uc774\ud130\uc14b \ub0b4\uc5d0\uc11c \ube44\ub514\uc624\uc758 \uae38\uc774 \ub610\ub294 \ubcf5\uc7a1\ub3c4\uc5d0 \ub530\ub77c \uc9c8\ubb38\uc758 \uac1c\uc218\uac00 \uc5b4\ub5bb\uac8c \ub2ec\ub77c\uc9c0\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \uc790\ub8cc\uc785\ub2c8\ub2e4.  QA \uc30d\uc758 \uac1c\uc218 \ubd84\ud3ec\ub97c \ud1b5\ud574 MotionBench \ub370\uc774\ud130\uc14b\uc758 \ub2e4\uc591\uc131\uacfc \uade0\ud615\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/extracted/6113584/figs/video_dynamic_annotation_ver2.jpg", "caption": "Figure 3: Basic statistics of MotionBench.", "description": "\uadf8\ub9bc 3\uc740 MotionBench \ub370\uc774\ud130\uc14b\uc758 \uae30\ubcf8 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc9c8\ubb38\uc758 \uc635\uc158 \ubd84\ud3ec\ub97c, (b)\ub294 \ube44\ub514\uc624 \uc9c0\uc18d \uc2dc\uac04 \ubd84\ud3ec\ub97c, (c)\ub294 \uc8fc\uc11d \uae38\uc774 \ubd84\ud3ec\ub97c, (d)\ub294 \ube44\ub514\uc624\ub2f9 \uc9c8\ubb38 \uac1c\uc218 \ubd84\ud3ec\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \uadf8\ub798\ud504\ub294 MotionBench \ub370\uc774\ud130\uc14b\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud1b5\uacc4\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud45c\ud604\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ube44\ub514\uc624 \uc9c0\uc18d \uc2dc\uac04 \ubd84\ud3ec\ub294 \ub370\uc774\ud130\uc14b \ub0b4 \ube44\ub514\uc624\uc758 \uae38\uc774\uac00 \ub2e4\uc591\ud558\uac8c \ubd84\ud3ec\ub418\uc5b4 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ub3d9\uc791 \ubc0f \ub3d9\uc791 \uc9c0\uc18d \uc2dc\uac04\uc744 \ud3ec\ucc29\ud558\uc5ec MotionBench\uc758 \ud3ec\uad04\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x7.png", "caption": "Figure 4: Example of dynamic information annotation", "description": "\uadf8\ub9bc 4\ub294 MotionBench \ub370\uc774\ud130\uc14b \uad6c\ucd95 \uacfc\uc815\uc5d0\uc11c \ub3d9\uc801 \uc815\ubcf4\ub97c \uc5b4\ub5bb\uac8c \uc8fc\uc11d \ucc98\ub9ac\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.  \uc790\ub3d9 QA \uc0dd\uc131 \ub2e8\uacc4 \uc774\uc804\uc5d0, \ube44\ub514\uc624\uc5d0 \ub300\ud55c \ub3d9\uc801\uc778 \ubcc0\ud654\ub97c \ubb18\uc0ac\ud558\ub294 \uc790\uc138\ud55c \ucea1\uc158\uc744 \uc218\ub3d9\uc73c\ub85c \uc791\uc131\ud569\ub2c8\ub2e4.  \ucea1\uc158\uc5d0\ub294 \ube44\ub514\uc624 \uc7a5\uba74\uc5d0\uc11c \uc77c\uc5b4\ub098\ub294 \ub3d9\uc791\ub4e4\uc758 \uc21c\uc11c\uc640 \uc138\ubd80 \uc0ac\ud56d\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4.  \uc774\ub807\uac8c \uc0dd\uc131\ub41c \ucea1\uc158\uc740 GPT-4\ub97c \ud65c\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\uacfc \ub2f5\ubcc0 \uc138\ud2b8(QA \uc30d)\ub97c \uc790\ub3d9\uc73c\ub85c \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \uadf8\ub9bc\uc740 \uc790\ub3d9 \uc8fc\uc11d \uc0dd\uc131 \uacfc\uc815\uc5d0 \ub300\ud55c \ub2e8\uacc4\ubcc4 \uc124\uba85\uacfc \ud568\uaed8, \uc218\ub3d9\uc73c\ub85c \uc8fc\uc11d \ucc98\ub9ac\ub41c \ub3d9\uc801 \ubcc0\ud654\uc640 GPT-4\ub97c \ud1b5\ud574 \uc0dd\uc131\ub41c QA \uc9c8\ubb38\uacfc \uc635\uc158\uc758 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub3d9\uc801 \uc815\ubcf4\uc758 \uc815\ud655\ud558\uace0 \uc0c1\uc138\ud55c \uc8fc\uc11d \ucc98\ub9ac \ubc29\uc2dd\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3. MotionBench: Motion-Level Benchmarking"}, {"figure_path": "https://arxiv.org/html/2501.02955/x8.png", "caption": "Figure 5: Summarization of prevalent paradigms for video compression and our proposed Through-Encoder Fusion (TE Fusion). Here we only illustrate the part before the VLM decoder where temporal compression performs.", "description": "\uadf8\ub9bc 5\ub294 \ube44\ub514\uc624 \uc555\ucd95\uc744 \uc704\ud55c \uae30\uc874 \ud328\ub7ec\ub2e4\uc784\ub4e4\uacfc \uc81c\uc548\ub41c Through-Encoder Fusion (TE Fusion) \ubc29\ubc95\uc744 \uc694\uc57d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \uc2dc\uac04\uc801 \uc555\ucd95\uc774 \uc218\ud589\ub418\ub294 VLM \ub514\ucf54\ub354 \uc774\uc804 \ubd80\ubd84\ub9cc \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874 \ubc29\ubc95\uc73c\ub85c\ub294 Temporal Fusion\uc774 \uc5c6\ub294 \ubc29\ubc95, Pre-Encoder Fusion, Post-Encoder Fusion\uc774 \uc788\uc73c\uba70, \uac01 \ubc29\ubc95\uc740 \ube44\ub514\uc624 \ud504\ub808\uc784\uc744 \ucc98\ub9ac\ud558\uace0 VLM \ub514\ucf54\ub354\uc5d0 \uc785\ub825\uc73c\ub85c \uc81c\uacf5\ud558\ub294 \ubc29\uc2dd\uc5d0 \ucc28\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4.  TE Fusion\uc740 \uc774\uc804 \ubc29\ubc95\ub4e4\uc758 \ud55c\uacc4\ub97c \uadf9\ubcf5\ud558\uae30 \uc704\ud574 Visual Encoder \ub2e8\uacc4\uc5d0\uc11c \uc778\uc811 \ud504\ub808\uc784\ub4e4\uc744 \uadf8\ub8f9\ud654\ud558\uc5ec \uc2ec\uce35\uc801\uc778 \uc735\ud569\uc744 \uc218\ud589\ud558\uace0, \uadf8\ub8f9 \ub2e8\uc704\ub85c \uacf5\uac04-\uc2dc\uac04\uc801 \uc555\ucd95\uc744 \uc218\ud589\ud558\ub294 \uc0c8\ub85c\uc6b4 \ubc29\ubc95\uc785\ub2c8\ub2e4.", "section": "4. Model Design: Motion-Level Perception"}, {"figure_path": "https://arxiv.org/html/2501.02955/x9.png", "caption": "Figure 6: Model performance variation with respect to different compression ratios k=2,4,8,16\ud835\udc5824816k=2,4,8,16italic_k = 2 , 4 , 8 , 16, given a fixed VLM input frame count of Ninput=16subscript\ud835\udc41input16N_{\\text{input}}=16italic_N start_POSTSUBSCRIPT input end_POSTSUBSCRIPT = 16. The pink dotted line represents the performance of the baseline model, which processes 16 frames without temporal compression. Note that each compression method is re-implemented on the GLM-4V-9B backbone to ensure a fair comparison.", "description": "\uadf8\ub9bc 6\uc740 \uace0\uc815\ub41c VLM \uc785\ub825 \ud504\ub808\uc784 \uc218(Ninput=16)\uc5d0\uc11c \ub2e4\uc591\ud55c \uc555\ucd95 \ube44\uc728(k=2, 4, 8, 16)\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubd84\ud64d\uc0c9 \uc810\uc120\uc740 \uc2dc\uac04\uc801 \uc555\ucd95 \uc5c6\uc774 16\ud504\ub808\uc784\uc744 \ucc98\ub9ac\ud558\ub294 \uae30\uc900 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \uc555\ucd95 \ubc29\ubc95\uc740 GLM-4V-9B \ubc31\ubcf8\uc5d0 \uc7ac\uad6c\ud604\ub418\uc5b4 \uacf5\uc815\ud55c \ube44\uad50\ub97c \ubcf4\uc7a5\ud569\ub2c8\ub2e4.  \uc989,  \ub3d9\uc77c\ud55c \uae38\uc774\uc758 VLM \ub514\ucf54\ub354 \uc2dc\ud000\uc2a4\ub97c \uc720\uc9c0\ud558\uba74\uc11c, \uc785\ub825 \ud504\ub808\uc784 \uc218\ub97c \uc904\uc774\uae30 \uc704\ud574 \ub2e4\uc591\ud55c \uc2dc\uac04\uc801 \uc555\ucd95 \uae30\ubc95\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uac01 \uadf8\ub798\ud504\ub294 \ub2e4\ub978 \ub370\uc774\ud130\uc14b(MotionBench, MVBench, LVBench, VideoMME)\uc5d0\uc11c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. Experiments"}]