{"references": [{"fullname_first_author": "Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2023-01-01", "reason": "This paper introduces the Chain-of-Thought prompting method, a foundational approach for LLM reasoning that is central to the current research on step-wise reasoning and is extensively referenced in the target paper."}, {"fullname_first_author": "Lightman", "paper_title": "Let's verify step by step", "publication_date": "2023-01-01", "reason": "This paper introduces the concept of Process Reward Models (PRMs), which are the focus of the target paper's investigation and are directly compared against in experiments."}, {"fullname_first_author": "Wang", "paper_title": "Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations", "publication_date": "2024-01-01", "reason": "This paper proposes a heuristic annotation method for PRMs, addressing the high cost of annotation, a key challenge addressed by the target paper's AdaptiveStep method."}, {"fullname_first_author": "Zhang", "paper_title": "Planning-Guided Transformer Decoding", "publication_date": "2023-01-01", "reason": "This paper addresses challenges in code generation using LLMs, a task also addressed by the target paper's AdaptiveStep method, and explores a related method for improving LLM reasoning."}, {"fullname_first_author": "Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-01-01", "reason": "This paper introduces the GSM8k dataset, a benchmark dataset for mathematical reasoning used in the target paper's experiments, demonstrating the importance of this dataset in the field."}]}