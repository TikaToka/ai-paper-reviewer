[{"figure_path": "https://arxiv.org/html/2501.00712/x1.png", "caption": "Figure 1: Overview of our proposed TAPE in standard decoder-only Transformer architecture.", "description": "\uadf8\ub9bc 1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 TAPE(conTextualized equivariAnt Position Embedding)\uac00 \ud45c\uc900 \ub514\ucf54\ub354 \uc804\uc6a9 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uc544\ud0a4\ud14d\ucc98\uc5d0 \uc5b4\ub5bb\uac8c \ud1b5\ud569\ub418\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 \uc704\uce58 \uc784\ubca0\ub529 \ubc29\uc2dd(a)\uacfc TAPE\ub97c \uc0ac\uc6a9\ud55c \ud5a5\uc0c1\ub41c \uc778\uacfc\uc801 \uc5b4\ud150\uc158 \ubc0f \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub808\uc774\uc5b4\uac00 \uc788\ub294 TAPE(b)\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. TAPE\ub294 \ub808\uc774\uc5b4 \uac04\uc5d0 \uc2dc\ud000\uc2a4 \ucf58\ud150\uce20\ub97c \ud1b5\ud569\ud558\uc5ec \uc704\uce58 \uc784\ubca0\ub529\uc744 \uc0c1\ud669\uc5d0 \ub9de\uac8c \uc870\uc815\ud568\uc73c\ub85c\uc368 \uc704\uce58 \uae30\ubc18 \uc8fc\uc18c \uc9c0\uc815 \uae30\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \uc21c\ubc29\ud5a5 \ubc0f \uc5ed\ubc29\ud5a5 \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub808\uc774\uc5b4\uc5d0 \uc758\ud574 \uc704\uce58 \uc815\ubcf4\uac00 \uc9c0\uc18d\uc801\uc73c\ub85c \uc5c5\ub370\uc774\ud2b8\ub428\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ub610\ud55c,  TAPE\ub294 \uc21c\uc5f4 \ubc0f \uc9c1\uad50 \ub4f1\ubcc0\uc131\uc744 \uac15\ud654\ud558\uc5ec \uc5c5\ub370\uc774\ud2b8 \uc911 \uc704\uce58 \uc784\ubca0\ub529\uc758 \uc548\uc815\uc131\uc744 \ubcf4\uc7a5\ud558\uace0 \uacac\uace0\uc131\uacfc \uc801\uc751\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3 OUR APPROACH"}, {"figure_path": "https://arxiv.org/html/2501.00712/x2.png", "caption": "Figure 2: Accuracy on addition task between different methods on 2\u00d7\\times\u00d7 context length. Models are trained on sequence with length up to 40 while test on sequence with length up to 80. The average accuracy across the heatmap is 26.32%, 26.56%, 22.45%, 26.98% and 32.82% respectively for RoPE, RandPE, NoPE, FIRE and TAPE.", "description": "\uadf8\ub9bc 2\ub294 \uc11c\ub85c \ub2e4\ub978 \uc704\uce58 \uc778\ucf54\ub529 \ubc29\ubc95(RoPE, RandPE, NoPE, FIRE, TAPE)\uc744 \uc0ac\uc6a9\ud558\uc5ec 2\ubc30 \uae38\uc774\uc758 \ubb38\ub9e5 \uae38\uc774\uc5d0\uc11c \ub367\uc148 \ubb38\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud55c \uc5f4 \uc9c0\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub378\uc740 \ucd5c\ub300 \uae38\uc774 40\uc758 \uc2dc\ud000\uc2a4\ub85c \ud559\uc2b5\ub418\uc5c8\uace0, \ucd5c\ub300 \uae38\uc774 80\uc758 \uc2dc\ud000\uc2a4\ub85c \ud14c\uc2a4\ud2b8\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc5f4 \uc9c0\ub3c4\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub294 RoPE, RandPE, NoPE, FIRE, TAPE\uc5d0 \ub300\ud574 \uac01\uac01 26.32%, 26.56%, 22.45%, 26.98%, 32.82%\uc785\ub2c8\ub2e4. \uc774\ub294 TAPE\uac00 \ub354 \uae34 \uc2dc\ud000\uc2a4\uc5d0 \ub300\ud574\uc11c\ub3c4 \uc6b0\uc218\ud55c \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.1 ARITHMETIC LEARNING"}, {"figure_path": "https://arxiv.org/html/2501.00712/x3.png", "caption": "Figure 3: Accuracy on passkey retrieval from 1k to 8k context length between Llama2 7B with different fine-tuning methods.", "description": "\uadf8\ub9bc 3\uc740 Llama2 7B \ubaa8\ub378\uc5d0 \ub2e4\uc591\ud55c \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc744 \uc801\uc6a9\ud588\uc744 \ub54c, \ubb38\ub9e5 \uae38\uc774\uac00 1k\uc5d0\uc11c 8k\ub85c \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ud328\uc2a4\ud0a4 \uac80\uc0c9 \uc815\ud655\ub3c4\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubbf8\uc138 \uc870\uc815 \uae30\ubc95(LoRA, LongLoRA, Theta Scaling, TAPE)\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec, \uac01 \uae30\ubc95\uc774 \ubb38\ub9e5 \uae38\uc774 \ubcc0\ud654\uc5d0 \ub530\ub978 \uac80\uc0c9 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uc5b4\ub5a4 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc774 \uae34 \ubb38\ub9e5\uc5d0\uc11c\uc758 \ud328\uc2a4\ud0a4 \uac80\uc0c9\uc5d0 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 Context Window Extension by Parameter-Efficient Tuning"}, {"figure_path": "https://arxiv.org/html/2501.00712/x4.png", "caption": "Figure 4: Visualization of TAPE\u2019s operations. The channel dimension is omitted for simplicity as all operations can be channel-wise. In the attention layer, the input token embeddings have a shape of N\u00d7B\ud835\udc41\ud835\udc35N\\times Bitalic_N \u00d7 italic_B, and the position embeddings have a shape of N\u00d7L\u00d7R\ud835\udc41\ud835\udc3f\ud835\udc45N\\times L\\times Ritalic_N \u00d7 italic_L \u00d7 italic_R. For the feed-forward layer, the N\ud835\udc41Nitalic_N dimension is omitted as its operations are position-wise. The input token embeddings then have a shape of B\ud835\udc35Bitalic_B (or B\u00d71\ud835\udc351B\\times 1italic_B \u00d7 1), and the position embeddings have a shape of L\u00d7R\ud835\udc3f\ud835\udc45L\\times Ritalic_L \u00d7 italic_R.", "description": "\uadf8\ub9bc 4\ub294 TAPE\uc758 \ub3d9\uc791\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucc44\ub110 \ucc28\uc6d0\uc740 \ub2e8\uc21c\ud654\ub97c \uc704\ud574 \uc0dd\ub7b5\ub418\uc5c8\uc73c\uba70, \ubaa8\ub4e0 \uc5f0\uc0b0\uc740 \ucc44\ub110\ubcc4\ub85c \uc218\ud589\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0\uc11c \uc785\ub825 \ud1a0\ud070 \uc784\ubca0\ub529\uc740 N\u00d7B\uc758 \ud615\ud0dc\ub97c \uac00\uc9c0\uba70, \uc704\uce58 \uc784\ubca0\ub529\uc740 N\u00d7L\u00d7R\uc758 \ud615\ud0dc\ub97c \uac00\uc9d1\ub2c8\ub2e4. \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub808\uc774\uc5b4\uc758 \uacbd\uc6b0, \uc5f0\uc0b0\uc774 \uc704\uce58\ubcc4\ub85c \uc218\ud589\ub418\ubbc0\ub85c N \ucc28\uc6d0\uc740 \uc0dd\ub7b5\ub429\ub2c8\ub2e4. \uadf8 \uacb0\uacfc, \uc785\ub825 \ud1a0\ud070 \uc784\ubca0\ub529\uc740 B(\ub610\ub294 B\u00d71)\uc758 \ud615\ud0dc\ub97c \uac00\uc9c0\uba70, \uc704\uce58 \uc784\ubca0\ub529\uc740 L\u00d7R\uc758 \ud615\ud0dc\ub97c \uac00\uc9d1\ub2c8\ub2e4.", "section": "3 OUR APPROACH"}, {"figure_path": "https://arxiv.org/html/2501.00712/x5.png", "caption": "Figure 5: Accuracy on addition task\ntrained with length 20 test on 2\u00d7\\times\u00d7 context length. The average accuracy across the heatmap is 26.12%, 26.12%, 39.44% and 41.42% respectively for RoPE, RandPE, FIRE and TAPE.", "description": "\uadf8\ub9bc 5\ub294 \uae38\uc774 20\uc73c\ub85c \ud559\uc2b5\ub41c \ub367\uc148 \ubb38\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud14c\uc2a4\ud2b8\ub294 \ubb38\ub9e5 \uae38\uc774\uac00 2\ubc30\uc778 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc9c4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud788\ud2b8\ub9f5\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub294 RoPE, RandPE, FIRE \ubc0f TAPE\uc5d0 \ub300\ud574 \uac01\uac01 26.12%, 26.12%, 39.44%, 41.42%\uc785\ub2c8\ub2e4.  \uc989, TAPE \ubaa8\ub378\uc774 \ub2e4\ub978 \uc138 \uac00\uc9c0 \ubc29\ubc95\ubcf4\ub2e4 \ub367\uc148 \ubb38\uc81c \ud480\uc774 \uc815\ud655\ub3c4\uac00 \ub354 \ub192\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, FIRE \ubc0f TAPE\ub294 \uae34 \ubb38\ub9e5\uc744 \ub2e4\ub8e8\ub294 \ub370 \uc0c1\ub2f9\ud788 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.1 ARITHMETIC LEARNING"}, {"figure_path": "https://arxiv.org/html/2501.00712/x6.png", "caption": "Figure 6: Accuracy on addition task on 2\u00d7\\times\u00d7 context length. The average accuracy is 26.98%, 32.82% and 33.92% respectively for FIRE, TAPE and TAPE + YaRN.", "description": "\uadf8\ub9bc 6\uc740 \ub9e5\ub77d \uae38\uc774\uac00 \ub450 \ubc30\uc778 \ub367\uc148 \ubb38\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub294 FIRE\uc758 \uacbd\uc6b0 26.98%, TAPE\uc758 \uacbd\uc6b0 32.82%, TAPE + YaRN\uc758 \uacbd\uc6b0 33.92% \uc785\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc774 \ub2e4\uc591\ud55c \uae38\uc774\uc758 \ub367\uc148 \ubb38\uc81c\uc5d0 \ub300\ud574 \uc5b4\ub5bb\uac8c \ub2e4\ub978 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, TAPE\uc640 TAPE + YaRN\uc758 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "4.1 \uc0b0\uc220 \ud559\uc2b5"}, {"figure_path": "https://arxiv.org/html/2501.00712/extracted/6105208/fig/vis_dp.png", "caption": "(a)  Dot-product patterns of positional embeddings of TAPE and RoPE.", "description": "\uadf8\ub9bc\uc740 TAPE\uc640 RoPE\uc758 \uc704\uce58 \uc784\ubca0\ub529\uc758 \uc810\uacf1 \ud328\ud134\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  TAPE\ub294 \uae34 \ubc94\uc704\uc758 \ud1a0\ud070 \uac04 \uad00\uacc4\uc5d0 \ub354 \uace0\ub974\uac8c \uc8fc\uc758\ub97c \uae30\uc6b8\uc774\ub294 \ubc18\uba74, RoPE\ub294 \ud1a0\ud070\uc758 \uad6d\uc9c0\uc801\uc778 \uad00\uacc4\uc5d0 \ub354 \uc9d1\uc911\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. TAPE\uc758 \uc810\uacf1 \ud328\ud134\uc740 \uae4a\uc774\uac00 \uae4a\uc5b4\uc9d0\uc5d0 \ub530\ub77c \ub300\uac01\uc120 \ud328\ud134\uc774 \uac10\uc18c\ud558\uace0, \uaca9\uc790\uc640 \uac19\uc740 \ud328\ud134\uc774 \ud615\uc131\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uba3c \ud1a0\ud070\uc5d0 \uad6c\uc870\uc801\uc774\uace0 \uc8fc\uae30\uc801\uc778 \ubc29\uc2dd\uc73c\ub85c \ub354 \uc9d1\uc911\ud558\uae30 \uc2dc\uc791\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "D. \ucd94\uac00 \uc124\uba85"}, {"figure_path": "https://arxiv.org/html/2501.00712/extracted/6105208/fig/vis_attn_diff.png", "caption": "(b)  Difference between TAPE and RoPE", "description": "\uadf8\ub9bc\uc740 TAPE\uc640 RoPE\uc758 \uc5b4\ud150\uc158 \ud328\ud134 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. TAPE\ub294 \uae34 \ubc94\uc704\uc758 \ud1a0\ud070\uc5d0\ub3c4 \uace0\ub974\uac8c \uc8fc\uc758\ub97c \uae30\uc6b8\uc774\ub294 \ubc18\uba74, RoPE\ub294 \ub300\uac01\uc120 \ud328\ud134\uc5d0 \uc9d1\uc911\ud558\uc5ec \uc9c0\uc5ed\uc801\uc778 \uc5b4\ud150\uc158\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. TAPE\uc758 \uacbd\uc6b0, \uae4a\uc774\uac00 \uae4a\uc5b4\uc9d0\uc5d0 \ub530\ub77c \ub300\uac01\uc120 \ud328\ud134\uc774 \uc904\uc5b4\ub4e4\uace0, \uba40\ub9ac \ub5a8\uc5b4\uc9c4 \ud1a0\ud070\uc5d0 \ub300\ud55c \uc8fc\uc758\uac00 \uccb4\uacc4\uc801\uc73c\ub85c \uc99d\uac00\ud569\ub2c8\ub2e4.", "section": "3.4 \ud6a8\uc728\uc131 \ubd84\uc11d"}, {"figure_path": "https://arxiv.org/html/2501.00712/x7.png", "caption": "Figure 7: Comparison of TAPE and RoPE methods in terms of positional embedding dot-product patterns and their resulting attention differences. (a) TAPE demonstrates a systematic attention to surrounding tokens with relatively small dynamic ranges, whereas RoPE exhibits a highly significant diagonal pattern with distinctively black regions. (b) TAPE effectively attends to longer-range tokens, avoiding excessive attention to the self-token, in contrast to RoPE.", "description": "\uadf8\ub9bc 7\uc740 \uc704\uce58 \uc815\ubcf4 \uc784\ubca0\ub529\uc758 \ub0b4\uc801 \ud328\ud134\uacfc \uadf8\uc5d0 \ub530\ub978 \uc5b4\ud150\uc158 \ucc28\uc774\ub97c TAPE\uc640 RoPE \ubc29\ubc95\ub860 \uce21\uba74\uc5d0\uc11c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. (a)\ub294 TAPE\uac00 \uc0c1\ub300\uc801\uc73c\ub85c \uc791\uc740 \ub3d9\uc801 \ubc94\uc704\ub97c \uac00\uc9c4 \uc8fc\ubcc0 \ud1a0\ud070\uc5d0 \ub300\ud55c \uccb4\uacc4\uc801\uc778 \uc5b4\ud150\uc158\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ubc18\uba74, RoPE\ub294 \ub69c\ub837\ud55c \uac80\uc740\uc0c9 \uc601\uc5ed\uc744 \uac00\uc9c4 \ub300\uac01\uc120 \ud328\ud134\uc774 \ub9e4\uc6b0 \ub450\ub4dc\ub7ec\uc9c0\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 TAPE\uac00 \uc790\uae30 \ud1a0\ud070\uc5d0 \ub300\ud55c \uacfc\ub3c4\ud55c \uc5b4\ud150\uc158\uc744 \ud53c\ud558\uba74\uc11c \uc7a5\uac70\ub9ac \ud1a0\ud070\uc5d0 \ud6a8\uacfc\uc801\uc73c\ub85c \uc5b4\ud150\uc158\uc744 \uc9d1\uc911\uc2dc\ud0a4\ub294 \ubc18\uba74 RoPE\ub294 \uadf8\ub807\uc9c0 \uc54a\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. OUR APPROACH"}]