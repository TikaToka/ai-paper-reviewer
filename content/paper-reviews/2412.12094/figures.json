[{"figure_path": "https://arxiv.org/html/2412.12094/x3.png", "caption": "Figure 1: The loss comparison between vanilla Transformer and proposed SepLLM. SepLLM achieves lower loss at different computation costs and different training time consistently.", "description": "\uc774 \uadf8\ub9bc\uc740 Vanilla Transformer\uc640 \uc81c\uc548\ub41c SepLLM \uac04\uc758 \ud6c8\ub828 \uc190\uc2e4\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. x\ucd95\uc740 \uacc4\uc0b0 \ube44\uc6a9(TFLOPS) \ub610\ub294 \ud6c8\ub828 \uc2dc\uac04(\ucd08)\uc744 \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \ud6c8\ub828 \uc190\uc2e4\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. SepLLM\uc740 \ub3d9\uc77c\ud55c \uacc4\uc0b0 \ube44\uc6a9\uc774\ub098 \ud6c8\ub828 \uc2dc\uac04\uc5d0\uc11c Vanilla Transformer\ubcf4\ub2e4 \ud6c8\ub828 \uc190\uc2e4\uc774 \ub0ae\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, SepLLM\uc774 \ub354 \ud6a8\uc728\uc801\uc784\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub610\ud55c SepLLM\uc774 \uacc4\uc0b0 \ube44\uc6a9\uacfc \ud6c8\ub828 \uc2dc\uac04 \ubaa8\ub450\uc5d0\uc11c \uc548\uc815\uc801\uc73c\ub85c \ub0ae\uc740 \uc190\uc2e4\uc744 \ub2ec\uc131\ud558\uc5ec \uc77c\uad00\ub41c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.12094/x4.png", "caption": "Figure 2: The visualization of attention scores among different layers given the input \u201cNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. \u2026\u201d. Note that the separator tokens like \u201c,\u201d and \u201c.\u201d contribute massive attentions.", "description": "\uc774 \uadf8\ub9bc\uc740 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. ...'\ub77c\ub294 \uc785\ub825\uc774 \uc8fc\uc5b4\uc84c\uc744 \ub54c, \uc5ec\ub7ec \uce35\uc5d0 \uac78\uce5c \uc5b4\ud150\uc158 \uc810\uc218\ub97c \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. \uc27c\ud45c(\",\")\uc640 \ub9c8\uce68\ud45c(\".\")\uc640 \uac19\uc740 \uad6c\ubd84\uc790 \ud1a0\ud070\ub4e4\uc774 \uc0c1\ub2f9\ud788 \ub192\uc740 \uc5b4\ud150\uc158 \uc810\uc218\ub97c \ubc1b\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub294\ub370,  \uc774\ub294 \uad6c\ubd84\uc790\ub4e4\uc774 \ubb38\ub9e5 \uc815\ubcf4\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc555\ucd95\ud558\uace0 \uc804\ub2ec\ud558\ub294 \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "Method"}, {"figure_path": "https://arxiv.org/html/2412.12094/x5.png", "caption": "Figure 3: The overall paradigm of\u00a0SepLLM. The left side illustrates the attention mask in the training or pre-filling stage given the input \u201cABC,DE.FG\\n\\absent\ud835\udc5b\\backslash n\\ italic_n\u201d. The right side illustrates the KV cache management in the generation stage.", "description": "\uc774 \uadf8\ub9bc\uc740 SepLLM\uc758 \uc804\ubc18\uc801\uc778 \ud328\ub7ec\ub2e4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc740 \"ABC,DE.FG\\n\" \uc785\ub825\uc5d0 \ub300\ud55c \ud6c8\ub828 \ub610\ub294 \uc0ac\uc804 \ucc44\uc6b0\uae30 \ub2e8\uacc4\uc758 \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc624\ub978\ucabd\uc740 \uc0dd\uc131 \ub2e8\uacc4\uc5d0\uc11c\uc758 KV \uce90\uc2dc \uad00\ub9ac\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SepLLM\uc740 \ud2b9\uc815 \ub808\uc774\uc5b4\uc5d0\uc11c \uac01 \ud1a0\ud070\uc774 \uc774\uc804 \ub808\uc774\uc5b4\uc5d0\uc11c \ucd9c\ub825\ub41c \uc774\uc804 \ud1a0\ud070\uc758 hidden state\uc758 \uc77c\ubd80\ub9cc \ubcfc \uc218 \uc788\ub3c4\ub85d \uc81c\ud55c\ud569\ub2c8\ub2e4. \uc774 \ubd80\ubd84\uc9d1\ud569\uc5d0\ub294 \ucd08\uae30 \uba87 \uac1c \ub2e8\uc5b4(attention sinks), \ud604\uc7ac \ud1a0\ud070 \uc774\uc804\uc758 \ubaa8\ub4e0 \uad6c\ubd84 \uae30\ud638 \ud1a0\ud070, \ud604\uc7ac \ud1a0\ud070\uc5d0 \uac00\uc7a5 \uac00\uae4c\uc6b4 n\uac1c\uc758 \ud1a0\ud070\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \ud6c8\ub828 \ub610\ub294 \uc0ac\uc804 \ucc44\uc6b0\uae30 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc785\ub825 \ucee8\ud14d\uc2a4\ud2b8\uc758 \ubaa8\ub4e0 \ud1a0\ud070\uc5d0 \ud574\ub2f9\ud558\ub294 \ubaa8\ub4e0 \ucffc\ub9ac \ubca1\ud130\uc640 \ubaa8\ub4e0 \ud0a4 \ubca1\ud130\ub97c \uacf1\ud560 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc 3\uc758 \ub9c8\uc2a4\ud06c \ud589\ub82c\uc5d0\uc11c \uac15\uc870 \ud45c\uc2dc\ub41c \uc694\uc18c\uc5d0 \ud574\ub2f9\ud558\ub294 \ucffc\ub9ac \ud0a4 \uc30d\uc758 \ubca1\ud130\ub9cc \uacf1\ud558\uba74 \ub429\ub2c8\ub2e4. \uc0dd\uc131 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc0c8 \ud1a0\ud070\uc744 \uc0dd\uc131\ud560 \ub54c \ucd08\uae30 \ud1a0\ud070, \uad6c\ubd84 \uae30\ud638 \ud1a0\ud070 \ubc0f \uc778\uc811 \ud1a0\ud070\uc5d0 \ub300\ud55c KV \uce90\uc2dc\ub9cc \uc720\uc9c0\ub429\ub2c8\ub2e4. \ub530\ub77c\uc11c SepLLM\uc758 KV \uce90\uc2dc\ub294 \ud6e8\uc52c \uc791\uace0 \uba54\ubaa8\ub9ac\uac00 \ub35c \ud544\uc694\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.12094/x6.png", "caption": "Figure 4: Overall framework of the proposed SepLLM\u00a0tailored for streaming applications. The KV pairs are storaged in four cache blocks (displayed as four columns), and are updated in each iteration (shown in a single row). Once the runtime usage S\u2062i\u2062z\u2062er\u2062u\u2062n\ud835\udc46\ud835\udc56\ud835\udc67subscript\ud835\udc52\ud835\udc5f\ud835\udc62\ud835\udc5bSize_{run}italic_S italic_i italic_z italic_e start_POSTSUBSCRIPT italic_r italic_u italic_n end_POSTSUBSCRIPT reach the max capacity c, SepLLM move KV caches of separator tokens in Past Window Cache into Separator Cache and drop other KV caches.", "description": "SepLLM\uc758 \uc2a4\ud2b8\ub9ac\ubc0d \uc801\uc6a9\uc744 \uc704\ud55c \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4. KV \uc30d\uc740 \ub124 \uac1c\uc758 \uce90\uc2dc \ube14\ub85d(\ucd08\uae30 \uce90\uc2dc, \uad6c\ubd84\uc790 \uce90\uc2dc, \uacfc\uac70 \uc708\ub3c4\uc6b0 \uce90\uc2dc, \ub85c\uceec \uc708\ub3c4\uc6b0 \uce90\uc2dc)\uc5d0 \uc800\uc7a5\ub429\ub2c8\ub2e4. \uac01 \ud589\uc740 \ubc18\ubcf5\uc744 \ub098\ud0c0\ub0b4\uace0, \uc5f4\uc740 \uac01 \uce90\uc2dc \ube14\ub85d\uc758 \uc0c1\ud0dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub7f0\ud0c0\uc784 \uc0ac\uc6a9\ub7c9(Sizerun)\uc774 \ucd5c\ub300 \uc6a9\ub7c9(c)\uc5d0 \ub3c4\ub2ec\ud558\uba74 SepLLM\uc740 \uacfc\uac70 \uc708\ub3c4\uc6b0 \uce90\uc2dc\uc5d0 \uc788\ub294 \uad6c\ubd84\uc790 \ud1a0\ud070\uc758 KV \uce90\uc2dc\ub97c \uad6c\ubd84\uc790 \uce90\uc2dc\ub85c \uc774\ub3d9\ud558\uace0 \ub2e4\ub978 KV \uce90\uc2dc\ub294 \uc0ad\uc81c\ud569\ub2c8\ub2e4. \uad6c\ubd84\uc790 \uce90\uc2dc\uac00 \ucd5c\ub300 \uc6a9\ub7c9(s)\uc5d0 \ub3c4\ub2ec\ud558\uba74 \ub85c\uceec \uc708\ub3c4\uc6b0 \uce90\uc2dc\uc640 \uacfc\uac70 \uc708\ub3c4\uc6b0 \uce90\uc2dc\uc758 \ud06c\uae30\uac00 \uc8fc\uae30\uc801\uc73c\ub85c \ubcc0\ud654\ud558\uba70, \ud3c9\uade0\uc801\uc73c\ub85c \uc804\uccb4 KV \uce90\uc2dc \uc0ac\uc6a9\ub7c9\uc740 \ucd5c\ub300 \uc6a9\ub7c9(c)\ubcf4\ub2e4 \uc791\uac8c \uc720\uc9c0\ub429\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.12094/x7.png", "caption": "(a) Loss w.r.t\u00a0steps", "description": "\uc774 \uadf8\ub798\ud504\ub294 \uc2a4\ud06c\ub798\uce58\ubd80\ud130 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ud6c8\ub828 \ub2e8\uacc4\uc5d0 \ub530\ub978 \uc190\uc2e4 \uac12\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Vanilla Transformer, SepLLM(n=64), SepLLM(n=128), SepLLM(n=64, H), SepLLM(n=64, H/T) \ub4f1 \ub2e4\uc591\ud55c \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98\uc5d0 \ub300\ud55c \ud6c8\ub828 \uc190\uc2e4 \uace1\uc120\uc744 \ube44\uad50\ud558\uc5ec SepLLM\uc774 Vanilla Transformer\uc5d0 \ube44\ud574 \ud6c8\ub828 \uc190\uc2e4\uc774 \ub0ae\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. x\ucd95\uc740 \ud6c8\ub828 \ub2e8\uacc4\ub97c, y\ucd95\uc740 \uc190\uc2e4 \uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.3. Training from Scratch"}, {"figure_path": "https://arxiv.org/html/2412.12094/x8.png", "caption": "(b) Loss Ratio w.r.t\u00a0FLOPs", "description": "\uc774 \uadf8\ub798\ud504\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \ud559\uc2b5 \uc190\uc2e4 \ube44\uc728\uc744 FLOPs(Floating Point Operations Per Second)\uc5d0 \ub530\ub77c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Vanilla Transformer \ubaa8\ub378\uc744 \uae30\uc900\uc73c\ub85c SepLLM\uacfc StrmLLM\uc758 \uc190\uc2e4 \ube44\uc728\uc744 FLOPs \uc99d\uac00\uc5d0 \ub530\ub77c \ud45c\uc2dc\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. SepLLM\uc740 \ub3d9\uc77c\ud55c FLOPs\uc5d0\uc11c Vanilla Transformer\ubcf4\ub2e4 \ub0ae\uc740 \uc190\uc2e4 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 SepLLM\uc774 \uc5f0\uc0b0 \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c Vanilla Transformer\ubcf4\ub2e4 \uc6b0\uc218\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ub610\ud55c, SepLLM\uc758 \uc5ec\ub7ec \ubcc0\ud615(n=64, n=128, n=64, H, n=64, H/T) \ub610\ud55c Vanilla Transformer\ubcf4\ub2e4 \ub0ae\uc740 \uc190\uc2e4 \ube44\uc728\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4.3. Training from Scratch"}, {"figure_path": "https://arxiv.org/html/2412.12094/x10.png", "caption": "Figure 5: Training loss curves for training from scratch. 5(b) shows the ratio of the loss values of different methods to that of Vanilla with respect to FLOPs.", "description": "\uc774 \uadf8\ub9bc\uc740 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ud560 \ub54c\uc758 \ud559\uc2b5 \uc190\uc2e4 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 5(b)\ub294 FLOPs\uc5d0 \ub300\ud55c Vanilla \ub300\ube44 \ub2e4\uc591\ud55c \uba54\uc11c\ub4dc\uc758 \uc190\uc2e4 \uac12 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SepLLM\uc740 Vanilla \ubaa8\ub378\ubcf4\ub2e4 \uc801\uc740 FLOPs\uc5d0\uc11c \ub354 \ub0ae\uc740 \uc190\uc2e4\uc744 \ub2ec\uc131\ud558\uba70, \ud2b9\ud788 SepLLM(n=64, H/T)\uac00 \ub450\ub4dc\ub7ec\uc9d1\ub2c8\ub2e4. StrmLLM\uc740 Vanilla\ubcf4\ub2e4 \uc190\uc2e4 \uac10\uc18c\uac00 \ub290\ub9bd\ub2c8\ub2e4.", "section": "4.3. Training from Scratch"}, {"figure_path": "https://arxiv.org/html/2412.12094/x11.png", "caption": "Figure 6: Training loss curves for the post-training.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0ac\uc804 \ud6c8\ub828 \ud6c4 \ub2e4\uc591\ud55c SepLLM \uc124\uc815(n=64, n=128, \ub354 \ud070 \ud559\uc2b5\ub960)\uc744 \uc0ac\uc6a9\ud55c \ud6c8\ub828 \uc190\uc2e4 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. n \uac12\uc744 \ub192\uc774\uace0 \ud559\uc2b5\ub960\uc744 \uc801\uc808\ud558\uac8c \ub192\uc774\uba74 \uc190\uc2e4 \uac10\uc18c\uc5d0 \ub3c4\uc6c0\uc774 \ub41c\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc804\uccb4 \uc5b4\ud150\uc158 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uccb4\ud06c\ud3ec\uc778\ud2b8\uc5d0\uc11c SepLLM \uc544\ud0a4\ud14d\ucc98\uc758 \uc694\uad6c \uc0ac\ud56d\uc5d0 \ub9de\ub294 \ubaa8\ub378\ub85c \uc0ac\ud6c4 \ud6c8\ub828\uc744 \ud1b5\ud574 \uc2e0\uc18d\ud558\uac8c \uc804\ud658\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4. Post-training"}, {"figure_path": "https://arxiv.org/html/2412.12094/x12.png", "caption": "Figure 7: The evolution of KV caches in the streaming setting.", "description": "\uc2a4\ud2b8\ub9ac\ubc0d \uc124\uc815\uc5d0\uc11c KV \uce90\uc2dc\uc758 \uc9c4\ud654 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774, \ud1a0\ud070 mo \uc774\ud6c4\uc5d0\ub294 n\uacfc Sizerun\uc774 \uc8fc\uae30\uc801\uc778 \ud568\uc218 \ud615\ud0dc\ub97c \ub760\uac8c \ub418\uba70, \uc0ac\uc6a9\ub418\ub294 \ud3c9\uade0 KV \uce90\uc2dc \ud06c\uae30\ub294 \ucd5c\ub300 \uc6a9\ub7c9\uc778 c\ubcf4\ub2e4 \ud6e8\uc52c \uc791\uc2b5\ub2c8\ub2e4.", "section": "3. Method"}]