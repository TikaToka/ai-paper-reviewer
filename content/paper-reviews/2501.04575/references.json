{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-11-28", "reason": "This paper introduces Flamingo, a visual language model that is foundational to many multimodal large language models (MLLMs), which are central to the development of GUI agents."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-VL: A frontier large vision-language model with versatile abilities", "publication_date": "2023-08-01", "reason": "This paper introduces Qwen-VL, a high-performing MLLM used in the InfiGUIAgent's training, significantly impacting its performance."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a vision encoder that is used in many MLLMs and is a key component of the InfiGUIAgent architecture."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-01", "reason": "This paper introduces LLaMA, a large language model that underlies many MLLMs and is crucial for advanced reasoning capabilities in InfiGUIAgent."}, {"fullname_first_author": "Wenyi Hong", "paper_title": "CogAgent: A visual language model for GUI agents", "publication_date": "2024-06-01", "reason": "This paper introduces CogAgent, a state-of-the-art GUI agent that serves as a strong baseline and a comparison point for InfiGUIAgent's performance."}]}