[{"content": "| Model |  | GSM8K | MATH | OlympiadBench | OmniMATH |\n|---|---|---|---|---|---| \n| Qwen2.5-Math-7B-PRM | System1 | 39.4<sup>\u2217</sup> | 52.2<sup>\u2217</sup> | 39.4<sup>\u2217</sup> | 33.1<sup>\u2217</sup> |\n| Math-Shepherd-PRM-7B | System1 | 47.9 | 29.5 | 24.8 | 23.8 |\n| RLHFlow-PRM-Mistral-8B | System1 | 50.4 | 33.4 | 13.8 | 15.8 |\n| RLHFlow-PRM-Deepseek-8B | System1 | 38.8 | 33.8 | 16.9 | 16.9 |\n| Skywork-PRM-1.5B | System1 | 59.0 | 48.0 | 19.3 | 19.2 |\n| Skywork-PRM-7B | System1 | 64.1<sup>\u2217</sup> | 43.2<sup>\u2217</sup> | 16.2<sup>\u2217</sup> | 17.9<sup>\u2217</sup> |\n| Llama-3.1-8B-Instruct | LLM-as-Judge | 27.5<sup>\u2217</sup> | 26.7<sup>\u2217</sup> | 18.5<sup>\u2217</sup> | 19.2<sup>\u2217</sup> |\n| GPT-4o | LLM-as-Judge | 61.9<sup>\u2217</sup> | 53.9<sup>\u2217</sup> | 48.3<sup>\u2217</sup> | 44.6<sup>\u2217</sup> |\n| QwQ-32B-Preview | LLM-as-Judge | 62.3<sup>\u2217</sup> | 52.7<sup>\u2217</sup> | 46.2<sup>\u2217</sup> | 43.9<sup>\u2217</sup> |\n| DeepSeek-R1-Distill-Qwen-14B | LLM-as-Judge | 67.3<sup>\u2217</sup> | 38.8<sup>\u2217</sup> | 29.9<sup>\u2217</sup> | 32.1<sup>\u2217</sup> |\n| **Dyve 14B** | System1 + System2 | **68.5** | **58.3** | **49.0** | **47.2** |", "caption": "Table 1: Performance comparison on ProcessBench. F1 scores, computed from accuracies on erroneous and correct samples, are reported for four benchmarks: GSM8K, MATH, OlympiadBench, and OmniMATH. Dyve 14B leverages a dual reasoning approach (fast System1 and slow System2) to achieve superior performance, with scores of 68.5, 58.3, 49.0, and 47.2, respectively, and it shows enhanced generalization on Olympiad-level mathematics. Models marked with a \u2217 are evaluated using our custom implementation to align with our experimental settings in the absence of an official evaluation script.", "description": "\ud45c 1\uc740 ProcessBench\ub77c\ub294 \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  GSM8K, MATH, OlympiadBench, OmniMATH \ub124 \uac00\uc9c0 \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc624\ub958\uac00 \uc788\ub294 \uc0d8\ud50c\uacfc \uc815\ub2f5 \uc0d8\ud50c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \uae30\ubc18\uc73c\ub85c F1 \uc810\uc218\ub97c \uacc4\uc0b0\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4. Dyve 14B \ubaa8\ub378\uc740 \ube60\ub978 System 1\uacfc \ub290\ub9b0 System 2\ub77c\ub294 \uc774\uc911 \ucd94\ub860 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\ub978 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc6d4\ub4f1\ud55c \uc131\ub2a5(\uac01\uac01 68.5, 58.3, 49.0, 47.2 \uc810\uc218)\uc744 \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uace0\ub09c\uc774\ub3c4 \uc218\ud559 \ubb38\uc81c\ub97c \ub2e4\ub8e8\ub294 Olympiad \uc218\uc900\uc758 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub3c4 \uc6b0\uc218\ud55c \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0 \ud45c\uc2dc\ub41c \uc77c\ubd80 \ubaa8\ub378\ub4e4\uc758 \uacb0\uacfc\ub294 \uacf5\uc2dd\uc801\uc778 \ud3c9\uac00 \uc2a4\ud06c\ub9bd\ud2b8\uac00 \uc5c6\uc5b4 \uc5f0\uad6c\uc9c4\uc774 \uc9c1\uc811 \uad6c\ud604\ud55c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5bb\uc5b4\uc9c4 \uacb0\uacfc\uc784\uc744 \uc720\uc758\ud574\uc57c \ud569\ub2c8\ub2e4.", "section": "4.1 Benchmarks"}]