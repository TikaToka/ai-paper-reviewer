---
title: "MEETING DELEGATE: Benchmarking LLMs on Attending Meetings on Our Behalf"
summary: "LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì´ ì‹¤ì œ íšŒì˜ ì°¸ì—¬ì— íš¨ê³¼ì ì¸ì§€ í‰ê°€í•œ ì—°êµ¬ë¡œ, GPT-4 ë“± ì£¼ìš” LLMì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ê³ , í•œê³„ì ê³¼ ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Peking University",]
showSummary: true
date: 2025-02-05
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.04376 {{< /keyword >}}
{{< keyword icon="writer" >}} Lingxiang Hu et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-10 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.04376" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.04376" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/meeting-delegate-benchmarking-llms-on" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

í˜„ëŒ€ ì—…ë¬´ í™˜ê²½ì—ì„œ íšŒì˜ëŠ” í•„ìˆ˜ì ì´ë‚˜ ì‹œê°„ ë‚­ë¹„, ì¼ì • ì¶©ëŒ ë“±ì˜ ë¬¸ì œì ì„ ì•ˆê³  ìˆìŠµë‹ˆë‹¤.  ë³¸ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤.  ì´ëŠ” LLMì˜ ìì—°ì–´ ì²˜ë¦¬ ë° ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©, ì°¸ì„ìë¥¼ ëŒ€ì‹ í•˜ì—¬ íšŒì˜ì— ì°¸ì—¬í•˜ê³  ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” ì‹¤ì œ íšŒì˜ë¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ GPT-4, Gemini ë“± ì—¬ëŸ¬ LLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.  **GPT-4ëŠ” ê· í˜• ì¡íŒ ì„±ê³¼**ë¥¼ ë³´ì˜€ìœ¼ë©°, ì¼ë¶€ LLMì€ ê³¼ë„í•˜ê²Œ ì ê·¹ì ì´ê±°ë‚˜ ì†Œê·¹ì ì¸ ê²½í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  **ì˜¤ë¥˜ ê°ì†Œ ë° ì‹¤ì‹œê°„ ì‘ë‹µ ì†ë„ ê°œì„ ** ë“±ì˜ ê°œì„ ì ì´ ì œì‹œë˜ì—ˆê³ , ì´ë¥¼ í†µí•´ **LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì‹¤ìš©ì„±**ì„ ë†’ì¼ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LLMì„ í™œìš©í•œ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì‹¤í˜„ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ë‹¤ì–‘í•œ LLMì˜ ì„±ëŠ¥ì„ ì‹¤ì œ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ í•œê³„ì ê³¼ ê°œì„  ë°©í–¥ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œ**ì˜ ì‹¤í˜„ ê°€ëŠ¥ì„±ê³¼ ê·¸ ê³¼ì œë¥¼ íƒêµ¬í•˜ì—¬, **ì‹¤ì œ íšŒì˜ë¡ì„ ì´ìš©í•œ ì¢…í•©ì ì¸ ë²¤ì¹˜ë§ˆí‚¹**ì„ í†µí•´ ë‹¤ì–‘í•œ LLMì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ê³ , LLMì„ íšŒì˜ ì°¸ì—¬ì— í™œìš©í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.  ì´ëŠ” **ìƒì‚°ì„± í–¥ìƒ ë° íš¨ìœ¨ì ì¸ íšŒì˜ ì°¸ì—¬**ì— ëŒ€í•œ ìš”êµ¬ê°€ ì¦ê°€í•˜ëŠ” í˜„ëŒ€ ì—…ë¬´ í™˜ê²½ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹™ë‹ˆë‹¤.  ë˜í•œ, ë³¸ ì—°êµ¬ëŠ” **ê°œì„  ë°©í–¥ ë° ë¯¸ë˜ ì—°êµ¬ ê³¼ì œ**ë¥¼ ì œì‹œí•˜ì—¬ LLM ê¸°ë°˜ íšŒì˜ ê¸°ìˆ  ë°œì „ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/shadow_clone_architecture-v4.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ì œì•ˆëœ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì•„í‚¤í…ì²˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì‚¬ìš©ìê°€ íšŒì˜ì— ì°¸ì„í•˜ê¸° ì „ì— ë¯¸ë¦¬ ê´€ë ¨ ì •ë³´(ê´€ì‹¬ ì£¼ì œ, ë°°ê²½ ì§€ì‹, ê³µìœ  ìë£Œ ë“±)ë¥¼ ì…ë ¥í•  ìˆ˜ ìˆëŠ” ì •ë³´ ìˆ˜ì§‘ ëª¨ë“ˆê³¼, íšŒì˜ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” íšŒì˜ ì°¸ì—¬ ëª¨ë“ˆ, ê·¸ë¦¬ê³  ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŒì„± ìƒì„± ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.  ì •ë³´ ìˆ˜ì§‘ ëª¨ë“ˆì€ LLMì´ íšŒì˜ì— ì°¸ì—¬í•˜ëŠ” ë° í•„ìš”í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì—­í• ì„ í•˜ê³ , íšŒì˜ ì°¸ì—¬ ëª¨ë“ˆì€ LLMì„ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ë©°, ìŒì„± ìƒì„± ëª¨ë“ˆì€ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ íšŒì˜ì— ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Architecture of the meeting delegate system.
> </details>





{{< table-caption >}}
|---|---|---| 
| **Phase I: Execute** | **Phase II: Assist** | **Phase III: Delegate** | 
| Data Boundary | User-defined boundaries | Privacy-protected boundaries | Data accessible by user | 
| Share Information | Only within user-defined boundaries | Some reasoning over sensitive data | Autonomous based on predefined goals and preferences | 
| Collect Information | Explicit requests only | Infer context beyond user instructions | Autonomously collects and reasons based on meeting context | 
| Decision-Making | No decision-making | Propose and ask for approval | Full autonomous decision-making | {{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ì™„ì „í•œ ììœ¨ ë¯¸íŒ… ëŒ€ë¦¬ì¸ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ììœ¨ì„±ê³¼ ì±…ì„ì˜ ì§„í–‰ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¨ê³„ë³„ë¡œ ë°ì´í„° ê²½ê³„, ì •ë³´ ê³µìœ , ì •ë³´ ìˆ˜ì§‘, ì˜ì‚¬ ê²°ì • ë°©ë²•ì— ëŒ€í•œ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. 1ë‹¨ê³„(ì‹¤í–‰)ì—ì„œëŠ” ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ê²½ê³„ ë‚´ì—ì„œë§Œ ì‘ë™í•˜ê³ , ëª…ì‹œì ìœ¼ë¡œ ìŠ¹ì¸ëœ ì •ë³´ë§Œ ê³µìœ í•˜ë©°, ì‚¬ìš©ìì˜ ëª…ì‹œì  ìš”ì²­ì— ë”°ë¼ì„œë§Œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.  2ë‹¨ê³„(ì§€ì›)ì—ì„œëŠ” ì‹œìŠ¤í…œì´ ê°œì¸ì •ë³´ ë³´í˜¸ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ë©´ì„œ ë¯¼ê°í•œ ë°ì´í„°ë¥¼ ì¶”ë¡ í•˜ê³ , í–‰ë™ì„ ì œì•ˆí•˜ì§€ë§Œ ì‚¬ìš©ìì˜ ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.  3ë‹¨ê³„(ìœ„ì„)ì—ì„œëŠ” ì‹œìŠ¤í…œì´ ììœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ê³µìœ í•˜ë©°, ì‚¬ìš©ì ì •ì˜ ëª©í‘œì™€ ê¸°ë³¸ ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²°ì •ì„ ë‚´ë¦½ë‹ˆë‹¤.  ê°œì¸ ì •ë³´ ë³´í˜¸ í•„í„°, ì˜ì‚¬ ê²°ì • ëª¨ë¸, ê°ì‚¬ ë¡œê·¸ë¥¼ í†µí•´ íˆ¬ëª…ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Progression of Autonomy and Responsibility in Achieving a Fully Autonomous Meeting Delegate.
> </details>





### In-depth insights


#### LLM Meeting Agents
LLM ë¯¸íŒ… ì—ì´ì „íŠ¸ëŠ” **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì„ í™œìš©í•˜ì—¬ íšŒì˜ ì°¸ì„ìë¥¼ ëŒ€ì‹ í•˜ì—¬ íšŒì˜ì— ì°¸ì—¬í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.  ì´ ì‹œìŠ¤í…œì€ íšŒì˜ ë§¥ë½ì„ ì´í•´í•˜ê³ , ìì—°ì–´ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•˜ë©°, ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ì—¬ íš¨ìœ¨ì ì¸ íšŒì˜ ì°¸ì—¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.  **í•µì‹¬ì ì¸ ê¸°ìˆ ì  ê³¼ì œ**ëŠ” ë‹¤ì–‘í•œ ì°¸ì—¬ìì˜ ë°œì–¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´í•´í•˜ê³ , ë¬¸ë§¥ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.  ì´ëŠ” LLMì˜ ìì—°ì–´ ì²˜ë¦¬ ë° ì¶”ë¡  ëŠ¥ë ¥ì— ì˜ì¡´í•˜ë©°, **ì˜¤ë¥˜ê°€ í¬í•¨ëœ ìŒì„± ì¸ì‹ ê²°ê³¼**ë‚˜ ëª¨í˜¸í•œ ë°œì–¸ì— ëŒ€í•œ ì²˜ë¦¬ ëŠ¥ë ¥ ë˜í•œ ì¤‘ìš”í•©ë‹ˆë‹¤.  **ê°œì¸ ì •ë³´ ë³´í˜¸** ë° **ì‹¤ì‹œê°„ ì‘ë‹µ** ë˜í•œ ì¤‘ìš”í•œ ê³ ë ¤ ì‚¬í•­ì´ë©°, í–¥í›„ ì—°êµ¬ë¥¼ í†µí•´ í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤.  **LLMì˜ ì¢…ë¥˜**ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ë„ ì¡´ì¬í•˜ë©°, íŠ¹íˆ **GPT ê³„ì—´** ëª¨ë¸ì´ ê· í˜•ì¡íŒ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°˜ë©´, ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ ì§€ë‚˜ì¹˜ê²Œ ì ê·¹ì ì´ê±°ë‚˜ ì†Œê·¹ì ì¸ ê²½í–¥ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.  ë”°ë¼ì„œ,  LLM ë¯¸íŒ… ì—ì´ì „íŠ¸ì˜ ì‹¤ìš©ì ì¸ ì ìš©ì„ ìœ„í•´ì„œëŠ” **ëª¨ë¸ ì„ íƒ**, **ì˜¤ë¥˜ ì²˜ë¦¬**, **ê°œì¸ ì •ë³´ ë³´í˜¸** ë“± ë‹¤ë°©ë©´ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

#### Benchmarking LLMs
ë³¸ ë…¼ë¬¸ì—ì„œ "LLM ë²¤ì¹˜ë§ˆí‚¹"ì€ **ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ì‹¤ì œ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€**í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ë‹¨ìˆœíˆ ì„±ëŠ¥ ìˆ˜ì¹˜ ë¹„êµë¥¼ ë„˜ì–´, **GPT-4, Gemini, Llama ë“± ê° ëª¨ë¸ì˜ íšŒì˜ ì°¸ì—¬ ì „ëµ(ëŠ¥ë™ì  ì°¸ì—¬ vs. ì‹ ì¤‘í•œ ì°¸ì—¬)**ì„ ë¶„ì„í•˜ê³ , **ì˜¤ë¥˜ í—ˆìš© ë²”ìœ„ ë° ë‹µë³€ ì ì ˆì„±** ë“± ì‹¤ì œ í™˜ê²½ ì ìš© ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.  **ì‹¤ì œ íšŒì˜ ë°ì´í„°ë¥¼ í™œìš©í•œ ë²¤ì¹˜ë§ˆí‚¹**ì€ ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , **LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ í˜„ì‹¤ì ì¸ ì ìš© ê°€ëŠ¥ì„± ë° í•œê³„**ë¥¼ ëª…í™•íˆ ì œì‹œí•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤(ëª…ì‹œì /ì•”ì‹œì  ë‹¨ì„œ, ì°¸ì—¬/ì¹¨ë¬µ)**ë¥¼ í¬í•¨í•œ ì¢…í•©ì ì¸ í‰ê°€ëŠ” LLM ê¸°ë°˜ ì‹œìŠ¤í…œì˜ ì‹¤ìš©ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•˜ë©°, **í–¥í›„ ì—°êµ¬ ë°©í–¥**ì„ ì œì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ, **ì „ì‚¬ ì˜¤ë¥˜ì— ëŒ€í•œ ë‚´ì„± ê°•í™” ë° ê´€ë ¨ ê¸°ìˆ  ë°œì „**ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

#### Real-World Testing
ì—°êµ¬ ë…¼ë¬¸ì˜ "ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸" ë¶€ë¶„ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” í†µì°°ë ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. **ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸ëŠ” ì œì•ˆëœ ì‹œìŠ¤í…œì˜ ì‹¤ìš©ì„±ê³¼ íš¨ìœ¨ì„±ì„ í‰ê°€í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•œ ë‹¨ê³„**ì…ë‹ˆë‹¤.  ì´ëŠ” ì‹œë®¬ë ˆì´ì…˜ì´ë‚˜ ì´ìƒì ì¸ ì¡°ê±´ì—ì„œì˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì‹¤ì œ ì‚¬ìš© í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë¬¸ì œì ì„ íŒŒì•…í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ì‹¤ì œ ë¯¸íŒ… ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•œ í­ë„“ì€ í…ŒìŠ¤íŠ¸**ëŠ” ì‹œìŠ¤í…œì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.  í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ëª¨ë¸ì˜ ê°•ì ê³¼ ì•½ì ì„ ë³´ì—¬ì£¼ë©°, ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  **ì˜¤ë¥˜ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ì˜ í•œê³„ì ì„ íŒŒì•…í•˜ê³  ê°œì„  ë°©í–¥ì„ ì„¤ì •**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì „ì‚¬ ì˜¤ë¥˜ì— ëŒ€í•œ ë‚´ì„±ì„ ë†’ì´ê±°ë‚˜, ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì„ ì¤„ì´ê³  ì‘ë‹µì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ëª¨ë¸ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°±ì€ ì‹œìŠ¤í…œì˜ ì‚¬ìš©ì„± ë° ì‹¤ìš©ì„±ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.  **ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì–»ì€ ë°ì´í„°ëŠ” í–¥í›„ ì‹œìŠ¤í…œ ê°œë°œ ë° ê°œì„ ì— ëŒ€í•œ ë°©í–¥**ì„ ì œì‹œí•˜ë©°, **LLM ê¸°ë°˜ ì‹œìŠ¤í…œì˜ ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±ì„ í‰ê°€**í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  ë”°ë¼ì„œ, ì‹¤ì œ í™˜ê²½ í…ŒìŠ¤íŠ¸ëŠ” LLM ê¸°ë°˜ ë¯¸íŒ… ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì„±ê³µì ì¸ êµ¬ì¶•ì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤.

#### Ethical Considerations
ì—°êµ¬ ë…¼ë¬¸ì˜ "ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­" ë¶€ë¶„ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ í†µí•´ ë„ì¶œëœ ì£¼ìš” í†µì°°ë ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. **AI ì‹œìŠ¤í…œì˜ ììœ¨ì„± ìˆ˜ì¤€ì„ ë‹¨ê³„ì ìœ¼ë¡œ ë†’ì´ëŠ” ì ‘ê·¼ ë°©ì‹**ì„ ì œì•ˆí•˜ì—¬, ì±…ì„ ìˆëŠ” AI ê°œë°œ ë° ë°°í¬ë¥¼ ìœ„í•œ í‹€ì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. **ê°œì¸ ì •ë³´ ë³´í˜¸**ëŠ” ìµœìš°ì„  ìˆœìœ„ë¡œ ë‹¤ë£¨ì–´ì ¸ì•¼ í•˜ë©°, **ë°ì´í„° ì•”í˜¸í™”, ì°¨ë“±ì  í”„ë¼ì´ë²„ì‹œ, ì‚¬ìš©ì ì •ì˜ ê²½ê³„ ì„¤ì •, ê°ì‚¬ ì¶”ì ** ë“±ì˜ ê¸°ìˆ ì„ í†µí•´ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ê°•í™”í•´ì•¼ í•©ë‹ˆë‹¤. **íˆ¬ëª…ì„±**ì„ í™•ë³´í•˜ê¸° ìœ„í•´ AI ì‹œìŠ¤í…œì˜ ê¸°ëŠ¥ê³¼ í•œê³„ë¥¼ ëª…í™•íˆ ë°íˆê³  ì‚¬ìš©ìì—ê²Œ AIê°€ ê°œì…ë˜ì—ˆìŒì„ ì•Œë¦¬ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. **ì¸ê°„ì˜ ê°œì…**ì€ AI ì‹œìŠ¤í…œì˜ ììœ¨ì„±ì„ ì œí•œí•˜ê³  ì±…ì„ ìˆëŠ” ì‚¬ìš©ì„ ë³´ì¥í•˜ëŠ” ë° í•„ìˆ˜ì ì´ë©°, ì´ë¥¼ ìœ„í•´ **ì¸ê°„ ì¤‘ì‹¬ ë£¨í”„ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤. **ì‚¬íšŒ ê²½ì œì  ì˜í–¥** ë˜í•œ ê³ ë ¤ë˜ì–´ì•¼ í•˜ë©°, **AI ì‹œìŠ¤í…œì´ ì¼ìë¦¬ ê°ì†Œë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±**ì„ ê³ ë ¤í•˜ì—¬ ì¸ê°„ ë…¸ë™ì„ ë³´ì™„í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ AI ê¸°ìˆ ì„ ê°œë°œí•´ì•¼ í•©ë‹ˆë‹¤. **í¸í–¥ì„±ê³¼ ê³µì •ì„±** ë˜í•œ ì¤‘ìš”í•œ ë¬¸ì œì´ë©°, **ë‹¤ì–‘í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í¸í–¥ì„±ì„ ì™„í™”í•˜ê³  ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§**ì„ í†µí•´ ê³µì •ì„±ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.

#### Future Work
ë³¸ ë…¼ë¬¸ì€ LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ í˜„ì¬ í•œê³„ì ê³¼ ë”ë¶ˆì–´ **í–¥í›„ ì—°êµ¬ ë°©í–¥**ì— ëŒ€í•œ ì‹¬ë„ìˆëŠ” ë…¼ì˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.  **ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ ë° ë‹¤êµ­ì–´ ì§€ì›**ê³¼ ê°™ì€ ê¸°ìˆ ì  ê°œì„ ì„ í†µí•´ ë³´ë‹¤ ì‹¤ì œì ì¸ í™˜ê²½ì—ì„œ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  **ê°œì¸ì •ë³´ë³´í˜¸ ë° ë³´ì•ˆ**ì„ ê°•í™”í•˜ê³ , **ì‚¬ìš©ìì˜ í”„ë¼ì´ë²„ì‹œ**ë¥¼ ë³´í˜¸í•˜ëŠ” ë°©ì•ˆ ë˜í•œ í•„ìˆ˜ì ì…ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ìœ í˜•ì˜ íšŒì˜ ë° ì°¸ê°€ì ì—­í• **ì— ëŒ€í•œ ì‹œìŠ¤í…œ ì ì‘ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì—°êµ¬ê°€ í•„ìš”í•˜ë©°, **ì¸ê°„ê³¼ AIì˜ í˜‘ì—…** ë°©ì‹ì„ ê°œì„ í•˜ì—¬ AIì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ë°©ì•ˆì„ ëª¨ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.  **ì˜¤ë¥˜ í—ˆìš© ë° ë§¥ë½ ì´í•´** ëŠ¥ë ¥ í–¥ìƒì€ í˜„ì‹¤ì ì¸ íšŒì˜ ìƒí™©ì— ëŒ€í•œ ì ì‘ë ¥ì„ ë†’ì´ëŠ”ë° ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.  ë‚˜ì•„ê°€, **ìœ¤ë¦¬ì , ì‚¬íšŒì  ì˜í–¥**ì„ ê³ ë ¤í•˜ì—¬ ì±…ì„ê° ìˆëŠ” AI ì‹œìŠ¤í…œ ê°œë°œì— ëŒ€í•œ ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.  **ì§€ì†ì ì¸ í‰ê°€ ë° ê°œì„ **ì„ í†µí•´ LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì´ ì‹¤ì œ ì—…ë¬´ í™˜ê²½ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ **ê¶ê·¹ì ì¸ ëª©í‘œ**ì…ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/demo_v4.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íšŒì˜ ì „ì— ì‚¬ìš©ìëŠ” íšŒì˜ ëª©ì ê³¼ ê³µìœ  ê°€ëŠ¥í•œ ì •ë³´ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ íšŒì˜ ë…¹ì·¨ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ íšŒì˜ì— ì°¸ì—¬í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ë§ì¶° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Workflow of an LLM-powered meeting delegate system. The process involves user input of meeting intent and shareable information prior to the meeting, real-time participation based on meeting transcripts, and response generation aligned with prompted instructions and meeting objectives.
> </details>



![](https://arxiv.org/html/2502.04376/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ë…¼ë¬¸ì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ êµ¬ì„±ì— ëŒ€í•œ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë§¤ì¹­ ë°ì´í„°ì…‹ì˜ ë‹¤ì–‘í•œ í†µê³„ì  íŠ¹ì§•ë“¤ì„ ë³´ì—¬ì£¼ëŠ” ë„¤ ê°œì˜ ì„œë¸Œ í”Œë¡¯ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ í”Œë¡¯ì€ ì°¸ì—¬ì ìˆ˜ ë¶„í¬ë¥¼, ë‘ ë²ˆì§¸ í”Œë¡¯ì€ ë°œí™” ìˆ˜ ë¶„í¬ë¥¼, ì„¸ ë²ˆì§¸ í”Œë¡¯ì€ ì‹¤ì œ ë°˜ì‘ì—ì„œ ì£¼ìš” ì§€ì  ìˆ˜ ë¶„í¬ë¥¼, ë„¤ ë²ˆì§¸ í”Œë¡¯ì€ ì…ë ¥ ì˜ë„ì™€ ê³µìœ  ê°€ëŠ¥í•œ ìƒí™© ì •ë³´ì— ìˆëŠ” ì£¼ìš” ì§€ì  ìˆ˜ ë¶„í¬ë¥¼ ê°ê° ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì…‹ì˜ ë³µì¡ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, ë§ì€ íšŒì˜ì— 4ëª… ì´ìƒì˜ ì°¸ê°€ìê°€ ìˆìœ¼ë©°, ë°œí™” ìˆ˜ê°€ 50ê°œë¥¼ ë„˜ëŠ” ê²½ìš°ë„ ë§ê³ , ê° ì°¸ê°€ìì˜ ë°œí™”ì— 10ê°œ ì´ìƒì˜ ì£¼ìš” ì§€ì ì´ í¬í•¨ëœ ê²½ìš°ë„ ë§ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Data statistics of the Matched Dataset.
> </details>



![](https://arxiv.org/html/2502.04376/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹(Matched Dataset)ì— ëŒ€í•œ ì‘ë‹µë¥ (Response Rate)ê³¼ ë¶ˆì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹(Mismatched Dataset)ì— ëŒ€í•œ ì¹¨ë¬µë¥ (Silence Rate)ì„ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì€ ì‹¤ì œ íšŒì˜ ë…¹ì·¨ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ëª¨ë¸ì´ ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ì—¬ ê´€ë ¨ì„± ìˆëŠ” ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤. ë¶ˆì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì€ ëª¨ë¸ì´ ì ì ˆí•˜ì§€ ì•Šì€ ìƒí™©ì—ì„œ ë°œì–¸í•˜ì§€ ì•ŠëŠ”ì§€, ì¦‰ ì ì ˆí•œ ì¹¨ë¬µì„ ìœ ì§€í•˜ëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì°¸ì—¬ ì „ëµ(active vs. cautious)ê³¼ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Response Rate on Matched Dataset vs. Silence Rate on Mismatched Dataset.
> </details>



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/error_solution.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ì¼ì¹˜ ë° ë¶ˆì¼ì¹˜ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì‘ë‹µ(ë¬´ìŒ) ë¹„ìœ¨ì˜ ì˜ëª»ëœ ì‚¬ë¡€ ì˜¤ë¥˜ ë¶„ì„ì—ì„œ ë‚˜ì˜¨ í•´ê²°ì±… ë°©í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¼ì¹˜ ë°ì´í„° ì„¸íŠ¸ëŠ” ì‹¤ì œ íšŒì˜ë¡ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê³ , ë¶ˆì¼ì¹˜ ë°ì´í„° ì„¸íŠ¸ëŠ” ì˜ë„ì ìœ¼ë¡œ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ì ì ˆí•˜ê²Œ ì¹¨ë¬µí•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ê³¼ ì•½ì , ê·¸ë¦¬ê³  í–¥í›„ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ë°©í–¥(ì˜ˆ: íšŒì˜ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ í–¥ìƒëœ ì¶”ë¡ , í–¥ìƒëœ ì§€ì‹œì‚¬í•­ ì¤€ìˆ˜, í–¥ìƒëœ ì¼ë°˜ì  ì¶”ë¡  ë“±)ì„ ì œì‹œí•©ë‹ˆë‹¤.  ì¦‰, LLMì´ íšŒì˜ì— íš¨ê³¼ì ìœ¼ë¡œ ì°¸ì—¬í•˜ê¸° ìœ„í•´ ê°œì„ í•´ì•¼ í•  ê¸°ìˆ ì  ì¸¡ë©´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Solution directions from error analysis of bad cases in Response (Silence) Rate for Matched and Mismatched Datasets.
> </details>



![](https://arxiv.org/html/2502.04376/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹(Matched Dataset)ì— ëŒ€í•œ ëŠìŠ¨í•œ ì¬í˜„ìœ¨(Loose Recall Rate)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ëª¨ë¸(GPT-3.5, GPT-4, GPT-40, Gemini 1.5 Flash, Gemini 1.5 Pro, Llama 3-8B, Llama 3-70B)ë³„ë¡œ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ìƒì„±ëœ ì‘ë‹µì´ ì‹¤ì œ íšŒì˜ ë‚´ìš©ì˜ ì£¼ìš” ìš”ì ì„ ì–¼ë§ˆë‚˜ ì˜ ë°˜ì˜í•˜ëŠ”ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ë†’ì€ ì¬í˜„ìœ¨ì€ ëª¨ë¸ì´ íšŒì˜ ë‚´ìš©ì„ ì˜ ì´í•´í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” ì‘ë‹µì„ ìƒì„±í–ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” ë‹¤ì–‘í•œ LLMë“¤ì´ íšŒì˜ ì°¸ì„ì ì—­í• ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ ë¹„êµí•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Loose recall rate on Matched Dataset.
> </details>



![](https://arxiv.org/html/2502.04376/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ìƒì„±ëœ ì‘ë‹µì˜ ê¸°ì›ì„ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. GPT-40, GPT-4, GPT-3.5, Gemini 1.5 Flash, Gemini 1.5 Pro, Llama3-8B, Llama3-70B ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ì‘ë‹µì— ëŒ€í•œ ê¸°ì› ë¹„ìœ¨ì„ 'ì˜ˆìƒ ì‘ë‹µ', 'ì…ë ¥ ì»¨í…ìŠ¤íŠ¸', 'ì´ì „ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸', 'í™˜ê°'ì˜ ë„¤ ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ê° ëª¨ë¸ì˜ ì‘ë‹µì—ì„œ ê° ë²”ì£¼ê°€ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì„ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì–´, ëª¨ë¸ì˜ ì‘ë‹µ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, 'ì˜ˆìƒ ì‘ë‹µ' ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì˜ ì‘ë‹µì´ ì •í™•í•˜ê³  ì‹ ë¢°ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: The attribution rate on matched dataset.
> </details>



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/dataset_construction_v2.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ í‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì°¸ê°€ìë“¤ì€ ë‹¤ë¥¸ ID ë²ˆí˜¸ì™€ ì•„ì´ì½˜ìœ¼ë¡œ í‘œì‹œë˜ê³ , ìƒ‰ìƒì´ ìˆëŠ” ìƒìëŠ” ê° ì°¸ê°€ìì˜ ë°œì–¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê³¼ì •ì—ëŠ” ì…ë ¥ ë§¥ë½ ì •ë³´ ì¶”ì¶œ, ëŒ€í™” ë‚´ìš© ë°œì·Œ, ê·¸ë¦¬ê³  LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ìë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤. ìƒì„±ëœ ì‘ë‹µì€ ì‹¤ì œ ì‘ë‹µê³¼ì˜ ë¹„êµë¥¼ í†µí•´ í‰ê°€ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Example of evaluation dataset construction. Participants are represented by different ID numbers and icons. Colored boxes indicate utterances from different participants. The process includes extracting Input Context Information, creating a Transcript Snapshot, and generating a response with the LLM-powered meeting delegate. The Generated Response is evaluated by comparison with the Ground-Truth Response.
> </details>



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/error_chimein.png)

> ğŸ”¼ ê·¸ë¦¼ 9(a)ëŠ” ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ì°¸ì—¬ ìœ í˜•ì´ 'ë¼ì–´ë“¤ê¸°'ì¸ ê²½ìš°ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜• ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'ë¼ì–´ë“¤ê¸°'ëŠ” ì°¸ê°€ìê°€ íšŒì˜ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ê¸° ìœ„í•´, ê° ëª¨ë¸ì— ëŒ€í•´ ë°œìƒí•œ ì˜¤ë¥˜ì˜ ìœ í˜•ê³¼ ê·¸ ë¹ˆë„ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ì˜¤ë¥˜ ìœ í˜•ì€ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì‹œì ì— ì‘ë‹µí•˜ê±°ë‚˜, ì ì ˆí•œ ë§¥ë½ì„ ì´í•´í•˜ì§€ ëª»í•˜ê±°ë‚˜,  ì¤‘ë³µëœ ë‚´ìš©ì„ ë°˜ë³µí•˜ëŠ” ë“±ì˜ ë¬¸ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ ë¶„ì„ì€ ê° LLMì˜ ê°•ì ê³¼ ì•½ì ì„ íŒŒì•…í•˜ê³ , í–¥í›„ ê°œì„  ë°©í–¥ì„ ëª¨ìƒ‰í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Chine In (Matched Dataset)
> </details>



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/error_explicit.png)

> ğŸ”¼ ê·¸ë¦¼ (b)ëŠ” ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ ëª…ì‹œì  ë‹¨ì„œ(Explicit Cue) ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜• ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª…ì‹œì  ë‹¨ì„œë€, íšŒì˜ ì°¸ê°€ìê°€ íŠ¹ì • ì°¸ê°€ìë¥¼ ì§€ëª©í•˜ì—¬ ì§ˆë¬¸í•˜ê±°ë‚˜ ì˜ê²¬ì„ ìš”ì²­í•˜ëŠ” ê²½ìš°ë¥¼ ë§í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸(GPT-40, Gemini 1.5 Pro, Gemini 1.5 Flash, Llama3-8B)ì— ëŒ€í•´ ê° ì˜¤ë¥˜ ìœ í˜•ì˜ ë°œìƒ íšŸìˆ˜ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ëª¨ë¸ë§ˆë‹¤ ì˜ëª»ëœ ì‘ë‹µì„ ìœ ë°œí•˜ëŠ” ì£¼ìš” ì˜¤ë¥˜ ìœ í˜•ì´ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, GPT-40 ëª¨ë¸ì€ ì˜ëª»ëœ ìµœì‹  ë°œí™”ì— ê¸°ë°˜í•œ ì˜ì‚¬ê²°ì •ì´ ì£¼ìš” ì˜¤ë¥˜ì¸ ë°˜ë©´, ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ ë‹¨ì„œë¥¼ ì¸ì‹í•˜ì§€ ëª»í•˜ê±°ë‚˜, ê´€ë ¨ ë§¥ë½ì„ ì°¾ì§€ ëª»í•˜ê±°ë‚˜, í™˜ê°(hallucination) í˜„ìƒì„ ë³´ì´ëŠ” ë“± ë‹¤ì–‘í•œ ì˜¤ë¥˜ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ë³„ë¡œ ê°•ì ê³¼ ì•½ì ì´ ë‹¤ë¥´ê³ , íšŒì˜ ìƒí™©ì— ëŒ€í•œ ì´í•´ë„ ë° ì¶”ë¡  ëŠ¥ë ¥ì— ì°¨ì´ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Explicit Cue (Matched Dataset)
> </details>



![](https://arxiv.org/html/2502.04376/extracted/6181287/figure/error_mismatch.png)

> ğŸ”¼ ê·¸ë¦¼ 9(c)ëŠ” ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜• ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì˜ëª»ëœ ì‹œì ì— ë°œí™”í•˜ê±°ë‚˜, ì ì ˆí•œ ì‹œì ì— ë°œí™”í•˜ì§€ ì•ŠëŠ” ë“±ì˜ ë¬¸ì œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ì€ ëª¨ë¸ì´ ë§í•˜ì§€ ì•Šì•„ì•¼ í•  ë•Œ ë§í•˜ëŠ” ê²½ìš°ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. ê·¸ë¦¼ì€ GPT-40, Gemini 1.5 Pro, Gemini 1.5 Flash, Llama3-8B ëª¨ë¸ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜•ì˜ ë¹ˆë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ëª¨ë¸ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ì˜¤ë¥˜ê°€ ë‹¤ì–‘í•œ ë¹ˆë„ë¡œ ë°œìƒí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (c) Mismatched Dataset
> </details>



![](https://arxiv.org/html/2502.04376/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 9ëŠ” ì„¸ ê°€ì§€ ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤(ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì˜ ì•”ì‹œì  í, ëª…ì‹œì  í, ë¶ˆì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹)ì—ì„œ ì‘ë‹µë¥  ì‹¤íŒ¨ ì‚¬ë¡€ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜• ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ê·¸ë˜í”„ëŠ” íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìœ í˜•(ì˜ˆ: ì˜ëª»ëœ ìµœì‹  ë°œí™” ê¸°ë°˜ ê²°ì •, ëŠ¥ë™ì  ì°¸ì—¬ í•„ìš”ì„± ê°„ê³¼, ëŒ€í™”ê°€ ì§„í–‰ ì¤‘ì´ë¯€ë¡œ ì¤‘ë‹¨í•  ìˆ˜ ì—†ë‹¤ëŠ” íŒë‹¨, ê´€ë ¨ ë§¥ë½ì„ ì°¾ì§€ ëª»í•¨, í™˜ê° ë“±)ì˜ ë¹ˆë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ì˜ ì£¼ìš” ì›ì¸ì„ íŒŒì•…í•˜ê³  í–¥í›„ ê°œì„ ì„ ìœ„í•œ ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9:  (a) Error Types Distribution for Response Rate Failure Cases Study in Chine In Matched Dataset. (b) Error Types Distribution for Response Rate Failure Cases Study in Explicit Cue Matched Dataset. (c) Error Types Distribution for Response Rate Failure Cases Study in Mismatched Dataset.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Type | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---| 
| Chime In | 39.3% | 37.9% | 61.3% | 71.8% | 41.9% | 84.1% | **93.8%** |
| Explicit Cue | 53.2% | 86.7% | 94.3% | 89.7% | 78.3% | 91.2% | **99.4%** |
| Implicit Cue | 52.2% | 67.2% | 71.9% | 83.6% | 55.9% | 90.0% | **94.8%** |
| All | 50.6% | 68.9% | 77.3% | 83.8% | 60.8% | 89.6% | **96.2%** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ì‹¤ì œ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ë§¤ì¹˜ëœ ë°ì´í„°ì…‹ì—ì„œ ê° ëª¨ë¸ì˜ ì‘ë‹µë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì‘ë‹µë¥ ì€ ê° ëª¨ë¸ì´ íšŒì˜ì— ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ì—¬ ê´€ë ¨ëœ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•œ ì§€í‘œì…ë‹ˆë‹¤. í‘œëŠ” ì„¸ ê°€ì§€ ìœ í˜•ì˜ íšŒì˜ ì°¸ì—¬ ì „ëµ(Chime In, Explicit Cue, Implicit Cue)ì— ë”°ë¥¸ ì‘ë‹µë¥ ì„ ë³´ì—¬ì£¼ë©°, ê° ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì‘ë‹µë¥ ë„ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ë“¤ì´ íšŒì˜ ì°¸ì—¬ ì‹œ ì „ëµì˜ ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ê²°ê³¼ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Response Rate for Matched Dateset.
> </details>

{{< table-caption >}}
| Type | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---| 
| Chime In | 35.2% | 42.3% | 57.7% | 66.2% | 43.7% | 81.7% | **95.8%** |
| Explicit Cue | 58.6% | 92.0% | 92.0% | 87.7% | 76.5% | 89.5% | **98.1%** |
| Implicit Cue | 54.3% | 65.8% | 68.3% | 81.9% | 53.5% | 89.7% | **94.7%** |
| All | 52.9% | 71.2% | 74.8% | 81.5% | 59.9% | 88.4% | **96.0%** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì˜ êµì§‘í•© í•˜ìœ„ ì§‘í•©ì— ëŒ€í•œ ì‘ë‹µë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì€ ì‹¤ì œ íšŒì˜ë¡ì—ì„œ ì¶”ì¶œí•œ ë°ì´í„°ì´ë©°,  ì´ í‘œëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸(GPT-3.5, GPT-4, GPT-40, Gemini 1.5 Flash, Gemini 1.5 Pro, Llama3-8B, Llama3-70B)ì— ëŒ€í•´ ê° ì‹œë‚˜ë¦¬ì˜¤(ëª…ì‹œì  ì‹ í˜¸, ì•”ì‹œì  ì‹ í˜¸, ë¼ì–´ë“¤ê¸°)ë³„ ì‘ë‹µë¥ ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ëª¨ë¸ì˜ í¬ê¸°ì™€ ì„±ëŠ¥ì— ë”°ë¥¸ ì‘ë‹µë¥  ì°¨ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  íŠ¹íˆ, Llama ëª¨ë¸ì˜ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ì°½ ì œí•œìœ¼ë¡œ ì¸í•´ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ê°€ ì œì™¸ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Response Rate for Intersection Subset of Matched Dateset.
> </details>

{{< table-caption >}}
| Type | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---| 
| Explicit Cue | 75.0% | 84.6% | 82.8% | 65.0% | **88.1%** | 36.0% | 41.6% |
| Implicit Cue | 70.4% | **79.5%** | 67.9% | 52.0% | 77.1% | 35.3% | 33.3% |
| All | 72.4% | 81.6% | 73.6% | 57.5% | **81.7%** | 35.6% | 37.0% |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ LLMsì˜ ì¹¨ë¬µë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¦‰, íšŒì˜ ì°¸ê°€ìê°€ ë§í•˜ì§€ ì•Šì•„ì•¼ í•  ë•Œ LLMsê°€ ì–¼ë§ˆë‚˜ ì˜ ì¹¨ë¬µí•˜ëŠ”ì§€ í‰ê°€í•œ ê²°ê³¼ì…ë‹ˆë‹¤.  ê° LLMì— ëŒ€í•´, ëª…ì‹œì  ë‹¨ì„œ, ì•”ì‹œì  ë‹¨ì„œ, ê·¸ë¦¬ê³  ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ì¹¨ë¬µë¥ ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ê° LLMì´ ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ëŠ” ëŠ¥ë ¥ê³¼ ë¶€ì ì ˆí•œ ê°œì…ì„ ìì œí•˜ëŠ” ëŠ¥ë ¥ì„ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Silence Rate for Mismatched Dataset.
> </details>

{{< table-caption >}}
| Type | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---| 
| Explicit Cue | 79.5% | 84.9% | **90.4%** | 76.7% | **90.4%** | 37.0% | 44.6% |
| Implicit Cue | 69.5% | **81.7%** | 74.4% | 58.5% | **81.7%** | 35.4% | 31.9% |
| All | 74.2% | 83.2% | 81.9% | 67.1% | **85.8%** | 36.1% | 38.7% |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ì˜ êµì§‘í•©ì— ëŒ€í•´ ê° ëª¨ë¸ì˜ ì¹¨ë¬µë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ì€ ì°¸ê°€ìê°€ ë§í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” ìƒí™©ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ í‘œëŠ” ê° ëª¨ë¸ì˜ ì¹¨ë¬µë¥ ì„ 'ëª…ì‹œì  ë‹¨ì„œ', 'ì•”ì‹œì  ë‹¨ì„œ', 'ì°¸ì—¬' ì˜ ì„¸ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë‚˜ëˆ„ì–´ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ëŠ” ê²½í–¥ì´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Silence Rate for Intersection Subset of Mismatched Dataset.
> </details>

{{< table-caption >}}
| Model | Chime In |  | Explicit Cue |  | Implicit Cue |  | All |  |
|---|---|---|---|---|---|---|---|---|
|  | Loose | Strict | Loose | Strict | Loose | Strict | Loose | Strict |
| GPT-3.5 | 43.5% | 29.5% | 54.5% | 42.5% | 47.8% | 37.0% | 49.5% | 38.0% |
| GPT-4 | 51.1% | 39.9% | 72.8% | 60.7% | **63.0%** | **49.6%** | 65.9% | 53.1% |
| GPT-4o | **53.9%** | **47.0%** | **77.8%** | **64.2%** | 62.5% | 47.9% | **67.3%** | **53.9%** |
| Gemini 1.5 Flash | 29.2% | 22.5% | 69.5% | 56.5% | 55.0% | 40.2% | 56.6% | 43.4% |
| Gemini 1.5 Pro | 34.6% | 28.8% | 72.8% | 59.9% | 56.0% | 43.5% | 60.5% | 48.6% |
| Llama3-8B | 46.7% | 35.5% | 59.6% | 48.7% | 52.7% | 40.5% | 54.2% | 42.6% |
| Llama3-70B | 45.8% | 34.7% | 69.6% | 59.4% | 55.9% | 44.0% | 59.1% | 47.9% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹(Matched Dataset)ì— ëŒ€í•œ ì¬í˜„ìœ¨(Recall Rate)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¬í˜„ìœ¨ì€ ìƒì„±ëœ ì‘ë‹µì´ ì‹¤ì œ ëŒ€í™”ì—ì„œ ì£¼ìš” ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì˜ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ì—¬, ê° ëª¨ë¸ì´ ì‹¤ì œ ë¯¸íŒ… ëŒ€í™”ì—ì„œ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ë°˜ì˜í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì„¸ë¶€ì ìœ¼ë¡œëŠ”, ëŠìŠ¨í•œ ì¬í˜„ìœ¨(loose recall rate)ê³¼ ì—„ê²©í•œ ì¬í˜„ìœ¨(strict recall rate) ë‘ ê°€ì§€ ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•˜ì˜€ìœ¼ë©°, ê° ëª¨ë¸ì˜ Explicit Cue, Implicit Cue, Chime In ë“± ë‹¤ì–‘í•œ ìƒí™©ë³„ ì„±ëŠ¥ì„ ì œì‹œí•©ë‹ˆë‹¤.  ì´ëŠ” LLM ê¸°ë°˜ ë¯¸íŒ… ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì‹¤ìš©ì„± í‰ê°€ì— ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Recall Rate for Matched Dataset.
> </details>

{{< table-caption >}}
| Model | Chime In |  | Explicit Cue |  | Implicit Cue |  | All |  | 
|---|---|---|---|---|---|---|---|---|
|  | Loose | Strict | Loose | Strict | Loose | Strict | Loose | Strict |
| GPT-3.5 | 55.6% | 47.2% | 58.4% | 46.9% | 56.1% | 45.2% | 57.1% | 46.0% |
| GPT-4 | **77.8%** | **52.8%** | 79.8% | 66.7% | 70.4% | 55.8% | 75.0% | 60.6% |
| GPT-4o | 66.7% | **52.8%** | **85.4%** | **70.6%** | **79.6%** | **59.8%** | **81.6%** | **64.4%** |
| Gemini 1.5 Flash | 44.4% | 32.2% | 79.8% | 64.6% | 67.3% | 49.3% | 71.9% | 55.4% |
| Gemini 1.5 Pro | 22.2% | 19.4% | 77.5% | 62.6% | 60.2% | 46.2% | 66.3% | 52.4% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì˜ êµì§‘í•© ë¶€ë¶„ì§‘í•©ì— ëŒ€í•œ ì¬í˜„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama ê²°ê³¼ì˜ êµì§‘í•© í†µê³„ê°€ ì œí•œì ì´ê¸° ë•Œë¬¸ì— Llama ê²°ê³¼ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³ ë ¤ëœ êµì§‘í•© ë¶€ë¶„ì§‘í•©ì˜ ì´ ì‚¬ë¡€ ìˆ˜ëŠ” 196ê°œì…ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ LLM ëª¨ë¸(GPT-3.5, GPT-4, GPT-40, Gemini 1.5 Flash, Gemini 1.5 Pro)ì— ëŒ€í•´,  'ëª…ì‹œì  ë‹¨ì„œ', 'ì•”ì‹œì  ë‹¨ì„œ', 'ì°¸ê°€' ë“±ì˜ ì„¸ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê·¸ë¦¬ê³  ì „ì²´ì ìœ¼ë¡œ  'ëŠìŠ¨í•œ ì¬í˜„ìœ¨'ê³¼ 'ì—„ê²©í•œ ì¬í˜„ìœ¨'ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ëŠìŠ¨í•œ ì¬í˜„ìœ¨ì€ ì ì–´ë„ í•˜ë‚˜ì˜ ì£¼ìš” ì§€ì ì´ ì–¸ê¸‰ë˜ë©´ 1ì´ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì…ë‹ˆë‹¤. ì—„ê²©í•œ ì¬í˜„ìœ¨ì€ ì‹¤ì œ ë°˜ì‘ì˜ ì£¼ìš” ì§€ì  ì¤‘ ìƒì„±ëœ ì‘ë‹µì— í¬í•¨ëœ ë¹„ìœ¨ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ LLMì´ íšŒì˜ ì°¸ê°€ì ì—­í• ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€, ì¦‰ íšŒì˜ ë‚´ìš©ì˜ ì£¼ìš” ì§€ì ì„ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ìƒì„±í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Recall Rate for Intersection Subset of Matched Dataset. Note that due to limited statistics for intersecting Llama results, Llama results are not included. The total number of cases in the considered Intersection Subset is 196.
> </details>

{{< table-caption >}}
| Metric | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---| 
| Chime In |  |  |  |  |  |  |  |
| Expected Response | 18.4% | 27.0% | **42.2%** | 25.3% | 35.2% | 25.4% | 27.4% |
| Input Context Info | 37.2% | 43.0% | 37.9% | 39.2% | 26.3% | 39.6% | 31.4% |
| Previous Transcript | 33.7% | 25.1% | **15.9%** | 28.6% | 28.1% | 31.6% | 32.4% |
| Hallucination | 10.8% | 4.93% | 4.05% | 6.93% | 10.4% | **3.43%** | 8.75% |
| Explicit Cue |  |  |  |  |  |  |  |
| Expected Response | 32.5% | 50.1% | 51.0% | 52.4% | **61.1%** | 31.9% | 50.1% |
| Input Context Info | 40.4% | 31.6% | 38.1% | 27.0% | 26.3% | 36.8% | 28.3% |
| Previous Transcript | 20.8% | 12.4% | **7.28%** | 14.4% | 9.25% | 25.4% | 16.8% |
| Hallucination | 6.43% | 5.98% | 3.58% | 6.24% | **3.35%** | 5.82% | 4.81% |
| Implicit Cue |  |  |  |  |  |  |  |
| Expected Response | 25.2% | 39.9% | 38.9% | 38.0% | **46.8%** | 28.2% | 38.9% |
| Input Context Info | 39.9% | 39.9% | 45.9% | 34.2% | 32.0% | 34.3% | 34.1% |
| Previous Transcript | 31.9% | 15.0% | **11.3%** | 22.4% | 14.8% | 35.7% | 22.6% |
| Hallucination | 2.96% | 5.12% | 3.8% | 5.48% | 6.32% | **1.80%** | 4.38% |
| All |  |  |  |  |  |  |  |
| Expected Response | 26.9% | 42.8% | 43.9% | 41.5% | **51.6%** | 29.1% | 41.2% |
| Input Context Info | 39.8% | 36.9% | 42.0% | 32.3% | 29.2% | 35.8% | 31.8% |
| Previous Transcript | 28.4% | 14.8% | **10.3%** | 20.3% | 13.8% | 31.6% | 21.9% |
| Hallucination | 4.95% | 5.44% | 3.74% | 5.91% | 5.48% | **3.39%** | 5.09% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì— ëŒ€í•œ ê·€ì† ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜ˆìƒ ì‘ë‹µ ì§€í‘œì˜ ê²½ìš° ê°’ì´ ë†’ì„ìˆ˜ë¡ ì¢‹ê³ , ì´ì „ ì „ì‚¬ ë° í™˜ê° ì§€í‘œì˜ ê²½ìš° ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ê° ëª¨ë¸(GPT-3.5, GPT-4, GPT-40, Gemini 1.5 Flash, Gemini 1.5 Pro, Llama3-8B, Llama3-70B)ì— ëŒ€í•´ ì„¸ ê°€ì§€ ë²”ì£¼(ì¼ì¹˜, ëª…ì‹œì  ë‹¨ì„œ, ì•”ì‹œì  ë‹¨ì„œ)ë³„ë¡œ ì˜ˆìƒ ì‘ë‹µ, ì»¨í…ìŠ¤íŠ¸ ì •ë³´, ì´ì „ ì „ì‚¬, í™˜ê°ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•  ë•Œ ë°ì´í„°ì…‹ì˜ ì–´ë–¤ ë¶€ë¶„ì— ë” ë§ì´ ì˜ì¡´í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  í™˜ê°ì„ ì–¼ë§ˆë‚˜ ìƒì„±í•˜ëŠ”ì§€ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Attribution Analysis results for Matched Dataset. For the Expected Response metric, higher values are better, while for the Previous Transcript and Hallucination metrics, lower values are preferable.
> </details>

{{< table-caption >}}
| Metric | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro |
|---|---|---|---|---|---| 
| Chime In |  |  |  |  |  |
| Expected Response | 22.0% | 30.9% | **35.8** | 29.2% | 22.2% |
| Input Context Info | 55.7% | 58.1% | 64.2% | 45.8% | 22.2% |
| Previous Transcript | 11.1% | 5.0% | **0.0%** | 12.5% | 44.4% |
| Hallucination | 11.1% | 5.9% | **0.0%** | 12.5% | 11.1% |
| Explicit Cue |  |  |  |  |  |
| Expected Response | 37.4% | 59.1% | 56.1% | 59.9% | **66.9%** |
| Input Context Info | 37.9% | 27.7% | 36.4% | 23.3% | 19.5% |
| Previous Transcript | 19.6% | 10.1% | **3.3%** | 11.7% | 12.5% |
| Hallucination | 5.1% | 5.98% | 3.1% | 5.1% | **1.2%** |
| Implicit Cue |  |  |  |  |  |
| Expected Response | 30.6% | 47.3% | 49.9% | 49.4% | **51.3%** |
| Input Context Info | 42.6% | 36.4% | 38.6% | 31.3% | 29.4% |
| Previous Transcript | 23.5% | 12.2% | **7.0%** | 17.6% | 12.1% |
| Hallucination | 3.3% | 4.0% | 4.5% | **1.7%** | 7.1% |
| All |  |  |  |  |  |
| Expected Response | 33.3% | 51.8% | 52.1% | 53.4% | **57.0%** |
| Input Context Info | 41.1% | 33.5% | 38.8% | 28.2% | 24.5% |
| Previous Transcript | 21.2% | 10.9% | **5.0%** | 14.7% | 13.8% |
| Hallucination | 4.5% | **3.7%** | 4.1% | **3.7%** | 4.6% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ì…‹ì˜ êµì§‘í•©ì— ëŒ€í•œ ê·€ì† ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜ˆìƒ ì‘ë‹µ ì§€í‘œì˜ ê²½ìš° ê°’ì´ ë†’ì„ìˆ˜ë¡ ì¢‹ê³ , ì´ì „ ì „ì‚¬ ë° í™˜ê° ì§€í‘œì˜ ê²½ìš° ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. Llama ê²°ê³¼ì˜ í†µê³„ê°€ ì œí•œì ì´ê¸° ë•Œë¬¸ì— Llama ê²°ê³¼ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³ ë ¤ëœ êµì§‘í•© í•˜ìœ„ ë°ì´í„°ì…‹ì˜ ì´ ì‚¬ë¡€ ìˆ˜ëŠ” 196ê±´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Attribution Analysis results for Intersection Subset of Matched Dataset. For the Expected Response metric, higher values are better, while for the Previous Transcript and Hallucination metrics, lower values are preferable. Note that due to limited statistics for the intersecting Llama results, Llama results are not included. The total number of cases in the considered Intersection Subset is 196.
> </details>

{{< table-caption >}}
| Type | Dataset | GPT-3.5 | GPT-4 | GPT-4o | Gemini 1.5 Flash | Gemini 1.5 Pro | Llama3-8B | Llama3-70B |
|---|---|---|---|---|---|---|---|---|
| Explicit Cue | Matched | 53.2% | 86.7% | 94.3% | 89.7% | 78.3% | 91.2% | **99.4%** |
| Explicit Cue | Noisy Name | 52.5% | 53.3% | 68.0% | 60.7% | 59.8% | 79.4% | **87.0%** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Noisy Name ë°ì´í„°ì…‹ì—ì„œ ê° ì–¸ì–´ ëª¨ë¸ì˜ ì‘ë‹µë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Noisy Name ë°ì´í„°ì…‹ì€ ì‹¤ì œ íšŒì˜ë¡ì— ì¡´ì¬í•˜ëŠ” ì „ì‚¬ ì˜¤ë¥˜ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ ì°¸ê°€ì ì´ë¦„ì„ ìŒì†Œì ìœ¼ë¡œ ìœ ì‚¬í•œ ë‹¨ì–´ë¡œ ë³€ê²½í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.  í‘œëŠ” ê° ëª¨ë¸ì˜ ì‘ë‹µë¥ ì„ 'ëª…ì‹œì  ë‹¨ì„œ', 'ì•”ì‹œì  ë‹¨ì„œ', ì „ì²´ì˜ ì„¸ ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆ„ì–´ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ì „ì‚¬ ì˜¤ë¥˜ê°€ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Response rate for Noisy Name Dataset.
> </details>

{{< table-caption >}}
| Metric | Chime In | Explicit Cue | Implicit Cue | All |
|---|---|---|---|---|
| Response Rate | 59.1% | 90.4% | 78.7% | 80.2% |
| Loose Recall | 46.2% | 82.6% | 75.0% | 74.7% |
| Strict Recall | 37.7% | 65.0% | 50.2% | 55.8% |
| Expected Response | 21.0% | 44.1% | 44.7% | 41.1% |
| Input Context Info | 57.2% | 36.0% | 31.9% | 37.3% |
| Previous Transcript | 14.1% | 14.4% | 14.0% | 14.2% |
| Hallucination | 7.7% | 5.4% | 9.4% | 7.3% |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” GPT-40 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, ë¬¸ë§¥ ì •ë³´ ì—†ì´(No-<Context>) ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ëŠ¥ë ¥ì„ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. GPT-40 ëª¨ë¸ì˜ ì‘ë‹µë¥ , ì¬í˜„ìœ¨(ì •ë°€ë„), ê¸°ëŒ€ ì‘ë‹µë¥ , ë¬¸ë§¥ ì •ë³´ í™œìš©ë¥ , ì´ì „ ë°œí™” í™œìš©ë¥ , ê·¸ë¦¬ê³  ì˜ëª»ëœ ì •ë³´ ìƒì„±ë¥  ë“± ë‹¤ì–‘í•œ ì§€í‘œë¥¼ 'Chime In', 'Explicit Cue', 'Implicit Cue' ì„¸ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ ê°ê° ì œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ GPT-40 ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: All Evaluation Metrics for GPT-4o in No-<Context> Scenario.
> </details>

{{< table-caption >}}
| Dataset | Scenarios | Error Type | Solution Direction |
|---|---|---|---|
| Matched | Chime In | Decision based on wrong latest utterance | Improved Instruction Following |
|  |  | Identify as cue to others or all participants | Enhanced Reasoning in Meeting Scenario |
|  |  | Missing the need for proactive participation | Enhanced Reasoning in Meeting Scenario |
|  |  | Decision made due to â€œConversation is still going, I canâ€™t interruptâ€ | Enhanced Reasoning in Meeting Scenario |
|  |  | Unable to find the related context | Enhanced General Reasoning |
|  |  | Other | N/A |
| Explicit Cue | Decision based on wrong latest utterance | Improved Instruction Following |
|  | Correctly recognizes the cue but does not respond | Enhanced Reasoning in Meeting Scenario |
|  | Ambiguity due to multiple names in a single utterance or long context | Enhanced Reasoning in Meeting Scenario |
|  | Fails to recognize the cue | Enhanced General Reasoning |
|  | Hallucination | Enhanced General Reasoning |
|  | Other | N/A |
| Mismatched | Mismatched | Decision based on wrong latest utterance | Improved Instruction Following |
|  |  | Latest utterance related to provided information | Enhanced Reasoning in Meeting Scenario |
|  |  | Failure to recognize cues directed to others | Enhanced Reasoning |
|  |  | Hallucination | Enhanced General Reasoning |
|  |  | Other | N/A |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Response Rate ì‹¤íŒ¨ ì‚¬ë¡€ ì—°êµ¬ì— ëŒ€í•œ ì˜¤ë¥˜ ìœ í˜•ê³¼ í•´ê²° ë°©í–¥ ê°„ì˜ ë§¤í•‘ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Response RateëŠ” ëª¨ë¸ì´ ì ì ˆí•œ ì‹œì ì— ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤.  í‘œëŠ” ì‹¤íŒ¨ ì‚¬ë¡€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜¤ë¥˜ ìœ í˜•ì„ ë¶„ë¥˜í•˜ê³ , ê° ìœ í˜•ì— ëŒ€í•œ ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'Explicit Cue' ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëª¨ë¸ì´ íë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‹ë³„í•˜ì§€ë§Œ ì‘ë‹µí•˜ì§€ ì•ŠëŠ” ê²½ìš°, ì´ëŠ” íšŒì˜ ìƒí™©ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì´ í•„ìš”í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  í‘œëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ êµ¬ì²´ì ì¸ ë°©í–¥ì„ ì œì‹œí•¨ìœ¼ë¡œì¨,  LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ì‹¤ì§ˆì ì¸ ê°œì„ ì— ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: Mapping between Error Types and Solution Direction for Response Rate Failure Cases Study.
> </details>

{{< table-caption >}}
| Model Name | Model Use Scenarios | Model Version |
|---|---|---|
| GPT-3.5 | Generate Response (Table 2 & Table 3 & Table 4 & Table 5, Prompt in Table 14) | gpt-3.5-turbo-1106 with 16k context window |
| GPT-4 | Generate Response (Table 2 & Table 3 & Table 4 & Table 5, Prompt in Table 14) | gpt-4-turbo-20240409 with 128k context window |
|  | Evaluation (Table 6 & Table 7, Prompt in Table 17) | gpt-4-1106-preview with 128k context window |
|  | Attribution (Table 8 & Table 9, Prompt in Table 19) | gpt-4-turbo-20240409 with 128k context window |
|  | Extract context information (Figure 8, Prompt in Table 21) |  |
|  | Extract test cases (Figure 8, Prompt in Table 27) |  |
| GPT-4o | Generate Response (Table 2 & Table 3 & Table 4 & Table 5, Prompt in Table 14) | gpt-4o-20240513-preview with 128k context window |{{< /table-caption >}}
> ğŸ”¼ í‘œ 13ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ì–¸ì–´ ëª¨ë¸ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë¸ ì´ë¦„, ëª¨ë¸ ë²„ì „, ëª¨ë¸ì´ ì‚¬ìš©ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.  ì´ëŠ” ì‹¤í—˜ì˜ ì¬í˜„ì„±ê³¼ íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ê° ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì‚¬ìš© ëª©ì ì„ ëª…í™•íˆ í•¨ìœ¼ë¡œì¨ ë…ìê°€ ì—°êµ¬ ê²°ê³¼ë¥¼ ë” ì˜ ì´í•´í•˜ê³  í•´ì„í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Details of Model Use Scenarios and Model Version.
> </details>

{{< table-caption >}}
| - You are a Meeting Delegate Agent that attends meetings on behalf of <Person Name>.
| - You are provided with the intent of participating in the meeting, specified as <Intents>.
| - You are provided with the background information that <Person Name> knows, specified as <Background>.
| - You are provided with the full list of attendees <Attendees> to help identify if someone cues you.
| - You are provided with the ongoing meeting transcript <Meeting Transcript> to determine if there is a need to respond.
| - Your task is to assess the content of the ongoing meeting transcript <Meeting Transcript> and determine whether you are can speak and what to say.
| - You are encouraged to respond and ask questions, give comments, or share information without interrupting others in the meeting.
| ## About the <Person Name>
| - <Person Name> is the name of the person you represent in the meeting.
| - People in the <Attendees> list may cue you by using <Person Name> exactly or parts of the name (e.g., first name, initials).
| ## About the <Attendees>
| - <Attendees> is a list of names of the people attending the meeting.
| - Each name in the list is a full name or a nickname.
| ## About the <Meeting Transcript>
| - <Meeting Transcript> is a series of utterances spoken by the meeting participants.
| - Each utterance is formatted as "Name: Content", where â€™Nameâ€™ is the speakerâ€™s name and â€™Contentâ€™ is their spoken text.
| - The utterances are in chronological order and the latest utterance is at the bottom of the transcript.
| - The utterances may contain typos and grammatical errors.
| ## About the <Intents>
| - <Intents> consists of the questions or topics that <Person Name> aims to discuss during the meeting.
| - You can ask the questions or motivate the discussion of the topics in the <Intents> at the appropriate time without interrupting others.
| ## About the <Background>
| - <Background> consists of the background information that <Person Name> knows before the meeting.
| - <Background> is a list of "Context" and "Information" pairs. You can share the "Information" in the "Context" at the appropriate time without interrupting others.
| ## Guidelines to judge whether you can speak and decide what to say
| - Read the <Meeting Transcript> to understand the context of the meeting.
| - Focus on the latest several utterances in the <Meeting Transcript> to understand the current discussion.
| - Remember that you are a delegate attending the meeting on behalf of <Person Name>.
| - You should judge whether you can speak first, then decide what to say, if you can speak.
| - Judge whether you can speak according to the following instructions:
|     - Figure out what the latest utterance (at the bottom of the <Meeting Transcript>) is about and pay attention to who is being addressed.
|     - If the latest utterance is a straightforward question or request or instructions to other participants, you MUST NOT speak to avoid interrupting others, even if the conversation is related to the <Intents> or <Background>.
|     - If the latest utterance is for the <Person Name>, you should respond to it.
|     - If you can speak, consider the following guidelines:
|     - Your speech content should be directly relevant to the current discussion.
|     - You can reference the <Intents> and <Background> to organize your speech.
|     - You should be polite and natural in your speech.
|     - You MUST NOT make up facts.
|     - You MUST NOT repeat what <Person Name> has said in the <Meeting Transcript>.
|     - Chit chat is a natural part of conversation. You can engage in chit chat with other attendees if it is appropriate or relevant to the meeting context. For example, you can say good morning, Thank you, Yeah, I agree.
|     - Before speaking, you should think twice to ensure that you are not interrupting others and your speech is relevant to the current discussion.
| ## Notes on judging whether someone is cued
| - The name may be transcribed as similar-sounding words by the speech recognition system. Especially, the pronunciation of Chinese names may be recognized as similar-sounding English words, for exmaple, "Si Li" may be transcribed as "Celine" or "silence".
| - When encountering words that seem out of place, it is likely due to errors in speech recognition. Examine the list of attendees to determine if the pronunciation of these words are similar to any English or Chinese names listed.
| - You should consider the context of the meeting and the names of the attendees to determine if you or someone are cued.
| <span class="ltx_text ltx_font_bold">CONTINUE ON THE NEXT PAGE</span>{{< /table-caption >}}
> ğŸ”¼ ë³¸ ë…¼ë¬¸ì˜ í‘œ 14ëŠ” íšŒì˜ ì°¸ì—¬ ëª¨ë“ˆì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì´ íšŒì˜ì— ì°¸ì—¬í•˜ì—¬ ì ì ˆí•œ ì‹œì ì— ì ì ˆí•œ ë°œì–¸ì„ í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” ì°¸ê°€ìì˜ ì—­í• , íšŒì˜ ëª©í‘œ, ê´€ë ¨ ë°°ê²½ ì§€ì‹, ê·¸ë¦¬ê³  ì§„í–‰ ì¤‘ì¸ íšŒì˜ ë‚´ìš© ë“± ë‹¤ì–‘í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, LLMì´  ìƒí™©ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤.  ë˜í•œ,  ë¶€ì ì ˆí•œ ê°œì…ì„ í”¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ëŠ” ë°©ë²• ë“±ì„ ëª…ì‹œì ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Prompt used for generating response in the Meeting Engagement module.
> </details>

{{< table-caption >}}
| The output of response <Response> | - The response should be a dictionary with the following format: 

```
{
    "thoughts": "<thoughts>",
    "speak": "<speak>"
}
```
- <thoughts>: The reasoning or considerations to judge whether you can speak and decide what to say. At the beginning, you should state who you are representing. Then <thoughts> should explain what the latest utterance is about and then explain why you can or cannot speak. If you can speak, you should also explain how you decide what to say. | - <speak>: The content you are going to speak. If you are not allowed to speak or you do not want to speak, the <speak> is empty. | ## Example 

```
- Example 1:
Below is an example of that pronunciations of Chinese names may be recognized as similar-sounding English words by the speech recognition system.
<Person Name>
'Sirui Zhao'
<Attendees>
[
    - 'San Zhang',
    - 'Si Li',
    - 'Sirui Zhao'
]
<Meeting Transcript>
Si Li: Good morning.
Sirui Zhao: Hello!
San Zhang: Hi!
Si Li: OK, Let's start our meeting. There are still some people who haven't joined, so let's start first. Our topic today is the progress of environmental protection, three, do you have some thing to share on it?
<Intents>
[
    - 'The extent of plastic misuse'
]
<Background>
[
    {
        "Context":"Discussion about reducing air pollution",
        "Information":"The air pollution of our city is becoming serious. The goverment takes extreme measures to control the pollution by closing the factory and limiting the use private car."
    }
]
<Response>
{
    - "thoughts": "I'm representing Sirui Zhao in the meeting. In the last utterance, the appearance of 'three' is abrupt. Contextually, there is no need for numbers; phonetically, "Three" sounds like "Sirui", which closely resembles 'Sirui' from the attendees, specifically <Person Name>. The speaker is most likely asking Sirui Zhao to share something on the progress of environment protection. So I need to give response. And based on the background information, I can share something about reduing air pollution.",
    - "speak": "Yes. The air pollution of our city is becoming serious. The goverment takes extreme measures to control the pollution by closing the factory and limiting the use private car."
}
```
| CONTINUE ON THE NEXT PAGE |{{< /table-caption >}}
> ğŸ”¼ í‘œ 15ëŠ” ë…¼ë¬¸ì˜ 'ë¯¸íŒ… ì°¸ì—¬ ëª¨ë“ˆì—ì„œ ì‘ë‹µ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸' ì„¹ì…˜ì— ìˆëŠ” í‘œì˜ ê³„ì†ì…ë‹ˆë‹¤. ì´ í‘œëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ë¯¸íŒ… ëŒ€ë¦¬ ì‹œìŠ¤í…œì˜ ë¯¸íŒ… ì°¸ì—¬ ëª¨ë“ˆì—ì„œ LLMì´ ë¯¸íŒ…ì— ì°¸ì—¬í•˜ëŠ” ë°©ì‹ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìì„¸íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” ë¯¸íŒ… ëŒ€ë¦¬ì¸ì˜ ì—­í• , ë¯¸íŒ… ì°¸ê°€ìì™€ ê³µìœ í•  ì •ë³´, ë¯¸íŒ…ì˜ ëª©í‘œ ë“±ì„ ëª…ì‹œí•˜ê³ , LLMì´ ì ì ˆí•œ ì‹œì ì— ê°œì…í•˜ì—¬ ê´€ë ¨ì„± ìˆëŠ” ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.  ì¦‰,  LLMì´ ë¯¸íŒ… ëŒ€ë¦¬ì¸ìœ¼ë¡œì„œ ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•˜ê²Œ ëŒ€í™”ì— ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì§€ì¹¨ì„ ì œê³µí•˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì„¸ë¶€ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 15: Prompt used for generating response in the Meeting Engagement module (continued).
> </details>

{{< table-caption >}}
| - Example 2: Below is an example of that you should not speak since the latest utterance is a straightforward question or request or instructions to other participants. | <Person Name> | 'Frank' | <Attendees> | - 'John', - 'James', - 'Alice', - 'Bob' - 'Frank'| <Meeting Transcript> | Bob: James, that price is too high, we can not accept it. James: Ok, I will contact the supplier again and discuss the price. John: Thank you, James. John: OK, Let's go to the next topic. Alice, what is your progress on the project development? | <Intents> | - 'Whether Bob fixed the bug I reported' | <Background> | { "Context":"Report on the dataset preparation progress", "Information":"The dataset preparation is almost done. We are now working on the data cleaning and normalization. We expect to finish it by the end of the week."} | <Response> | - "thoughts": "I am representing Frank in the meeting. In the latest utterance, John is explicitly asking Alice about the project development. I can not speak.", - "speak": "" | - You are representing <Person Name> in the meeting. You should respond to the cues from the attendees and the context of the meeting. | - You should not interrupt others in the meeting. |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ë…¼ë¬¸ì˜ '3. LLM ê¸°ë°˜ íšŒì˜ ìœ„ì„ ì‹œìŠ¤í…œ' ì„¹ì…˜ì— í¬í•¨ëœ í‘œ 16ì…ë‹ˆë‹¤. í‘œ 16ì€ íšŒì˜ ì°¸ì—¬ ëª¨ë“ˆì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ì´ë©°,  <Person Name>, <Attendees>, <Meeting Transcript>, <Intents>, <Background> ì™€ ê°™ì€ ë³€ìˆ˜ë“¤ì„ í¬í•¨í•˜ì—¬ LLMì´ íšŒì˜ì— ì°¸ì—¬í•˜ëŠ” ì—­í• ì„ ë” ì˜ ì´í•´í•˜ê³  ì ì ˆí•œ ì‹œì ì— ê°œì…í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•˜ëŠ” ì§€ì¹¨ê³¼ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. í‘œì˜ ìº¡ì…˜ì€ ë‚´ìš©ì„ ì¶©ë¶„íˆ ì„¤ëª…í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë” ìì„¸í•œ ì„¤ëª…ì€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 16: Prompt used for generating response in the Meeting Engagement module (continued).
> </details>

{{< table-caption >}}
## Evaluation Guidelines for Meeting AI Assistant

| Point | Description |
|---|---| 
| **Role** | You are an Evaluation Agent assessing the meeting AI assistant's response against a standard answer. |
| **Provided Information** | You'll receive the standard answer summary and the AI assistant's raw response. |
| **Task** | Summarize the AI assistant's response's main points, comparing them to the standard answer's main points. |
| **About the AI Assistant** | Designed to represent the user in meetings. |
| **About the Standard Answer** | A list of strings representing the main points of the ground truth response. |
| **About the Actual Response** | The AI assistant's string response to the meeting content.  Reference the transcript for context. |
| **Evaluation Guidelines** | Compare main points in the standard and actual responses. Summarize the actual response's main points at the same granularity as the standard answer. Omit uninformative politeness or pleasantries (e.g., "If you need more help, please let me know."). |
| **Matching Main Points** |  Identify semantically similar main points between the actual and standard responses.  Create a list showing the index of each matching point in the actual response relative to the standard answer's main point order (e.g., if the first main point in the actual response matches the second in the standard answer, list the index '2'). If there is no match, use '-1'.|
| **Metrics** | Count the number of main points in the actual response (ActualMainPointsCount) and the number of matching points (MatchingMainPointsCount). |
| **Output Format** | JSON format, including explanation of steps, actual main points, counts, matching main points, matching indices, and the number of matching main points. If the actual response is empty, all counts should be 0.  Maintain the same length of MatchingIndex as the ActualMainPointsCount. |
| **Example Matching Indices** | If ActualMainPointsCount is 5, the MatchingIndex might be [1, 2, -1, -1, 4], showing that the first, second, and fifth main points of the actual response match points 1, 2, and 4 in the standard answer respectively, while the third and fourth do not match any. |{{< /table-caption >}}
> ğŸ”¼ í‘œ 17ì€ ìƒì„±ëœ ì‘ë‹µì´ ì‹¤ì œ ì‘ë‹µê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í”„ë¡¬í”„íŠ¸ëŠ” í‰ê°€ìì—ê²Œ ìƒì„±ëœ ì‘ë‹µì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ìƒì„±ëœ ì‘ë‹µì˜ ì£¼ìš” ë‚´ìš©ì´ ì‹¤ì œ ì‘ë‹µì˜ ì£¼ìš” ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.  ì¼ì¹˜ ì—¬ë¶€ íŒë‹¨ ì‹œ,  ì˜ë¯¸ìƒ ìœ ì‚¬í•œ ë‚´ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ê³ , ë‹¨ìˆœí•œ ì¸ì‚¬ë§ì´ë‚˜ ì •ì¤‘í•œ í‘œí˜„ì€ ì£¼ìš” ë‚´ìš©ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.  ì¶œë ¥ í˜•ì‹ì€ JSONìœ¼ë¡œ,  ì‹¤ì œ ì‘ë‹µì˜ ì£¼ìš” ë‚´ìš© ê°œìˆ˜,  ì¼ì¹˜í•˜ëŠ” ì£¼ìš” ë‚´ìš© ê°œìˆ˜,  ì¬í˜„ìœ¨,  ì •ë°€ë„ ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 17: Prompt used for evaluating the generated response against the ground-truth one.
> </details>

{{< table-caption >}}
## Example 1

| StandardAnswer | ActualResponse | Explanation | ActualMainPoints | ActualMainPointsCount | MatchingMainPoints | MatchingIndex | MatchingMainPointsCount |
|---|---|---|---|---|---|---|---| 
| ["Calculated word error rate on Czech transcripts", "Conducted testing sessions with PERSON11 and PERSON18", "Contributed to the PROJECT3 deliverable", "Waiting for new tasks"] | "Hi everyone. Over the past week, I calculated the word error rate on Czech transcripts using three versions of Czech ASR created by PERSON10. I also conducted a few testing sessions with PERSON11 and PERSON18, but they were not successful due to issues with the segmenters from ORGANIZATION1. I have updated the German transcripts in its corresponding path. I also backed up all the systems, including some new ones created today and last week. For the next week, I am waiting for new tasks. By the way, do we have the golden transcripts for the English videos?" | First, summarize the main points in the <ActualResponse>. The <ActualResponse> has the following main points: 1. Calculated word error rate on Czech transcripts. 2. Conducted testing sessions with PERSON11 and PERSON18. 3. Updated German transcripts in its corresponding path. 4. Backed up all the systems. 5. Waiting for new tasks. 6. Ask about the golden transcripts for the English videos. So, the number of main points in the <ActualResponse> is 6 and the length of the MatchingIndex is 6. Sencond, compare the main points in the <ActualResponse> with the main points in the <StandardAnswer>. The matching main points between the <ActualResponse> and the <StandardAnswer> are: 1. Calculated word error rate on Czech transcripts. This point mahes with the first point in the <StandardAnswer>. 2. Conducted testing sessions with PERSON11 and PERSON18. This point matches with the second point in the <StandardAnswer>. 3. Waiting for new tasks. This point matches with the fourth point in the <StandardAnswer>. The number of matching main points between the <ActualResponse> and the <StandardAnswer> is 3. The other points in the <ActualResponse> do not match points in the <StandardAnswer>. | ["Calculated word error rate on Czech transcripts", "Conducted testing sessions with PERSON11 and PERSON18", "Updated German transcripts in its corresponding path", "Backed up all the systems", "Waiting for new tasks", "Ask about the golden transcripts for the English videos"] | 6 | ["Calculated word error rate on Czech transcripts", "Conducted testing sessions with PERSON11 and PERSON18", "Waiting for new tasks"] | [1,2,-1,-1,4,-1] | 3 |

## Example 2

| StandardAnswer | ActualResponse | Explanation | ActualMainPoints | ActualMainPointsCount | MatchingMainPoints | MatchingIndex | MatchingMainPointsCount |
|---|---|---|---|---|---|---|---| 
| ["Confirm the task about writing a report about the calculation and share it with others", "Synthesize the information other team members have shared", "Wait for the next task"] | "Sure, I will finish the calculation. I will also write a report about the calculation." | First, summarize the main points in the <ActualResponse>. The <ActualResponse> has the following main points: 1. Confirm the task about finishing the calculation and writing a report about it. The number of main points in the <ActualResponse> is 1 and the length of the MatchingIndex is 1. Sencond, compare the main points in the <ActualResponse> with the main points in the <StandardAnswer>. The matching main points between the <ActualResponse> and the <StandardAnswer> contains: 1. Confirm the task about finishing the calculation and writing a report about it. This point matches with the first point in the <StandardAnswer>. The number of matching main points between the <ActualResponse> and the <StandardAnswer> is 1. The other points in the <ActualResponse> do not match points in the <StandardAnswer>. | ["Confirm the task about finishing the calculation and writing a report about it"] | 1 | ["Confirm the task about finishing the calculation and writing a report about it"] | [1] | 1 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 18ì€ ìƒì„±ëœ ì‘ë‹µì„ ì‹¤ì œ ì‘ë‹µê³¼ ë¹„êµí•˜ì—¬ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ë³¸ ë…¼ë¬¸ì˜ 4ì¥(Benchmark Dataset)ì— ì†í•˜ë©°, ì‹¤ì œ ì‘ë‹µê³¼ ì§€ìƒ ì§„ì‹¤ ì‘ë‹µ ê°„ì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì„¸ë¶€ì ì¸ ì§€ì¹¨ê³¼ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 18: Prompt used for evaluating the generated response against the ground-truth one (continued).
> </details>

{{< table-caption >}}
|---|---|---|---|
| You are an Attribution Agent responsible for assessing the response generated by a meeting AI assistant and determining its source. |  |  |  |
| You are provided with the list of <ActualResponse>. |  |  |  |
| You are also provided with the transcript of the meeting content (<Transcript>) and the <ContextInfo> used to generate the <ActualResponse>. |  |  |  |
| Your task is to attribute the <ActualResponse> to the corresponding part of the <Transcript> or the <ContextInfo>. |  |  |  |
| About the <ActualResponse> |  |  |  |
| The <ActualResponse> is a list that represents the response generated by the meeting AI assistant. |  |  |  |
| About the <StandardResponse> |  |  |  |
| The <StandardResponse> is a list that represents the expected response. |  |  |  |
| The <StandardResponse> may be the same as <ActualResponse>, or it may not be. |  |  |  |
| About the <Transcript> |  |  |  |
| The transcript are the collection of utterances from the meeting participants. |  |  |  |
| Each utterance is formatted as "Name: Content", where â€™Nameâ€™ is the speakerâ€™s name and â€™Contentâ€™ is their spoken text. |  |  |  |
| Utterances are in chronological order and may contain typos and grammatical errors. |  |  |  |
| The transcript ends at the time stamp when the meeting AI assistant should generate the response. |  |  |  |
| Example utterances: |  |  |  |
| PERSON1: Hello everyone, Iâ€™m glad to see you all here today. (id=0) |  |  |  |
| About the <ContextInfo> |  |  |  |
| <ContextInfo> is a dictionary that contains <Intents> and <Background>. |  |  |  |
| <Intents> consists of the questions or topics that can generate the <ActualResponse>. |  |  |  |
| <Background> is a list of "Context" and "Information" pairs. For each pair, "Information" can be shared in the "Context" situation to generate the <ActualResponse>. And each pair can be used many times. |  |  |  |
| Guidelines for Attribution |  |  |  |
| You need to decide whether the main points in the <ActualResponse> match the <StandardResponse>. |  |  |  |
| The number of main points in the <ActualResponse> is not fixed. PointID is used to identify the main points in the <ActualResponse>. |  |  |  |
| When assessing whether the main points in the <ActualResponse> originate from the <Transcript> or the <ContextInfo>, consider the following: |  |  |  |
| 1. If the main point has a similar or the same meaning as the <ContextInfo>. You should consider it as originating from the <ContextInfo>. |  |  |  |
| 2. If the main point explicitly repeats or closely relates to any point already mentioned in the <Transcript>. However, casual interactions such as greetings or small talk are permissible and not regarded as sourced from the <Transcript>."" |  |  |  |
| There are four situations for the origin of the main points in the <ActualResponse>: |  |  |  |
| 1. The main point in the <ActualResponse> can originate from the <ContextInfo> but is not present in the <Transcript>. You should append [PointID, 1, 0] to the AttributionList. |  |  |  |
| 2. The main point in the <ActualResponse> does not originate from the <ContextInfo> but originates from the <Transcript>. You should append [PointID, 0, 1] to the AttributionList. |  |  |  |
| 3. The main point in the <ActualResponse> can originate from both the <ContextInfo> and the <Transcript>. You should append [PointID, 1, 1] to the AttributionList. |  |  |  |
| 4. The main point in the <ActualResponse> does not originate from the <ContextInfo> and is not present in the <Transcript>. You should append [PointID, 0, 0] to the AttributionList. |  |  |  |
| Output Format |  |  |  |
| The output MUST be in the JSON format. |  |  |  |
| You MUST explain the process of attribution for every main point in the <ActualResponse>. |  |  |  |
| Note that AttributionList should only contain the List of lists and should not contain any additional information or annotations. |  |  |  |
| **CONTINUE ON THE NEXT PAGE** |  |  |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 19ëŠ” ìƒì„±ëœ ì‘ë‹µì˜ ì¶œì²˜ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” í‰ê°€ ì—ì´ì „íŠ¸ì—ê²Œ ì œê³µë˜ë©°, ìƒì„±ëœ ì‘ë‹µì„ í‰ê°€í•˜ê³ , í•´ë‹¹ ì‘ë‹µì˜ ì£¼ìš” ìš”ì ì´  <Transcript>(ëŒ€í™” ë‚´ìš©) ë˜ëŠ” <ContextInfo>(ë§¥ë½ ì •ë³´)ì—ì„œ ìœ ë˜í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” <ActualResponse>(ì‹¤ì œ ì‘ë‹µ), <StandardResponse>(í‘œì¤€ ì‘ë‹µ), <Transcript>(ëŒ€í™” ë‚´ìš©), <ContextInfo>(ë§¥ë½ ì •ë³´) ë“±ì˜ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, í‰ê°€ ì—ì´ì „íŠ¸ê°€ ê° ì£¼ìš” ìš”ì ì˜ ì¶œì²˜ë¥¼ íŒë‹¨í•˜ëŠ” ë° í•„ìš”í•œ ì§€ì¹¨ê³¼ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤. 
> <details>
> <summary>read the caption</summary>
> Table 19: Prompt used for the attribution of the generated response.
> </details>

{{< table-caption >}}
| - The output MUST include the following fields: | | 
|---|---| 
| - Explanation: For every main point in the <ActualResponse>, explain the process of attribution. Especially, explain why the main point matches or does not match the <StandardResponse> and why it originates from the <Transcript> or the <ContextInfo>. |  | 
| - AttributionList: A list of lists, where each list contains PointID and the attribution for a main point in the <ActualResponse>. |  | 
| - PointsCount: The number of main points in the <ActualResponse>. |  | 
| ## Example<br> <a download="" href="data:text/plain;base64,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{{< /table-caption >}}
> ğŸ”¼ í‘œ 20ì€ ìƒì„±ëœ ì‘ë‹µì˜ ì¶œì²˜ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•œ ì§€ì¹¨ì„ ì œê³µí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” í‰ê°€ ì—ì´ì „íŠ¸ê°€ AI ì¡°êµì˜ ì‘ë‹µì„ í‰ê°€í•˜ê³ , í•´ë‹¹ ì‘ë‹µì´ ëŒ€í™” ë‚´ìš©ì´ë‚˜ ì¶”ê°€ ì •ë³´ ì¤‘ ì–´ë””ì—ì„œ ìœ ë˜í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  í‰ê°€ ì—ì´ì „íŠ¸ëŠ” <ActualResponse>(ì‹¤ì œ ì‘ë‹µ), <Transcript>(ëŒ€í™” ë‚´ìš©), ê·¸ë¦¬ê³  <ContextInfo>(ìƒí™© ì •ë³´)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì˜ ì¶œì²˜ë¥¼ íŒë³„í•´ì•¼ í•©ë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ì—ëŠ” <StandardResponse>(í‘œì¤€ ì‘ë‹µ)ë„ í¬í•¨ë˜ì–´ ì‹¤ì œ ì‘ë‹µê³¼ì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  ì´ í‘œëŠ” <ActualResponse>ì˜ ì£¼ìš” ë‚´ìš©ì„ <Transcript>ì´ë‚˜ <ContextInfo> ì¤‘ ì–´ë””ì—ì„œ ê°€ì ¸ì™”ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ë°©ë²•ê³¼ ê·¸ ê²°ê³¼ë¥¼ í‘œê¸°í•˜ëŠ” í˜•ì‹ì— ëŒ€í•œ ìì„¸í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 20: Prompt used for the attribution of the generated response (continued).
> </details>

{{< table-caption >}}
|- Your task is to update the summary of the utterances of {participant} in a meeting transcript.|- You are provided with a <Transcript Snippet> that contains a portion of the meeting transcript.|- You are also provided with <Previous Summary> which contains the summary of utterances for {participant} in other parts of the meeting.|- You need to update the <Previous Summary> based on the utterances of the {participant} in the <Transcript Snippet>.|## On the provided <Transcript Snippet>|- Transcripts are the collection of utterances from the meeting participants.|- The transcript data is deidentified. Speakers and other named entities are not identified by names, but rather by IDs in the format ENTITYNUMBER (e.g. PERSON1 or PROJECT3) or just ENTITY (e.g. PATH).|- Speaker IDs at the beginning of transcript lines are enclosed in round brackets, all other deidentified entities in square brackets.|- Each utterence ends with "(id=x)", which is the utterance id, an increasing number from 0 to indicate the serial number of utterance in the whole meeting transcript.|- The provided transcript snippet maybe not start from the beginning of the meeting.|- Example utterances:|Â Â Â Â (PERSON1) Hello everyone, Iâ€™m glad to see you all here today. (id=0)|Â Â Â Â (PERSON2) Hi, Iâ€™m excited to be here. (id=1)|Â Â Â Â (PERSON3) Iâ€™m looking forward to the discussion. [PERSON1] mentioned that the project is going well. (id=2)|## On the <Previous Summary>|- The <Previous Summary> is a structured summary of the utterances of {participant} in the meeting transcript.|- The <Previous Summary> contains two parts, "wanted information" and "provided information".|Â Â Â Â - "wanted information" is a list of questions made by the {participant}.|Â Â Â Â - "provided information" is the information provided by the participant to others. It is a list of Context and Information pairs, where the "Context" is the context in which where the {participant} provides the "Information".|## Instructions on updating the <Previous Summary>|- Identify the utterances of {participant} in the <Transcript Snippet>.|- If {participant} does not speak in the <Transcript Snippet>, do NOT update the <Previous Summary>.|- Focus on only the informative utterances and ignore the greetings, appreciation, simple acknowledge and other chit chat.|- Extract the "wanted information" and "provided information" from the <Transcript Snippet>.|- You should try to use original utterances as much as possible after removing noise words and polishing them for better readability.|- The second or third personal pronoun (you, he, she, they) in the utterances should be properly replaced with the corresponding participantâ€™s ID to avoid ambiguity.|- Use the extracted information to update the <Previous Summary>.|- You can modify the existing "wanted information" and "provided information" or add new information, but do not remove any existing information.|- You MUST NOT mix the information provided by {participant} and other participants while updating the <Previous Summary>.|- You MUST NOT miss any important information provided by {participant} in the <Transcript Snippet>.|## Requirement on the output format|- You MUST explain your thoughts and steps of updating the <Previous Summary> before providing the updated summary.|- Output must be in Json format with the "Thoughts" and "Updated Summary" as the key.|- The "Thoughts" is your thoughts and steps of updating the <Previous Summary>.|- The "Updated Summary" contains the updated summary of the utterances for {participant}.|- <span class="ltx_text ltx_font_bold">CONTINUE ON THE NEXT PAGE</span>|{{< /table-caption >}}
> ğŸ”¼ ë³¸ ë…¼ë¬¸ì˜ í‘œ 21ì€ ì‹¤ì œ íšŒì˜ë¡ì—ì„œ ì°¸ê°€ìì˜ ë°œì–¸ ìš”ì•½ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì´ íšŒì˜ ë…¹ì·¨ë¡ì˜ ì¼ë¶€ë¥¼ í¬í•¨í•˜ëŠ” <Transcript Snippet>ê³¼ ì´ì „ì— ìš”ì•½ëœ ì°¸ê°€ì ë°œì–¸ ë‚´ìš©ì„ ë‹´ì€ <Previous Summary>ë¥¼ ì…ë ¥ë°›ì•„ <Previous Summary>ë¥¼ ì—…ë°ì´íŠ¸í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì´ <Transcript Snippet>ì—ì„œ ì°¸ê°€ìì˜ ë°œì–¸ì„ ì‹ë³„í•˜ê³ , ë‹¨ìˆœí•œ ì¸ì‚¬ë§ì´ë‚˜ ê°ì‚¬ í‘œì‹œ ë“±ì˜ ë¹„ì •ë³´ì„± ë°œì–¸ì„ ì œì™¸í•œ ì •ë³´ì„± ë°œì–¸ì„ ì¶”ì¶œí•˜ì—¬ <Previous Summary>ì— ì¶”ê°€í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ ì •ë³´ë¥¼ ì œê±°í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì°¸ê°€ìì˜ ì •ë³´ì™€ í˜¼í•©í•˜ì§€ ì•Šë„ë¡ ëª…ì‹œì ìœ¼ë¡œ ì§€ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.  ìš”ì•½ëœ ì •ë³´ëŠ” 'wanted information' ê³¼ 'provided information' ë‘ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê°ê° ì°¸ê°€ìê°€ ìš”ì²­í•œ ì •ë³´ì™€ ì œê³µí•œ ì •ë³´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 21: Prompt used for extracting context information.
> </details>

{{< table-caption >}}
## Example 1

- Here is an example of updating the utterances summary for PERSON2. You can refer to this example for better understanding.
- Suppose the transcript snippet contains the following utterances:
    (PERSON3) Good moring. (id=2)
    (PERSON1) Letâ€™s get started with todayâ€™s meeting on the recent progress of our software development project. Weâ€™ll go through updates from each team and discuss any blockers or issues. [PERSON2], could you start with the development updates?. (id=3)
    (PERSON2) Sure, [PERSON1]. Weâ€™ve made significant progress this sprint. We completed the implementation of the new authentication module and integrated it with our existing systems. (id=4)
    (PERSON1) Thatâ€™s great to hear, [PERSON2]. How about the feature for real-time notifications? Is it on track? (id=5)
    (PERSON2) Yes, it is. Weâ€™re about 75% done with it. The core functionality is in place, and we are now working on optimizing the delivery speed and ensuring it works seamlessly across different devices. (id=6)
- Suppose the previous summary of PERSON2 contains the following information:
    ```json
    {
      "wanted information": [],
      "provided information": []
    }
    ```
- The thoughts and updated summary will be:
    ```json
    {
      "Thoughts":"In the transcript snippet, PERSON2 responds to PERSON1â€™s questions about the development updates and the progress of the feature for real-time notifications. This information can be added to the "provided information" for PERSON2.",
      "Updated Summary":
        {
          "wanted information": [],
          "provided information": [
            {
              "Context": "Respond to other participantâ€™s question about the development updates",
              "Information": "Weâ€™ve made significant progress this sprint. We completed the implementation of the new authentication module and integrated it with our existing systems."
            },
            {
              "Context": "Respond to other participantâ€™s question about the progress of the feature for real-time notifications",
              "Information": "Weâ€™re about 75% done with it. The core functionality is in place, and we are now working on optimizing the delivery speed and ensuring it works seamlessly across different devices."
            }
          ]
        }
    }
    ```

## Example 2

- Here is another example of updating the utterances summary for PERSON2. You can refer to this example for better understanding.
- Suppose the transcript snippet contains the following utterances:
    (PERSON3) Good moring. (id=2)
    (PERSON1) Letâ€™s get started with todayâ€™s meeting on the recent progress of our software development project. Weâ€™ll go through updates from each team and discuss any blockers or issues. [PERSON2], could you start with the development updates?. (id=3)
    (PERSON2) Sure, [PERSON1]. Weâ€™ve made significant progress this sprint. We completed the implementation of the new authentication module and integrated it with our existing systems. (id=4){{< /table-caption >}}
> ğŸ”¼ í‘œ 22ëŠ” ë³¸ ë…¼ë¬¸ì˜ 'ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ' ê³¼ì •ì— ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ìš”ì•½ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ì ì¸ íšŒì˜ë¡ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìš”ì•½ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” íšŒì˜ ì°¸ì„ìì˜ ë°œì–¸ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ë°©ë²•, ì¶”ê°€ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•, ê·¸ë¦¬ê³  ê¸°ì¡´ ìš”ì•½ ì •ë³´ì™€ì˜ í†µí•© ë°©ë²• ë“±ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ê³  ìˆìœ¼ë©°,  ì‹¤ì œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ì´í•´ë„ë¥¼ ë†’ì´ê³  ìˆìŠµë‹ˆë‹¤.  ì´ëŠ” ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì •í™•í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì§€ì¹¨ì„ ì œì‹œí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 22: Prompt used for extracting context information (continued).
> </details>

{{< table-caption >}}
PERSON1|PERSON2|PERSON3
---|---|---
(PERSON1) That's great to hear, [PERSON2]. How about the feature for real-time notifications? Is it on track? (id=5)|(PERSON2) Yes, it is. We're about 75% done with it. The core functionality is in place, and we are now working on optimizing the delivery speed and ensuring it works seamlessly across different devices. (id=6)|(PERSON3) [PERSON2], have you had a chance to address the bug I reported last week related to the authentication module? (id=7)
(PERSON2) Yes, [PERSON3]. We identified the root cause of the bug, and it's been fixed. It was due to a conflict with a third-party library we were using. (id=8)|(PERSON3) That's good to hear. Thank you, [PERSON2]. (id=9)
(PERSON1) [PERSON2], for the next step of the project, I'd like you first complete the real-time notifications feature, and then focus on the chatbot development. (id=10)|(PERSON2) Understood, I will do that. (id=11)|(PERSON2) By the way, what's the timeline of our project? (id=12)
(PERSON1) We are aiming to finish the project by the end of August. (id=13)|(PERSON2) Ok, I know. (id=14)|(PERSON1) Let's move to the next topic. [PERSON3], could you provide an update on the testing progress? (id=15)|(PERSON3) Sure. Certainly. We've conducted tests on the new authentication module, and everything looks good so far. (id=16)|(PERSON1) Mhm. (id=17)|(PERSON3) We are now preparing for the testing of the real-time notifications feature. (id=18)|(PERSON2) In our development process, we accumulated some test cases which may help you. (id=19)|(PERSON3) That's helpful, thank you. (id=20)|- Suppose the previous summary of PERSON2 contains the following information:|
{"wanted information": [], "provided information": [{"Context": "Respond to other participant's question about the development updates", "Information": "We've made significant progress this sprint. We completed the implementation of the new authentication module and integrated it with our existing systems."}, {"Context": "Respond to other participant's question about the progress of the feature for real-time notifications", "Information": "We're about 75% done with it. The core functionality is in place, and we are now working on optimizing the delivery speed and ensuring it works seamlessly across different devices."} ]}|- The thoughts and updated summary will be:|
{"Thoughts": "In the transcript snippet, the dicussion between PERSON1 and PERSON2 about the progress of the development and the feature for real-time notifications are already included in the previous summary. PERSON2 responds to PERSON3's question about the bug in the authentication module, which can be added to the "provided information" for PERSON2. PERSON2 also comments on PERSON3's statement about the testing progress, offering to provide some test cases, which can be added to the "provided information" for PERSON2.", "Updated Summary": {"wanted information": ["What's the timeline of the project?"], "provided information": [{"Context": "Respond to other participant's question about the bug in the authentication module", "Information": "We're about 75% done with it. The core functionality is in place, and we are now working on optimizing the delivery speed and ensuring it works seamlessly across different devices."}]}}|{{< /table-caption >}}
> ğŸ”¼ í‘œ 23ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ì˜ ì—°ì†ì…ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë¯¸íŒ… ì°¸ê°€ìì˜ ë°œí™” ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì‘ì—…ì— ëŒ€í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.  ë¯¸íŒ… ë…¹ì·¨ë¡ì˜ ì¼ë¶€ë¥¼ ë‹´ì€ <Transcript Snippet>, ì°¸ê°€ìì˜ ë°œí™” ìš”ì•½ì„ ë‹´ì€ <Previous Summary>ê°€ ì£¼ì–´ì§€ë©°, <Transcript Snippet>ì— ìˆëŠ” ì°¸ê°€ìì˜ ë°œí™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ <Previous Summary>ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” ì°¸ê°€ìê°€ <Transcript Snippet>ì— ë°œí™”í•˜ì§€ ì•Šì€ ê²½ìš°, <Previous Summary>ë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šë„ë¡ ì§€ì‹œí•˜ê³ , ì¸ì‚¬ë§ì´ë‚˜ ê°ì‚¬ í‘œí˜„ ë“± ë¹„ì •ë³´ì„± ë°œí™”ëŠ” ë¬´ì‹œí•˜ë„ë¡ í•©ë‹ˆë‹¤. ë˜í•œ,  ì¶”ì¶œëœ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ <Previous Summary>ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ê³¼ ì£¼ì˜ì‚¬í•­ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.  ì´ í‘œëŠ” ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ ê³¼ì •ì—ì„œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ë³´ì—¬ì£¼ë©°, ì‹¤í—˜ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ê³¼ ì¬í˜„ì„±ì„ í™•ë³´í•˜ëŠ”ë° ê¸°ì—¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 23: Prompt used for extracting context information (continued).
> </details>

{{< table-caption >}}
||Example 3||
|---|---|---|
|(PERSON13) Hi.|(PERSON6) Hi everyone. (id=1)|(PERSON19) Hi. (id=2)|
|Thanks for, uhm. (id=0)|(PERSON13) Yeah, great. |Thanks for joining and, uh, yeah okay.|
|So, yeah. |Uh, I I see that people have written up ehm what they did. (id=3)|(PERSON19) Hi [PERSON13], I can hear you. (id=4)|
|(PERSON13) Yep, thatâ€™s great. |Uh, and also you were evaluating-.|Yes, so thatâ€™s thatâ€™s re re record.|
|What you did.|So what I have, uh, on my mind now is uh, uh, well, uh, preparations. |So, uh, [PERSON13], uh I am busy, uh, with the IW SLT, uh, write-up.|
|Uh, that was the, uh, the wra last part that I did.|Now busy with interviewing people people to uh to replace those who are em moving forward <laugh/> so to say.|So there is number of colleagues on projects that I am supervising, uh, that who are going for studies abroad and other things.|
|Uh, so, uh, what I think we should focus on is the demo for Project Officer.|Then we need to focus on the ladder climbing, uh, which is building uh, uh, [PROJECT3] test set plus, uh, regularly, uh, testing on it.|Ehm, and, ehm what else, uh, the deliverables.|
|Yeah.|[PROJECT3] deliverables.|So, Iâ€™ll try to provide the links-.|
|Or those who of you, who are already working on the deliverables, please mention that.|And yeah.|Letâ€™s letâ€™s go quickly over what what have done.|
|So [PERSON6] you are the first on the list.|Ehm, ehm, so please briefly update what what you have been working on.|And what what is the plan for the next week. (id=5)|
|(PERSON6) <other_noise/>|So, luckily.|<laugh/>|
|Not luckily but this week I had like quite less tasks to do.|So first I calculated the word error rate on Czech transcripts using that three versions of, uh, Czech ASR which [PERSON10] created.|And so yesterday [PERSON10] told me that they were, uh, and the golden transcript and its corresponding video there were there were huge huge mismatch.|
|And I <unintelligible/> and he said to update me. | | |{{< /table-caption >}}
> ğŸ”¼ í‘œ 24ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ context ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ í‘œëŠ” ì‹¤ì œ íšŒì˜ë¡ì˜ ì¼ë¶€ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¸ê°€ìì˜ ë°œì–¸ ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  íŠ¹íˆ, ì°¸ê°€ìê°€ ë°œí™”í•˜ì§€ ì•Šì€ ê²½ìš° ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šì•„ì•¼ í•˜ë©°, ì¸ì‚¬ë§ì´ë‚˜ ê°ì‚¬ í‘œì‹œ ë“±ì˜ ë¹„ì •ë³´ì ì¸ ë°œì–¸ì€ ì œì™¸í•´ì•¼ í•©ë‹ˆë‹¤.  ë˜í•œ, ìš”ì•½ ì—…ë°ì´íŠ¸ ê³¼ì •ì—ì„œ ì°¸ê°€ìì˜ ì˜ë„ì™€ ì •ë³´ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ê³ , ì›ë¬¸ ë°œì–¸ì„ ìµœëŒ€í•œ í™œìš©í•˜ë©°, ë‹¤ë¥¸ ì°¸ê°€ìì˜ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.  ì¶œë ¥ í˜•ì‹ì€ JSONì´ë©°, ì—…ë°ì´íŠ¸ëœ ìš”ì•½ê³¼ ê·¸ ê³¼ì •ì— ëŒ€í•œ ì„¤ëª…ì„ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 24: Prompt used for extracting context information (continued).
> </details>

{{< table-caption >}}
|[id]|PERSON|Content
|-|-|-
|6|PERSON 6|And lastly yeah I think I did-. Uh, it was the input in the [PROJECT 3] deliverable of for the punctuator and through caser. <unintelligible/>
|7|PERSON 13|Mhm.
|8|PERSON 13|Mhm, yeah.
|9|PERSON 6|And I donâ€™t have-. I think that apart from the testing sessions to do this week so I am waiting for new tasks. 
|10|PERSON 13|Yeah, so.
|11|PERSON 6|Yeah, yeah, yeah.
|12|PERSON 13|So, so I will make it to do-.
|13|PERSON 6|So I have updated the German transcripts in its corresponding path and like do we have the golden transcripts for the English videos? 
|14|PERSON 13|Yes, thatâ€™s the other part.
|15|PERSON 10|can you maybe tell us more details about that?
|16|PERSON 13|Mhm.
|17|PERSON 10|Yeah, yeah.
|18|PERSON 6|The transcription is for the completely different audio than itâ€™s in the subdirectory. 
|19|PERSON 13|Oh, so then someone must have like messed it up.
|20|PERSON 10|Yeah, yeah, I I may maybe itâ€™s just like uh.
|21|PERSON 13|Mhm.
|22|PERSON 10|I I havenâ€™t checked but-.
|23|PERSON 13|Yeah, so [PERSON 10] can you coul could you do this check?
|24|PERSON 6|Okay.
|25|PERSON 10|Well, I just like listened to the audio and followed the talk transcript <other_noise/> and it was completely off. I think it is-. There must be some miss-match because-. Uh, yeah, there is some some serious mismatch there. It should not be hard Like try listening to all the files that are within this demo for [PERSON 15], uh, and try to locate the correct file, the appropriate files. But we should have, we should have the transcripts ready for all of those. So we should be able to, uh, to evaluate it. And also for the English ones we have the translations. So for the English ones [PERSON 6], uh, I would like you to evaluate not only the word error rate of the ASR. But also the machine translation quality or at the SLT even. Uh, with the translation quality into German and Czech. Both are available.{{< /table-caption >}}
> ğŸ”¼ í‘œ 25ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ì´ì „ í˜ì´ì§€ì—ì„œ ì´ì–´ì§€ëŠ” í‘œì´ë©°,  ë¯¸íŒ… ë…¹ì·¨ë¡ì—ì„œ ì°¸ê°€ìì˜ ë°œì–¸ ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ì§€ì¹¨ê³¼ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.  íŠ¹íˆ,  ì°¸ê°€ìì˜ ë°œì–¸ì—ì„œ 'ì›í•˜ëŠ” ì •ë³´'ì™€ 'ì œê³µëœ ì •ë³´'ë¥¼ ì¶”ì¶œí•˜ê³  ì´ì „ ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ,  ì˜ëª»ëœ ì •ë³´ë‚˜ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ìš”ì•½ì˜ ê°€ë…ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 25: Prompt used for extracting context information (continued).
> </details>

{{< table-caption >}}
|- Suppose the previous summary of PERSON6 contains the following information:
|---|---| 
| "wanted information" | [] |
| "provided information" | [] |
|- The thoughts and updated summary will be:
|---|---| 
| "Thoughts" | "PERSON6 responds to PERSON13's questions about the work done and the plan for the next week, which can be added to the 'provided information' for PERSON6. PERSON6 also asks about the golden transcripts for the English videos, which can be added to the 'wanted information' for PERSON6." |
| "Updated Summary" | {
  "wanted information": [
    "Do we have the golden transcripts for the English videos?" 
  ],
  "provided information": [
    {
      "Context": "Respond to other participant's question about the work done and the plan for the next week",
      "Information": "This week I had quite less tasks to do. So first I calculated the word error rate on Czech transcripts using three versions of Czech ASR created by [PERSON10]. And so yesterday [PERSON10] told me that there were huge mismatch between the golden transcript and its corresponding video. And he said to update me. And then we conducted a few testing sessions with [PERSON11] and [PERSON18]. And they were not quite successful because the segmenters from [ORGANIZATION1] were still down and [PERSON12] today is working on them. And lastly, I think I did the input in the [PROJECT3] deliverable for the punctuator and through caser. Apart from the testing sessions to do this week so I am waiting for new tasks."
    },
    {
      "Context": "Respond to other participant's question about the word error rate for the English and German transcripts",
      "Information": "I have updated the German transcripts in its corresponding path, and I don't konw if we have the golden transcripts for the English videos."
    }
  ]
}
|{{< /table-caption >}}
> ğŸ”¼ í‘œ 26ì€ ë³¸ ë…¼ë¬¸ì˜ '4.1 ë°ì´í„°ì…‹ êµ¬ì„±' ì„¹ì…˜ì— ì†í•˜ë©°, ì‹¤ì œ íšŒì˜ë¡ì—ì„œ ë¬¸ë§¥ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í‘œëŠ” ì´ì „ í˜ì´ì§€ì—ì„œ ì´ì–´ì§€ëŠ” í‘œì˜ ì—°ì†ì´ë©°, íšŒì˜ ì°¸ì—¬ìì˜ ë°œí™” ìš”ì•½ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ë²•ì„ ìì„¸íˆ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ”  íšŒì˜ë¡ì˜ ì¼ë¶€, ì´ì „ ìš”ì•½, ë° ì°¸ê°€ìì˜ ì˜ë„ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ë©°,  ìì—°ìŠ¤ëŸ½ê³  ê´€ë ¨ì„± ìˆëŠ” ìš”ì•½ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ì§€ì¹¨ì„ ì œì‹œí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 26: Prompt used for extracting context information (continued).
> </details>

{{< table-caption >}}
[{"Explanation": "PERSON18 provides a comment about using a tokenizer before an inverse segmenter.", "Type": "Chime In", "Response IDs": "79", "ID": "78", "Speaker": "Speaker 13"}, {"Explanation": "PERSON18 explains the benefits of using a tokenizer before an inverse segmenter and shares a script path.", "Type": "Chime In", "Response IDs": "81", "ID": "80", "Speaker": "Speaker 13"}, {"Explanation": "PERSON18 further clarifies the usage of the Moses seg tokenizer and detokenizer.", "Type": "Chime In", "Response IDs": "83", "ID": "82", "Speaker": "Speaker 13"}]{{< /table-caption >}}
> ğŸ”¼ í‘œ 27ì€ íšŒì˜ë¡ì—ì„œ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 4.1ì ˆ 'ë°ì´í„°ì…‹ êµ¬ì„±'ì— ì†í•˜ë©°,  LLM ê¸°ë°˜ íšŒì˜ ëŒ€ë¦¬ ì‹œìŠ¤í…œì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.  ìì„¸íˆëŠ”,  íšŒì˜ë¡ì—ì„œ 'ì°¸ê°€ì ê°œì…', 'ëª…ì‹œì  ë‹¨ì„œ', 'ì•”ì‹œì  ë‹¨ì„œ' ì„¸ ê°€ì§€ ìœ í˜•ì˜ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ê³¼ ì˜ˆì‹œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ìœ í˜•ì˜ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ì— ëŒ€í•œ ì„¤ëª…, ì¶œë ¥ í˜•ì‹, ê·¸ë¦¬ê³  ì˜ˆì‹œê°€ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 27: Prompt used for extracting test cases from meeting transcript.
> </details>

{{< table-caption >}}
| Example 1 |  <a download="" href="data:text/plain;base64,ICAgIDxFdmFsdWF0aW9uIERhdGFzZXQ+CiAgICBbCiAgICAgICAgIkV4cGxhbmF0aW9uIjogIlBFUlNPTjE4J3MgdXR0ZXJhbmNlIGlzIGluZm9ybWF0aXZlIGFuZCBzdWl0YWJsZSBmb3IgZXZhbHVhdGlvbiBkYXRhc2V0LiBQRVJTT04xOCBzcG9udGFuZW91c2x5IGNvbnRyaWJ1dGVzIHRvIHRoZSBjb252ZXJzYXRpb24gd2l0aG91dCBiZWluZyBkaXJlY3RseSBwcm9tcHRlZC4gVGhpcyBpcyBhIENoaW1lIEluIGluc3RlYWQgb2YgSW1wbGljaXQgQ3VlIHNpbmNlIFtQRVJTT04xOF0gaXMgbm90IGFscmVhZHkgZW5nYWdlZCBpbiB0aGUgY29udmVyc2F0aW9uLiIsCiAgICAgICAgIlR5cGUiOiAiQ2hpbWUgaW4iLAogICAgICAgICJSZXNwb25zZSBJRCI6IFs3NywgNzksIDgxLCA4M10KICAgICAgICAiSUQiOiA3NiwKICAgICAgICAiU3BlYWtlciI6ICJTcGVha2VyIDE5IiwKICAgIF0=" download="" >â¬‡</a> | 
| Example 2 | &lt;Transcript&gt;
"speaker": "Speaker 13", "content": "Yes, so I need to review these and the internal deadline is in 6 days from now. Uh, so, hopefully I will get back to all of you. To each of you independently towards the end of the week if there is anything unclear. So that we meet the internal deadline on the 8th. Yeah, okay. Great. Uh. So [PERSON18], what what is your progress? (id=117)" | 
|  | "speaker": "Speaker 18", "content": "Hmhm. Yes, and by reading the papers I found an interesting tool. (id=118)" | 
|  | "speaker": "Speaker 13", "content": "Mhm. (id=119)" | 
|  | "speaker": "Speaker 18", "content": "I found out that itâ€™s possible to measure out the speech rate by cutting the syllables. And there is one tool. One patent tool, which can detect the gender of speaker and the speech rate. (id=120)" | 
|  | "speaker": "Speaker 13", "content": "Mhm. (id=121)" | 
|  | "speaker": "Speaker 18", "content": "And some other characteristics. So we can try it and make a dashboard out of it. (id=122)" | 
|  | "speaker": "Speaker 13", "content": "Mhm. Thatâ€™s thatâ€™s useful thing. Uh, and later on we could even create models like-. If we if we recognise that someone is speaking too fast, we could use like a harsher summarisation. (id=123)" | 
|  | "speaker": "Speaker 18", "content": "Yes. (id=124)" | 
|  | "speaker": "Speaker 13", "content": "So we could be reducing reducing their speech mole with a different model. (id=125)" | 
|  | "speaker": "Speaker 18", "content": "Yes, and there was also speech modes. Like whether it was angry or normal and so on. (id=126)" | 
|  | "speaker": "Speaker 13", "content": "Mhm. (id=127)" | 
|  | "speaker": "Speaker 18", "content": "But I have no idea how the tool works in practice. I I I I saw it only in Gi GitHub and I buy it. (id=128)" | 
|  | "speaker": "Speaker 13", "content": "Yeah, uh. (id=129)" | 
|  | "speaker": "Speaker 18", "content": "So we can try it and make a dashboard out of it. (id=130)" | 
|  | <a download="" href="data:text/plain;base64,ICAgPEV2YWx1YXRpb24gRGF0YXNldD4KICAgWwogICAgICJFeHBsYW5hdGlvbiI6ICJQRVJTT04xOCdzIHV0dGVyYW5jZSBpcyBpbmZvcm1hdGl2ZSBhbmQgc3VpdGFibGUgZm9yIGV2YWx1YXRpb24gZGF0YXNldC4gUEVSU09OMTggd2FzIGRpcmVjdGx5IHByb21wdGVkIGJ5IFNwZWFrZXIgMTMuIFRoaXMgaXMgYW4gRXhwbGljaXQgQ3VlLiIsCiAgICAgIlR5cGUiOiAiRXhwbGljaXQgQ3VlIiwKICAgICAiUmVzcG9uc2UgSUQiOiBbMTE4LCAxMjAsIDEyMiwgMTI0LCAxMjYsIDEyOCwgMTMwXQogICAgICJJRCI6IDExNywKICAgICAiU3BlYWtlciI6ICJTcGVha2VyIDEzIiwKICAgXQ==" download="" >â¬‡</a> |{{< /table-caption >}}
> ğŸ”¼ í‘œ 28ì€ íšŒì˜ë¡ì—ì„œ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 4.1ì ˆ ë°ì´í„°ì…‹ êµ¬ì„± ë¶€ë¶„ì— ì†í•˜ë©°, íšŒì˜ ë…¹ì·¨ë¡ì—ì„œ íŠ¹ì • ì°¸ê°€ìì˜ ì‘ë‹µ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ í‰ê°€ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” 'ì°¸ê°€', 'ëª…ì‹œì  ë‹¨ì„œ', 'ì•”ì‹œì  ë‹¨ì„œ' ì„¸ ê°€ì§€ ë²”ì£¼ë¡œ ë¶„ë¥˜ëœ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ ì¶”ì¶œí•˜ëŠ” ì§€ì¹¨ê³¼ í•¨ê»˜, í’ˆì§ˆì´ ë†’ì€ ë°œí™”ë§Œ í¬í•¨í•˜ê³ , ê°„ë‹¨í•œ í™•ì¸ì´ë‚˜ ë™ì˜ ê°™ì€ ë¬´ì˜ë¯¸í•œ ë°œí™”ëŠ” ì œì™¸í•˜ë©°, ì‘ë‹µì´ ì‹¤ì§ˆì ì¸ ë‚´ìš©ì„ ë‹´ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 28: Prompt used for extracting test cases from meeting transcript (continued).
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}