{"references": [{"fullname_first_author": "Brooks, T.", "paper_title": "Video generation models as world simulators", "publication_date": "2024", "reason": "This paper is a foundational work in video generation, providing a new perspective on video generation models as world simulators which greatly impacts this research."}, {"fullname_first_author": "Yang, Z.", "paper_title": "CogVideoX: Text-to-video diffusion models with an expert transformer", "publication_date": "2024", "reason": "This paper introduces a 3D full attention mechanism and expert transformers into video generation to improve motion consistency and semantic alignment, directly influencing the methods explored in this research."}, {"fullname_first_author": "Kong, W.", "paper_title": "Hunyuanvideo: A systematic framework for large video generative models", "publication_date": "2025", "reason": "This paper presents HunyuanVideo, a state-of-the-art text-to-video diffusion model which this paper uses as a benchmark model for testing their Enhance-A-Video method."}, {"fullname_first_author": "HaCohen, Y.", "paper_title": "LTX-Video: Realtime video latent diffusion", "publication_date": "2024", "reason": "This paper introduces LTX-Video, a real-time latent text-to-video diffusion model used as a benchmark model in this paper's experiments, making it a critical reference for comparing performance."}, {"fullname_first_author": "Zheng, Z.", "paper_title": "Open-Sora: Democratizing efficient video production for all", "publication_date": "2024", "reason": "This paper introduces Open-Sora, another efficient text-to-video generation model with a decomposed spatial-temporal attention mechanism that is used as a benchmark model in this research, demonstrating the influence of different architecture designs on video generation."}]}