{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-00-00", "reason": "This paper is highly relevant due to its focus on video generation models and their capabilities, directly addressing the core topic of the main paper."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-00-00", "reason": "This work is crucial due to its introduction of open diffusion models for video generation, a technique directly relevant to the methods used in the main paper."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-00-00", "reason": "This paper tackles the challenge of data limitations in video diffusion models, a problem directly relevant to the main paper's focus on datasets for long-form narrative video generation."}, {"fullname_first_author": "Yanghao Li", "paper_title": "Scaling language-image pre-training via masking", "publication_date": "2023-00-00", "reason": "This work is significant for its advancements in language-image pre-training, a technique fundamental to the main paper's approach that integrates text and image embeddings."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant because it details the approach of using high-resolution image synthesis with latent diffusion models, a key aspect of the main paper\u2019s methodology."}]}