[{"content": "| Crawling Method | Selection Pool Size | Commonsense Reasoning (4 tasks) | Language Understanding (6 tasks) | Reading Comprehension (3 tasks) | Symbolic Problem Solving (5 tasks) | World Knowledge (5 tasks) | Core (23 tasks) | % of Oracle | \n|---|---|---|---|---|---|---|---|---| \n| **Oracle Selection (Upper Bound):** Random sample from the top 10% rated data from ClueWeb22 using DCLM fastText for pretraining |  | 0.2438 | 0.2209 | 0.1483 | 0.2039 | 0.2403 | 0.2239 | 100% | \n| n.a. | 45\u00d7 | 0.2438 | 0.2209 | 0.1483 | 0.2039 | 0.2403 | 0.2239 | 100% | \n| **Crawl-then-Select:** Crawl 1\u00d7 and 2\u00d7 more data from ClueWeb22 and select top-rated 1\u00d7 data using DCLM fastText for pretraining |  |  |  |  |  |  |  |  | \n| Random | 1\u00d7 | 0.1906 | 0.1890 | 0.0244 | 0.1834 | 0.1930 | 0.1748 | 78.1% | \n|  | 2\u00d7 | 0.1896 | 0.1967 | 0.1260 | 0.2000 | 0.2024 | 0.1964 | 87.7% | \n| Indegree | 1\u00d7 | 0.1730 | 0.1680 | 0.0326 | 0.1616 | 0.1668 | 0.1556 | 69.5% | \n|  | 2\u00d7 | 0.1845 | 0.1856 | 0.0970 | 0.1958 | 0.1953 | 0.1865 | 83.3% | \n| **Ours:** Crawl 1\u00d7 data using Craw4LLM for pretraining |  |  |  |  |  |  |  |  | \n| Craw4LLM | 1\u00d7 | 0.2116 | 0.2311 | 0.0826 | 0.1979 | 0.2486 | 0.2133 | 95.3% |", "caption": "Table 1: \nDownstream LLM performance.\nAll models are pretrained on 1\u00d7 data, which corresponds to 20M documents and 32.9B tokens.\nThe evaluation metric is centered accuracy (0 = random guess)\u00a0(Li et\u00a0al., 2024).\nBest/2nd best in the last two groups are bolded/underlined.\nSee Appendix\u00a0C for detailed results.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ud558\ub958 \uc791\uc5c5\uc5d0\uc11c \uc0ac\uc804 \ud6c8\ub828\ub41c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \ubaa8\ub378\uc740 20M\uac1c\uc758 \ubb38\uc11c\uc640 32.9B \ud1a0\ud070\uc5d0 \ud574\ub2f9\ud558\ub294 1\ubc30\uc758 \ub370\uc774\ud130\ub85c \uc0ac\uc804 \ud6c8\ub828\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud3c9\uac00 \uc9c0\ud45c\ub294 \uc911\uc2ec \uc815\ud655\ub3c4(0\uc740 \ubb34\uc791\uc704 \ucd94\uce21)(Li et al., 2024)\uc774\uba70, \ub9c8\uc9c0\ub9c9 \ub450 \uadf8\ub8f9\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740/\ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uc810\uc218\ub294 \uad75\uc740 \uae00\uc528/\ubc11\uc904\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc790\uc138\ud55c \uacb0\uacfc\ub294 \ubd80\ub85d C\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Hyper-parameter | Value |\n|---|---| \n| n<sub>layers</sub> | 24 |\n| n<sub>heads</sub> | 8 |\n| d<sub>model</sub> | 1,024 |\n| d<sub>head</sub> | 128 |\n| Warmup | 2,000 |\n| Learning Rate | 3e-3 |\n| Weight Decay | 0.033 |\n| z-loss | 1e-4 |\n| Global Batch Size | 512 |\n| Sequence Length | 2048 |", "caption": "Table 2: Model and training hyper-parameters.\nnlayerssubscript\ud835\udc5blayersn_{\\text{layers}}italic_n start_POSTSUBSCRIPT layers end_POSTSUBSCRIPT, nlayerssubscript\ud835\udc5blayersn_{\\text{layers}}italic_n start_POSTSUBSCRIPT layers end_POSTSUBSCRIPT, dmodelsubscript\ud835\udc51modeld_{\\text{model}}italic_d start_POSTSUBSCRIPT model end_POSTSUBSCRIPT, and dheadsubscript\ud835\udc51headd_{\\text{head}}italic_d start_POSTSUBSCRIPT head end_POSTSUBSCRIPT denote the number of layers, attention heads, width, and width per attention head, respectively.", "description": "\ud45c 2\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc5b8\uc5b4 \ubaa8\ub378\uc758 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  `nlayers`\ub294 \ub808\uc774\uc5b4 \uc218, `nheads`\ub294 \uc5b4\ud150\uc158 \ud5e4\ub4dc \uc218, `dmodel`\uc740 \ubaa8\ub378\uc758 \ub108\ube44, `dhead`\ub294 \uc5b4\ud150\uc158 \ud5e4\ub4dc \ub2f9 \ub108\ube44\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc740 \ubaa8\ub378\uc758 \uad6c\uc870\uc640 \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc911\uc694\ud55c \uc694\uc18c\uc785\ub2c8\ub2e4.", "section": "3 Experimental Methodology"}, {"content": "| Crawling | Selection | Commonsense Reasoning |  |  |  |\n|---|---|---|---|---|---| \n| **Method** | **Pool Size** | CommonsenseQA | COPA | OpenBookQA | PIQA |\n| **Oracle Selection (Upper Bound)** |  |  |  |  |  |\n| n.a. | 45\u00d7 | 0.2850 | 0.7000 | 0.3300 | 0.6812 |\n| **Crawl-then-Select** |  |  |  |  |  |\n| Random | 1\u00d7 | 0.2072 | 0.6700 | 0.2980 | 0.6746 |\n| Random | 2\u00d7 | 0.2588 | 0.6200 | 0.3160 | 0.6785 |\n| Random | 4\u00d7 | 0.2326 | 0.6400 | 0.3380 | 0.6757 |\n| Indegree | 1\u00d7 | 0.3219 | 0.6000 | 0.2780 | 0.6513 |\n| Indegree | 2\u00d7 | 0.1966 | 0.6600 | 0.3040 | 0.6752 |\n| Indegree | 4\u00d7 | 0.2088 | 0.6400 | 0.3400 | 0.6817 |\n| **Ours** |  |  |  |  |  |\n| Craw4LLM | 1\u00d7 | 0.2277 | 0.6600 | 0.3300 | 0.6926 |", "caption": "Table 3: Results for commonsense reasoning tasks.", "description": "\ubcf8 \ud45c\ub294 \uc0c1\uc2dd \ucd94\ub860 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc0c1\uc2dd \ucd94\ub860 \uacfc\uc81c(CommonsenseQA, COPA, OpenBookQA, PIQA)\uc5d0 \ub300\ud574, \ub2e4\uc591\ud55c \ud06c\ub864\ub9c1 \ubc29\ubc95(\ubb34\uc791\uc704 \ud06c\ub864\ub9c1, In-degree \uae30\ubc18 \ud06c\ub864\ub9c1, CRAW4LLM)\uacfc \ud06c\ub864\ub9c1 \ub370\uc774\ud130 \uaddc\ubaa8(1x, 2x, 4x)\uc5d0 \ub530\ub978 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. Oracle Selection (Upper Bound)\ub294 \ucd5c\uc0c1\uc704 10% \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uc5b4 \ube44\uad50 \uae30\uc900\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 CRAW4LLM\uc758 \ud6a8\uc728\uc131 \ubc0f \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 Evaluation Results"}, {"content": "| Crawling | Selection | Language Understanding |  |  |  |  |  |\n|---|---|---|---|---|---|---|---| \n| **Method** | **Pool Size** | BIG-Bench Lang. Id. | HellaSwag (zero-shot) | HellaSwag | LAMBADA | Winograd | Winogrande |\n|---|---|---|---|---|---|---|---| \n| **Oracle Selection (Upper Bound)** |  |  |  |  |  |  |  |\n| n.a. | 45\u00d7 | 0.2515 | 0.3856 | 0.3905 | 0.4432 | 0.6557 | 0.5130 |\n| **Crawl-then-Select** |  |  |  |  |  |  |  |\n| Random | 1\u00d7 | 0.2490 | 0.3709 | 0.3716 | 0.3990 | 0.6044 | 0.5146 |\n| Random | 2\u00d7 | 0.2468 | 0.3882 | 0.3925 | 0.4073 | 0.6007 | 0.5130 |\n| Random | 4\u00d7 | 0.2521 | 0.4011 | 0.4019 | 0.4390 | 0.6154 | 0.5130 |\n| Indegree | 1\u00d7 | 0.2566 | 0.3515 | 0.3519 | 0.3596 | 0.5971 | 0.5004 |\n| Indegree | 2\u00d7 | 0.2547 | 0.3749 | 0.3771 | 0.3773 | 0.5861 | 0.5241 |\n| Indegree | 4\u00d7 | 0.2562 | 0.3994 | 0.4008 | 0.4159 | 0.6190 | 0.5178 |\n| **Ours** |  |  |  |  |  |  |  |\n| Craw4LLM | 1\u00d7 | 0.2544 | 0.4035 | 0.4048 | 0.4196 | 0.6593 | 0.5288 |", "caption": "Table 4: Results for language understanding tasks.", "description": "\ud45c 4\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \uc774\ud574 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc791\uc5c5(BIG-Bench Lang. ID, HellaSwag(zero-shot), HellaSwag, LAMBADA, Winograd, Winogrande)\uc5d0 \ub300\ud574 \uc138 \uac00\uc9c0 \ud06c\ub864\ub9c1 \ubc29\ubc95 (\ubb34\uc791\uc704 \ud06c\ub864\ub9c1, In-degree \uae30\ubc18 \ud06c\ub864\ub9c1, CRAW4LLM)\uacfc \ub370\uc774\ud130 \uc120\ud0dd \ubc29\uc2dd(\ud06c\ub864\ub9c1 \ub370\uc774\ud130 1\ubc30, 2\ubc30, 4\ubc30 \ud06c\ub864\ub9c1 \ud6c4 \uc0c1\uc704 1\ubc30 \uc120\ud0dd)\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc624\ub77c\ud074 \uc120\ud0dd(Oracle Selection) \uacb0\uacfc\ub294 \ucd5c\uace0 \uc131\ub2a5\uc758 \uae30\uc900\uc810 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5\uc740 \uc911\uc2ec\ud654\ub41c \uc815\ud655\ub3c4(centered accuracy)\ub85c \uce21\uc815\ub429\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Crawling | Selection | Reading Comprehension |  |  |\n|---|---|---|---|---|\n| **Method** | **Pool Size** | BoolQ | CoQA | SQuAD |\n| **Oracle Selection (Upper Bound)** |  |  |  |  |\n| n.a. | 45\u00d7 | 0.5755 | 0.2479 | 0.3139 |\n| **Crawl-then-Select** |  |  |  |  |\n| Random | 1\u00d7 | 0.5080 | 0.1799 | 0.1882 |\n| Random | 2\u00d7 | 0.5807 | 0.2053 | 0.2759 |\n| Random | 4\u00d7 | 0.5911 | 0.2361 | 0.2951 |\n| Indegree | 1\u00d7 | 0.5324 | 0.1666 | 0.1616 |\n| Indegree | 2\u00d7 | 0.5697 | 0.1843 | 0.2390 |\n| Indegree | 4\u00d7 | 0.5765 | 0.2147 | 0.2736 |\n| **Ours** |  |  |  |  |\n| Craw4LLM | 1\u00d7 | 0.5440 | 0.2264 | 0.2215 |", "caption": "Table 5: Results for reading comprehension tasks.", "description": "\ud45c 5\ub294 \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc \uc911 \uc77d\uae30 \uc774\ud574(Reading Comprehension) \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01\uac01\uc758 \ud06c\ub864\ub9c1 \ubc29\ubc95(CRAW4LLM, \ub79c\ub364 \ud06c\ub864\ub9c1, Indegree \uae30\ubc18 \ud06c\ub864\ub9c1)\uacfc \ud06c\ub864\ub9c1 \ub370\uc774\ud130 \ud06c\uae30(1x, 2x, 4x)\ubcc4\ub85c BoolQ, CoQA, SQUAD \uc138 \uac00\uc9c0 \uc77d\uae30 \uc774\ud574 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc131\ub2a5(\uc815\ud655\ub3c4)\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec CRAW4LLM\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Oracle Selection (Upper Bound)\ub294 \ucd5c\uc0c1\uc704 10% \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4 Evaluation Results"}, {"content": "| Crawling | Selection | AGI Eval LSAT-AR | BIG-Bench CS Algorithms | BIG-Bench Dyck Lang. | BIG-Bench Operators | BIG-Bench Repeat Copy Logic |\n|---|---|---|---|---|---|---|\n| **Oracle Selection (Upper Bound)** |  | 0.2739 | 0.4341 | 0.2160 | 0.2143 | 0.0625 |\n| **Crawl-then-Select** |  |  |  |  |  |  |\n| Random | 1\u00d7 | 0.2391 | 0.4568 | 0.1970 | 0.2143 | 0.0000 |\n| Random | 2\u00d7 | 0.2696 | 0.4538 | 0.2520 | 0.1762 | 0.0313 |\n| Random | 4\u00d7 | 0.1957 | 0.4568 | 0.2600 | 0.1857 | 0.0625 |\n| Indegree | 1\u00d7 | 0.2304 | 0.4371 | 0.1900 | 0.1429 | 0.0000 |\n| Indegree | 2\u00d7 | 0.2609 | 0.4235 | 0.2340 | 0.2143 | 0.0313 |\n| Indegree | 4\u00d7 | 0.2174 | 0.4538 | 0.2530 | 0.1667 | 0.0938 |\n| **Ours** |  |  |  |  |  |  |\n| Craw4LLM | 1\u00d7 | 0.2696 | 0.4371 | 0.1620 | 0.2095 | 0.0938 |", "caption": "Table 6: Results for symbolic problem solving tasks.", "description": "\ud45c 6\uc740 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc774\uba70, \uae30\ud638\uc801 \ubb38\uc81c \ud574\uacb0 \uc791\uc5c5\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc73c\ub85c, \uac01 \ubaa8\ub378\uc774 AGI Eval, LSAT-AR, BIG-Bench CS Algorithms, BIG-Bench Dyck Lang, BIG-Bench Operators, BIG-Bench Repeat Copy Logic \ub4f1 \ub2e4\uc591\ud55c \uae30\ud638\uc801 \ubb38\uc81c \ud574\uacb0 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2ec\uc131\ud55c \uc131\ub2a5 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud06c\ub864\ub9c1 \ubc29\ubc95(\uc784\uc758 \ud06c\ub864\ub9c1, In-degree \ud06c\ub864\ub9c1, CRAW4LLM)\uacfc \ud06c\ub864\ub9c1 \ub370\uc774\ud130 \ud06c\uae30(1x, 2x, 4x)\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ube44\uad50\ud558\uc5ec CRAW4LLM\uc758 \ud6a8\uc728\uc131\uacfc \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.", "section": "4 Evaluation Results"}, {"content": "| Crawling | Selection | World Knowledge |  |  |  |  |\n|---|---|---|---|---|---|---|\n| **Method** | **Pool Size** | ARC Easy | ARC Challenge | BIG-Bench-Bench QA Wikidata | Jeopardy | MMLU |\n| **Oracle Selection (Upper Bound)** |  |  |  |  |  |  |\n| n.a. | 45\u00d7 | 0.5951 | 0.3166 | 0.4945 | 0.1176 | 0.2805 |\n| **Crawl-then-Select** |  |  |  |  |  |  |\n| Random | 1\u00d7 | 0.5152 | 0.2799 | 0.5186 | 0.0461 | 0.2552 |\n| Random | 2\u00d7 | 0.5425 | 0.2807 | 0.5081 | 0.0648 | 0.2561 |\n| Random | 4\u00d7 | 0.5577 | 0.2867 | 0.5126 | 0.0970 | 0.2543 |\n| Indegree | 1\u00d7 | 0.4857 | 0.2509 | 0.4888 | 0.0138 | 0.2618 |\n| Indegree | 2\u00d7 | 0.5248 | 0.2790 | 0.5205 | 0.0555 | 0.2464 |\n| Indegree | 4\u00d7 | 0.5749 | 0.2935 | 0.5084 | 0.0959 | 0.2430 |\n| **Ours** |  |  |  |  |  |  |\n| Craw4LLM | 1\u00d7 | 0.6103 | 0.3208 | 0.5143 | 0.1323 | 0.2661 |", "caption": "Table 7: Results for world knowledge tasks.", "description": "\ud45c 7\uc740 \uc138\uacc4 \uc9c0\uc2dd \uad00\ub828 \uacfc\uc81c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud589\uc740 \ud06c\ub864\ub9c1 \ubc29\ubc95(\uc784\uc758, \ucc28\uc218 \uae30\ubc18, CRAW4LLM)\uacfc \ud06c\ub864\ub9c1 \ub370\uc774\ud130 \ud06c\uae30(1x, 2x, 4x)\uc5d0 \ub530\ub978 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc138\uacc4 \uc9c0\uc2dd \uacfc\uc81c\ub294 \ub2e4\uc591\ud55c \uc9c0\uc2dd \ub370\uc774\ud130\ubca0\uc774\uc2a4(ARC Easy, ARC Challenge, BIG-Bench QA, Wikidata, Jeopardy, MMLU)\ub97c \uc0ac\uc6a9\ud558\uba70, \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4 \uc810\uc218\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  \uc624\ub77c\ud074 \uc120\ud0dd(\ucd5c\uc0c1\uc704 10% \ub370\uc774\ud130 \uc0ac\uc6a9) \uacb0\uacfc\ub294 \uc0c1\ud55c\uc120\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 CRAW4LLM\uc774 \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \ub354 \ud6a8\uc728\uc801\uc73c\ub85c \uace0\ud488\uc9c8\uc758 \uc138\uacc4 \uc9c0\uc2dd \uad00\ub828 \ub370\uc774\ud130\ub97c \uc218\uc9d1\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \ud3c9\uac00 \uacb0\uacfc"}]