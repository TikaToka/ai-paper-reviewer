{"references": [{"fullname_first_author": "Stefan Baack", "paper_title": "A critical analysis of the largest source for generative AI training data: Common Crawl", "publication_date": "2024-00-00", "reason": "This paper provides a critical analysis of Common Crawl, a dataset heavily used in LLM pretraining, highlighting its limitations and inefficiencies."}, {"fullname_first_author": "Junghoo Cho", "paper_title": "Efficient crawling through URL ordering", "publication_date": "1998-00-00", "reason": "This foundational paper introduces the concept of URL ordering for efficient web crawling, which is directly relevant to the proposed CRAW4LLM method."}, {"fullname_first_author": "Jeffrey Li", "paper_title": "Datacomp-LM: In search of the next generation of training sets for language models", "publication_date": "2024-00-00", "reason": "This paper introduces the DCLM fastText classifier used in CRAW4LLM for scoring the importance of web pages for LLM pretraining."}, {"fullname_first_author": "Jordan Hoffmann", "paper_title": "Training compute-optimal large language models", "publication_date": "2022-00-00", "reason": "This paper provides insights into training compute-optimal LLMs, which is crucial for evaluating the efficiency and effectiveness of CRAW4LLM in terms of data usage."}, {"fullname_first_author": "Arnold Overwijk", "paper_title": "ClueWeb22: 10 billion web documents with visual and semantic information", "publication_date": "2022-00-00", "reason": "This paper describes ClueWeb22, the dataset used for the experiments in the paper, providing context and background for the experimental evaluation."}]}