<table id='3' style='font-size:14px'><tr><td></td><td>The First Stage</td><td>The Second Stage</td></tr><tr><td>Training budget</td><td>300B</td><td>100B</td></tr><tr><td>Maximum learning rate</td><td>6e-5</td><td>2e-5</td></tr><tr><td>Final learning rate</td><td>6e-6</td><td>1e-6</td></tr><tr><td>LR warmup iters</td><td>50</td><td>50</td></tr><tr><td>Sequence length</td><td>8192</td><td>8192</td></tr><tr><td>Batch size (tokens)</td><td>16M</td><td>16M</td></tr><tr><td>B for Lb</td><td>-</td><td>0.01</td></tr><tr><td>Tensor parallel</td><td>2</td><td>1</td></tr><tr><td>Pipeline parallel</td><td>1</td><td>8</td></tr></table>