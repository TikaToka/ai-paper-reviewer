[{"content": "| Models | Resolution | Image | Region output | Region Decoder | Pixel Grounding | End to End Model | \n|---|---|---|---|---|---|---|\n| RSGPT (Hu et al., 2023) | 224 \u00d7 224 | \u2713 | \u00d7 | \u00d7 | \u00d7 | \u2713 | \n| H2RSVLM (Pang et al., 2024) | 336 \u00d7 336 | \u2713 | \u00d7 | \u00d7 | \u00d7 | \u2713 | \n| RS-LLaVA (Bazi et al., 2024) | 336 \u00d7 336 | \u2713 | \u00d7 | \u00d7 | \u00d7 | \u2713 | \n| GeoChat (Kuckreja et al., 2024) | 504 \u00d7 504 | \u2713 | \u2713 | \u00d7 | \u00d7 | \u2713 | \n| SkyEyeGPT (Zhan et al., 2024) | 448 \u00d7 448 | \u2713 | \u2713 | \u00d7 | \u00d7 | \u2713 | \n| EarthGPT (Zhang et al., 2024c) | - | \u2713 | \u2713 | \u00d7 | \u00d7 | \u2713 | \n| LHRS-Bot (Muhtar et al., 2024) | 224\u00d7224 | \u2713 | \u2713 | \u00d7 | \u00d7 | \u2713 | \n| SkySenseGPT (Luo et al., 2024) | 504 \u00d7 504 | \u2713 | \u2713 | \u00d7 | \u00d7 | \u2713 | \n| GeoPixel | dynamic upto 4k | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |", "caption": "Table 1: Comparison of remote sensing large multimodal models (RS-LMMs), focusing on their grounding capabilities. The \u2018Region Output\u2019 column highlights the model\u2019s ability to associate objects with specific spatial regions. Existing models primarily utilize LLMs to generate bounding box coordinates for object grounding. However, none of the current RS-LMMs possess the capability for \u2018pixel grounding\u2019, i.e., generating detailed segmentation masks, which are crucial for fine-grained spatial interpretation.", "description": "\ud45c 1\uc740 \uc6d0\uaca9 \uac10\uc9c0 \ub300\uaddc\ubaa8 \ub2e4\uc911 \ubaa8\ub4dc \ubaa8\ub378(RS-LMM)\uc744 \ube44\uad50\ud558\uace0, \ud2b9\ud788 \uac1d\uccb4 \uc811\uc9c0 \uae30\ub2a5\uc5d0 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4. '\uc601\uc5ed \ucd9c\ub825' \uc5f4\uc740 \uac1d\uccb4\ub97c \ud2b9\uc815 \uacf5\uac04 \uc601\uc5ed\uacfc \uc5f0\uacb0\ud558\ub294 \ubaa8\ub378\uc758 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 \ubaa8\ub378\uc740 \uc8fc\ub85c LLM\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac1d\uccb4 \uc811\uc9c0\ub97c \uc704\ud55c \uacbd\uacc4 \uc0c1\uc790 \uc88c\ud45c\ub97c \uc0dd\uc131\ud558\uc9c0\ub9cc, \ud604\uc7ac RS-LMM \uc911 \uc5b4\ub5a4 \uac83\ub3c4 '\ud53d\uc140 \uc811\uc9c0' \uae30\ub2a5, \uc989 \uc138\ubc00\ud55c \uacf5\uac04 \ud574\uc11d\uc5d0 \uc911\uc694\ud55c \uc0c1\uc138 \ubd84\ud560 \ub9c8\uc2a4\ud06c \uc0dd\uc131 \uae30\ub2a5\uc744 \uac16\ucd94\uace0 \uc788\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "3. Method"}, {"content": "| Model | CIDEr | METEOR | Uni-Target AP50 | Uni-Target mIoU | Uni-Target Recall | Multi-Target AP50 | Multi-Target mIoU | Multi-Target Recall | Overall AP50 | Overall mIoU | Overall Recall |\n|---|---|---|---|---|---|---|---|---|---|---|---| \n| GLaMM<sub>(CVPR'24)</sub> | 0.1 | 5.8 | 1.2 | 18.1 | 14.8 | 0.5 | 16.5 | 6.3 | 0.5 | 16.9 | 7.1 |\n| LISA\u2020<sub>(CVPR'24)</sub> | 14.6 | 22.3 | 9.5 | 41.7 | 43.1 | 8.3 | 43.1 | 27.5 | 8.5 | 42.7 | 29.0 |\n| PixelLM\u2020<sub>(CVPR'24)</sub> | 18.3 | 22.5 | 13.5 | 41.2 | 44.0 | 10.4 | 42.9 | 28.1 | 10.5 | 42.4 | 29.6 |\n| GLaMM-ft<sub>(CVPR'24)</sub> | 15.7 | 23.0 | 18.8 | 44.4 | 48.5 | 12.4 | 47.1 | 31.1 | 12.5 | 46.4 | 32.8 |\n| GeoPixel | **21.6** | **24.0** | **25.5** | **50.8** | **55.6** | **18.0** | **52.9** | **37.0** | **19.0** | **52.3** | **38.8** |", "caption": "Table 2: Performance Comparison on RS-GCG task. LISA\u2020\u2020\\dagger\u2020 and PixelLM\u2020\u2020\\dagger\u2020 denote the pretrained LISA and PixelLM models adopted for RS-GCG and finetuned on GeoPixelD training data. GLaMM represents the zero-shot performance, whereas GLaMM-FT refers to the pretrained model finetuned on GeoPixelD. GeoPixel outperforms other models across all metrics.", "description": "\ud45c 2\ub294 \uc6d0\uaca9 \uac10\uc9c0 \uae30\ubc18 \ub300\ud654 \uc0dd\uc131(RS-GCG) \uc791\uc5c5\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LISA\u2020\uc640 PixelLM\u2020\ub294 RS-GCG\uc5d0 \uc801\uc6a9\ud558\uace0 GeoPixelD \ud559\uc2b5 \ub370\uc774\ud130\ub85c \ubbf8\uc138 \uc870\uc815\ub41c \uc0ac\uc804 \ud559\uc2b5\ub41c LISA \ubc0f PixelLM \ubaa8\ub378\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. GLaMM\uc740 \uc81c\ub85c\uc0f7(zero-shot) \uc131\ub2a5\uc744, GLaMM-FT\ub294 GeoPixelD\ub85c \ubbf8\uc138 \uc870\uc815\ub41c \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. GeoPixel\uc740 \ubaa8\ub4e0 \ud3c9\uac00 \uc9c0\ud45c\uc5d0\uc11c \ub2e4\ub978 \ubaa8\ub378\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 CIDEr, METEOR, AP50, mIoU, \uc7ac\ud604\uc728(Recall)\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc9c0\ud45c\uac00 \ub2e8\uc77c \ub300\uc0c1, \ub2e4\uc911 \ub300\uc0c1 \ubc0f \uc804\uccb4 \uc138 \uac00\uc9c0 \ubc94\uc8fc\ub85c \ub098\ub258\uc5b4 \uc81c\uc2dc\ub429\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Method | Validation Set |  |  | Test Set |  |  |\n|---|---|---|---|---|---|---|\n|  | P@0.5 | oIoU | mIoU | P@0.5 | oIoU | mIoU |\n| RRN (Li et al., 2018) | 51.09 | 66.53 | 46.06 | 51.07 | 66.43 | 45.64 |\n| CSMA (Ye et al., 2019) | 55.68 | 69.68 | 48.85 | 55.32 | 69.39 | 48.54 |\n| LSCM (Hui et al., 2020) | 57.12 | 69.28 | 50.36 | 56.02 | 69.05 | 49.92 |\n| CMPC (Huang et al., 2020) | 57.93 | 70.15 | 50.41 | 55.83 | 69.22 | 49.24 |\n| BRINet (Hu et al., 2020) | 58.79 | 70.73 | 51.14 | 56.90 | 69.88 | 49.65 |\n| CMPC+ (Liu et al., 2022) | 59.19 | 70.14 | 51.41 | 57.65 | 68.64 | 50.24 |\n| LGCE (Yuan et al., 2024) | 68.10 | 76.68 | 60.16 | 67.65 | 76.34 | 59.37 |\n| LAVT (Yang et al., 2024) | 69.54 | 77.59 | 61.46 | 69.52 | 77.19 | 61.04 |\n| RMSIN (Liu et al., 2024c) | 74.66 | 78.27 | 65.10 | 74.26 | 77.79 | 64.20 |\n| Geopixel-ft | **80.00** | **81.77** | **67.99** | **83.33** | **84.90** | **67.30** |", "caption": "Table 3: Performance Comparison of GeoPixel in Referring Expression Segmentation on RRSIS-D dataset. The segmentation accuracy based on referring expressions is expressed through the Precision at IoU threshold of 0.5 (P@0.5), Overall Intersection-over-Union (oIoU) and Mean Intersection-over-Union (mIoU).", "description": "\ud45c 3\uc740 GeoPixel \ubaa8\ub378\uc758 RRSIS-D \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ucc38\uc870 \ud45c\ud604 \ubd84\ud560 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucc38\uc870 \ud45c\ud604\uc744 \uae30\ubc18\uc73c\ub85c \ud55c \ubd84\ud560 \uc815\ud655\ub3c4\ub294 IoU \uc784\uacc4\uac12 0.5\uc5d0\uc11c\uc758 \uc815\ubc00\ub3c4(P@0.5), \uc804\uccb4 \uad50\ucc28 \ud569\uc9d1\ud569 \ube44\uc728(oIoU), \ud3c9\uade0 \uad50\ucc28 \ud569\uc9d1\ud569 \ube44\uc728(mIoU) \uc138 \uac00\uc9c0 \uc9c0\ud45c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec GeoPixel\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Training | Inference | CIDEr | METEOR | AP50 | mIoU | Recall |\n|---|---|---|---|---|---|---|\n| $\nmathcal{P}=9$ | $\nmathcal{P}=1$ | 14.6 | 23.1 | 12.9 | 47.8 | 32.2 |\n| $\nmathcal{P}=4$ |  | 17.7 | 23.9 | 16.6 | 51.8 | 37.1 |\n| $\nmathcal{P}=9$ |  | **20.5** | **24.3** | **17.6** | **52.1** | **37.4** |", "caption": "Table 4: Effect of Inference Resolution. Reported metrics show the relationship between resolution and overall performance.", "description": "\ud45c 4\ub294 \ucd94\ub860 \ud574\uc0c1\ub3c4\uc758 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf4\uace0\ub41c \uc9c0\ud45c\ub294 \ud574\uc0c1\ub3c4\uc640 \uc804\ubc18\uc801\uc778 \uc131\ub2a5 \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ub2e4\uc591\ud55c \ud328\uce58 \uc218 (P)\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd94\ub860\uc744 \uc218\ud589\ud588\uc744 \ub54c CIDEr, METEOR, AP50, mIoU, \uc7ac\ud604\uc728\uacfc \uac19\uc740 \uc5ec\ub7ec \uc131\ub2a5 \uc9c0\ud45c\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ud574\uc0c1\ub3c4\uac00 \ubaa8\ub378\uc758 \uc131\ub2a5, \ud2b9\ud788 \uc774\ubbf8\uc9c0\uc758 \uc2dc\ub9e8\ud2f1 \uc774\ud574\uc640 \uac1d\uccb4 \uc704\uce58 \ud30c\uc545\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc989, \uc785\ub825 \uc774\ubbf8\uc9c0\ub97c \uc5bc\ub9c8\ub098 \uc138\ubd84\ud654\ud574\uc11c \ucc98\ub9ac\ud558\ub294\uc9c0\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \ub2ec\ub77c\uc9d0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.4. Ablation Study"}, {"content": "| Data | Objects | Phrases | Avg. Len | mIoU | Recall |\n|---|---|---|---|---|---|---|\n| Instances only | 1,740 | 1,740 | 634 | 58.4 | 48.8 |\n| Semantic only | 21,483 | 698 | 518 | 44.1 | 37.7 |\n| Mix data | 38,161 | 2,989 | 737 | 50.9 | 33.3 |", "caption": "Table 5: Effect of Annotation Complexity. Avg. Len is the average character length of captions.", "description": "\ud45c 5\ub294 \uc8fc\uc11d\uc758 \ubcf5\uc7a1\uc131\uc774 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ub2e4\ub978 \uc8fc\uc11d \uc720\ud615(\uc778\uc2a4\ud134\uc2a4 \uc804\uc6a9, \uc758\ubbf8\ub860\uc801 \uc804\uc6a9, \ud63c\ud569 \ub370\uc774\ud130)\uc5d0 \ub530\ub978 \ud3c9\uade0 \ubb38\uc7a5 \uae38\uc774(Avg. Len), \ud3c9\uade0 IoU(mIoU) \ubc0f \uc7ac\ud604\uc728(Recall)\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uc8fc\uc11d \ubcf5\uc7a1\ub3c4\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ubaa8\ub378 \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \ud63c\ud569 \ub370\uc774\ud130\uc14b\uc758 \uacbd\uc6b0 \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uac00\uc7a5 \ub0ae\uc740 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. GeoPixelD-RS Pixel Grounding Dataset"}, {"content": "| Training Data | VP | CIDEr | METEOR | AP50 | mIoU | Recall |\n|---|---|---|---|---|---|---|---|\n| Set-1A | Set-1B |  |  |  |  |  |  |\n| \u2713 |  | T | 19.3 | 23.6 | 18.2 | 48.0 | 33.6 |\n| \u2713 | \u2713 | T | 20.5 | 24.0 | 17.8 | 51.7 | 36.7 |\n| \u2713 | \u2713 | F | 18.7 | 24.4 | 15.3 | 51.6 | 35.1 |", "caption": "Table 6: Effect of Data Complexity and Training Vision Projection (VP) Layer. T stands for Trainable and F for Frozen.", "description": "\ud45c 6\uc740 \ub370\uc774\ud130 \ubcf5\uc7a1\uc131\uacfc \ud6c8\ub828\ub41c \ube44\uc804 \ud22c\uc601(VP) \ub808\uc774\uc5b4\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'T'\ub294 \ud6c8\ub828 \uac00\ub2a5\ud568\uc744, 'F'\ub294 \uace0\uc815\ub428\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \uc11c\ub85c \ub2e4\ub978 \ub370\uc774\ud130 \ubcf5\uc7a1\uc131 \uc218\uc900(Set-1A\uc640 Set-1B)\uc5d0\uc11c \ube44\uc804 \ud22c\uc601 \ub808\uc774\uc5b4\ub97c \ud6c8\ub828\uc2dc\ud0a4\uac70\ub098 \uace0\uc815\uc2dc\ucf30\uc744 \ub54c\uc758 \uc131\ub2a5 \uc9c0\ud45c(CIDER, METEOR, AP50, mIoU, RECALL) \ubcc0\ud654\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \ub370\uc774\ud130 \ubcf5\uc7a1\uc131\uacfc \ube44\uc804 \ud22c\uc601 \ub808\uc774\uc5b4 \ud6c8\ub828 \uc5ec\ubd80\uac00 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "5.4. Ablation Study"}]