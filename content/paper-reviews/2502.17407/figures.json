[{"figure_path": "https://arxiv.org/html/2502.17407/x1.png", "caption": "Figure 1: Performance of Qwen2.5-1.5B-Math with different test-time scaling strategies.\u2014\u2014Once configured to use comparable inference FLOPs, all three methods (Outcome Reward Modeling, Process Reward Modeling, and Budget Forcing) achieve similar performance.", "description": "\ubcf8 \uadf8\ub9bc\uc740 Qwen2.5-1.5B-Math \ubaa8\ub378\uc5d0 \uc138 \uac00\uc9c0 \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5 \ubc29\ubc95(Outcome Reward Modeling, Process Reward Modeling, Budget Forcing)\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 \ube44\uc2b7\ud55c \uc218\uc900\uc758 \ucd94\ub860 FLOPs(Floating Point Operations)\ub97c \uc0ac\uc6a9\ud558\ub3c4\ub85d \uc124\uc815\ub418\uc5c8\uc73c\uba70, \uacb0\uacfc\uc801\uc73c\ub85c \uc138 \uac00\uc9c0 \ubc29\ubc95 \ubaa8\ub450 \uc720\uc0ac\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5 \ubc29\ubc95\ub4e4\uc774 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc788\uc5b4 \uc720\uc0ac\ud55c \ud6a8\uacfc\ub97c \uac00\uc9c8 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3.1 Baselines: Test-Time Scaling Strategies"}, {"figure_path": "https://arxiv.org/html/2502.17407/x2.png", "caption": "Figure 2: Comparison of different inference-time scaling strategies. Blue boxes represent selected outputs, while red boxes indicate rejected ones.", "description": "\uadf8\ub9bc 2\ub294 \uc138 \uac00\uc9c0 \uc11c\ub85c \ub2e4\ub978 \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5 \uc804\ub7b5(\uacb0\uacfc \ubcf4\uc0c1 \ubaa8\ub378\ub9c1, \ud504\ub85c\uc138\uc2a4 \ubcf4\uc0c1 \ubaa8\ub378\ub9c1 \ubc0f \uc608\uc0b0 \uac15\uc81c)\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \uc804\ub7b5\uc740 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc5ec\ub7ec \uc751\ub2f5 \ud6c4\ubcf4 \uc911\uc5d0\uc11c \ucd5c\uc885 \ucd9c\ub825\uc73c\ub85c \uc120\ud0dd\ub41c \uc751\ub2f5(\ud30c\ub780\uc0c9 \uc0c1\uc790)\uacfc \uae30\uac01\ub41c \uc751\ub2f5(\ube68\uac04\uc0c9 \uc0c1\uc790)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 \uac01 \uc804\ub7b5\uc758 \uc758\uc0ac\uacb0\uc815 \uacfc\uc815\uacfc \uadf8 \ucc28\uc774\uc810\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.1 \uae30\uc900: \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5 \uc804\ub7b5"}, {"figure_path": "https://arxiv.org/html/2502.17407/x3.png", "caption": "Figure 3: # of generated tokens for 1.5B and 7B models in a greedy setting, divided by correctness. Languages are represented as scatter plots, overlaid on box plots.", "description": "\uc774 \uadf8\ub9bc\uc740 \ud0d0\uc695\uc801 \uc124\uc815\uc5d0\uc11c 15\uc5b5 \ubc0f 70\uc5b5 \ub9e4\uac1c\ubcc0\uc218 \ubaa8\ub378\uc5d0 \ub300\ud574 \uc0dd\uc131\ub41c \ud1a0\ud070\uc758 \uc218\ub97c \uc815\ud655\uc131\uc73c\ub85c \ub098\ub208 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc5b8\uc5b4\ub294 \uc0c1\uc790 \uadf8\ub9bc \uc704\uc5d0 \uc0b0\uc810\ub3c4\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc0c1\uc790 \uadf8\ub9bc\uc740 \uac01 \uc5b8\uc5b4\uc5d0 \ub300\ud55c \uc0dd\uc131\ub41c \ud1a0\ud070 \uc218\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\uace0, \uc0b0\uc810\ub3c4\ub294 \uac01 \uc5b8\uc5b4\uc5d0 \ub300\ud55c \uac1c\ubcc4 \ub370\uc774\ud130 \ud3ec\uc778\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \ud06c\uae30\uac00 \ub2e4\uc591\ud55c \uc5b8\uc5b4\uc5d0 \uac78\uccd0 \uc0dd\uc131\ub41c \uc751\ub2f5\uc758 \uae38\uc774\uc640 \uc815\ud655\uc131\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 \ucd94\ub860 FLOP \uacc4\uc0b0"}, {"figure_path": "https://arxiv.org/html/2502.17407/x4.png", "caption": "Figure 4: Gains of ORM compared to a greedy-decoding baseline. The semi-transparent \u201ccloud\u201d indicates the 2D data distribution via a KDE density plot, and the overlaid lines are third-order polynomial regressions modeling how each ORM setting scales with the baseline score.", "description": "\uadf8\ub9bc 4\ub294 \ub2e4\uc591\ud55c K \uac12(2, 4, 8)\uc744 \uac16\ub294 ORM(Outcome Reward Modeling) \uc124\uc815\uc5d0\uc11c \uadf8\ub9ac\ub514 \ub514\ucf54\ub529 \uae30\uc900\uc120\uacfc \ube44\uad50\ud558\uc5ec \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc18\ud22c\uba85\ud55c \u2018\uad6c\ub984\u2019\uc740 KDE \ubc00\ub3c4 \ud50c\ub86f\uc744 \ud1b5\ud574 2\ucc28\uc6d0 \ub370\uc774\ud130 \ubd84\ud3ec\ub97c \ub098\ud0c0\ub0b4\uace0, \uacb9\uccd0\uc9c4 3\ucc28 \ub2e4\ud56d\uc2dd \ud68c\uadc0\uc120\uc740 \uac01 ORM \uc124\uc815\uc774 \uae30\uc900\uc120 \uc810\uc218\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, x\ucd95\uc740 \uae30\uc900\uc120 \uc810\uc218, y\ucd95\uc740 ORM \uc124\uc815\uc5d0 \ub530\ub978 \uc131\ub2a5 \ud5a5\uc0c1(\uae30\uc900\uc120 \uc810\uc218 \ub300\ube44 \uc0c1\ub300\uc801 \uc99d\uac00\ubd84)\uc744 \ub098\ud0c0\ub0b4\uba70, \uac01 \uc810\uc740 \ud2b9\uc815 \uc5b8\uc5b4\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c, \ud68c\uadc0\uc120\uc740 \uc804\ubc18\uc801\uc778 \uacbd\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 MT-MATH100 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub294 K \uac12\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \uc77c\uad00\ub418\uac8c \ud5a5\uc0c1\ub418\ub294 \ubc18\uba74, MT-AIME2024 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub294 K \uac12\uc758 \ubcc0\ud654\uc5d0 \ub530\ub978 \uc131\ub2a5 \ud5a5\uc0c1\uc774 \ubbf8\ubbf8\ud558\uac70\ub098, \uacbd\uc6b0\uc5d0 \ub530\ub77c\uc11c\ub294 \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 ORM\uc774 \uc5b4\ub824\uc6b4 \ubb38\uc81c\uc5d0 \ub300\ud574\uc11c\ub294 \ubaa8\ub4e0 \uc5b8\uc5b4\uc5d0\uc11c \uc77c\uad00\ub41c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uac00\uc838\uc624\uc9c0 \ubabb\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4 Result 1: ORM and PRM"}, {"figure_path": "https://arxiv.org/html/2502.17407/x5.png", "caption": "Figure 5: PRM inference FLOPs as a function of generation steps S\ud835\udc46Sitalic_S and candidates per step c\ud835\udc50citalic_c. The left panel uses a verifier size of 72B, while the right panel uses a 7B RM, displaying adjusted configurations to yield similar costs.", "description": "\uadf8\ub9bc 5\ub294 Process Reward Modeling (PRM)\uc758 \ucd94\ub860 \uc5f0\uc0b0\ub7c9(FLOPs)\uc744 \uc0dd\uc131 \ub2e8\uacc4 \uc218(S)\uc640 \uac01 \ub2e8\uacc4\ub2f9 \ud6c4\ubcf4 \uc218(c)\uc758 \ud568\uc218\ub85c \ub098\ud0c0\ub0b8 \uac83\uc785\ub2c8\ub2e4. \uc67c\ucabd \ud328\ub110\uc740 72B \ud06c\uae30\uc758 \uac80\uc99d\uae30\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc6b0\ub97c, \uc624\ub978\ucabd \ud328\ub110\uc740 7B \ud06c\uae30\uc758 RM\uc744 \uc0ac\uc6a9\ud55c \uacbd\uc6b0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uacbd\uc6b0 \ubaa8\ub450 \ube44\uc2b7\ud55c \ube44\uc6a9\uc744 \uc5bb\ub3c4\ub85d \uc124\uc815\uc744 \uc870\uc815\ud588\uc2b5\ub2c8\ub2e4.  \uc989, \uc11c\ub85c \ub2e4\ub978 \ud06c\uae30\uc758 \uac80\uc99d\uae30\ub97c \uc0ac\uc6a9\ud558\ub354\ub77c\ub3c4 \ube44\uc2b7\ud55c \uacc4\uc0b0 \ube44\uc6a9\uc744 \uac16\ub3c4\ub85d PRM\uc758 \uc124\uc815\uc744 \uc870\uc815\ud558\uc5ec \ube44\uad50 \ubd84\uc11d\uc744 \uc218\ud589\ud588\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1 Baselines: Test-Time Scaling Strategies"}, {"figure_path": "https://arxiv.org/html/2502.17407/x6.png", "caption": "Figure 6: Inference FLOPs versus PRM performance and consistency. (Left) Second-degree polynomial regressions for average performance on 14 languages, comparing the 7B (blue) and 72B (green) reward models. (Right) Fleiss\u2019 kappa (top) and standard deviation (bottom) plotted against the same FLOPs budget; the fitted curves reveal no clear monotonic trend.", "description": "\uadf8\ub9bc 6\uc740 PRM(Process Reward Modeling)\uc758 \ucd94\ub860 \uc5f0\uc0b0\ub7c9(FLOPs)\uacfc \uc131\ub2a5 \ubc0f \uc77c\uad00\uc131 \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub9bc\uc740 14\uac1c \uc5b8\uc5b4\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\ub294 2\ucc28 \ub2e4\ud56d\uc2dd \ud68c\uadc0\uc120\uc744 \ubcf4\uc5ec\uc8fc\uba70, \ubcf4\uc0c1 \ubaa8\ub378\uc758 \ud06c\uae30(\ub9e4\uac1c\ubcc0\uc218 \uc218)\uc5d0 \ub530\ub978 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud30c\ub780\uc0c9\uc740 7B \ub9e4\uac1c\ubcc0\uc218 \ubaa8\ub378, \ub179\uc0c9\uc740 72B \ub9e4\uac1c\ubcc0\uc218 \ubaa8\ub378\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub9bc\uc740 \ub3d9\uc77c\ud55c FLOPs \uc608\uc0b0\uc5d0 \ub300\ud55c Fleiss\u2019 kappa(\uc77c\uad00\uc131 \uce21\uc815 \uc9c0\ud45c)\uc640 \ud45c\uc900 \ud3b8\ucc28\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub54c, \uba85\ud655\ud55c \ub2e8\uc870 \uad00\uacc4\ub294 \uad00\ucc30\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "3.2 \ucd94\ub860 FLOPs \uacc4\uc0b0"}, {"figure_path": "https://arxiv.org/html/2502.17407/x7.png", "caption": "Figure 7: Comparison of PRM vs. ORM performance on MATH (solid lines) and AIME (dashed lines). 1.5B models are shown with plus markers, 7B models with stars. Blue lines represent PRM, green lines represent ORM. White box annotations indicate the performance difference (ORM \u2212 PRM) at the highest compute setting for each line.", "description": "\uadf8\ub9bc 7\uc740 MATH \ubc0f AIME \ub370\uc774\ud130\uc14b\uc5d0\uc11c PRM\uacfc ORM\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uc2e4\uc120\uc740 MATH \ub370\uc774\ud130\uc14b, \uc810\uc120\uc740 AIME \ub370\uc774\ud130\uc14b\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  '+' \ub9c8\ucee4\ub294 1.5B \ubaa8\ub378, '*' \ub9c8\ucee4\ub294 7B \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud30c\ub780\uc0c9 \uc120\uc740 PRM, \ub179\uc0c9 \uc120\uc740 ORM\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \uc120\uc758 \uac00\uc7a5 \ub192\uc740 \ucef4\ud4e8\ud305 \uc124\uc815\uc5d0\uc11c ORM\uacfc PRM\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ud770\uc0c9 \uc0c1\uc790 \uc8fc\uc11d\uc73c\ub85c \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uac01 \ubaa8\ub378\uc758 \ud06c\uae30\uc640 \uc0ac\uc6a9\ub41c \uacc4\uc0b0 \ub9ac\uc18c\uc2a4\uc5d0 \ub530\ub978 \uc0c1\ub300\uc801 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 Result 1: ORM and PRM"}, {"figure_path": "https://arxiv.org/html/2502.17407/x8.png", "caption": "Figure 8: Performance of Qwen2.5-Math-1.5B +SFT and + MT-SFT at each training checkpoint. Average score and error bars for each checkpoint are displayed. The shaded region is the mean \u00b1plus-or-minus\\pm\u00b1 standard deviation for MT-SFT.", "description": "\uadf8\ub9bc 8\uc740 Qwen2.5-Math-1.5B \ubaa8\ub378\uc5d0 \ub300\ud574 SFT(Supervised Fine-Tuning)\uc640 MT-SFT(\ub2e4\uad6d\uc5b4 SFT)\ub97c \uc801\uc6a9\ud588\uc744 \ub54c, \uac01 \ud559\uc2b5 \uccb4\ud06c\ud3ec\uc778\ud2b8\ubcc4 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  y\ucd95\uc740 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ub098\ud0c0\ub0b4\uace0, x\ucd95\uc740 \ud559\uc2b5 \uc9c4\ud589 \ub2e8\uacc4(checkpoint)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc5d0\ub7ec \ubc14\ub294 \uac01 \uccb4\ud06c\ud3ec\uc778\ud2b8\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4 \ud45c\uc900\ud3b8\ucc28\ub97c \ub098\ud0c0\ub0b4\uba70, MT-SFT\uc758 \ud3c9\uade0 \u00b1 \ud45c\uc900\ud3b8\ucc28 \ubc94\uc704\ub294 \uc74c\uc601\uc73c\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc989, \uc774 \uadf8\ub798\ud504\ub294 \ub450 \uac00\uc9c0 fine-tuning \ubc29\ubc95\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ud559\uc2b5 \uacfc\uc815\uc5d0 \ub530\ub77c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MT-SFT\ub294 \ub2e4\uad6d\uc5b4 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud588\uc73c\ubbc0\ub85c, \ub2e8\uc77c \uc5b8\uc5b4 \ub370\uc774\ud130\ub9cc\uc744 \uc0ac\uc6a9\ud55c SFT\ubcf4\ub2e4 \ucd08\uae30 \uc131\ub2a5\uc740 \ub2e4\uc18c \ub0ae\uc9c0\ub9cc, \ud559\uc2b5\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5 Result 2: Budget Forcing"}, {"figure_path": "https://arxiv.org/html/2502.17407/x9.png", "caption": "Figure 9: Performance of MR1 on MT-AIME2024 at B\u2062F={2048,4096,8192}\ud835\udc35\ud835\udc39204840968192BF=\\{2048,4096,8192\\}italic_B italic_F = { 2048 , 4096 , 8192 }. Grey dots represent individual languages. Solid lines indicate average performance, while dashed lines highlight reference performances for selected languages.", "description": "\uadf8\ub9bc 9\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4\uc5d0 \ub300\ud55c MT-AIME2024 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc138 \uac00\uc9c0 \ub2e4\ub978 \ubc84\uc9d3(2048, 4096, 8192 \ud1a0\ud070)\uc744 \uc0ac\uc6a9\ud55c MR1 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud68c\uc0c9 \uc810\uc740 \uac1c\ubcc4 \uc5b8\uc5b4\ub97c \ub098\ud0c0\ub0b4\uace0, \uc2e4\uc120\uc740 \ud3c9\uade0 \uc131\ub2a5\uc744, \uc810\uc120\uc740 \ud2b9\uc815 \uc5b8\uc5b4\uc5d0 \ub300\ud55c \uae30\uc900 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5 \uae30\ubc95\uc778 BF(Budget Forcing)\uc774 \uc5b8\uc5b4 \uac04\uc5d0 \uc5bc\ub9c8\ub098 \uc798 \uc77c\ubc18\ud654\ub418\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \uc790\ub8cc\uc785\ub2c8\ub2e4. \uac01 \ubc84\uc9d3\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 \ud2b9\uc815 \uc5b8\uc5b4\uc5d0\uc11c\uc758 \uc131\ub2a5\uc774 \ud3c9\uade0 \uc131\ub2a5\uacfc \uc5b4\ub5bb\uac8c \ub2e4\ub978\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5 Result 2: Budget Forcing"}, {"figure_path": "https://arxiv.org/html/2502.17407/x10.png", "caption": "Figure 10: Heatmap representation of IMO problems from 2006 to 2024. Each row corresponds to a competition year, and each column represents a problem (Q1\u2013Q6). Green cells indicate questions that have been included in the M-IMO subset, while gray cells represent problems that were not selected.", "description": "\uadf8\ub9bc 10\uc740 2006\ub144\ubd80\ud130 2024\ub144\uae4c\uc9c0\uc758 IMO(International Mathematical Olympiad) \ubb38\uc81c\ub4e4\uc758 \ud788\ud2b8\ub9f5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub300\ud68c \uc5f0\ub3c4\uc5d0 \ud574\ub2f9\ud558\uba70, \uac01 \uc5f4\uc740 \ubb38\uc81c(Q1~Q6)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucd08\ub85d\uc0c9 \uc140\uc740 M-IMO \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \ubb38\uc81c\ub97c, \ud68c\uc0c9 \uc140\uc740 \uc120\ud0dd\ub418\uc9c0 \uc54a\uc740 \ubb38\uc81c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 M-IMO \ub370\uc774\ud130\uc14b\uc774 \uc5b4\ub5a4 \uae30\uc900\uc73c\ub85c IMO \ubb38\uc81c\ub4e4\uc744 \uc120\ud0dd\ud588\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2 Multilingual Competition Level Math"}, {"figure_path": "https://arxiv.org/html/2502.17407/x11.png", "caption": "Figure 11: Solve rates (%) of different multilingual math datasets evaluated. For the OLMo2 series, we use the base models, while for the Qwen2.5 series, the instruct-tuned variants are used. Euler-Instruct presents a significantly lower solve rate, indicating its greater difficulty.", "description": "\uadf8\ub9bc 11\uc740 \ub2e4\uc591\ud55c \ub2e4\uad6d\uc5b4 \uc218\ud559 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \ud3c9\uac00\ub41c \ud480\uc774 \uc131\uacf5\ub960(%)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OLMo2 \uacc4\uc5f4\uc758 \uacbd\uc6b0 \uae30\ubcf8 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud588\uace0, Qwen2.5 \uacc4\uc5f4\uc758 \uacbd\uc6b0 instruction-tuning\ub41c \ubcc0\ud615 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. Euler-Instruct \ub370\uc774\ud130\uc14b\uc740 \uc0c1\ub2f9\ud788 \ub0ae\uc740 \ud480\uc774 \uc131\uacf5\ub960\uc744 \ubcf4\uc5ec\uc8fc\uc5b4, \ud574\ub2f9 \ub370\uc774\ud130\uc14b\uc758 \ub09c\uc774\ub3c4\uac00 \ub192\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc640 \uc885\ub958\uc758 \uc5b8\uc5b4 \ubaa8\ub378\uc774 \ub2e4\uad6d\uc5b4 \uc218\ud559 \ubb38\uc81c \ud480\uc774\uc5d0 \ub300\ud574 \uc5b4\ub5a4 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "3.1 \uae30\uc900: \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \uc2a4\ucf00\uc77c\ub9c1 \uc804\ub7b5"}, {"figure_path": "https://arxiv.org/html/2502.17407/x12.png", "caption": "Figure 12: Model Results from Table\u00a09. Left shows accuracy on MT-MATH500 (entire translated subset for language group (B)), and right shows average performance of MT-AIME2024.", "description": "\uadf8\ub9bc 12\ub294 \ud45c 9\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 55\uac1c \uc5b8\uc5b4 \uc911 14\uac1c \uc5b8\uc5b4(\uc5b8\uc5b4 \uadf8\ub8f9 B)\ub85c \ubc88\uc5ed\ub41c MT-MATH500 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uace0, \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 MT-AIME2024 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uadf8\ub798\ud504\ub294 \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uc591\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uac1c\uc758 \ub370\uc774\ud130 \ud3ec\uc778\ud2b8\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \uaddc\ubaa8\uc758 \ud6c8\ub828 \ub370\uc774\ud130\uac00 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uacfc \ub2e4\uad6d\uc5b4 \ubaa8\ub378 \ud559\uc2b5 \uc2dc \ub370\uc774\ud130\uc14b \ud06c\uae30\uc758 \uc911\uc694\uc131\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.1 \uae30\uc900: \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \uc2a4\ucf00\uc77c\ub9c1 \uc804\ub7b5"}]