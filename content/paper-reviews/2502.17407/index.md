---
title: "Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning"
summary: "ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡ ì—ì„œ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•œ ì—°êµ¬ë¡œ, ë†€ëê²Œë„ ì˜ì–´ì—ì„œë§Œ ì„±ëŠ¥ í–¥ìƒì´ í¬ë‹¤ëŠ” ê²ƒì„ ë°í˜”ìŠµë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Yonsei University",]
showSummary: true
date: 2025-02-24
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.17407 {{< /keyword >}}
{{< keyword icon="writer" >}} Guijin Son et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-25 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.17407" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.17407" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/linguistic-generalizability-of-test-time" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ë³¸ ë…¼ë¬¸ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‚¬ì „ í•™ìŠµ ì»´í“¨íŒ… ê·œëª¨ í™•ì¥ì´ ë‹¤êµ­ì–´ ëŠ¥ë ¥ í–¥ìƒì— íš¨ê³¼ì ì´ì§€ë§Œ, í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì€ ë‹¤êµ­ì–´ ê³¼ì œì— íš¨ê³¼ì ìœ¼ë¡œ ì¼ë°˜í™”ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì„ ë°íˆê³  ìˆìŠµë‹ˆë‹¤.** ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ì£¼ë¡œ ì˜ì–´ì— ì§‘ì¤‘í•˜ì—¬ ë‹¤êµ­ì–´ ëŠ¥ë ¥ì— ëŒ€í•œ ì œí•œì ì¸ ì´í•´ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.  íŠ¹íˆ, í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²•ë“¤ì´ ë‹¤êµ­ì–´ ë¬¸ì œ í•´ê²°ì— ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì´ ì¤‘ìš”í•œ ë¬¸ì œì ìœ¼ë¡œ ì§€ì ë©ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” **55ê°œ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ” ë‹¤êµ­ì–´ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬ MCLMê³¼ í™•ì¥ëœ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°–ì¶˜ ë‹¤êµ­ì–´ LLMì¸ MR1-1.5Bë¥¼ ê°œë°œí•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œì ì„ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤.**  ì„¸ ê°€ì§€ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²•(ORM, PRM, BF)ì„ ì‹¤í—˜í•œ ê²°ê³¼, ì˜ì–´ì—ì„œëŠ” ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìœ¼ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ì—ì„œëŠ” ë¯¸ë¯¸í•œ í–¥ìƒë§Œì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  ì´ëŠ” í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì´ ë‹¤êµ­ì–´ ë¬¸ì œì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©ë˜ì§€ ì•ŠìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ë³¸ ì—°êµ¬ëŠ” ë‹¤êµ­ì–´ ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ê³ , ë‹¤êµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì€ ì˜ì–´ì—ì„œëŠ” íš¨ê³¼ì ì´ì§€ë§Œ, ë‹¤ë¥¸ ì–¸ì–´ë¡œëŠ” ì¼ë°˜í™”ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ìƒˆë¡œìš´ ë‹¤êµ­ì–´ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬ MCLMê³¼ ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ MR1-1.5Bë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²•ì˜ ë‹¤êµ­ì–´ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ë‹¤êµ­ì–´ í™˜ê²½ì—ì„œì˜ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì¤‘ìš”í•œ í†µì°°ë ¥**ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ê³ , ë‹¤êµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì˜ ë°œì „ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, **ìƒˆë¡œìš´ ë‹¤êµ­ì–´ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬ MCLMê³¼ ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ MR1-1.5Bë¥¼ ê³µê°œ**í•˜ì—¬ í›„ì† ì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ë°˜ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.17407/x1.png)

> ğŸ”¼ ë³¸ ê·¸ë¦¼ì€ Qwen2.5-1.5B-Math ëª¨ë¸ì— ì„¸ ê°€ì§€ í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ ë°©ë²•(Outcome Reward Modeling, Process Reward Modeling, Budget Forcing)ì„ ì ìš©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤.  ê° ë°©ë²•ì€ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ ì¶”ë¡  FLOPs(Floating Point Operations)ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ë˜ì—ˆìœ¼ë©°, ê²°ê³¼ì ìœ¼ë¡œ ì„¸ ê°€ì§€ ë°©ë²• ëª¨ë‘ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ ë°©ë²•ë“¤ì´ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì— ìˆì–´ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Performance of Qwen2.5-1.5B-Math with different test-time scaling strategies.â€”â€”Once configured to use comparable inference FLOPs, all three methods (Outcome Reward Modeling, Process Reward Modeling, and Budget Forcing) achieve similar performance.
> </details>





{{< table-caption >}}
| Models | MGSM |
|---|---| 
| Gemma2-9B | 78.37 |
| Qwen2.5-14B-Instruct | 82.27 |
| Qwen2.5-72B-Instruct | 88.16 |
| Mistral-Large | 89.01 |
| GPT-4o-mini | 87.36 |
| o3-mini | **89.30** |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ìˆ˜í•™ ì¶”ë¡  ëŠ¥ë ¥ì„ MGSM(Multilingual General Math Benchmark) ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  2025ë…„ 1ì›” 31ì¼ ë²„ì „ì˜ o3-mini ëª¨ë¸ì„ ì œì™¸í•˜ê³ , ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ì˜ ì ìˆ˜ëŠ” Yang et al.(2024b) ë…¼ë¬¸ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.  í‘œëŠ” ê° ëª¨ë¸ì˜ MGSM ì ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ì–´, ëª¨ë¸ì˜ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ìˆ˜í•™ ì¶”ë¡  ëŠ¥ë ¥ì´ ìš°ìˆ˜í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: MGSM performance of different models. The 2025-01-31 version is used for o3-mini, remaining scores were sourced from the Yang etÂ al. (2024b).
> </details>





### In-depth insights


#### Multilingual Math
ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” ë‹¤êµ­ì–´ ìˆ˜í•™ ë¬¸ì œ í•´ê²°ì˜ í•µì‹¬ì€ **LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì˜ ë‹¤êµ­ì–´ ëŠ¥ë ¥ê³¼ ì¶”ë¡  ëŠ¥ë ¥ì„ ë™ì‹œì— í‰ê°€**í•˜ëŠ” ë° ìˆìŠµë‹ˆë‹¤.  ë‹¨ìˆœíˆ ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ëœ ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ ë¿ ì•„ë‹ˆë¼, **ë¬¸ì œ í•´ê²° ê³¼ì •ì˜ ì¶”ë¡  ê³¼ì •** ë˜í•œ ì¤‘ìš”í•˜ê²Œ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.  ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ë°ì´í„°ì…‹ì˜ í•œê³„ë¥¼ ë„˜ì–´, **ì‹¤ì œ ìˆ˜í•™ ê²½ì‹œëŒ€íšŒ ìˆ˜ì¤€ì˜ ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ë¬¸ì œë“¤ì„ ë‹¤êµ­ì–´ë¡œ ë‹¤ë£¨ëŠ” ì **ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.  ì´ëŠ” LLMì˜ ì§„ì •í•œ ì–¸ì–´ ì´í•´ ë° ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ë”ìš± íš¨ê³¼ì ì´ë©°,  ë‹¨ìˆœí•œ ë²ˆì—­ ëŠ¥ë ¥ì„ ë„˜ì–´ **ê¹Šì´ ìˆëŠ” ì˜ë¯¸ ì´í•´ì™€ ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥**ì„ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ë”°ë¼ì„œ ì´ ì—°êµ¬ëŠ” **LLMì˜ ë‹¤êµ­ì–´ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì˜ í•œê³„ì™€ ê°€ëŠ¥ì„±**ì„ ë™ì‹œì— ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤.  **ë‹¤êµ­ì–´ ì§€ì›ì˜ ë²”ìœ„ì™€ ì„±ëŠ¥ì˜ ê· í˜•**ì„ ì´ë£¨ëŠ” ê²ƒì´ ì•ìœ¼ë¡œì˜ ì—°êµ¬ ê³¼ì œê°€ ë  ê²ƒì…ë‹ˆë‹¤.

#### Test-Time Scaling
ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¬ "Test-Time Scaling"ì€ **ëª¨ë¸ì˜ ì‚¬ì „ í•™ìŠµ ì´í›„, ì¶”ë¡  ë‹¨ê³„ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ê¸°ì¡´ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) í•™ìŠµì€ ë§‰ëŒ€í•œ ì»´í“¨íŒ… ìì›ì„ í•„ìš”ë¡œ í•˜ë©°, ë‹¤êµ­ì–´ ì§€ì›ì˜ ì–´ë ¤ì›€ë„ ì¡´ì¬í–ˆìŠµë‹ˆë‹¤.  Test-Time Scalingì€ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ **ì¶”ë¡  ì‹œì ì— ì¶”ê°€ì ì¸ ì—°ì‚°ì´ë‚˜ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.  ë…¼ë¬¸ì—ì„œëŠ” Outcome Reward Modeling (ORM), Process Reward Modeling (PRM), Budget Forcing (BF) ë“±ì˜ ì„¸ ê°€ì§€ Test-Time Scaling ê¸°ë²•ì„ ë‹¤êµ­ì–´ ìˆ˜í•™ ë¬¸ì œ í’€ì´ì— ì ìš©í•˜ì—¬ í‰ê°€í–ˆìŠµë‹ˆë‹¤.  í¥ë¯¸ë¡­ê²Œë„, **Test-Time Scalingì€ ì˜ì–´ì™€ ê°™ì€ ê³ ìì› ì–¸ì–´ì—ëŠ” íš¨ê³¼ì ì´ì§€ë§Œ, ì €ìì› ì–¸ì–´ì—ì„œëŠ” ì¼ë°˜í™”ê°€ ì˜ ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì **ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” **ì‚¬ì „ í•™ìŠµ ë‹¨ê³„ì˜ ëŒ€ê·œëª¨ ë‹¤êµ­ì–´ í•™ìŠµì´ ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ëŠ¥ë ¥ì— ì¤‘ìš”í•œ ì˜í–¥**ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, í–¥í›„ ì—°êµ¬ëŠ” **Test-Time Scalingì˜ ë‹¤êµ­ì–´ ì¼ë°˜í™” ë¬¸ì œë¥¼ í•´ê²°**í•˜ê³ , ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ì‘ì—…ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ê°œë°œí•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶°ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.

#### Cross-Lingual Gains
ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” "Cross-Lingual Gains"ëŠ” ë‹¤êµ­ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì— ëŒ€í•œ ë‚´ìš©ìœ¼ë¡œ ì¶”ì¸¡ë©ë‹ˆë‹¤. íŠ¹íˆ **ì „ì´ í•™ìŠµ(transfer learning)** ë° **ë‹¤êµ­ì–´ ì‚¬ì „ í›ˆë ¨(multilingual pre-training)**ì˜ íš¨ê³¼ë¥¼ ë‹¤êµ­ì–´ ì¶”ë¡  ê³¼ì œì— ì ìš©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ê°œì„ ì— ì´ˆì ì„ ë§ì¶˜ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ë‹¨ì¼ ì–¸ì–´ ëª¨ë¸ì— ë¹„í•´ ë‹¤êµ­ì–´ ëª¨ë¸ì´ ì—¬ëŸ¬ ì–¸ì–´ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ ì–¸ì–´ì  íŠ¹ì§•ì„ ìŠµë“í•˜ê³ , **ìƒˆë¡œìš´ ì–¸ì–´ì— ëŒ€í•œ ì ì‘ë ¥(adaptability)**ì´ í–¥ìƒë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ë‹¨ìˆœíˆ ë‹¤êµ­ì–´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•Šê³ , **ëª¨ë¸ì˜ êµ¬ì¡° ë° í•™ìŠµ ì „ëµ(model architecture and training strategies)**ì´ ì ì ˆíˆ ì„¤ê³„ë˜ì–´ì•¼ í•¨ì„ ê°•ì¡°í•˜ëŠ” ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ë˜í•œ, **í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥(test-time scaling)** ê¸°ë²•ì„ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ì ê³¼ í•œê³„ì— ëŒ€í•œ ë…¼ì˜ê°€ ìˆì„ ê²ƒìœ¼ë¡œ ë³´ì´ë©°, íŠ¹ì • ì–¸ì–´ì— ëŒ€í•œ ì„±ëŠ¥ ê°œì„ ì´ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì¼ë°˜í™”ë˜ì§€ ì•ŠëŠ” í˜„ìƒ(generalization)ì— ëŒ€í•œ ë¶„ì„ì´ ì£¼ìš” ë‚´ìš©ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë‹¤êµ­ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì€ ë‹¨ìˆœíˆ ë°ì´í„°ì˜ ì–‘ì  ì¦ê°€ë¿ ì•„ë‹ˆë¼, **ëª¨ë¸ì˜ ì„¤ê³„ ë° í•™ìŠµ ë°©ì‹ì˜ ê°œì„ (improvements in model design and learning methods)**ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” ì—°êµ¬ê°€ í•„ìš”í•¨ì„ ê°•ì¡°í•˜ëŠ” ë¶€ë¶„ì´ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Methodology
ë³¸ ë…¼ë¬¸ì˜ ë°©ë²•ë¡ ì€ **ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ê³¼ì œì— ëŒ€í•œ ì„¸ ê°€ì§€ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²•** (Outcome Reward Modeling, Process Reward Modeling, Budget Forcing)ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  ê° ê¸°ë²•ì€ **ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸**ì— ì ìš©ë˜ì–´ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , **ë‹¤ì–‘í•œ ì–¸ì–´ ê°„ì˜ ì„±ëŠ¥ ì¼ê´€ì„±**ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ Fleiss' kappaë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  **ë‹¤êµ­ì–´ ê²½ìŸ ìˆ˜ì¤€ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬(MCLM)**ì„ ìƒˆë¡­ê²Œ ì œì‹œí•˜ì—¬ ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ë³µì¡í•œ ì¶”ë¡  ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ë‹¨ìˆœí•œ ë¬¸ì œ í•´ê²°ì„ ë„˜ì–´ **ëª¨ë¸ì˜ ì§„ì •í•œ ë‹¤êµ­ì–´ ì¶”ë¡  ëŠ¥ë ¥**ì„ í‰ê°€í•˜ê³ , **í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì˜ í•œê³„**ë¥¼ ë°íˆëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.  **MR1-1.5Bë¼ëŠ” ë‹¤êµ­ì–´ LLM**ì„ í›ˆë ¨í•˜ì—¬ ì„±ëŠ¥ ë¹„êµì— í™œìš©í•˜ê³ , **ê²°ê³¼ëŠ” ê³µê°œ**í•˜ì—¬ í›„ì† ì—°êµ¬ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤.  **ì¶”ë¡  ì—°ì‚°ëŸ‰(FLOPs)**ì„ í†µì œí•˜ì—¬ ê¸°ë²• ê°„ ê³µì •í•œ ë¹„êµë¥¼ ìˆ˜í–‰í•˜ëŠ” ì ë„ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.  ì „ë°˜ì ìœ¼ë¡œ, **ì‹¤í—˜ ì„¤ê³„ëŠ” ì—„ë°€í•˜ê³  ì²´ê³„ì ì´ë©°**, ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ì™€ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²•ì˜ ì¼ë°˜í™” ë¬¸ì œì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#### Future Research
ë³¸ ë…¼ë¬¸ì€ **ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡ ì—ì„œì˜ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì˜ ì–¸ì–´ ì¼ë°˜í™” ê°€ëŠ¥ì„±**ì— ëŒ€í•œ ì¤‘ìš”í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ MCLMì„ ì‚¬ìš©í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì´ ì˜ì–´ì™€ ê°™ì€ ê³ ìì› ì–¸ì–´ì—ì„œëŠ” íš¨ê³¼ì ì´ì§€ë§Œ, ì €ìì› ì–¸ì–´ë¡œ í™•ì¥í•˜ëŠ” ë°ëŠ” ì–´ë ¤ì›€ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. **ë¯¸ë˜ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ì–¸ì–´ì  í¸í–¥ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ë°©ë²•ë¡  ê°œë°œ**ì— ì´ˆì ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ, **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ìì²´ ìˆ˜ì • ëŠ¥ë ¥ í–¥ìƒ**ì— ëŒ€í•œ ì—°êµ¬ë„ ì¤‘ìš”í•©ë‹ˆë‹¤. **ì €ìì› ì–¸ì–´ì— ëŒ€í•œ ë°ì´í„° ë¶€ì¡± ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë°ì´í„° ì¦ê°• ê¸°ë²•** ê°œë°œë„ ì¤‘ìš”í•œ ì—°êµ¬ ë¶„ì•¼ì…ë‹ˆë‹¤.  ë‚˜ì•„ê°€, **ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ì¶”ë¡  ìœ í˜•ì„ í¬í•¨í•˜ëŠ” ë”ìš± í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬** ê°œë°œì„ í†µí•´ ì—°êµ¬ ê²°ê³¼ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë†’ì¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.  **í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ê³„ì‚° ë¹„ìš© ìµœì í™”** ì—°êµ¬ë„ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡ ë¿ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ë‹¤êµ­ì–´ ê³¼ì œì—ë„ í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§ ê¸°ë²• ì ìš©**ì— ëŒ€í•œ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.17407/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” ì„¸ ê°€ì§€ ì„œë¡œ ë‹¤ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ ì „ëµ(ê²°ê³¼ ë³´ìƒ ëª¨ë¸ë§, í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ë§ ë° ì˜ˆì‚° ê°•ì œ)ì„ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. ê° ì „ëµì€ ëª¨ë¸ì´ ìƒì„±í•œ ì—¬ëŸ¬ ì‘ë‹µ í›„ë³´ ì¤‘ì—ì„œ ìµœì¢… ì¶œë ¥ìœ¼ë¡œ ì„ íƒëœ ì‘ë‹µ(íŒŒë€ìƒ‰ ìƒì)ê³¼ ê¸°ê°ëœ ì‘ë‹µ(ë¹¨ê°„ìƒ‰ ìƒì)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì„ í†µí•´ ê° ì „ëµì˜ ì˜ì‚¬ê²°ì • ê³¼ì •ê³¼ ê·¸ ì°¨ì´ì ì„ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Comparison of different inference-time scaling strategies. Blue boxes represent selected outputs, while red boxes indicate rejected ones.
> </details>



![](https://arxiv.org/html/2502.17407/x3.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ íƒìš•ì  ì„¤ì •ì—ì„œ 15ì–µ ë° 70ì–µ ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì— ëŒ€í•´ ìƒì„±ëœ í† í°ì˜ ìˆ˜ë¥¼ ì •í™•ì„±ìœ¼ë¡œ ë‚˜ëˆˆ ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì–¸ì–´ëŠ” ìƒì ê·¸ë¦¼ ìœ„ì— ì‚°ì ë„ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ìƒì ê·¸ë¦¼ì€ ê° ì–¸ì–´ì— ëŒ€í•œ ìƒì„±ëœ í† í° ìˆ˜ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ê³ , ì‚°ì ë„ëŠ” ê° ì–¸ì–´ì— ëŒ€í•œ ê°œë³„ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ í¬ê¸°ê°€ ë‹¤ì–‘í•œ ì–¸ì–´ì— ê±¸ì³ ìƒì„±ëœ ì‘ë‹µì˜ ê¸¸ì´ì™€ ì •í™•ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: # of generated tokens for 1.5B and 7B models in a greedy setting, divided by correctness. Languages are represented as scatter plots, overlaid on box plots.
> </details>



![](https://arxiv.org/html/2502.17407/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ë‹¤ì–‘í•œ K ê°’(2, 4, 8)ì„ ê°–ëŠ” ORM(Outcome Reward Modeling) ì„¤ì •ì—ì„œ ê·¸ë¦¬ë”” ë””ì½”ë”© ê¸°ì¤€ì„ ê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°˜íˆ¬ëª…í•œ â€˜êµ¬ë¦„â€™ì€ KDE ë°€ë„ í”Œë¡¯ì„ í†µí•´ 2ì°¨ì› ë°ì´í„° ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ê³ , ê²¹ì³ì§„ 3ì°¨ ë‹¤í•­ì‹ íšŒê·€ì„ ì€ ê° ORM ì„¤ì •ì´ ê¸°ì¤€ì„  ì ìˆ˜ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¦‰, xì¶•ì€ ê¸°ì¤€ì„  ì ìˆ˜, yì¶•ì€ ORM ì„¤ì •ì— ë”°ë¥¸ ì„±ëŠ¥ í–¥ìƒ(ê¸°ì¤€ì„  ì ìˆ˜ ëŒ€ë¹„ ìƒëŒ€ì  ì¦ê°€ë¶„)ì„ ë‚˜íƒ€ë‚´ë©°, ê° ì ì€ íŠ¹ì • ì–¸ì–´ì— ëŒ€í•œ ê²°ê³¼ë¥¼, íšŒê·€ì„ ì€ ì „ë°˜ì ì¸ ê²½í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ MT-MATH100 ë°ì´í„°ì…‹ì—ì„œëŠ” K ê°’ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ ì¼ê´€ë˜ê²Œ í–¥ìƒë˜ëŠ” ë°˜ë©´, MT-AIME2024 ë°ì´í„°ì…‹ì—ì„œëŠ” K ê°’ì˜ ë³€í™”ì— ë”°ë¥¸ ì„±ëŠ¥ í–¥ìƒì´ ë¯¸ë¯¸í•˜ê±°ë‚˜, ê²½ìš°ì— ë”°ë¼ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ORMì´ ì–´ë ¤ìš´ ë¬¸ì œì— ëŒ€í•´ì„œëŠ” ëª¨ë“  ì–¸ì–´ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜¤ì§€ ëª»í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Gains of ORM compared to a greedy-decoding baseline. The semi-transparent â€œcloudâ€ indicates the 2D data distribution via a KDE density plot, and the overlaid lines are third-order polynomial regressions modeling how each ORM setting scales with the baseline score.
> </details>



![](https://arxiv.org/html/2502.17407/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” Process Reward Modeling (PRM)ì˜ ì¶”ë¡  ì—°ì‚°ëŸ‰(FLOPs)ì„ ìƒì„± ë‹¨ê³„ ìˆ˜(S)ì™€ ê° ë‹¨ê³„ë‹¹ í›„ë³´ ìˆ˜(c)ì˜ í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì…ë‹ˆë‹¤. ì™¼ìª½ íŒ¨ë„ì€ 72B í¬ê¸°ì˜ ê²€ì¦ê¸°ë¥¼ ì‚¬ìš©í•œ ê²½ìš°ë¥¼, ì˜¤ë¥¸ìª½ íŒ¨ë„ì€ 7B í¬ê¸°ì˜ RMì„ ì‚¬ìš©í•œ ê²½ìš°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ê²½ìš° ëª¨ë‘ ë¹„ìŠ·í•œ ë¹„ìš©ì„ ì–»ë„ë¡ ì„¤ì •ì„ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.  ì¦‰, ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ê²€ì¦ê¸°ë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„ ë¹„ìŠ·í•œ ê³„ì‚° ë¹„ìš©ì„ ê°–ë„ë¡ PRMì˜ ì„¤ì •ì„ ì¡°ì •í•˜ì—¬ ë¹„êµ ë¶„ì„ì„ ìˆ˜í–‰í–ˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: PRM inference FLOPs as a function of generation steps Sğ‘†Sitalic_S and candidates per step cğ‘citalic_c. The left panel uses a verifier size of 72B, while the right panel uses a 7B RM, displaying adjusted configurations to yield similar costs.
> </details>



![](https://arxiv.org/html/2502.17407/x6.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ PRM(Process Reward Modeling)ì˜ ì¶”ë¡  ì—°ì‚°ëŸ‰(FLOPs)ê³¼ ì„±ëŠ¥ ë° ì¼ê´€ì„± ê°„ì˜ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì™¼ìª½ ê·¸ë¦¼ì€ 14ê°œ ì–¸ì–´ì— ëŒ€í•œ í‰ê·  ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” 2ì°¨ ë‹¤í•­ì‹ íšŒê·€ì„ ì„ ë³´ì—¬ì£¼ë©°, ë³´ìƒ ëª¨ë¸ì˜ í¬ê¸°(ë§¤ê°œë³€ìˆ˜ ìˆ˜)ì— ë”°ë¥¸ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŒŒë€ìƒ‰ì€ 7B ë§¤ê°œë³€ìˆ˜ ëª¨ë¸, ë…¹ìƒ‰ì€ 72B ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ ë™ì¼í•œ FLOPs ì˜ˆì‚°ì— ëŒ€í•œ Fleissâ€™ kappa(ì¼ê´€ì„± ì¸¡ì • ì§€í‘œ)ì™€ í‘œì¤€ í¸ì°¨ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë•Œ, ëª…í™•í•œ ë‹¨ì¡° ê´€ê³„ëŠ” ê´€ì°°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Inference FLOPs versus PRM performance and consistency. (Left) Second-degree polynomial regressions for average performance on 14 languages, comparing the 7B (blue) and 72B (green) reward models. (Right) Fleissâ€™ kappa (top) and standard deviation (bottom) plotted against the same FLOPs budget; the fitted curves reveal no clear monotonic trend.
> </details>



![](https://arxiv.org/html/2502.17407/x7.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ MATH ë° AIME ë°ì´í„°ì…‹ì—ì„œ PRMê³¼ ORMì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤.  ì‹¤ì„ ì€ MATH ë°ì´í„°ì…‹, ì ì„ ì€ AIME ë°ì´í„°ì…‹ì˜ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  '+' ë§ˆì»¤ëŠ” 1.5B ëª¨ë¸, '*' ë§ˆì»¤ëŠ” 7B ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. íŒŒë€ìƒ‰ ì„ ì€ PRM, ë…¹ìƒ‰ ì„ ì€ ORMì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ì„ ì˜ ê°€ì¥ ë†’ì€ ì»´í“¨íŒ… ì„¤ì •ì—ì„œ ORMê³¼ PRMì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ í°ìƒ‰ ìƒì ì£¼ì„ìœ¼ë¡œ í‘œì‹œí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê° ëª¨ë¸ì˜ í¬ê¸°ì™€ ì‚¬ìš©ëœ ê³„ì‚° ë¦¬ì†ŒìŠ¤ì— ë”°ë¥¸ ìƒëŒ€ì  ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Comparison of PRM vs. ORM performance on MATH (solid lines) and AIME (dashed lines). 1.5B models are shown with plus markers, 7B models with stars. Blue lines represent PRM, green lines represent ORM. White box annotations indicate the performance difference (ORM âˆ’ PRM) at the highest compute setting for each line.
> </details>



![](https://arxiv.org/html/2502.17407/x8.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ Qwen2.5-Math-1.5B ëª¨ë¸ì— ëŒ€í•´ SFT(Supervised Fine-Tuning)ì™€ MT-SFT(ë‹¤êµ­ì–´ SFT)ë¥¼ ì ìš©í–ˆì„ ë•Œ, ê° í•™ìŠµ ì²´í¬í¬ì¸íŠ¸ë³„ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  yì¶•ì€ í‰ê·  ì •í™•ë„ë¥¼ ë‚˜íƒ€ë‚´ê³ , xì¶•ì€ í•™ìŠµ ì§„í–‰ ë‹¨ê³„(checkpoint)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì—ëŸ¬ ë°”ëŠ” ê° ì²´í¬í¬ì¸íŠ¸ì—ì„œì˜ ì •í™•ë„ í‘œì¤€í¸ì°¨ë¥¼ ë‚˜íƒ€ë‚´ë©°, MT-SFTì˜ í‰ê·  Â± í‘œì¤€í¸ì°¨ ë²”ìœ„ëŠ” ìŒì˜ìœ¼ë¡œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì¦‰, ì´ ê·¸ë˜í”„ëŠ” ë‘ ê°€ì§€ fine-tuning ë°©ë²•ì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ í•™ìŠµ ê³¼ì •ì— ë”°ë¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. MT-SFTëŠ” ë‹¤êµ­ì–´ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ, ë‹¨ì¼ ì–¸ì–´ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•œ SFTë³´ë‹¤ ì´ˆê¸° ì„±ëŠ¥ì€ ë‹¤ì†Œ ë‚®ì§€ë§Œ, í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Performance of Qwen2.5-Math-1.5B +SFT and + MT-SFT at each training checkpoint. Average score and error bars for each checkpoint are displayed. The shaded region is the mean Â±plus-or-minus\pmÂ± standard deviation for MT-SFT.
> </details>



![](https://arxiv.org/html/2502.17407/x9.png)

> ğŸ”¼ ê·¸ë¦¼ 9ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ì— ëŒ€í•œ MT-AIME2024 ë°ì´í„°ì…‹ì—ì„œ ì„¸ ê°€ì§€ ë‹¤ë¥¸ ë²„ì§“(2048, 4096, 8192 í† í°)ì„ ì‚¬ìš©í•œ MR1 ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íšŒìƒ‰ ì ì€ ê°œë³„ ì–¸ì–´ë¥¼ ë‚˜íƒ€ë‚´ê³ , ì‹¤ì„ ì€ í‰ê·  ì„±ëŠ¥ì„, ì ì„ ì€ íŠ¹ì • ì–¸ì–´ì— ëŒ€í•œ ê¸°ì¤€ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ ê¸°ë²•ì¸ BF(Budget Forcing)ì´ ì–¸ì–´ ê°„ì— ì–¼ë§ˆë‚˜ ì˜ ì¼ë°˜í™”ë˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì  ìë£Œì…ë‹ˆë‹¤. ê° ë²„ì§“ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  íŠ¹ì • ì–¸ì–´ì—ì„œì˜ ì„±ëŠ¥ì´ í‰ê·  ì„±ëŠ¥ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: Performance of MR1 on MT-AIME2024 at Bâ¢F={2048,4096,8192}ğµğ¹204840968192BF=\{2048,4096,8192\}italic_B italic_F = { 2048 , 4096 , 8192 }. Grey dots represent individual languages. Solid lines indicate average performance, while dashed lines highlight reference performances for selected languages.
> </details>



![](https://arxiv.org/html/2502.17407/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 10ì€ 2006ë…„ë¶€í„° 2024ë…„ê¹Œì§€ì˜ IMO(International Mathematical Olympiad) ë¬¸ì œë“¤ì˜ íˆíŠ¸ë§µì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° í–‰ì€ ëŒ€íšŒ ì—°ë„ì— í•´ë‹¹í•˜ë©°, ê° ì—´ì€ ë¬¸ì œ(Q1~Q6)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ˆë¡ìƒ‰ ì…€ì€ M-IMO í•˜ìœ„ ë°ì´í„°ì…‹ì— í¬í•¨ëœ ë¬¸ì œë¥¼, íšŒìƒ‰ ì…€ì€ ì„ íƒë˜ì§€ ì•Šì€ ë¬¸ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ M-IMO ë°ì´í„°ì…‹ì´ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ IMO ë¬¸ì œë“¤ì„ ì„ íƒí–ˆëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: Heatmap representation of IMO problems from 2006 to 2024. Each row corresponds to a competition year, and each column represents a problem (Q1â€“Q6). Green cells indicate questions that have been included in the M-IMO subset, while gray cells represent problems that were not selected.
> </details>



![](https://arxiv.org/html/2502.17407/x11.png)

> ğŸ”¼ ê·¸ë¦¼ 11ì€ ë‹¤ì–‘í•œ ë‹¤êµ­ì–´ ìˆ˜í•™ ë°ì´í„°ì…‹ì— ëŒ€í•´ í‰ê°€ëœ í’€ì´ ì„±ê³µë¥ (%)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. OLMo2 ê³„ì—´ì˜ ê²½ìš° ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í–ˆê³ , Qwen2.5 ê³„ì—´ì˜ ê²½ìš° instruction-tuningëœ ë³€í˜• ëª¨ë¸ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. Euler-Instruct ë°ì´í„°ì…‹ì€ ìƒë‹¹íˆ ë‚®ì€ í’€ì´ ì„±ê³µë¥ ì„ ë³´ì—¬ì£¼ì–´, í•´ë‹¹ ë°ì´í„°ì…‹ì˜ ë‚œì´ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ í¬ê¸°ì™€ ì¢…ë¥˜ì˜ ì–¸ì–´ ëª¨ë¸ì´ ë‹¤êµ­ì–´ ìˆ˜í•™ ë¬¸ì œ í’€ì´ì— ëŒ€í•´ ì–´ë–¤ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: Solve rates (%) of different multilingual math datasets evaluated. For the OLMo2 series, we use the base models, while for the Qwen2.5 series, the instruct-tuned variants are used. Euler-Instruct presents a significantly lower solve rate, indicating its greater difficulty.
> </details>



![](https://arxiv.org/html/2502.17407/x12.png)

> ğŸ”¼ ê·¸ë¦¼ 12ëŠ” í‘œ 9ì˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì™¼ìª½ ê·¸ë˜í”„ëŠ” 55ê°œ ì–¸ì–´ ì¤‘ 14ê°œ ì–¸ì–´(ì–¸ì–´ ê·¸ë£¹ B)ë¡œ ë²ˆì—­ëœ MT-MATH500 ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ê³ , ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ëŠ” MT-AIME2024 ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê·  ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê·¸ë˜í”„ëŠ” í›ˆë ¨ ë°ì´í„°ì˜ ì–‘ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì£¼ëŠ” ì—¬ëŸ¬ ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ê·œëª¨ì˜ í›ˆë ¨ ë°ì´í„°ê°€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ë‹¤êµ­ì–´ ëª¨ë¸ í•™ìŠµ ì‹œ ë°ì´í„°ì…‹ í¬ê¸°ì˜ ì¤‘ìš”ì„±ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 12: Model Results from TableÂ 9. Left shows accuracy on MT-MATH500 (entire translated subset for language group (B)), and right shows average performance of MT-AIME2024.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Subset | Source Benchmark | Languages | Sample Size per Language | Evaluation Method |
|---|---|---|---|---|
| MT-MATH100 | Math-500 | 55 | 100 | Rule-based verifier |
| MT-AIME2024 | AIME 2024 | 55 | 30 | Rule-based verifier |
| M-IMO | IMO (2006, 2024) | 38 | 22â€“27 | LLM-as-a-Judge |
| M-MO | Domestic/Regional Olympiads | 11 | 28â€“31 | LLM-as-a-Judge |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì˜ MCLM ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê°œìš”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° í•˜ìœ„ ë°ì´í„°ì…‹(MT-MATH100, MT-AIME2024, M-IMO, M-MO)ì˜ ì†ŒìŠ¤ ë²¤ì¹˜ë§ˆí¬, ì–¸ì–´ ë²”ìœ„(ì „ì²´ ëª©ë¡ì€ ë¶€ë¡ ì°¸ì¡°), ìƒ˜í”Œ í¬ê¸° ë° í‰ê°€ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° í•˜ìœ„ ë°ì´í„°ì…‹ì€ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ìˆ˜í•™ ë¬¸ì œì™€ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ í¬í•¨í•˜ë©°, ì´ëŠ” ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  ì–¸ì–´ì˜ ì „ì²´ ëª©ë¡ì€ ë¶€ë¡ A.1ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Overview of benchmark subsets: source benchmarks, language coverage (full lists in the appendix), sample sizes, and evaluation methods. Please see AppendixÂ A.1 for the full list of languages.
> </details>

{{< table-caption >}}
| k | (S,c) | BF |
|---|---|---|
| 2 | (3, 3) | â‰ˆ 2048 tokens |
| 4 | (4, 5) | â‰ˆ 4096 tokens |
| 8 | (5, 8) | â‰ˆ 8192 tokens |{{< /table-caption >}}
> ğŸ”¼ í‘œ 3ì€ PRM(Process Reward Modeling)ê³¼ BF(Budget Forcing)ì— ëŒ€í•œ ì„¤ì •ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì„¤ì •ê°’(S, c, BF)ì€ ORM(Outcome Reward Modeling)ê³¼ ë™ì¼í•œ ì¶”ë¡  FLOPs(Floating Point Operations)ë¥¼ ê°–ë„ë¡ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.  ì¦‰, ì„¸ ê°€ì§€ ë°©ë²• ëª¨ë‘ ë¹„ìŠ·í•œ ê³„ì‚° ë¹„ìš©ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ì„¤ì •ì´ êµ¬ì„±ëœ ê²ƒì…ë‹ˆë‹¤.  SëŠ” ìƒì„± ë‹¨ê³„ ìˆ˜, cëŠ” ê° ë‹¨ê³„ì—ì„œ ìƒì„±ë˜ëŠ” í›„ë³´ ë‹µë³€ì˜ ê°œìˆ˜, BFëŠ” í—ˆìš©ë˜ëŠ” í† í° ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ í‘œëŠ” í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ ë°©ë²•ë“¤ì˜ ê³„ì‚° ë¹„ìš©ì„ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë©´ì„œ ë¹„êµí•˜ê¸° ìœ„í•œ ì‹¤í—˜ ì„¤ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Selected configurations for PRM and BF. Each Sğ‘†Sitalic_S, cğ‘citalic_c, and Bâ¢Fğµğ¹BFitalic_B italic_F is set so that the inference FLOPs match ORM.
> </details>

{{< table-caption >}}
| Models | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO | Average |
|---|---|---|---|---|---| 
| Qwen2.5-Math-1.5B-Instruct | 42.32 Â± 8.61 | 16.36 Â± 6.89 | 12.23 Â± 6.02 | 25.00 Â± 19.10 | 23.98 |
| Deepseek-R1-1.5B | 49.40 Â± 8.84 | 17.21 Â± 6.69 | 21.94 Â± 6.75 | 26.77 Â± 19.83 | 28.83 |
| GPT-4o-Mini | 70.30 Â± 3.68 | 20.18 Â± 6.83 | 13.33 Â± 5.36 | 30.81 Â± 15.80 | 33.66 |
| o3-Mini | **84.89** Â± 2.80 | **45.33** Â± 5.35 | **29.75** Â± 6.86 | **51.42** Â± 16.94 | **52.85** |
| Qwen2.5-Math-1.5B + SFT | 37.47 Â± 7.56 | 14.85 Â± 6.69 | 10.50 Â± 5.16 | 18.40 Â± 14.92 | 20.30 |
| Qwen2.5-Math-1.5B + MT-SFT | 42.02 Â± 7.46 | 16.67 Â± 7.31 | 10.52 Â± 4.63 | 19.92 Â± 12.68 | 22.28 |
| Deepseek-R1-1.5B + MT-SFT | **55.61** Â± 10.93 | **19.94** Â± 8.10 | **19.20** Â± 6.24 | **28.97** Â± 16.64 | **30.93** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì¸ MCLMì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° íŒ¨ë„ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì€ êµµê²Œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì–¸ì–´ë³„ ì„¸ë¶€ ê²°ê³¼ëŠ” ë¶€ë¡ Cë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ëŠ¥ë ¥ì„ ë¹„êµí•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ê³¼ ì•½ì ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Model performance across MCLM. Best model highlighted in bold for each panel. For results per language see AppendixÂ C.
> </details>

{{< table-caption >}}
| Lang. Group | Languages (ISO Codes, Sorted Alphabetically) | # Lang. |
|---|---|---|
| (A) | af, ar, bg, bn, ca, cs, cy, da, de, el, en, es, et, fa, fi, fr, gu, he, hi, hr, hu, id, it, ja, kn, ko, lt, lv, mk, ml, mr, ne, nl, no, pa, pl, pt, ro, ru, sk, sl, so, sq, sv, sw, ta, te, th, tl, tr, uk, ur, vi, zh-cn, zh-tw | 55 |
| (B) | af, ar, de, en, es, fr, he, id, it, ja, ko, tr, vi, zh-cn | 14 |
| (C) | af, ar, bg, cs, da, de, el, en, et, es, fi, fr, he, hr, hu, id, it, ja, ko, lt, lv, mk, nl, no, pl, pt, ro, ru, sk, sl, sq, sv, th, tr, uk, vi, zh-cn, zh-tw  | 38 |
| (D) | cs, de, en, fr, ja, ko, nl, pl, ru, sk, zh-cn | 11 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë„¤ ê°€ì§€ ìˆ˜í•™ ë¬¸ì œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹(MT-MATH100, MT-AIME2024, M-IMO, M-MO)ì— í¬í•¨ëœ ì–¸ì–´ ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë°ì´í„°ì…‹ì€ ì„œë¡œ ë‹¤ë¥¸ ìˆ˜ì˜ ì–¸ì–´ë¥¼ í¬í•¨í•˜ë©°, MT-MATH100ì€ 55ê°œ, MT-AIME2024ëŠ” 55ê°œ, M-IMOëŠ” 38ê°œ, M-MOëŠ” 11ê°œì˜ ì–¸ì–´ ì½”ë“œ(ISO ì½”ë“œ)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.  ì´ í‘œëŠ” ê° ë°ì´í„°ì…‹ì— ì‚¬ìš©ëœ ì–¸ì–´ì˜ ì¢…ë¥˜ì™€ ê°œìˆ˜ë¥¼ ëª…í™•íˆ ë³´ì—¬ì¤Œìœ¼ë¡œì¨, ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ëŠ” ë‹¤êµ­ì–´ì  ì¸¡ë©´ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Full language lists for each dataset subset. MT-MATH100, MT-AIME2024, M-IMO, and M-MO cover 55, 38, and 11 ISO codes respectively.
> </details>

{{< table-caption >}}
| Rank | Model | MATH-500 | MATH-100 | Score Diff. | Rank Diff. |
|---|---|---|---|---|---| 
| 1 | o3-mini | 85.00 | 85.93 | 0.93 | - |
| 2 | Eurus-2-7B-PRIME | 73.76 | 76.63 | 2.86 | - |
| 3 | Qwen2.5-Math-7B-Instruct | 73.70 | 75.98 | 2.27 | - |
| 4 | DeepSeek-R1-Distill-Qwen-32B | 72.73 | 75.98 | 3.24 | - |
| 5 | DeepSeek-R1-Distill-Qwen-7B | 67.25 | 68.69 | 1.44 | 1 â–² |
| 6 | AceMath-7B-Instruct | 65.90 | 70.06 | 4.16 | 1 â–¼ |
| 7 | AceMath-1.5B-Instruct | 65.60 | 68.19 | 2.58 | - |
| 8 | DeepSeek-R1-Distill-Qwen-1.5B | 53.74 | 56.78 | 3.05 | - |
| 9 | Qwen2.5-Math-1.5B-Instruct | 51.80 | 51.30 | 0.51 | - |
| 10 | Qwen2.5-Math-1.5B-OREO | 39.92 | 38.45 | 1.47 | - |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” MATH-500 ë°ì´í„°ì…‹ê³¼ MATH-100 ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  MATH-500 ì ìˆ˜ì™€ MATH-100 ì ìˆ˜ì˜ ì ˆëŒ€ê°’ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ì ìˆ˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ê³ , MATH-100 ë°ì´í„°ì…‹ì—ì„œì˜ ìˆœìœ„ ë³€í™”ë¥¼ MATH-500 ë°ì´í„°ì…‹ì—ì„œì˜ ìˆœìœ„ì™€ ë¹„êµí•˜ì—¬ ìˆœìœ„ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ëª¨ë¸ì˜ ìƒëŒ€ì  ì„±ëŠ¥ ë³€í™”ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Model rankings and score comparison between MATH-500 and MATH-100. The score difference was computed as the absolute difference between the MATH-500 and MATH-100 scores. The rank difference indicates the change in ranking on MATH-100 relative to the performance on MATH-500.
> </details>

{{< table-caption >}}
| Language | Competition Links |
|---|---| 
| French | https://euler.ac-versailles.fr/spip.php?rubrique207 |
| German | DeMO |
| Japanese | https://www.imojp.org/domestic/jmo_overview.html#Problems |
| Dutch | https://prime.ugent.be/activiteiten/puma/<br>https://wiskundeolympiade.nl/wedstrijdarchief/1e-ronde |
| Czech | https://www.matematickaolympiada.cz/mo-pro-ss/rocnik<br>https://iksko.org/problems.php |
| Polish | https://om.sem.edu.pl/problems/ |
| Slovakian | https://skmo.sk/dokumenty.php?rocnik=74<br>https://riesky.sk/archiv/ |
| Russian | https://mmo.mccme.ru// |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ë…¼ë¬¸ì˜ M-MO ë¶€ë¶„ì§‘í•©ì— í¬í•¨ëœ ìˆ˜í•™ ê²½ì‹œëŒ€íšŒ ë§í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´(í”„ë‘ìŠ¤ì–´, ë…ì¼ì–´, ì¼ë³¸ì–´, ë„¤ëœë€ë“œì–´, ì²´ì½”ì–´, í´ë€ë“œì–´, ìŠ¬ë¡œë°”í‚¤ì•„ì–´, ëŸ¬ì‹œì•„ì–´)ì— ëŒ€í•œ ê²½ì‹œëŒ€íšŒ ë¬¸ì œ ë§í¬ë¥¼ ì œê³µí•˜ì—¬, í•´ë‹¹ ë°ì´í„°ì…‹ì— ì‚¬ìš©ëœ ë‹¤ì–‘í•œ ì¶œì²˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Link to mathematical competition links that has been included in M-MO subset.
> </details>

{{< table-caption >}}
| Dataset | # Lang. | # Inst. | Diff. |
|---|---|---|---|
| MGSM8KInstruct | 10 | 73.6k | G.S |
| mCoT-MATH | 10 | 6.3M | G.S |
| Euler-Instruct (Ours) | 55 | 250K | C.L |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì„¸ ê°€ì§€ ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ë°ì´í„°ì…‹(MGSM8KInstruct, mCoT-MATH, Euler-Instruct)ì„ ë¹„êµ ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤. ê° ë°ì´í„°ì…‹ì˜ ì–¸ì–´ ìˆ˜, ë¬¸ì œ ìˆ˜, ë‚œì´ë„ ìˆ˜ì¤€(G.S: ì´ˆë“±í•™ìƒ ìˆ˜ì¤€, C.L: ëŒ€íšŒ ìˆ˜ì¤€)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Euler-Instruct ë°ì´í„°ì…‹ì€ ê¸°ì¡´ ë°ì´í„°ì…‹ë³´ë‹¤ ë” ë§ì€ ì–¸ì–´ì™€ ê²½ìŸ ìˆ˜ì¤€ì˜ ë¬¸ì œë¥¼ í¬í•¨í•˜ì—¬ ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ì—°êµ¬ì— ìœ ìš©í•œ ìë£Œì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Comparison of Multilingual Mathematical Reasoning Datasets. The Diff. column indicates difficulty level, where G.S represents grade school level and C.L represents competition level.
> </details>

{{< table-caption >}}
| Languages | # Lang. | # Instances |
|---|---|---|
| ko | 1 | 24k |
| af, fr, ko | 3 | 8k |
| af, ar, fr, he, id, ko, tr | 7 | â‰ˆ3.5k |
| all 14 in Euler-Instruct | 14 | â‰ˆ1.7k |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì„¸ ê°€ì§€ ì–¸ì–´ ëª¨ë¸ í•™ìŠµì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ëª¨ë“  ëª¨ë¸ì€ ì´ 24,000ê°œì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì—ˆìœ¼ë©°,  '# Instances' ì—´ì€ ê° ì–¸ì–´ì— ì‚¬ìš©ëœ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  í‘œì—ëŠ” í•™ìŠµì— ì‚¬ìš©ëœ ì–¸ì–´ì˜ ìˆ˜ì™€ ê° ì–¸ì–´ë³„ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆì–´,  ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ í•™ìŠµ ì„¤ì •ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  íŠ¹íˆ,  ì œí•œëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ í•™ìŠµ ì „ëµì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Details on trained models. All models are trained with a total of 24,000 instances. # Instances denote the number of instances used per language.
> </details>

{{< table-caption >}}
| Category | Section 5 | 
|---|---| 
| **Sequence Length** | 16,384 | 
| **Learning Rate** | 2 Ã— 10<sup>âˆ’5</sup> | 
| **Global Batch (Effective)** | 128 | 
| **Learning Rate Scheduler** | Cosine Decay | 
| **Warmup Ratio** | 0.05 | 
| **Training Epochs** | 3 | {{< /table-caption >}}
> ğŸ”¼ í‘œ 10ì€ ë…¼ë¬¸ 5ì¥ì—ì„œ ì‚¬ìš©ëœ SFT(Supervised Fine-Tuning)ì˜ ì„¤ì • ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  SFTëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.  í‘œì—ëŠ” ì‹œí€€ìŠ¤ ê¸¸ì´, í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ì›œì—… ë¹„ìœ¨, í•™ìŠµ ì—í­ ë“±ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì„¤ì • ê°’ë“¤ì€ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ê³¼ ìµœì¢… ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: SFT configuration details for SectionÂ 5.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 47.47 | 20.00 | 11.11 |  |
| Albanian | 45.45 | 10.00 | 4.00 |  |
| Arabic | 38.38 | 30.00 | 11.11 |  |
| Bengali | 37.37 | 3.33 |  |  |
| Bulgarian | 39.39 | 13.33 | 7.41 |  |
| Catalan | 50.51 | 23.33 |  |  |
| Chinese (Simplified) | 63.64 | 26.67 | 18.52 | 40.00 |
| Chinese (Traditional) | 61.62 | 20.00 | 18.52 |  |
| Croatian | 49.49 | 20.00 | 7.41 |  |
| Czech | 44.44 | 13.33 | 14.81 | 6.67 |
| Danish | 53.54 | 16.67 | 22.22 |  |
| Dutch | 50.51 | 36.67 | 11.11 | 20.00 |
| Estonian | 39.39 | 10.00 | 4.00 |  |
| Finnish | 41.41 | 16.67 | 8.00 |  |
| French | 62.63 | 30.00 | 18.52 | 51.61 |
| German | 47.47 | 26.67 | 11.11 | 10.00 |
| Greek | 33.33 | 13.33 | 5.26 |  |
| Gujarati | 39.39 | 10.00 |  |  |
| Hebrew | 38.38 | 13.33 | 3.70 |  |
| Hindi | 35.35 | 6.67 |  |  |
| Hungarian | 51.52 | 10.00 | 8.00 |  |
| Indonesian | 56.57 | 16.67 | 14.29 |  |
| Italian | 51.52 | 20.00 | 20.00 |  |
| Japanese | 56.57 | 16.67 | 8.00 | 0.00 |
| Kannada | 37.37 | 10.00 |  |  |
| Korean | 44.44 | 13.33 | 3.70 | 36.67 |
| Latvian | 40.40 | 10.00 | 12.00 |  |
| Lithuanian | 45.45 | 6.67 | 18.52 |  |
| Macedonian | 43.43 | 10.00 | 11.11 |  |
| Malayalam | 43.43 | 23.33 |  |  |
| Marathi | 34.34 | 13.33 |  |  |
| Nepali | 36.36 | 6.67 |  |  |
| Norwegian | 53.54 | 23.33 | 11.11 |  |
| Persian | 38.38 | 10.00 |  |  |
| Polish | 54.55 | 26.67 | 14.81 | 26.67 |
| Portuguese | 55.56 | 10.00 | 24.00 |  |
| Punjabi | 37.37 | 16.67 |  |  |
| Romanian | 49.49 | 13.33 | 25.93 |  |
| Russian | 59.60 | 20.00 | 16.00 | 20.00 |
| Slovak | 48.48 | 20.00 | 11.11 | 6.67 |
| Slovenian | 49.49 | 10.00 | 14.81 |  |
| Somali | 42.42 | 23.33 |  |  |
| Spanish | 55.56 | 20.00 | 18.52 |  |
| Swahili | 34.34 | 16.67 |  |  |
| Swedish | 58.59 | 20.00 | 8.00 |  |
| Tagalog | 46.46 | 16.67 |  |  |
| Tamil | 38.38 | 10.00 |  |  |
| Telugu | 39.39 | 6.67 |  |  |
| Thai | 39.39 | 23.33 | 3.70 |  |
| Turkish | 43.43 | 13.33 | 7.41 |  |
| Ukrainian | 38.38 | 13.33 | 11.11 |  |
| Urdu | 35.35 | 20.00 |  |  |
| Vietnamese | 44.44 | 13.33 | 7.41 |  |
| Welsh | 39.39 | 16.67 |  |  |
| English | 67.68 | 20.00 | 18.52 | 56.67 |
| Average | 46.01 | 16.36 | 12.23 | 25.00 |
| Standard Deviation | 8.61 | 6.89 | 6.02 | 19.10 |
| Fleissâ€™ Kappa | 0.56 | 0.68 | 0.24 |  |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ MCLM ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê° ì–¸ì–´ë³„ë¡œ ì–»ì€ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  Greedy decoding ë°©ì‹ì„ ì‚¬ìš©í–ˆìœ¼ë©°, MT-MATH100, MT-AIME2024, M-IMO, M-MO ë„¤ ê°€ì§€ í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„(%), í‰ê· , í‘œì¤€ í¸ì°¨, Fleiss' Kappa ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ì¶”ë¡  ì„±ëŠ¥ê³¼ ì¼ê´€ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: Evaluation results of Qwen2.5-Math-1.5B-Instruct with greedy decoding on MCLM.
> </details>

{{< table-caption >}}
| Language | ORM (K=2) MT-MATH100 | ORM (K=2) MT-AIME2024 | ORM (K=4) MT-MATH100 | ORM (K=4) MT-AIME2024 | ORM (K=8) MT-MATH100 | ORM (K=8) MT-AIME2024 |
|---|---|---|---|---|---|---|
|Afrikaans|53.54|23.33|56.57|16.67|60.61|23.33|
|Albanian|52.53|10.00|50.51|10.00|47.47|13.33|
|Arabic|43.43|20.00|46.46|13.33|51.52|16.67|
|Bengali|41.41|10.00|40.40|10.00|41.41|13.33|
|Bulgarian|45.45|26.67|46.46|20.00|51.52|16.67|
|Catalan|59.60|33.33|63.64|33.33|61.62|26.67|
|Chinese (Simplified)|69.70|36.67|76.77|30.00|78.79|26.67|
|Chinese (Traditional)|68.69|13.33|70.71|20.00|74.75|26.67|
|Croatian|51.52|16.67|59.60|23.33|58.59|30.00|
|Czech|49.49|13.33|56.57|10.00|59.60|16.67|
|Danish|53.54|23.33|56.57|20.00|59.60|26.67|
|Dutch|51.52|30.00|57.58|26.67|63.64|23.33|
|Estonian|46.46|13.33|48.48|13.33|50.51|13.33|
|Finnish|41.41|13.33|48.48|20.00|53.54|20.00|
|French|64.65|40.00|68.69|33.33|73.74|30.00|
|German|54.55|23.33|63.64|23.33|64.65|30.00|
|Greek|39.39|13.33|44.44|10.00|47.47|10.00|
|Gujarati|44.44|10.00|43.43|16.67|47.47|13.33|
|Hebrew|44.44|16.67|46.46|13.33|49.49|10.00|
|Hindi|40.40|10.00|45.45|13.33|47.47|16.67|
|Hungarian|53.54|10.00|57.58|10.00|63.64|16.67|
|Indonesian|58.59|20.00|56.57|20.00|59.60|16.67|
|Italian|57.58|26.67|60.61|26.67|69.70|16.67|
|Japanese|59.60|16.67|66.67|23.33|70.71|26.67|
|Kannada|45.45|10.00|47.47|16.67|52.53|13.33|
|Korean|53.54|16.67|56.57|23.33|57.58|13.33|
|Latvian|45.45|10.00|51.52|20.00|54.55|16.67|
|Lithuanian|48.48|10.00|52.53|10.00|57.58|13.33|
|Macedonian|50.51|13.33|51.52|13.33|50.51|10.00|
|Malayalam|47.47|20.00|52.53|20.00|56.57|23.33|
|Marathi|39.39|13.33|43.43|23.33|43.43|20.00|
|Nepali|38.38|6.67|46.46|3.33|46.46|6.67|
|Norwegian|59.60|26.67|61.62|16.67|65.66|23.33|
|Persian|40.40|13.33|41.41|13.33|39.39|16.67|
|Polish|54.55|16.67|57.58|16.67|64.65|16.67|
|Portuguese|58.59|13.33|60.61|13.33|62.63|26.67|
|Punjabi|41.41|16.67|43.43|20.00|42.42|16.67|
|Romanian|51.52|23.33|54.55|23.33|56.57|20.00|
|Russian|60.61|20.00|65.66|23.33|68.69|23.33|
|Slovak|52.53|10.00|54.55|20.00|55.56|33.33|
|Slovenian|47.47|16.67|51.52|20.00|54.55|30.00|
|Somali|44.44|16.67|46.46|16.67|46.46|10.00|
|Spanish|58.59|23.33|65.66|26.67|68.69|30.00|
|Swahili|37.37|13.33|41.41|20.00|45.45|13.33|
|Swedish|57.58|20.00|59.60|23.33|60.61|20.00|
|Tagalog|50.51|16.67|55.56|20.00|57.58|23.33|
|Tamil|41.41|16.67|44.44|16.67|47.47|16.67|
|Telugu|42.42|13.33|46.46|20.00|48.48|20.00|
|Thai|44.44|10.00|49.49|20.00|57.58|13.33|
|Turkish|50.51|16.67|46.46|13.33|54.55|20.00|
|Ukrainian|44.44|23.33|51.52|16.67|52.53|26.67|
|Urdu|38.38|16.67|41.41|16.67|44.44|20.00|
|Vietnamese|49.49|23.33|50.51|30.00|52.53|33.33|
|Welsh|38.38|16.67|44.44|16.67|44.44|20.00|
|English|71.72|16.67|73.74|26.67|76.77|36.67|
|Average|50.01|17.64|53.50|18.85|56.25|20.12|
|Standard Deviation|8.47|7.05|8.83|6.23|9.50|6.97|
|Fleissâ€™ Kappa|0.57|0.66|0.60|0.64|0.61|0.63|{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì— ëŒ€í•´ Best-of-N (K=2, 4, 8) ê¸°ë²•ì„ ì ìš©í•˜ì—¬ MT-MATH100 ë° MT-AIME2024 ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  Qwen2.5-Math-RM-72B ëª¨ë¸ì´ ORM(Outcome Reward Modeling)ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ì„¤ì •(K ê°’)ì— ë”°ë¥¸ MT-MATH100 ë° MT-AIME2024 ë°ì´í„°ì…‹ì˜ ì •í™•ë„, í‘œì¤€í¸ì°¨, Fleiss' kappa ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  Best-of-N ê¸°ë²•ì€ ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ ì‘ë‹µì„ ìƒì„±í•˜ê³  ê·¸ ì¤‘ ê°€ì¥ ì¢‹ì€ ì‘ë‹µì„ ì„ íƒí•˜ëŠ” ë°©ì‹ì´ë©°,  ORMì€ ëª¨ë¸ì˜ ì‘ë‹µì— ëŒ€í•œ ë³´ìƒì„ ëª¨ë¸ë§í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.  ì´ í‘œëŠ” test-time scaling ê¸°ë²•ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ K ê°’ê³¼ ë‘ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: Evaluation results of Qwen2.5-Math-1.5B-Instruct with Best-of-N (K=2,4,8)ğ¾248(K=2,4,8)( italic_K = 2 , 4 , 8 ) using Qwen2.5-Math-RM-72B as ORM on MT-MATH100 and MT-AIME2024.
> </details>

{{< table-caption >}}
| Language | PRM (S=3, c=3) MT-MATH100 | PRM (S=3, c=3) MT-AIME2024 | PRM (S=4, c=5) MT-MATH100 | PRM (S=4, c=5) MT-AIME2024 | PRM (S=5, c=8) MT-MATH100 | PRM (S=5, c=8) MT-AIME2024 | PRM (S=5, c=8) M-IMO | PRM (S=5, c=8) M-MO |
|---|---|---|---|---|---|---|---|---|
| Afrikaans | 52.53 | 6.67 | 57.58 | 20.00 | 64.65 | 10.00 | 22.73 |  |
| Albanian | 44.44 | 13.33 | 52.53 | 10.00 | 45.45 | 16.67 | 11.54 |  |
| Arabic | 41.41 | 13.33 | 52.53 | 13.33 | 45.45 | 10.00 | 7.41 |  |
| Bengali | 40.40 | 13.33 | 44.44 | 13.33 | 41.41 | 16.67 |  |  |
| Bulgarian | 42.42 | 20.00 | 42.42 | 10.00 | 55.56 | 10.00 | 11.11 |  |
| Catalan | 55.56 | 10.00 | 66.67 | 26.67 | 61.62 | 26.67 |  |  |
| Chinese (Simplified) | 64.65 | 13.33 | 75.76 | 16.67 | 71.72 | 33.33 | 25.93 |  |
| Chinese (Traditional) | 63.64 | 26.67 | 73.74 | 16.67 | 72.73 | 26.67 | 29.63 | 53.33 |
| Croatian | 50.51 | 13.33 | 51.52 | 20.00 | 54.55 | 23.33 | 14.81 |  |
| Czech | 50.51 | 10.00 | 52.53 | 16.67 | 58.59 | 20.00 | 14.81 | 10.00 |
| Danish | 57.58 | 10.00 | 60.61 | 30.00 | 60.61 | 20.00 | 22.22 |  |
| Dutch | 56.57 | 20.00 | 56.57 | 26.67 | 59.60 | 20.00 | 7.41 | 20.00 |
| Estonian | 47.47 | 13.33 | 51.52 | 3.33 | 49.49 | 10.00 | 11.54 |  |
| Finnish | 41.41 | 10.00 | 43.43 | 6.67 | 49.49 | 10.00 | 15.38 |  |
| French | 62.63 | 13.33 | 65.66 | 30.00 | 70.71 | 20.00 | 18.52 | 51.61 |
| German | 54.55 | 40.00 | 62.63 | 30.00 | 58.59 | 23.33 | 22.22 | 16.67 |
| Greek | 42.42 | 13.33 | 39.39 | 6.67 | 44.44 | 20.00 | 4.35 |  |
| Gujarati | 42.42 | 6.67 | 39.39 | 13.33 | 41.41 | 13.33 |  |  |
| Hebrew | 46.46 | 6.67 | 42.42 | 23.33 | 47.47 | 6.67 | 7.41 |  |
| Hindi | 39.39 | 10.00 | 46.46 | 20.00 | 47.47 | 10.00 |  |  |
| Hungarian | 57.58 | 26.67 | 61.62 | 10.00 | 57.58 | 3.33 | 19.23 |  |
| Indonesian | 56.57 | 16.67 | 57.58 | 13.33 | 64.65 | 13.33 | 20.83 |  |
| Italian | 61.62 | 13.33 | 61.62 | 20.00 | 67.68 | 23.33 | 23.08 |  |
| Japanese | 64.65 | 20.00 | 66.67 | 26.67 | 66.67 | 16.67 | 15.38 | 7.14 |
| Kannada | 44.44 | 23.33 | 42.42 | 13.33 | 47.47 | 13.33 |  |  |
| Korean | 46.46 | 10.00 | 45.45 | 13.33 | 50.51 | 13.33 | 14.81 | 26.67 |
| Latvian | 47.47 | 6.67 | 50.51 | 16.67 | 51.52 | 10.00 | 15.38 |  |
| Lithuanian | 42.42 | 10.00 | 49.49 | 6.67 | 45.45 | 16.67 | 14.81 |  |
| Macedonian | 41.41 | 13.33 | 47.47 | 16.67 | 48.48 | 23.33 | 11.11 |  |
| Malayalam | 38.38 | 16.67 | 42.42 | 16.67 | 43.43 | 13.33 |  |  |
| Marathi | 39.39 | 10.00 | 43.43 | 10.00 | 36.36 | 13.33 |  |  |
| Nepali | 41.41 | 16.67 | 41.41 | 26.67 | 42.42 | 10.00 |  |  |
| Norwegian | 59.60 | 23.33 | 65.66 | 30.00 | 59.60 | 26.67 | 18.52 |  |
| Persian | 37.37 | 20.00 | 43.43 | 13.33 | 39.39 | 13.33 |  |  |
| Polish | 49.49 | 23.33 | 58.59 | 23.33 | 62.63 | 20.00 | 25.93 | 36.67 |
| Portuguese | 58.59 | 20.00 | 57.58 | 16.67 | 61.62 | 30.00 | 19.23 |  |
| Punjabi | 39.39 | 20.00 | 40.40 | 13.33 | 49.49 | 6.67 |  |  |
| Romanian | 57.58 | 16.67 | 55.56 | 13.33 | 57.58 | 10.00 | 22.22 |  |
| Russian | 53.54 | 23.33 | 65.66 | 23.33 | 64.65 | 20.00 | 15.38 | 23.33 |
| Slovak | 51.52 | 10.00 | 52.53 | 13.33 | 53.54 | 20.00 | 14.81 |  |
| Slovenian | 44.44 | 23.33 | 47.47 | 16.67 | 45.45 | 26.67 | 11.11 |  |
| Somali | 43.43 | 6.67 | 42.42 | 23.33 | 40.40 | 3.33 |  |  |
| Spanish | 60.61 | 16.67 | 65.66 | 26.67 | 72.73 | 30.00 | 29.63 |  |
| Swahili | 38.38 | 13.33 | 41.41 | 13.33 | 41.41 | 10.00 |  |  |
| Swedish | 55.56 | 13.33 | 57.58 | 13.33 | 57.58 | 20.00 | 15.38 |  |
| Tagalog | 47.47 | 20.00 | 51.52 | 10.00 | 55.56 | 10.00 |  |  |
| Tamil | 41.41 | 10.00 | 45.45 | 16.67 | 45.45 | 16.67 |  |  |
| Telugu | 42.42 | 6.67 | 45.45 | 13.33 | 48.48 | 16.67 |  |  |
| Thai | 39.39 | 6.67 | 47.47 | 6.67 | 50.51 | 10.00 | 14.81 |  |
| Turkish | 45.45 | 13.33 | 50.51 | 23.33 | 45.45 | 10.00 | 11.11 |  |
| Ukrainian | 39.39 | 6.67 | 45.45 | 23.33 | 51.52 | 6.67 | 18.52 |  |
| Urdu | 39.39 | 20.00 | 40.40 | 16.67 | 42.42 | 13.33 |  |  |
| Vietnamese | 47.47 | 26.67 | 53.54 | 20.00 | 51.52 | 13.33 | 29.63 |  |
| Welsh | 43.43 | 10.00 | 48.48 | 6.67 | 51.52 | 6.67 |  |  |
| English | 73.74 | 26.67 | 79.80 | 23.33 | 72.73 | 23.33 | 29.63 | 60.00 |
| Average | 48.87 | 15.33 | 52.54 | 17.15 | 53.54 | 16.00 | 17.31 | 30.54 |
| Standard Deviation | 8.76 | 6.93 | 9.98 | 6.95 | 9.71 | 7.15 | 6.44 | 18.88 |
| Fleissâ€™ Kappa | 0.57 | 0.78 | 0.58 | 0.61 | 0.60 | 0.62 | 0.43 |  |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” MCLM ë²¤ì¹˜ë§ˆí¬ì—ì„œ Qwen2.5-Math-PRM-72Bë¥¼ PRM(Process Reward Modeling)ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ë¡œ MT-MATH100, MT-AIME2024, M-IMO, M-MO ë„¤ ê°€ì§€ í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ì™€, ì„¸ ê°€ì§€ ë‹¤ë¥¸ PRM ì„¤ì •(S=3, c=3), (S=4, c=5), (S=5, c=8)ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë˜í•œ, ê° ì„¤ì •ì— ëŒ€í•œ ì „ì²´ í‰ê·  ì •í™•ë„, í‘œì¤€ í¸ì°¨, ê·¸ë¦¬ê³  Fleiss' Kappa ê°’ì„ í†µí•´ ëª¨ë¸ì˜ ì¼ê´€ì„±ì„ í‰ê°€í•œ ê²°ê³¼ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Evaluation results of Qwen2.5-Math-1.5B-Instruct using Qwen2.5-Math-PRM-72B as PRM on MCLM.
> </details>

{{< table-caption >}}
|                    | MT-MATH100                                      |                       |                       |                       |
|--------------------|------------------------------------------------------|-----------------------|-----------------------|-----------------------|
| **Language**       | **PRM (S=7, c=5)** | **PRM (S=7, c=7)** | **PRM (S=7, c=11)** |                       |
| Afrikaans          | 55.56                                                | 51.52                   | 58.59                   |                       |
| Arabic             | 44.44                                                | 42.42                   | 44.44                   |                       |
| Chinese (Simplified) | 71.72                                                | 74.75                   | 76.77                   |                       |
| French              | 64.65                                                | 72.73                   | 69.70                   |                       |
| German              | 57.58                                                | 58.59                   | 58.59                   |                       |
| Hebrew              | 46.46                                                | 39.39                   | 44.44                   |                       |
| Indonesian          | 59.60                                                | 62.63                   | 61.62                   |                       |
| Italian             | 60.61                                                | 60.61                   | 58.59                   |                       |
| Japanese            | 67.68                                                | 67.68                   | 63.64                   |                       |
| Korean              | 48.48                                                | 45.45                   | 50.51                   |                       |
| Spanish             | 64.65                                                | 67.68                   | 68.69                   |                       |
| Turkish             | 50.51                                                | 53.54                   | 48.48                   |                       |
| Vietnamese          | 51.52                                                | 49.49                   | 51.52                   |                       |
| English             | 75.76                                                | 79.80                   | 74.75                   |                       |
| Average             | 58.51                                                | 59.02                   | 59.31                   |                       |
| Standard Deviation | 9.62                                                 | 12.57                   | 10.60                   |                       |
| Fleissâ€™ Kappa      | 0.56                                                 | 0.57                   | 0.56                   |                       |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , Qwen2.5-Math-PRM-72B ëª¨ë¸ì„ Process Reward Modeling (PRM) ë°©ë²•ì˜ í‰ê°€ìë¡œ ì‚¬ìš©í•˜ì—¬ MT-MATH100 ë°ì´í„°ì…‹ì— ëŒ€í•´ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¨, PRMì˜ ìƒì„± ë‹¨ê³„ ìˆ˜(S)ë¥¼ 7ë¡œ ê³ ì •í•˜ê³ , ìƒì„± í›„ë³´ ìˆ˜(c)ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì—¬ ì‹¤í—˜í•˜ì˜€ìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ì–¸ì–´ë³„ MT-MATH100 ì •í™•ë„, í‘œì¤€ í¸ì°¨, Fleiss' Kappa ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ë‹¤ì–‘í•œ í›„ë³´ ìˆ˜(c)ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Evaluation results of Qwen2.5-Math-1.5B-Instruct using Qwen2.5-Math-PRM-72B as PRM with steps fixed at (S=7)ğ‘†7(S=7)( italic_S = 7 ) on MT-MATH100.
> </details>

{{< table-caption >}}
| Language | PRM (S=3, c=8) | PRM (S=6, c=8) | PRM (S=9, c=8) |
|---|---|---|---| 
| **MT-MATH100** |  |  |  |
| **Language** | **PRM (S=3, c=8)** | **PRM (S=6, c=8)** | **PRM (S=9, c=8)** |
|Afrikaans | 54.55 | 55.56 | 60.61 |
|Arabic | 41.41 | 44.44 | 52.53 |
|Chinese (Simplified) | 71.72 | 71.72 | 70.71 |
|French | 67.68 | 64.65 | 67.68 |
|German | 56.57 | 57.58 | 66.67 |
|Hebrew | 42.42 | 46.46 | 45.45 |
|Indonesian | 60.61 | 59.60 | 62.63 |
|Italian | 56.57 | 60.61 | 61.62 |
|Japanese | 63.64 | 67.68 | 62.63 |
|Korean | 47.47 | 48.48 | 48.48 |
|Spanish | 65.66 | 64.65 | 72.73 |
|Turkish | 53.54 | 50.51 | 49.49 |
|Vietnamese | 57.58 | 51.52 | 57.58 |
|English | 75.76 | 75.76 | 77.78 |
|Average | 58.23 | 58.51 | 61.18 |
|Standard Deviation | 10.22 | 9.62 | 9.65 |
|Fleissâ€™ Kappa | 0.56 | 0.58 | 0.58 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , Qwen2.5-Math-PRM-72B ëª¨ë¸ì„ PRM(Process Reward Modeling)ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ MT-MATH100 ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¨ì¼ ì§ˆì˜ì— ëŒ€í•´ ìƒì„±ë˜ëŠ” í›„ë³´ ë‹µë³€ì˜ ìˆ˜(candidates)ë¥¼ 8ê°œë¡œ ê³ ì •í•˜ê³ , ìƒì„± ë‹¨ê³„(generation steps)ë¥¼ ë³€í™”ì‹œì¼œê°€ë©° ì •í™•ë„ì™€ ì¼ê´€ì„±ì„ ì¸¡ì •í•˜ì˜€ìŠµë‹ˆë‹¤. ê° ì–¸ì–´ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ì™€ ì „ì²´ í‰ê·  ì„±ëŠ¥, í‘œì¤€ í¸ì°¨, Fleiss' kappa ê°’ ë“±ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  MT-MATH100ì€ 55ê°œ ì–¸ì–´ë¡œ êµ¬ì„±ëœ ìˆ˜í•™ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì˜ í•˜ìœ„ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 15: Evaluation results of Qwen2.5-Math-1.5B-Instruct using Qwen2.5-Math-PRM-72B as PRM with the number of candidates fixed at 8, on MT-MATH100.
> </details>

{{< table-caption >}}
|                       | **MT-MATH100**                                                                   |                       |                       |
|-----------------------|------------------------------------------------------------------------------------|-----------------------|-----------------------|
| **Language**          | **PRM (S=7, c=7)** | **PRM (S=7, c=11)** | **PRM (S=7, c=18)** |
| Afrikaans             | 51.52                | 58.59                | 58.59                |
| Arabic                | 42.42                | 44.44                | 52.53                |
| Chinese (Simplified)  | 74.75                | 76.77                | 76.77                |
| French                | 72.73                | 69.70                | 71.72                |
| German                | 58.59                | 58.59                | 60.61                |
| Hebrew                | 39.39                | 44.44                | 41.41                |
| Indonesian            | 62.63                | 61.62                | 62.63                |
| Italian               | 60.61                | 58.59                | 64.65                |
| Japanese              | 67.68                | 63.64                | 61.62                |
| Korean                | 45.45                | 50.51                | 50.51                |
| Spanish               | 67.68                | 68.69                | 68.69                |
| Turkish               | 53.54                | 48.48                | 52.53                |
| Vietnamese            | 49.49                | 51.52                | 51.52                |
| English               | 79.80                | 74.75                | 70.71                |
| Average               | 59.02                | 59.31                | 60.32                |
| Standard Deviation    | 12.57                | 10.60                | 9.84                 |
| Fleissâ€™ Kappa        | 0.52                 | 0.55                 | 0.54                 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-PRM-7B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í›„ë³´ ìƒì„± íšŸìˆ˜ë¥¼ 7íšŒë¡œ ê³ ì •í•œ ìƒíƒœì—ì„œ Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì˜ MT-MATH100 ë°ì´í„°ì…‹ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì–¸ì–´ë³„ MT-MATH100 ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ëŠ” ìƒì„¸ ê²°ê³¼í‘œì´ë©°, í‰ê·  ì •í™•ë„, í‘œì¤€í¸ì°¨, Fleissâ€™ kappa ê°’ë„ í•¨ê»˜ ì œì‹œí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ê³¼ ì–¸ì–´ ê°„ ì¼ê´€ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 16: Evaluation results of Qwen2.5-Math-1.5B-Instruct using Qwen2.5-Math-PRM-7B as PRM with the number of candidates fixed at 7, on MT-MATH100.
> </details>

{{< table-caption >}}
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T17.1">
<tr class="ltx_tr" id="A3.T17.1.1">
<td class="ltx_td ltx_border_r ltx_border_tt" id="A3.T17.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A3.T17.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T17.1.1.2.1">MT-MATH100</span></td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.2.1"><span class="ltx_text ltx_font_bold" id="A3.T17.1.2.1.1">Language</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.2.2"><span class="ltx_text ltx_font_bold" id="A3.T17.1.2.2.1">PRM (S=3, c=13)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.2.3"><span class="ltx_text ltx_font_bold" id="A3.T17.1.2.3.1">PRM (S=6, c=13)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T17.1.2.4"><span class="ltx_text ltx_font_bold" id="A3.T17.1.2.4.1">PRM (S=9, c=13)</span></td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.3.1">Afrikaans</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.3.2">55.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.3.3">59.60</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T17.1.3.4">54.55</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.4.1">Arabic</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.4.2">44.44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.4.3">45.45</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.4.4">44.44</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.5.1">Chinese (Simplified)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.5.2">75.76</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.5.3">70.71</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.5.4">79.80</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.6.1">French</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.6.2">64.65</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.6.3">71.72</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.6.4">73.74</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.7.1">German</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.7.2">55.56</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.7.3">63.64</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.7.4">61.62</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.8.1">Hebrew</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.8.2">46.46</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.8.3">43.43</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.8.4">47.47</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.9.1">Indonesian</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.9.2">56.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.9.3">58.59</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.9.4">61.62</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.10.1">Italian</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.10.2">62.63</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.10.3">60.61</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.10.4">61.62</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.11.1">Japanese</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.11.2">58.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.11.3">67.68</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.11.4">59.60</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.12">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.12.1">Korean</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.12.2">49.49</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.12.3">48.48</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.12.4">51.52</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.13.1">Spanish</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.13.2">60.61</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.13.3">73.74</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.13.4">64.65</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.14">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.14.1">Turkish</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.14.2">49.49</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.14.3">50.51</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.14.4">49.49</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.15">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.15.1">Vietnamese</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.15.2">52.53</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.15.3">48.48</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.15.4">45.45</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.16" style="background-color:#FCE5CD;">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.16.1"><span class="ltx_text" id="A3.T17.1.16.1.1" style="background-color:#FCE5CD;">English</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.16.2"><span class="ltx_text" id="A3.T17.1.16.2.1" style="background-color:#FCE5CD;">71.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.16.3"><span class="ltx_text" id="A3.T17.1.16.3.1" style="background-color:#FCE5CD;">73.74</span></td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.16.4"><span class="ltx_text" id="A3.T17.1.16.4.1" style="background-color:#FCE5CD;">77.78</span></td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.17">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.17.1">Average</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.17.2">57.43</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T17.1.17.3">59.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T17.1.17.4">59.52</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.18">
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.18.1">Standard Deviation</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.18.2">9.10</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T17.1.18.3">10.90</td>
<td class="ltx_td ltx_align_center" id="A3.T17.1.18.4">11.59</td>
</tr>
<tr class="ltx_tr" id="A3.T17.1.19">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A3.T17.1.19.1">Fleissâ€™ Kappa</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A3.T17.1.19.2">0.54</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A3.T17.1.19.3">0.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T17.1.19.4">0.52</td>
</tr>
</table>{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ë…¼ë¬¸ì˜ 4.2ì ˆ 'í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ë§'ì—ì„œ Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì— Qwen2.5-Math-PRM-7Bë¥¼ PRM(Process Reward Modeling)ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ MT-MATH100 ë°ì´í„°ì…‹ì— ëŒ€í•´ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í›„ë³´ ìƒì„± ë‹¨ê³„(generation steps, S)ë¥¼ 3, 6, 9ë¡œ, ê° ë‹¨ê³„ì—ì„œ ìƒì„±í•˜ëŠ” í›„ë³´ ê°œìˆ˜(candidates per step, c)ë¥¼ 13ê°œë¡œ ê³ ì •í•˜ê³ , ë‹¤ì–‘í•œ ì–¸ì–´ì— ëŒ€í•œ ì •í™•ë„ ë° ì¼ê´€ì„±ì„ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ ì •í™•ë„ì™€ ì „ì²´ì ì¸ ì¼ê´€ì„± ì§€í‘œ(Fleiss' kappa)ê°€ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 17: Evaluation results of Qwen2.5-Math-1.5B-Instruct using Qwen2.5-Math-PRM-7B as PRM with the number of candidates fixed at 13, on MT-MATH100.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 47.47 | 36.67 | 5.56 |  |
| Albanian | 31.31 | 13.33 | 8.00 |  |
| Arabic | 36.36 | 23.33 | 7.41 |  |
| Bengali | 33.33 | 10.00 |  |  |
| Bulgarian | 41.41 | 10.00 | 11.11 |  |
| Catalan | 47.47 | 16.67 |  |  |
| Chinese (Simplified) | 57.58 | 23.33 | 18.52 |  |
| Chinese (Traditional) | 43.43 | 16.67 | 22.22 | 23.33 |
| Croatian | 38.38 | 16.67 | 7.41 |  |
| Czech | 33.33 | 30.00 | 3.70 | 3.33 |
| Danish | 41.41 | 23.33 | 7.41 |  |
| Dutch | 45.45 | 16.67 | 7.41 | 16.67 |
| Estonian | 38.38 | 10.00 | 12.00 |  |
| Finnish | 30.30 | 23.33 | 12.00 |  |
| French | 39.39 | 6.67 | 7.41 | 35.48 |
| German | 45.45 | 23.33 | 18.52 | 6.67 |
| Greek | 30.30 | 16.67 | 0.00 |  |
| Gujarati | 27.27 | 6.67 |  |  |
| Hebrew | 36.36 | 16.67 | 7.41 |  |
| Hindi | 36.36 | 10.00 |  |  |
| Hungarian | 39.39 | 16.67 | 8.00 |  |
| Indonesian | 37.37 | 13.33 | 4.76 |  |
| Italian | 41.41 | 13.33 | 12.00 |  |
| Japanese | 45.45 | 20.00 | 12.00 | 3.57 |
| Kannada | 32.32 | 10.00 |  |  |
| Korean | 39.39 | 16.67 | 14.81 | 16.67 |
| Latvian | 30.30 | 6.67 | 4.00 |  |
| Lithuanian | 31.31 | 6.67 | 14.81 |  |
| Macedonian | 31.31 | 0.00 | 7.41 |  |
| Malayalam | 27.27 | 13.33 |  |  |
| Marathi | 33.33 | 13.33 |  |  |
| Nepali | 35.35 | 13.33 |  |  |
| Norwegian | 37.37 | 16.67 | 11.11 |  |
| Persian | 29.29 | 20.00 |  |  |
| Polish | 38.38 | 6.67 | 11.11 | 13.33 |
| Portuguese | 47.47 | 20.00 | 8.00 |  |
| Punjabi | 29.29 | 16.67 |  |  |
| Romanian | 41.41 | 10.00 | 18.52 |  |
| Russian | 46.46 | 16.67 | 12.00 | 20.00 |
| Slovak | 35.35 | 16.67 | 11.11 | 10.00 |
| Slovenian | 35.35 | 23.33 | 11.11 |  |
| Somali | 26.26 | 16.67 |  |  |
| Spanish | 46.46 | 16.67 | 11.11 |  |
| Swahili | 36.36 | 6.67 |  |  |
| Swedish | 39.39 | 13.33 | 8.00 |  |
| Tagalog | 35.35 | 13.33 |  |  |
| Tamil | 33.33 | 10.00 |  |  |
| Telugu | 34.34 | 13.33 |  |  |
| Thai | 30.30 | 10.00 | 7.41 |  |
| Turkish | 42.42 | 6.67 | 11.11 |  |
| Ukrainian | 35.35 | 3.33 | 11.11 |  |
| Urdu | 28.28 | 13.33 |  |  |
| Vietnamese | 31.31 | 10.00 | 7.41 |  |
| Welsh | 30.30 | 23.33 |  |  |
| English | 65.66 | 20.00 | 25.93 | 53.33 |
| Average | 37.47 | 14.85 | 10.50 | 18.40 |
| Standard Deviation | 7.56 | 6.69 | 5.16 | 14.92 |
| Fleissâ€™ Kappa | 0.41 | 0.13 | 0.19 |  |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì— ì¶”ê°€ì ì¸ ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ ì‚¬ê³ ë ¥(System 2 Thinking) í•™ìŠµì„ ì ìš©í•œ í›„ MCLM ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ MT-MATH100, MT-AIME2024, M-IMO, M-MO í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ ì ìˆ˜ì™€ í‘œì¤€í¸ì°¨, ê·¸ë¦¬ê³  ì „ì²´ì ì¸ ì¼ê´€ì„±(Fleiss' Kappa)ì„ ì œì‹œí•©ë‹ˆë‹¤.  ë‹¨ìˆœ ì •í™•ë„ ë¿ ì•„ë‹ˆë¼, ë‹¤ì–‘í•œ ì–¸ì–´ì— ê±¸ì³ ëª¨ë¸ì˜ ì„±ëŠ¥ ì¼ê´€ì„±ì„ í‰ê°€í•˜ì—¬, í…ŒìŠ¤íŠ¸ ì‹œê°„ ìŠ¤ì¼€ì¼ë§ì˜ ì–¸ì–´ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë¶„ì„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 18: Evaluation results of Qwen2.5-Math-1.5B-Instruct + SFT on MCLM.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 39.39 | 10.00 | 13.64 |  |
| Albanian | 39.39 | 16.67 | 7.69 |  |
| Arabic | 41.41 | 16.67 | 14.81 |  |
| Bengali | 39.39 | 30.00 |  |  |
| Bulgarian | 42.42 | 10.00 | 11.11 |  |
| Catalan | 51.52 | 26.67 |  |  |
| Chinese (Simplified) | 50.51 | 23.33 | 7.41 |  |
| Chinese (Traditional) | 52.53 | 20.00 | 11.11 | 13.33 |
| Croatian | 38.38 | 13.33 | 11.11 |  |
| Czech | 51.52 | 23.33 | 11.11 | 10.00 |
| Danish | 40.40 | 6.67 | 3.70 |  |
| Dutch | 48.48 | 20.00 | 11.11 | 20.00 |
| Estonian | 37.37 | 23.33 | 15.38 |  |
| Finnish | 40.40 | 20.00 | 7.69 |  |
| French | 46.46 | 10.00 | 7.41 | 32.26 |
| German | 49.49 | 10.00 | 7.41 | 3.33 |
| Greek | 28.28 | 20.00 | 17.39 |  |
| Gujarati | 42.42 | 13.33 |  |  |
| Hebrew | 39.39 | 13.33 | 3.70 |  |
| Hindi | 45.45 | 13.33 |  |  |
| Hungarian | 43.43 | 40.00 | 11.54 |  |
| Indonesian | 51.52 | 16.67 | 16.67 |  |
| Italian | 48.48 | 13.33 | 11.54 |  |
| Japanese | 50.51 | 6.67 | 11.54 | 3.57 |
| Kannada | 32.32 | 10.00 |  |  |
| Korean | 55.56 | 10.00 | 11.11 | 26.67 |
| Latvian | 42.42 | 10.00 | 15.38 |  |
| Lithuanian | 36.36 | 13.33 | 7.41 |  |
| Macedonian | 39.39 | 13.33 | 18.52 |  |
| Malayalam | 34.34 | 26.67 |  |  |
| Marathi | 37.37 | 23.33 |  |  |
| Nepali | 42.42 | 16.67 |  |  |
| Norwegian | 42.42 | 10.00 | 3.70 |  |
| Persian | 47.47 | 10.00 |  |  |
| Polish | 38.38 | 10.00 | 14.81 | 20.00 |
| Portuguese | 50.51 | 26.67 | 11.54 |  |
| Punjabi | 29.29 | 16.67 |  |  |
| Romanian | 45.45 | 6.67 | 11.11 |  |
| Russian | 57.58 | 13.33 | 7.69 | 36.67 |
| Slovak | 47.47 | 20.00 | 7.41 |  |
| Slovenian | 39.39 | 23.33 | 18.52 |  |
| Somali | 22.22 | 26.67 |  |  |
| Spanish | 44.44 | 16.67 | 0.00 |  |
| Swahili | 34.34 | 6.67 |  |  |
| Swedish | 42.42 | 10.00 | 3.85 |  |
| Tagalog | 35.35 | 6.67 |  |  |
| Tamil | 36.36 | 23.33 |  |  |
| Telugu | 36.36 | 13.33 |  |  |
| Thai | 34.34 | 26.67 | 14.81 |  |
| Turkish | 39.39 | 23.33 | 7.41 |  |
| Ukrainian | 49.49 | 10.00 | 7.41 |  |
| Urdu | 32.32 | 20.00 |  |  |
| Vietnamese | 47.47 | 10.00 | 18.52 |  |
| Welsh | 28.28 | 20.00 |  |  |
| English | 51.52 | 26.67 | 7.41 | 40.00 |
| Average | 42.02 | 16.67 | 10.52 | 20.58 |
| Standard Deviation | 7.46 | 7.31 | 4.63 | 13.17 |
| Fleissâ€™ Kappa | 0.40 | 0.13 | 0.25 |  |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ë…¼ë¬¸ì˜ 5ì¥ 'Result 2: Budget Forcing' ì—ì„œ ë‹¤êµ­ì–´ ê²½ìŸ ìˆ˜ì¤€ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬(MCLM)ì— ëŒ€í•œ Qwen2.5-Math-1.5B-Instruct + MT-SFT ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  MT-MATH100, MT-AIME2024, M-IMO, M-MO ë„¤ ê°€ì§€ í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„, í‘œì¤€í¸ì°¨, ê·¸ë¦¬ê³  Fleiss' kappa ê°’ì„ ê° ì–¸ì–´ë³„ë¡œ ì œì‹œí•˜ì—¬ ë‹¤êµ­ì–´ ì„±ëŠ¥ì˜ ì¼ê´€ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. ê° ì–¸ì–´ì˜ ì ìˆ˜ëŠ” í•´ë‹¹ ëª¨ë¸ì´ MCLMì˜ ê° í•˜ìœ„ ë°ì´í„°ì…‹ì—ì„œ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ë¬¸ì œë¥¼ í’€ì—ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  í‘œì¤€í¸ì°¨ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ ë³€ë™ì„±ì„, Fleiss' kappa ê°’ì€ ë‹¤êµ­ì–´ ê°„ ì¼ê´€ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 19: Evaluation results of Qwen2.5-Math-1.5B-Instruct + MT-SFT on MCLM.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 58.59 | 20.00 | 11.11 |  |
| Albanian | 46.46 | 30.00 | 16.00 |  |
| Arabic | 51.52 | 20.00 | 18.52 |  |
| Bengali | 56.57 | 10.00 |  |  |
| Bulgarian | 57.58 | 16.67 | 11.11 |  |
| Catalan | 64.65 | 30.00 |  |  |
| Chinese (Simplified) | 69.70 | 16.67 | 25.93 |  |
| Chinese (Traditional) | 67.68 | 20.00 | 18.52 | 33.33 |
| Croatian | 59.60 | 36.67 | 18.52 |  |
| Czech | 57.58 | 33.33 | 18.52 | 16.67 |
| Danish | 56.57 | 16.67 | 14.81 |  |
| Dutch | 64.65 | 30.00 | 22.22 | 23.33 |
| Estonian | 39.39 | 6.67 | 12.00 |  |
| Finnish | 52.53 | 16.67 | 20.00 |  |
| French | 63.64 | 26.67 | 29.63 | 48.39 |
| German | 63.64 | 16.67 | 25.93 | 26.67 |
| Greek | 38.38 | 13.33 | 10.53 |  |
| Gujarati | 47.47 | 3.33 |  |  |
| Hebrew | 61.62 | 23.33 | 7.41 |  |
| Hindi | 61.62 | 23.33 |  |  |
| Hungarian | 55.56 | 26.67 | 24.00 |  |
| Indonesian | 69.70 | 13.33 | 23.81 |  |
| Italian | 69.70 | 36.67 | 28.00 |  |
| Japanese | 62.63 | 16.67 | 12.00 | 3.57 |
| Kannada | 42.42 | 16.67 |  |  |
| Korean | 61.62 | 20.00 | 11.11 | 30.00 |
| Latvian | 49.49 | 6.67 | 20.00 |  |
| Lithuanian | 40.40 | 23.33 | 14.81 |  |
| Macedonian | 59.60 | 23.33 | 25.93 |  |
| Malayalam | 41.41 | 3.33 |  |  |
| Marathi | 39.39 | 23.33 |  |  |
| Nepali | 50.51 | 10.00 |  |  |
| Norwegian | 67.68 | 13.33 | 18.52 |  |
| Persian | 61.62 | 13.33 |  |  |
| Polish | 62.63 | 16.67 | 22.22 | 23.33 |
| Portuguese | 75.76 | 23.33 | 16.00 |  |
| Punjabi | 42.42 | 13.33 |  |  |
| Romanian | 58.59 | 26.67 | 22.22 |  |
| Russian | 68.69 | 33.33 | 20.00 | 26.67 |
| Slovak | 58.59 | 13.33 | 11.11 | 20.00 |
| Slovenian | 56.57 | 30.00 | 14.81 |  |
| Somali | 30.30 | 20.00 |  |  |
| Spanish | 69.70 | 30.00 | 25.93 |  |
| Swahili | 42.42 | 20.00 |  |  |
| Swedish | 54.55 | 13.33 | 20.00 |  |
| Tagalog | 47.47 | 23.33 |  |  |
| Tamil | 40.40 | 16.67 |  |  |
| Telugu | 36.36 | 23.33 |  |  |
| Thai | 59.60 | 13.33 | 29.63 |  |
| Turkish | 61.62 | 36.67 | 22.22 |  |
| Ukrainian | 67.68 | 16.67 | 18.52 |  |
| Urdu | 50.51 | 20.00 |  |  |
| Vietnamese | 61.62 | 13.33 | 33.33 |  |
| Welsh | 34.34 | 16.67 |  |  |
| English | 67.68 | 20.00 | 14.81 | 66.67 |
| Average | 55.61 | 19.94 | 19.20 | 28.97 |
| Standard Deviation | 10.93 | 8.10 | 6.24 | 16.64 |
| Fleissâ€™ Kappa | 0.47 | 0.30 | 0.19 |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 20ëŠ” ë‹¤êµ­ì–´ ê²½ìŸ ìˆ˜ì¤€ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬(MCLM)ì—ì„œ DeepSeek-R1-1.5B ëª¨ë¸ì— ë‹¤êµ­ì–´ ë¯¸ì„¸ ì¡°ì •(MT-SFT)ì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ì–¸ì–´ì˜ ìˆ˜í•™ ë¬¸ì œì— ëŒ€í•œ ëª¨ë¸ì˜ ì •í™•ë„, í‘œì¤€ í¸ì°¨, ê·¸ë¦¬ê³  ì–¸ì–´ ê°„ ì¼ê´€ì„±(Fleiss' Kappa)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  MT-MATH100, MT-AIME2024, M-IMO, M-MO ë„¤ ê°€ì§€ í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ê°ê° ì œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ MT-SFTë¥¼ ì ìš©í•œ ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ì¶”ë¡  ëŠ¥ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 20: Evaluation results of DeepSeek-R1-1.5B + MT-SFT on MCLM.
> </details>

{{< table-caption >}}
| Language | BF (N=2048) | BF (N=4096) | BF (N=8192) |  |  |  |
|---|---|---|---|---|---|---|
| **Language** | **MT-AIME2024** | **MT-AIME2024** | **MT-MATH100** | **MT-AIME2024** | **M-IMO** | **M-MO** |
|Afrikaans|23.33|23.33|59.60|30.00|9.09| |
|Albanian|23.33|26.67|48.48|26.67|7.69| |
|Arabic|16.67|23.33|60.61|26.67|14.81| |
|Bengali|33.33|30.00|54.55|23.33| | |
|Bulgarian|33.33|33.33|61.62|26.67|22.22| |
|Catalan|20.00|43.33|64.65|43.33| | |
|Chinese (Simplified)|20.00|16.67|69.70|16.67|22.22| |
|Chinese (Traditional)|26.67|26.67|70.71|36.67|18.52|40.00|
|Croatian|30.00|30.00|60.61|30.00|37.04| |
|Czech|40.00|20.00|62.63|20.00|29.63|33.33|
|Danish|30.00|33.33|61.62|30.00|22.22| |
|Dutch|10.00|23.33|70.71|36.67|25.93|20.00|
|Estonian|23.33|16.67|40.40|20.00|15.38| |
|Finnish|20.00|33.33|51.52|20.00|30.77| |
|French|16.67|23.33|72.73|16.67|25.93|51.61|
|German|26.67|20.00|75.76|26.67|25.93|30.00|
|Greek|6.67|13.33|42.42|16.67|21.74| |
|Gujarati|16.67|16.67|51.52|16.67| | |
|Hebrew|33.33|23.33|60.61|16.67|14.81| |
|Hindi|26.67|10.00|61.62|20.00| | |
|Hungarian|30.00|26.67|58.59|23.33|26.92| |
|Indonesian|10.00|30.00|73.74|30.00|25| |
|Italian|20.00|26.67|74.75|36.67|23.08| |
|Japanese|20.00|16.67|63.64|36.67|23.08|7.14|
|Kannada|10.00|13.33|49.49|10.00| | |
|Korean|16.67|23.33|64.65|20.00|11.11|40.00|
|Latvian|30.00|20.00|52.53|10.00|23.08| |
|Lithuanian|10.00|6.67|46.46|26.67|18.52| |
|Macedonian|20.00|20.00|63.64|23.33|25.93| |
|Malayalam|10.00|13.33|51.52|13.33| | |
|Marathi|20.00|26.67|51.52|23.33| | |
|Nepali|30.00|13.33|54.55|20.00| | |
|Norwegian|26.67|26.67|65.66|20.00|18.52| |
|Persian|26.67|23.33|62.63|36.67| | |
|Polish|23.33|20.00|66.67|16.67|14.81|23.33|
|Portuguese|20.00|26.67|79.80|20.00|15.38| |
|Punjabi|23.33|26.67|51.52|20.00| | |
|Romanian|30.00|23.33|60.61|10.00|22.22| |
|Russian|36.67|30.00|72.73|30.00|23.08|30.00|
|Slovak|40.00|23.33|66.67|30.00|25.93| |
|Slovenian|20.00|20.00|60.61|33.33|25.93| |
|Somali|20.00|16.67|35.35|16.67| | |
|Spanish|30.00|30.00|71.72|40.00|18.52| |
|Swahili|13.33|13.33|41.41|30.00| | |
|Swedish|13.33|16.67|62.63|23.33|19.23| |
|Tagalog|10.00|20.00|52.53|23.33| | |
|Tamil|26.67|20.00|44.44|23.33| | |
|Telugu|13.33|16.67|44.44|20.00| | |
|Thai|26.67|13.33|64.65|23.33|11.11| |
|Turkish|20.00|16.67|61.62|16.67|33.33| |
|Ukrainian|30.00|26.67|73.74|23.33|22.22| |
|Urdu|23.33|20.00|46.46|20.00| | |
|Vietnamese|20.00|26.67|62.63|40.00|25.93| |
|Welsh|20.00|16.67|42.42|13.33| | |
|English|20.00|26.67|71.72|40.00|22.22|76.67|
|Average|22.48|22.24|59.45|24.42|21.55|35.21|
|Standard Deviation|7.94|6.85|10.52|8.32|6.44|19.01|
|Fleissâ€™ Kappa|0.33|0.37|0.44|0.32|0.19| |{{< /table-caption >}}
> ğŸ”¼ í‘œ 21ì€ Qwen2.5-Math-1.5B-Instruct ëª¨ë¸ì— ëŒ€í•´ ì˜ˆì‚° ì œì•½(Budget Forcing) ê¸°ë²•ì„ ì ìš©í–ˆì„ ë•Œì˜ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì˜ˆì‚° ì œì•½ì€ ëª¨ë¸ì´ ìƒì„±í•  ìˆ˜ ìˆëŠ” í† í°ì˜ ìˆ˜ë¥¼ ì œí•œí•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, ì—¬ê¸°ì„œëŠ” 2048, 4096, 8192 í† í°ì˜ ì„¸ ê°€ì§€ ë‹¤ë¥¸ ì˜ˆì‚°ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜í–ˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ì–¸ì–´ë³„ë¡œ ì„¸ ê°€ì§€ ë‹¤ë¥¸ ì˜ˆì‚° ì„¤ì •ì—ì„œ MT-MATH100, MT-AIME2024, M-IMO, M-MO ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„, í‘œì¤€ í¸ì°¨, ê·¸ë¦¬ê³  Fleiss' Kappa ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì–¸ì–´ ê°„ ì¼ê´€ì„±ì„ ë‹¤ì–‘í•œ ì˜ˆì‚° ìˆ˜ì¤€ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 21: Evaluation results of Qwen2.5-Math-1.5B-Instruct with Budget Forcing (Bâ¢F=2048,4096,8192ğµğ¹204840968192BF=2048,4096,8192italic_B italic_F = 2048 , 4096 , 8192).
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 72.73 | 13.33 | 27.78 |  |
| Albanian | 60.61 | 16.67 | 20 |  |
| Arabic | 76.77 | 13.33 | 14.81 |  |
| Bengali | 72.73 | 16.67 |  |  |
| Bulgarian | 72.73 | 16.67 |  |  |
| Catalan | 73.74 | 20.00 |  |  |
| Chinese (Simplified) | 77.78 | 20.00 | 7.41 |  |
| Chinese (Traditional) | 73.74 | 23.33 | 11.11 | 56.67 |
| Croatian | 73.74 | 30.00 | 22.22 |  |
| Czech | 75.76 | 20.00 | 11.11 | 16.67 |
| Danish | 72.73 | 23.33 | 18.52 |  |
| Dutch | 77.78 | 16.67 | 18.52 | 23.33 |
| Estonian | 57.58 | 13.33 | 20 |  |
| Finnish | 70.71 | 20.00 | 16 |  |
| French | 77.78 | 20.00 | 25.93 | 48.39 |
| German | 76.77 | 23.33 | 25.93 | 26.67 |
| Greek | 64.65 | 13.33 | 10.53 |  |
| Gujarati | 55.56 | 16.67 |  |  |
| Hebrew | 71.72 | 20.00 | 7.41 |  |
| Hindi | 70.71 | 30.00 |  |  |
| Hungarian | 71.72 | 26.67 | 20 |  |
| Indonesian | 69.70 | 20.00 | 19.05 |  |
| Italian | 78.79 | 23.33 | 12 |  |
| Japanese | 76.77 | 23.33 | 16 | 3.57 |
| Kannada | 57.58 | 20.00 |  | 40 |
| Korean | 77.78 | 20.00 | 14.81 |  |
| Latvian | 59.60 | 13.33 | 20 |  |
| Lithuanian | 61.62 | 16.67 | 25.93 |  |
| Macedonian | 77.78 | 16.67 | 22.22 |  |
| Malayalam | 56.57 | 10.00 |  |  |
| Marathi | 63.64 | 16.67 |  |  |
| Nepali | 67.68 | 20.00 |  |  |
| Norwegian | 73.74 | 23.33 | 22.22 |  |
| Persian | 74.75 | 30.00 |  |  |
| Polish | 71.72 | 16.67 | 22.22 | 26.67 |
| Portuguese | 78.79 | 26.67 | 20 |  |
| Punjabi | 58.59 | 16.67 |  |  |
| Romanian | 76.77 | 23.33 | 14.81 |  |
| Russian | 77.78 | 20.00 | 20 | 43.33 |
| Slovak | 74.75 | 23.33 | 18.52 | 23.33 |
| Slovenian | 71.72 | 23.33 | 14.81 |  |
| Somali | 38.38 | 6.67 |  |  |
| Spanish | 75.76 | 30.00 | 14.81 |  |
| Swahili | 46.46 | 13.33 |  |  |
| Swedish | 76.77 | 16.67 | 24 |  |
| Tagalog | 60.61 | 16.67 |  |  |
| Tamil | 54.55 | 10.00 |  |  |
| Telugu | 60.61 | 16.67 |  |  |
| Thai | 73.74 | 20.00 | 14.81 |  |
| Turkish | 70.71 | 20.00 | 7.41 |  |
| Ukrainian | 76.77 | 23.33 | 14.81 |  |
| Urdu | 63.64 | 50.00 |  |  |
| Vietnamese | 76.77 | 26.67 | 14.81 |  |
| Welsh | 50.51 | 20.00 |  |  |
| English | 83.84 | 20.00 | 22.22 | 46.67 |
| Average | 69.33 | 20.12 | 17.64 | 32.30 |
| Standard Deviation | 9.42 | 6.57 | 5.38 | 15.92 |
| Fleiss Kappa | 0.61 | 0.51 | 0.38 | 15.81 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-7B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ MCLM(Multilingual Competition Level Math) ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê° ì–¸ì–´ë³„ë¡œ ìˆ˜í–‰í•œ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  greedy decoding ë°©ì‹ì„ ì‚¬ìš©í–ˆìœ¼ë©°, MT-MATH100, MT-AIME2024, M-IMO, M-MO ë„¤ ê°€ì§€ í•˜ìœ„ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ì–¸ì–´ë³„ë¡œ ì œì‹œí•©ë‹ˆë‹¤. í‰ê·  ì •í™•ë„ì™€ í‘œì¤€ í¸ì°¨, Fleiss' Kappa ê°’ì„ í†µí•´ ì „ë°˜ì ì¸ ì„±ëŠ¥ê³¼ ì–¸ì–´ ê°„ ì¼ê´€ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 22: Evaluation results of Qwen2.5-Math-7B-Instruct with greedy decoding on MCLM.
> </details>

{{< table-caption >}}
| Language | ORM (K=2) MT-MATH100 | ORM (K=2) MT-AIME2024 | ORM (K=4) MT-MATH100 | ORM (K=4) MT-AIME2024 | ORM (K=8) MT-MATH100 | ORM (K=8) MT-AIME2024 |
|---|---|---|---|---|---|---|
| Afrikaans | 74.75 | 16.67 | 73.74 | 26.67 | 76.77 | 33.33 |
| Albanian | 68.69 | 20.00 | 65.66 | 26.67 | 68.69 | 26.67 |
| Arabic | 76.77 | 13.33 | 82.83 | 23.33 | 83.84 | 20.00 |
| Bengali | 69.70 | 16.67 | 75.76 | 16.67 | 74.75 | 16.67 |
| Bulgarian | 73.74 | 16.67 | 77.78 | 20.00 | 79.80 | 16.67 |
| Catalan | 75.76 | 26.67 | 77.78 | 20.00 | 76.77 | 30.00 |
| Chinese (Simplified) | 77.78 | 20.00 | 81.82 | 26.67 | 82.83 | 26.67 |
| Chinese (Traditional) | 77.78 | 23.33 | 81.82 | 23.33 | 81.82 | 23.33 |
| Croatian | 75.76 | 30.00 | 78.79 | 33.33 | 78.79 | 33.33 |
| Czech | 75.76 | 20.00 | 81.82 | 23.33 | 81.82 | 23.33 |
| Danish | 73.74 | 26.67 | 72.73 | 43.33 | 74.75 | 43.33 |
| Dutch | 76.77 | 20.00 | 78.79 | 26.67 | 81.82 | 40.00 |
| Estonian | 62.63 | 16.67 | 64.65 | 23.33 | 65.66 | 30.00 |
| Finnish | 73.74 | 23.33 | 77.78 | 33.33 | 75.76 | 33.33 |
| French | 81.82 | 23.33 | 81.82 | 20.00 | 81.82 | 26.67 |
| German | 78.79 | 33.33 | 81.82 | 40.00 | 83.84 | 40.00 |
| Greek | 65.66 | 20.00 | 67.68 | 23.33 | 70.71 | 16.67 |
| Gujarati | 58.59 | 13.33 | 59.60 | 20.00 | 64.65 | 16.67 |
| Hebrew | 73.74 | 13.33 | 75.76 | 20.00 | 76.77 | 30.00 |
| Hindi | 70.71 | 26.67 | 75.76 | 26.67 | 75.76 | 36.67 |
| Hungarian | 73.74 | 26.67 | 76.77 | 20.00 | 76.77 | 23.33 |
| Indonesian | 75.76 | 30.00 | 76.77 | 33.33 | 77.78 | 43.33 |
| Italian | 79.80 | 26.67 | 79.80 | 26.67 | 82.83 | 33.33 |
| Japanese | 78.79 | 23.33 | 79.80 | 30.00 | 80.81 | 23.33 |
| Kannada | 55.56 | 13.33 | 57.58 | 13.33 | 59.60 | 20.00 |
| Korean | 79.80 | 16.67 | 76.77 | 23.33 | 77.78 | 26.67 |
| Latvian | 61.62 | 16.67 | 65.66 | 10.00 | 66.67 | 10.00 |
| Lithuanian | 63.64 | 20.00 | 68.69 | 30.00 | 69.70 | 20.00 |
| Macedonian | 76.77 | 16.67 | 80.81 | 20.00 | 79.80 | 23.33 |
| Malayalam | 59.60 | 10.00 | 62.63 | 16.67 | 68.69 | 23.33 |
| Marathi | 65.66 | 26.67 | 68.69 | 20.00 | 69.70 | 16.67 |
| Nepali | 64.65 | 13.33 | 69.70 | 16.67 | 68.69 | 16.67 |
| Norwegian | 72.73 | 26.67 | 74.75 | 30.00 | 76.77 | 33.33 |
| Persian | 76.77 | 23.33 | 75.76 | 23.33 | 76.77 | 16.67 |
| Polish | 77.78 | 10.00 | 78.79 | 10.00 | 78.79 | 16.67 |
| Portuguese | 81.82 | 26.67 | 80.81 | 36.67 | 83.84 | 40.00 |
| Punjabi | 58.59 | 20.00 | 59.60 | 16.67 | 62.63 | 26.67 |
| Romanian | 79.80 | 23.33 | 81.82 | 26.67 | 79.80 | 30.00 |
| Russian | 78.79 | 26.67 | 82.83 | 20.00 | 86.87 | 26.67 |
| Slovak | 77.78 | 30.00 | 79.80 | 33.33 | 81.82 | 30.00 |
| Slovenian | 73.74 | 13.33 | 78.79 | 20.00 | 78.79 | 23.33 |
| Somali | 38.38 | 6.67 | 42.42 | 13.33 | 44.44 | 20.00 |
| Spanish | 75.76 | 26.67 | 78.79 | 26.67 | 81.82 | 30.00 |
| Swahili | 48.48 | 13.33 | 49.49 | 20.00 | 51.52 | 23.33 |
| Swedish | 77.78 | 30.00 | 76.77 | 30.00 | 77.78 | 30.00 |
| Tagalog | 58.59 | 13.33 | 65.66 | 10.00 | 66.67 | 16.67 |
| Tamil | 59.60 | 16.67 | 65.66 | 10.00 | 62.63 | 10.00 |
| Telugu | 61.62 | 20.00 | 63.64 | 23.33 | 62.63 | 16.67 |
| Thai | 76.77 | 16.67 | 79.80 | 23.33 | 77.78 | 30.00 |
| Turkish | 76.77 | 26.67 | 79.80 | 26.67 | 79.80 | 26.67 |
| Ukrainian | 77.78 | 23.33 | 78.79 | 23.33 | 79.80 | 26.67 |
| Urdu | 66.67 | 33.33 | 67.68 | 30.00 | 72.73 | 30.00 |
| Vietnamese | 73.74 | 33.33 | 76.77 | 33.33 | 80.81 | 36.67 |
| Welsh | 51.52 | 20.00 | 53.54 | 16.67 | 56.57 | 6.67 |
| English | 84.85 | 26.67 | 84.85 | 30.00 | 86.87 | 26.67 |
| Average | 70.98 | 21.21 | 73.35 | 23.82 | 74.62 | 25.76 |
| Standard Deviation | 9.46 | 6.52 | 9.20 | 7.41 | 8.86 | 8.37 |
| Fleissâ€™ Kappa | 0.62 | 0.55 | 0.65 | 0.57 | 0.67 | 0.57 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-7B-Instruct ëª¨ë¸ì— ëŒ€í•´, ì„¸ ê°€ì§€ ë‹¤ë¥¸ Best-of-N (K=2, 4, 8) ì „ëµì„ ì‚¬ìš©í•˜ì—¬ MT-MATH100 ë° MT-AIME2024 ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Qwen2.5-Math-RM-72Bê°€ ORM(Outcome Reward Modeling)ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.  ê° ì „ëµì— ëŒ€í•œ í‰ê·  ì •í™•ë„, í‘œì¤€ í¸ì°¨, ê·¸ë¦¬ê³  Fleiss' kappa ê°’ì´ ì œì‹œë˜ì–´ ë‹¤êµ­ì–´ ì„±ëŠ¥ì˜ ì•ˆì •ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 23: Evaluation results of Qwen2.5-Math-7B-Instruct with Best-of-N (K=2,4,8)ğ¾248(K=2,4,8)( italic_K = 2 , 4 , 8 ) using Qwen2.5-Math-RM-72B as ORM on MT-MATH100 and MT-AIME2024.
> </details>

{{< table-caption >}}
| Language | PRM (S=3, c=3)  |  | PRM (S=4, c=5) |  | PRM (S=5, c=8) |  |
|---|---|---|---|---|---|---|
| **Language** | **MT-MATH100** | **MT-AIME2024** | **MT-MATH100** | **MT-AIME2024** | **MT-MATH100** | **MT-AIME2024** |
|Afrikaans|70.71|20.00|70.71|16.67|70.71|20.00|
|Albanian|60.61|16.67|62.63|33.33|61.62|26.67|
|Arabic|65.66|26.67|78.79|26.67|82.83|30.00|
|Bengali|67.68|16.67|70.71|10.00|68.69|23.33|
|Bulgarian|69.70|20.00|74.75|10.00|75.76|30.00|
|Catalan|72.73|16.67|70.71|20.00|71.72|16.67|
|Chinese (Simplified)|72.73|16.67|73.74|33.33|78.79|30.00|
|Chinese (Traditional)|71.72|16.67|76.77|20.00|77.78|23.33|
|Croatian|69.70|20.00|72.73|16.67|70.71|33.33|
|Czech|69.70|16.67|77.78|10.00|73.74|30.00|
|Danish|63.64|23.33|69.70|33.33|66.67|30.00|
|Dutch|71.72|6.67|72.73|26.67|75.76|26.67|
|Estonian|46.46|20.00|51.52|13.33|59.60|20.00|
|Finnish|64.65|16.67|66.67|13.33|72.73|33.33|
|French|73.74|20.00|72.73|16.67|76.77|26.67|
|German|73.74|10.00|68.69|10.00|76.77|26.67|
|Greek|63.64|16.67|64.65|13.33|67.68|13.33|
|Gujarati|56.57|13.33|56.57|26.67|55.56|13.33|
|Hebrew|66.67|10.00|68.69|20.00|75.76|26.67|
|Hindi|58.59|16.67|63.64|20.00|72.73|13.33|
|Hungarian|68.69|16.67|69.70|30.00|72.73|20.00|
|Indonesian|69.70|26.67|68.69|20.00|72.73|10.00|
|Italian|71.72|16.67|77.78|30.00|73.74|23.33|
|Japanese|71.72|23.33|75.76|16.67|76.77|13.33|
|Kannada|46.46|16.67|53.54|10.00|54.55|16.67|
|Korean|69.70|16.67|72.73|13.33|74.75|16.67|
|Latvian|59.60|10.00|63.64|13.33|63.64|16.67|
|Lithuanian|55.56|20.00|62.63|13.33|65.66|16.67|
|Macedonian|69.70|16.67|75.76|16.67|75.76|23.33|
|Malayalam|49.49|20.00|57.58|23.33|52.53|20.00|
|Marathi|56.57|20.00|55.56|23.33|57.58|23.33|
|Nepali|51.52|16.67|61.62|20.00|52.53|23.33|
|Norwegian|69.70|20.00|67.68|20.00|69.70|26.67|
|Persian|71.72|26.67|71.72|16.67|72.73|23.33|
|Polish|61.62|13.33|67.68|13.33|76.77|10.00|
|Portuguese|72.73|10.00|71.72|26.67|79.80|26.67|
|Punjabi|46.46|13.33|45.45|10.00|52.53|20.00|
|Romanian|66.67|13.33|70.71|33.33|77.78|30.00|
|Russian|75.76|16.67|76.77|16.67|76.77|33.33|
|Slovak|70.71|23.33|75.76|26.67|70.71|13.33|
|Slovenian|70.71|23.33|72.73|30.00|74.75|20.00|
|Somali|40.40|3.33|42.42|10.00|42.42|6.67|
|Spanish|71.72|13.33|77.78|20.00|80.81|23.33|
|Swahili|48.48|6.67|42.42|10.00|44.44|16.67|
|Swedish|70.71|16.67|76.77|36.67|71.72|26.67|
|Tagalog|55.56|23.33|59.60|16.67|58.59|13.33|
|Tamil|50.51|10.00|55.56|3.33|57.58|20.00|
|Telugu|53.54|13.33|58.59|20.00|54.55|20.00|
|Thai|67.68|10.00|71.72|16.67|71.72|26.67|
|Turkish|63.64|20.00|71.72|20.00|64.65|16.67|
|Ukrainian|75.76|20.00|77.78|26.67|79.80|20.00|
|Urdu|57.58|26.67|62.63|20.00|66.67|23.33|
|Vietnamese|72.73|23.33|73.74|13.33|73.74|33.33|
|Welsh|50.51|20.00|43.43|13.33|45.45|20.00|
|English|73.74|23.33|75.76|20.00|75.76|23.33|
|Average|64.17|17.27|67.09|19.27|68.45|22.00|
|Standard Deviation|9.25|5.33|9.65|7.61|10.02|6.56|
|Fleissâ€™ Kappa|0.56|0.56|0.54|0.57|0.56|0.59|{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” Qwen2.5-Math-7B-Instruct ëª¨ë¸ì— ëŒ€í•´, Qwen2.5-Math-PRM-72B ëª¨ë¸ì„ Process Reward Modeling (PRM) ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ MT-MATH100 ë° MT-AIME2024 ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì–¸ì–´ì— ëŒ€í•œ MT-MATH100 ë° MT-AIME2024ì˜ ì •í™•ë„, í‘œì¤€ í¸ì°¨, Fleissâ€™ kappa ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ PRM ê¸°ë²•ì„ ì‚¬ìš©í–ˆì„ ë•Œì˜ ëª¨ë¸ ì„±ëŠ¥ê³¼ ì–¸ì–´ ê°„ ì¼ê´€ì„±ì„ ë‹¤ì–‘í•œ ì–¸ì–´ì—ì„œ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 24: Evaluation results of Qwen2.5-Math-7B-Instruct using Qwen2.5-Math-PRM-72B as PRM on MT-MATH100 and MT-AIME2024.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 73.74 | 23.33 | 9.09 |  |
| Albanian | 66.67 | 20.00 | 15.38 |  |
| Arabic | 71.72 | 16.67 | 3.70 |  |
| Bengali | 64.65 | 3.33 |  |  |
| Bulgarian | 72.73 | 20.00 | 18.52 |  |
| Catalan | 70.71 | 26.67 |  |  |
| Chinese (Simplified) | 70.71 | 23.33 | 14.81 |  |
| Chinese (Traditional) | 69.70 | 23.33 | 11.11 | 26.67 |
| Croatian | 72.73 | 16.67 | 18.52 |  |
| Czech | 71.72 | 33.33 | 11.11 | 36.67 |
| Danish | 71.72 | 23.33 | 22.22 |  |
| Dutch | 69.70 | 20.00 | 3.70 | 3.33 |
| Estonian | 76.77 | 16.67 | 15.38 |  |
| Finnish | 72.73 | 6.67 | 15.38 |  |
| French | 70.71 | 23.33 | 14.81 | 48.39 |
| German | 73.74 | 20.00 | 18.52 | 26.67 |
| Greek | 71.72 | 10.00 | 13.04 |  |
| Gujarati | 67.68 | 13.33 |  |  |
| Hebrew | 71.72 | 10.00 | 7.41 |  |
| Hindi | 70.71 | 6.67 |  |  |
| Hungarian | 73.74 | 26.67 | 11.54 |  |
| Indonesian | 68.69 | 13.33 | 16.67 |  |
| Italian | 72.73 | 23.33 | 11.54 |  |
| Japanese | 70.71 | 30.00 | 7.69 | 7.14 |
| Kannada | 61.62 | 23.33 |  |  |
| Korean | 72.73 | 26.67 | 22.22 | 36.67 |
| Latvian | 69.70 | 20.00 | 7.69 |  |
| Lithuanian | 68.69 | 16.67 | 7.41 |  |
| Macedonian | 71.72 | 20.00 | 22.22 |  |
| Malayalam | 62.63 | 23.33 |  |  |
| Marathi | 63.64 | 20.00 |  |  |
| Nepali | 67.68 | 10.00 |  |  |
| Norwegian | 75.76 | 30.00 | 11.11 |  |
| Persian | 66.67 | 26.67 |  |  |
| Polish | 72.73 | 13.33 | 22.22 | 26.67 |
| Portuguese | 70.71 | 26.67 | 7.69 |  |
| Punjabi | 69.70 | 16.67 |  |  |
| Romanian | 73.74 | 26.67 | 11.11 |  |
| Russian | 73.74 | 23.33 | 15.38 | 50.00 |
| Slovak | 72.73 | 20.00 | 18.52 |  |
| Slovenian | 72.73 | 16.67 | 7.41 |  |
| Somali | 57.58 | 20.00 |  |  |
| Spanish | 71.72 | 26.67 | 14.81 |  |
| Swahili | 65.66 | 23.33 |  |  |
| Swedish | 72.73 | 23.33 | 23.08 |  |
| Tagalog | 71.72 | 20.00 |  |  |
| Tamil | 67.68 | 20.00 |  |  |
| Telugu | 66.67 | 16.67 |  |  |
| Thai | 70.71 | 26.67 | 7.41 |  |
| Turkish | 71.72 | 10.00 | 11.11 |  |
| Ukrainian | 73.74 | 23.33 | 14.81 |  |
| Urdu | 68.69 | 23.33 |  |  |
| Vietnamese | 71.72 | 6.67 | 14.81 |  |
| Welsh | 65.66 | 26.67 |  |  |
| English | 75.76 | 33.33 | 7.41 | 50.00 |
| Average | 70.30 | 20.18 | 13.33 | 30.81 |
| Standard Deviation | 3.68 | 6.83 | 5.36 | 15.80 |
| Fleissâ€™ Kappa | 0.71 | 0.33 | 0.25 |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 25ëŠ” GPT-4-mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ MCLM ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê·¸ë¦¬ë”” ë””ì½”ë”© ë°©ì‹ìœ¼ë¡œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ë¡œ MT-MATH100, MT-AIME2024, M-IMO, M-MO ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ ì ìˆ˜ì™€ í‘œì¤€ í¸ì°¨, ê·¸ë¦¬ê³  í”Œë ˆì´ìŠ¤ ì¹´íŒŒ ê°’ì„ ì œì‹œí•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì¼ê´€ì„±ì„ ë‹¤ê°ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 25: Evaluation results of gpt-4o-mini with greedy decoding on MCLM.
> </details>

{{< table-caption >}}
| Language | MT-MATH100 | MT-AIME2024 | M-IMO | M-MO |
|---|---|---|---|---|
| Afrikaans | 85.86 | 46.67 | 33.33 |  |
| Albanian | 86.87 | 53.33 | 28.00 |  |
| Arabic | 86.87 | 43.33 | 22.22 |  |
| Bengali | 86.87 | 43.33 |  |  |
| Bulgarian | 87.88 | 46.67 | 40.74 |  |
| Catalan | 87.88 | 53.33 |  |  |
| Chinese (Simplified) | 85.86 | 50 | 25.93 |  |
| Chinese (Traditional) | 84.85 | 40 | 29.63 | 66.67 |
| Croatian | 84.85 | 46.67 | 33.33 |  |
| Czech | 84.85 | 36.67 | 29.63 | 53.33 |
| Danish | 85.86 | 40 | 40.74 |  |
| Dutch | 86.87 | 50 | 33.33 | 40.00 |
| Estonian | 83.84 | 50 | 28.00 |  |
| Finnish | 84.85 | 40 | 28.00 |  |
| French | 86.87 | 43.33 | 29.63 | 67.74 |
| German | 86.87 | 43.33 | 33.33 | 43.33 |
| Greek | 87.88 | 56.67 | 21.05 |  |
| Gujarati | 83.84 | 46.67 |  |  |
| Hebrew | 81.82 | 40 | 7.41 |  |
| Hindi | 83.84 | 43.33 |  |  |
| Hungarian | 86.87 | 53.33 | 28.00 |  |
| Indonesian | 84.85 | 43.33 | 33.33 |  |
| Italian | 82.83 | 50 | 36.00 |  |
| Japanese | 86.87 | 50 | 16.00 | 17.86 |
| Kannada | 86.87 | 43.33 |  |  |
| Korean | 77.78 | 46.67 | 25.93 | 60.00 |
| Latvian | 87.88 | 46.67 | 32.00 |  |
| Lithuanian | 85.86 | 46.67 | 33.33 |  |
| Macedonian | 83.84 | 43.33 | 33.33 |  |
| Malayalam | 85.86 | 46.67 |  |  |
| Marathi | 83.84 | 36.67 |  |  |
| Nepali | 79.8 | 46.67 |  |  |
| Norwegian | 82.83 | 53.33 | 22.22 |  |
| Persian | 87.88 | 53.33 |  |  |
| Polish | 81.82 | 43.33 | 37.04 | 40.00 |
| Portuguese | 82.83 | 36.67 | 36.00 |  |
| Punjabi | 87.88 | 43.33 |  |  |
| Romanian | 81.82 | 40 | 40.74 |  |
| Russian | 85.86 | 56.67 | 20.00 | 50.00 |
| Slovak | 87.88 | 46.67 | 33.33 | 46.67 |
| Slovenian | 85.86 | 46.67 | 29.63 |  |
| Somali | 87.88 | 50 |  |  |
| Spanish | 72.73 | 50 | 29.63 |  |
| Swahili | 86.87 | 43.33 |  |  |
| Swedish | 79.8 | 43.33 | 28.00 |  |
| Tagalog | 85.86 | 46.67 |  |  |
| Tamil | 84.85 | 43.33 |  |  |
| Telugu | 82.83 | 33.33 |  |  |
| Thai | 84.85 | 40 | 22.22 |  |
| Turkish | 84.85 | 40 | 33.33 |  |
| Ukrainian | 84.85 | 50 | 29.63 |  |
| Urdu | 84.85 | 36.67 |  |  |
| Vietnamese | 85.86 | 46.67 | 37.04 |  |
| Welsh | 85.86 | 46.67 |  |  |
| English | 83.84 | 36.67 | 29.63 | 80.00 |
| Average | 84.89 | 45.33 | 29.75 | 51.42 |
| Standard Deviation | 2.80 | 5.35 | 6.86 | 16.94 |
| Fleissâ€™ Kappa | 0.88 | 0.73 | 0.44 |  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 26ì€ ë‹¤êµ­ì–´ ìˆ˜í•™ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì¸ MCLMì—ì„œ 03-mini ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  greedy decoding ë°©ì‹ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ë‹¤ì–‘í•œ ì–¸ì–´(55ê°œ ì–¸ì–´)ì—ì„œì˜ MT-MATH100, MT-AIME2024, M-IMO, M-MO ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„, í‘œì¤€í¸ì°¨, Fleissâ€™ kappa ê°’ì„ ì œì‹œí•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì¼ê´€ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ ê²°ê³¼ëŠ” ë¶€ë¡ Cì— ìì„¸íˆ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 26: Evaluation results of o3-mini with greedy decoding on MCLM.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}