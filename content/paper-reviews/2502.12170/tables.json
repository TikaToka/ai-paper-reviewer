[{"content": "| Model | R<sub>\u0394 params</sub> | R<sub>\u0394 FLOPs</sub> | L | D | T | \u03b7 | \u03c1 |\n|---|---|---|---|---|---|---|---|---|\n| 1.4B | 0.22% | 0.38% | 24 | 2048 | 4096 | 0.0132 | 2 |\n| 1.34B | 0.49% | 0.8% | 42 | 1536 | 4096 | 0.0293 | 2.67 |\n| 2.8B | 0.23% | 0.4% | 32 | 2560 | 4096 | 0.0137 | 1.6 |\n| 6.9B | 0.14% | 0.26% | 32 | 4096 | 4096 | 0.0085 | 1 |\n| Formula | \u03b7/6 | \u03b7/(3+\u03c1/4) |  |  |  |  |  |", "caption": "Table 1: Ratios of extra parameters and computation introduced by MUDD connections: (last row) analytical results and (upper rows) concrete values for typical model architectures and hyperparameters. L = number of layers, T = sequence length.", "description": "\uc774 \ud45c\ub294 MUDD \uc5f0\uacb0\uc774 Transformer \ubaa8\ub378\uc5d0 \ucd94\uac00\ub418\uc5c8\uc744 \ub54c \ubc1c\uc0dd\ud558\ub294 \ucd94\uac00\uc801\uc778 \ud30c\ub77c\ubbf8\ud130\uc640 \uacc4\uc0b0\ub7c9\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc758 \uc704\ucabd \ubd80\ubd84\uc740 \uc77c\ubc18\uc801\uc778 \ubaa8\ub378 \uad6c\uc870\uc640 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc5d0 \ub300\ud55c \uad6c\uccb4\uc801\uc778 \uac12\uc744 \uc81c\uc2dc\ud558\uace0, \ub9c8\uc9c0\ub9c9 \ud589\uc740 \uc774\ub860\uc801\uc778 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  L\uc740 \ub808\uc774\uc5b4 \uc218, T\ub294 \uc2dc\ud000\uc2a4 \uae38\uc774\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ucd94\uac00 \ud30c\ub77c\ubbf8\ud130 \ube44\uc728\uc740 \uc804\uccb4 \ubaa8\ub378 \ud30c\ub77c\ubbf8\ud130 \uc218 \ub300\ube44 MUDD \uc5f0\uacb0\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \ud544\uc694\ud55c \ud30c\ub77c\ubbf8\ud130 \uc218\uc758 \ube44\uc728\uc744, \ucd94\uac00 \uacc4\uc0b0 \ube44\uc728\uc740 \uc804\uccb4 \uc21c\uc804\ud30c \uc5f0\uc0b0\ub7c9 \ub300\ube44 MUDD \uc5f0\uacb0 \uac00\uc911\uce58 \uc0dd\uc131\uacfc \uacc4\uce35 \uac04 \uc9d1\uacc4\uc5d0 \ud544\uc694\ud55c \uc5f0\uc0b0\ub7c9\uc758 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "2.6 \ubcf5\uc7a1\ub3c4 \ubd84\uc11d"}, {"content": "| params | n<sub>layers</sub> | d<sub>model</sub> | n<sub>heads</sub> | learning rate | batch size (in tokens) | tokens |\n|---|---|---|---|---|---|---|\n| 405M | 24 | 1024 | 16 | 3e-4 | 0.5M | 7B |\n| 834M | 24 | 1536 | 24 | 2.5e-4 | 0.5M | 15B |\n| 1.4B | 24 | 2048 | 32 | 2e-4 | 0.5M | 26B |\n| *Scaling by depth* |  |  |  |  |  |  |\n| 797M | 34 | 1280 | 20 | 2.5e-4 | 0.5M | 15B |\n| 1.34B | 42 | 1536 | 24 | 2e-4 | 0.5M | 26B |", "caption": "Table 2: Model sizes and hyperparameters for scaling experiments.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \ud655\uc7a5 \uc2e4\ud5d8\uc744 \uc704\ud574 \uc0ac\uc6a9\ub41c \ubaa8\ub378 \ud06c\uae30\uc640 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378 \ud06c\uae30\ub294 \ud30c\ub77c\ubbf8\ud130 \uc218(params), \ub808\uc774\uc5b4 \uc218(nlayers), \uc784\ubca0\ub529 \ucc28\uc6d0(dmodel), \ud5e4\ub4dc \uc218(nheads)\ub85c \uc815\uc758\ub429\ub2c8\ub2e4. \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 \ud559\uc2b5\ub960(learning rate), \ubc30\uce58 \ud06c\uae30(batch size), \ud1a0\ud070 \uc218(tokens)\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4. \ud45c\uc758 \uc0c1\ub2e8 \uc808\ubc18\uc740 \uae30\ubcf8\uc801\uc778 \ud655\uc7a5 \uc2e4\ud5d8 \uc124\uc815\uc744 \ub098\ud0c0\ub0b4\uace0, \ud558\ub2e8 \uc808\ubc18\uc740 \uae4a\uc774\ub97c \ub298\ub9ac\uace0 \ub108\ube44\ub97c \uc904\uc774\ub294 'DeepNarrow' \ubaa8\ub378\uc5d0 \ub300\ud55c \uc124\uc815\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378 \ud06c\uae30\uc640 \uae4a\uc774, \ub108\ube44\uc758 \uad00\uacc4\ub97c \uc2e4\ud5d8\uc801\uc73c\ub85c \ud655\uc778\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.", "section": "3.1 Scaling Laws"}, {"content": "Model|Pile ppl\u2193|FLAN ppl\u2193|LAM|BADA|PIQA|WinoGrande|ARC-E|ARC-C|SciQ|LogiQA|BoolQ|HellaSwag|RACE-M|RACE-H|Avg acc\u2191 / \u0394acc\n---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---\nPythia-1.4B|7.29|9.30|61.6|71.0|57.2|60.5|26.1|86.6|21.4|63.3|40.5|37.3|33.9|50.8\nMUDDPythia-1.4B|6.92|8.54|63.9|71.8|57.4|61.6|26.2|87.2|23.0|62.0|42.6|38.7|34.7|51.7/+0.9\nPythia-2.8B|6.63|8.16|64.7|73.9|59.4|64.4|29.5|88.2|21.2|64.5|45.4|38.1|34.9|53.1\nMUDDPythia-2.8B|6.29|7.50|68.5|74.6|61.4|66.5|31.9|90.4|21.5|68.1|46.8|39.0|36.7|55.0/+1.9\nPythia-6.9B|6.29|7.85|67.3|75.2|60.9|67.3|31.3|89.7|25.3|63.7|48.0|40.6|37.0|55.1\nPythia-12B|6.01|7.26|70.5|76.0|63.9|70.2|31.8|90.2|22.4|67.4|50.3|40.6|38.3|56.5\nMUDDFM-2.8B|6.01|7.08|70.7|75.7|63.4|70.4|34.2|91.8|24.0|67.4|49.5|40.6|38.1|56.9\n\nPythia-1.4B|-|-|54.5|71.0|57.5|63.1|28.9|92.2|22.9|63.0|40.5|35.4|34.6|51.2\nMUDDPythia-1.4B|-|-|58.2|73.0|59.0|64.1|28.2|94.0|23.8|61.5|42.6|37.9|35.2|52.5/+1.3\nPythia-2.8B|-|-|60.5|73.6|60.6|67.3|32.3|94.3|21.7|65.6|45.1|38.4|35.6|54.1\nMUDDPythia-2.8B|-|-|63.6|75.5|63.6|70.3|34.0|95.5|28.1|67.5|47.1|44.5|37.3|57.0/+2.9\nPythia-6.9B|-|-|63.8|75.5|63.7|70.2|35.6|95.1|27.0|65.7|48.1|39.0|36.5|56.4\nPythia-12B|-|-|67.3|76.0|64.2|71.0|36.5|95.3|21.8|68.0|50.3|40.1|38.8|57.2\nMUDDFM-2.8B|-|-|65.6|76.4|66.8|73.0|39.2|95.6|25.2|70.9|49.8|41.4|38.0|58.4", "caption": "Table 3: Zero-shot and five-shot downstream evaluations results.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \ud558\ub958 \uc791\uc5c5(\ud558\ub958 \ud3c9\uac00)\uc5d0\uc11c \uc81c\ub85c\uc0f7(0-shot) \ubc0f \ud30c\uc774\ube0c\uc0f7(5-shot) \uc124\uc815\uc73c\ub85c  MUDDPythia \ubc0f Pythia \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\ub7ec \uc5b8\uc5b4 \ubaa8\ub378\ub9c1 \ubca4\uce58\ub9c8\ud06c(LAMBADA, PIQA, WinoGrande, ARC, SciQ, BoolQ, HellaSwag, RACE)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4 \uc810\uc218\uc640 Pile \ubc0f FLAN \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c perplexity \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 MUDDPythia \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Pythia \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2. \ub300\uaddc\ubaa8 \ud655\uc7a5 \uad50\uc721 \ubc0f \ud558\ub958 \ud3c9\uac00"}, {"content": "| Model | Training (K tokens/s) |  | Inference (tokens/s) |  |\n|---|---|---|---|---|\n| Size | TFM++ | MUDDFM | TFM++ | MUDDFM |\n| 1.3B | 1147 | 1030 \u00d7**89.8%** | 325 | 286 \u00d7**88.1%** |\n| 2.8B | 684 | 575 \u00d7**84.0%** | 181 | 163 \u00d7**90.0%** |\n| 6.9B | 332 | 318 \u00d7**95.6%** | 95.5 | 89.7 \u00d7**94.0%** |", "caption": "Table 4: Training throughput and inference speed comparison between Transformer++ and MUDDFormer.", "description": "\ud45c 4\ub294 Transformer++\uc640 MUDDFormer\uc758 \ud559\uc2b5 \ucc98\ub9ac\ub7c9\uacfc \ucd94\ub860 \uc18d\ub3c4\ub97c \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  \ubaa8\ub378 \ud06c\uae30\ubcc4(1.3B, 2.8B, 6.9B) Transformer++\uc640 MUDDFormer\uc758 TPU v5p-128 pod\ub97c \uc0ac\uc6a9\ud55c \ud559\uc2b5 \ucc98\ub9ac\ub7c9 (K tokens/s)\uacfc NVIDIA A100 80G GPU\ub97c \uc0ac\uc6a9\ud55c \ucd94\ub860 \uc18d\ub3c4 (tokens/s)\ub97c \uce21\uc815\ud558\uc5ec \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub300\ud55c \uc0c1\ub300\uc801\uc778 \uc18d\ub3c4 \ube44\uc728(%)\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 MUDDFormer\uc758 \ud6a8\uc728\uc131\uc744 Transformer++\uc640 \ube44\uad50\ud558\uc5ec \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.4. Training and Inference Efficiency"}, {"content": "| Config | ppl | Config | ppl |\n|---|---|---|---| \n| Transformer++ | 11.68 | MUDDFormer | **10.77** |\n| + Static Dense | 11.44 | - Q dense | 10.89 |\n| + Dynamic Dense | 11.09 | - K dense | 10.90 |\n| + Multiway Static Dense | 11.27 | - V dense | 11.05 |\n| + Multiway Dynamic Dense | 10.83 | - R dense | 11.14 |\n| + Mul. Dyn. Dense + Re-alloc | **10.77** |  |  |\n| + Re-alloc | 11.93 |  |  |", "caption": "Table 5: Ablations of MUDDFormer\u2019s components.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 3.5\uc808 \"Ablations and Variants\"\uc5d0\uc11c MUDDFormer\uc758 \uc131\ub2a5\uc5d0 \uac01 \uad6c\uc131 \uc694\uc18c\uac00 \uae30\uc5ec\ud558\ub294 \uc815\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, Transformer++ \ubaa8\ub378\uc5d0 MUDDFormer\uc758 \uad6c\uc131 \uc694\uc18c(\uc815\uc801, \ub3d9\uc801, \ub2e4\uc911 \uacbd\ub85c \ubc00\uc9d1 \uc5f0\uacb0, \ub9e4\uac1c\ubcc0\uc218 \uc7ac\ud560\ub2f9)\ub97c \uc21c\ucc28\uc801\uc73c\ub85c \ucd94\uac00\ud558\uc5ec \uc131\ub2a5 \ubcc0\ud654\ub97c \uce21\uc815\ud558\uace0, \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uc911\uc694\uc131\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4. \ub610\ud55c, \ub2e4\uc911 \uacbd\ub85c \ubc00\uc9d1 \uc5f0\uacb0\uc758 \uacbd\uc6b0 \uac01 \uc785\ub825 \uc2a4\ud2b8\ub9bc(\ucffc\ub9ac, \ud0a4, \uac12, \uc794\ucc28)\uc5d0 \ub300\ud574 \ubc00\uc9d1 \uc5f0\uacb0\uc744 \uc81c\uac70\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c, \uac01 \uad6c\uc131 \uc694\uc18c\uac00 MUDDFormer\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud558\uba70, \ud2b9\ud788 \uac12 \uc2a4\ud2b8\ub9bc\uc5d0 \ub300\ud55c \ubc00\uc9d1 \uc5f0\uacb0\uc774 \uc911\uc694\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.5 Ablations and Variants"}, {"content": "| Model | n<sub>layers</sub> | d<sub>model</sub> | d<sub>mlp</sub> | n<sub>heads</sub> | params |\n|---|---|---|---|---|---| \n| (MUDD)ViT-S/16 | 12 | 384 | 1536 | 6 | 22M |\n| ViT-M/16 | 12 | 512 | 2048 | 8 | 39M |", "caption": "Table 6: ViT Model architectures for ImageNet-1k classification.", "description": "\uc774 \ud45c\ub294 ImageNet-1k \uc774\ubbf8\uc9c0 \ubd84\ub958 \uc791\uc5c5\uc5d0 \uc0ac\uc6a9\ub41c \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38(ViT) \ubaa8\ub378\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ub808\uc774\uc5b4 \uc218, \ubaa8\ub378 \ucc28\uc6d0, MLP \ucc28\uc6d0, \ud5e4\ub4dc \uc218 \ubc0f \ud30c\ub77c\ubbf8\ud130 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ViT-S/16, MUDDViT-S/16 \ubc0f ViT-M/16 \ubaa8\ub378\uc758 \uc138\ubd80 \uc0ac\ud56d\uc744 \ube44\uad50\ud558\uc5ec MUDD \uc5f0\uacb0\uc774 \ubaa8\ub378 \uad6c\uc870\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.5. Ablations and Variants"}, {"content": "| Model | val. loss | acc@e90 | acc@e300 | Rel. size |\n|---|---|---|---|---|\n| ViT-S/16 | 0.993 | 53.4 | 76.0 | 1 |\n| MUDDViT-S/16 | 0.877 | 56.0 | 78.0 | 1.007 |\n| ViT-M/16 | 0.890 | 55.2 | 77.9 | 1.72 |", "caption": "Table 7: ViT for ImageNet-1k classification results.", "description": "\ud45c 7\uc740 Vision Transformer (ViT) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec ImageNet-1k \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \uc774\ubbf8\uc9c0 \ubd84\ub958 \uc791\uc5c5\uc744 \uc218\ud589\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ViT-S/16 \ubaa8\ub378\uacfc MUDD \uc5f0\uacb0\uc744 \ucd94\uac00\ud55c MUDDViT-S/16 \ubaa8\ub378, \uadf8\ub9ac\uace0 \ub354 \ud070 ViT-M/16 \ubaa8\ub378\uc758 \uac80\uc99d \uc190\uc2e4(validation loss)\uacfc \uc0c1\uc704 1% \uc815\ud655\ub3c4(top-1 accuracy)\ub97c 90 \uc5d0\ud3ed\uacfc 300 \uc5d0\ud3ed\uc5d0\uc11c \uce21\uc815\ud558\uc5ec \ube44\uad50\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 MUDD \uc5f0\uacb0\uc774 ViT \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uacfc \ubaa8\ub378 \ud06c\uae30\uc758 \ubcc0\ud654\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "3.5. Ablations and Variants"}]