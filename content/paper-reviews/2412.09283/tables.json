[{"content": "| Captioning Methods | 3DVAE<sub>*score*</sub>\u2193 | CLIP<sub>*SenbySen*</sub>\u2191 | Avg. Length |\n|---|---|---|---| \n| Panda-70M | 140.25 | 0.1956 | 13 words |\n| ShareGPT4Video | 141.00 | 0.2132 | 191 words |\n| LLaVA-Video-72B | 139.88 | 0.2060 | 102 words |\n| MiraData(GPT-4o) | **137.50** | **0.2156** | 263 words |\n| InstanceCap**(Ours)** | **134.25** | **0.2133** | 157 words |", "caption": "Table 1: Quantitative comparisons on reconstruction-via-recaption results. The best results are marked in bold, and the second-best are underscored.\nAs a reference, CogVideoX-5b accepts 226226226226 text tokens, with any excess being truncated.", "description": "\ud45c 1\uc740 \ube44\ub514\uc624 \uc7ac\uc0dd\uc131\uc744 \ud1b5\ud574 \ub2e4\uc591\ud55c \ucea1\uc158 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Panda-70M, ShareGPT4Video, LLaVA-Video-72B, MiraData(GPT-40) \ubc0f \uc81c\uc548\ub41c InstanceCap(Ours)\uc758 5\uac00\uc9c0 \ubc29\ubc95\uc774 \ube44\uad50\ub429\ub2c8\ub2e4. \uac01 \ucea1\uc158 \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ub41c \ucea1\uc158\uc744 \uc0ac\uc6a9\ud558\uc5ec CogVideoX-5b \ubaa8\ub378\ub85c \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\uace0 \uc6d0\ubcf8 \ube44\ub514\uc624\uc640\uc758 \ucc28\uc774\ub97c \uacc4\uc0b0\ud558\uc5ec \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \ud3c9\uac00 \uc9c0\ud45c\ub85c\ub294 3DVAE \uc810\uc218\uc640 CLIP SenbySen \uc810\uc218\uac00 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ud45c\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\ub294 \uad75\uac8c \ud45c\uc2dc\ub418\uace0 \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uacb0\uacfc\ub294 \ubc11\uc904\uc774 \uadf8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. \ucc38\uace0\ub85c CogVideoX-5b\ub294 \ucd5c\ub300 226\uac1c\uc758 \ud14d\uc2a4\ud2b8 \ud1a0\ud070\uc744 \ud5c8\uc6a9\ud558\uba70 \ucd08\uacfc\ub418\ub294 \ubd80\ubd84\uc740 \uc798\ub9bd\ub2c8\ub2e4.", "section": "4.2. Comparison with SOTA caption models"}, {"content": "| T2V Model | Single\u2191 | | | | | Multiple\u2191 | | | Average\u2191 |\n|---|---|---|---|---|---|---|---|---|---|\n|  | Action | Color | Shape | Texture | Detail | Action | Color | Texture |  |\n| CogVideoX-5B [30] | 64% | 60% | 44% | 60% | 20% | 8% | 48% | 40% | 43.00% |\n| Pyramid-Flow-2B [8] | 44% | 68% | 32% | 32% | 7% | 4% | 24% | 16% | 28.38% |\n| Open-Sora Plan v1.3-2.7B [11] | 64% | 44% | 36% | 32% | 27% | 20% | 32% | 12% | 33.38% |\n| Open-Sora v1.2-1.1B [35] | 40% | 56% | 36% | 40% | 13% | 12% | 16% | 16% | 28.63% |\n| + \\mathtt{InstanceCap} (Ours) | **56%** | **60%** | **40%** | **48%** | **27%** | **16%** | **32%** | **24%** | **37.88%** |\n| + Panda-captioner [4] | 40% | 48% | 28% | 40% | 20% | 8% | 20% | 12% | 27.00% |\n| + ShareGPT4Video [3] | 40% | 44% | 32% | 24% | 13% | **16%** | 8% | **20%** | 24.63% |\n| + LLaVA [16] | **52%** | 52% | 28% | 28% | **20%** | 12% | **28%** | 16% | **29.50%** |", "caption": "Table 2: Quantitative comparison between\u00a0\ud835\ude78\ud835\ude97\ud835\ude9c\ud835\ude9d\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e\ud835\ude72\ud835\ude8a\ud835\ude99\ud835\ude78\ud835\ude97\ud835\ude9c\ud835\ude9d\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e\ud835\ude72\ud835\ude8a\ud835\ude99\\mathtt{InstanceCap}typewriter_InstanceCap\u00a0and SOTA video captioning models, all based on the popular T2V model Open-Sora. Additionally, we also compare three powerful T2V models, including CogVideoX-5B, Pyramid-Flow, and Open-Sora Plan. The best results of video captioning methods and Open-Sora are marked in bold, and the second-best are underscored.", "description": "\ud45c 2\ub294 InstanceCap\uacfc \ucd5c\uc2e0 \ube44\ub514\uc624 \ucea1\uc158 \ubaa8\ub378\ub4e4\uc744 \ube44\uad50\ud55c \uc815\ub7c9\uc801 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \ubaa8\ub378\uc740 \ub110\ub9ac \uc0ac\uc6a9\ub418\ub294 T2V \ubaa8\ub378\uc778 Open-Sora\ub97c \uae30\ubc18\uc73c\ub85c \ud569\ub2c8\ub2e4. \ub610\ud55c CogVideoX-5B, Pyramid-Flow, Open-Sora Plan\uacfc \uac19\uc740 \uc138 \uac00\uc9c0 \uac15\ub825\ud55c T2V \ubaa8\ub378\uacfc\ub3c4 \ube44\uad50\ud569\ub2c8\ub2e4. \ube44\ub514\uc624 \ucea1\uc158 \ubc29\ubc95\uacfc Open-Sora\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\ub294 \uad75\uac8c \ud45c\uc2dc\ud558\uace0 \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uacb0\uacfc\ub294 \ubc11\uc904\uc744 \uae0b\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 InstanceCap\uc744 \uc0ac\uc6a9\ud55c fine-tuning\uc774 Open-Sora\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 InstanceCap\uc740 \ubcf5\uc7a1\ud55c \uc778\uc2a4\ud134\uc2a4 \uc138\ubd80 \uc815\ubcf4\ub97c \ucea1\ucc98\ud558\ub294 \ub2a5\ub825\uc5d0\uc11c \ub2e4\ub978 \ucea1\uc154\ub2dd \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud569\ub2c8\ub2e4. \ub610\ud55c InstanceCap\uc740 CogVideoX\uc640 \uac19\uc740 \ub354 \ud070 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4.3. Text-to-video generation"}, {"content": "| Distortion type | 3DVAE score\u2193 | Setting | \n|---|---|---| \n| **Blurring** | 7.71 | GaussianBlur(kernel=(5, 5), sigma=0) | \n| **Compression artifacts** | 11.19 | JPEG compression (quality 5-30) | \n| **Corruptions** | 39.80 | Random pixel masking (binary mask) | \n| **Random noise** | 49.70 | Gaussian noise (mean=0, stddev=25) | \n| **Brightness distortion** | 63.25 | Scaling (factor 0.5-1.5) | \n| **Spatial shifts** | 78.94 | Random affine shifts (\u00b110 pixels) | \n| **T2V models Avg.** | 134 ~ 145 | - | \n| **Broken video** | 149.50 | - |", "caption": "Table S1: 3DVAE scores for various distortions and video models, showcasing its effectiveness in capturing perceptual similarities and reconstruction accuracy. The setting column provides details of the experimental setup for each distortion type.", "description": "\ud45c S1\uc740 \ub2e4\uc591\ud55c \uc65c\uace1 \uc720\ud615\uacfc \ube44\ub514\uc624 \ubaa8\ub378\uc5d0 \ub300\ud55c 3DVAE \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uc9c0\uac01\uc801 \uc720\uc0ac\uc131\uacfc \uc7ac\uad6c\uc131 \uc815\ud655\ub3c4\ub97c \ud3ec\ucc29\ud558\ub294 \ub370 \uc788\uc5b4\uc11c\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc124\uc815 \uc5f4\uc740 \uac01 \uc65c\uace1 \uc720\ud615\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uc124\uc815\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. 3DVAE \uc810\uc218\ub294 \uc6d0\ubcf8 \ube44\ub514\uc624\uc640 \uc7ac\uad6c\uc131\ub41c \ube44\ub514\uc624 \uac04\uc758 \ucc28\uc774\ub97c \uce21\uc815\ud558\uba70, \ub0ae\uc740 \uc810\uc218\ub294 \ub354 \ub192\uc740 \uc720\uc0ac\uc131\uacfc \ub354 \ub098\uc740 \uc7ac\uad6c\uc131 \ud488\uc9c8\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ube14\ub7ec\ub9c1, \uc555\ucd95 \uc544\ud2f0\ud329\ud2b8, \uc190\uc0c1, \uc784\uc758 \ub178\uc774\uc988, \ubc1d\uae30 \uc65c\uace1, \uacf5\uac04 \uc774\ub3d9 \ubc0f \uae68\uc9c4 \ube44\ub514\uc624\uc640 \uac19\uc740 \ub2e4\uc591\ud55c \uc65c\uace1 \uc720\ud615\uc774 \ub098\uc5f4\ub418\uc5b4 \uc788\uc73c\uba70 \uac01\uac01\uc5d0 \ub300\ud55c 3DVAE \uc810\uc218\uac00 \uc81c\uacf5\ub429\ub2c8\ub2e4. \ub610\ud55c \uc5ec\ub7ec T2V \ubaa8\ub378\uc5d0 \ub300\ud55c \ud3c9\uade0 3DVAE \uc810\uc218 \ubc94\uc704\ub3c4 \ud45c\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Evaluation metrics for video reconstruction"}, {"content": "| Instance Detail | Instance Detail | Hallucination Scores | Hallucination Scores |\n|---|---|---|---| \n| **1** | Descriptions are extremely vague, imprecise, or largely inaccurate. Almost no specific details from the video are captured correctly. | **1** | Severe hallucination - Describes many nonexistent details, significantly misrepresents what is shown, or introduces extensive irrelevant content with many unrelated topics or external information. |\n| **2** | Descriptions have major inaccuracies or omit many important details. Only a few basic elements are described correctly. | **2** | Frequent hallucination - Multiple instances of fabricated or misrepresented details and significant extra content introducing information beyond the video scope. |\n| **3** | Descriptions are moderately accurate but lack precision in some areas. Core details are present but some secondary details are missing or incorrect. | **3** | Occasional hallucination - A few minor instances of fabricated details, misrepresentations, or the addition of extra content not covered in the video. |\n| **4** | Descriptions are largely accurate and detailed. Most key elements and nuances from the video are captured correctly, with only minor omissions or imprecisions. | **4** | Minimal hallucination - One or two very minor discrepancies or limited introduction of external information. |\n| **5** | Descriptions are highly precise and comprehensive. All important details from the video are captured accurately, including subtle elements and specific examples. | **5** | No hallucination - All described details accurately reflect what is shown in the video, with no external content added. |", "caption": "Table S2: This table outlines scoring criteria for Instance Detail and Hallucination Scores, integrating intrinsic and extrinsic hallucinations into a unified framework for evaluation.", "description": "\ud45c S2\ub294 \uc778\uc2a4\ud134\uc2a4 \uc138\ubd80 \uc815\ubcf4 \ubc0f \ud658\uac01 \uc810\uc218\uc5d0 \ub300\ud55c \ucc44\uc810 \uae30\uc900\uc744 \uc124\uba85\ud558\uace0 \ub0b4\ubd80 \ubc0f \uc678\ubd80 \ud658\uac01\uc744 \ud1b5\ud569 \ud3c9\uac00 \ud504\ub808\uc784\uc6cc\ud06c\uc5d0 \ud1b5\ud569\ud569\ub2c8\ub2e4. \uc778\uc2a4\ud134\uc2a4 \uc138\ubd80 \uc815\ubcf4\ub294 \ud14d\uc2a4\ud2b8\uac00 \ube44\ub514\uc624\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc124\uba85\ud558\ub294\uc9c0\ub97c \ud3c9\uac00\ud569\ub2c8\ub2e4. \ud658\uac01 \uc810\uc218(HS)\ub294 \ud14d\uc2a4\ud2b8\uac00 \ube44\ub514\uc624\uc5d0 \uc5c6\ub294 \ub0b4\uc6a9\uc744 \uc5bc\ub9c8\ub098 \ub9ce\uc774 \ub3c4\uc785\ud558\ub294\uc9c0 \ud3c9\uac00\ud558\uace0, \ubcf8\uc9c8\uc801 \ud658\uac01(\ube44\ub514\uc624\uc5d0 \uc788\ub294 \ub0b4\uc6a9\uc5d0 \ub300\ud55c \ud658\uac01)\uacfc \uc678\uc801 \ud658\uac01(\ube44\ub514\uc624\uc5d0 \uc5c6\ub294 \ub0b4\uc6a9\uc5d0 \ub300\ud55c \ud658\uac01)\uc744 \ubaa8\ub450 \ud3ec\ud568\ud569\ub2c8\ub2e4.", "section": "5. Evaluation metrics for video reconstruction"}]