---
title: "InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption"
summary: "InstanceCap: ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜ì„ í†µí•´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì„ ê°œì„ í•©ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Computer Vision", "Video Understanding", "ğŸ¢ Nanjing University",]
showSummary: true
date: 2024-12-12
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2412.09283 {{< /keyword >}}
{{< keyword icon="writer" >}} Tiehan Fan et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2024-12-16 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2412.09283" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2412.09283" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/instancecap-improving-text-to-video" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

**í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì€ ìµœê·¼ ëª‡ ë…„ ë™ì•ˆ ê¸‰ì†ë„ë¡œ ë°œì „í–ˆì§€ë§Œ í˜„ì¬ ë¹„ë””ì˜¤ ìº¡ì…˜ì€ ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ ì¶©ì‹¤ë„ì™€ ì¼ê´€ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì„¸ë¶€ ì •ë³´ ë¶€ì¡±, í™˜ê° ë° ë¶€ì •í™•í•œ ë™ì‘ ë¬˜ì‚¬ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.** ê¸°ì¡´ ë¹„ë””ì˜¤ ìº¡ì…˜ ë°©ë²•ì€ ì§§ì€ ìº¡ì…˜, ë°€ë„ê°€ ë†’ì€ ìº¡ì…˜, ê±°ì¹œ ìˆ˜ì¤€ì˜ êµ¬ì¡°í™”ëœ ìº¡ì…˜ì˜ ì„¸ ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜ë  ìˆ˜ ìˆìœ¼ë©°, ê°ê° ê³ ìœ í•œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. **ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ìº¡ì…˜ê³¼ ë¹„ë””ì˜¤ ê°„ì˜ ë†’ì€ ì¶©ì‹¤ë„ì™€ ìº¡ì…˜ ì½˜í…ì¸ ì˜ ì •í™•ì„±ì„ ë³´ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.**

ì´ ì—°êµ¬ì—ì„œëŠ” **ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜ í”„ë ˆì„ì›Œí¬ì¸ InstanceCap**ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” **ì¸ìŠ¤í„´ìŠ¤, ë°°ê²½ ë° ì¹´ë©”ë¼ ì›€ì§ì„ì„ í†µí•©í•˜ëŠ” êµ¬ì¡°**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒìœ¼ë¡œ **ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ ë° ì„¸ë¶„í™”ëœ ë¹„ë””ì˜¤ ìº¡ì…˜ì„ ë‹¬ì„±**í•©ë‹ˆë‹¤. **InstanceCapì€ ì „ì—­ ë¹„ë””ì˜¤ë¥¼ ë¡œì»¬ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë³€í™˜**í•˜ê³  **MLLMì„ ì‚¬ìš©í•˜ì—¬ ë°€ë„ê°€ ë†’ì€ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ êµ¬ë¬¸ìœ¼ë¡œ êµ¬ì²´í™”í•˜ì—¬ ìº¡ì…˜ì˜ ì¶©ì‹¤ë„ì™€ ì •í™•ì„±ì„ í–¥ìƒ**ì‹œí‚µë‹ˆë‹¤. ë˜í•œ, í•™ìŠµì„ ìœ„í•´ 22K **InstanceVid** ë°ì´í„° ì„¸íŠ¸ê°€ ì„ ë³„ë˜ì—ˆìœ¼ë©° ì¶”ë¡ ì„ ìœ„í•´ ë§ì¶¤í™”ëœ í”„ë¡¬í”„íŠ¸ í–¥ìƒ íŒŒì´í”„ë¼ì¸ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” InstanceCapì´ ì´ì „ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ ìº¡ì…˜ê³¼ ë¹„ë””ì˜¤ ê°„ì˜ ë†’ì€ ì¶©ì‹¤ë„ë¥¼ ë³´ì¥í•˜ê³  í™˜ê°ì„ ì¤„ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} InstanceCapì€ ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ ë° ì„¸ë¶„í™”ëœ ë¹„ë””ì˜¤ ìº¡ì…˜ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} InstanceCapì€ ìº¡ì…˜ê³¼ ë¹„ë””ì˜¤ ê°„ì˜ ì¶©ì‹¤ë„ë¥¼ í–¥ìƒì‹œí‚¤ê³  í™˜ê°ì„ ì¤„ì…ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} InstanceVidëŠ” InstanceCapì„ í•™ìŠµí•˜ê¸° ìœ„í•´ ì„ ë³„ëœ 22K ë°ì´í„° ì„¸íŠ¸ì…ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
**InstanceCap**ì€ í˜„ì¬ ì—°êµ¬ ë™í–¥ê³¼ ê´€ë ¨í•˜ì—¬ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì˜ ì¶©ì‹¤ë„ë¥¼ ê°œì„ í•˜ëŠ” ë° ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹™ë‹ˆë‹¤. **ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì™€ í–¥ìƒëœ í‰ê°€ ì§€í‘œë¥¼ ì œê³µí•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ ì„¸ë¶€ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” ë° ìˆì–´ì„œ ìƒì„± ëª¨ë¸ì˜ ê¸°ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë” ì •í™•í•œ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.** ì´ëŠ” í–¥í›„ ì—°êµ¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ê¸¸ì„ ì—´ì–´ ë”ìš± ì‚¬ì‹¤ì ì´ê³  ì •í™•í•œ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆê³  ë¹„ë””ì˜¤ ìƒì„± ë° í¸ì§‘ ì‘ìš© í”„ë¡œê·¸ë¨ê³¼ ê°™ì€ ì‹¤ì œ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2412.09283/x1.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCapê³¼ ë‹¤ë¥¸ ìº¡ì…˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. InstanceCapìœ¼ë¡œ ìƒì„±ëœ ë¹„ë””ì˜¤ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ì™€ ë§¤ìš° ìœ ì‚¬í•˜ë©°, ë†’ì€ ë””í…Œì¼ ì¶©ì‹¤ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. InstanceCapì—ì„œ ìƒì„±ëœ ìº¡ì…˜ì€ ë‹¤ë¥¸ ìº¡ì…˜ ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ë” ìì„¸í•˜ê³  ì •í™•í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ ì›ì€ í–¥ìƒëœ ë””í…Œì¼ì„ ê°•ì¡° í‘œì‹œí•©ë‹ˆë‹¤. ì•„ë˜ ìº¡ì…˜ì€ ê° ìº¡ì…˜ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ì€ ì˜ëª»ëœ ìº¡ì…˜, íŒŒë€ìƒ‰ì€ ëª¨í˜¸í•œ ìº¡ì…˜, ë…¹ìƒ‰ì€ ìì„¸í•˜ê³  ì •í™•í•œ ë¹„ë””ì˜¤ ì„¤ëª…ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ëª¨ë“  ë¹„ë””ì˜¤ëŠ” Hailuo AI222https://hailuoai.com/videoë¼ëŠ” ë™ì¼í•œ ë¹„ë””ì˜¤ ìƒì„± ì œí’ˆì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì´ ì œí’ˆì˜ ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ê¸°ëŠ¥ì€ InstanceCapì˜ íš¨ê³¼ë¥¼ ë¶„ëª…íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Top: Comparison of the reconstruction-via-recaption results betweenÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and state-of-the-art captioning methods for annotating the ground truth video.Â ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ produces results that more closely resemble the original video, showing greater detail fidelity (highlighted by the red circle). Bottom: The corresponding captions generated byÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and others. Red denotes incorrect captions, blue represents ambiguous captions, and green indicates detailed and accurate descriptions of video. Specific visual hints are marked as A, B, and C for clarity. All videos are generated using the same video generation product, Hailuo AI222https://hailuoai.com/video, which has robust prompt-following capabilities, clearly highlighting the effectiveness ofÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCap.
> </details>





{{< table-caption >}}
| Captioning Methods | 3DVAE<sub>*score*</sub>â†“ | CLIP<sub>*SenbySen*</sub>â†‘ | Avg. Length |
|---|---|---|---| 
| Panda-70M | 140.25 | 0.1956 | 13 words |
| ShareGPT4Video | 141.00 | 0.2132 | 191 words |
| LLaVA-Video-72B | 139.88 | 0.2060 | 102 words |
| MiraData(GPT-4o) | **137.50** | **0.2156** | 263 words |
| InstanceCap**(Ours)** | **134.25** | **0.2133** | 157 words |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ë¹„ë””ì˜¤ ì¬ìƒì„±ì„ í†µí•´ ë‹¤ì–‘í•œ ìº¡ì…˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Panda-70M, ShareGPT4Video, LLaVA-Video-72B, MiraData(GPT-40) ë° ì œì•ˆëœ InstanceCap(Ours)ì˜ 5ê°€ì§€ ë°©ë²•ì´ ë¹„êµë©ë‹ˆë‹¤. ê° ìº¡ì…˜ ëª¨ë¸ì—ì„œ ìƒì„±ëœ ìº¡ì…˜ì„ ì‚¬ìš©í•˜ì—¬ CogVideoX-5b ëª¨ë¸ë¡œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ê³  ì›ë³¸ ë¹„ë””ì˜¤ì™€ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. í‰ê°€ ì§€í‘œë¡œëŠ” 3DVAE ì ìˆ˜ì™€ CLIP SenbySen ì ìˆ˜ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. í‘œì—ì„œ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ëŠ” êµµê²Œ í‘œì‹œë˜ê³  ë‘ ë²ˆì§¸ë¡œ ì¢‹ì€ ê²°ê³¼ëŠ” ë°‘ì¤„ì´ ê·¸ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì°¸ê³ ë¡œ CogVideoX-5bëŠ” ìµœëŒ€ 226ê°œì˜ í…ìŠ¤íŠ¸ í† í°ì„ í—ˆìš©í•˜ë©° ì´ˆê³¼ë˜ëŠ” ë¶€ë¶„ì€ ì˜ë¦½ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Quantitative comparisons on reconstruction-via-recaption results. The best results are marked in bold, and the second-best are underscored. As a reference, CogVideoX-5b accepts 226226226226 text tokens, with any excess being truncated.
> </details>





### In-depth insights


#### InstanceCap Framework
**InstanceCap í”„ë ˆì„ì›Œí¬ëŠ” í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ì˜ ë””í…Œì¼ê³¼ ë™ì‘ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œ**ë¡œ í•©ë‹ˆë‹¤. í•µì‹¬ì€ **ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜**ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì˜ **ì„¸ë°€í•œ ë¬˜ì‚¬**ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” **ë³´ì¡° ëª¨ë¸ í´ëŸ¬ìŠ¤í„°(AMC)**ë¥¼ í™œìš©í•˜ì—¬ ê¸€ë¡œë²Œ ë¹„ë””ì˜¤ë¥¼ ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¶„í• í•˜ê³ , ê° ì¸ìŠ¤í„´ìŠ¤ì˜ í´ë˜ìŠ¤, ì™¸í˜•, ë™ì‘, ì›€ì§ì„, ìœ„ì¹˜ ë“±ì˜ **ìƒì„¸ ì •ë³´**ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ì¶”ì¶œëœ ì •ë³´ëŠ” **CoT(Chain-of-Thought) íŒŒì´í”„ë¼ì¸**ì„ í†µí•´ **MLLM(Multimodal Large Language Models)ì´ êµ¬ì¡°í™”ëœ ë¬¸êµ¬**ë¡œ ë³€í™˜ë˜ì–´ ìº¡ì…˜ì˜ **ì¶©ì‹¤ë„**ë¥¼ ë†’ì…ë‹ˆë‹¤. InstanceCapì€ ê¸°ì¡´ ìº¡ì…˜ ë°©ì‹ê³¼ ë‹¬ë¦¬ **í™˜ê° ë° ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì¤„ì—¬** ìº¡ì…˜ê³¼ ë¹„ë””ì˜¤ ê°„ì˜ **ë†’ì€ ì¼ê´€ì„±**ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë˜í•œ, **InstanceVid ë°ì´í„°ì…‹ì„ í†µí•´ T2V ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •**í•˜ì—¬ **ì¸ìŠ¤í„´ìŠ¤ ë””í…Œì¼ ë° ë™ì‘ ìƒì„±ì˜ ì •í™•ë„**ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. **InstanceEnhancerëŠ” ì¶”ë¡  ê³¼ì •ì—ì„œ ì§§ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”**í•˜ì—¬ **ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ëŠ” ê°„ê²°í•˜ê³  í’ë¶€í•œ ìº¡ì…˜ ìƒì„±**ì„ ì§€ì›í•©ë‹ˆë‹¤.

#### Instance-Aware Captions
**ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ ìº¡ì…˜**ì€ ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ì˜ íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ëŠ” ê°ì²´ì˜ **í´ë˜ìŠ¤, ì™¸ê´€, ë™ì‘, ì›€ì§ì„ ë° ìœ„ì¹˜**ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì†ì„±ì„ ê°•ì¡°í•˜ì—¬ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì´ëŸ¬í•œ ìº¡ì…˜ì€ ë©€í‹°ë¯¸ë””ì–´ ì½˜í…ì¸  ì´í•´ë¥¼ í–¥ìƒì‹œí‚¤ê³  ë” í’ë¶€í•˜ê³  ì •í™•í•œ ì„¤ëª…ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ì€ ë‚¨ìê°€ ê³µì„ ë˜ì§„ë‹¤."ë¼ëŠ” ë‹¨ìˆœ ìº¡ì…˜ ëŒ€ì‹  ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ ìº¡ì…˜ì€ "ì™¼ìª½ì— ìˆëŠ” ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ì€ ë‚¨ìê°€ ì˜¤ë¥¸ìª½ì— ì„œ ìˆëŠ” ì—¬ìì—ê²Œ ë†êµ¬ê³µì„ ë˜ì§„ë‹¤."ì™€ ê°™ì´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì„¸ë¶„í™”ëœ ìº¡ì…˜ì€ ì»´í“¨í„° ë¹„ì „ ì‘ì—…, íŠ¹íˆ **ê°ì²´ ê°ì§€, ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ë° í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±**ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤. **ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ ìº¡ì…˜ì„ ì‚¬ìš©í•˜ë©´ ì¸ìŠ¤í„´ìŠ¤ ê°„ì˜ ê´€ê³„ë¥¼ ë” ì˜ ì´í•´í•˜ê³  ë” ì •í™•í•˜ê³  ìƒí™©ì— ë§ëŠ” ìº¡ì…˜ì„ ìƒì„±**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ **í™˜ê° ë° ê´€ë ¨ ì—†ëŠ” ì½˜í…ì¸  ìƒì„±ì„ ì¤„ì´ëŠ”** ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ ìº¡ì…˜ì€ ì¸ê°„ê³¼ ê¸°ê³„ ëª¨ë‘ì—ê²Œ ë” í’ë¶€í•˜ê³  ìœ ìµí•œ ë©€í‹°ë¯¸ë””ì–´ ê²½í—˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

#### 22K InstanceVid Dataset
**InstanceVid ë°ì´í„°ì…‹ì€ 22Kê°œì˜ ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ê³ í™”ì§ˆ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ìœ¼ë¡œ, í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±(T2V) ëª¨ë¸ í•™ìŠµì— í™œìš©ë©ë‹ˆë‹¤.** ìƒ˜í”Œë“¤ì€ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ **ê³ ê°•ë„ ì›€ì§ì„**ì„ ë³´ì´ëŠ” ì¸ìŠ¤í„´ìŠ¤ë¥¼ í¬í•¨í•˜ë„ë¡ ì„ ë³„ë˜ì—ˆìœ¼ë©°, ì¸ìŠ¤í„´ìŠ¤ì˜ ì™¸í˜•, í–‰ë™, ì›€ì§ì„ ë“±ì— ëŒ€í•œ **ìƒì„¸í•œ ì„¤ëª…**ì´ ì œê³µë©ë‹ˆë‹¤.  InstanceVidëŠ” **ì‹¤ì™¸ ì¥ë©´**ê³¼ **2-10ì´ˆ** ë¶„ëŸ‰ì˜ ì§§ì€ ë¹„ë””ì˜¤ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤. ì‹¤ì™¸ ì¥ë©´ì˜ ê· í˜•ìˆëŠ” êµ¬ì„±ì€ íŠ¹ì • í™˜ê²½ í¸í–¥ì„ ë°©ì§€í•˜ê³  ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì§§ì€ ë¹„ë””ì˜¤ëŠ” ê³¼ë„í•œ ì¥ë©´ ì „í™˜ì„ ìµœì†Œí™”í•˜ê³ , ì˜¤í”ˆì†ŒìŠ¤ T2V ëª¨ë¸ì˜ ìµœì í™”ëœ ìƒì„± ë²”ìœ„ì— ë§ì¶° íš¨ìœ¨ì ì¸ í•™ìŠµì„ ì§€ì›í•©ë‹ˆë‹¤. InstanceVidëŠ” **ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨**ì˜ ì„¸ë¶€ ì •ë³´ì™€ ì›€ì§ì„ ì¼ê´€ì„±ì„ í–¥ìƒì‹œì¼œ T2V ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•©ë‹ˆë‹¤. **InstanceCap**ì´ë¼ëŠ” ìƒˆë¡œìš´ ìº¡ì…˜ êµ¬ì¡°ì™€ ê²°í•©í•˜ì—¬ T2V ëª¨ë¸ì˜ ë””í…Œì¼ ë° ëª¨ì…˜ ì•¡ì…˜ ìƒì„± ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.

#### Reconstruction & T2V
**ì¬êµ¬ì„±(Reconstruction)**ê³¼ **í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±(T2V)**ì€ ìƒí˜¸ë³´ì™„ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ë©°, ì„œë¡œì˜ ë°œì „ì— ê¸°ì—¬í•©ë‹ˆë‹¤. ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ì¬êµ¬ì„±ì€ T2V ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ **ì •í™•í•œ ë°ì´í„°**ë¥¼ ì œê³µí•˜ê³ , T2VëŠ” ì¬êµ¬ì„± ê¸°ìˆ ì˜ **í•œê³„ë¥¼ ê·¹ë³µ**í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. InstanceCapê³¼ ê°™ì€ **ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ êµ¬ì¡°í™” ìº¡ì…˜**ì€ ì¬êµ¬ì„±ì˜ **ì¶©ì‹¤ë„ë¥¼ í–¥ìƒ**ì‹œí‚¤ê³ , T2V ëª¨ë¸ì´ **ì„¸ë¶€ ì‚¬í•­ê³¼ ì›€ì§ì„ì„ ë” ì •í™•í•˜ê²Œ** ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ë” **ëŒ€ê·œëª¨ ë°ì´í„°ì…‹**ê³¼ **ê°•ë ¥í•œ T2V ëª¨ë¸**ì„ í™œìš©í•˜ì—¬ ì¬êµ¬ì„± ë° ìƒì„± í’ˆì§ˆì„ ë”ìš± í–¥ìƒì‹œí‚¤ëŠ” ë° ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.

#### Limitations & Future
**InstanceCapì˜ í•œê³„ëŠ” ê°ì²´ ê°ì§€ ë°©ë²•ì˜ ì •í™•ë„ì— ì˜ì¡´í•œë‹¤ëŠ” ì **ì…ë‹ˆë‹¤. ë„ë©”ì¸ë³„ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ ê°ì§€ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•´ì•¼ í•˜ë©°, ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ëŠ” ì¥ë©´ì—ì„œëŠ” ì´ì ì´ ì¤„ì–´ë“­ë‹ˆë‹¤. ë˜í•œ, **InstanceVid ë°ì´í„° ì„¸íŠ¸ì˜ ê·œëª¨ê°€ ì‚¬ì „ í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸ë¡œ ì‚¬ìš©í•˜ê¸°ì—ëŠ” ì œí•œì **ì…ë‹ˆë‹¤. í–¥í›„ ì—°êµ¬ì—ì„œëŠ” **ë” í° ë¹„ë””ì˜¤ ë°ì´í„° ì„¸íŠ¸ì— InstanceCapì„ ì ìš©**í•˜ê³  **ë” ê°•ë ¥í•œ T2V ëª¨ë¸ì„ í›ˆë ¨í•˜ì—¬ ê·¸ ì˜í–¥ì„ í™•ëŒ€**í•  ê³„íšì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ ì„¸ë¶€ ì‚¬í•­ê³¼ ë™ì‘ì— ëŒ€í•œ ìƒì„± ê¸°ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2412.09283/x2.png)

> ğŸ”¼ InstanceCap íŒŒì´í”„ë¼ì¸ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì£¼ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤. ì „ì—­ ë¹„ë””ì˜¤ë¥¼ ì§€ì—­ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” AMC íŒ¨ëŸ¬ë‹¤ì„ê³¼, ìƒì„¸ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë¬¸êµ¬ë¡œ êµ¬ì²´í™”í•˜ëŠ” ê°œì„ ëœ CoT í”„ë¡œì„¸ìŠ¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. 'dense promptsì—ì„œ structured phrasesë¡œ' ë””ìì¸ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ê·¸ë¦¼ 3ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Overview of InstanceCap pipeline. Details of â€œfrom dense prompts to structured phrasesâ€ design are shown in FigureÂ 3.
> </details>



![](https://arxiv.org/html/2412.09283/x3.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCap íŒŒì´í”„ë¼ì¸ì˜ 'ë°€ì§‘ í”„ë¡¬í”„íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ë¬¸êµ¬ë¡œ' ë””ìì¸ì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë¹¨ê°„ìƒ‰ í™”ì‚´í‘œë¡œ í‘œì‹œëœ ì •ë³´ ìƒí˜¸ ì‘ìš©ì„ í†µí•´ MLLMì´ ì†ì„±ì— ëŒ€í•œ ì •í™•í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì •í™•í•˜ê²Œ ìº¡ì²˜í•  ìˆ˜ ìˆë„ë¡ ê°œì„ ëœ CoT íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Details on â€œfrom dense prompts to structured phrasesâ€ design. We propose an improved CoT pipeline with carefully designed information interactions (red arrow), which facilitates MLLMs to accurately capture instances with precise descriptions on attributes.
> </details>



![](https://arxiv.org/html/2412.09283/x4.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceVid ë°ì´í„°ì…‹ì˜ í†µê³„ì  íŠ¹ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. InstanceVidëŠ” ë‹¤ì–‘í•œ ì¸ìŠ¤í„´ìŠ¤, ê´‘ë²”ìœ„í•œ ì¥ë©´, ì •í™•í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ ìº¡ì…˜, ë¹„ë””ì˜¤ ìƒì„±ì— ì í•©í•œ ê¸¸ì´ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ” ì˜¤í”ˆ ë„ë©”ì¸ ì‹œë‚˜ë¦¬ì˜¤ì˜ ë¹„ë””ì˜¤ì— ëŒ€í•œ êµ¬ structured ìº¡ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ë¦¼ 4ëŠ” ì¥ë©´(ì˜ˆ: í† í¬ì‡¼ ë° ì¸í„°ë·°, ë„ì‹œ, ë„ì‹œ, í’ê²½ ë° í’ê²½)ê³¼ ê¸¸ì´([0, 4], (4, 6), (6, 8), (8, 10), (10, 15), (15, 20), (20, 30), (30+))ì˜ ë‘ ê°€ì§€ ì£¼ìš” ì°¨ì›ì—ì„œ InstanceVidì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğš…ğš’ğšğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğš…ğš’ğš\mathtt{InstanceVid}typewriter_InstanceVidÂ provides structured captions for videos in open-domain scenarios, featuring diverse instance, expansive scenes, precise and instance-aware captions, and video-generation-friendly durations.
> </details>



![](https://arxiv.org/html/2412.09283/x5.png)

> ğŸ”¼ InstanceEnhancerëŠ” ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ëœ íŠœë‹ ì—†ëŠ” ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. Stage Aì—ì„œëŠ” ì§§ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ìì„¸í•œ ê¸´ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥í•©ë‹ˆë‹¤. Stage B(I)&(II)ì—ì„œëŠ” í™•ì¥ëœ ìº¡ì…˜ê³¼ ì›ë³¸ ìº¡ì…˜ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¶„í• í•˜ê³  ê°œì„ í•˜ì—¬ ìƒí™©ë³„ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë™ì‹œì— ì •í™•í•œ ì¸ìŠ¤í„´ìŠ¤ ì‹ë³„ì„ ë³´ì¥í•©ë‹ˆë‹¤. InstanceEnhancerëŠ” ìƒì„±ëœ í˜•ì‹ì„ ì‚¬ìš©ëœ í•™ìŠµ ì…ë ¥ì— í•´ë‹¹í•˜ëŠ” ìº¡ì…˜ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì—„ê²©í•˜ê²Œ ì œí•œí•˜ì—¬ í•™ìŠµ ë° ì¶”ë¡  ê°„ì˜ í”„ë¡¬í”„íŠ¸ ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: High-level overview ofÂ InstanceEnhancer, illustrating the data flow and the partitioning of stages. For a detailed implementation, refer to the supplemental materials, which provide an in-depth description of the enhancer pipeline design and the interdependencies between the stages.
> </details>



![](https://arxiv.org/html/2412.09283/x6.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCapê³¼ MiraDataì˜ ë¹„ë””ì˜¤ ì¬êµ¬ì„± ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. InstanceCapì€ ì›ë³¸ ë¹„ë””ì˜¤ì™€ ì¬êµ¬ì„±ëœ ë¹„ë””ì˜¤ ì‚¬ì´ì˜ ì‹œê°ì  ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì¸ 3DVAE ì ìˆ˜ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ ì›ê³¼ ì„ ì€ InstanceCapì´ ì›ë³¸ ë¹„ë””ì˜¤(GT)ì™€ ìœ ì‚¬í•œ ì˜ë¯¸ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ìœ ì§€í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Comparison on reconstruction-via-recaption betweenÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and MiraData. Corresponding 3DVAE scores are also indicated. Similar semantics shared betweenÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and GT are indicated by red circles and lines.
> </details>



![](https://arxiv.org/html/2412.09283/x7.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCapê³¼ OpenSoraì˜ ë‹¨ì¼ ë° ë‹¤ì¤‘ ë™ì‘ ì ìˆ˜ì— ëŒ€í•œ ì‹œê°ì  ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¹„ë””ì˜¤ ìƒì„±ì˜ ë™ì  ì •ë„ ì¸¡ë©´ì—ì„œ InstanceCapì€ ë” ë‚˜ì€ ì¼ê´€ì„±ê³¼ í–¥ìƒëœ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ë™ì  ìƒì„± íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¦‰, InstanceCapì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë¹„ë””ì˜¤ëŠ” OpenSoraë³´ë‹¤ ë” ë¶€ë“œëŸ½ê³  ì‚¬ì‹¤ì ì¸ ì›€ì§ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Visual comparison ofÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and Opensora on Single and Multiple Action Score. In terms of the dynamic degree of video generation, we show better consistency and enhanced multi-instance dynamic generation effect.
> </details>



![](https://arxiv.org/html/2412.09283/x8.png)

> ğŸ”¼ ì¸ìŠ¤í„´ìŠ¤ ë””í…Œì¼ ë° í™˜ê° ì ìˆ˜ì— ëŒ€í•œ ì‚¬ìš©ì ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤. InstanceCapì˜ ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜ì´ MiraData[9]ì˜ ëŒ€ëµì ì¸ êµ¬ì¡°í™” ìº¡ì…˜ë³´ë‹¤ ëª…í™•í•œ ì´ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” InstanceCapê³¼ MiraDataì— ëŒ€í•´ ê°ê° 4.60ê³¼ 3.35ì˜ ì¸ìŠ¤í„´ìŠ¤ ë””í…Œì¼ ì ìˆ˜ì™€ 4.12ì™€ 4.31ì˜ í™˜ê° ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: User study on instance detail and hallucination scores. Our instance-aware structured caption shows clear advantages compared to the coarse-structured MiraDataÂ [9].
> </details>



![](https://arxiv.org/html/2412.09283/x9.png)

> ğŸ”¼ InstanceCapê³¼ Open-Soraì˜ ì¸ìŠ¤í„´ìŠ¤ ë ˆë²¨ ì†ì„± ë¹„êµ. InstanceCapì€ ë³µì¡í•œ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ë° ë‹¤ì¤‘ ì†ì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ì •í™•í•œ ì¸ìŠ¤í„´ìŠ¤ ì„¸ë¶€ ì¶©ì‹¤ë„ ë° ëª…ë ¹ ì¤€ìˆ˜ ê¸°ëŠ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œ InstanceCapì€ 'ë°ì€ ê°ˆìƒ‰ ê°€ë°©'ê³¼ ê°™ì€ ì„¸ë¶€ ì‚¬í•­ì„ ì •í™•í•˜ê²Œ ìƒì„±í•˜ëŠ” ë°˜ë©´ Open-SoraëŠ” ì´ëŸ¬í•œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë†“ì¹©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9:  Visual comparison ofÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and Open-Sora on instance-level attributes.Â ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ excels in precise instance detail fidelity and instruction-following capabilities, even with complex multi-instance and multi-attribute scenarios.
> </details>



![](https://arxiv.org/html/2412.09283/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 10ì€ InstanceCapì—ì„œ ì¸ê°„ì´ ì„¤ê³„í•œ ì¹´ë©”ë¼ ì´ë™ íŒíŠ¸ì™€ í´ë˜ìŠ¤ íŒíŠ¸ì˜ ì˜í–¥ì„ ë³´ì—¬ì£¼ëŠ” ablation study ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (a)ëŠ” ì¹´ë©”ë¼ ì´ë™ íŒíŠ¸ê°€ MLLM ë¼ë²¨ë§ ì •í™•ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥, (b)ëŠ” ì¸ê°„ì´ ì„¤ê³„í•œ í´ë˜ìŠ¤ íŒíŠ¸ê°€ ì¸ìŠ¤í„´ìŠ¤ ë¼ë²¨ë§ ì„¸ë¶€ ì‚¬í•­ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¹´ë©”ë¼ ì´ë™ íŒíŠ¸ëŠ” 'ì¤Œ ì¸'ì²˜ëŸ¼ ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ì—ì„œ 'ê¾¸ì¤€í•˜ê³  ì ì§„ì ì¸ ì¤Œ ì¸'ê³¼ ê°™ì´ ë” ìì„¸í•œ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. í´ë˜ìŠ¤ íŒíŠ¸ëŠ” 'ë‚˜ì´ ë“  ë‚¨ì'ì—ì„œ 'ì¤‘ë…„ ë‚¨ì„±, í° ë¨¸ë¦¬, ë°ë‹˜ ì…”ì¸ ì™€ ì²­ë°”ì§€ ì°©ìš©, ì™¼ìª½ ì†ëª©ì— ì‹œê³„ ì°©ìš©'ê³¼ ê°™ì´ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ë” í’ë¶€í•˜ê³  ì •í™•í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: (a) Ablation study on the effect of camera movement hints on the accuracy of MLLM labeling. (b) Impact of human-designed class hints on the details of instance labeling.
> </details>



![](https://arxiv.org/html/2412.09283/x11.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCap ë…¼ë¬¸ì˜ ê·¸ë¦¼ 11ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. (a)ëŠ” ì•½í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ, ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆëŠ” ëŒ€ìƒì— ëŒ€í•œ ì¬êµ¬ì„± ì‹œê°í™”ë¥¼ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. (b)ëŠ” ë¹¨ê°„ìƒ‰ ë°°ê²½ í™”ë©´ì„ ì‚¬ìš©í–ˆì„ ë•Œ MLLM ë¼ë²¨ë§ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. ì•½í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ëŠ” ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆëŠ” ì¥ë©´ì—ì„œ íŠ¹ì • ëŒ€ìƒì„ êµ¬ë³„í•˜ê³  ì„¤ëª…í•˜ëŠ” MLLMì˜ ëŠ¥ë ¥ì„ ì œí•œí•˜ì—¬, ì†ì„± í˜¼í•© ë° ëª¨í˜¸í•œ ì£¼ì„ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, InstanceCapì€ ì¸ìŠ¤í„´ìŠ¤ë³„ íŠ¹ì§• ì¶”ì¶œì— íƒì›”í•˜ì—¬ ì½”ì¹˜ì™€ ì„ ìˆ˜ì™€ ê°™ì€ ê·¸ë¦¼ì„ ì •í™•í•˜ê²Œ êµ¬ë¶„í•©ë‹ˆë‹¤. ë‹¨ìƒ‰ ë°°ê²½ì€ MLLMì— ì˜ëª»ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ì—¬ ìº¡ì…˜ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. InstanceCapì—ì„œ ì„¤ê³„í•œ íë¦¿í•œ ë°°ê²½ ë§ˆìŠ¤í‚¹ ì ‘ê·¼ ë°©ì‹ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì¥ë©´ê³¼ì˜ ì‹œê°ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì—¬ MLLMì´ ìµœì†Œí•œì˜ í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ë§Œìœ¼ë¡œ ì •í™•í•˜ê³  ë¬¸ë§¥ì ìœ¼ë¡œ ê´€ë ¨ëœ ì£¼ì„ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: (a) Comparison against the weak visual prompt for reconstruction-via-caption visualization on multi-instance targets. (b) Comparison against color screen backgrounds (red), which may negatively affect MLLM labeling performance.
> </details>



![](https://arxiv.org/html/2412.09283/x12.png)

> ğŸ”¼ Positive/Negative Lexiconì€ ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ ë¯¸ì  í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ ê°¤ëŸ¬ë¦¬ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹ ì¤‘í•˜ê²Œ ìˆ˜ì§‘í•˜ê³  í˜•ìš©ì‚¬ë¥¼ ì¶”ì¶œí•˜ì—¬ Positive Lexiconì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ê°•ë ¥í•œ LLMì¸ GPT-40ì„ ì‚¬ìš©í•˜ì—¬ Negative Lexiconì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬ì„±í•˜ê³  ì¶”ê°€ë¡œ ë³´ê°•í–ˆìŠµë‹ˆë‹¤. ë‘ ì–´íœ˜ì§‘ ëª¨ë‘ ì„¸ì‹¬í•œ ìˆ˜ë™ ì‹¬ì‚¬ë¥¼ ê±°ì³ ë‹¤ë“¬ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ë¦¼ S1ì€ Positive/Negative Lexiconì˜ ìì„¸í•œ ë‚´ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸ì •ì ì¸ ë‹¨ì–´(kaleidoscopic, delicate, grand ë“±)ëŠ” ë¹„ë””ì˜¤ ìƒì„±ì— ë„ì›€ì´ ë˜ëŠ” ë°˜ë©´, ë¶€ì •ì ì¸ ë‹¨ì–´(dull, rough, harsh ë“±)ëŠ” í”¼í•´ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S1: The detail of Positive/Negative Lexicon
> </details>



![](https://arxiv.org/html/2412.09283/x13.png)

> ğŸ”¼ InstanceEnhancer íŒŒì´í”„ë¼ì¸ì˜ ìƒì„¸ ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤. ì§§ì€ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì–´ì§€ë©´, ë¨¼ì € LLMsë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸í•œ ê¸´ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥í•©ë‹ˆë‹¤. ê·¸ í›„, í™•ì¥ëœ ê¸´ í”„ë¡¬í”„íŠ¸ì™€ ì›ë³¸ ì§§ì€ í”„ë¡¬í”„íŠ¸ ëª¨ë‘ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹ë³„í•˜ê³  ë¶„í• í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë¶„í• ëœ ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ì™€ ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ë¦¼ S9ëŠ” ì˜ˆì‹œ ë²ˆí˜¸ 1ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S2: Detailed overview of theÂ InstanceEnhancerÂ pipeline. Example No.1 as shown in FigureÂ S9.
> </details>



![](https://arxiv.org/html/2412.09283/x14.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Insevalì˜ ì¶”ë¡  ì˜ˆì‹œë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¨ì¼ ë° ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ì•¡ì…˜, ìƒ‰ìƒ, ëª¨ì–‘, ì§ˆê° ë° ì„¸ë¶€ ì‚¬í•­ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì°¨ì›ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ì˜ˆì‹œëŠ” ë¬¸ì¥ê³¼ ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S3: Inference examples of Inseval.
> </details>



![](https://arxiv.org/html/2412.09283/x15.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ê³¼ ìƒìš© ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, ì—¬ëŸ¬ ë¬¼ì²´ê°€ ë“±ì¥í•˜ê³  ë³µì¡í•œ ì†ì„±ì„ ê°€ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ìˆì–´ì„œ ìƒìš© ëª¨ë¸ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'ì‚¬ê°í˜• ìŠ¤í”¼ì»¤ê°€ ë‘¥ê·¼ ì„ ë°˜ ìœ„ì— ìˆë‹¤'ì™€ ê°™ì´ ì—¬ëŸ¬ ì†ì„±ì„ ê°€ì§„ í”„ë¡¬í”„íŠ¸ì—ì„œ ìƒìš© ëª¨ë¸ì€ ëª¨ë“  ì†ì„±ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ë°˜ë©´, ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì€ ì†ì„±ì„ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, 'ë…¹ìƒ‰ ì´êµ¬ì•„ë‚˜ê°€ ë“±ì— ë¾°ì¡±í•œ ë³ì„ ë‹¬ê³  ë°”ìœ„ ìœ„ì— ìˆë‹¤. ê·¼ì²˜ì—ëŠ” ì‘ì€ ì¡°ê°œ ëª©ê±¸ì´ë¥¼ í•œ ìˆ˜ë‹¬ì´ ë“±ì— ë–  ìˆë‹¤'ì™€ ê°™ì´ ë³µì¡í•œ ì¥ë©´ì„ ë¬˜ì‚¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì—ì„œë„ ìƒìš© ëª¨ë¸ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S4: Visualization comparing open-source models and commercial models on prompts with poorer performance.
> </details>



![](https://arxiv.org/html/2412.09283/x16.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ InstanceCapì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì„¤ì •í•˜ê³  ê°ì²´ ì™¸í˜•, ë™ì‘, ì„¬ì„¸í•œ ë‹¨ì–´ ì‚¬ìš©, ì œì•½ ì¡°ê±´ ë“± ë‹¤ì–‘í•œ ëŠ¥ë ¥ì„ ëª…ì‹œí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ê°ì²´ì˜ ìƒ‰ìƒ ë¶€ë¶„ì— ì¤‘ì ì„ ë‘ê³  ì‚¬ëŒì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…(ì˜ˆ: ì˜ë³µ ìŠ¤íƒ€ì¼ ë° ìƒ‰ìƒ, ë‚˜ì´, ì„±ë³„, ì²´í˜•, í‘œì • ë“±)ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ë˜í•œ ì€ìœ ë‚˜ ì˜ì¸í™”ì™€ ê°™ì€ ìˆ˜ì‚¬ì  ì¥ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì‚¬ì‹¤ì„ ê°ê´€ì ìœ¼ë¡œ ì§„ìˆ í•˜ë©°, ì˜¤ë””ì˜¤ ì‹ í˜¸ê°€ ì—†ìœ¼ë¯€ë¡œ ì†Œë¦¬ ê´€ë ¨ ì¸¡ë©´ì€ ì œì™¸í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ëŠ” í˜„ì¬ í”„ë ˆì„ì˜ í”„ë ˆì„ ë²ˆí˜¸ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•Šê³  êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜•ì‹ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ë„ë¡ ì œì•½í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S5: System prompt ofÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCap.
> </details>



![](https://arxiv.org/html/2412.09283/x17.png)

> ğŸ”¼ InstanceCap ë…¼ë¬¸ì˜ Figure S6ëŠ” ë¹„ë””ì˜¤ì˜ ì‹œê°„ì  ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ì½”ë“œëŠ” ë¹„ë””ì˜¤ì˜ ê¸¸ì´, í”„ë ˆì„ ìˆ˜, ê° í”„ë ˆì„ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ë“±ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ InstanceCap ëª¨ë¸ì´ ì‹œê°„ì  ë§¥ë½ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë¹„ë””ì˜¤ ìº¡ì…˜ ìƒì„± ë° ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ì •ë ¬ ì‘ì—…ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S6: Code of getting video temporal metadata.
> </details>



![](https://arxiv.org/html/2412.09283/x18.png)

> ğŸ”¼ InstanceCapì€ ì¹´ë©”ë¼ ì›€ì§ì„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê¸° ìœ„í•´ CoT í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë§Œì•½ ì¹´ë©”ë¼ ì›€ì§ì„ì´ 'Undetermined'ì¸ ê²½ìš°, ë¹„ë””ì˜¤ì˜ ë³€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´ë©”ë¼ì˜ ì›€ì§ì„ê³¼ ì´¬ì˜ ê°ë„ë¥¼ ì¶”ë¡ í•˜ë„ë¡ MLLMì— ì§€ì‹œí•©ë‹ˆë‹¤.  ì¹´ë©”ë¼ ì›€ì§ì„ì´ 'static'ì¸ ê²½ìš°, ì¹´ë©”ë¼ê°€ ì •ì ì¸ì§€ ì›€ì§ì´ëŠ”ì§€, ê·¸ë¦¬ê³  ë¹„ë””ì˜¤ì—ì„œ ì¹´ë©”ë¼ì˜ ì›€ì§ì„ê³¼ ì´¬ì˜ ê°ë„ê°€ ë¬´ì—‡ì¸ì§€ ì¶”ë¡ í•˜ë„ë¡ MLLMì— ì§€ì‹œí•©ë‹ˆë‹¤. ê·¸ ì™¸ì˜ ê²½ìš°, ì£¼ì–´ì§„ ì¹´ë©”ë¼ ì›€ì§ì„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´ë©”ë¼ì˜ ì›€ì§ì„ê³¼ ì´¬ì˜ ê°ë„ë¥¼ ì¶”ë¡ í•˜ë„ë¡ MLLMì— ì§€ì‹œí•©ë‹ˆë‹¤. MLLMì€ 'Sharply', 'rapidly', 'slowly' ë“±ê³¼ ê°™ì€ ì •ë„ ë¶€ë¶€ì‚¬ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ì›€ì§ì„ê³¼ ì´¬ì˜ ê°ë„ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ìš”ì•½í•´ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S7: Prompt of camera movement.
> </details>



![](https://arxiv.org/html/2412.09283/x19.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ í–‰ë™ê³¼ ì›€ì§ì„ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. 2ë‹¨ê³„ CoT í”„ë¡¬í”„íŠ¸ê°€ ì œê³µë©ë‹ˆë‹¤. 1ë‹¨ê³„ì—ì„œëŠ” ë°°ê²½ì„ ë¬´ì‹œí•˜ê³  ëŒ€ìƒ ë¬¼ì²´ê°€ ë¹„ë””ì˜¤ì—ì„œ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ë¬»ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ì—ì„œëŠ” ì›€ì§ì„ ìƒíƒœì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ì ì ˆí•œ í˜•ìš©ì‚¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìì„¸íˆ ì„¤ëª…í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ë˜í•œ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¡œ ë‹µí•˜ì§€ ì•Šê³  ëŒ€ìƒ ë¬¼ì²´ì™€ ê´€ë ¨ ì—†ëŠ” ë¬¼ì²´ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤. ëŒ€ìƒ ë¬¼ì²´ê°€ ìˆëŠ” í™˜ê²½ì— ëŒ€í•œ ì¶”ì¸¡ì´ë‚˜ 'íë¦¿í•œ ë°°ê²½'ì— ëŒ€í•œ ì–¸ê¸‰ë„ í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S8: Prompt of actions and motion.
> </details>



![](https://arxiv.org/html/2412.09283/x20.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ LLMsë¥¼ ìœ„í•œ ì„¤ê³„ëœ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì§§ì€ í”„ë¡¬í”„íŠ¸ 'Two wolves were hunting a rabbit in the snow.'ì—ì„œ ì‹œì‘í•˜ì—¬, ë‘ ë‹¨ê³„ë¥¼ ê±°ì³ ë” ìì„¸í•œ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„(Stage A)ì—ì„œëŠ” ì£¼ì–´ì§„ ì§§ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¥ë©´ì„ ìì„¸í•˜ê²Œ ë¬˜ì‚¬í•˜ëŠ” ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆì‹œì—ì„œëŠ” ëˆˆ ë®ì¸ ìˆ²ì—ì„œ ë‘ ë§ˆë¦¬ì˜ ëŠ‘ëŒ€ê°€ í† ë¼ë¥¼ ì‚¬ëƒ¥í•˜ëŠ” ì¥ë©´ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë‹¨ê³„(Stage B(I))ì—ì„œëŠ” ê¸´ í”„ë¡¬í”„íŠ¸ì—ì„œ ì£¼ìš” ê°ì²´(instance)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” 'ëŠ‘ëŒ€', 'í† ë¼'ì™€ ê°™ì´ ì¥ë©´ì´ ì•„ë‹Œ ë§Œì§ˆ ìˆ˜ ìˆëŠ” ê°œì²´ë¥¼ ì¶”ì¶œí•˜ë©°, ì—¬ëŸ¬ ê°œì²´ê°€ ìˆì„ ê²½ìš° ê°ê° ë¶„ë¦¬í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” 'a wolf BREAK a wolf BREAK a rabbit' ê³¼ ê°™ì´ ì¶”ì¶œëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ë‘ ë‹¨ê³„ë¥¼ í†µí•´ ì§§ì€ í”„ë¡¬í”„íŠ¸ë¥¼ LLMsê°€ ì´í•´í•˜ê³  í™œìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S9: Designed example for LLMs.
> </details>



![](https://arxiv.org/html/2412.09283/x21.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Insevalì˜ í‰ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¨ì¼ ê°ì²´ ë° ë‹¤ì¤‘ ê°ì²´ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ì— ëŒ€í•œ í‰ê°€ í”„ë¡¬í”„íŠ¸ê°€ ìì„¸íˆ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 'Detail' ì°¨ì›ì— ëŒ€í•œ ì¶”ê°€ í”„ë¡¬í”„íŠ¸ë„ ì œê³µë©ë‹ˆë‹¤. ê° í”„ë¡¬í”„íŠ¸ëŠ” MLLMì´ ìƒì„±ëœ ë¹„ë””ì˜¤ë¥¼ í•´ë‹¹ ì°¨ì›ê³¼ ì¼ì¹˜ì‹œí‚¤ëŠ”ì§€ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ ì¼ë°˜ì ì¸ CoT Q-A ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S10: Evaluation prompts of Inseval.
> </details>



![](https://arxiv.org/html/2412.09283/x22.png)

> ğŸ”¼ Open-Sora ëª¨ë¸ì„ ìœ„í•œ ì •ë ¬ í”„ë¡¬í”„íŠ¸ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë‘ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. 1ë‹¨ê³„ì—ì„œëŠ” InstanceCap JSONì„ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. 2ë‹¨ê³„ì—ì„œëŠ” LLMsì— ë” ì •í™•í•œ ì§€ì¹¨ì„ ì œê³µí•˜ê¸° ìœ„í•´ íŠ¹ë³„íˆ ê³ ì•ˆëœ ì—¬ëŸ¬ ê°€ì§€ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼ì–´ì§„ InstanceCap JSONì„ ë°”íƒ•ìœ¼ë¡œ, 2ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMsì´ ì›ë³¸ ë¹„ë””ì˜¤ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ì¤‘ìš”í•œ ì„¸ë¶€ ì‚¬í•­ì„ ëª¨ë‘ ìœ ì§€í•˜ëŠ” ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ ë‹¨ë½ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure S11: Aligning prompt used during alignment with the open source model.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| T2V Model | Singleâ†‘ | | | | | Multipleâ†‘ | | | Averageâ†‘ |
|---|---|---|---|---|---|---|---|---|---|
|  | Action | Color | Shape | Texture | Detail | Action | Color | Texture |  |
| CogVideoX-5B [30] | 64% | 60% | 44% | 60% | 20% | 8% | 48% | 40% | 43.00% |
| Pyramid-Flow-2B [8] | 44% | 68% | 32% | 32% | 7% | 4% | 24% | 16% | 28.38% |
| Open-Sora Plan v1.3-2.7B [11] | 64% | 44% | 36% | 32% | 27% | 20% | 32% | 12% | 33.38% |
| Open-Sora v1.2-1.1B [35] | 40% | 56% | 36% | 40% | 13% | 12% | 16% | 16% | 28.63% |
| + \mathtt{InstanceCap} (Ours) | **56%** | **60%** | **40%** | **48%** | **27%** | **16%** | **32%** | **24%** | **37.88%** |
| + Panda-captioner [4] | 40% | 48% | 28% | 40% | 20% | 8% | 20% | 12% | 27.00% |
| + ShareGPT4Video [3] | 40% | 44% | 32% | 24% | 13% | **16%** | 8% | **20%** | 24.63% |
| + LLaVA [16] | **52%** | 52% | 28% | 28% | **20%** | 12% | **28%** | 16% | **29.50%** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” InstanceCapê³¼ ìµœì‹  ë¹„ë””ì˜¤ ìº¡ì…˜ ëª¨ë¸ë“¤ì„ ë¹„êµí•œ ì •ëŸ‰ì  ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ì€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” T2V ëª¨ë¸ì¸ Open-Soraë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë˜í•œ CogVideoX-5B, Pyramid-Flow, Open-Sora Planê³¼ ê°™ì€ ì„¸ ê°€ì§€ ê°•ë ¥í•œ T2V ëª¨ë¸ê³¼ë„ ë¹„êµí•©ë‹ˆë‹¤. ë¹„ë””ì˜¤ ìº¡ì…˜ ë°©ë²•ê³¼ Open-Soraì—ì„œ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ëŠ” êµµê²Œ í‘œì‹œí•˜ê³  ë‘ ë²ˆì§¸ë¡œ ì¢‹ì€ ê²°ê³¼ëŠ” ë°‘ì¤„ì„ ê¸‹ìŠµë‹ˆë‹¤. ì´ í‘œëŠ” InstanceCapì„ ì‚¬ìš©í•œ fine-tuningì´ Open-Soraì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ InstanceCapì€ ë³µì¡í•œ ì¸ìŠ¤í„´ìŠ¤ ì„¸ë¶€ ì •ë³´ë¥¼ ìº¡ì²˜í•˜ëŠ” ëŠ¥ë ¥ì—ì„œ ë‹¤ë¥¸ ìº¡ì…”ë‹ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•©ë‹ˆë‹¤. ë˜í•œ InstanceCapì€ CogVideoXì™€ ê°™ì€ ë” í° ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Quantitative comparison betweenÂ ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™ğ™¸ğš—ğšœğšğšŠğš—ğšŒğšğ™²ğšŠğš™\mathtt{InstanceCap}typewriter_InstanceCapÂ and SOTA video captioning models, all based on the popular T2V model Open-Sora. Additionally, we also compare three powerful T2V models, including CogVideoX-5B, Pyramid-Flow, and Open-Sora Plan. The best results of video captioning methods and Open-Sora are marked in bold, and the second-best are underscored.
> </details>

{{< table-caption >}}
| Distortion type | 3DVAE scoreâ†“ | Setting | 
|---|---|---| 
| **Blurring** | 7.71 | GaussianBlur(kernel=(5, 5), sigma=0) | 
| **Compression artifacts** | 11.19 | JPEG compression (quality 5-30) | 
| **Corruptions** | 39.80 | Random pixel masking (binary mask) | 
| **Random noise** | 49.70 | Gaussian noise (mean=0, stddev=25) | 
| **Brightness distortion** | 63.25 | Scaling (factor 0.5-1.5) | 
| **Spatial shifts** | 78.94 | Random affine shifts (Â±10 pixels) | 
| **T2V models Avg.** | 134 ~ 145 | - | 
| **Broken video** | 149.50 | - |{{< /table-caption >}}
> ğŸ”¼ í‘œ S1ì€ ë‹¤ì–‘í•œ ì™œê³¡ ìœ í˜•ê³¼ ë¹„ë””ì˜¤ ëª¨ë¸ì— ëŒ€í•œ 3DVAE ì ìˆ˜ë¥¼ ë³´ì—¬ì£¼ë©°, ì§€ê°ì  ìœ ì‚¬ì„±ê³¼ ì¬êµ¬ì„± ì •í™•ë„ë¥¼ í¬ì°©í•˜ëŠ” ë° ìˆì–´ì„œì˜ íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¤ì • ì—´ì€ ê° ì™œê³¡ ìœ í˜•ì— ëŒ€í•œ ì‹¤í—˜ ì„¤ì •ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. 3DVAE ì ìˆ˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ì™€ ì¬êµ¬ì„±ëœ ë¹„ë””ì˜¤ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ë©°, ë‚®ì€ ì ìˆ˜ëŠ” ë” ë†’ì€ ìœ ì‚¬ì„±ê³¼ ë” ë‚˜ì€ ì¬êµ¬ì„± í’ˆì§ˆì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. í‘œì—ëŠ” ë¸”ëŸ¬ë§, ì••ì¶• ì•„í‹°íŒ©íŠ¸, ì†ìƒ, ì„ì˜ ë…¸ì´ì¦ˆ, ë°ê¸° ì™œê³¡, ê³µê°„ ì´ë™ ë° ê¹¨ì§„ ë¹„ë””ì˜¤ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì™œê³¡ ìœ í˜•ì´ ë‚˜ì—´ë˜ì–´ ìˆìœ¼ë©° ê°ê°ì— ëŒ€í•œ 3DVAE ì ìˆ˜ê°€ ì œê³µë©ë‹ˆë‹¤. ë˜í•œ ì—¬ëŸ¬ T2V ëª¨ë¸ì— ëŒ€í•œ í‰ê·  3DVAE ì ìˆ˜ ë²”ìœ„ë„ í‘œì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table S1: 3DVAE scores for various distortions and video models, showcasing its effectiveness in capturing perceptual similarities and reconstruction accuracy. The setting column provides details of the experimental setup for each distortion type.
> </details>

{{< table-caption >}}
| Instance Detail | Instance Detail | Hallucination Scores | Hallucination Scores |
|---|---|---|---| 
| **1** | Descriptions are extremely vague, imprecise, or largely inaccurate. Almost no specific details from the video are captured correctly. | **1** | Severe hallucination - Describes many nonexistent details, significantly misrepresents what is shown, or introduces extensive irrelevant content with many unrelated topics or external information. |
| **2** | Descriptions have major inaccuracies or omit many important details. Only a few basic elements are described correctly. | **2** | Frequent hallucination - Multiple instances of fabricated or misrepresented details and significant extra content introducing information beyond the video scope. |
| **3** | Descriptions are moderately accurate but lack precision in some areas. Core details are present but some secondary details are missing or incorrect. | **3** | Occasional hallucination - A few minor instances of fabricated details, misrepresentations, or the addition of extra content not covered in the video. |
| **4** | Descriptions are largely accurate and detailed. Most key elements and nuances from the video are captured correctly, with only minor omissions or imprecisions. | **4** | Minimal hallucination - One or two very minor discrepancies or limited introduction of external information. |
| **5** | Descriptions are highly precise and comprehensive. All important details from the video are captured accurately, including subtle elements and specific examples. | **5** | No hallucination - All described details accurately reflect what is shown in the video, with no external content added. |{{< /table-caption >}}
> ğŸ”¼ í‘œ S2ëŠ” ì¸ìŠ¤í„´ìŠ¤ ì„¸ë¶€ ì •ë³´ ë° í™˜ê° ì ìˆ˜ì— ëŒ€í•œ ì±„ì  ê¸°ì¤€ì„ ì„¤ëª…í•˜ê³  ë‚´ë¶€ ë° ì™¸ë¶€ í™˜ê°ì„ í†µí•© í‰ê°€ í”„ë ˆì„ì›Œí¬ì— í†µí•©í•©ë‹ˆë‹¤. ì¸ìŠ¤í„´ìŠ¤ ì„¸ë¶€ ì •ë³´ëŠ” í…ìŠ¤íŠ¸ê°€ ë¹„ë””ì˜¤ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. í™˜ê° ì ìˆ˜(HS)ëŠ” í…ìŠ¤íŠ¸ê°€ ë¹„ë””ì˜¤ì— ì—†ëŠ” ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ë§ì´ ë„ì…í•˜ëŠ”ì§€ í‰ê°€í•˜ê³ , ë³¸ì§ˆì  í™˜ê°(ë¹„ë””ì˜¤ì— ìˆëŠ” ë‚´ìš©ì— ëŒ€í•œ í™˜ê°)ê³¼ ì™¸ì  í™˜ê°(ë¹„ë””ì˜¤ì— ì—†ëŠ” ë‚´ìš©ì— ëŒ€í•œ í™˜ê°)ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table S2: This table outlines scoring criteria for Instance Detail and Hallucination Scores, integrating intrinsic and extrinsic hallucinations into a unified framework for evaluation.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}