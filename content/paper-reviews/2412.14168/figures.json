[{"figure_path": "https://arxiv.org/html/2412.14168/x2.png", "caption": "Figure 1: \nDemonstration for the applications of FashionComposer.\nFashionComposer takes different kinds of conditions\u00a0(e.g., garment image, face image, parametric human model) equally as \u201cassets\u201d to composite diverse and realistic fashion images.\nThus supporting various fashion-related applications like controllable model image generation, virtual try-on, human album generation, etc.", "description": "\uadf8\ub9bc 1\uc740 FashionComposer\uc758 \uc751\uc6a9 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. FashionComposer\ub294 \uc758\ub958 \uc774\ubbf8\uc9c0, \uc5bc\uad74 \uc774\ubbf8\uc9c0, \ub9e4\uac1c\ubcc0\uc218\ud654\ub41c \uc778\uccb4 \ubaa8\ub378\uacfc \uac19\uc774 \ub2e4\uc591\ud55c \uc870\uac74\ub4e4\uc744 \ub3d9\ub4f1\ud55c \"\uc790\uc0b0\"\uc73c\ub85c \uac04\uc8fc\ud558\uc5ec \ub2e4\uc591\ud558\uace0 \uc0ac\uc2e4\uc801\uc778 \ud328\uc158 \uc774\ubbf8\uc9c0\ub97c \ud569\uc131\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc81c\uc5b4 \uac00\ub2a5\ud55c \ubaa8\ub378 \uc774\ubbf8\uc9c0 \uc0dd\uc131, \uac00\uc0c1 \ud53c\ud305, \uc778\ubb3c \uc0ac\uc9c4 \uc0dd\uc131 \ub4f1 \ub2e4\uc591\ud55c \ud328\uc158 \uad00\ub828 \uc751\uc6a9 \ud504\ub85c\uadf8\ub7a8\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.14168/extracted/6081173/fig/comp_quali_v3.jpg", "caption": "Figure 2: Overall pipeline of FashionComposer.\nFashionComposer takes garments composition and optional face, text prompt, and a densepose map projected from SMPL as inputs. The text prompt is encoded and fused with UNets through cross-attention and subject-binding attention, while the garment features are extracted and injected for denoising through Feature Injection Attention.", "description": "\uadf8\ub9bc 2\ub294 FashionComposer\uc758 \uc804\uccb4 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. FashionComposer\ub294 \uc758\ub958 \uad6c\uc131, \uc120\ud0dd\uc801 \uc5bc\uad74 \uc774\ubbf8\uc9c0, \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8 \ubc0f SMPL\uc5d0\uc11c \ud22c\uc601\ub41c densepose \ub9f5\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uc2b5\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub294 \uc778\ucf54\ub529\ub418\uc5b4 cross-attention \ubc0f subject-binding attention\uc744 \ud1b5\ud574 UNet\uacfc \uacb0\ud569\ub418\uace0, \uc758\ub958 \ud2b9\uc9d5\uc740 Feature Injection Attention\uc744 \ud1b5\ud574 \ucd94\ucd9c\ub418\uc5b4 \uc7a1\uc74c \uc81c\uac70\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.14168/extracted/6081173/fig/comp_v2.jpg", "caption": "Figure 3: Qualitative comparison with multi-reference customization methods, including Emu2\u00a0[27], Collage Diffusion\u00a0[25], Paint by Example\u00a0[34] and AnyDoor\u00a0[6].", "description": "\uadf8\ub9bc 3\uc740 Emu2, Collage Diffusion, Paint by Example, AnyDoor \ub124 \uac00\uc9c0 \ub2e4\uc911 \ucc38\uc870 \uc774\ubbf8\uc9c0 \ud3b8\uc9d1 \ubc29\ubc95\uc744 \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc740 \uc5ec\ub7ec \uac1c\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\ub294\ub370, \uadf8\ub9bc\uc5d0\uc11c\ub294 \uac01 \ubc29\ubc95\uc758 \uacb0\uacfc \uc774\ubbf8\uc9c0\ub97c \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec \uc11c\ub85c \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc7a5\ub2e8\uc810\uc744 \uba85\ud655\ud788 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574 \ub2e4\uc591\ud55c \uc758\ub958\uc640 \ud3ec\uc988\uc758 \uc774\ubbf8\uc9c0\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 FashionComposer\uac00 \uc81c\uc2dc\ud558\ub294 \ub2e4\uc911 \ucc38\uc870 \uc774\ubbf8\uc9c0 \ud3b8\uc9d1 \ubc29\ubc95\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\ub2e4 \uba85\ud655\ud558\uac8c \uc81c\uc2dc\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.14168/extracted/6081173/fig/tryon.jpg", "caption": "Figure 4: Qualitative comparison with garment-centric fashion image synthesis methods, including\nStableGarment\u00a0[30],\nIMAGDressing-v1\u00a0[26],\nand Magic Clothing\u00a0[4],\nwhere ours better preserves the identity of the target objects.\nNote that all approaches do not finetune the model on the test samples.", "description": "\uadf8\ub9bc 4\ub294 \uc758\ub958 \uc911\uc2ec \ud328\uc158 \uc774\ubbf8\uc9c0 \ud569\uc131 \ubc29\ubc95\ub4e4(StableGarment[30], IMAGDressing-v1[26], Magic Clothing[4])\uacfc \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc81c\uc548\ub41c \ubc29\ubc95\uc740 \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub300\uc0c1 \ubb3c\uccb4\uc758 \uc815\uccb4\uc131\uc744 \ub354 \uc798 \ubcf4\uc874\ud569\ub2c8\ub2e4. \ubaa8\ub4e0 \ubc29\ubc95\ub4e4\uc740 \ud14c\uc2a4\ud2b8 \uc0d8\ud50c\uc5d0\uc11c \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.  \uc989, \uadf8\ub9bc\uc740 \uc5ec\ub7ec \uac00\uc9c0 \uc758\ub958 \uc911\uc2ec \ud328\uc158 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70, \ud2b9\ud788 \uc81c\uc548\ub41c \ubaa8\ub378\uc774 \ub2e4\ub978 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc758\ub958\uc758 \ud2b9\uc9d5\uc744 \ub354 \uc798 \uc720\uc9c0\ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubaa8\ub378\uc744 \uc7ac \ud559\uc2b5\uc2dc\ud0a4\uc9c0 \uc54a\uc558\ub2e4\ub294 \uc810\ub3c4 \uc911\uc694\ud55c \ube44\uad50 \ud3ec\uc778\ud2b8\uc785\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.14168/extracted/6081173/fig/ablation_ref_v2.jpg", "caption": "Figure 5: Diverse virtual try-on results of FashionComposer for upper, lower, and outfit try-on tasks.", "description": "\uadf8\ub9bc 5\ub294 FashionComposer\uac00 \uc0c1\uc758, \ud558\uc758, \ub610\ub294 \uc758\uc0c1 \uc804\uccb4\ub97c \uac00\uc0c1\uc73c\ub85c \uc785\ud600 \ubcf4\ub294 \ub2e4\uc591\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc5f4\uc740 \ub2e4\ub978 \uc720\ud615\uc758 \uac00\uc0c1 \ud53c\ud305(\uc0c1\uc758, \ud558\uc758, \uc804\uccb4 \uc758\uc0c1)\uc744 \ub098\ud0c0\ub0b4\uba70, FashionComposer\uc758 \ub2e4\uc591\ud55c \uc785\ub825 \uc870\uac74(\ud14d\uc2a4\ud2b8, \uc758\ub958 \uc774\ubbf8\uc9c0, \ud3ec\uc988, \uc0ac\ub78c \uc774\ubbf8\uc9c0)\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc720\uc5f0\uc131\uacfc \uc801\uc751\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc2a4\ud0c0\uc77c, \uc0c9\uc0c1, \ud328\ud134\uc758 \uc758\uc0c1\ub4e4\uc774 \uc815\ud655\ud558\uac8c \uc0ac\ub78c\uc758 \uc2e0\uccb4\uc5d0 \ub9de\ucdb0 \uc785\ud600\uc9c4 \ubaa8\uc2b5\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 FashionComposer\uac00 \ub2e4\uc591\ud55c \uc758\ub958 \uc544\uc774\ud15c\uacfc \uc2e0\uccb4 \uc720\ud615\uc5d0 \uc801\uc6a9 \uac00\ub2a5\ud558\uace0 \ud604\uc2e4\uac10 \uc788\ub294 \uac00\uc0c1 \ud53c\ud305 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3. \uac00\uc0c1 \ud53c\ud305 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2412.14168/x3.png", "caption": "Figure 6: Qualitative comparison for the reference encoder. Reference UNet better preserves the fine details of the garments.", "description": "\uadf8\ub9bc 6\uc740 \ucc38\uc870 \uc778\ucf54\ub354(Reference UNet)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\uc785\ub2c8\ub2e4.  \ub2e4\ub978 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud588\uc744 \ub54c, Reference UNet\uc774 \uc758\ub958\uc758 \uc138\uc138\ud55c \ub514\ud14c\uc77c\uc744 \ub354 \uc798 \ubcf4\uc874\ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Reference UNet\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740 \uacbd\uc6b0 \uc758\ub958\uc758 \uc9c8\uac10\uc774\ub098 \uc8fc\ub984 \ub4f1 \ubbf8\uc138\ud55c \ubd80\ubd84\uc774 \uc190\uc2e4\ub418\ub294 \ubc18\uba74, Reference UNet\uc744 \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc5d0\ub294 \uc774\ub7ec\ud55c \ub514\ud14c\uc77c\uc774 \uc798 \uc720\uc9c0\ub418\uc5b4 \ub354\uc6b1 \uc0ac\uc2e4\uc801\uc778 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 Reference UNet\uc774 \uc758\ub958 \uc774\ubbf8\uc9c0\uc758 \ud2b9\uc9d5\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ucd94\ucd9c\ud558\uace0 \ubcf5\uc6d0\ud558\ub294 \ub370 \ud0c1\uc6d4\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.14168/x4.png", "caption": "Figure 7: Qualitative ablation study on subject-binding attention. Bind(1) means only modifying the self-attention modules of UNet blocks with the smallest resolution. Conv-in refers to injecting the mask map through the Convolution-in layer of the reference UNet. We highlight mistakes in rows 2-3 using red boxes.", "description": "\uadf8\ub9bc 7\uc740 \uc81c\uc548\ub41c \uc8fc\uc81c \ubc14\uc778\ub529 \uc5b4\ud150\uc158\uc5d0 \ub300\ud55c \uc815\uc131\uc801 \ube44\uad50 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Bind(1)\uc740 \uac00\uc7a5 \uc791\uc740 \ud574\uc0c1\ub3c4\uc758 UNet \ube14\ub85d\uc758 \uc790\uae30 \uc5b4\ud150\uc158 \ubaa8\ub4c8\ub9cc \uc218\uc815\ud558\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uace0, Conv-in\uc740 \ucc38\uc870 UNet\uc758 \ud569\uc131\uacf1 \uc785\ub825 \uacc4\uce35\uc744 \ud1b5\ud574 \ub9c8\uc2a4\ud06c \ub9f5\uc744 \uc8fc\uc785\ud558\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. 2\ubc88\uc9f8\uc640 3\ubc88\uc9f8 \ud589\uc758 \uc2e4\uc218\ub294 \ube68\uac04\uc0c9 \uc0c1\uc790\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc124\uc815\uc5d0\uc11c \uc8fc\uc81c \ubc14\uc778\ub529 \uc5b4\ud150\uc158\uc758 \ud6a8\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uba70, \ud2b9\ud788 \ubd80\ubd84\uc801\uc778 \uc8fc\uc81c \ubc14\uc778\ub529\uc774 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4.4 Ablation Study"}]