[{"content": "| Models | Size | shots | VideoMME w/o sub. Short | VideoMME w/o sub. Medium | VideoMME w/o sub. Long | VideoMME w/o sub. Avg | VideoMME w/ sub. Short | VideoMME w/ sub. Medium | VideoMME w/ sub. Long | VideoMME w/ sub. Avg |\n|---|---|---|---|---|---|---|---|---|---|---|\n| **Proprietary Models** |  |  |  |  |  |  |  |  |  |  |\n| GPT-4V [2023] | - | 384 | 70.5 | 55.8 | 53.5 | 59.9 | 73.2 | 59.7 | 56.9 | 63.3 |\n| GPT-4o [March 2024] | - | 384 | 80.0 | 70.3 | 65.3 | 71.9 | 82.8 | 76.6 | 72.1 | 77.2 |\n| Gemini-1.5-Pro [2024] | - | 0.5 fps | **81.7** | **74.3** | **67.4** | **75.0** | **84.5** | **81.0** | **77.4** | **81.3** |\n| Claude3-Opus [March 2024] | - | - | 71.0 | 57.4 | 51.2 | 60.0 | 73.5 | 60.1 | 54.7 | 62.9 |\n| **Open-source MLLMs** |  |  |  |  |  |  |  |  |  |  |\n| VideoChat2 [2024] | 7B | 196 | 48.3 | 37.0 | 33.2 | 39.5 | 52.8 | 39.4 | 39.2 | 43.8 |\n| VideoLLaVA [2023] | 7B | 49 | 45.3 | 38.0 | 36.2 | 39.9 | 46.1 | 40.7 | 38.1 | 41.6 |\n| Sharegpt4Video [2024a] | 7B | 16 | 48.3 | 36.3 | 35.0 | 39.9 | 53.6 | 39.3 | 37.9 | 43.6 |\n| InternVL-Chat-V1.5 [2024b] | 20B | 10 | 60.2 | 46.4 | 45.6 | 47.8 | 61.7 | 49.1 | 46.6 | 52.4 |\n| Video-CCAM [2024b] | 14B | 96 | 62.2 | 50.6 | 46.7 | 53.2 | 66.0 | 56.3 | 49.9 | 57.4 |\n| Long-LLaVA [2024b] | 7B | 128 | 61.9 | 51.4 | 45.4 | 52.9 | 66.2 | 54.7 | 50.3 | 57.1 |\n| VITA [2024b] | 8x7B | 20 | 64.2 | 53.3 | 47.6 | 55.0 | 67.9 | 55.3 | 49.6 | 57.6 |\n| Kangaroo [2024b] | 8B | 64 | 66.1 | 55.3 | 46.7 | 56.0 | 68.0 | 55.4 | 49.3 | 57.6 |\n| LongVILA [2024] | 7B | 256 | 69.0 | 58.3 | 53.0 | 60.1 | 72.9 | 64.9 | 57.4 | 65.1 |\n| LongVA [2024a] | 7B | 128 | 61.1 | 50.4 | 46.2 | 52.6 | 61.6 | 53.6 | 47.6 | 54.3 |\n| LongVA+Ours | 7B | 128 | **61.6** | **52.0** | **46.8** | **53.5** | **64.2** | **54.4** | **48.5** | **55.7** |\n| Video-XL\u2020 [2024] | 7B | 128 | 63.1 | 52.4 | 48.7 | 54.7 | 68.3 | 55.7 | 52.1 | 58.7 |\n| Video-XL+Ours | 7B | 128 | **64.1** | **53.6** | **49.1** | **55.6** | **68.9** | **57.1** | **52.3** | **59.5** |\n| LLaVA-Video [2024c] | 7B | 64 | 76.1 | 61.8 | 52.1 | 63.3 | 78.0 | 69.3 | 61.8 | 69.7 |\n| LLaVA-Video+Ours | 7B | 64 | **77.2** | **62.4** | **53.8** | **64.4** | **80.1** | **69.4** | **65.1** | **71.5** |", "caption": "Table 1: Experimental results on VideoMME benchmarks, we report results with and without subtitle assistance. \u2020 indicates that the results were reproduced using their official weights. The best is in bold.", "description": "\ud45c 1\uc740 VideoMME \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc790\ub9c9 \uc9c0\uc6d0 \uc720\ubb34\uc5d0 \ub530\ub978 \uacb0\uacfc\ub97c \ubaa8\ub450 \uc81c\uc2dc\ud558\uba70, \u2020 \ud45c\uc2dc\ub294 \uacf5\uc2dd \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc7ac\ud604\ud55c \uacb0\uacfc\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \uc9e7\uc740, \uc911\uac04, \uae34 \ube44\ub514\uc624 \uae38\uc774\uc5d0 \ub300\ud574 \uac01\uac01 \ud3c9\uac00\ub418\uc5c8\uc73c\uba70, \ucd5c\uace0 \uc131\ub2a5\uc740 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ubaa8\ub378\uc758 \ud06c\uae30(Size), \uc0ac\uc6a9\ub41c \uc0f7\uc758 \uc218(shots), \uadf8\ub9ac\uace0 \uc790\ub9c9 \uc720\ubb34\uc5d0 \ub530\ub978 \uc9e7\uc740, \uc911\uac04, \uae34 \ube44\ub514\uc624\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4(Performance)\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\ub294 \ub2e4\uc591\ud55c \ud06c\uae30\uc640 \uc720\ud615\uc758 \ub2e4\uc911 \ubaa8\ub4dc \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, VideoMME \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uace0 \ube44\uad50\ud558\ub294 \uac83\uc744 \ubaa9\uc801\uc73c\ub85c \ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Models | Size | shots | MLVU | LongVideo. |\n|---|---|---|---|---|\n| Proprietary Models |  |  |  |  |\n| GPT-4V (OpenAI, 2023) | - | 384 | 49.2 | 60.7 |\n| GPT-4o (OpenAI, March 2024) | - | 384 | 64.6 | 66.7 |\n| Gemini-1.5-Pro (Team et al., 2024) | - | 0.5 fps | - | 64.4 |\n| Open-source MLLMs |  |  |  |  |\n| VideoChat2 (Li et al., 2024) | 7B | 196 | 47.9 | 39.3 |\n| VideoLLaVA (Lin et al., 2023) | 7B | 49 | 47.3 | 37.6 |\n| Shargpt4Video (Chen et al., 2024a) | 7B | 16 | 46.4 | 41.8 |\n| Video-CCAM (Fei et al., 2024b) | 14B | 96 | 63.1 | - |\n| LongVA (Zhang et al., 2024a) | 7B | 128 | 56.3 | 47.8 |\n| LongVA+Ours | 7B | 128 | **58.9** | **52.8** |\n| Video-XL\u2020 (Shu et al., 2024) | 7B | 128 | 64.3 | 49.8 |\n| Video-XL+Ours | 7B | 128 | **65.2** | **50.6** |\n| LLaVA-Video (Zhang et al., 2024c) | 7B | 64 | 70.8 | 58.2 |\n| LLaVA-Video+Ours | 7B | 64 | **71.4** | **58.9** |", "caption": "Table 2: Experimental results on MLVU and LongVideoBench benchmarks, \u201dLongVideo.\u201d refers to LongVideoBench.", "description": "\ud45c 2\ub294 MLVU\uc640 LongVideoBench \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LongVideo\ub294 LongVideoBench\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4. \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 MLVU\uc640 LongVideoBench \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 MLVU\uc640 LongVideoBench \uc810\uc218\ub85c \ub098\ud0c0\ub0b4\uba70,  \"Long Video\" \uc5f4\uc740 LongVideoBench \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uae34 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ube44\uad50\ud558\uace0, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc6b0\uc218\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Models | Size | MVBench | NEXT-QA |\n|---|---|---|---| \n| Proprietary Models |  |  |  |\n| GPT-4V (OpenAI, 2023) | - | 43.5 | - |\n| GPT-4o (OpenAI, March 2024) | - | - | 76.0 |\n| Open-source MLLMs |  |  |  |\n| mPLUG-Owl (Ye et al., 2023) | 7B | 29.7 | 33.8 |\n| Video-LLaVA (Lin et al., 2023) | 7B | - | 40.2 |\n| VideoChat2 (Li et al., 2024) | 7B | 51.9 | 78.6 |\n| TimeChat (Ren et al., 2024) | 7B | 38.5 | - |\n| ST-LLM (Liu et al., 2025) | 7B | 54.9 | - |\n| PLLaVA (Xu et al., 2024) | 7B | 58.1 | 45.6 |\n| Long-LLaVA (Wang et al., 2024b) | 7B | 54.6 | - |\n| VideoLLava (Lin et al., 2023) | 7B | 52.5 | 71.1 |\n| LongVA (Zhang et al., 2024a) | 7B | 49.7 | 69.3 |\n| LongVA+Ours | 7B | 50.9 | 69.9 |\n| LLaVA-Video (Zhang et al., 2024c) | 7B | 58.6 | 74.2 |\n| LLaVA-Video+Ours | 7B | 60.5 | 75.1 |", "caption": "Table 3: Results on NEXT-QA and MVBench.", "description": "\ud45c 3\uc740 NEXT-QA \ubc0f MVBench \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378(7B, 14B, 20B \ub4f1)\ub4e4\uc758  \ub450 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4(Accuracy)\ub97c \uc81c\uc2dc\ud558\uc5ec, \uac01 \ubaa8\ub378\uc758 \uc7a5\ub2e8\uc810 \ubc0f \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \ud2b9\ud788,  \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 CoS \uae30\ubc95\uc744 \uc801\uc6a9\ud55c \ubaa8\ub378\uacfc \uc801\uc6a9\ud558\uc9c0 \uc54a\uc740 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec CoS\uc758 \ud6a8\uacfc\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method's Variants | VideoXL |  |  |  | LLaVA-Video |  |  |  |\n|---|---|---|---|---|---|---|---|---|\n| BVS | OFL | PFL | NFL | DWM | short | medium | long | avg |\n|  | \u2713 | \u2713 | \u2713 | \u2713 | 63.1 | 52.4 | 48.7 | 54.7 |\n| \u2713 |  | \u2713 | \u2713 | \u2713 | 52.3 | 45.6 | 47.2 | 48.4 |\n| \u2713 | \u2713 |  | \u2713 | \u2713 | 63.8 | 53.3 | 48.8 | 55.3 |\n| \u2713 | \u2713 | \u2713 |  | \u2713 | 63.5 | 53.2 | 48.6 | 55.2 |\n| \u2713 | \u2713 | \u2713 | \u2713 |  | 63.4 | 53.3 | 48.5 | 55.1 |\n| **\u2713** | **\u2713** | **\u2713** | **\u2713** | **\u2713** | **64.1** | **53.6** | **49.1** | **55.6** |", "caption": "Table 4: Ablation Study on VideoMME with VideoXL and LLaVA-Video", "description": "\ud45c 4\ub294 VideoMME \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec VideoXL\uacfc LLaVA-Video \ubaa8\ub378\uc5d0 \ub300\ud574 CoS(Chain-of-Shot Prompting)\uc758 \uac01 \ubaa8\ub4c8(Binary Video Summary, Original Frame, Positive Shots, Negative Shots, Dynamic Weighting Mechanism)\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub4c8\uc758 \uc720\ubb34\uc5d0 \ub530\ub978 \uc9e7\uc740, \uc911\uac04, \uae34 \uc601\uc0c1 \uae38\uc774\ubcc4 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec CoS\uc758 \ud6a8\uacfc\ub97c \uac80\uc99d\ud569\ub2c8\ub2e4.  \uacb0\uacfc\ub294 \uac01 \ubaa8\ub4c8\uc774 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uae30\uc5ec\ub3c4\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3. Methodology"}, {"content": "| (a) Various MLLM for Binary video summary | (b) Shot-sampling rate | (c) Aggregation shot count |\n|---|---|---|\n| LongVA (Zhang et al., 2024a) | 64 | 2 |\n|  | 96 | 4 |\n|  | 128 | 8 |\n|  | 192 | 16 |\n| MinichatGPT (Zhu et al., 2023) |  |  |\n| Qwen2 (Wang et al., 2024a) |  |  |\n| LLaVA1.5 (Liu et al., 2024a) |  |  |", "caption": "Table 5: Parameter ablation study on VideoMME with LongVA as the baseline.", "description": "\ud45c 5\ub294 LongVA \ubaa8\ub378\uc744 \uae30\uc900\uc73c\ub85c VideoMME \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub9e4\uac1c\ubcc0\uc218\ub97c \uc81c\uac70\ud588\uc744 \ub54c\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  (a)\ub294 \uc774\uc9c4 \ube44\ub514\uc624 \uc694\uc57d\uc5d0 \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c MLLM \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5 \ube44\uad50, (b)\ub294 \uc0f7 \uc0d8\ud50c\ub9c1 \ube44\uc728\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654, (c)\ub294 \ubaa8\uc790\uc774\ud06c \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc2dc \uacb0\ud569\ub418\ub294 \uc5f0\uc18d \uc0f7 \uac1c\uc218\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubc0f \ucc98\ub9ac \uc2dc\uac04 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc2e4\ud5d8\uc740 \uc138 \uac00\uc9c0 \ube44\ub514\uc624 \uae38\uc774(\uc9e7\uc740, \uc911\uac04, \uae34)\uc5d0 \ub300\ud574 \ud3c9\uac00\ub418\uc5c8\uc73c\uba70,  \uc131\ub2a5\uc740 \uc815\ud655\ub3c4(accuracy)\ub85c \uce21\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 CoS \ubc29\ubc95\uc758 \uac01 \uad6c\uc131 \uc694\uc18c(\uc774\uc9c4 \ube44\ub514\uc624 \uc694\uc57d, \ube44\ub514\uc624 \uacf5\ub3d9 \ucd94\ub860, \ub3d9\uc801 \uac00\uc911\uce58 \uba54\ucee4\ub2c8\uc998)\uc758 \ud6a8\uacfc\uc640 \ucd5c\uc801\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. Experiments"}]