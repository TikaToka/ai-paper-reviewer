[{"content": "| Methods | Work | Setting | Speedup |\n|---|---|---|---|\n| Activation <br> Polynomialization | Iron (NeurIPS\u201922) | MPC | 9.6x |\n|  | BOLT (S&P\u201924) | MPC | 24.6x |\n|  | BumbleBee (NDSS\u201925) | MPC | 22.3x |\n|  | NEXUS (NDSS\u201925) | FHE | 5.3x |\n| Activation <br> Sparsification | TEAL (ICLR\u201925) | 25% sparsity | 1.3x |\n|  |  | 50% sparsity | 1.9x |\n|  |  | 90% sparsity | 9.5x |\n| Activation <br> Quantization | SmoothQuant (ICML\u201923) | W16A8 | 2.0x |\n|  |  | W16A4 | 4.0x |\n|  | OmniQuant (ICLR\u201924) | W16A8 | 2.0x |\n|  |  | W16A4 | 4.0x |", "caption": "Table 1: Activation approximation techniques and their inference efficiency gains. For activation polynomialization, the baseline work is SIRNN (S&P\u201921) [29], a private inference protocol without polynomialization. For activation sparsification and quantization, the baseline is full-precision (FP16) inference without any accelerations.", "description": "\ud45c 1\uc740 \ud65c\uc131\ud654 \uadfc\uc0ac \uae30\ubc95\uacfc \uadf8\uc5d0 \ub530\ub978 \ucd94\ub860 \ud6a8\uc728 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud65c\uc131\ud654 \ub2e4\ud56d\uc2dd \uadfc\uc0ac\uc758 \uacbd\uc6b0, \uae30\uc900 \uc5f0\uad6c\ub294 \ub2e4\ud56d\uc2dd \uadfc\uc0ac \uc5c6\uc774 \uac1c\uc778 \uc815\ubcf4 \ubcf4\ud638 \ucd94\ub860 \ud504\ub85c\ud1a0\ucf5c\uc744 \uc0ac\uc6a9\ud558\ub294 SIRNN(S&P\u201921) [29]\uc785\ub2c8\ub2e4. \ud65c\uc131\ud654 \ud76c\uc18c\ud654 \ubc0f \uc591\uc790\ud654\uc758 \uacbd\uc6b0, \uae30\uc900\uc740 \uac00\uc18d \uc5c6\uc774 \uc804\uccb4 \uc815\ubc00\ub3c4(FP16) \ucd94\ub860\uc785\ub2c8\ub2e4.  \ub2e4\uc2dc \ub9d0\ud574, \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ud65c\uc131\ud654 \uadfc\uc0ac \uae30\ubc95\ub4e4\uc744 \uc18c\uac1c\ud558\uace0, \uac01 \uae30\ubc95\uc774 \uae30\uc874 \ubc29\uc2dd \ub300\ube44 \ucd94\ub860 \uc18d\ub3c4\ub97c \uc5bc\ub9c8\ub098 \ud5a5\uc0c1\uc2dc\ud0a4\ub294\uc9c0(\uc18d\ub3c4 \ud5a5\uc0c1 \ubc30\uc218) \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud65c\uc131\ud654 \uadfc\uc0ac \uae30\ubc95\uc740 \ud06c\uac8c \ud65c\uc131\ud654 \ub2e4\ud56d\uc2dd \uadfc\uc0ac, \ud65c\uc131\ud654 \ud76c\uc18c\ud654, \ud65c\uc131\ud654 \uc591\uc790\ud654 \uc138 \uac00\uc9c0\ub85c \ubd84\ub958\ub429\ub2c8\ub2e4. \uac01 \uae30\ubc95\ubcc4 \ub300\ud45c\uc801\uc778 \uc5f0\uad6c\ub4e4\uc774 \uc81c\uc2dc\ub418\uba70, \uc2e4\ud5d8 \ud658\uacbd(MPC, FHE \ub4f1)\uacfc \uc18d\ub3c4 \ud5a5\uc0c1 \ubc30\uc218\uac00 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 \ubc30\uacbd"}, {"content": "Methods | Works | Setting | \\epsilon_{l}^{up} | \\epsilon_{l}^{down} | \\textbf{PPL}\\downarrow | \\textbf{ASR}\\downarrow\n---|---|---|---|---|---|---\nActivation <br> Polynomialization | Iron [19] | MPC | \\mathcal{N}(0,0.064^{2}) | Lap(0, 0.049) | 43.74 | 58.07\n| BOLT [21] | MPC | \\mathcal{N}(0,0.042^{2}) | Lap(0, 0.036) | 15.81 | 35.76\n| BumbleBee [22] | MPC | \\mathcal{N}(0,0.026^{2}) | Lap(0, 0.018) | 11.28 | 20.56\n| NEXUS [23] | FHE | \\mathcal{N}(0,0.031^{2}) | Lap(0, 0.014) | 12.93 | 21.15\nActivation <br> Sparsification | TEAL [24] | 10% sparsity | \\mathcal{N}(0,0.35^{2},|X|\\leq 0.04) | \\text{Lap}(0,0.024,|X|\\leq 0.003) | 8.05 | 5.00\n|  |  | 25% sparsity | \\mathcal{N}(0,0.35^{2},|X|\\leq 0.11) | \\text{Lap}(0,0.024,|X|\\leq 0.007) | 8.09 | 28.85\n|  |  | 50% sparsity | \\mathcal{N}(0,0.35^{2},|X|\\leq 0.24) | \\text{Lap}(0,0.024,|X|\\leq 0.017) | 8.57 | 57.12\n|  |  | 90% sparsity | \\mathcal{N}(0,0.35^{2},|X|\\leq 0.57) | \\text{Lap}(0,0.024,|X|\\leq 0.055) | 206.47 | 0.02\nActivation <br> Quantization | SmoothQuant [27] | W16A8 | \\mathcal{N}(0,0.027^{2}) | Lap(0,0.019) | 9.56 | 41.92\n|  |  | W16A4 | \\mathcal{N}(0,0.035^{2}) | Lap(0,0.024) | 10.35 | 55.19\n| OmniQuant [28] | W16A8 | \\mathcal{N}(0,0.029^{2}) | Lap(0,0.028) | 9.85 | 33.46\n|  |  | W16A4 | \\mathcal{N}(0,0.036^{2}) | Lap(0,0.037) | 10.79 | 47.11", "caption": "Table 2: Benchmark of different training-free activation approximation techniques on Llama-3.1-8B-Instruct. Note that the baseline PPL is 8.05, ASR is 0.19.", "description": "\ud45c 2\ub294 Llama-3.1-8B-Instruct \ubaa8\ub378\uc5d0 \ub300\ud574 \ub2e4\uc591\ud55c training-free activation approximation \uae30\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \ubca4\uce58\ub9c8\ud06c\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uae30\ubc95\uc740 activation polynomialization, sparsification, quantization \uc138 \uac00\uc9c0 \ubc94\uc8fc\ub85c \ub098\ub258\uba70, \uac01 \ubc94\uc8fc \ub0b4\uc5d0\uc11c \ub300\ud45c\uc801\uc778 \uae30\ubc95\ub4e4\uc744 \uc120\uc815\ud558\uc5ec \uc2e4\ud5d8\ud588\uc2b5\ub2c8\ub2e4.  \uacb0\uacfc\ub294 perplexity (PPL)\uc640 attack success rate (ASR)\uc73c\ub85c \uce21\uc815\ub418\uc5c8\uc73c\uba70, baseline PPL\uc740 8.05, baseline ASR\uc740 0.19\uc785\ub2c8\ub2e4.  \uac01 \uae30\ubc95\uc758 \uc801\uc6a9 \ud6c4 PPL\uacfc ASR \ubcc0\ud654\ub97c \ud1b5\ud574 activation approximation\uc774 \ubaa8\ub378 \uc131\ub2a5 \ubc0f \uc548\uc804\uc131\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 Activation Approximation Error"}, {"content": "| Family | Model | Sensitive | Baseline | Error Before \ud835\udc16<sup>up</sup> | Error Before \ud835\udc16<sup>down</sup> |\n|---|---|---|---|---|---|---|\n| Llama | Llama-2-7B-Chat | [0-3] | 1.34 | 7.84 |  \ud835\udf70(0,0.045<sup>2</sup>) | 56.73 |\n|  |  |  |  |  | Lap(0, 0.100) | 49.80 |\n|  |  |  |  |  |  | 10.96 |\n|  | Llama-2-13B-Chat | [0-3] | 0.00 | 7.07 | \ud835\udf70(0,0.042<sup>2</sup>) | 47.88 |\n|  |  |  |  |  | Lap(0, 0.125) | 52.12 |\n|  |  |  |  |  |  | 18.46 |\n|  | Llama-3.1-8B-Instruct | [0-3] | 0.19 | 8.05 | \ud835\udf70(0,0.075<sup>2</sup>) | 69.23 |\n|  |  |  |  |  | Lap(0, 0.085) | 67.50 |\n|  |  |  |  |  |  | 11.70 |\n| Phi3 | Phi-3-Mini-4K-Instruct | [0-3] | 0.00 | 6.71 | \ud835\udf70(0,0.040<sup>2</sup>) | 82.61 |\n|  |  |  |  |  | Lap(0, 0.120) | 32.38 |\n|  |  |  |  |  |  | 9.46 |\n|  | Phi-3.5-Mini-Instruct | [0-3] | 0.77 | 6.86 | \ud835\udf70(0,0.033<sup>2</sup>) | 79.50 |\n|  |  |  |  |  | Lap(0, 0.100) | 44.72 |\n|  |  |  |  |  |  | 7.45 |\n| Mistral | Mistral-7B-Instruct-v0.3 | [0-6] | 34.61 | 6.13 | \ud835\udf70(0,0.200<sup>2</sup>) | 73.18 |\n|  |  |  |  |  | Lap(0, 0.075) | 71.02 |\n|  |  |  |  |  |  | 6.24 |\n|  | Mixtral-8x7B-Instruct-v0.1 | [0-4] | 1.15 | 4.61 | \ud835\udf70(0,0.400<sup>2</sup>) | 82.47 |\n|  |  |  |  |  | Lap(0, 0.225) | 87.64 |\n|  |  |  |  |  |  | 19.31 |\n|  | Zephyr-7B-\u03b2 | [0-4] | 22.31 | 7.01 | \ud835\udf70(0,0.250<sup>2</sup>) | 88.30 |\n|  |  |  |  |  | Lap(0, 0.113) | 82.35 |\n|  |  |  |  |  |  | 9.07 |\n| Qwen | Qwen2-7B-Instruct | [0-4] | 0.38 | 8.46 | \ud835\udf70(0,0.300<sup>2</sup>) | 52.16 |\n|  |  |  |  |  | Lap(0, 0.058) | 73.82 |\n|  |  |  |  |  |  | 23.94 |\n|  | Qwen2.5-32B-Instruct | [0-4] | 0.00 | 5.74 | \ud835\udf70(0,0.200<sup>2</sup>) | 37.48 |\n|  |  |  |  |  | Lap(0, 0.043) | 46.13 |\n|  |  |  |  |  |  | 21.54 |", "caption": "Table 3: Impact surface and magnitude of activation approximations on safety-aligned LLMs.", "description": "\ud45c 3\uc740 \uc548\uc804\ud558\uac8c \uc815\ub82c\ub41c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc5d0\uc11c \ud65c\uc131\ud654 \uadfc\uc0ac\uc758 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \uc548\uc804\uc5d0 \ubbfc\uac10\ud55c \uacc4\uce35\uc758 \uc218, \uae30\uc900 PPL(\ud37c\ud50c\ub809\uc11c\ud2f0) \ubc0f ASR(\uacf5\uaca9 \uc131\uacf5\ub960), Wup(\uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \uc804) \ubc0f Wdown(\uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \ud6c4) \uc804\uc758 \ud65c\uc131\ud654 \uc624\ub958 \ud06c\uae30, \uadf8\ub9ac\uace0 \uac01 \uc624\ub958\uc5d0 \ub300\ud55c MVA(\uac00\uc7a5 \ucde8\uc57d\ud55c \uadfc\uc0ac\uac12)\uc5d0\uc11c\uc758 ASR \ubc0f PPL \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ud65c\uc131\ud654 \uadfc\uc0ac\uac00 LLM\uc758 \uc548\uc804\uc131\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uacc4\uce35\ubcc4\ub85c, \uadf8\ub9ac\uace0 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4 \uac04\uc5d0 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.  \uc989, \ud65c\uc131\ud654 \uadfc\uc0ac\uac00 \ubaa8\ub378\uc758 \uc548\uc804\uc131\uc5d0 \uc5b4\ub5a4 \uc601\ud5a5\uc744 \uc8fc\ub294\uc9c0, \uc5b4\ub290 \uc815\ub3c4\uc758 \ud06c\uae30\uc758 \uc601\ud5a5\uc778\uc9c0\ub97c \uacc4\uce35\uacfc \ubaa8\ub378 \ubcc4\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 Safety Assessment and Analysis"}, {"content": "| Model | None | GCG | AutoDAN | DRA |\n|---|---|---|---|---|\n| Llama-2-7B-Chat | 1.3 | 34.5 | 0.5 | 69.2 |\n| + DPO | 0.0 | 29.1 | 0.0 | 38.4 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 3.3 |\n| Llama-2-13B-Chat | 0.0 | 28.0 | 0.0 | 58.4 |\n| + DPO | 0.0 | 20.5 | 0.0 | 19.2 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 1.5 |\n| Llama-3.1-8B-Instruct | 0.2 | 36.0 | 1.0 | 75.3 |\n| + DPO | 0.0 | 34.9 | 0.0 | 58.4 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 0.2 |\n| Phi-3-Mini-4K-Instruct | 0.0 | 56.0 | 84.5 | 91.2 |\n| + DPO | 0.0 | 27.4 | 69.0 | 84.7 |\n| + QuadA | 0.0 | 1.5 | 0.8 | 6.3 |\n| Phi-3.5-Mini-Instruct | 0.8 | 58.0 | 86.5 | 96.7 |\n| + DPO | 0.0 | 31.0 | 72.1 | 88.2 |\n| + QuadA | 0.0 | 4.9 | 2.5 | 10.4 |\n| Mistral-7B-Instruct-v0.3 | 34.6 | 84.3 | 93.0 | 98.5 |\n| + DPO | 0.0 | 20.5 | 64.4 | 86.0 |\n| + QuadA | 0.8 | 1.2 | 1.0 | 2.5 |\n| Mixtral-8x7B-Instruct-v0.1 | 1.2 | 79.5 | 88.5 | 92.0 |\n| + DPO | 0.0 | 12.3 | 36.7 | 52.5 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 0.8 |\n| Zephyr-7B-\u03b2 | 22.3 | 78.6 | 97.5 | 94.8 |\n| + DPO | 0.0 | 19.5 | 70.2 | 88.1 |\n| + QuadA | 0.0 | 2.9 | 0.4 | 7.0 |\n| Qwen2-7B-Instruct | 0.4 | 48.4 | 62.5 | 79.3 |\n| + DPO | 0.0 | 32.5 | 53.0 | 67.9 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 4.5 |\n| Qwen2.5-32B-Instruct | 0.0 | 36.6 | 31.5 | 57.9 |\n| + DPO | 0.0 | 17.9 | 6.8 | 24.1 |\n| + QuadA | 0.0 | 0.0 | 0.0 | 0.2 |", "caption": "Table 4: Attack success rates (ASR) of applying different adaptive prompt-based jailbreak attacks. None means the jailbreak prompt without any suffix.", "description": "\ud45c 4\ub294 \ub2e4\uc591\ud55c \uc801\uc751\ud615 \ud504\ub86c\ud504\ud2b8 \uae30\ubc18 \ud0c8\uc625 \uacf5\uaca9\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'None'\uc740 \uc811\ubbf8\uc0ac\uac00 \uc5c6\ub294 \ud0c8\uc625 \ud504\ub86c\ud504\ud2b8\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc0ac\uc804 \ud6c8\ub828\ub41c \uc548\uc804\ud55c LLMs\uc5d0 \ub300\ud574 GCG, AutoDAN, DRA\uc640 \uac19\uc740 \uc138 \uac00\uc9c0 \uc801\uc751\ud615 \ud0c8\uc625 \uacf5\uaca9\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ud2b9\uc815 LLM \ubaa8\ub378\uc744 \ub098\ud0c0\ub0b4\uba70, \uac01 \uc5f4\uc740 \ud2b9\uc815 \uacf5\uaca9 \ubc29\ubc95 \ub610\ub294 \uacf5\uaca9\uc774 \uc5c6\ub294 \uacbd\uc6b0\uc758 ASR\uc744 \ubc31\ubd84\uc728\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  +DPO \ubc0f +QuadA \uc5f4\uc740 \uac01\uac01 DPO(Direct Preference Optimization) \uae30\ubc18 \uc548\uc804 \uc815\ub82c \ubc0f \uc81c\uc548\ub41c QuadA \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc548\uc804\ud558\uac8c \uc815\ub82c\ub41c \ubaa8\ub378\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 QuadA \ubc29\ubc95\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc989, QuadA\ub294 \uc801\uc751\ud615 \ud0c8\uc625 \uacf5\uaca9\uc5d0 \ub300\ud574 \uc548\uc804\uc131\uc774 \uac15\ud654\ub41c LLM\uc744 \ub9cc\ub4dc\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4 Safety Defense for Activation Approximation"}, {"content": "| Model | NA | LA | mva |\n|---|---|---|---| \n| Llama-2-7B-Chat | 40.76 | 26.15 | **0.00** |\n| Llama-2-13B-Chat | 44.52 | 30.95 | **0.00** |\n| Llama-3.1-8B-Instruct | 61.84 | 45.79 | **0.19** |\n| Phi-3-Mini-4K-Instruct | 56.83 | 41.26 | **0.00** |\n| Phi-3.5-Mini-Instruct | 64.80 | 35.76 | **0.00** |\n| Mistral-7B-Instruct-v0.3 | 71.45 | 52.84 | **0.77** |\n| Mixtral-8x7B-Instruct-v0.1 | 78.04 | 59.37 | **1.05** |\n| Zephyr-7B-\u03b2 | 81.20 | 62.35 | **0.38** |\n| Qwen2-7B-Instruct | 64.36 | 33.17 | **0.00** |\n| Qwen2.5-32B-Instruct | 35.58 | 22.06 | **0.00** |", "caption": "Table 5: Attack success rates (ASR) of applying perturbations with different magnitudes during activation approximation-robust safety alignment.", "description": "\ud45c 5\ub294 \ud65c\uc131\ud654 \uadfc\uc0ac \uac15\uac74\ud55c \uc548\uc804 \uc815\ub82c \uc911\uc5d0 \uc11c\ub85c \ub2e4\ub978 \ud06c\uae30\uc758 \uc12d\ub3d9\uc744 \uc801\uc6a9\ud560 \ub54c \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ud65c\uc131\ud654 \uadfc\uc0ac \uae30\ubc95(\ud65c\uc131\ud654 \ub2e4\ud56d\uc2dd\ud654, \ud65c\uc131\ud654 \ud76c\uc18c\ud654, \ud65c\uc131\ud654 \uc591\uc790\ud654)\uc5d0 \ub300\ud574 10\uac00\uc9c0 \uc548\uc804 \uc815\ub82c\ub41c LLMs\uc5d0\uc11c \uc548\uc804\uc131\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ud3c9\uac00\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  'NA'\ub294 \uc12d\ub3d9\uc774 \uc5c6\ub294 \uacbd\uc6b0, 'LA'\ub294 MVA(\uac00\uc7a5 \ucde8\uc57d\ud55c \uadfc\uc0ac)\ubcf4\ub2e4 10% \ud070 \ud06c\uae30\uc758 \uc12d\ub3d9, \uadf8\ub9ac\uace0 'MVA'\ub294 \uac00\uc7a5 \ucde8\uc57d\ud55c \uadfc\uc0ac\uc5d0 \ud574\ub2f9\ud558\ub294 \uc12d\ub3d9\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub97c \ud1b5\ud574 MVA\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc548\uc804 \uc815\ub82c\uc744 \uc218\ud589\ud558\uba74 \ud65c\uc131\ud654 \uadfc\uc0ac \uc624\ub958\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc800\ud56d\uc131\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub428\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 Ablation Study"}]