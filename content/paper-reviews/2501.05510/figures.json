[{"figure_path": "https://arxiv.org/html/2501.05510/x1.png", "caption": "Figure 1: \nA demonstrative comparison between offline and online video understanding\u00a0[5].\nOffline video understanding focuses on answering questions based on the entirety of a video. In contrast, online video understanding involves posing queries about the context of a video at intermediate points, demanding the ability to trace back past information, perceive ongoing events, and adapt to continuous input.", "description": "\uadf8\ub9bc 1\uc740 \uc624\ud504\ub77c\uc778 \ubc0f \uc628\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574 \ubc29\uc2dd\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc624\ud504\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574\ub294 \uc804\uccb4 \ube44\ub514\uc624\ub97c \uae30\ubc18\uc73c\ub85c \uc9c8\ubb38\uc5d0 \ub2f5\ud558\ub294 \ubc18\uba74, \uc628\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574\ub294 \ube44\ub514\uc624 \uc911\uac04 \uc9c0\uc810\uc5d0\uc11c \ubb38\ub9e5\uc5d0 \ub300\ud55c \uc9c8\ubb38\uc744 \ud558\uace0 \uacfc\uac70 \uc815\ubcf4\ub97c \ucd94\uc801\ud558\uace0, \ud604\uc7ac \uc9c4\ud589 \uc911\uc778 \uc774\ubca4\ud2b8\ub97c \uc778\uc9c0\ud558\uba70, \uc9c0\uc18d\uc801\uc778 \uc785\ub825\uc5d0 \uc801\uc751\ud558\ub294 \ub2a5\ub825\uc744 \ud544\uc694\ub85c \ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.05510/x2.png", "caption": "Figure 2: Examples of each task in OVO-Bench. The 14 tasks are categorized into three different kinds of perceiving modes in online video understanding: Backward Tracing, Real-Time Visual Perception, and Forward Active Responding.", "description": "\uadf8\ub9bc 2\ub294 OVO-Bench\uc758 \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucd1d 14\uac1c\uc758 \uacfc\uc81c\ub294 \ud06c\uac8c \uc138 \uac00\uc9c0 \uc720\ud615\uc758 \uc628\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574 \uc778\uc2dd \ubaa8\ub4dc\ub85c \ubd84\ub958\ub429\ub2c8\ub2e4: \uacfc\uac70 \ucd94\uc801(Backward Tracing), \uc2e4\uc2dc\uac04 \uc2dc\uac01\uc801 \uc778\uc2dd(Real-Time Visual Perception), \uadf8\ub9ac\uace0 \uc804\ud5a5\uc801 \ub2a5\ub3d9\uc801 \uc751\ub2f5(Forward Active Responding). \uac01 \ubaa8\ub4dc\ub294 \ube44\ub514\uc624\uc758 \uacfc\uac70, \ud604\uc7ac, \ubbf8\ub798\uc5d0 \ub300\ud55c \uc9c8\ubb38\uc5d0 \uc5b4\ub5bb\uac8c \ub300\uc751\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\uacfc \ub2f5\ubcc0\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uacfc\uac70 \ucd94\uc801\uc740 \uacfc\uac70 \uc774\ubca4\ud2b8\ub97c \ucd94\uc801\ud558\uc5ec \uc9c8\ubb38\uc5d0 \ub2f5\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uace0, \uc2e4\uc2dc\uac04 \uc2dc\uac01\uc801 \uc778\uc2dd\uc740 \ud604\uc7ac \uc77c\uc5b4\ub098\ub294 \uc77c\uc744 \uc774\ud574\ud558\uace0 \uc989\uc2dc \ubc18\uc751\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uba70, \uc804\ud5a5\uc801 \ub2a5\ub3d9\uc801 \uc751\ub2f5\uc740 \ucda9\ubd84\ud55c \ubbf8\ub798 \uc815\ubcf4\uac00 \uc81c\uacf5\ub420 \ub54c\uae4c\uc9c0 \uc751\ub2f5\uc744 \uc9c0\uc5f0\uc2dc\ud0a4\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uac01 \uacfc\uc81c\ub294 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc720\ud615\uacfc \uc2dc\ub098\ub9ac\uc624\ub97c \ub2e4\ub8e8\uc5b4 \uc628\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574 \ubaa8\ub378\uc758 \ud3ec\uad04\uc801\uc778 \ud3c9\uac00\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3. OVO-Bench"}, {"figure_path": "https://arxiv.org/html/2501.05510/extracted/6119562/sec/image/model0.png", "caption": "Figure 3: \nGeneration pipeline of OVO-Bench.\nWithin public annotations,\ndata is carefully filtered and relevant multiple-choice QAs are auto-generated.\nThe effective system prompt and efficient answer prompt are employed to guide MLLMs toward precise outputs. The Video-LLMs we use to annotate videos are GPT-4o and Gemini-1.5 Pro.", "description": "\uadf8\ub9bc 3\uc740 OVO-Bench\uc758 \ub370\uc774\ud130 \uc0dd\uc131 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 \uacf5\uac1c\ub41c \uc8fc\uc11d \ub370\uc774\ud130\uc5d0\uc11c \uad00\ub828\uc131\uc774 \ub192\uc740 \uac1d\uad00\uc2dd \ubb38\uc81c\uc640 \ub2f5\ubcc0(QAs)\uc744 \uc790\ub3d9\uc73c\ub85c \uc0dd\uc131\ud558\uae30 \uc704\ud574 \ub370\uc774\ud130\ub97c \uc2e0\uc911\ud558\uac8c \ud544\ud130\ub9c1\ud558\uace0 \uc120\ud0dd\ud569\ub2c8\ub2e4.  \uc2dc\uc2a4\ud15c \ud504\ub86c\ud504\ud2b8\uc640 \ud6a8\uc728\uc801\uc778 \uc751\ub2f5 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec  \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(MLLMs)\uc774 \uc815\ud655\ud55c \uacb0\uacfc\ub97c \uc0dd\uc131\ud558\ub3c4\ub85d \uc720\ub3c4\ud569\ub2c8\ub2e4. \ube44\ub514\uc624 \uc8fc\uc11d\uc744 \ub2ec\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \ube44\ub514\uc624-LLM\uc740 GPT-4o\uc640 Gemini-1.5 Pro\uc785\ub2c8\ub2e4.", "section": "3. OVO-Bench"}, {"figure_path": "https://arxiv.org/html/2501.05510/x3.png", "caption": "Figure 4: \nLeft Queries Temporal Distribution in OVO-Bench. Center Linguistic Characteristics of Text Queries. Right Video category distribution of OVO-Bench.", "description": "\uadf8\ub9bc 4\ub294 OVO-Bench \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc138 \uac00\uc9c0 \uce21\uba74\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc740 \uc9c8\ubb38\uc758 \uc2dc\uac04\uc801 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc73c\ub85c, OVO-Bench\uc758 \uc9c8\ubb38\ub4e4\uc774 \ube44\ub514\uc624 \uc804\uccb4 \uc2dc\uac04\uc5d0 \uac78\uccd0 \uace0\ub974\uac8c \ubd84\ud3ec\ub418\uc5b4 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac00\uc6b4\ub370\ub294 \uc9c8\ubb38\uc758 \uc5b8\uc5b4\uc801 \ud2b9\uc9d5\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc6cc\ub4dc \ud074\ub77c\uc6b0\ub4dc\ub85c, \uc790\uc8fc \ub4f1\uc7a5\ud558\ub294 \ub2e8\uc5b4\ub4e4\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud45c\ud604\ud569\ub2c8\ub2e4. \uc774\ub294 \uc9c8\ubb38\uc758 \uc8fc\uc694 \uc8fc\uc81c\uc640 \ubc94\uc704\ub97c \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd\uc740 OVO-Bench \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \ube44\ub514\uc624\uc758 \uce74\ud14c\uace0\ub9ac \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud30c\uc774 \ucc28\ud2b8\ub85c, \uac01 \uce74\ud14c\uace0\ub9ac\uc758 \ube44\ub514\uc624 \uc218\ub97c \ube44\uc728\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub294 OVO-Bench\uc758 \ub370\uc774\ud130\uc14b \ub2e4\uc591\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 \ub370\uc774\ud130\uc14b \ud1b5\uacc4"}, {"figure_path": "https://arxiv.org/html/2501.05510/x4.png", "caption": "Figure 5: \nPerformance comparison between online Video-LLMs and offline Video-LLMs. The figure illustrates the average scores of different models on the OVO-Bench in real-time visual perception tasks.", "description": "\uadf8\ub9bc 5\ub294 \uc628\ub77c\uc778 \ube44\ub514\uc624-LLM\uacfc \uc624\ud504\ub77c\uc778 \ube44\ub514\uc624-LLM\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 OVO-Bench\uc758 \uc2e4\uc2dc\uac04 \uc2dc\uac01\uc801 \uc778\uc2dd \uc791\uc5c5\uc5d0\uc11c \uc5ec\ub7ec \ubaa8\ub378\uc758 \ud3c9\uade0 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc628\ub77c\uc778 \ubc0f \uc624\ud504\ub77c\uc778 \ubaa8\ub378 \ubaa8\ub450\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ube44\uad50\ud558\uc5ec \uc2e4\uc2dc\uac04 \uc2dc\uac01\uc801 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05510/x5.png", "caption": "Figure 6: \nMultiple triggering evaluation pipeline of prompt offline models for online video understanding. Offline Video-LLMs are densely queried along the temporal axes to make independent decisions of whether existing visual content provide enough clues for answering.", "description": "\uadf8\ub9bc 6\uc740 \uc624\ud504\ub77c\uc778 \ube44\ub514\uc624-LLM\uc744 \uc704\ud55c \ub2e4\uc911 \ud2b8\ub9ac\uac70 \ud3c9\uac00 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc628\ub77c\uc778 \ube44\ub514\uc624 \uc774\ud574\ub97c \uc704\ud574, \uc624\ud504\ub77c\uc778 \ube44\ub514\uc624-LLM\uc740 \uc2dc\uac04\uc801 \ucd95\uc744 \ub530\ub77c \ubc00\uc9d1\ub418\uac8c \uc9c8\ubb38\uc744 \ubc1b\uc2b5\ub2c8\ub2e4. \uac01 \uc9c8\ubb38 \uc2dc\uc810\ub9c8\ub2e4 \ubaa8\ub378\uc740 \uae30\uc874\uc758 \uc2dc\uac01\uc801 \ucf58\ud150\uce20\uac00 \ub2f5\ubcc0\uc5d0 \ucda9\ubd84\ud55c \ub2e8\uc11c\ub97c \uc81c\uacf5\ud558\ub294\uc9c0 \uc5ec\ubd80\ub97c \ub3c5\ub9bd\uc801\uc73c\ub85c \ud310\ub2e8\ud569\ub2c8\ub2e4.  \uc989, \ube44\ub514\uc624\uc758 \ud2b9\uc815 \uc2dc\uc810\uc5d0 \uc9c8\ubb38\uc774 \uc8fc\uc5b4\uc9c0\uba74, \ubaa8\ub378\uc740 \uadf8 \uc2dc\uc810\uae4c\uc9c0\uc758 \ube44\ub514\uc624 \ud504\ub808\uc784\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2f5\uc744 \ucc3e\uc544\uc57c \ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacfc\uc815\uc744 \ud1b5\ud574 \ubaa8\ub378\uc758 \uc2e4\uc2dc\uac04 \ucd94\ub860 \ub2a5\ub825\uacfc \uc81c\ud55c\ub41c \uc815\ubcf4\ub9cc\uc73c\ub85c\ub3c4 \uc815\ud655\ud55c \ub2f5\ubcc0\uc744 \ub3c4\ucd9c\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.05510/extracted/6119562/sec/image/supplimentary/222.png", "caption": "Figure 7: \nPrompts used for Online(up) and Offline(down) Models on Forward Active Responding and Response Examples. Despite our vision for online models, existing online models, like videollm-online, are still far from satisfactory, showing limited adaptation ability, and would easily encounter collapse when processing complicated or out-of-training-domain video and queries. Offline models are inclined to perform random guessing when the queries contain words like \u201dis/currently/ongoing\u201d.", "description": "\uadf8\ub9bc 7\uc740 \ub17c\ubb38\uc758 3.2\uc808(Benchmark Construction)\uc5d0 \uc788\ub294 \uadf8\ub9bc\uc73c\ub85c, Forward Active Responding \uc791\uc5c5\uc5d0 \ub300\ud55c \uc628\ub77c\uc778(\uc704\ucabd) \ubc0f \uc624\ud504\ub77c\uc778(\uc544\ub798\ucabd) \ubaa8\ub378\uc5d0 \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8\uc640 \uc751\ub2f5 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc628\ub77c\uc778 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc5f0\uad6c\uc9c4\uc758 \uae30\ub300\uc640 \ub2ec\ub9ac, VideoLLM-online\uacfc \uac19\uc740 \uae30\uc874 \uc628\ub77c\uc778 \ubaa8\ub378\uc740 \ubcf5\uc7a1\ud558\uac70\ub098 \ud6c8\ub828 \ub370\uc774\ud130 \uc601\uc5ed \ubc16\uc758 \ube44\ub514\uc624 \ubc0f \uc9c8\uc758\ub97c \ucc98\ub9ac\ud560 \ub54c \uc801\uc751\ub825\uc774 \ubd80\uc871\ud558\uace0 \uc27d\uac8c \uc2e4\ud328\ud558\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \ubc18\uba74 \uc624\ud504\ub77c\uc778 \ubaa8\ub378\uc740  'is/currently/ongoing' \uacfc \uac19\uc740 \ub2e8\uc5b4\uac00 \uc9c8\ubb38\uc5d0 \ud3ec\ud568\ub420 \uacbd\uc6b0 \ubb34\uc791\uc704\ub85c \ucd94\uce21\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "3. Benchmark Construction"}, {"figure_path": "https://arxiv.org/html/2501.05510/extracted/6119562/sec/image/supplimentary/111.png", "caption": "Figure 8: \nPrompts used for Online(up) and Offline(down) Models on Real-Time Visual Perception and Response Examples.\nThree tasks including [ACR], [OCR], and [ASI] are included as demonstrations. Our benchmarks involve a large ratio of questions, whose answers shift over time, which means that models can hardly figure out the answer by randomly selecting frames from original videos.", "description": "\uadf8\ub9bc 8\uc740 \uc2e4\uc2dc\uac04 \ube44\ub514\uc624 \uc774\ud574\uc5d0 \ub300\ud55c \uc628\ub77c\uc778 \ubc0f \uc624\ud504\ub77c\uc778 \ubaa8\ub378\uc5d0 \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8\uc640 \uc751\ub2f5 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  [ACR](Action Recognition), [OCR](Optical Character Recognition), [ASI](Action Sequential Identification) \uc138 \uac00\uc9c0 \uc791\uc5c5\uc774 \uc2dc\ubc94\uc73c\ub85c \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ubca4\uce58\ub9c8\ud06c\uc5d0\ub294 \uc2dc\uac04\uc5d0 \ub530\ub77c \ub2f5\ubcc0\uc774 \ubc14\ub00c\ub294 \uc9c8\ubb38\uc774 \ub9ce\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4, \ubaa8\ub378\uc774 \uc6d0\ubcf8 \ube44\ub514\uc624\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \ud504\ub808\uc784\uc744 \uc120\ud0dd\ud558\uc5ec \ub2f5\uc744 \ucc3e\ub294 \uac83\uc774 \uc5b4\ub835\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. OVO-Bench"}]