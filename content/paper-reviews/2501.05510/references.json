{"references": [{"fullname_first_author": "Leonard B\u00e4rmann", "paper_title": "Where did I leave my keys?-episodic-memory-based question answering on egocentric videos", "publication_date": "2022-00-00", "reason": "This paper introduces episodic memory into egocentric video question answering, a key aspect of online video understanding."}, {"fullname_first_author": "Fabian Caba Heilbron", "paper_title": "ActivityNet: A large-scale video benchmark for human activity understanding", "publication_date": "2015-00-00", "reason": "This paper is foundational for large-scale video understanding benchmarks, providing a basis for comparison with newer, more advanced benchmarks."}, {"fullname_first_author": "Mu Cai", "paper_title": "TemporalBench: Benchmarking fine-grained temporal understanding for multimodal video models", "publication_date": "2024-00-00", "reason": "This paper is crucial because it provides a benchmark that evaluates temporal understanding, a vital aspect of online video understanding, and helps to highlight the limitations of existing video models."}, {"fullname_first_author": "Joya Chen", "paper_title": "VideoLLM-online: Online video large language model for streaming video", "publication_date": "2024-00-00", "reason": "This paper introduces VideoLLM-online, a pioneering work on online video understanding and a key model for comparison in the current work."}, {"fullname_first_author": "Kristen Grauman", "paper_title": "Ego4D: Around the world in 3,000 hours of egocentric video", "publication_date": "2022-00-00", "reason": "This paper introduces Ego4D, a large-scale egocentric video dataset which is a valuable resource for training and evaluating video understanding models, especially those focused on online scenarios."}]}