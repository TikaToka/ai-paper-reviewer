<table id='2' style='font-size:16px'><tr><td>Method</td><td>Size</td><td>#tokens</td><td>NExT-QA</td></tr><tr><td>LangRepo (Kahatapitiya et al., 2024)</td><td>7B</td><td>3136+</td><td>54.6</td></tr><tr><td>LangRepo (Kahatapitiya et al., 2024)</td><td>12B</td><td>3136+</td><td>60.9</td></tr><tr><td>Tarsier (Wang et al., 2024a)</td><td>7B</td><td>4608+</td><td>71.6</td></tr><tr><td>LLoVi (Zhang et al., 2024a)</td><td>157B</td><td>1000s</td><td>67.7</td></tr><tr><td>IG- VLM (Kim et al., 2024)</td><td>34B</td><td>1536+</td><td>70.9</td></tr><tr><td>VideoAgent (Wang et al., 2024b)</td><td>GPT-4</td><td>2091+</td><td>71.3</td></tr><tr><td>VideoTree (Wang et al., 2024c)</td><td>GPT-4</td><td>3978+</td><td>73.5</td></tr><tr><td>Tarsier (Wang et al., 2024a)</td><td>34B</td><td>4608+</td><td>79.2</td></tr><tr><td>BLIP-3-Video</td><td>4B</td><td>32</td><td>76.4</td></tr><tr><td>BLIP-3-Video</td><td>4B</td><td>128</td><td>77.1</td></tr></table>