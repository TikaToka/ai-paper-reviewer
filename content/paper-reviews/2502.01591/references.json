{"references": [{"fullname_first_author": "D. Hafner", "paper_title": "Mastering diverse domains through world models", "publication_date": "2023-01-04", "reason": "This paper introduces DreamerV3, a state-of-the-art model-based reinforcement learning agent that served as a significant baseline and inspiration for the current work."}, {"fullname_first_author": "V. Micheli", "paper_title": "Transformers are sample-efficient world models", "publication_date": "2022-09-00", "reason": "This paper introduced the use of transformer world models in model-based reinforcement learning, a core component of the approach presented in this paper."}, {"fullname_first_author": "V. Micheli", "paper_title": "Efficient world models with context-aware tokenization", "publication_date": "2024-06-19", "reason": "This paper builds upon the prior work by introducing improvements to the tokenizer, a critical component also improved upon in this paper."}, {"fullname_first_author": "R. S. Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "This is a foundational textbook in reinforcement learning which provided the theoretical background for much of the work."}, {"fullname_first_author": "J. Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-07-06", "reason": "This paper introduced the Proximal Policy Optimization (PPO) algorithm, the core RL algorithm used in this paper."}]}