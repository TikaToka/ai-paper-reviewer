[{"figure_path": "https://arxiv.org/html/2412.19412/x4.png", "caption": "Figure 1: Overall Image Matching Accuracy and Efficiency on Six Datasets of Real Cross-modal Image Pairs. AUC of the pose error (@10\u2218superscript1010^{\\circ}10 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPT) or reprojection error (@10101010px) is used for accuracy evaluation, while Pairs Per Second is used for efficiency test. Left: AUCs on each dataset of representative methods are reported. Right: average performance is summarized, wherein different colors indicate matching pipelines of sparse, semi-dense and dense matching, while our MINIMA is marked as \u2605\u2605\\bigstar\u2605. Only with synthetic multimodal data created by our data engine, MINIMA can generalize to real cross-modal scenes with large improvements.", "description": "\uadf8\ub9bc 1\uc740 \uc2e4\uc81c \ub2e4\uc911 \ubaa8\ub4dc \uc774\ubbf8\uc9c0 \uc30d\uc758 6\uac1c \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \uc218\ud589\ub41c \uc804\uccb4 \uc774\ubbf8\uc9c0 \ub9e4\uce6d \uc815\ud655\ub3c4\uc640 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc815\ud655\ub3c4 \ud3c9\uac00\uc5d0\ub294 \uc790\uc138 \uc624\ucc28(10\ub3c4) \ub610\ub294 \uc7ac\ud22c\uc601 \uc624\ucc28(10\ud53d\uc140)\uc758 AUC\uac00 \uc0ac\uc6a9\ub418\uace0, \ud6a8\uc728\uc131 \ud14c\uc2a4\ud2b8\uc5d0\ub294 \ucd08\ub2f9 \uc30d(Pairs Per Second)\uc774 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ub300\ud45c\uc801\uc778 \ubc29\ubc95\ub4e4\uc758 \uac01 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud55c AUC\ub97c \ubcf4\uc5ec\uc8fc\uace0, \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 \ub2e4\uc591\ud55c \uc0c9\uc0c1\uc73c\ub85c \uc2a4\ud30c\uc2a4, \uc138\ubbf8-\ub374\uc2a4, \ub374\uc2a4 \ub9e4\uce6d \ud30c\uc774\ud504\ub77c\uc778\uc744 \uad6c\ubd84\ud558\uc5ec \ud3c9\uade0 \uc131\ub2a5\uc744 \uc694\uc57d\ud569\ub2c8\ub2e4.  MINIMA\ub294 \ubcc4\ud45c(\u2605\u2605)\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ub370\uc774\ud130 \uc5d4\uc9c4\uc73c\ub85c \uc0dd\uc131\ub41c \ud569\uc131 \ub2e4\uc911 \ubaa8\ub4dc \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud574\uc57c\ub9cc MINIMA\ub294 \uc2e4\uc81c \ub2e4\uc911 \ubaa8\ub4dc \uc7a5\uba74\uc5d0 \uc77c\ubc18\ud654\ud558\uc5ec \uc131\ub2a5\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.19412/x5.png", "caption": "Figure 2: Qualitative Results on Real Cross-modal Image Pairs. Our methods MINIMALG (sparse) and MINIMARoMa (dense) are compared with the sparse matching pipeline ReDFeat\u00a0[7] and OmniGlue\u00a0[20], and semi-dense matcher XoFTR\u00a0[43]. ReDFeat and XoFTR are cross-modal methods, and OmniGlue is known for its generalization ability. Matches generated by each method are drawn, where the red lines indicate epipolar error (pose) or projection error (homography) beyond 5\u00d710\u221245superscript1045\\times 10^{-4}5 \u00d7 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT or 3333 pixels. Details are recorded in the top-left of each image pair, including the geometric errors created by default RANSAC estimation and the (# correct match / # match).", "description": "\uadf8\ub9bc 2\ub294 \uc2e4\uc81c \ub2e4\uc911 \ubaa8\ub4dc \uc774\ubbf8\uc9c0 \uc30d\uc5d0 \ub300\ud55c \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc81c\uc2dc\ub41c \ubc29\ubc95\uc778 MINIMALG(\ud76c\uc18c)\uc640 MINIMARoMa(\uc870\ubc00)\uc744 \ud76c\uc18c \ub9e4\uce6d \ud30c\uc774\ud504\ub77c\uc778\uc778 ReDFeat [7]\uc640 OmniGlue [20], \uadf8\ub9ac\uace0 \ubc18\uc870\ubc00 \ub9e4\ucc98\uc778 XoFTR [43]\uacfc \ube44\uad50\ud569\ub2c8\ub2e4. ReDFeat\uc640 XoFTR\uc740 \ub2e4\uc911 \ubaa8\ub4dc \ubc29\ubc95\uc774\uace0, OmniGlue\ub294 \uc77c\ubc18\ud654 \ub2a5\ub825\uc73c\ub85c \uc54c\ub824\uc838 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\ub41c \ub9e4\uce6d\uc774 \ud45c\uc2dc\ub418\uba70, \ube68\uac04\uc0c9 \uc120\uc740 5\u00d710\u207b\u2074 \ub610\ub294 3\ud53d\uc140\uc744 \ucd08\uacfc\ud558\ub294 \uc5d0\ud53c\ud3f4\ub77c \uc624\ucc28(\uc790\uc138) \ub610\ub294 \ud22c\uc601 \uc624\ucc28(\ud638\ubaa8\uadf8\ub798\ud53c)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \uc774\ubbf8\uc9c0 \uc30d\uc758 \uc88c\uc0c1\ub2e8\uc5d0\ub294 \uae30\ubcf8 RANSAC \ucd94\uc815\uc73c\ub85c \uc0dd\uc131\ub41c \uae30\ud558 \uc624\ucc28\uc640 \uc815\ud655\ud55c \ub9e4\uce6d \uc218\ub97c \ud3ec\ud568\ud55c \uc138\ubd80 \uc815\ubcf4\uac00 \uae30\ub85d\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub2ec\ub9ac\ud2f0(\uc608: RGB-\uc801\uc678\uc120, RGB-\uae4a\uc774)\ub97c \uac00\uc9c4 \uc774\ubbf8\uc9c0 \uc30d\uc758 \ub9e4\uce6d \uc815\ud655\ub3c4\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uace0, \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \ub2e4\uc911 \ubaa8\ub4dc \uc774\ubbf8\uc9c0 \ub9e4\uce6d\uc5d0\uc11c\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.19412/x6.png", "caption": "Figure 3: Overview of the proposed MINIMA pipeline: a single model for any cross-modal matching tasks. Wherein the Data Engine is to generate a large multimodal image matching dataset, which supports the training of matching models to obtain cross-modal ability.", "description": "\uadf8\ub9bc 3\uc740 \uc81c\uc548\ub41c MINIMA \ud30c\uc774\ud504\ub77c\uc778\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub4e0 \uc885\ub958\uc758 \ud06c\ub85c\uc2a4-\ubaa8\ub2ec \ub9e4\uce6d \uc791\uc5c5\uc5d0 \ub300\ud574 \ub2e8\uc77c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4. \ub370\uc774\ud130 \uc5d4\uc9c4\uc740 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0\ub97c \ud3ec\ud568\ud558\ub294 \ub300\uaddc\ubaa8\uc758 \uc774\ubbf8\uc9c0 \ub9e4\uce6d \ub370\uc774\ud130\uc14b\uc744 \uc0dd\uc131\ud558\uba70, \uc774\ub294 \ud06c\ub85c\uc2a4-\ubaa8\ub2ec \uc131\ub2a5\uc744 \ud655\ubcf4\ud558\uae30 \uc704\ud574 \ub9e4\uce6d \ubaa8\ub378\uc758 \ud559\uc2b5\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \ub370\uc774\ud130 \uc5d4\uc9c4\uc740 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0\ub97c \uac00\uc9c4 \uc774\ubbf8\uc9c0 \uc30d\uc744 \uc0dd\uc131\ud558\uace0, \uc0dd\uc131\ub41c \ub370\uc774\ud130\uc758 \uc815\ud655\uc131\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \uc815\ud655\ud55c \ub9e4\uce6d \ub808\uc774\ube14\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \ub2e8\uc77c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud568\uc73c\ub85c\uc368 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0 \uc870\ud569\uc5d0 \ub300\ud55c \uc720\uc5f0\uc131\uacfc \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3. Cross-Modal Generation with Data Engine"}, {"figure_path": "https://arxiv.org/html/2412.19412/x7.png", "caption": "Figure 4:  Pixel Intensity Statistic for Generated Modalities. The statistic differences reveal the excellent ability of our data engine to generate modality gaps.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0dd\uc131\ub41c \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0(\uc801\uc678\uc120, \uae4a\uc774, \uc774\ubca4\ud2b8, \ub178\uba40, \ud398\uc778\ud2b8, \uc2a4\ucf00\uce58)\uc5d0 \ub300\ud55c \ud53d\uc140 \uac15\ub3c4 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub2ec\ub9ac\ud2f0\uc758 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc744 \ud1b5\ud574 \ub370\uc774\ud130 \uc5d4\uc9c4\uc774 \uc2e4\uc81c \ubaa8\ub2ec\ub9ac\ud2f0 \uac04\uc758 \ucc28\uc774\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uc0dd\uc131\ub41c \ub370\uc774\ud130\uac00 \uc2e4\uc81c \ub370\uc774\ud130\ucc98\ub7fc \ub2e4\uc591\ud55c \ud2b9\uc9d5\uc744 \uac00\uc9c0\uace0 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0 \ub9e4\uce6d \ubaa8\ub378 \ud559\uc2b5\uc5d0 \ub3c4\uc6c0\uc774 \ub420 \uc218 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "3. Cross-Modal Generation with Data Engine"}, {"figure_path": "https://arxiv.org/html/2412.19412/x8.png", "caption": "Figure 5: Training Loss and AUC@5\u2218superscript55^{\\circ}5 start_POSTSUPERSCRIPT \u2218 end_POSTSUPERSCRIPT w.r.t. Epochs, using Scratch Training and Fine-tuning. The basic model is LoFTR. The test set is our synthetic RGB-IR of MD-syn.", "description": "\uadf8\ub9bc 5\ub294 LoFTR \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c, MD-syn \ub370\uc774\ud130\uc14b\uc758 \ud569\uc131 RGB-IR \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2a4\ud06c\ub798\uce58 \ubc29\uc2dd\uacfc \ud30c\uc778\ud29c\ub2dd \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5\ud588\uc744 \ub54c, \uc5d0\ud3ed\uc5d0 \ub530\ub978 \ud559\uc2b5 \uc190\uc2e4\uacfc AUC@5\u00b0\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2a4\ud06c\ub798\uce58 \ubc29\uc2dd\uc740 \ucc98\uc74c\ubd80\ud130 \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \ubc29\uc2dd\uc774\uace0, \ud30c\uc778\ud29c\ub2dd \ubc29\uc2dd\uc740 \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c \ucd94\uac00 \ud559\uc2b5\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub450 \uac00\uc9c0 \ud559\uc2b5 \ubc29\uc2dd\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \ud30c\uc778\ud29c\ub2dd \ubc29\uc2dd\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.19412/x9.png", "caption": "Figure A1: Visualization Results of Infrared generation on MSRS. The first two columns are real RGB and Infrared images.", "description": "\uc774 \uadf8\ub9bc\uc740 MSRS \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc801\uc678\uc120 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc55e\uc758 \ub450 \uc5f4\uc740 \uc2e4\uc81c RGB \uc774\ubbf8\uc9c0\uc640 \uc801\uc678\uc120 \uc774\ubbf8\uc9c0\uc774\uace0, \ub098\uba38\uc9c0 \uc5f4\uc740 \uac01\uac01 XOFTR, CPSTN \ubc0f \uc81c\uc548\ub41c \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\ub41c \uc801\uc678\uc120 \uc774\ubbf8\uc9c0\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uc2e4\uc81c \uc801\uc678\uc120 \uc774\ubbf8\uc9c0\uc640 \uc720\uc0ac\ud55c \uc801\uc678\uc120 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\ub294 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "A.1. Quality Verification of Modality Generation"}]