{"references": [{"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A frontier large vision-language model with versatile abilities", "publication_date": "2023-08-12", "reason": "This paper introduces a large vision-language model that is relevant to Mobile-Agent-V's multimodal capabilities."}, {"fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent-v2: Mobile device operation assistant with effective navigation via multi-agent collaboration", "publication_date": "2024-06-01", "reason": "This paper is a direct predecessor to the current work, improving upon previous mobile automation frameworks."}, {"fullname_first_author": "Zhao Yang", "paper_title": "AppAgent: Multimodal agents as smartphone users", "publication_date": "2023-12-13", "reason": "This paper introduces a baseline framework for comparison, which is essential for evaluating the improvements of Mobile-Agent-V."}, {"fullname_first_author": "Junyang Wang", "paper_title": "Mobile-agent: Autonomous multi-modal mobile device agent with visual perception", "publication_date": "2024-01-16", "reason": "This paper provides another important baseline and framework for comparison, establishing a clear progression of work."}, {"fullname_first_author": "Quanfeng Lu", "paper_title": "GUI odyssey: A comprehensive dataset for cross-app GUI navigation on mobile devices", "publication_date": "2024-06-08", "reason": "This paper addresses the challenge of scalability in mobile automation, providing relevant data for training and development."}]}