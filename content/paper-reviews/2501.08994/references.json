{"references": [{"fullname_first_author": "P. Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper is foundational for the use of transformers in high-resolution image synthesis, a key technique leveraged in the RepVideo model."}, {"fullname_first_author": "A. Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This paper introduces a groundbreaking approach to zero-shot text-to-image generation, which is highly relevant to the task of text-to-video generation addressed by RepVideo."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This work lays the theoretical foundation for denoising diffusion models, a core component of many modern video generation techniques, including those evaluated in the RepVideo paper."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper significantly advances diffusion models by enabling high-resolution image synthesis using a latent diffusion approach, improving upon the capabilities of earlier diffusion models and informing the architecture of RepVideo."}, {"fullname_first_author": "U. Singer", "paper_title": "Make-A-Video: Text-to-video generation without text-video data", "publication_date": "2022-00-00", "reason": "This paper is a pioneering work in text-to-video generation, which directly inspires the RepVideo approach by demonstrating the feasibility and potential of generating high-quality videos from text alone, without requiring paired text-video data for training."}]}