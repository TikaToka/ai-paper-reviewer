[{"figure_path": "https://arxiv.org/html/2501.08994/x1.png", "caption": "Figure 1: The examples generated by RepVideo. RepVideo effectively generates diverse videos with enhanced temporal coherence and fine-grained spatial details.", "description": "RepVideo \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc608\uc2dc\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4. RepVideo\ub294 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc774 \ud5a5\uc0c1\ub418\uace0 \uc138\ubc00\ud55c \uacf5\uac04\uc801 \ub514\ud14c\uc77c\uae4c\uc9c0 \ud45c\ud604\ud558\ub294 \uace0\ud488\uc9c8\uc758 \ub2e4\uc591\ud55c \ube44\ub514\uc624\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \ub2ec, \ud638\ub791\uc774, \ud48d\uacbd, \ud558\ud2b8, \uadf8\ub9ac\uace0 \uc0ac\ub78c \ub4f1 \ub2e4\uc591\ud55c \uc8fc\uc81c\uc758 \ube44\ub514\uc624\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, \uac01 \ube44\ub514\uc624\ub294 \ubd80\ub4dc\ub7ec\uc6b4 \uc6c0\uc9c1\uc784\uacfc \uc0ac\uc2e4\uc801\uc778 \ubb18\uc0ac\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "I. INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2501.08994/x2.png", "caption": "Figure 2: The architecture of recent transformer-based video diffusion models. These methods typically consist of three core components: a 3D VAE, the text encoder, and a transformer network.", "description": "\uadf8\ub9bc 2\ub294 \ucd5c\uadfc \ubcc0\ud658\uae30 \uae30\ubc18 \ube44\ub514\uc624 \ud655\uc0b0 \ubaa8\ub378\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubaa8\ub378\uc740 \uc77c\ubc18\uc801\uc73c\ub85c \uc138 \uac00\uc9c0 \ud575\uc2ec \uad6c\uc131 \uc694\uc18c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. 3D VAE\ub294 \uacf5\uac04 \ubc0f \uc2dc\uac04 \ucc28\uc6d0\uc744 \ub530\ub77c \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \uc555\ucd95\ud558\uc5ec \uace0\ud574\uc0c1\ub3c4 \ube44\ub514\uc624\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uace0 GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \uc904\uc77c \uc218 \uc788\ub294 \ucef4\ud329\ud2b8\ud55c \uc7a0\uc7ac \ud45c\ud604\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8 \uc778\ucf54\ub354\ub294 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \ucc98\ub9ac\ud558\uc5ec \ube44\ub514\uc624 \uc0dd\uc131 \uacfc\uc815 \uc804\uccb4\ub97c \uc548\ub0b4\ud558\ub294 \uc758\ubbf8\ub97c \ud3ec\ucc29\ud558\ub294 \uc784\ubca0\ub529 \uc9d1\ud569\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4. \ube44\ub514\uc624\uc758 \uc7a0\uc7ac \ud45c\ud604\uc740 \ud1a0\ud070 \uc2dc\ud000\uc2a4\ub85c \ud3c9\ud3c9\ud558\uac8c \ucc98\ub9ac\ub418\uba70 \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529 \ud1a0\ud070\uacfc \ud568\uaed8 \ubcc0\ud658\uae30 \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4. \ubcc0\ud658\uae30\uc758 \uac15\ub825\ud55c \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc744 \ud65c\uc6a9\ud558\uc5ec \ube44\ub514\uc624 \uc2dc\ud000\uc2a4 \ub0b4\uc758 \ubcf5\uc7a1\ud55c \uacf5\uac04 \ubc0f \uc2dc\uac04\uc801 \uad00\uacc4\ub97c \ud559\uc2b5\ud558\uace0, \uc0dd\uc131\ub41c \ud504\ub808\uc784\uc774 \uc77c\uad00\ub418\uace0 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc758 \uc758\ubbf8 \uc815\ubcf4\uc640 \uc815\ub82c\ub418\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uad6c\uc131 \uc694\uc18c\ub97c \ud1b5\ud569\ud568\uc73c\ub85c\uc368, \ubcc0\ud658\uae30 \uae30\ubc18 \ud655\uc0b0 \ubaa8\ub378\uc740 \uace0\ud574\uc0c1\ub3c4, \uc7a5\uc2dc\uac04 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uacfc \uc758\ubbf8\uc801 \uc815\ub82c\uc774 \ubaa8\ub450 \uc6b0\uc218\ud55c \ud2b9\uc9d5\uc785\ub2c8\ub2e4.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.08994/x3.png", "caption": "Figure 3: The visualization of the attention distribution of each frame\u2019s token across the entire token sequence. The results highlight significant variations in attention distributions across layers, with deeper layers focusing more on tokens from the same frame and exhibiting weaker attention to tokens from other frames.", "description": "\uadf8\ub9bc 3\uc740 \ubcc0\ud658\uae30 \uc5ec\ub7ec \uacc4\uce35\uc5d0 \uac78\uccd0 \uc804\uccb4 \ud1a0\ud070 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uac01 \ud504\ub808\uc784\uc758 \ud1a0\ud070\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158 \ubd84\ud3ec\ub97c \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. \uacb0\uacfc\ub294 \uacc4\uce35 \uac04 \uc5b4\ud150\uc158 \ubd84\ud3ec\uc758 \uc0c1\ub2f9\ud55c \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae4a\uc740 \uacc4\uce35\uc77c\uc218\ub85d \ub3d9\uc77c\ud55c \ud504\ub808\uc784\uc758 \ud1a0\ud070\uc5d0 \ub354 \uc9d1\uc911\ud558\uace0 \ub2e4\ub978 \ud504\ub808\uc784\uc758 \ud1a0\ud070\uc5d0\ub294 \uc5b4\ud150\uc158\uc774 \uc57d\ud574\uc9d1\ub2c8\ub2e4. \uc774\ub294 \uae4a\uc740 \uacc4\uce35\uc774 \uc774\uc804 \uacc4\uce35\ubcf4\ub2e4 \ub354\uc6b1 \ud2b9\uc815 \ud504\ub808\uc784\uc758 \uc815\ubcf4\ub97c \uac15\uc870\ud568\uc73c\ub85c\uc368 \ud504\ub808\uc784 \uac04\uc758 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ub370 \uae30\uc5ec\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc989, \uc0c1\uc704 \uacc4\uce35\uc740 \uc804\uccb4\uc801\uc778 \ub9e5\ub77d\uc744 \ud30c\uc545\ud558\uace0 \ud558\uc704 \uacc4\uce35\uc740 \uc138\ubd80\uc801\uc778 \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\ub294 \uc5ed\ud560\uc744 \ub2f4\ub2f9\ud569\ub2c8\ub2e4. \ub610\ud55c, \uac01 \uacc4\uce35\uc740 \uc11c\ub85c \ub2e4\ub978 \ud2b9\uc9d5 \uacf5\uac04\uc5d0 \uc9d1\uc911\ud558\uc5ec \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \ud3ec\ucc29\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.08994/x4.png", "caption": "Figure 4: The visualization of attention maps across transformer layers. Each layer attends to distinct regions, capturing diverse spatial features. However, the lack of coordination across layers results in fragmented feature representations, weakening the model\u2019s ability to establish coherent spatial semantics within individual frames.", "description": "\uadf8\ub9bc 4\ub294 \ubcc0\uc555\uae30 \uc5ec\ub7ec \uacc4\uce35\uc5d0 \uac78\uccd0 \uc5b4\ud150\uc158 \ub9f5\uc744 \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \uacc4\uce35\uc740 \uc11c\ub85c \ub2e4\ub978 \uc601\uc5ed\uc5d0 \uc9d1\uc911\ud558\uc5ec \ub2e4\uc591\ud55c \uacf5\uac04\uc801 \ud2b9\uc9d5\uc744 \ud3ec\ucc29\ud558\uc9c0\ub9cc, \uacc4\uce35 \uac04\uc758 \uc870\uc815 \ubd80\uc871\uc73c\ub85c \uc778\ud574 \ud2b9\uc9d5 \ud45c\ud604\uc774 \ub2e8\ud3b8\ud654\ub418\uc5b4 \uac1c\ubcc4 \ud504\ub808\uc784 \ub0b4\uc5d0\uc11c \uc77c\uad00\ub41c \uacf5\uac04\uc801 \uc758\ubbf8\ub97c \ud655\ub9bd\ud558\ub294 \ubaa8\ub378\uc758 \ub2a5\ub825\uc774 \uc57d\ud654\ub429\ub2c8\ub2e4.  \uc989, \uac01 \uacc4\uce35\uc774 \uc774\ubbf8\uc9c0\uc758 \ub2e4\ub978 \ubd80\ubd84\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uc5b4 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uc9c0\ub9cc, \uc11c\ub85c \uc815\ubcf4\ub97c \uacf5\uc720\ud558\uace0 \uc870\uc728\ud558\ub294 \uacfc\uc815\uc774 \ubd80\uc871\ud558\uc5ec \uc804\uccb4 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc77c\uad00\ub41c \uc774\ud574\uac00 \uc5b4\ub824\uc6cc\uc9c0\ub294 \ud604\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ube44\ub514\uc624 \uc0dd\uc131\uc758 \uacf5\uac04\uc801 \uc77c\uad00\uc131\uc5d0 \ubd80\uc815\uc801\uc778 \uc601\ud5a5\uc744 \ubbf8\uce69\ub2c8\ub2e4.", "section": "III. \ubc29\ubc95\ub860"}, {"figure_path": "https://arxiv.org/html/2501.08994/x5.png", "caption": "Figure 5: The average similarity between adjacent frame features across diffusion layers and denoising steps. The similarity decreases as layer depth increases for a given denoising step, indicating greater differentiation in deeper layers. Additionally, similarity between adjacent frames declines as the denoising process progresses.", "description": "\uadf8\ub9bc 5\ub294 \ub514\ud4e8\uc804 \ub808\uc774\uc5b4\uc640 \ub514\ub178\uc774\uc9d5 \ub2e8\uacc4\uc5d0 \uac78\uccd0 \uc778\uc811\ud55c \ud504\ub808\uc784 \ud2b9\uc9d5\ub4e4 \uac04\uc758 \ud3c9\uade0 \uc720\uc0ac\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\uc815 \ub514\ub178\uc774\uc9d5 \ub2e8\uacc4\uc5d0\uc11c \ub808\uc774\uc5b4\uc758 \uae4a\uc774\uac00 \uae4a\uc5b4\uc9c8\uc218\ub85d \uc720\uc0ac\ub3c4\uac00 \uac10\uc18c\ud558\ub294\ub370, \uc774\ub294 \ub354 \uae4a\uc740 \ub808\uc774\uc5b4\uc5d0\uc11c \ud2b9\uc9d5\ub4e4\uc774 \ub354\uc6b1 \ucc28\ubcc4\ud654\ub428\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub610\ud55c, \ub514\ub178\uc774\uc9d5 \uacfc\uc815\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \uc778\uc811 \ud504\ub808\uc784 \uac04\uc758 \uc720\uc0ac\ub3c4\ub294 \uac10\uc18c\ud558\ub294\ub370, \uc774\ub294 \ub514\ud4e8\uc804 \ubaa8\ub378\uc774 \ub514\ub178\uc774\uc9d5 \uacfc\uc815\uc744 \ud1b5\ud574 \ud504\ub808\uc784 \ud2b9\uc9d5\ub4e4\uc744 \ub354\uc6b1 \ub2e4\uc591\ud654\uc2dc\ud0a4\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ud604\uc0c1\uc740 \uc2ec\uce35\uc801\uc778 \ub808\uc774\uc5b4\uc5d0\uc11c \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc774 \uac10\uc18c\ud558\uace0, \ube44\ub514\uc624 \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \uc800\ud574\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.08994/x6.png", "caption": "Figure 6: The comparison of the original feature maps from a standard transformer layer with those obtained after aggregation in the Feature Cache Module. The aggregated features demonstrate more comprehensive semantic information and clearer structural details.", "description": "\uc774 \uadf8\ub9bc\uc740 \ud45c\uc900 \ubcc0\uc555\uae30 \uacc4\uce35\uc758 \uc6d0\ub798 \ud2b9\uc9d5 \ub9f5\uacfc \ud2b9\uc9d5 \uce90\uc2dc \ubaa8\ub4c8\uc5d0\uc11c \uc9d1\uacc4\ub41c \ud6c4 \uc5bb\uc740 \ud2b9\uc9d5 \ub9f5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc9d1\uacc4\ub41c \ud2b9\uc9d5 \ub9f5\uc740 \ub354\uc6b1 \ud3ec\uad04\uc801\uc778 \uc758\ubbf8 \uc815\ubcf4\uc640 \ub354 \uba85\ud655\ud55c \uad6c\uc870\uc801 \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uc5ec\ub7ec \ubcc0\uc555\uae30 \uacc4\uce35\uc758 \ud2b9\uc9d5\uc744 \ud1b5\ud569\ud558\uc5ec \ub354\uc6b1 \ud48d\ubd80\ud558\uace0 \uc548\uc815\uc801\uc778 \uc758\ubbf8 \uc815\ubcf4\ub97c \uc5bb\uace0,  \ud654\uc9c8 \uac1c\uc120 \ubc0f \uc2dc\uac04\uc801 \uc77c\uad00\uc131 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "III. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.08994/x7.png", "caption": "Figure 7: The comparison of adjacent frame similarity between original and aggregated features. The aggregated features from the Feature Cache Module exhibit higher similarity between adjacent frames compared to the original transformer layers, indicating improved temporal coherence.", "description": "\uadf8\ub9bc 7\uc740 \ubcc0\uc555\uae30 \uc5ec\ub7ec \uacc4\uce35\uc758 \ud2b9\uc9d5\uc744 \uc9d1\uacc4\ud558\ub294 \uae30\ub2a5\uc744 \uac00\uc9c4 \ud2b9\uc9d5 \uce90\uc2dc \ubaa8\ub4c8\uc744 \ud1b5\ud574 \uc5bb\uc740 \uc9d1\uacc4\ub41c \ud2b9\uc9d5\uacfc \uc6d0\ub798 \ubcc0\uc555\uae30 \uacc4\uce35\uc5d0\uc11c \uc5bb\uc740 \uc6d0\ub798 \ud2b9\uc9d5 \uac04\uc758 \uc778\uc811 \ud504\ub808\uc784 \uc720\uc0ac\uc131 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc9d1\uacc4\ub41c \ud2b9\uc9d5\uc740 \uc6d0\ub798 \ubcc0\uc555\uae30 \uacc4\uce35\uc5d0 \ube44\ud574 \uc778\uc811 \ud504\ub808\uc784 \uac04\uc758 \uc720\uc0ac\uc131\uc774 \ub354 \ub192\uc544 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ud2b9\uc9d5 \uce90\uc2dc \ubaa8\ub4c8\uc774 \uc5ec\ub7ec \uacc4\uce35\uc5d0\uc11c \ud2b9\uc9d5\uc744 \ud1b5\ud569\ud558\uc5ec \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \ub192\uc774\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  \uc989, \uc778\uc811\ud55c \ud504\ub808\uc784\ub4e4\uc758 \uc2dc\uac01\uc801 \ucc28\uc774\uac00 \uac10\uc18c\ud558\uc5ec \ube44\ub514\uc624\uac00 \ub354 \ub9e4\ub044\ub7fd\uac8c \ubcf4\uc774\ub294 \ud6a8\uacfc\uac00 \uc788\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.", "section": "III. \ubc29\ubc95\ub860"}, {"figure_path": "https://arxiv.org/html/2501.08994/x8.png", "caption": "Figure 8: The architecture of the enhanced cross-layer\nrepresentation framework.", "description": "\uadf8\ub9bc 8\uc740 RepVideo\uc758 \ud5a5\uc0c1\ub41c \uacc4\uce35 \uac04 \ud45c\ud604 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ube14\ub85d\uc5d0 Feature Cache Module\uacfc Gating Mechanism\uc744 \ucd94\uac00\ud558\uc5ec \uc774\uc804 \uacc4\uce35\ub4e4\uc758 \ud2b9\uc9d5\ub4e4\uc744 \ud65c\uc6a9\ud569\ub2c8\ub2e4. Feature Cache Module\uc740 \uc5ec\ub7ec \uacc4\uce35\uc758 \ucd9c\ub825 \ud1a0\ud070 \uc2dc\ud000\uc2a4\ub97c \uc800\uc7a5\ud558\uace0, \uc774\ub4e4\uc758 \ud3c9\uade0\uc744 \uacc4\uc0b0\ud558\uc5ec \uac15\ud654\ub41c \ud2b9\uc9d5\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. Gating Mechanism\uc740 \uc6d0\ubcf8 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uc785\ub825\uacfc \uac15\ud654\ub41c \ud2b9\uc9d5\uc744 \uacb0\ud569\ud558\uc5ec \uac01 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uacc4\uce35\uc5d0 \ud5a5\uc0c1\ub41c \uc785\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 RepVideo\ub294 \uacf5\uac04\uc801 \uc138\ubd80 \uc815\ubcf4\ub97c \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \ud504\ub808\uc784 \uac04 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uc5ec \ub354\uc6b1 \ud5a5\uc0c1\ub41c \uc2dc\uacc4\uc5f4 \uc77c\uad00\uc131\uacfc \uacf5\uac04\uc801 \ud488\uc9c8\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "III. \ubc29\ubc95\ub860"}, {"figure_path": "https://arxiv.org/html/2501.08994/x9.png", "caption": "Figure 9: The qualitative comparison between our method and the baseline CogVideoX-2B\u00a0[31]. The first row shows results from the baseline CogVideoX-2B\u00a0[31], while the second row presents the results generated by RepVideo, demonstrating significant improvements in quality and coherence.", "description": "\uadf8\ub9bc 9\ub294 \uc81c\uc548\ub41c RepVideo \ubaa8\ub378\uacfc \uae30\uc900 \ubaa8\ub378\uc778 CogVideoX-2B [31]\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \uacb0\uacfc\ub97c \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  CogVideoX-2B [31] \ubaa8\ub378\uc758 \uacb0\uacfc\ub294 \uc704\ucabd \ud589\uc5d0, RepVideo \ubaa8\ub378\uc758 \uacb0\uacfc\ub294 \uc544\ub798\ucabd \ud589\uc5d0 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub3d9\uc77c\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uc77c\ubd80 \ud504\ub808\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. RepVideo\uac00 \ube44\ub514\uc624\uc758 \uc9c8\uacfc \uc77c\uad00\uc131 \uba74\uc5d0\uc11c \uc0c1\ub2f9\ud55c \uac1c\uc120\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574 \ube44\ub514\uc624 \uc2dc\ud000\uc2a4 \uc804\uccb4\ub97c \ubcf4\uc5ec\uc8fc\uc9c0\ub294 \uc54a\uace0,  \uba87\uba87 \ub300\ud45c\uc801\uc778 \ud504\ub808\uc784\ub4e4\uc744 \uc120\ubcc4\ud558\uc5ec \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 RepVideo\uac00 \uacf5\uac04\uc801 \uc138\ubd80 \ubb18\uc0ac\uc640 \uc2dc\uac04\uc801 \uc77c\uad00\uc131 \ubaa8\ub450\uc5d0\uc11c \ud5a5\uc0c1\ub41c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc9c1\uad00\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, RepVideo\ub294 \uae30\uc900\ubaa8\ub378\ubcf4\ub2e4 \ub354\uc6b1 \uc138\ubc00\ud558\uace0 \uc815\ud655\ud55c \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uba70, \uc6c0\uc9c1\uc784\uc758 \uc790\uc5f0\uc2a4\ub7ec\uc6c0\uacfc \uc5f0\uc18d\uc131 \ub610\ud55c \ub354\uc6b1 \ub6f0\uc5b4\ub0a8\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "IV. \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.08994/x10.png", "caption": "Figure 10: The Layer-wise comparison of feature maps between CogVideoX-2B and RepVideo. The comparison shows that RepVideo consistently captures richer semantic information and maintains more coherent spatial details across layers compared to CogVideoX-2B\u00a0[31].", "description": "\uadf8\ub9bc 10\uc740 CogVideoX-2B\uc640 RepVideo\uc758 \ud2b9\uc9d5 \ub9f5\uc744 \uacc4\uce35\ubcc4\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. RepVideo\ub294 CogVideoX-2B [31]\uc5d0 \ube44\ud574 \ubaa8\ub4e0 \uacc4\uce35\uc5d0\uc11c \ub354 \ud48d\ubd80\ud55c \uc758\ubbf8 \uc815\ubcf4\ub97c \uc77c\uad00\ub418\uac8c \ud3ec\ucc29\ud558\uace0 \ub354\uc6b1 \uc77c\uad00\uc131 \uc788\ub294 \uacf5\uac04\uc801 \uc138\ubd80 \uc815\ubcf4\ub97c \uc720\uc9c0\ud569\ub2c8\ub2e4.  \uc989, RepVideo\ub294 \uc774\ubbf8\uc9c0\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \ub354\uc6b1 \uc815\ud655\ud558\uace0 \uc0c1\uc138\ud558\uac8c \ud45c\ud604\ud558\uba70, \uc774\ub294 \uc601\uc0c1 \uc0dd\uc131\uc758 \uc9c8 \ud5a5\uc0c1\uc5d0 \ud06c\uac8c \uae30\uc5ec\ud569\ub2c8\ub2e4.  \ud2b9\ud788 \uae4a\uc774 \uc788\ub294 \ub808\uc774\uc5b4\uc5d0\uc11c\ub3c4 \uc758\ubbf8 \uc815\ubcf4\uc758 \uc190\uc2e4\uc774 \uc801\uace0, \ubcf4\ub2e4 \uc77c\uad00\ub41c \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uc5ec, \ubcf4\ub2e4 \uc790\uc5f0\uc2a4\ub7fd\uace0 \ud604\uc2e4\uc801\uc778 \uc601\uc0c1 \uc0dd\uc131\uc5d0 \uc720\ub9ac\ud569\ub2c8\ub2e4.", "section": "IV. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.08994/x11.png", "caption": "Figure 11: The comparison of attention maps between CogVideoX-2B and RepVideo. The comparison demonstrates that RepVideo could maintain more consistent semantic relationship compared to CogVideoX-2B\u00a0[31].", "description": "\uadf8\ub9bc 11\uc740 CogVideoX-2B\uc640 RepVideo\uc758 \uc5b4\ud150\uc158 \ub9f5\uc744 \ube44\uad50\ud558\uc5ec RepVideo\uac00 CogVideoX-2B [31]\ubcf4\ub2e4 \uc77c\uad00\ub41c \uc758\ubbf8 \uad00\uacc4\ub97c \uc720\uc9c0\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CogVideoX-2B\ub294 \uae4a\uc774\uac00 \uae4a\uc5b4\uc9d0\uc5d0 \ub530\ub77c \uc5b4\ud150\uc158\uc774 \uc5ec\ub7ec \ud504\ub808\uc784\uc5d0 \uac78\uccd0 \ud37c\uc9c0\uace0, \uc758\ubbf8\uc801\uc73c\ub85c \uad00\ub828 \uc5c6\ub294 \uc601\uc5ed\uc5d0 \uc9d1\uc911\ud558\ub294 \ubc18\uba74, RepVideo\ub294 \ud2b9\uc815 \uac1d\uccb4\ub098 \uc8fc\uc81c\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158\uc774 \ub354\uc6b1 \uc9d1\uc911\uc801\uc774\uace0 \uc77c\uad00\ub418\uc5b4 \uc2dc\ub9e8\ud2f1\ud55c \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4. \uc774\ub294 RepVideo\uc758 \uac15\ud654\ub41c \ud45c\ud604 \ubc29\uc2dd\uc774 \uac01 \ud504\ub808\uc784\uc758 \uc758\ubbf8\uc801 \uc5f0\uad00\uc131\uc744 \ubcf4\ub2e4 \ud6a8\uacfc\uc801\uc73c\ub85c \ud3ec\ucc29\ud558\uace0, \uc2dc\uac01\uc801 \uc77c\uad00\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \uae30\uc5ec\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ub2e4\uc591\ud55c \ub808\uc774\uc5b4\uc5d0\uc11c\uc758 \uc5b4\ud150\uc158 \ubd84\ud3ec\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud568\uc73c\ub85c\uc368, RepVideo\uac00 \uc2dc\ub9e8\ud2f1 \uc815\ubcf4\ub97c \ubcf4\ub2e4 \ud6a8\uacfc\uc801\uc73c\ub85c \uc720\uc9c0\ud558\uace0, \uc2dc\uacc4\uc5f4 \uc77c\uad00\uc131\uc744 \uac1c\uc120\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "V. DISCUSSION"}, {"figure_path": "https://arxiv.org/html/2501.08994/x12.png", "caption": "Figure 12: The cosine similarity between consecutive frames across layers.", "description": "\uadf8\ub9bc 12\ub294 \uc5ec\ub7ec \ub808\uc774\uc5b4\uc5d0 \uac78\uccd0 \uc5f0\uc18d\ub41c \ud504\ub808\uc784 \uac04\uc758 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub808\uc774\uc5b4\ubcc4\ub85c \uc5f0\uc18d \ud504\ub808\uc784 \uc30d\uc758 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub97c \uacc4\uc0b0\ud558\uc5ec, \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4. \ub192\uc740 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub294 \ud504\ub808\uc784 \uac04\uc758 \uc2dc\uac01\uc801 \uc720\uc0ac\uc131\uc774 \ud06c\ub2e4\ub294 \uac83\uc744 \ub098\ud0c0\ub0b4\uba70, \ub530\ub77c\uc11c \ub354 \ub9e4\ub044\ub7fd\uace0 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc774 \ub192\uc740 \ube44\ub514\uc624 \uc0dd\uc131\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 RepVideo \ubaa8\ub378\uc774 \uc774\uc804 \ubaa8\ub378\uc778 CogVideoX-2B\ubcf4\ub2e4 \uc5f0\uc18d \ud504\ub808\uc784 \uac04\uc758 \uc720\uc0ac\ub3c4\uac00 \ub354 \ub192\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud558\uba70, RepVideo\uc758 \uc2dc\uac04\uc801 \uc77c\uad00\uc131 \uac1c\uc120 \ud6a8\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788 \uae4a\uc740 \ub808\uc774\uc5b4\uc5d0\uc11c\ub3c4 \ub192\uc740 \uc720\uc0ac\ub3c4\ub97c \uc720\uc9c0\ud558\ub294 \uac83\uc740  RepVideo\uc758 \ud2b9\uc9d5\uc785\ub2c8\ub2e4.", "section": "IV. \uc2e4\ud5d8"}]