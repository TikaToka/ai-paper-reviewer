{"references": [{"fullname_first_author": "Daya Guo", "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "publication_date": "2025-01-22", "reason": "This is the main research paper being described in the provided text and the basis for all other cited works."}, {"fullname_first_author": "A. Kumar", "paper_title": "Training language models to self-correct via reinforcement learning", "publication_date": "2024-09-17", "reason": "This paper is relevant due to its focus on improving language models through reinforcement learning, a technique also employed in the main study."}, {"fullname_first_author": "S. Shao", "paper_title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models", "publication_date": "2024-02-11", "reason": "This paper is cited as foundational for the RL algorithm (GRPO) used in the primary research."}, {"fullname_first_author": "D. Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-09-09", "reason": "This paper is highly relevant because it introduced the MMLU benchmark, a key dataset used for evaluating reasoning capabilities in LLMs in the study."}, {"fullname_first_author": "D. Silver", "paper_title": "Mastering chess and shogi by self-play with a general reinforcement learning algorithm", "publication_date": "2017-12-01", "reason": "This paper is important as it describes AlphaZero, a seminal work in reinforcement learning which has influenced methods used in this paper."}]}