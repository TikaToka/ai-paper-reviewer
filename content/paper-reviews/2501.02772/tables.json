[{"content": "|             | SQuAD R@5 | SQuAD M@5 | NQ R@5 | NQ M@5 | TriviaQA R@5 | TriviaQA M@5 | PAQ R@5 | PAQ M@5 | RIR R@5 | RIR M@5 |\n|-------------|------------|------------|---------|---------|----------------|----------------|---------|---------|---------|---------|\n| _Pre-trained retrieval model_ |\n| SBERT       | 0.812      | 0.667      | 0.754   | 0.576   | 0.677          | 0.413          | 0.808   | 0.701   | 0.376   | 0.297   |\n| E5          | 0.803      | 0.674      | 0.760   | 0.581   | 0.645          | 0.390          | 0.816   | 0.716   | 0.484   | 0.396   |\n| BGE         | 0.829      | 0.701      | 0.674   | 0.502   | 0.690          | 0.422          | 0.752   | 0.647   | 0.451   | 0.367   |\n| GTE         | 0.866      | 0.744      | 0.767   | 0.587   | 0.726          | 0.443          | 0.836   | 0.736   | 0.528   | 0.435   |\n| _Retrained retrieval model_ |\n| SBERT<sub>RT</sub> | 0.742      | 0.585      | 0.739   | 0.550   | 0.577          | 0.342          | 0.859   | 0.742   | 0.739   | 0.631   |\n| BGE<sub>RT</sub>  | 0.841      | 0.701      | 0.751   | 0.553   | 0.640          | 0.384          | 0.901   | 0.802   | 0.953   | 0.881   |\n| GeAR        | 0.883      | 0.762      | 0.747   | 0.567   | 0.660          | 0.398          | 0.940   | 0.855   | 0.961   | 0.903   |\n| GeAR<sub>w/o</sub>\u2112<sub>LM</sub> | 0.889      | 0.776      | 0.755   | 0.565   | 0.660          | 0.399          | 0.955   | 0.877   | 0.963   | 0.907   |", "caption": "Table 1: Comparison of documents retrieval performance on different datasets, where R@k stands for Recall@k, M@k stands for MAP@k.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubb38\uc11c \uac80\uc0c9 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. R@k\ub294 Recall@k\ub97c, M@k\ub294 MAP@k\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc989, R@k\ub294 \uc0c1\uc704 k\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc\uc5d0 \uc2e4\uc81c \uad00\ub828 \ubb38\uc11c\uac00 \ud3ec\ud568\ub420 \ud655\ub960\uc774\uace0, M@k\ub294 \ud3c9\uade0\uc801\uc73c\ub85c \uc0c1\uc704 k\uac1c\uc758 \uac80\uc0c9 \uacb0\uacfc\uc5d0\uc11c \uad00\ub828 \ubb38\uc11c\uc758 \uc21c\uc704\uac00 \uc5bc\ub9c8\ub098 \ub192\uc740\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc2dc\ub41c GeAR \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \uae30\uc874 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec GeAR\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \uc804\uccb4 \uc131\ub2a5"}, {"content": "|                       | SQuAD R@1 | SQuAD M@1 | NQ R@1 | NQ M@1 | TriviaQA R@1 | TriviaQA M@1 | PAQ R@1 | PAQ M@1 | RIR R@3 | RIR M@3 |\n|-----------------------|------------|------------|---------|---------|----------------|----------------|---------|---------|---------|---------|\n| _Pre-trained retrieval model_ |            |            |         |         |                |                |         |         |         |         |\n| SBERT                   | 0.739       | 0.800       | 0.558    | 0.652    | 0.359           | 0.583           | 0.498    | 0.561    | 0.891    | 0.874    |\n| E5                      | 0.783       | 0.847       | 0.590    | 0.683    | 0.379           | 0.613           | 0.573    | 0.640    | 0.891    | 0.878    |\n| BGE                      | 0.768       | 0.830       | 0.570    | 0.663    | 0.362           | 0.589           | 0.565    | 0.630    | 0.894    | 0.881    |\n| GTE                      | 0.758       | 0.820       | 0.548    | 0.639    | 0.352           | 0.572           | 0.525    | 0.590    | 0.895    | 0.886    |\n| _Retrained retrieval model_ |            |            |         |         |                |                |         |         |         |         |\n| SBERT<sub>RT</sub>       | 0.516       | 0.568       | 0.445    | 0.523    | 0.281           | 0.472           | 0.363    | 0.418    | 0.899    | 0.991    |\n| BGE<sub>RT</sub>        | 0.455       | 0.538       | 0.601    | 0.656    | 0.288           | 0.475           | 0.409    | 0.466    | 0.897    | 0.888    |\n| GeAR                     | 0.810       | 0.874       | 0.765    | 0.871    | 0.515           | 0.808           | 0.885    | 0.965    | 0.954    | 0.897    |", "caption": "Table 2: Comparison of units localization performance on different datasets, where R@k stands for Recall@k, M@k stands for MAP@k.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e8\uc704 \uc9c0\uc5ed\ud654 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. R@k\ub294 Recall@k\ub97c, M@k\ub294 MAP@k\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc989, \uc774 \ud45c\ub294 \uc9c8\uc758\uc5b4\uc640 \uad00\ub828\ub41c \uc815\ubcf4 \ub2e8\uc704(\uc608: \ubb38\uc7a5)\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \ucc3e\uc544\ub0b4\ub294\uc9c0\ub97c \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uce21\uc815\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Recall@k\ub294 \uc0c1\uc704 k\uac1c\uc758 \uacb0\uacfc \uc911\uc5d0 \uc2e4\uc81c \uad00\ub828 \uc815\ubcf4 \ub2e8\uc704\uac00 \ud3ec\ud568\ub41c \ube44\uc728\uc774\uace0, MAP@k\ub294 \uc0c1\uc704 k\uac1c\uc758 \uacb0\uacfc\uc758 \uc815\ud655\ub3c4\ub97c \ud3c9\uade0\ud55c \uac12\uc785\ub2c8\ub2e4.  \ub530\ub77c\uc11c,  R@k\uc640 M@k \uac12\uc774 \ub192\uc744\uc218\ub85d \ud574\ub2f9 \ubaa8\ub378\uc758 \ub2e8\uc704 \uc9c0\uc5ed\ud654 \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.2 \uc804\ubc18\uc801\uc778 \uc131\ub2a5"}, {"content": "| SQuAD |  | NQ |  | TriviaQA |  | PAQ |  | RIR |  |\n|---|---|---|---|---|---|---|---|---|---|---|\n| EM | F1 | EM | F1 | EM | F1 | EM | F1 | Rouge-1 | Rouge-L |\n| 61.2 | 65.3 | 66.1 | 61.0 | 47.4 | 60.0 | 88.1 | 92.4 | 87.4 | 87.1 |", "caption": "Table 3: Generation performance of GeAR\u00a0on different tasks.", "description": "\ud45c 3\uc740 GeAR \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uacfc\uc81c(Question Answering Retrieval, Relevant Information Retrieval)\uc5d0\uc11c \uc0dd\uc131 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  EM(Exact Match)\uacfc F1 \uc810\uc218\ub294 \uc9c8\uc758\uc751\ub2f5 \uacfc\uc81c\uc758 \uc815\ud655\ub3c4\ub97c \uce21\uc815\ud558\uace0, Rouge \uc810\uc218\ub294 \uad00\ub828 \uc815\ubcf4 \uac80\uc0c9 \uacfc\uc81c\uc5d0\uc11c \uc0dd\uc131 \ud14d\uc2a4\ud2b8\uc758 \ud488\uc9c8\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c GeAR\uc758 \uc131\ub2a5\uc744 \uc218\uce58\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \ubaa8\ub378\uc758 \uc804\ubc18\uc801\uc778 \uc0dd\uc131 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4 Experiments"}, {"content": "| Hyperparameter | Assignment |\n|---|---| \n| Computing Infrastructure | 16 MI200-64GB GPUs |\n| Number of epochs | 10 |\n| Batch size per GPU | 48 / 16 |\n| Maximum sequence length | 512 |\n| Optimizer | AdamW |\n| AdamW epsilon | 1e-8 |\n| AdamW beta weights | 0.9, 0.999 |\n| Learning rate scheduler | Cosine lr schedule |\n| Initialization learning rate | 1e-5 |\n| Minimum learning rate | 1e-6 |\n| Weight decay | 0.05 |\n| Warmup steps | 1000 |\n| Warmup learning rate | 1e-6 |", "caption": "Table 4: Hyperparameter settings", "description": "\ud45c 4\ub294 GeAR \ubaa8\ub378\uc758 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucef4\ud4e8\ud305 \uc778\ud504\ub77c, \uc5d0\ud3ed \uc218, \ubc30\uce58 \ud06c\uae30, \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \ud559\uc2b5\ub960, \uac00\uc911\uce58 \uac10\uc18c \ub4f1\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\uc5ec \ubaa8\ub378 \ud6c8\ub828 \uacfc\uc815\uc744 \uc7ac\ud604\ud558\ub294 \ub370 \ud544\uc694\ud55c \ubaa8\ub4e0 \uc911\uc694\ud55c \uc124\uc815\uc744 \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.4 \ud6c8\ub828 \ubaa9\ud45c"}, {"content": "| Scenario | Data Number |\n|---|---| \n| QAR | 30,000,000 |\n| RIR | 5,676,877 |", "caption": "Table 5: Training data statistics.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \ub370\uc774\ud130 \uad6c\uc131 \uc139\uc158\uc5d0 \uc788\ub294 \ud45c 5\uc785\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 GeAR \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc9c8\ubb38 \ub2f5\ubcc0 \uac80\uc0c9(QAR)\uacfc \uad00\ub828 \uc815\ubcf4 \uac80\uc0c9(RIR) \ub450 \uac00\uc9c0 \uc2dc\ub098\ub9ac\uc624\uc5d0 \ub300\ud574 \ud559\uc2b5 \ub370\uc774\ud130 \uc218\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc815\ubcf4\uac00 \ub2f4\uaca8 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 \ub370\uc774\ud130 \uad6c\uc131"}, {"content": "| Scenario | Dataset | Documents Number | Queries Number |\n|---|---|---|---| \n| QA | Squad | 20,239 | 5,928 |\n| QA | NQ | 64,501 | 2,889 |\n| QA | TriviaQA | 104,160 | 14,000 |\n| QA | PAQ | 932,601 | 20,000 |\n| RIR | RIR | 2,315,413 | 145,562 |", "caption": "Table 6: The evaluation data statistics for the document retrieval task.", "description": "\ud45c 6\uc740 \ubb38\uc11c \uac80\uc0c9 \uacfc\uc81c\ub97c \uc704\ud55c \ud3c9\uac00 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b(Squad, NQ, TriviaQA, PAQ)\uc5d0 \ub300\ud574 \ubb38\uc11c \uc218\uc640 \uc9c8\uc758 \uc218\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \uc2e4\ud5d8 \uc124\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \uaddc\ubaa8\uc640 \ubd84\ud3ec\ub97c \uba85\ud655\ud788 \ubcf4\uc5ec\uc8fc\uc5b4, \uc2e4\ud5d8 \uacb0\uacfc\uc758 \uc2e0\ub8b0\uc131\uacfc \uc77c\ubc18\ud654 \uac00\ub2a5\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4.1 Setup"}, {"content": "| Scenario | Dataset | Data Number |\n|---|---|---|\n| QA | Squad | 5,928 |\n|  | NQ | 2,889 |\n|  | TriviaQA | 14,000 |\n|  | PAQ | 20,000 |\n| RIR | RIR | 10,000 |", "caption": "Table 7: The evaluation data statistics for the units localization and information generation tasks.", "description": "\ud45c 7\uc740 \ubb38\uc11c \uac80\uc0c9 \uc2dc\uc2a4\ud15c\uc758 \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud574 \uc0ac\uc6a9\ub41c \ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ub2e8\uc704 \uc9c0\uc5ed\ud654(Units Localization) \uc791\uc5c5\uacfc \uc815\ubcf4 \uc0dd\uc131(Information Generation) \uc791\uc5c5\uc5d0 \uc0ac\uc6a9\ub41c \uc9c8\ubb38 \uc751\ub2f5(QA) \ub370\uc774\ud130\uc14b\uacfc \uad00\ub828 \uc815\ubcf4 \uac80\uc0c9(RIR) \ub370\uc774\ud130\uc14b\uc758 \ucffc\ub9ac(\uc9c8\ubb38)\uc640 \ubb38\uc11c \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30\ub97c \uba85\ud655\ud788 \ud558\uc5ec \uc2e4\ud5d8 \uacb0\uacfc\uc758 \uc2e0\ub8b0\uc131\uc744 \ub192\uc774\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "4.1 Setup"}]