[{"figure_path": "https://arxiv.org/html/2501.11425/x1.png", "caption": "Figure 1: Illustration of language agents struggling with error correction in trajectory generation. These errors can cause agents to enter loops, hindering recovery in long trajectories and resulting in suboptimal outcomes.\nAgent-R enables agents to effectively detect and address errors in real-time, handling long-horizon tasks and avoiding loops with greater self-reflection capabilities.", "description": "\uadf8\ub9bc 1\uc740 \uc5d0\uc774\uc804\ud2b8\uac00 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc5d0\uc11c \uc624\ub958 \uc218\uc815\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \uc5b8\uc5b4 \uc5d0\uc774\uc804\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc624\ub958\ub294 \uc5d0\uc774\uc804\ud2b8\uac00 \ubc18\ubcf5\uc801\uc778 \ub3d9\uc791\uc744 \ud558\uac8c \ub9cc\ub4e4\uc5b4 \uc7a5\uae30\uc801\uc778 \uacbd\ub85c \ubcf5\uad6c\ub97c \ubc29\ud574\ud558\uace0 \ucd5c\uc801\uc774 \uc544\ub2cc \uacb0\uacfc\ub97c \ucd08\ub798\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. Agent-R\uc740 \uc5d0\uc774\uc804\ud2b8\uac00 \uc2e4\uc2dc\uac04\uc73c\ub85c \uc624\ub958\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uac10\uc9c0\ud558\uace0 \ud574\uacb0\ud558\uc5ec \uc7a5\uae30\uc801\uc778 \uc791\uc5c5\uc744 \ucc98\ub9ac\ud558\uace0 \ubc18\ubcf5\uc801\uc778 \ub3d9\uc791\uc744 \ud53c\ud558\uba74\uc11c \ud5a5\uc0c1\ub41c \uc790\uae30 \ubc18\uc131 \ub2a5\ub825\uc744 \uac16\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.11425/x2.png", "caption": "Figure 2: The framework of Agent-R consists of two phases. In Phase I, we adopt MCTS and a model-guided reflection mechanism to construct revision trajectories. In Phase II, the agents are trained using the collected revision trajectories. These two phases can be repeated iteratively. rs is the revision signal, t\u2032superscript\ud835\udc61\u2032t^{\\prime}italic_t start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is the transition point between the bad and good trajectories, and L\u2062(\u03b8)\ud835\udc3f\ud835\udf03L(\\theta)italic_L ( italic_\u03b8 ) is the loss function to be optimized.", "description": "\uadf8\ub9bc 2\ub294 Agent-R\uc758 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ub450 \ub2e8\uacc4\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 1\ub2e8\uacc4\uc5d0\uc11c\ub294 MCTS\uc640 \ubaa8\ub378 \uae30\ubc18\uc758 \ubc18\uc131 \uba54\ucee4\ub2c8\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\uc815\ub41c \uacbd\ub85c(revision trajectories)\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. 2\ub2e8\uacc4\uc5d0\uc11c\ub294 \uc218\uc9d1\ub41c \uc218\uc815\ub41c \uacbd\ub85c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5d0\uc774\uc804\ud2b8\ub97c \ud6c8\ub828\uc2dc\ud0b5\ub2c8\ub2e4. \uc774 \ub450 \ub2e8\uacc4\ub294 \ubc18\ubcf5\uc801\uc73c\ub85c \uc218\ud589\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  rs\ub294 \uc218\uc815 \uc2e0\ud638(revision signal), t\u2032\ub294 \uc798\ubabb\ub41c \uacbd\ub85c\uc640 \uc62c\ubc14\ub978 \uacbd\ub85c \uc0ac\uc774\uc758 \uc804\ud658\uc810(transition point), L(\u03b8)\ub294 \ucd5c\uc801\ud654\ud574\uc57c \ud560 \uc190\uc2e4 \ud568\uc218(loss function)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc218\uc815\ub41c \uacbd\ub85c\ub294 \uc798\ubabb\ub41c \uacbd\ub85c\ub97c \uc218\uc815\ud558\uc5ec \uc62c\ubc14\ub978 \uacbd\ub85c\ub97c \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc5d0\uc11c \ub9cc\ub4e4\uc5b4\uc9d1\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uc774\ub7ec\ud55c \uc218\uc815\ub41c \uacbd\ub85c\ub97c \ud1b5\ud574 \uc5d0\uc774\uc804\ud2b8\uc758 \uc790\uac00 \ud559\uc2b5 \ubc0f \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc774\ub04c\uc5b4\ub0b4\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2501.11425/x3.png", "caption": "Figure 3: Results of different training trajectories under different iterations on three interactive environments.", "description": "\uadf8\ub9bc 3\uc740 \uc138 \uac00\uc9c0 \uc0c1\ud638\uc791\uc6a9 \ud658\uacbd(WebShop, SciWorld, TextCraft)\uc5d0\uc11c \uc11c\ub85c \ub2e4\ub978 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub978 \ub2e4\uc591\ud55c \ud6c8\ub828 \uacbd\ub85c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud658\uacbd\uc5d0 \ub300\ud574 \uc138 \uac00\uc9c0 \ud6c8\ub828 \ubc29\ubc95(\uae30\uc900, \ucd5c\uc801 \uacbd\ub85c, Agent-R)\uc758 \ud3c9\uade0 \ucd5c\uc885 \uc810\uc218\ub97c \ubc18\ubcf5 \ud69f\uc218\ubcc4\ub85c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec Agent-R\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ud658\uacbd \ubaa8\ub450\uc5d0\uc11c Agent-R\uc744 \uc0ac\uc6a9\ud55c \ud6c8\ub828\uc774 \ubc18\ubcf5 \ud69f\uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \uc9c0\uc18d\uc801\uc73c\ub85c \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 Agent-R\uc774 \ubc18\ubcf5\uc801\uc778 \uc790\uae30 \ud559\uc2b5\uc744 \ud1b5\ud574 \uc5d0\uc774\uc804\ud2b8\uc758 \uc131\ub2a5\uc744 \uac1c\uc120\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.11425/x4.png", "caption": "Figure 4: Average count of repeated action lengths for different training trajectories and different iterations in three interactive environments.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc138 \uac00\uc9c0 \uc0c1\ud638 \uc791\uc6a9 \ud658\uacbd(WebShop, SciWorld, TextCraft)\uc5d0\uc11c \ubc18\ubcf5\ub418\ub294 \ud589\ub3d9\uc758 \ud3c9\uade0 \ud69f\uc218\ub97c \ub2e4\uc591\ud55c \ud6c8\ub828 \uacbd\ub85c\uc640 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub77c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud658\uacbd\uc5d0 \ub300\ud574, \ucd08\uae30 \uc0c1\ud0dc(Vanilla), \ucd5c\uc801 \uacbd\ub85c\ub9cc \uc0ac\uc6a9\ud55c \ud6c8\ub828(w/ Optimal), Agent-R\uc744 \uc0ac\uc6a9\ud55c \ud6c8\ub828(w/ Agent-R #Iter1, #Iter2, #Iter3)\uc758 \ub124 \uac00\uc9c0 \uacbd\uc6b0\uc5d0 \ub300\ud55c \ubc18\ubcf5 \ud589\ub3d9 \uc2dc\ud000\uc2a4\uc758 \ud3c9\uade0 \uae38\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Agent-R \ud6c8\ub828\uc758 \ubc18\ubcf5 \ud69f\uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ubc18\ubcf5\ub418\ub294 \ud589\ub3d9\uc758 \ud69f\uc218\uac00 \uc904\uc5b4\ub4dc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 Agent-R\uc774 \uc5d0\uc774\uc804\ud2b8\uac00 \ubc18\ubcf5\uc801\uc778 \ud589\ub3d9\uc5d0 \ube60\uc9c0\ub294 \uac83\uc744 \ubc29\uc9c0\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.4 Findings with Analysis"}, {"figure_path": "https://arxiv.org/html/2501.11425/x5.png", "caption": "Figure 5: Average revision length of different iterations on three interactive environments.", "description": "\uadf8\ub9bc 5\ub294 \uc138 \uac00\uc9c0 \uc0c1\ud638 \uc791\uc6a9 \ud658\uacbd(WebShop, SciWorld, TextCraft)\uc5d0\uc11c Agent-R\uc758 \ubc18\ubcf5 \ud6c8\ub828 \ud69f\uc218\uc5d0 \ub530\ub978 \ud3c9\uade0 \uc218\uc815 \uae38\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc218\uc815 \uae38\uc774\ub294 \uc798\ubabb\ub41c \uacbd\ub85c\ub97c \ucc98\uc74c \uc778\uc2dd\ud55c \uc2dc\uc810\ubd80\ud130 \uc62c\ubc14\ub978 \uacbd\ub85c\ub85c \uc804\ud658\ud558\uae30\uae4c\uc9c0 \uac78\ub9b0 \ud589\ub3d9(action)\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ubc18\ubcf5 \ud6c8\ub828\uc774 \uc9c4\ud589\ub420\uc218\ub85d \ud3c9\uade0 \uc218\uc815 \uae38\uc774\uac00 \uc9e7\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub294 Agent-R\uc774 \uc798\ubabb\ub41c \ud589\ub3d9\uc744 \ub354\uc6b1 \ube60\ub974\uace0 \ud6a8\uc728\uc801\uc73c\ub85c \uc778\uc9c0\ud558\uace0 \uc218\uc815\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  \uc774\ub294 \uc5d0\uc774\uc804\ud2b8\uc758 \uc790\uae30 \ubc18\uc131 \ub2a5\ub825 \ud5a5\uc0c1\uacfc \ub354 \ub098\uc740 \uacbd\ub85c \uacc4\ud68d \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4.", "section": "4.4 Findings with Analysis"}, {"figure_path": "https://arxiv.org/html/2501.11425/x6.png", "caption": "Figure 6: Comparison of different training methods on three interactive environments.", "description": "\uadf8\ub9bc 6\uc740 \uc138 \uac00\uc9c0 \uc0c1\ud638\uc791\uc6a9 \ud658\uacbd(WebShop, SciWorld, TextCraft)\uc5d0\uc11c \uc11c\ub85c \ub2e4\ub978 \ud559\uc2b5 \ubc29\ubc95(\ub2e8\uc77c \uc791\uc5c5 \ud559\uc2b5, \uc9c1\uc811 \uc218\uc815, Agent-R\uc758 \ub2e4\uc911 \uc791\uc5c5 \ud559\uc2b5)\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. Agent-R\uc758 \ub2e4\uc911 \uc791\uc5c5 \ud559\uc2b5 \ubc29\ubc95\uc774 \ub2e4\ub978 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \ubc18\ubcf5 \ud559\uc2b5\uc744 \uac70\ub4ed\ud560\uc218\ub85d \uadf8 \ucc28\uc774\uac00 \ub354\uc6b1 \ucee4\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiment"}]