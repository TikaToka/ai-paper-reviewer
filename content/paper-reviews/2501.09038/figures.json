[{"figure_path": "https://arxiv.org/html/2501.09038/x1.png", "caption": "Figure 1: Sample scenarios from the Physics-IQ dataset for testing physical understanding in generative video models. Models are shown the beginning of a video (single frame for image2video models; 3 seconds for video2video models) and need to predict how the video continues over the next 5 seconds, which requires understanding different physical properties: Solid Mechanics, Fluid Dynamics, Optics, Thermodynamics, and Magnetism. See here for an animated version of this figure.", "description": "\uadf8\ub9bc 1\uc740 \ubb3c\ub9ac\uc801 \uc774\ud574\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 Physics-IQ \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac00\uc838\uc628 \uc0d8\ud50c \uc2dc\ub098\ub9ac\uc624\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ubbf8\uc9c0-\ube44\ub514\uc624 \ubaa8\ub378\uc758 \uacbd\uc6b0\uc5d0\ub294 \ub2e8\uc77c \ud504\ub808\uc784\uc744, \ube44\ub514\uc624-\ube44\ub514\uc624 \ubaa8\ub378\uc758 \uacbd\uc6b0\uc5d0\ub294 3\ucd08 \ubd84\ub7c9\uc758 \ube44\ub514\uc624 \ud074\ub9bd\uc744 \ubaa8\ub378\uc5d0 \ubcf4\uc5ec\uc8fc\uace0, \ub2e4\uc74c 5\ucd08 \ub3d9\uc548\uc758 \ube44\ub514\uc624\ub97c \uc608\uce21\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774\ub294 \uace0\uccb4\uc5ed\ud559, \uc720\uccb4\uc5ed\ud559, \uad11\ud559, \uc5f4\uc5ed\ud559, \uc790\uae30\ub825 \ub4f1 \ub2e4\uc591\ud55c \ubb3c\ub9ac\uc801 \uc6d0\ub9ac\ub97c \uc774\ud574\ud574\uc57c\ub9cc \uac00\ub2a5\ud55c \uc791\uc5c5\uc785\ub2c8\ub2e4.  \uac01 \uc2dc\ub098\ub9ac\uc624\ub294 \ub2e4\uc591\ud55c \ubb3c\ub9ac\uc801 \ud604\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uac1c\uc758 \ube44\ub514\uc624 \ud074\ub9bd\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ud574\ub2f9 \uadf8\ub9bc\uc758 \uc560\ub2c8\uba54\uc774\uc158 \ubc84\uc804\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub294 \ub9c1\ud06c\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "Physics-IQ benchmark"}, {"figure_path": "https://arxiv.org/html/2501.09038/x2.png", "caption": "Figure 2: Overview of the Physics-IQ evaluation protocol. A video generative model produces a 5 second continuation of the conditioning frame(s), optionally including a textual description of the conditioning frames for models that accept text input. They are compared against the ground truth test frames using four metrics that quantify different properties of physical understanding. The metrics are defined and explained in the methods section. Code to run the evaluation is available at Physics-IQ-benchmark.", "description": "\uadf8\ub9bc 2\ub294 Physics-IQ \ud3c9\uac00 \ud504\ub85c\ud1a0\ucf5c\uc744 \uac1c\uad04\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc740 \uc870\uac74 \ud504\ub808\uc784(\ub4e4)\uc758 5\ucd08 \uc5f0\uc18d\uc744 \uc0dd\uc131\ud558\uba70, \ud14d\uc2a4\ud2b8 \uc785\ub825\uc744 \ud5c8\uc6a9\ud558\ub294 \ubaa8\ub378\uc758 \uacbd\uc6b0 \uc870\uac74 \ud504\ub808\uc784\uc5d0 \ub300\ud55c \ud14d\uc2a4\ud2b8 \uc124\uba85\uc744 \uc120\ud0dd\uc801\uc73c\ub85c \ud3ec\ud568\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc0dd\uc131\ub41c \ud504\ub808\uc784\uc740 \ubb3c\ub9ac\uc801 \uc774\ud574\uc758 \ub2e4\uc591\ud55c \uc18d\uc131\uc744 \uc815\ub7c9\ud654\ud558\ub294 \ub124 \uac00\uc9c0 \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\uc81c \ud504\ub808\uc784\uacfc \ube44\uad50\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc9c0\ud45c\ub294 \ubc29\ubc95\ub860 \uc139\uc158\uc5d0\uc11c \uc815\uc758 \ubc0f \uc124\uba85\ub418\uba70, \ud3c9\uac00\ub97c \uc2e4\ud589\ud558\ub294 \ucf54\ub4dc\ub294 Physics-IQ-benchmark\uc5d0\uc11c \uc774\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "Evaluation protocol"}, {"figure_path": "https://arxiv.org/html/2501.09038/x3.png", "caption": "Figure 3: A qualitative overview of recent synthetic datasets related to physical understanding (19, 20, 17, 38, 18, 36, 37, 39). These datasets are great for the purposes they were designed for, but not ideal for evaluating models trained on real-world videos due to the distribution shift.", "description": "\uadf8\ub9bc 3\uc740 \ubb3c\ub9ac\uc801 \uc774\ud574\uc640 \uad00\ub828\ub41c \ucd5c\uadfc \ud569\uc131 \ub370\uc774\ud130\uc14b\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ub370\uc774\ud130\uc14b\ub4e4\uc740 \uac01 \ubaa9\uc801\uc5d0 \ub9de\uac8c \uc798 \uc124\uacc4\ub418\uc5c8\uc9c0\ub9cc, \uc2e4\uc81c \uc601\uc0c1 \ub370\uc774\ud130\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\ub4e4\uc744 \ud3c9\uac00\ud558\ub294 \ub370\ub294 \uc801\ud569\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.  \uc2e4\uc81c \uc601\uc0c1\uacfc \ud569\uc131 \uc601\uc0c1 \uac04\uc758 \ucc28\uc774(\ubd84\ud3ec \ucc28\uc774) \ub54c\ubb38\uc5d0 \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \uc81c\ub300\ub85c \ud3c9\uac00\ud560 \uc218 \uc5c6\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 CRAFT, IntPhys, Physion, ESPRIT, Physion++, CoPhy, CLEVERER, PhyWorld \ub370\uc774\ud130\uc14b\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b\uc740 \ubb3c\ub9ac\uc801 \ud604\uc0c1\uc744 \ub2e4\ub8e8\uc9c0\ub9cc, \uc2dc\ubbac\ub808\uc774\uc158 \ud658\uacbd\uc5d0\uc11c \uc0dd\uc131\ub418\uc5c8\uae30 \ub54c\ubb38\uc5d0 \uc2e4\uc81c \uc138\uacc4\uc758 \ubcf5\uc7a1\uc131\uacfc\ub294 \ucc28\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4.", "section": "\ubaa8\ub378"}, {"figure_path": "https://arxiv.org/html/2501.09038/x4.png", "caption": "Figure 4: How well do current video generative models understand physical principles? Left.\u00a0The Physics-IQ score is an aggregated measure across four individual metrics, normalized such that pairs of real videos that differ only by physical randomness score 100%. All evaluated models show a large gap, with the best model scoring 24.1%, indicating that physical understanding is severely limited. Right.\u00a0In addition, the mean rank of models across all four metrics is shown here; the Spearman correlation between aggregated results on the left and mean rank on the right is high (-\u2062.87,p<.005-.87p.005\\text{-}.87,\\emph{p}<.005- .87 , p < .005), thus aggregating to a single Physics-IQ score largely preserves model rankings.", "description": "\uadf8\ub9bc 4\ub294 \ud604\uc7ac \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc774 \ubb3c\ub9ac\uc801 \uc6d0\ub9ac\ub97c \uc5bc\ub9c8\ub098 \uc798 \uc774\ud574\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ub124 \uac00\uc9c0 \uac1c\ubcc4 \uc9c0\ud45c\ub97c \uc885\ud569\ud55c Physics-IQ \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubb3c\ub9ac\uc801 \ubb34\uc791\uc704\uc131\ub9cc \ub2e4\ub978 \uc2e4\uc81c \ube44\ub514\uc624 \uc30d\uc758 \uc810\uc218\ub97c 100%\ub85c \uc815\uaddc\ud654\ud588\uc2b5\ub2c8\ub2e4. \ud3c9\uac00\ub41c \ubaa8\ub4e0 \ubaa8\ub378\uc740 \ud070 \uaca9\ucc28\ub97c \ubcf4\uc774\uba70, \ucd5c\uace0 \ubaa8\ub378\uc758 \uc810\uc218\uac00 24.1%\uc5d0 \ubd88\uacfc\ud558\uc5ec \ubb3c\ub9ac\uc801 \uc774\ud574\uac00 \ub9e4\uc6b0 \uc81c\ud55c\uc801\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 \ub124 \uac00\uc9c0 \uc9c0\ud45c\uc5d0 \uac78\uce5c \ubaa8\ub378\uc758 \ud3c9\uade0 \uc21c\uc704\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\uc758 \uc9d1\uacc4 \uacb0\uacfc\uc640 \uc624\ub978\ucabd \uadf8\ub798\ud504\uc758 \ud3c9\uade0 \uc21c\uc704 \uac04\uc758 \uc2a4\ud53c\uc5b4\ub9cc \uc0c1\uad00 \uad00\uacc4\ub294 \ub192\uc2b5\ub2c8\ub2e4(-0.87, p<.005). \ub530\ub77c\uc11c \ub2e8\uc77c Physics-IQ \uc810\uc218\ub85c \uc9d1\uacc4\ud558\uba74 \ubaa8\ub378 \uc21c\uc704\uac00 \ud06c\uac8c \uc720\uc9c0\ub429\ub2c8\ub2e4.", "section": "\uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.09038/x5.png", "caption": "Figure 5: Relationship between visual realism and physical understanding. Left. A multimodal large language model (Gemini 1.5 Pro) is asked to identify the generated video among the real and the generated video for each scenario (MLLM score) in a two-alternative forced choice paradigm. Chance rate is 50%; lower scores indicate that the model finds it harder to tell apart generated from real videos (= better realism). Sora-generated videos are hardest to distinguish from real videos for the model, whereas Lumiere (multiframe) is easiest. Right. Do models that produce \u2018realistic-looking\u2019 videos (as assessed by the MLLM score) also score better in terms of physical understanding (as assessed via the Physics-IQ score)? This scatterplot with linear fit and 95% confidence interval as a shaded blue area shows that this is not the case: Visual realism is uncorrelated with physical understanding (Pearson\u2019s r = - 0.46, p=.247 not significant). Note that the y axis on this plot is inverted for easier interpretation (up & right are best).", "description": "\uadf8\ub9bc 5\ub294 \uc2dc\uac01\uc801 \uc0ac\uc2e4\uc131\uacfc \ubb3c\ub9ac\uc801 \uc774\ud574 \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ub2e4\uc911 \ubaa8\ub4dc \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(Gemini 1.5 Pro)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc640 \uc2e4\uc81c \ube44\ub514\uc624\ub97c \uad6c\ubd84\ud558\ub294 2AFC(two-alternative forced choice) \ud328\ub7ec\ub2e4\uc784\uc5d0\uc11c \uac01 \uc2dc\ub098\ub9ac\uc624\uc5d0 \ub300\ud55c MLLM \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud655\ub960\uc740 50%\uc774\uba70, \uc810\uc218\uac00 \ub0ae\uc744\uc218\ub85d \ubaa8\ub378\uc774 \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc640 \uc2e4\uc81c \ube44\ub514\uc624\ub97c \uad6c\ubd84\ud558\uae30 \uc5b4\ub835\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4(\uc989, \uc0ac\uc2e4\uc131\uc774 \ub192\uc74c). Sora\uac00 \uc0dd\uc131\ud55c \ube44\ub514\uc624\ub294 \ubaa8\ub378\uc774 \uc2e4\uc81c \ube44\ub514\uc624\uc640 \uad6c\ubd84\ud558\uae30 \uac00\uc7a5 \uc5b4\ub824\uc6e0\uace0, Lumiere(\ub2e4\uc911 \ud504\ub808\uc784)\uac00 \uac00\uc7a5 \uc26c\uc6e0\uc2b5\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 MLLM \uc810\uc218\ub85c \ud3c9\uac00\ud55c \uc0ac\uc2e4\uc801\uc778 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ubaa8\ub378\uc774 Physics-IQ \uc810\uc218\ub85c \ud3c9\uac00\ud55c \ubb3c\ub9ac\uc801 \uc774\ud574\ub3c4\uc5d0\uc11c\ub3c4 \ub354 \uc88b\uc740 \uc810\uc218\ub97c \ubc1b\ub294\uc9c0 \uc5ec\ubd80\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc120\ud615 \ud68c\uadc0\uc120\uacfc 95% \uc2e0\ub8b0 \uad6c\uac04\uc744 \uc74c\uc601 \ucc98\ub9ac\ud55c \uc601\uc5ed\uc73c\ub85c \ud45c\uc2dc\ud55c \uc0b0\uc810\ub3c4\ub294 \uc2dc\uac01\uc801 \uc0ac\uc2e4\uc131\uacfc \ubb3c\ub9ac\uc801 \uc774\ud574 \uac04\uc5d0 \uc0c1\uad00\uad00\uacc4\uac00 \uc5c6\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4(\ud53c\uc5b4\uc2a8 \uc0c1\uad00 \uacc4\uc218 r = -0.46, p=.247, \uc720\uc758\ud558\uc9c0 \uc54a\uc74c). \ud574\uc11d\uc744 \uc6a9\uc774\ud558\uac8c \ud558\uae30 \uc704\ud574 y\ucd95\uc774 \ubc18\uc804\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4(\uc704\ucabd \ubc0f \uc624\ub978\ucabd\uc774 \uac00\uc7a5 \uc88b\uc74c).", "section": "\uacb0\uacfc(Results)"}, {"figure_path": "https://arxiv.org/html/2501.09038/x6.png", "caption": "Figure 6: Performance comparison of video generative models across different physical categories (columns) and metrics (rows). For the top three metrics, higher is better; for the last metric lower values are best. Throughout, physical variance (i.e., the performance that is achievable by real videos differing only by physical randomness) is indicated by a dashed line. Across metrics and categories, models show a considerable lack in physical understanding. More lenient metrics like \ud835\uddb2\ud835\uddc9\ud835\uddba\ud835\uddcd\ud835\uddc2\ud835\uddba\ud835\uddc5\u2062-\u2062\ud835\udda8\ud835\uddc8\ud835\uddb4\ud835\uddb2\ud835\uddc9\ud835\uddba\ud835\uddcd\ud835\uddc2\ud835\uddba\ud835\uddc5-\ud835\udda8\ud835\uddc8\ud835\uddb4\\mathsf{Spatial}\\text{-}\\mathsf{IoU}sansserif_Spatial - sansserif_IoU (top row) that only assess where an action occurred lead to higher scores than more strict metrics that also take into account e.g.\u00a0when or how much action should be taking place.", "description": "\uadf8\ub9bc 6\uc740 \ub2e4\uc591\ud55c \ubb3c\ub9ac\uc801 \ubc94\uc8fc(\uc5f4, \ud589)\uc5d0 \uac78\uccd0 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc0c1\uc704 \uc138 \uac00\uc9c0 \uc9c0\ud45c\ub294 \uac12\uc774 \ub192\uc744\uc218\ub85d \uc88b\uace0, \ub9c8\uc9c0\ub9c9 \uc9c0\ud45c\ub294 \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4.  \uc2e4\uc81c \ube44\ub514\uc624\uc758 \ubb3c\ub9ac\uc801 \ubb34\uc791\uc704\uc131\uc73c\ub85c \uc778\ud55c \uc131\ub2a5(\ubb3c\ub9ac\uc801 \ubd84\uc0b0)\uc740 \uc810\uc120\uc73c\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ubaa8\ub4e0 \uc9c0\ud45c\uc640 \ubc94\uc8fc\uc5d0\uc11c \ubaa8\ub378\uc740 \ubb3c\ub9ac\uc801 \uc774\ud574\uac00 \ubd80\uc871\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc791\uc6a9\uc774 \ubc1c\uc0dd\ud55c \uc704\uce58\ub9cc \ud3c9\uac00\ud558\ub294 Spatial-IoU\uc640 \uac19\uc740 \uad00\ub300\ud55c \uc9c0\ud45c\ub294 \uc791\uc6a9\uc774 \uc5b8\uc81c, \uc5bc\ub9c8\ub098 \ub9ce\uc774 \ubc1c\uc0dd\ud588\ub294\uc9c0 \uace0\ub824\ud558\ub294 \ubcf4\ub2e4 \uc5c4\uaca9\ud55c \uc9c0\ud45c\ubcf4\ub2e4 \uc810\uc218\uac00 \ub192\uc2b5\ub2c8\ub2e4.", "section": "\uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.09038/x7.png", "caption": "Figure 7: We here visualize success and failure scenarios within the fluid dynamics and solid mechanics categories for the two best models, VideoPoet and Runway Gen 3, according to our metrics. Both models are able to generate physics plausible frames for scenarios such as smearing paint on glass (VideoPoet) and pouring red liquid on a rubber duck (Runway Gen 3). At the same time, the models fail to simulate a ball falling into a crate or cutting a tangerine with a knife. See here for an animated version.", "description": "\uadf8\ub9bc 7\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ucc99\ub3c4\uc5d0 \ub530\ub77c \uc720\uccb4 \uc5ed\ud559 \ubc0f \uace0\uccb4 \uc5ed\ud559 \ubc94\uc8fc\uc5d0\uc11c \ub450 \uac00\uc9c0 \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc778 VideoPoet\uacfc Runway Gen 3\uc758 \uc131\uacf5 \ubc0f \uc2e4\ud328 \uc0ac\ub840\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubaa8\ub378 \ubaa8\ub450 \uc720\ub9ac\uc5d0 \ud398\uc778\ud2b8\ub97c \ubc14\ub974\ub294(VideoPoet) \ubc0f \uace0\ubb34 \uc624\ub9ac\uc5d0 \ube68\uac04 \uc561\uccb4\ub97c \ubd93\ub294(Runway Gen 3) \uc2dc\ub098\ub9ac\uc624\uc640 \uac19\uc774 \ubb3c\ub9ac\uc801\uc73c\ub85c \ud0c0\ub2f9\ud55c \ud504\ub808\uc784\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ub3d9\uc2dc\uc5d0 \uc774 \ubaa8\ub378\ub4e4\uc740 \uc0c1\uc790\uc5d0 \uacf5\uc774 \ub5a8\uc5b4\uc9c0\ub294 \uac83 \ub610\ub294 \uce7c\ub85c \uade4\uc744 \uc790\ub974\ub294 \uac83\uc744 \uc2dc\ubbac\ub808\uc774\uc158\ud558\ub294 \ub370 \uc2e4\ud328\ud569\ub2c8\ub2e4. \uc560\ub2c8\uba54\uc774\uc158 \ubc84\uc804\uc740 \uc5ec\uae30\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "\uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.09038/x8.png", "caption": "Figure 8: Illustration of recording setup (top) and perspectives (bottom).", "description": "\uadf8\ub9bc 8\uc740 \ub17c\ubb38\uc758 Physics-IQ \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc744 \uc218\uc9d1\ud558\uae30 \uc704\ud55c \ub179\ud654 \uc124\uc815\uacfc \uc138 \uac00\uc9c0 \ub2e4\ub978 \uac01\ub3c4(\uc67c\ucabd, \uc911\uc559, \uc624\ub978\ucabd)\uc5d0\uc11c \ucd2c\uc601\ud55c \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0c1\ub2e8\uc740 \uc138 \uac1c\uc758 \uce74\uba54\ub77c\uac00 \uc0bc\uac01\ub300\uc5d0 \uace0\uc815\ub418\uc5b4 \ubb3c\uccb4\uc758 \uc6c0\uc9c1\uc784\uc744 \ub2e4\uc591\ud55c \uc2dc\uc810\uc5d0\uc11c \ud3ec\ucc29\ud558\ub3c4\ub85d \ubc30\uce58\ub41c \ub179\ud654 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud558\ub2e8\uc740 \uac01\uac01\uc758 \uce74\uba54\ub77c \uc704\uce58\uc5d0\uc11c \ucea1\ucc98\ub41c \ub3d9\uc77c\ud55c \uc7a5\uba74\uc758 \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uad00\uc810\uc5d0\uc11c \ub3d9\uc77c\ud55c \ubb3c\ub9ac\uc801 \ud604\uc0c1\uc744 \uc5b4\ub5bb\uac8c \ub2e4\ub974\uac8c \ud3ec\ucc29\ud560 \uc218 \uc788\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 Physics-IQ \ub370\uc774\ud130\uc14b\uc774 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\uc5ec \ubaa8\ub378\uc758 \ubb3c\ub9ac\uc801 \uc774\ud574\ub3c4\ub97c \ubcf4\ub2e4 \ud3ec\uad04\uc801\uc73c\ub85c \ud3c9\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc74c\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "Physics-IQ benchmark"}, {"figure_path": "https://arxiv.org/html/2501.09038/extracted/6132070/figures/combined_setup_views.png", "caption": "Figure 9: The switch frames (here: center view only) of all scenarios in the Physics-IQ benchmark. A switch frame is the last conditioning frame before a model is asked to predict 5 seconds of future frames.", "description": "\uadf8\ub9bc 9\ub294 Physics-IQ \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \ubaa8\ub4e0 \uc2dc\ub098\ub9ac\uc624\uc758 '\uc2a4\uc704\uce58 \ud504\ub808\uc784'(Switch Frame)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2a4\uc704\uce58 \ud504\ub808\uc784\uc740 \ubaa8\ub378\uc774 \ud5a5\ud6c4 5\ucd08 \ub3d9\uc548\uc758 \uc601\uc0c1\uc744 \uc608\uce21\ud558\uae30 \uc804\uc5d0 \uc81c\uacf5\ub418\ub294 \ub9c8\uc9c0\ub9c9 \uc870\uac74 \ud504\ub808\uc784\uc785\ub2c8\ub2e4. \uc989, \ubaa8\ub378\uc740 \uc2a4\uc704\uce58 \ud504\ub808\uc784\uae4c\uc9c0\uc758 \uc601\uc0c1\uc744 \ubcf4\uace0 \uadf8 \ub2e4\uc74c 5\ucd08\uac04\uc758 \uc601\uc0c1\uc744 \uc608\uce21\ud574\uc57c \ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \uac01 \uc2dc\ub098\ub9ac\uc624\uc5d0 \ub300\ud55c \uc911\uc559 \uc2dc\uc810\uc758 \uc2a4\uc704\uce58 \ud504\ub808\uc784\ub9cc\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "Physics-IQ benchmark"}, {"figure_path": "https://arxiv.org/html/2501.09038/extracted/6132070/figures/all_scenarios_overview.png", "caption": "Figure 10: Since mean squared error (MSE) values can be hard to interpret, this figure shows the effect of a distortion applied to the scene, serving as a rough intuition for the effect of a MSE at different noise levels.", "description": "\uadf8\ub9bc 10\uc740 \ud3c9\uade0 \uc81c\uacf1 \uc624\ucc28(MSE) \uac12\uc774 \uc9c1\uad00\uc801\uc73c\ub85c \uc774\ud574\ud558\uae30 \uc5b4\ub824\uc6b8 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0, \uc774\ubbf8\uc9c0\uc5d0 \uc65c\uace1\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc591\ud55c \uc218\uc900\uc758 MSE \ub178\uc774\uc988\uac00 \uc774\ubbf8\uc9c0\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ub300\ub7b5\uc801\uc73c\ub85c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \uc2dc\uac01\uc801 \uc124\uba85\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \ub178\uc774\uc988\uac00 \uc5c6\ub294 \uc774\ubbf8\uc9c0\ubd80\ud130 MSE \uac12\uc774 \uc810\uc810 \ucee4\uc9d0\uc5d0 \ub530\ub77c \uc774\ubbf8\uc9c0\uac00 \uc65c\uace1\ub418\ub294 \uc815\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "Metrics for physical understanding"}]