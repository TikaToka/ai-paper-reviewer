[{"content": "| Win / Tie / Lose Rate % |\n|---|---|---|\n| 35.6 / 4.8 / **59.6** | 91.2 / 1.0 / 7.8  |  91.4 / 0.4 / 8.2 |\n| 91.6 / 0.2 / 8.2 | 90.2 / 0.6 / 9.2 | 92.6 / 0.6 / 6.8 |\n| 91.8 / 1.0 / 7.2 | 91.4 / 0.4 / 8.2 | 87.2 / 1.0 / 11.8 |", "caption": "Table 1: Base and SFT-initialized alignment methods on the Llama 3.1 8B model with the UF dataset. SFT-initialized methods demonstrate better performance compared to their traditional formulations without \u2112SFTsubscript\u2112SFT\\mathcal{L}_{\\mathrm{SFT}}caligraphic_L start_POSTSUBSCRIPT roman_SFT end_POSTSUBSCRIPT. Results marked with \u2020\u2020{\\dagger}\u2020 correspond to training with \u2112SFTsubscript\u2112SFT\\mathcal{L}_{\\mathrm{SFT}}caligraphic_L start_POSTSUBSCRIPT roman_SFT end_POSTSUBSCRIPT, using the best hyperparameters: lr=1\u00d710\u22126lr1superscript106\\text{lr}=1\\times 10^{-6}lr = 1 \u00d7 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT for ORPO and lr=7\u00d710\u22127lr7superscript107\\text{lr}=7\\times 10^{-7}lr = 7 \u00d7 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT for ASFT. For other setups, the best hyperparameters are: lr=5\u00d710\u22127lr5superscript107\\text{lr}=5\\times 10^{-7}lr = 5 \u00d7 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT for standard SFT ORPO/ASFT, and lr=1\u00d710\u22125lr1superscript105\\text{lr}=1\\times 10^{-5}lr = 1 \u00d7 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT/6\u00d710\u221266superscript1066\\times 10^{-6}6 \u00d7 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT for Base ORPO/ASFT.", "description": "\ud45c 1\uc740 Llama 3.1 8B \ubaa8\ub378\uacfc UF \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uae30\ubcf8 \ubc0f SFT \ucd08\uae30\ud654 \uc815\ub82c \uc54c\uace0\ub9ac\uc998\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SFT \ucd08\uae30\ud654 \ubc29\ubc95\uc740 \uae30\uc874\uc758 \u2112SFT\uac00 \uc5c6\ub294 \ubc29\ubc95\uc5d0 \ube44\ud574 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \u2020 \ud45c\uc2dc\ub294 \ucd5c\uc801\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(ORPO\uc758 \uacbd\uc6b0 lr=1\u00d710\u207b\u2076, ASFT\uc758 \uacbd\uc6b0 lr=7\u00d710\u207b\u2077)\ub97c \uc0ac\uc6a9\ud558\uc5ec \u2112SFT\ub85c \ud559\uc2b5\ud55c \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub2e4\ub978 \uc124\uc815\uc758 \uacbd\uc6b0 \ucd5c\uc801 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 \ud45c\uc900 SFT ORPO/ASFT\uc5d0 \ub300\ud574 lr=5\u00d710\u207b\u2077, \uae30\ubcf8 ORPO/ASFT\uc5d0 \ub300\ud574 lr=1\u00d710\u207b\u2075/6\u00d710\u207b\u2076\uc785\ub2c8\ub2e4.", "section": "4. Results"}, {"content": "| Init | Method | LC% (std) | WR% (std) | AH% (CI) |\n|---|---|---|---|---|\n| Base | SFT | 6.7 (0.43) | 4.5 (0.63) | 3.5 (-0.7, 0.8) |\n| SFT | ORPO | **24.1** (0.84) | **17.8** (1.17) | **15.3** (-1.6, 1.8) |\n| SFT | ASFT | 16.4 (0.72) | 11.9 (0.99) | 10.6 (-1.2, 1.3) |\n| Base | ORPO | 14.8 (0.71) | 10.3 (0.95) | 8.4 (-1.3, 1.3) |\n| Base | ASFT | 14.5 (0.73) | 10.2 (0.94) | 7.5 (-1.1, 1.2) |\n| SFT | ORPO<sup>\u2020</sup> | 13.4 (0.69) | 9.3 (0.91) | 7.7 (-0.9, 1.1) |\n| SFT | ASFT<sup>\u2020</sup> | 11.4 (0.63) | 7.5 (0.83) | 7.5 (-1.1, 1.1) |\n| SFT | DPO | **23.4** (0.85) | **20.0** (1.18) | **17.5** (-1.8, 1.8) |", "caption": "Table 2: AlpacaEval 2 and ArenaHard Results for Llama 3.2 3B and Llama 3.1 8B UF. The SFT model was trained on the UltraChat dataset. The best hyperparameters for each method were selected according to Section\u00a04.2. Bold values indicate the best performance for each benchmark, while underlined values represent the second-best performance. See Section 5.3 for more details.", "description": "\ud45c 2\ub294 Llama 3.2 3B \ubc0f Llama 3.1 8B \ubaa8\ub378\uc5d0 \ub300\ud55c AlpacaEval 2 \ubc0f ArenaHard \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  SFT(Supervised Fine-Tuning) \ubaa8\ub378\uc740 UltraChat \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud559\uc2b5\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc5d0 \ub300\ud55c \ucd5c\uc801\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 4.2\uc808\uc5d0 \ub530\ub77c \uc120\ud0dd\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uad75\uc740 \uac12\uc740 \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ucd5c\uace0 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uace0, \ubc11\uc904 \uce5c \uac12\uc740 \ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.3\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4. Experimental Setup"}, {"content": "| Method | Llama 3.2 3B UF |  |  | Llama 3.1 8B UF |  |  |\n|---|---|---|---|---|---|---|\n|  | AlpacaEval 2 | ArenaHard |  | AlpacaEval 2 | ArenaHard |  |\n|---|---|---|---|---|---|---|\n|  | LC% (std) | WR% (std) | WR% (CI) | LC% (std) | WR% (std) | WR% (CI) |\n|---|---|---|---|---|---|---|\n| SFT | 5.02 (0.34) | 3.21 (0.55) | 1.4 (-0.4, 0.4) | 10.27 (0.54) | 5.44 (0.70) | 2.6 (-0.5, 0.6) |\n| DPO | 11.43 (0.58) | 11.79 (0.99) | 6.8 (-1.0, 0.9) | 26.82 (0.77) | 23.69 (1.25) | 19.0 (-1.9, 1.8) |\n| IPO | 11.24 (0.60) | 11.67 (1.01) | 6.8 (-1.0, 1.1) | 28.18 (0.83) | 24.43 (1.26) | 19.1 (-1.6, 1.5) |\n| SimPO | 10.56 (0.44) | 11.94 (0.95) | 6.4 (-1.0, 1.1) | 27.65 (0.77) | 25.62 (1.29) | 21.5 (-1.9, 1.9) |\n| ORPO | 10.67 (0.50) | 12.23 (0.97) | 6.6 (-1.0, 1.1) | 28.25 (0.71) | 28.59 (1.33) | 20.9 (-2.0, 2.0) |\n| APO Zero | 10.36 (0.53) | 11.22 (0.98) | 6.0 (-1.0, 0.9) | 23.15 (0.76) | 19.03 (1.18) | 17.3 (-1.8, 1.8) |\n| NCA | 10.33 (0.53) | 11.02 (0.97) | 5.1 (-0.7, 0.8) | 23.21 (0.80) | 18.67 (1.17) | 15.1 (-1.5, 1.6) |\n| Cal-DPO | 10.62 (0.57) | 10.15 (0.94) | 4.8 (-0.9, 0.9) | 23.19 (0.82) | 18.85 (1.18) | 15.2 (-1.5, 1.6) |\n| ASFT | 10.63 (0.55) | 9.21 (0.88) | 5.1 (-0.9, 0.9) | 20.82 (0.79) | 16.34 (1.13) | 13.5 (-1.6, 1.5) |", "caption": "Table 3: Methods that include (\u2713) or omit (\u2717) length-based probability normalization in their original formulation.", "description": "\uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc9c1\uc811 \uc815\ub82c \uc54c\uace0\ub9ac\uc998(Direct Alignment Algorithms, DAAs)\ub4e4\uc774 \uc6d0\ub798 \uc81c\uc2dc\ub418\uc5c8\uc744 \ub54c \uae38\uc774 \uae30\ubc18 \ud655\ub960 \uc815\uaddc\ud654(length-based probability normalization)\ub97c \uc0ac\uc6a9\ud588\ub294\uc9c0 \uc5ec\ubd80\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \u2713\ub294 \uae38\uc774 \uae30\ubc18 \uc815\uaddc\ud654\ub97c \uc0ac\uc6a9\ud588\uc74c\uc744, \u2717\ub294 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \ud45c\ub97c \ud1b5\ud574 \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \uc6d0\ub798 \uc124\uacc4\uc5d0\uc11c\uc758 \ucc28\uc774\uc810\uc744 \uba85\ud655\ud788 \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "A.1. Probability Normalization"}, {"content": "| Method | Use normalization |\n|---|---| \n| DPO (Rafailov et al., 2023) | \u2717 |\n| IPO (Azar et al., 2023) | \u2717 |\n| SimPO (Meng et al., 2024) | \u2713 |\n| NCA (Chen et al., 2024) | \u2717 |\n| Cal-DPO (Xiao et al., 2024) | \u2717 |\n| APO-Zero (D\u2019Oosterlinck et al., 2024) | \u2717 |\n| ORPO (Hong et al., 2024) | \u2713 |\n| ASFT (Wang et al., 2024) | \u2713 |", "caption": "Table 4: Representative training hyperparameters for Llama 3.2 3B and Llama 3.1 8B models.", "description": "\uc774 \ud45c\ub294 Llama 3.2 3B \ubc0f Llama 3.1 8B \ubaa8\ub378\uc5d0 \ub300\ud55c \ub300\ud45c\uc801\uc778 \ud6c8\ub828 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ucd5c\ub300 \ud1a0\ud070 \uae38\uc774, \uc5d0\ud3ec\ud06c \uc218, \ud559\uc2b5\ub960(SFT, \uae30\ubcf8 \ucd08\uae30\ud654, \uc815\ub82c), \ucd5c\uc801\ud654\uae30, \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(Adam \u03b21, \u03b22), \ubc30\uce58 \ud06c\uae30, \ud559\uc2b5 \uc77c\uc815, \uc6dc\uc5c5 \ube44\uc728, \ucd5c\ub300 \uadf8\ub798\ub514\uc5b8\ud2b8 \ub188, \uba54\ubaa8\ub9ac \ucd5c\uc801\ud654, \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998 \ub4f1 \ub2e4\uc591\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 Llama \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294 \ub370 \uc0ac\uc6a9\ub41c \uc124\uc815\uc744 \uc790\uc138\ud788 \uc124\uba85\ud558\uc5ec \uc7ac\ud604\uc131\uc744 \ub192\uc774\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "A.2. Training Details"}, {"content": "| Hyperparameter | Value |\n|---|---| \n| Max Tokens Length | 1024 (TL;DR setup), 4096 (UF setup) |\n| Epochs | 1 (or 2 when specified) |\n| Learning Rate (SFT) | 6.0 \u00d7 10<sup>-6</sup> |\n| Learning Rate (Base Init.) | {6.0 \u00d7 10<sup>-6</sup>, 8.0 \u00d7 10<sup>-6</sup>, 1.0 \u00d7 10<sup>-5</sup>} |\n| Learning Rate (Alignment) | {3.0 \u00d7 10<sup>-7</sup>, 5.0 \u00d7 10<sup>-7</sup>, 7.0 \u00d7 10<sup>-7</sup>, 1.0 \u00d7 10<sup>-6</sup>} |\n| Optimizer | Adam (Kingma & Ba, 2014) |\n| Adam \u03b2<sub>1</sub> | 0.9 |\n| Adam \u03b2<sub>2</sub> | 0.95 |\n| Batch Size | 128 |\n| Learning Schedule | Linear Decay |\n| Warm-up Ratio | 0.03 |\n| Max Gradient Norm | 2 |\n| Memory Optimization | DeepSpeed (Rasley et al., 2020) |\n| Attention Mechanism | Flash Attention 2 (Dao, 2023) |", "caption": "Table 5: Summary of dataset sizes used for training and validation.", "description": "\uc774 \ud45c\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc138 \uac00\uc9c0 \ub370\uc774\ud130\uc14b(UltraChat, UltraFeedback, Reddit TL;DR)\uc758 \ud06c\uae30\ub97c \uc694\uc57d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc740 \ud6c8\ub828\uacfc \uac80\uc99d\uc5d0 \uc0ac\uc6a9\ub41c \uc608\uc81c\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. Reddit TL;DR \ub370\uc774\ud130\uc14b\uc740 SFT(Supervised Fine-Tuning)\uc640 \uc120\ud638\ub3c4(Preference) \ud3c9\uac00\uc5d0 \uac01\uac01 \ub2e4\ub978 \ud06c\uae30\uc758 \ub370\uc774\ud130\uac00 \uc0ac\uc6a9\ub418\uc5c8\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "A. Implementation Details"}, {"content": "| Dataset | Training Examples | Validation Examples |\n|---|---|---|\n| UltraChat | 207,865 | 23,110 |\n| UltraFeedback | 61,135 | 2,000 |\n| Reddit TL;DR (SFT) | 41,947 | 11,941 |\n| Reddit TL;DR (Preference) | 73,396 | 21,198 |", "caption": "Table 6: Range of \u03b2\ud835\udefd\\betaitalic_\u03b2 values tested for each DAA method on all scenarios.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uc124\uc815\uc5d0\uc11c \ub2e4\uc591\ud55c \uc9c1\uc811 \uc815\ub82c \uc54c\uace0\ub9ac\uc998(DAA)\uc5d0 \ub300\ud574 \ud14c\uc2a4\ud2b8\ub41c \u03b2 \uac12\uc758 \ubc94\uc704\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 DAA \uba54\uc11c\ub4dc\uc5d0 \ub300\ud574 \uc5ec\ub7ec \uac1c\uc758 \u03b2 \uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5\uacfc KL \ubc1c\uc0b0 \uac04\uc758 \uc808\ucda9\uc744 \uc870\uc0ac\ud588\uc2b5\ub2c8\ub2e4.  \u03b2 \uac12\uc740 \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \ucd5c\uc801 \uc131\ub2a5\uc744 \ucc3e\uae30 \uc704\ud574 \uc2e0\uc911\ud558\uac8c \uc120\ud0dd\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "A.2.2. \u03b2-Sensitivity Experiments"}, {"content": "| Method | \\beta Values Tested |\n|---|---| \n| DPO | {0.001, 0.003, 0.005, 0.01, 0.05, 0.1} |\n| IPO | {0.0007, 0.001, 0.005, 0.01, 0.05, 0.1} |\n| SimPO | {0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0} |\n| ORPO | {0.05, 0.1, 0.2, 0.5, 1.0, 2.0} |\n| ASFT | {0.05, 0.1, 0.2, 0.5, 1.0, 2.0} |\n| APO-Zero | {0.001, 0.003, 0.005, 0.01, 0.05, 0.1, 0.2} |\n| Cal-DPO | {0.00005, 0.0001, 0.0003, 0.0005, 0.001, 0.003} |\n| NCA | {0.0001, 0.0003, 0.0005, 0.001, 0.005, 0.007, 0.01, 0.03, 0.05} |", "caption": "Table 7: Best hyperparameters for each DAA method across setups.", "description": "\ud45c 7\uc740 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uc124\uc815(Llama 3.2 3B TL;DR, Llama 3.2 3B UF, Llama 3.1 8B UF)\uc5d0\uc11c \ub2e4\uc591\ud55c \uc9c1\uc811 \uc815\ub82c \uc54c\uace0\ub9ac\uc998(DAA)\uc5d0 \ub300\ud574 \ucd5c\uc801\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 DAA \ubc29\ubc95\uacfc \uc124\uc815\uc5d0 \ub300\ud574 \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc744 \ub2ec\uc131\ud55c \ud559\uc2b5\ub960\uacfc \ubca0\ud0c0(\u03b2) \uac12\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \uc54c\uace0\ub9ac\uc998\uc758 \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud558\ub294 \ub370 \uc0ac\uc6a9\ub41c \uad6c\uccb4\uc801\uc778 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uc124\uc815"}, {"content": "Method | Llama 3.2 3B TL;DR |  | Llama 3.2 3B UF |  | Llama 3.1 8B UF |  | \n---|---|---|---|---|---|---\nDPO | 7.0x10^-7 | 0.05 | 1.0x10^-6 | 0.01 | 1.0x10^-6 | 0.003 \nIPO | 1.0x10^-6 | 0.005 | 7.0x10^-7 | 0.001 | 1.0x10^-6 | 0.001 \nSimPO | 3.0x10^-7 | 0.5 | 7.0x10^-7 | 1.0 | 6.0x10^-7 | 1.0 \nORPO | 3.0x10^-7 | 0.5 | 5.0x10^-7 | 0.2 | 5.0x10^-7 | 0.5 \nASFT | 3.0x10^-7 | 0.001 | 1.0x10^-6 | 0.2 | 7.0x10^-7 | 0.1 \nAPO Zero | 3.0x10^-7 | 0.001 | 3.0x10^-7 | 0.005 | 3.0x10^-7 | 0.003 \nNCA | 3.0x10^-7 | 0.0001 | 3.0x10^-7 | 0.0005 | 3.0x10^-7 | 0.0003 \nCal-DPO | 3.0x10^-7 | 0.00003 | 5.0x10^-7 | 0.0003 | 3.0x10^-7 | 0.0003", "caption": "Table 8: Generation hyperparameters for Llama 3.1 8B and Llama 3.2 3B models.", "description": "\uc774 \ud45c\ub294 Llama 3.1 8B \ubc0f Llama 3.2 3B \ubaa8\ub378\uc5d0 \uc0ac\uc6a9\ub41c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uad00\ub828 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294 \uc628\ub3c4(temperature), Top-k, Top-p \ubc0f \ucd5c\ub300 \ud1a0\ud070 \uc218(Max New Tokens) \ub4f1\uc758 \uac12\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70,  Llama 3.1 8B\uc640 Llama 3.2 3B \ubaa8\ub378 \uac01\uac01\uc5d0 \ub300\ud574 \uc11c\ub85c \ub2e4\ub978 \uc124\uc815\uc774 \uc788\uc74c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc740 \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud558\ub294 \ubc29\uc2dd\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc911\uc694\ud55c \uc694\uc18c\ub4e4\uc785\ub2c8\ub2e4.  \uc608\ub97c \ub4e4\uc5b4, \uc628\ub3c4\uac00 \ub192\uc744\uc218\ub85d \uc0dd\uc131\ub418\ub294 \ud14d\uc2a4\ud2b8\ub294 \ub354\uc6b1 \ub2e4\uc591\ud558\uace0 \uc608\uce21 \ubd88\uac00\ub2a5\ud574\uc9c0\ub294 \ubc18\uba74, Top-k\ub098 Top-p\ub294 \uc0dd\uc131 \uacfc\uc815\uc758 \ubb34\uc791\uc704\uc131\uc744 \uc870\uc808\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \ucd5c\ub300 \ud1a0\ud070 \uc218\ub294 \uc0dd\uc131\ub418\ub294 \ud14d\uc2a4\ud2b8\uc758 \ucd5c\ub300 \uae38\uc774\ub97c \uc81c\ud55c\ud569\ub2c8\ub2e4.", "section": "A. Implementation Details"}]