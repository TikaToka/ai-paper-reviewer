{"references": [{"fullname_first_author": "T. Xie", "paper_title": "Sorry-bench: Systematically evaluating large language model safety refusal behaviors", "publication_date": "2024-06-14", "reason": "This paper introduces a benchmark for evaluating the safety refusal behaviors of LLMs, a crucial aspect of LLM safety testing which is also discussed in the target paper."}, {"fullname_first_author": "X. Yuan", "paper_title": "S-eval: Automatic and adaptive test generation for benchmarking safety evaluation of large language models", "publication_date": "2024-05-14", "reason": "This paper proposes an automatic and adaptive test generation method for LLM safety evaluation, addressing the challenges of creating comprehensive and relevant test cases which are also discussed in the target paper."}, {"fullname_first_author": "Z. Zhang", "paper_title": "Safetybench: Evaluating the safety of large language models with multiple choice questions", "publication_date": "2023-09-07", "reason": "This paper presents SafetyBench, a benchmark for evaluating LLM safety using multiple-choice questions, offering a structured approach to assessing different aspects of LLM safety and is referenced in the target paper."}, {"fullname_first_author": "W. Zhang", "paper_title": "Chisafetybench: A chinese hierarchical safety benchmark for large language models", "publication_date": "2024-06-10", "reason": "This paper focuses on evaluating the safety of LLMs in the Chinese language, highlighting the importance of considering cultural and linguistic factors in LLM safety testing, which is important for the context of the target paper."}, {"fullname_first_author": "Z. Ying", "paper_title": "Safebench: A safety evaluation framework for multimodal large language models", "publication_date": "2024-10-18", "reason": "This paper extends the evaluation of LLM safety to multimodal models, reflecting the growing trend of multimodal LLMs and is relevant to the target paper."}]}