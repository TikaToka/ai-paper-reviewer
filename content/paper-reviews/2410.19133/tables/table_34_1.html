<br><table id='10' style='font-size:18px'><tr><td>Hyperparameter</td><td>Value</td></tr><tr><td>Data Type</td><td>bf16</td></tr><tr><td>Number of Epochs</td><td>1</td></tr><tr><td>Optimizer Type</td><td>AdamW</td></tr><tr><td>Weight Decay</td><td>0.0</td></tr><tr><td>Learning Rate</td><td>1e-5</td></tr><tr><td>End Learning Rate</td><td>1e-6</td></tr><tr><td>Warmup Ratio</td><td>0.03</td></tr><tr><td>Accumulate Gradient Steps</td><td>4</td></tr><tr><td>Sequence Length</td><td>4096</td></tr><tr><td>Batch Size</td><td>128</td></tr></table>