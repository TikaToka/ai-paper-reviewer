{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-08-01", "reason": "This paper explores video generation models as a tool for world simulation, a concept relevant to the current paper's aim of generating long, coherent video sequences."}, {"fullname_first_author": "Jake Bruce", "paper_title": "Genie: Generative interactive environments", "publication_date": "2024-01-01", "reason": "This work introduces Genie, a generative interactive model that shares similarities with the current paper's approach in handling masked frames during training and inference."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "MaskGIT: Masked generative image transformer", "publication_date": "2022-01-01", "reason": "The paper introduces MaskGIT, a foundational masked modeling approach for image generation, which heavily influences the current paper's intra-frame generation strategy."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "Muse: Text-to-image generation via masked generative transformers", "publication_date": "2023-01-01", "reason": "Muse extends masked modeling to text-to-image generation, a related task that shares conceptual similarities with the paper's approach to autoregressive video generation."}, {"fullname_first_author": "Boyuan Chen", "paper_title": "Diffusion forcing: Next-token prediction meets full-sequence diffusion", "publication_date": "2024-07-01", "reason": "This paper explores diffusion forcing, a training technique relevant to the current paper's discussion of teacher forcing and its impact on autoregressive video generation."}]}