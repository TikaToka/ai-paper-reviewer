[{"content": "| Capability | Domain | Task | Evaluation Dataset | Size | Reference |\n|---|---|---|---|---|---| \n| **Unseen - Similar** |  |  |  |  |  |\n| Tasks | Finance | Sentiment Analysis | FPB | 970 | Malo et al. (2014) | \n|  |  |  | FiQA SA | 235 | Maia et al. (2018) | \n|  |  | Monetary policy Stance | FOMC | 496 | Shah et al. (2023) | \n|  |  | Named entity recognition | NER | 98 | Alvarado et al. (2015) | \n|  |  | Abstractive Summarization | EDTSUM | 2,000 | Zhou et al. (2021) | \n| *Total* |  |  |  | 3,799 |  | \n| **Unseen - Novel** |  |  |  |  |  |\n| Concept | General | Knowledge Recall | MMLU | 14,042 | (Hendrycks et al., 2021) | \n|  |  |  | AI2-ARC | 3,548 | Clark et al. (2018) | \n|  |  |  | Nq-open | 7,842 | Kwiatkowski et al. (2019) | \n|  | Finance |  | **MMLU-Finance** | 1,460 | - | \n| Tasks | Finance | Extractive Summarization | Flare-ECTSUM | 495 | Mukherjee et al. (2022) | \n|  |  | ESG Issue Classification | MLESG | 300 | Chen et al. (2023b) | \n|  |  | Rumour Detection | MA | 500 | Yang et al. (2020) | \n|  |  | Stock Movement Prediction | SM-Bigdata | 1,470 | Soun et al. (2022) | \n|  |  |  | SM-ACL | 3,720 | Xu and Cohen (2018) | \n|  |  |  | SM-CIKM | 1,140 | Wu et al. (2018) | \n|  |  | Fraud Detection | CRA-CCF | 2,280 | Feng et al. (2024) | \n|  |  |  | CRA-CCFraud | 2,100 | Feng et al. (2024) | \n|  |  | Credit Scoring | Flare-German | 200 | Hofmann (1994) | \n|  |  |  | Flare-Astralian | 139 | Quinlan (1987) | \n|  |  |  | CRA-LendingClub | 2,690 | Feng et al. (2024) | \n|  |  | Distress Identification | CRA-Polish | 1,740 | Feng et al. (2024) | \n|  |  |  | CRA-Taiwan | 1,370 | Feng et al. (2024) | \n|  |  | Claim Analysis | CRA-ProroSeguro | 2,380 | Feng et al. (2024) | \n|  |  |  | CRA-TravelInsurance | 2,530 | Feng et al. (2024) | \n|  |  | Tabular QA | Flare-TATQA | 1,670 | Zhu et al. (2021) | \n|  |  | Open QA | Finance Bench | 150 | Islam et al. (2023) | \n| IF/Chat | General | Precise IF | MT-bench | 80 | Zheng et al. (2023) | \n| Reasoning | Math | Reasoning | MathQA | 2,985 | Amini et al. (2019a) | \n|  | General | Social Reasoning | Social-IQA | 2,636 | Welbl et al. (2017) | \n|  |  | Common Reasoning | Open-book-qa | 500 | Mihaylov et al. (2018) | \n|  |  |  | Hellaswag | 10,003 | Zellers et al. (2019) | \n|  |  |  | Winogrande | 1,767 | Sakaguchi et al. (2019) | \n|  |  |  | PIQA | 3,000 | Bisk et al. (2020) | \n|  | Finance | Exam | CFA-Easy | 1,030 | Link | \n|  |  |  | **CFA-Challenge** | 90 | - | \n| *Total* |  |  |  | 91,872 |  |", "caption": "Table 1: Summary of our evaluation dataset. New datasets released with FinDaP are color-highlighted for emphasis.", "description": "\ud45c 1\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc758 \uc694\uc57d\ubcf8\uc785\ub2c8\ub2e4.  FinDaP\uc640 \ud568\uaed8 \uc0c8\ub86d\uac8c \uacf5\uac1c\ub41c \ub370\uc774\ud130\uc14b\uc740 \uac15\uc870\ub97c \uc704\ud574 \uc0c9\uc0c1\uc73c\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ud3c9\uac00 \uc791\uc5c5\uc5d0 \ub300\ud55c \ub3c4\uba54\uc778 \ud2b9\uc815 \uc791\uc5c5, \ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30, \ucc38\uace0 \ubb38\ud5cc \uc815\ubcf4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b\uc740 \uc720\uc0ac\ud55c \uc791\uc5c5\uacfc \uc0c8\ub85c\uc6b4 \uc791\uc5c5\uc73c\ub85c \ub098\ub258\uc5b4\uc838 \uc788\uc73c\uba70, \uac01\uac01\uc5d0 \ub300\ud55c \uc5ec\ub7ec \ud558\uc704 \uc791\uc5c5\uc774 \uc138\ubd84\ud654\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \uc885\ud569\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2 FINDAP Setup"}, {"content": "| Finance LLM | Capability | Continue Pre-training | Instruction Tuning | Preference Alignment | Task | Method | Reasoning Task | Direct Answer | CoT Answer |\n|---|---|---|---|---|---|---|---|---|---|---|\n| FinTral | Concept, Task | \u2718 | \u2714 | \u2718 | \u2714 | \u2714 | \u2718 | \u2718 | \u2714 | \u2718 |\n| PIXIU | Task | \u2718 | \u2718 | \u2718 | \u2714 | \u2718 | \u2718 | \u2718 | \u2714 | \u2718 |\n| FinLLM | Concept, Task | \u2714 | \u2714 | \u2718 | \u2714 | \u2718 | \u2718 | \u2718 | \u2714 | \u2718 |\n| AdaptLLM | Concept | \u2718 | \u2714 | \u2718 | \u2718 | \u2718 | \u2718 | \u2718 | \u2714 | \u2718 |\n| Llama-Fin | Concept, IF/Chat, Task, Reasoning | \u2714 | \u2714 | \u2714 | \u2714 | \u2714 | \u2714 | \u2714 | \u2714 | \u2714 |", "caption": "Table 2: Comparison between Llama-Fin with other open finance LLMs.", "description": "\ud45c 2\ub294 Llama-Fin\uacfc \ub2e4\ub978 \uacf5\uac1c \uae08\uc735 LLM\ub4e4\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  Llama-Fin\uc758 \uae30\ub2a5(\uac1c\ub150, \uacfc\uc81c, \ucd94\ub860, \uc9c0\uc2dc \ub530\ub974\uae30, \ucc44\ud305 \ub4f1)\uacfc \ub2e4\ub978 \ubaa8\ub378\ub4e4(FinTral, PIXIU, FinLLM, AdaptLLM)\uc758 \uae30\ub2a5\uc744 \ube44\uad50\ud558\uc5ec Llama-Fin\uc758 \uac15\uc810\uacfc \ucc28\ubcc4\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc774 \uc9c0\ub2cc \uae30\ub2a5\uacfc \uc0ac\uc6a9\ub41c \ud559\uc2b5 \ubc29\ubc95(\uc9c0\uc18d\uc801 \uc0ac\uc804 \ud6c8\ub828, \uc9c0\uc2dc \uc870\uc815, \uc120\ud638\ub3c4 \uc815\ub82c)\uc744 \ub098\uc5f4\ud558\uc5ec, Llama-Fin\uc774 \uccb4\uacc4\uc801\uc778 \uc124\uacc4\uc640 \ud3ec\uad04\uc801\uc778 \ud3c9\uac00\ub97c \ud1b5\ud574 \ub2e4\ub978 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud568\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "2 FINDAP Setup"}, {"content": "| Concept, IF/Chat | Task, Reasoning |\n|---|---|", "caption": "Table 3: Summary of curated texts. New datasets released with FinDaP are color-highlighted for emphasis.", "description": "\ud45c 3\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud14d\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc694\uc57d\ubcf8\uc785\ub2c8\ub2e4.  FinDaP\uc5d0\uc11c \uc0c8\ub86d\uac8c \uacf5\uac1c\ub41c \ub370\uc774\ud130\uc14b\uc740 \uac15\uc870\ub97c \uc704\ud574 \uc0c9\uc0c1\uc774 \ub2e4\ub974\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub370\uc774\ud130\uc14b \uc774\ub984, \ub370\uc774\ud130 \uc720\ud615(\uc77c\ubc18 \ub3c4\uba54\uc778 \ud14d\uc2a4\ud2b8, \ub3c4\uba54\uc778 \ud2b9\uc815 \ud14d\uc2a4\ud2b8), \uadf8\ub9ac\uace0 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30(\ud1a0\ud070 \uc218)\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uc815\ubcf4\ub294 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uad6c\uc131\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "2 FINDAP Setup"}, {"content": "| Capability | Domain | CPT Dataset | Size | Reference |\n|---|---|---|---|---|\n| Concept | General | NaturalInstrution | 100,000 | Mishra et al. (2022) |\n|  |  | PromptSource | 100,000 | Bach et al. (2022) |\n|  |  | Math | 29,837 | Amini et al. (2019b) |\n|  |  | Aqua | 97,500 | Ling et al. (2017) |\n|  |  | CREAK | 10,200 | Onoe et al. (2021) |\n|  |  | ESNLI | 549,367 | Camburu et al. (2018) |\n|  |  | QASC | 8,130 | Khot et al. (2020) |\n|  |  | SODA | 1,190,000 | Kim et al. (2022) |\n|  |  | StrategyQA | 2,290 | Geva et al. (2021) |\n|  |  | UnifiedSKG | 779,000 | Xie et al. (2022) |\n|  |  | GSM8K | 7,470 | Cobbe et al. (2021) |\n|  |  | ApexInstr | 1,470,000 | Huang et al. (2024b) |\n|  |  | DeepmindMath | 379,000 | Saxton (2019) |\n|  |  | DialogueStudio | 1,070,000 | Zhang et al. (2023) |\n|  | Finance | Fineweb-Fin | 4,380,000 | - |\n|  |  | Book-Fin | 4,500 | - |\n| Total |  |  | 10,177,294 |  |", "caption": "Table 4: Summary of our curated prompts. New datasets released with FinDaP are color-highlighted for emphasis. For datasets without formal references but only a URL, we provide their links.", "description": "\ud45c 4\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8 \ub370\uc774\ud130\uc14b\uc744 \uc694\uc57d\ud55c \ud45c\uc785\ub2c8\ub2e4. FinDaP\ub97c \ud1b5\ud574 \uc0c8\ub86d\uac8c \uacf5\uac1c\ub41c \ub370\uc774\ud130\uc14b\uc740 \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc77c\ubd80 \ub370\uc774\ud130\uc14b\uc740 \uacf5\uc2dd\uc801\uc778 \ucc38\uace0 \ubb38\ud5cc\uc774 \uc5c6\uace0 URL\ub9cc \uc81c\uacf5\ub418\ub294 \uacbd\uc6b0\ub3c4 \uc788\ub294\ub370, \uc774 \ud45c\uc5d0\uc11c\ub294 \ud574\ub2f9 URL\uc744 \ud568\uaed8 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uc989, \uc774 \ud45c\ub294 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c \ud504\ub86c\ud504\ud2b8\ub4e4\uc758 \ucd9c\ucc98\uc640 \ud06c\uae30\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, \ubaa8\ub378 \ud559\uc2b5 \uacfc\uc815\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub3d5\uace0 \uc7ac\ud604\uc131\uc744 \ub192\uc774\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4. \ud2b9\ud788, \ub3c4\uba54\uc778 \ud2b9\ud654\ub41c \ud504\ub86c\ud504\ud2b8\uc640 \uc77c\ubc18\uc801\uc778 \ud504\ub86c\ud504\ud2b8\uc758 \ube44\uc728\uc744 \ud30c\uc545\ud558\ub294\ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "2 FINDAP Setup"}, {"content": "| Capability | Domain | Task | IT Dataset | Size | Reference |\n|---|---|---|---|---|---| \n| Tasks | Finance | Relation Cls. | FingptFinred | 27,600 | Sharma et al. (2022) |\n|  |  | NER | FingptNERCls | 13,500 | Yang et al. (2023) |\n|  |  |  | FingptNER | 511 | Alvarado et al. (2015) |\n|  |  | Headline Cls. | FingptHeadline | 82,200 | Sinha et al. (2020) |\n|  |  | Sentiment Cls. | SentimentCls | 47,600 | Yang et al. (2023) |\n|  |  |  | SentimentTra | 76,800 | Yang et al. (2023) |\n|  |  | Summariz. | TradeTheEvent | 258,000 | Zhou et al. (2021) |\n| IF/Chat | General | IF/Chat | SelfInstruct | 82,000 | Wang et al. (2022) |\n|  |  |  | SlimOrca | 518,000 | Lian et al. (2023) |\n|  |  |  | UltraChat | 774,000 | Ding et al. (2023) |\n|  |  |  | ShareGPT | 100,000 | Link |\n|  | Finance | QA | FinanceInstruct | 178,000 | Link |\n|  |  |  | FingptConvfinqa | 8,890 | Chen et al. (2022) |\n|  |  |  | FlareFinqa | 6,250 | Chen et al. (2021) |\n|  |  |  | FlareFiqa | 17,100 | Yang et al. (2023) |\n| Reasoning | Math | QA | OrcaMath | 200,000 | Mitra et al. (2024) |\n|  |  |  | MetaMathQA | 395000 | Yu et al. (2023) |\n|  |  |  | MathInstruct | 262,000 | Xiang Yue (2023) |\n|  | Code | QA | MagicodeInstruct | 111,000 | Luo et al. (2023) |\n|  | Finance | CFA Exam | Exercise | 2,950 | - |\n| Total |  |  |  | 3,161,401 |  |", "caption": "Table 5: Final recipe of Llama-Fin. The joint training of CPT and IT is structured into two groups, with each group undergoing joint training sequentially. The second group utilizes higher-quality data (sourced from books), following the typical curriculum training practice\u00a0(Gao et\u00a0al., 2024). For PA, we employ a modified DPO loss with an additional\nnegative log-likelihood term, similar to Pang et\u00a0al. (2024), as it has shown to be more effective than relying solely on the original DPO loss.", "description": "\ud45c 5\ub294 Llama-Fin\uc758 \ucd5c\uc885 \ud559\uc2b5 \ub808\uc2dc\ud53c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. CPT\uc640 IT\uc758 \uacb0\ud569 \ud559\uc2b5\uc740 \ub450 \uadf8\ub8f9\uc73c\ub85c \ub098\ub258\uc5b4 \uc21c\ucc28\uc801\uc73c\ub85c \uc9c4\ud589\ub418\uba70, \ub450 \ubc88\uc9f8 \uadf8\ub8f9\uc740 Gao et al.(2024)\uc758 \ucee4\ub9ac\ud058\ub7fc \ud559\uc2b5 \ubc29\uc2dd\uc5d0 \ub530\ub77c \ucc45\uc5d0\uc11c \uc5bb\uc740 \uace0\ud488\uc9c8 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. PA\uc758 \uacbd\uc6b0 Pang et al.(2024)\uacfc \uc720\uc0ac\ud558\uac8c \uc218\uc815\ub41c DPO \uc190\uc2e4 \ud568\uc218\uc5d0 \ucd94\uac00\uc801\uc778 \uc74c\uc758 \ub85c\uadf8 \uc6b0\ub3c4 \ud56d\uc744 \uc0ac\uc6a9\ud558\ub294\ub370, \uc774\ub294 \uae30\uc874 DPO \uc190\uc2e4\ub9cc \uc0ac\uc6a9\ud558\ub294 \uac83\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4.", "section": "4 \ucd5c\uc885 \ub808\uc2dc\ud53c \ubc0f \ud3c9\uac00"}, {"content": "| Continual Pre-training (CPT) and Instruction Tuning (IT) |\n|---|---|---|\n| **Data** | 50% CPT, 50% IT |  |\n| **Curriculum** | **Group 1** | CPT: 50% Domain-specific Text (Web and book), 50% General text (verfiable text) |\n|  |  | IT: 20% Domain-specific tasks, 80% General tasks |\n|  | **Group 2** | CPT: Group 1 data + domain-specific books |\n|  |  | IT: Group1 + Exercises extracted from books |\n| **Steps** |  | Group 1: 3.84B tokens; Group 2: 1.66B tokens |\n|  |  | (8,000 context length, 16 A100) |\n| **Model** | **Intialization** | Llama3-8b-instruct |\n|  | **Attention** | CPT: full attention with cross-docuemnt attention masking |\n|  |  | IT: full attention with instruction mask-out and cross-docuemnt attention masking |\n| **Optim.** |  | AdamW (weight decay = 0.1, \u03b2\u2081=0.9, \u03b2\u2082=0.95) |\n|  | **LR** | Group 1: 5e-6 with 10% warmup; Group 2: 5e-6 with 50% warmup |\n|  | **Batch size** | 128K tokens |\n| **Stop Cri.** | Loss of development set stops decreasing (\u2248 1 epoch) |  |\n| Continual Pre-training (CPT) and Instruction Tuning (IT) |\n|---|---|---|\n| **Data** | Trajectory-GenORM and Trajectory-GenPRM |  |\n| **Steps** | 24.58 M tokens |  |\n| **Model** | **Initialization** | CPT+IT |\n|  | **Loss** | DPO with an additional negative log-likelihood term |\n| **Optim.** | **LR** | 5e-7 with 10% warmup |\n|  | **Batch size** | 32K tokens |\n| **Stop Cri.** | Loss of development set stops decreasing |  |", "caption": "Table 6: Overview of the results on unseen evaluation set. \u2018*\u2019 indicates that \u2018GPT4o\u2019 is used as the judge. Llama-Fin and its variant (\u2018CPT+IT\u2019) are highlighted in blue. The best performing model for 8b on each benchmark is bolded. The overall best performance across all models is underlined. + indicates that Llama-Fin outperforms the base Llama3-8B-instruct.", "description": "\ud45c 6\uc740 \uc81c\uc2dc\ub41c \ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uad00\ucc30\ub41c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Llama-Fin \ubc0f CPT+IT \ubcc0\ud615 \ubaa8\ub378\uc740 \ud30c\ub780\uc0c9\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c 8B \ubaa8\ub378 \uc911 \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc740 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \ubaa8\ub4e0 \ubaa8\ub378 \uc911 \ucd5c\uace0 \uc131\ub2a5\uc740 \ubc11\uc904\uc774 \uadf8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. GPT-4\uac00 \ud310\uc815\uc790\ub85c \uc0ac\uc6a9\ub41c \uacbd\uc6b0\uc5d0\ub294 '*' \ud45c\uc2dc\uac00 \ub418\uc5b4\uc788\uc2b5\ub2c8\ub2e4. '+ ' \ud45c\uc2dc\ub294 Llama-Fin\uc774 \uae30\uc900 Llama3-8B-instruct \ubaa8\ub378\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec Llama-Fin \ubaa8\ub378\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\uace0, \uac01 \ubca4\uce58\ub9c8\ud06c\ubcc4 \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc744 \uba85\ud655\ud788 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \ub610\ud55c,  GPT-4o\ub97c \uc0ac\uc6a9\ud55c \ud3c9\uac00 \uacb0\uacfc\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4, \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ub354\uc6b1 \uac1d\uad00\uc801\uc73c\ub85c \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 \ucd5c\uc885 \ub808\uc2dc\ud53c \ubc0f \ud3c9\uac00"}]