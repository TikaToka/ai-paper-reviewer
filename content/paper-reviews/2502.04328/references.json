{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Robust speech recognition via large-scale weak supervision", "publication_date": "2022-XX-XX", "reason": "This paper introduced Whisper, a large speech recognition model used as an audio encoder in the Ola model, contributing to its audio understanding capabilities."}, {"fullname_first_author": "Bo Li", "paper_title": "LLaVA-OneVision: Easy visual task transfer", "publication_date": "2024-XX-XX", "reason": "This paper presented LLaVA-OneVision, a large vision-language model that served as a foundation for Ola's progressive modality alignment, significantly influencing its visual understanding."}, {"fullname_first_author": "Yuhao Dong", "paper_title": "Insight-V: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2024-XX-XX", "reason": "This paper introduced a method used in Ola's progressive modality alignment strategy, improving its performance and efficiency in multi-modal learning."}, {"fullname_first_author": "Zuyan Liu", "paper_title": "Oryx MLLM: On-demand spatial-temporal understanding at arbitrary resolution", "publication_date": "2024-XX-XX", "reason": "This paper introduced OryxViT, a vision encoder used in Ola, which is designed for processing images and videos at arbitrary resolutions, enhancing its visual capabilities."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The first-ever comprehensive evaluation benchmark of multi-modal LLMs in video analysis", "publication_date": "2024-XX-XX", "reason": "This paper presented VideoMME, a benchmark dataset used for evaluating Ola's performance on video understanding, offering a comprehensive standard for comparison."}]}