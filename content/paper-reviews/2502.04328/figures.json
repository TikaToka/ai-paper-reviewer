[{"figure_path": "https://arxiv.org/html/2502.04328/x2.png", "caption": "Figure 1: Ola pushes the frontiers of the omni-modal language model across image, video and audio understanding benchmarks.  We compare Ola with existing state-of-the-art open-sourced multimodal models and GPT-4o on their abilities in mainstream image, video, and audio benchmarks. For fair comparisons, we select around 7B versions of existing MLLMs. Ola can achieve outperforming performance against omni-modal and specialized MLLMs in all modalities thanks to our progressive alignment strategy. \u201c\u00d7\\times\u00d7\u201d indicates that the model is not capable of the task and \u201c\u2212--\u201d indicates the result is lacking. The score for LibriSpeech is inverted as lower is better for the WER metric.", "description": "\uadf8\ub9bc 1\uc740 Ola \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624 \uc774\ud574 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \ubaa8\ub4dc\ub97c \uc544\uc6b0\ub974\ub294 \ubc94\uc6a9 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \ud55c\uacc4\ub97c \ub6f0\uc5b4\ub118\ub294 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. Ola \ubaa8\ub378\uc740 \uae30\uc874 \ucd5c\ucca8\ub2e8 \uc624\ud508\uc18c\uc2a4 \ub2e4\uc911 \ubaa8\ub4dc \ubaa8\ub378 \ubc0f GPT-4\uc640 \ube44\uad50\ub418\uc5b4 \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \uc131\ub2a5\uc774 \ud3c9\uac00\ub429\ub2c8\ub2e4. \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \uae30\uc874 MLLM \uc911 \uc57d 7B \ubc84\uc804\uc744 \uc120\ud0dd\ud558\uc600\uc2b5\ub2c8\ub2e4. Ola\ub294 \uc810\uc9c4\uc801 \uc815\ub82c \uc804\ub7b5 \ub355\ubd84\uc5d0 \ubaa8\ub4e0 \ubaa8\ub4dc\uc5d0\uc11c \ub2e4\uc911 \ubaa8\ub2ec \ubc0f \ud2b9\uc218\ud654\ub41c MLLM\uc744 \ub2a5\uac00\ud558\ub294 \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.  '\u00d7'\ub294 \ubaa8\ub378\uc774 \ud574\ub2f9 \uc791\uc5c5\uc744 \uc218\ud589\ud560 \uc218 \uc5c6\uc74c\uc744, '-'\ub294 \uacb0\uacfc\uac00 \ubd80\uc871\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. LibriSpeech \uc810\uc218\ub294 WER \uc9c0\ud45c\uac00 \ub0ae\uc744\uc218\ub85d \uc88b\uc73c\ubbc0\ub85c \ubc18\uc804\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.04328/x3.png", "caption": "Figure 2: Ola Architecture. Ola supports omni-modal inputs including text, image, video, and audio, capable of processing the inputs simultaneously with competitive performance on understanding tasks for all these modalities. Meanwhile, Ola supports user-friendly real-time streaming decoding for texts and speeches thanks to the text detokenizer and the speech decoder.", "description": "\uadf8\ub9bc 2\ub294 Ola \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Ola\ub294 \ud14d\uc2a4\ud2b8, \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624\ub97c \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0\uc758 \uc785\ub825\uc744 \ub3d9\uc2dc\uc5d0 \ucc98\ub9ac\ud560 \uc218 \uc788\uc73c\uba70, \ubaa8\ub4e0 \ubaa8\ub2ec\ub9ac\ud2f0\uc5d0 \ub300\ud55c \uc774\ud574 \uc791\uc5c5\uc5d0\uc11c \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \ud14d\uc2a4\ud2b8 \ub514\ud1a0\ud06c\ub098\uc774\uc800\uc640 \uc74c\uc131 \ub514\ucf54\ub354 \ub355\ubd84\uc5d0 Ola\ub294 \uc0ac\uc6a9\uc790 \uce5c\ud654\uc801\uc778 \uc2e4\uc2dc\uac04 \uc2a4\ud2b8\ub9ac\ubc0d \ub514\ucf54\ub529\uc744 \uc9c0\uc6d0\ud558\uc5ec \ud14d\uc2a4\ud2b8\uc640 \uc74c\uc131 \ucd9c\ub825\uc744 \uc2e4\uc2dc\uac04\uc73c\ub85c \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uac01 \ubaa8\ub2ec\ub9ac\ud2f0(\ud14d\uc2a4\ud2b8, \uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624)\ub294 \ud574\ub2f9 \ubaa8\ub2ec\ub9ac\ud2f0\uc5d0 \ud2b9\ud654\ub41c \uc778\ucf54\ub354\ub97c \ud1b5\ud574 \ucc98\ub9ac\ub41c \ud6c4, \ub2e4\uc911 \ubaa8\ub2ec\ub9ac\ud2f0 \uc785\ub825\uc744 \ud1b5\ud569\ud558\ub294 \ubaa8\ub4c8\uc744 \uac70\uccd0 Ola \uc5b8\uc5b4 \ubaa8\ub378\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4.  Ola \ubaa8\ub378\uc740 \uc774 \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\uc5ec \ud14d\uc2a4\ud2b8 \ub610\ub294 \uc74c\uc131\uc73c\ub85c \ucd9c\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc2e4\uc2dc\uac04 \ucc98\ub9ac \uae30\ub2a5\uc740 \uc0ac\uc6a9\uc790\uc640\uc758 \uc0c1\ud638 \uc791\uc6a9\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3. Ola: Omni-Modal Understanding"}, {"figure_path": "https://arxiv.org/html/2502.04328/x4.png", "caption": "Figure 3: Progressive modality alignment helps to learn better omni-modal models.  We compare our progressive alignment strategy with two baseline training pipelines on Image QA(MMBench\u00a0[40]), Video QA(VideoMME\u00a0[21]), and ASR(LibriSpeech\u00a0[54]): 1) direct mixing where all instruction tuning data is merged and trained in a single stage, and 2) balanced sampling where we upsample certain sources to make the training data more balanced among modalities. The experiment is conducted on a subsampled training set for efficiency and we train models for the same number of steps for fair comparisons. The score is normalized based on the score of progressive alignment to calculate the relative score and the ASR score is inverted as lower is better for the WER metric.", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \ubaa8\ub2ec\ub9ac\ud2f0(\uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc624\ub514\uc624)\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \uc81c\uc548\ub41c '\uc810\uc9c4\uc801 \ubaa8\ub2ec\ub9ac\ud2f0 \uc815\ub82c(Progressive Modality Alignment)' \uc804\ub7b5\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \uc8fc\uc694 \uc791\uc5c5(\uc774\ubbf8\uc9c0 \uc9c8\uc758\uc751\ub2f5(Image QA), \ube44\ub514\uc624 \uc9c8\uc758\uc751\ub2f5(Video QA), \uc790\ub3d9 \uc74c\uc131 \uc778\uc2dd(ASR))\uc5d0 \ub300\ud574, \uc81c\uc548\ub41c \uc804\ub7b5\uacfc \ub450 \uac00\uc9c0 \uae30\uc900 \ubc29\ubc95(\ubaa8\ub4e0 \ub370\uc774\ud130\ub97c \uc11e\uc5b4 \ud55c\uaebc\ubc88\uc5d0 \ud559\uc2b5\ud558\ub294 '\uc9c1\uc811 \ud63c\ud569(Direct Mixing)', \ub370\uc774\ud130 \ubd88\uade0\ud615\uc744 \ud574\uc18c\ud558\uae30 \uc704\ud574 \uc77c\ubd80 \ub370\uc774\ud130\ub97c \uacfc\ub300 \uc0d8\ud50c\ub9c1\ud558\ub294 '\uade0\ud615 \uc0d8\ud50c\ub9c1(Balanced Sampling)')\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \ud6a8\uc728\uc131\uc744 \uc704\ud574 \ucd95\uc18c\ub41c \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc600\uc73c\uba70, \ubaa8\ub378 \ud559\uc2b5 \ub2e8\uacc4\ub294 \ub3d9\uc77c\ud558\uac8c \uc720\uc9c0\ud588\uc2b5\ub2c8\ub2e4. \uc810\uc9c4\uc801 \uc815\ub82c \uc804\ub7b5\uc758 \uc131\ub2a5\uc744 \uae30\uc900\uc73c\ub85c \uc810\uc218\ub97c \uc815\uaddc\ud654\ud588\uace0, ASR \uc791\uc5c5\uc758 \uacbd\uc6b0 WER(Word Error Rate) \uc9c0\ud45c\uc758 \ud2b9\uc131\uc0c1 \ub0ae\uc740 \uac12\uc774 \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\ub3c4\ub85d \uc810\uc218\ub97c \ubc18\uc804\ud588\uc2b5\ub2c8\ub2e4.", "section": "3. Ola: Omni-Modal Understanding"}, {"figure_path": "https://arxiv.org/html/2502.04328/x5.png", "caption": "Figure 4: Illustrations of the Ola Progressive Modality Alignment. We visualize the relationships among modalities in the left part. Speech acts as the connection between language and audio knowledge, while video constructs the bridge with highly relevant visual and audio information. Therefore, we design the progressive alignment training strategy from primary to periphery. Furthermore, we design the cross-modality video-audio data to better capture the relationships among modalities.", "description": "\uadf8\ub9bc 4\ub294 Ola\uc758 \uc810\uc9c4\uc801 \ubaa8\ub2ec\ub9ac\ud2f0 \uc815\ub82c \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ubd80\ubd84\uc740 \uc5b8\uc5b4, \ube44\uc804, \uccad\uac01 \ubaa8\ub2ec\ub9ac\ud2f0 \uac04\uc758 \uad00\uacc4\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc74c\uc131\uc740 \uc5b8\uc5b4\uc640 \uccad\uac01 \uc9c0\uc2dd\uc744 \uc5f0\uacb0\ud558\ub294 \ub9e4\uac1c\uccb4 \uc5ed\ud560\uc744 \ud558\uace0, \ube44\ub514\uc624\ub294 \uc2dc\uac01 \ubc0f \uccad\uac01 \uc815\ubcf4\ub97c \ubc00\uc811\ud558\uac8c \uc5f0\uacb0\ud558\ub294 \ub2e4\ub9ac \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c, \uac00\uc7a5 \uc911\uc694\ud55c \ubaa8\ub2ec\ub9ac\ud2f0(\ud14d\uc2a4\ud2b8\uc640 \uc774\ubbf8\uc9c0)\ubd80\ud130 \uc2dc\uc791\ud558\uc5ec \uc810\uc9c4\uc801\uc73c\ub85c \ub2e4\ub978 \ubaa8\ub2ec\ub9ac\ud2f0(\ube44\ub514\uc624, \uc624\ub514\uc624)\ub97c \ucd94\uac00\ud558\ub294 \ud6c8\ub828 \uc804\ub7b5\uc744 \uc124\uacc4\ud588\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \ubaa8\ub2ec\ub9ac\ud2f0 \uac04\uc758 \uad00\uacc4\ub97c \ub354 \uc798 \ud3ec\ucc29\ud558\uae30 \uc704\ud574 \uad50\ucc28 \ubaa8\ub2ec\ub9ac\ud2f0 \ube44\ub514\uc624-\uc624\ub514\uc624 \ub370\uc774\ud130\ub97c \uc124\uacc4\ud588\uc2b5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 Ola \ubaa8\ub378\uc774 \ub2e8\uc21c\ud788 \ubaa8\ub4e0 \ubaa8\ub2ec\ub9ac\ud2f0\ub97c \ud55c\uaebc\ubc88\uc5d0 \ud559\uc2b5\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, \ud14d\uc2a4\ud2b8\uc640 \uc774\ubbf8\uc9c0 \uc774\ud574\ub77c\ub294 \uae30\ubcf8\uc801\uc778 \ub2a5\ub825\uc744 \uba3c\uc800 \ud655\ubcf4\ud55c \ud6c4, \uc810\uc9c4\uc801\uc73c\ub85c \uc74c\uc131\uacfc \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \ucd94\uac00\ud558\uc5ec \ub354\uc6b1 \uac15\ub825\ud558\uace0 \ud1b5\ud569\uc801\uc778 \ub2e4\uc911 \ubaa8\ub2ec\ub9ac\ud2f0 \uc774\ud574 \ub2a5\ub825\uc744 \uac16\ucd94\ub3c4\ub85d \ud6c8\ub828\ud558\ub294 \uacfc\uc815\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.", "section": "3. Ola: Omni-Modal Understanding"}, {"figure_path": "https://arxiv.org/html/2502.04328/x6.png", "caption": "Figure 5: Generative results on speech and visual understanding tasks. We illustrate results on speech and video understanding and show the strong ability of omni-modal Ola compared with conventional vision-language models.", "description": "\uadf8\ub9bc 5\ub294 \uc74c\uc131 \ubc0f \uc2dc\uac01\uc801 \uc774\ud574 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc74c\uc131 \ubc0f \ube44\ub514\uc624 \uc774\ud574\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uace0 \uae30\uc874\uc758 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ub2e4\uc911 \ubaa8\ub2ec Ola\uc758 \uac15\ub825\ud55c \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294, \uc74c\uc131 \uc774\ud574 \ubd80\ubd84\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \uac10\uc815\uacfc \ub258\uc559\uc2a4\ub97c \ub2f4\uc740 \uc74c\uc131 \ub370\uc774\ud130\ub97c \ubd84\uc11d\ud558\uc5ec \uc9c8\ubb38\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud558\ub294 Ola\uc758 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc2dc\uac01\uc801 \uc774\ud574 \ubd80\ubd84\uc5d0\uc11c\ub294 \ube44\ub514\uc624\uc640 \uc74c\uc131 \uc815\ubcf4\ub97c \ud568\uaed8 \ud65c\uc6a9\ud558\uc5ec \ub9e5\ub77d\uc744 \ud30c\uc545\ud558\uace0 \ubcf4\ub2e4 \uc815\ud655\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\ub294 Ola\uc758 \ub2a5\ub825\uc744 \uae30\uc874 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 Ola\uac00 \ub2e8\uc21c\ud788 \uc774\ubbf8\uc9c0\ub098 \uc74c\uc131\ub9cc\uc744 \ucc98\ub9ac\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, \uc774\ub4e4\uc744 \ud1b5\ud569\uc801\uc73c\ub85c \uc774\ud574\ud558\uace0 \ud65c\uc6a9\ud558\uc5ec \ub354\uc6b1 \ud48d\ubd80\ud558\uace0 \uc815\ud655\ud55c \uacb0\uacfc\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "4. \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2502.04328/x7.png", "caption": "Figure 6: Showcases on Text and Audio Understanding.", "description": "\uadf8\ub9bc 6\uc740 Ola \ubaa8\ub378\uc758 \ud14d\uc2a4\ud2b8 \ubc0f \uc624\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc74c\uc545, \uc74c\uc131, \uc18c\ub9ac \uad00\ub828 \uc624\ub514\uc624 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec Ola \ubaa8\ub378\uc774 \uc9c8\ubb38\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc608\uc2dc\ub294 \uc624\ub514\uc624 \ud074\ub9bd, \uc9c8\ubb38, \uadf8\ub9ac\uace0 Ola \ubaa8\ub378\uc758 \uc751\ub2f5\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc73c\uba70, Ola \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc624\ub514\uc624 \ub370\uc774\ud130\ub97c \uc815\ud655\ud558\uac8c \uc774\ud574\ud558\uace0, \uc801\uc808\ud55c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc758 \uac15\ub825\ud55c \uba40\ud2f0\ubaa8\ub2ec \uc774\ud574 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uc88b\uc740 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "4. Showcases"}]