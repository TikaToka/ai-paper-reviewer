[{"figure_path": "https://arxiv.org/html/2502.07563/x1.png", "caption": "Figure 1: Computation Decomposition in LASP-2 with masking. Colored chunks represent inter-chunks.", "description": "\uadf8\ub9bc 1\uc740 \ub9c8\uc2a4\ud06c\uac00 \uc788\ub294 LASP-2\uc758 \uacc4\uc0b0 \ubd84\ud574\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc0c9\uc0c1\uc758 \uccad\ud06c\ub294 \uc11c\ub85c \ub2e4\ub978 GPU\uc5d0\uc11c \ubcd1\ub82c\ub85c \ucc98\ub9ac\ub418\ub294 \uacc4\uc0b0 \ub2e8\uc704\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ud2b9\ud788, \uc0c9\uc73c\ub85c \uad6c\ubd84\ub41c \uccad\ud06c\ub4e4\uc740 \ub2e4\ub978 \uccad\ud06c\ub4e4\uacfc\uc758 \uc758\uc874\uc131\uc774 \uc5c6\uc5b4 \ubcd1\ub82c \ucc98\ub9ac\uac00 \uac00\ub2a5\ud55c 'inter-chunks'\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 LASP-2\uac00 \ub9c8\uc2a4\ud06c\ub97c \uc0ac\uc6a9\ud558\ub294 \uc0c1\ud669\uc5d0\uc11c\ub3c4 \ud6a8\uc728\uc801\uc778 \ubcd1\ub82c \ucc98\ub9ac\ub97c \ub2ec\uc131\ud558\ub294 \ubc29\uc2dd\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc124\uba85\ud569\ub2c8\ub2e4.  \uac01 \uccad\ud06c \ub0b4\ubd80\uc758 \uacc4\uc0b0(intra-chunk)\uacfc \ub2e4\ub978 \uccad\ud06c\ub4e4\uacfc\uc758 \uc0c1\ud638\uc791\uc6a9 \uacc4\uc0b0(inter-chunk)\uc758 \ubd84\ub9ac\ub97c \ud1b5\ud574, \ud6a8\uc728\uc801\uc778 \ubcd1\ub82c \ucc98\ub9ac\uc640 \ub9c8\uc2a4\ud06c \ucc98\ub9ac\uc5d0 \ub530\ub978 \uc131\ub2a5 \uc800\ud558\ub97c \ucd5c\uc18c\ud654\ud558\ub294 LASP-2\uc758 \uc54c\uace0\ub9ac\uc998 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2 LASP-2 with Masking"}, {"figure_path": "https://arxiv.org/html/2502.07563/x2.png", "caption": "Figure 2: Visualization of LASP-2H on Linear Attention and Standard Attention hybrid model. We exemplify LASP-2H on the hybrid layers of linear attention and standard attention modules with both TP and SP (both have a dimension of 2). The communication operations colored in yellow and green are for TP and SP, respectively. AG/RS: all-gather in forward and reduce-scatter in backward, and vice versa. AG/No: all-gather in forward and no-op in backward, and vice versa. Note that the SP communication operations for linear attention operate on the memory state \ud835\udc0ct\u2208\u211dd\u00d7dsubscript\ud835\udc0c\ud835\udc61superscript\u211d\ud835\udc51\ud835\udc51\\mathbf{M}_{t}\\in\\mathbb{R}^{d\\times d}bold_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_d \u00d7 italic_d end_POSTSUPERSCRIPT, while for standard attention, they operate on states \ud835\udc0at,\ud835\udc15t\u2208\u211dC\u00d7dsubscript\ud835\udc0a\ud835\udc61subscript\ud835\udc15\ud835\udc61superscript\u211d\ud835\udc36\ud835\udc51\\mathbf{K}_{t},\\mathbf{V}_{t}\\in\\mathbb{R}^{C\\times d}bold_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_C \u00d7 italic_d end_POSTSUPERSCRIPT.", "description": "\uadf8\ub9bc 2\ub294 \uc120\ud615 \uc5b4\ud150\uc158\uacfc \ud45c\uc900 \uc5b4\ud150\uc158 \ud558\uc774\ube0c\ub9ac\ub4dc \ubaa8\ub378\uc5d0\uc11c LASP-2H\uc758 \uc2dc\uac01\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc5d0\uc11c\ub294 \uc120\ud615 \uc5b4\ud150\uc158 \ubaa8\ub4c8\uacfc \ud45c\uc900 \uc5b4\ud150\uc158 \ubaa8\ub4c8\uc758 \ud558\uc774\ube0c\ub9ac\ub4dc \ub808\uc774\uc5b4\uc5d0\uc11c TP(Tensor Parallelism)\uc640 SP(Sequence Parallelism)\ub97c \ubaa8\ub450 \uc0ac\uc6a9\ud558\ub294 LASP-2H\uc758 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub178\ub780\uc0c9\uacfc \ucd08\ub85d\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \ud1b5\uc2e0 \uc5f0\uc0b0\uc740 \uac01\uac01 TP\uc640 SP\uc5d0 \ud574\ub2f9\ud569\ub2c8\ub2e4.  AG/RS\ub294 \uc21c\ubc29\ud5a5 \uc804\ub2ec \uc2dc all-gather, \uc5ed\ubc29\ud5a5 \uc804\ub2ec \uc2dc reduce-scatter\ub97c \uc758\ubbf8\ud558\uba70, AG/No\ub294 \uc21c\ubc29\ud5a5 \uc804\ub2ec \uc2dc all-gather, \uc5ed\ubc29\ud5a5 \uc804\ub2ec \uc2dc no-op(\uc5f0\uc0b0 \uc5c6\uc74c)\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc120\ud615 \uc5b4\ud150\uc158\uc758 \uacbd\uc6b0 SP \ud1b5\uc2e0 \uc5f0\uc0b0\uc740 \uba54\ubaa8\ub9ac \uc0c1\ud0dc  Mt\u2208\u211dd\u00d7d\uc5d0 \ub300\ud574 \uc218\ud589\ub418\uc9c0\ub9cc, \ud45c\uc900 \uc5b4\ud150\uc158\uc758 \uacbd\uc6b0 Kt, Vt\u2208\u211dC\u00d7d \uc0c1\ud0dc\uc5d0 \ub300\ud574 \uc218\ud589\ub428\uc744 \uc8fc\ubaa9\ud574\uc57c \ud569\ub2c8\ub2e4.  \uc989, \uc774 \uadf8\ub9bc\uc740 LASP-2H\uac00 \uc120\ud615 \uc5b4\ud150\uc158\uacfc \ud45c\uc900 \uc5b4\ud150\uc158 \ubaa8\ub450\uc5d0 \ud6a8\uc728\uc801\uc73c\ub85c \ubcd1\ub82c \ucc98\ub9ac\ub97c \uc801\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4.", "section": "3. Hybrid Model Sequence Parallelism"}, {"figure_path": "https://arxiv.org/html/2502.07563/x3.png", "caption": "Figure 3: Speed Comparison (tokens/s). Experiments were carried out on a pure Linear-Llama3-1B model, utilizing the basic linear attention module. A total of 64 A100 GPUs were employed, and the SP size T\ud835\udc47Titalic_T was also set to 64. To accommodate very-long sequence lengths, such as 2048K, the batch size was kept fixed at 1 throughout this experiment.", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \uc2dc\ud000\uc2a4 \uae38\uc774\uc5d0 \ub530\ub978 LASP-2\uc758 \uc18d\ub3c4 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\ud5d8\uc740 \uae30\ubcf8 \uc120\ud615 \uc5b4\ud150\uc158 \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud558\ub294 \uc21c\uc218 Linear-Llama3-1B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ucd1d 64\uac1c\uc758 A100 GPU\uac00 \uc0ac\uc6a9\ub418\uc5c8\uc73c\uba70, \uc2dc\ud000\uc2a4 \ubcd1\ub82c \ucc98\ub9ac \ud06c\uae30(SP size T)\ub3c4 64\ub85c \uc124\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4. 2048K\uc640 \uac19\uc774 \ub9e4\uc6b0 \uae34 \uc2dc\ud000\uc2a4 \uae38\uc774\ub97c \ucc98\ub9ac\ud558\uae30 \uc704\ud574 \ubc30\uce58 \ud06c\uae30\ub294 1\ub85c \uace0\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uadf8\ub798\ud504\ub294 \uc2dc\ud000\uc2a4 \uae38\uc774\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c LASP-2\uc758 \ucc98\ub9ac\ub7c9(tokens/s)\uc774 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \uc2dc\ud000\uc2a4 \uae38\uc774\uac00 512K\ub97c \ub118\uc5b4\uc11c\uba74\uc11c LASP-2\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc774 \ub450\ub4dc\ub7ec\uc9d1\ub2c8\ub2e4.", "section": "4.2 Speed"}]