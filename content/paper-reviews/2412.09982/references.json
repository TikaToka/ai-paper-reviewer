{"references": [{"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian Splatting for Real-Time Radiance Field Rendering", "publication_date": "2023-00-00", "reason": "This paper introduces the core rendering technique upon which SplineGS builds, differentiable rasterization of 3D Gaussians, enabling real-time rendering and providing a more explicit scene representation than previous methods like NeRF."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis", "publication_date": "2020-00-00", "reason": "This work establishes Neural Radiance Fields as a core underlying representation for Novel View Synthesis, which many dynamic NVS methods, including SplineGS, build upon."}, {"fullname_first_author": "Chen Gao", "paper_title": "Dynamic View Synthesis from Dynamic Monocular Video", "publication_date": "2021-00-00", "reason": "This is a key reference for dynamic NeRFs, introducing DynNeRF, which serves as an important baseline comparison for SplineGS and related dynamic 3D scene reconstruction methods."}, {"fullname_first_author": "Zhan Li", "paper_title": "Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis", "publication_date": "2024-00-00", "reason": "This paper presents STGS, which models dynamic 3D gaussian trajectories using polynomial functions and provides an approach to high-quality and fast rendering, which SplineGS directly compares and builds upon."}, {"fullname_first_author": "Yu-Lun Liu", "paper_title": "Robust Dynamic Radiance Fields", "publication_date": "2023-00-00", "reason": "This work introduces RoDynRF, a concurrent work, and provides a key comparison for showing the benefits of spline-based motion modeling as is core to SplineGS."}]}