{"references": [{"fullname_first_author": "Rameen Abdal", "paper_title": "Image2StyleGAN: How to embed images into the StyleGAN latent space?", "publication_date": "2019-12-01", "reason": "This paper is foundational for understanding how to embed images into the StyleGAN latent space, a technique relevant to the concept personalization methods discussed in the target paper."}, {"fullname_first_author": "Yuval Alaluf", "paper_title": "A neural space-time representation for text-to-image personalization", "publication_date": "2023-01-01", "reason": "This paper directly addresses text-to-image personalization, a core concept for the proposed TokenVerse method."}, {"fullname_first_author": "Omri Avrahami", "paper_title": "Break-a-Scene: Extracting multiple concepts from a single image", "publication_date": "2023-01-01", "reason": "This paper tackles multi-concept extraction from a single image, a key challenge addressed by the target paper's TokenVerse approach."}, {"fullname_first_author": "Tero Karras", "paper_title": "A style-based generator architecture for generative adversarial networks", "publication_date": "2019-06-14", "reason": "This paper introduces the StyleGAN architecture, whose modulation space is leveraged and further explored in the target paper."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-01-01", "reason": "This paper introduces latent diffusion models, which are the foundation for the text-to-image generation method explored in the target paper."}]}