{"references": [{"fullname_first_author": "Honglie Chen", "paper_title": "VGGSound: A large-scale audio-visual dataset", "publication_date": "2020-00-00", "reason": "This paper introduces a large-scale audio-visual dataset crucial for training and evaluating video-to-audio synthesis models, which is the main focus of the current work."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "This paper proposes a powerful image synthesis method which serves as a foundation for the MMAudio model's architecture and multimodal training."}, {"fullname_first_author": "Vladimir Iashin", "paper_title": "Synchformer: Efficient synchronization from sparse cues", "publication_date": "2024-00-00", "reason": "This paper introduces a key component for the conditional synchronization module in MMAudio, improving audio-visual alignment in video-to-audio generation."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a powerful multimodal model used for video and text feature extraction in MMAudio, enabling the model to understand semantics from both modalities."}, {"fullname_first_author": "Yongqi Wang", "paper_title": "Frieren: Efficient video-to-audio generation with rectified flow matching", "publication_date": "2024-00-00", "reason": "This paper proposes a strong baseline method for video-to-audio synthesis that MMAudio improves upon, setting a competitive benchmark for performance."}]}