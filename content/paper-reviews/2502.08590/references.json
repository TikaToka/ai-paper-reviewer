{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces Stable Video Diffusion, a significant advancement in video diffusion models that is directly relevant to the current paper's approach to video relighting."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This foundational paper on denoising diffusion probabilistic models underpins many of the techniques used in video generation and manipulation, including those employed in the current work."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Scaling in-the-wild training for diffusion-based illumination harmonization and editing by imposing consistent light transport", "publication_date": "2024-00-00", "reason": "This paper introduces a state-of-the-art image relighting model (IC-Light) that is central to the current paper's method, providing the basis for adapting image relighting to video."}, {"fullname_first_author": "Yuwei Guo", "paper_title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning", "publication_date": "2023-07-00", "reason": "Animatediff is a key component of Light-A-Video, providing the video diffusion model that enables temporally consistent video generation, thus addressing a major challenge in video relighting."}, {"fullname_first_author": "Chenlin Meng", "paper_title": "Sdedit: Guided image synthesis and editing with stochastic differential equations", "publication_date": "2021-08-00", "reason": "This paper introduces SDEdit, a method for image editing with diffusion models.  It is used as a baseline for comparison in the evaluation of Light-A-Video's performance."}]}