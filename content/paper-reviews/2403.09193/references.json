{"references": [{"fullname_first_author": "Robert Geirhos", "paper_title": "Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.", "publication_date": "2019-00-00", "reason": "This paper is foundational to the current work, introducing the texture vs. shape bias in CNNs and its effects on accuracy and robustness."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2024-00-00", "reason": "This paper introduces InternVL, a key VLM model used extensively in the experiments and analysis of the current study."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "CLIP, introduced in this paper, is a fundamental model used as the vision backbone for many VLMs analyzed in the current study."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-00-00", "reason": "Flamingo is another important VLM architecture that is analyzed in the current study, offering insights into multimodal model biases."}, {"fullname_first_author": "Haotian Liu", "paper_title": "InstructBLIP: Towards general-purpose vision-language models with instruction tuning", "publication_date": "2023-00-00", "reason": "InstructBLIP is a significant VLM model in the study, demonstrating the impact of instruction tuning on visual biases."}]}