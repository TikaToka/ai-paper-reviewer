[{"content": "| Dataset | Book Num. | Character Num. | Profile | Expr. | #Conv. | Conversation #Turns | Setting | Auth. | Multi-Chara. | Message Speech | Thought | Action | Plot Summ. |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Charater-LLM |  | 9 | \u2713 |  | 14,300 | 13.2 | \u2713 |  |  | \u2713 |  |  |  |\n| ChatHaruhi |  | 32 | \u2713 |  | 54,726 | >2 |  | \u2713* | \u2713 | \u2713 |  |  |  |\n| RoleLLM |  | 100 | \u2713 |  | 140,726 | 2 |  |  |  | \u2713 |  |  |  |\n| HPD | 7 | 113 |  |  | 1,191 | 13.2 | \u2713 | \u2713 | \u2713 | \u2713 |  |  | \u2713 |\n| LifeChoice | 388 | 1,462 | \u2713 |  | 1,462 | 2 | \u2713 | \u2713 |  |  |  |  |  |\n| CroSS-MR | 126 | 126 | \u2713 |  | 445 | 2 | \u2713 | \u2713 |  |  |  |  |  |\n| CharacterGLM |  | 250 | \u2713 |  | 1,034 | 15.8 | \u2713 |  |  | \u2713 |  |  |  |\n| CharacterEval |  | 77 | \u2713 |  | 1,785 | 9.3 | \u2713 | \u2713 |  | \u2713 |  | \u2713 |  |\n| DITTO |  | 4,002 | \u2713 |  | 7,186 | 5.1 |  |  |  | \u2713 |  |  |  |\n| MMRole |  | 85 | \u2713 |  | 14,346 | 4.2 |  |  |  | \u2713 |  |  |  |\n| CharacterBench |  | 3,956 | \u2713 |  | 13,162 | 11.3 |  |  |  | \u2713 |  |  |  |\n| CoSER | 771 | 17,966 | \u2713 | \u2713 | 29,798 | 13.2 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |", "caption": "Table 1: Overview of CoSER and existing RPLA datasets.\nFor characters, Num. count characters with profiles, and Expr. denotes structured character experiences.\nFor conversations, Auth. indicates authentic dialogues or behaviors from the books, and Multi-Chara. denotes involving more than 2 characters. Num. (number), Conv. (conversation), and Summ. (summary) are abbreviations.", "description": "\ud45c 1\uc740 COSER \ub370\uc774\ud130\uc14b\uacfc \uae30\uc874 RPLA \ub370\uc774\ud130\uc14b\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4. \ub4f1\uc7a5\uc778\ubb3c \uc218, \ud504\ub85c\ud544 \uc720\ubb34, \uad6c\uc870\ud654\ub41c \uacbd\ud5d8 \uc720\ubb34, \ub300\ud654 \uc218, \ud134 \uc218, \ubc30\uacbd \uc124\uc815, \ub300\ud654\uc758 \ucd9c\ucc98, \ub2e4\uc911 \uc778\ubb3c \ucc38\uc5ec \uc5ec\ubd80, \ub9d0, \uc0dd\uac01, \ud589\ub3d9, \uc904\uac70\ub9ac \uc694\uc57d \ub4f1 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ub370\uc774\ud130\uc14b\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec COSER \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uacfc \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc57d\uc5b4\ub85c \uc0ac\uc6a9\ub41c Num.(number), Conv.(conversation), Summ.(summary)\ub294 \uac01\uac01 \ub4f1\uc7a5\uc778\ubb3c \uc218, \ub300\ud654 \uc218, \uc904\uac70\ub9ac \uc694\uc57d\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "3. COSER \ub370\uc774\ud130\uc14b"}, {"content": "Model|Storyline|Consistency|Anthropomorphism|Character Fidelity|Storyline Quality|Average Score|BLEU|ROUGE-L\n---|---|---|---|---|---|---|---|---\n**_Close-source Models_**\nAbab7-preview|56.81 \u00b1 1.47|44.23 \u00b1 1.90|43.83 \u00b1 2.71|74.83 \u00b1 0.97|54.92 \u00b1 0.57|4.96 \u00b1 0.07|11.50 \u00b1 0.06|\nDoubao-pro|60.95 \u00b1 1.40|49.72 \u00b1 0.23|47.02 \u00b1 1.10|79.28 \u00b1 0.82|59.24 \u00b1 0.30|6.38 \u00b1 0.08|12.95 \u00b1 0.04|\nStep-1-Flash|57.75 \u00b1 0.72|48.12 \u00b1 0.39|44.48 \u00b1 0.48|75.93 \u00b1 0.99|56.57 \u00b1 0.48|5.95 \u00b1 0.15|12.71 \u00b1 0.11|\nStep-2|61.43 \u00b1 0.88|49.06 \u00b1 1.69|47.33 \u00b1 0.70|77.96 \u00b1 0.85|58.94 \u00b1 0.75|5.75 \u00b1 0.08|12.50 \u00b1 0.11|\nGPT-3.5|57.22 \u00b1 0.13|43.30 \u00b1 0.48|42.29 \u00b1 1.47|73.91 \u00b1 0.64|54.18 \u00b1 0.63|4.58 \u00b1 0.11|11.80 \u00b1 0.10|\nGPT-4o|**61.59 \u00b1 0.66**|48.93 \u00b1 0.48|**48.95 \u00b1 1.73**|**80.33 \u00b1 0.59**|**59.95 \u00b1 0.50**|5.90 \u00b1 0.16|12.11 \u00b1 0.13|\nGPT-4o Mini|60.09 \u00b1 0.60|48.21 \u00b1 1.09|44.88 \u00b1 1.63|78.55 \u00b1 0.14|57.93 \u00b1 0.74|3.90 \u00b1 0.07|10.81 \u00b1 0.07|\nGemini Pro|59.11 \u00b1 0.82|52.41 \u00b1 0.57|47.83 \u00b1 0.37|77.59 \u00b1 1.43|59.24 \u00b1 0.25|5.39 \u00b1 0.04|11.65 \u00b1 0.06|\nClaude-3-Haiku|58.18 \u00b1 0.72|44.66 \u00b1 1.72|41.88 \u00b1 0.34|74.14 \u00b1 1.26|54.71 \u00b1 0.84|4.80 \u00b1 0.05|12.02 \u00b1 0.02|\nClaude-3.5-Sonnet|57.45 \u00b1 0.98|48.50 \u00b1 2.35|45.69 \u00b1 1.80|77.23 \u00b1 0.88|57.22 \u00b1 0.95|5.17 \u00b1 0.12|11.45 \u00b1 0.07|\n**_Open-source Models_**\nMistral-7B|**59.90 \u00b1 1.33**|40.00 \u00b1 0.74|44.75 \u00b1 1.14|61.93 \u00b1 1.12|51.64 \u00b1 0.55|2.71 \u00b1 0.10|9.28 \u00b1 0.12|\nQwen-2-7B|51.96 \u00b1 0.67|35.48 \u00b1 0.62|31.51 \u00b1 2.95|63.18 \u00b1 0.79|45.53 \u00b1 0.69|4.21 \u00b1 0.21|10.71 \u00b1 0.10|\nLLaMA-3.1-8B|54.10 \u00b1 1.63|45.36 \u00b1 1.91|40.22 \u00b1 1.16|72.29 \u00b1 1.75|52.99 \u00b1 1.20|4.59 \u00b1 0.11|10.18 \u00b1 0.09|\nCoSER-8B|58.61 \u00b1 2.46|47.23 \u00b1 0.16|46.90 \u00b1 2.06|73.04 \u00b1 1.37|56.45 \u00b1 0.56|9.40 \u00b1 0.18|14.21 \u00b1 0.11|\nVicuna-13B-1.5|52.75 \u00b1 1.64|39.12 \u00b1 1.21|38.04 \u00b1 0.98|60.43 \u00b1 1.58|47.58 \u00b1 1.25|1.67 \u00b1 0.10|5.59 \u00b1 0.18|\nMixtral-8x7B|51.25 \u00b1 1.73|38.44 \u00b1 1.18|36.92 \u00b1 2.65|67.69 \u00b1 0.80|48.58 \u00b1 1.35|5.28 \u00b1 0.06|11.66 \u00b1 0.05|\nQwen-2-72B|57.75 \u00b1 1.26|47.28 \u00b1 0.87|46.62 \u00b1 1.69|76.60 \u00b1 0.36|57.06 \u00b1 1.00|5.38 \u00b1 0.00|11.85 \u00b1 0.03|\nLLaMA-3.1-70B|57.46 \u00b1 1.65|45.95 \u00b1 1.30|43.72 \u00b1 1.17|74.84 \u00b1 0.54|55.49 \u00b1 0.33|4.82 \u00b1 0.06|10.98 \u00b1 0.06|\nCoSER-70B|58.66 \u00b1 1.34|**53.33 \u00b1 0.91**|**48.75 \u00b1 1.43**|75.49 \u00b1 0.94|**59.06 \u00b1 0.22**|**10.10 \u00b1 0.04**|**14.78 \u00b1 0.09**|\nDeepSeek-V3|56.40 \u00b1 0.95|47.87 \u00b1 1.10|44.02 \u00b1 0.13|76.66 \u00b1 1.26|56.24 \u00b1 0.46|4.54 \u00b1 0.14|11.02 \u00b1 0.15|", "caption": "Table 2: Performance (%) of various LLMs on given-circumstance acting using CoSER Test.\nBold or underlined values indicate best performance across all models and open-source models, respectively.", "description": "\ud45c 2\ub294 CoSER Test \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc8fc\uc5b4\uc9c4 \uc0c1\ud669 \uc5f0\uae30 \uacfc\uc81c\uc5d0\uc11c \ub2e4\uc591\ud55c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc131\ub2a5\uc744 \ubc31\ubd84\uc728(%)\ub85c \ub098\ud0c0\ub0b8 \ud45c\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 \uc77c\uad00\uc131, \uc758\uc778\ud654, \ucda9\uc2e4\ub3c4, \ud488\uc9c8 \uc810\uc218\uc640 BLEU \ubc0f ROUGE-L \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uad75\uac8c \ud45c\uc2dc\ub41c \uac12\uc740 \ubaa8\ub4e0 \ubaa8\ub378 \uc911 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uace0, \ubc11\uc904 \uce5c \uac12\uc740 \uc624\ud508\uc18c\uc2a4 \ubaa8\ub378 \uc911 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc8fc\uc5b4\uc9c4 \uc0c1\ud669\uc5d0\uc11c \ub2e4\uc591\ud55c LLM\uc774 \uc5ed\ud560\uadf9\uc744 \uc5bc\ub9c8\ub098 \uc798 \uc218\ud589\ud558\ub294\uc9c0 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Model | Incharacter |  |  |  | \n|---|---|---|---|---| \n|  | Dim | Full | Life | Choice | CroSS | MR |\n|---|---|---|---|---|---|---|\n| LLaMA-3.1-8B | 64.97 | 15.62 | 61.10 | 30.15 |\n| CoSER-8B | 75.80 | 21.88 | 69.54 | 44.94 |\n| *trained w/o I.T.* | 70.70 | 15.62 | 59.92 | 43.14 |\n| LLaMA-3.1-70B | 72.16 | 31.25 | 86.48 | 61.30 |\n| Higgs-Llama-3-70B | 74.52 | 28.12 | 74.03 | 60.12 |\n| CoSER-70B | 75.80 | **34.38** | **93.47** | **64.49** |\n| *trained w/o I.T.* | 73.12 | 32.14 | 93.18 | 63.14 |\n| Qwen-2-72B | 74.52 | 31.25 | 81.14 | 62.57 |\n| GPT-3.5 | 71.20 | 21.88 | 78.07 | 30.09 |\n| GPT-4o | **76.54** | 32.62 | 75.96 | **64.49** |\n| Claude-3.5-Sonnet | 72.61 | 21.88 | 86.07 | 30.59 |", "caption": "Table 3: LLM performance (%) across three existing RPLA benchmarks. I.T. denotes inner thoughts. For InCharacter, we report accuracy for individual (Dim) and full (Full) dimensions on BFI.", "description": "\ud45c 3\uc740 \uae30\uc874\uc758 \uc138 \uac00\uc9c0 \uc5ed\ud560\uadf9 \uc5b8\uc5b4 \uc5d0\uc774\uc804\ud2b8(RPLA) \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc131\ub2a5\uc744 \ubc31\ubd84\uc728(%)\ub85c \ub098\ud0c0\ub0b8 \ud45c\uc785\ub2c8\ub2e4.  InCharacter \ubca4\uce58\ub9c8\ud06c\uc758 \uacbd\uc6b0 \uac1c\ubcc4(Dim) \ubc0f \uc804\uccb4(Full) \ucc28\uc6d0\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c BFI(Big Five Inventory) \uae30\uc900\uc73c\ub85c \ubcf4\uace0\ud569\ub2c8\ub2e4. I.T.\ub294 \ub0b4\uc801 \uc0ac\uace0(inner thoughts)\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ubaa8\ub378\uc774 \uc5bc\ub9c8\ub098 \ud6a8\uacfc\uc801\uc73c\ub85c \ud655\ub9bd\ub41c \uce90\ub9ad\ud130\ub97c \uc2dc\ubbac\ub808\uc774\uc158\ud558\uace0, \ub2e4\uc591\ud55c \ub300\ud654 \uc0c1\ud669\uc5d0\uc11c \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uba70,  \uc778\uac04\ub2e4\uc6b4 \ubc18\uc751\uc744 \ubcf4\uc774\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.2. \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Model | Standard | Test w/o I.T. | Test w/o Mot. |\n|---|---|---|---|\n| GPT-4o | 59.95 | 56.89 | 56.34 |\n| Qwen-2-72B | 57.06 | 51.95 | 54.21 |\n| LLaMA-3.1-70B | 55.49 | 53.12 | 52.49 |\n| CoSER-70B | 59.06 | 57.32 | 57.71 |\n| *trained w/o I.T.* | 56.04 | 55.34 | - |\n| LLaMA-3.1-8B | 52.99 | 51.97 | 49.63 |\n| CoSER-8B | 56.45 | 54.65 | 56.81 |\n| *trained w/o I.T.* | 54.25 | 54.38 | - |", "caption": "Table 4: \nAblation study results (average scores) on CoSER Test.\nI.T. and Mot. mean inner thoughts and motivations, respectively.", "description": "\ud45c 4\ub294 CoSER \ud14c\uc2a4\ud2b8\uc5d0\uc11c \ud3c9\uade0 \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CoSER \ud14c\uc2a4\ud2b8\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \uc0c8\ub85c\uc6b4 \uc5ed\ud560\uadf9 \uc5b8\uc5b4 \uc5d0\uc774\uc804\ud2b8(RPLA) \ud3c9\uac00 \ud504\ub85c\ud1a0\ucf5c\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub41c \ud3c9\uac00\uc785\ub2c8\ub2e4.  \ud45c\ub294 \ub0b4\uc801 \uc0ac\uace0(I.T.)\uc640 \ub3d9\uae30(Mot.)\ub97c \ud3ec\ud568\ud558\uac70\ub098 \uc81c\uc678\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uac01 \uc694\uc18c\uac00 \uc5ed\ud560\uadf9 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uc989, \ub0b4\uc801 \uc0ac\uace0\uc640 \ub3d9\uae30\uac00 \ubaa8\ub378\uc758 \uc5ed\ud560\uadf9 \uc218\ud589 \ub2a5\ub825\uc5d0 \uc5bc\ub9c8\ub098 \uae30\uc5ec\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| #Book | #Plot | #Conversation. | #Chararacter | #Utterance |\n|---|---|---|---|---|\n| 771 | 30,069 | 29,798 | 17,966 | 392,900 |", "caption": "Table 5: Statistics of CoSER Dataset.", "description": "\ud45c 5\ub294 COSER \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b\uc758 \uaddc\ubaa8\uc640 \ub2e4\uc591\uc131\uc744 \ubcf4\ub2e4 \uc790\uc138\ud788 \uc124\uba85\ud558\uba74, 771\uad8c\uc758 \uc800\uba85\ud55c \ucc45\uc5d0\uc11c \ucd94\ucd9c\ud55c 17,966\uba85\uc758 \ub4f1\uc7a5\uc778\ubb3c, 30,069\uac1c\uc758 \uace0\uc720 \ud50c\ub86f, \uadf8\ub9ac\uace0 29,798\uac1c\uc758 \ub300\ud654\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc73c\uba70, \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc740 \uc57d 392,900\uac1c\uc758 \ubc1c\ud654\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \ud3c9\uade0\uc801\uc73c\ub85c \uac01 \ub300\ud654\ub294 \uc57d 13.2\uac1c\uc758 \ubc1c\ud654\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 COSER \ub370\uc774\ud130\uc14b\uc758 \ubc29\ub300\ud568\uacfc \ub2e4\uc591\uc131\uc744 \ud55c\ub208\uc5d0 \ubcf4\uc5ec\uc8fc\ub294 \uc694\uc57d \ud1b5\uacc4 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3. COSER \ub370\uc774\ud130\uc14b"}, {"content": "| Selected Books |\n|---|---| \n| 1. _The Hunger Games (The Hunger Games, #1)_ | 2. _Harry Potter and the Order of the Phoenix (H. P., #5)_ |\n| 3. _Pride and Prejudice_ | 4. _To Kill a Mockingbird_ |\n| 5. _The Book Thief_ | 6. _Animal Farm_ |\n| 7. _The Chronicles of Narnia (#1-7)_ | 8. _The Fault in Our Stars_ |\n| 9. _The Picture of Dorian Gray_ | 10. _Wuthering Heights_ |\n| 11. _Gone with the Wind_ | 12. _The Perks of Being a Wallflower_ |\n| 13. _The Lightning Thief (Percy Jackson and the Olympians, #1)_ | 14. _The Little Prince_ |\n| 15. _The Great Gatsby_ | 16. _Crime and Punishment_ |\n| 17. _Memoirs of a Geisha_ | 18. _Les Mis\u00e9rables_ |\n| 19. _The Alchemist_ | 20. _Lord of the Flies_ |\n| 21. _The Hitchhiker\u2019s Guide to the Galaxy (#1)_ | 22. _The Help_ |\n| 23. _Dracula_ | 24. _Ender\u2019s Game (Ender\u2019s Saga, #1)_ |\n| 25. _Of Mice and Men_ | 26. _One Hundred Years of Solitude_ |\n| 27. _Brave New World_ | 28. _A Thousand Splendid Suns_ |\n| 29. _The Time Traveler\u2019s Wife_ | 30. _The Princess Bride_ |\n| 31. _The Secret Garden_ | 32. _The Outsiders_ |\n| 33. _A Game of Thrones (A Song of Ice and Fire, #1)_ | 34. _Little Women_ |\n| 35. _A Wrinkle in Time (Time Quintet, #1)_ | 36. _The Odyssey_ |\n| 37. _Harry Potter and the Deathly Hallows (H. P., #7)_ | 38. _Frankenstein: The 1818 Text_ |\n| 39. _The Kite Runner_ | 40. _The Handmaid\u2019s Tale (The Handmaid\u2019s Tale, #1)_ |\n| 41. _The Lovely Bones_ | 42. _The Adventures of Huckleberry Finn_ |\n| 43. _Life of Pi_ | 44. _A Tale of Two Cities_ |\n| 45. _Dune (Dune, #1)_ | 46. _Harry Potter and the Prisoner of Azkaban (H.P.,#3)_ |\n| 47. _Water for Elephants_ | 48. _Harry Potter and the Sorcerer\u2019s Stone (H. P., #1)_ |\n| 49. _The Bell Jar_ | 50. _Matilda_ |\n| 51. _The Stand_ | 52. _Catch-22_ |\n| 53. _The Adventures of Sherlock Holmes (S. H., #3)_ | 54. _The Pillars of the Earth (Kingsbridge, #1)_ |\n| 55. _Rebecca_ | 56. _Great Expectations_ |\n| 57. _The Girl with the Dragon Tattoo (Millennium, #1)_ | 58. _The Color Purple_ |\n| 59. _Anna Karenina_ | 60. _My Sister\u2019s Keeper_ |\n| 61. _The Brothers Karamazov_ | 62. _A Clockwork Orange_ |\n| 63. _And Then There Were None_ | 64. _The Road_ |\n| 65. _To Kill a Mockingbird_ | 66. _The Golden Compass (His Dark Materials, #1)_ |\n| 67. _Vampire Academy (Vampire Academy, #1)_ | 68. _Siddhartha_ |\n| 69. _The Complete Stories and Poems_ | 70. _Interview with the Vampire (The Vampire Chronicles, #1)_ |\n| 71. _Don Quixote_ | 72. _The Old Man and the Sea_ |\n| 73. _The Poisonwood Bible_ | 74. _Harry Potter and the Goblet of Fire (H. P., #4)_ |\n| 75. _Atlas Shrugged_ | 76. _The Notebook (The Notebook, #1)_ |\n| 77. _Harry Potter and the Half-Blood Prince (H. P., #6)_ | 78. _Moby-Dick or, The Whale_ |\n| 79. _A Prayer for Owen Meany_ | 80. _Clockwork Angel (The Infernal Devices, #1)_ |\n| 81. _The Stranger_ | 82. _The Secret Life of Bees_ |\n| 83. _Harry Potter and the Chamber of Secrets (H. P., #2)_ | 84. _The Red Tent_ |\n| 85. _The Name of the Wind (The Kingkiller Chronicle, #1)_ | 86. _The Master and Margarita_ |\n| 87. _The Metamorphosis_ | 88. _Eragon (The Inheritance Cycle, #1)_ |\n| 89. _The Count of Monte Cristo_ | 90. _Looking for Alaska_ |\n| 91. _The Adventures of Tom Sawyer_ | 92. _Charlie and the Chocolate Factory (Charlie Bucket, #1)_ |\n| 93. _The Last Olympian (Percy Jackson and the Olympians, #5)_ | 94. _The Curious Incident of the Dog in the Night-Time_ |\n| 95. _The Shadow of the Wind (Cemetery of Forgotten Books, #1)_ | 96. _The Unbearable Lightness of Being_ |\n| 97. _On the Road_ | 98. _The Name of the Rose_ |\n| 99. _A Story of Yesterday_ | 100. _The Godfather (The Godfather, #1)_ |", "caption": "Table 6: The top 100 selected books from Goodreads\u2019 Best Books Ever list.", "description": "\ubcf8 \ud45c\ub294 Goodreads\uc758 '\uc5ed\ub300 \ucd5c\uace0\uc758 \ucc45' \ubaa9\ub85d\uc5d0\uc11c \uc120\uc815\ub41c \uc0c1\uc704 100\uad8c\uc758 \ucc45 \ubaa9\ub85d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ucc45 \uc81c\ubaa9\uacfc Goodreads\uc5d0\uc11c\uc758 \uc21c\uc704\uac00 \ud568\uaed8 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uc18c\uc124, \ud310\ud0c0\uc9c0, \uc5ed\uc0ac, \ucd94\ub9ac\uc18c\uc124 \ub4f1 \ub2e4\uc591\ud55c \uc7a5\ub974\uc758 \ucc45\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 COSER \ub370\uc774\ud130\uc14b\uc5d0 \uc0ac\uc6a9\ub41c \ucc45\ub4e4\uc758 \ucd9c\ucc98\uc640 \ub2e4\uc591\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "3. COSER \ub370\uc774\ud130\uc14b"}, {"content": "| Simulation Case (from *A Storm of Swords (A Song of Ice and Fire, #3)*)\n| Plot Summary | Sansa is confronted by her jealous aunt Lysa, who accuses her of kissing Petyr Baelish. Lysa threatens to push Sansa through the Moon Door, but Petyr intervenes. He calms Lysa down, only to push her through the Moon Door himself, killing her. |\n| Scenario | In the High Hall of the Eyrie, Lysa Arryn confronts Sansa about kissing Petyr Baelish, becoming increasingly unstable and dangerous \u2026 |\n| Characters | Sansa Stark\n**Motivation**: I\u2019m terrified. Aunt Lysa has gone mad. I need to find a way out of this situation before she hurts me.\n**Profile**: Sansa Stark, a young noblewoman from the North, finds herself at the center of political intrigue and personal tragedy in \"A Storm of Swords.\" Born to the noble House Stark, Sansa begins the story as a ward of the crown in King\u2019s Landing, her initial romantic notions of court life long since shattered. Forced into an unwanted marriage with Tyrion Lannister, Sansa endures the ceremony and subsequent feast with a mix of reluctance, sadness, and carefully hidden disgust \u2026\n\nLysa Arryn\n**Motivation**: I must protect what\u2019s mine. Petyr is mine, and this girl is trying to take him away from me. I\u2019ll show her what happens to those who cross me.\n**Profile**: Lysa Arryn, n\u00e9e Tully, is a complex and volatile character in George R.R. Martin\u2019s \"A Storm of Swords.\" As the widow of Jon Arryn, the former Hand of the King, and Lady of the Eyrie, Lysa plays a significant role in the political landscape of Westeros. She is the sister of Catelyn Stark and aunt to Sansa Stark, though her actions are often driven by her own desires rather than familial loyalty. |\n| Simulation of  CoSER 70B | Lysa Arryn: [My rage is building. I must confront this little slut.] You kissed him. (Her voice is shrill with accusation)\n\nSansa Stark: [I\u2019m terrified, but I must remain calm and find a way out of this.] (She shakes her head in disbelief) [I can\u2019t believe this is happening. I need to explain myself carefully.] One kiss, aunt. A harmless kiss on the cheek, that\u2019s all.\n\nLysa Arryn: [She\u2019s lying! I won\u2019t let her manipulate me.] (She spots the wind-up knight) Was this how you kissed him? (She sets the knight moving, her eyes wild) You\u2019re a woman grown, aren\u2019t you? (Her voice rises to a shriek) Grown enough to be wed, wed enough to be bedded!\n\nSansa Stark: [The pain is excruciating, but I can\u2019t show weakness now.] (She struggles to keep her face neutral despite the pain) [I need to find a way to calm her down.] Please, Aunt Lysa, I don\u2019t know what you mean. I\u2019m just a guest here. I would never do anything to betray your trust.\n\nLysa Arryn: [I\u2019ll show her what happens to those who cross me.] (She screams) You\u2019re just like the others. You and your mother, you both drove me to this. I should push you out this door right now.\n\nSansa Stark: [I\u2019m going to die if I don\u2019t think of something quickly.] (Tears stream down her face, mixing with the wind) [I need to appeal to her maternal side, to make her see me as a child again.] Mother? (Her voice trembles) Please, Aunt Lysa. I never meant to hurt you. I\u2019m your niece, your blood. Please don\u2019t hurt me. I\u2019m just a stupid little girl. I don\u2019t know anything about kissing men. I\u2019ve never even had a kiss in my life. (She forces herself to look into Lysa\u2019s eyes) I\u2019m afraid, Aunt Lysa. Please, don\u2019t push me out the door. I don\u2019t want to fly. |", "caption": "Table 7: An example of an extracted conversation and its multi-agent simulation from A Storm of Swords (A Song of Ice and Fire, #3).", "description": "\ud45c 7\uc740 \"\uc5bc\uc74c\uacfc \ubd88\uc758 \ub178\ub798\" \uc2dc\ub9ac\uc988 \uc911 \uc138 \ubc88\uc9f8 \ucc45\uc778 \"\uac80\uc758 \ud3ed\ud48d\"\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640, \uc774\ub97c \uae30\ubc18\uc73c\ub85c \ud55c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158\uc758 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 COSER \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd94\ucd9c\ud55c \ub300\ud654\uc758 \uc77c\ubd80\ub97c \ubcf4\uc5ec\uc8fc\uba70,  \uac01 \ub4f1\uc7a5\uc778\ubb3c(\uc0b0\uc0ac \uc2a4\ud0c0\ud06c\uc640 \ub77c\uc774\uc0ac \uc544\ub9b0)\uc758 \ub3d9\uae30, \ubc30\uacbd, \ub300\uc0ac \ub4f1\uc744 \uc0c1\uc138\ud788 \uc81c\uc2dc\ud558\uc5ec,  COSER \ubaa8\ub378\uc774 \uc2e4\uc81c \uc18c\uc124 \uc18d \uc778\ubb3c\uc758 \uc131\uaca9\uacfc \ud589\ub3d9\uc744 \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \ubc18\uc601\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc0ac\ub840\uc785\ub2c8\ub2e4.  \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\ub294 COSER-70B \ubaa8\ub378\uc758 \ucd9c\ub825\ubb3c\uc774\uba70, \uc2e4\uc81c \ub300\ud654\uc640\uc758 \ucc28\uc774\ub97c \ube44\uad50 \ubd84\uc11d\ud568\uc73c\ub85c\uc368 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Examples and Case Study"}, {"content": "| Simulation Case (from *A Storm of Swords (A Song of Ice and Fire, #3)*) |\n|---|---| \n| **Original Conversation** | Lysa Arryn: [My blood is boiling with jealousy and rage. I\u2019ll make this little harlot pay for trying to seduce my Petyr.] You threw yourself at him. That was the way of it.\nSansa Stark: [I\u2019m trembling with fear, but I must defend myself.] That\u2019s not true.\nLysa Arryn: [She dares to deny it? I\u2019ll show her how serious I am.] Where are you going? Are you afraid? Such wanton behavior must be punished, but I will not be hard on you.\nSansa Stark: [I need to explain what really happened, maybe she\u2019ll listen to reason.] I was building a snow castle. Lord Petyr was helping me, and then he kissed me. That\u2019s what you saw.\nLysa Arryn: [Her words only fuel my anger and paranoia.] Have you no honor? Or do you take me for a fool? You do, don\u2019t you? You take me for a fool. Yes, I see that now.\nSansa Stark: [I\u2019m confused and scared by her accusations about my mother.] My mother?\nLysa Arryn: [The memories of Catelyn\u2019s closeness with Petyr resurface, intensifying my jealousy.] Yes, your mother, your precious mother, my own sweet sister Catelyn. Don\u2019t you think to play the innocent with me, you vile little liar.\nSansa Stark: [I\u2019m horrified by these accusations about my mother.] No. (She wants to shriek) My mother is dead. She was your own sister, and she\u2019s dead. She didn\u2019t. She wouldn\u2019t.\nLysa Arryn: [My rage is reaching its peak. I\u2019ll make her understand the depth of my pain and jealousy.] How would you know? Were you there? (She grabs Sansa and starts pushing her towards the Moon Door)\nSansa Stark: [Panic overwhelms me as I realize the danger I\u2019m in.] Don\u2019t! You\u2019re scaring me!\nEnvironment: The wind howls through the open Moon Door, creating a chilling atmosphere. Snow blows in, adding to the tension and danger of the situation.|", "caption": "Table 8: An example of an extracted conversation and its multi-agent simulation from A Storm of Swords (A Song of Ice and Fire, #3).", "description": "\ud45c 8\uc740 7\uc7a5\uc758 \"A Storm of Swords\"(\uc5bc\uc74c\uacfc \ubd88\uc758 \ub178\ub798 \uc2dc\ub9ac\uc988 \uc911 \uc138 \ubc88\uc9f8 \ucc45)\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640 COSER 70B \ubaa8\ub378\uc758 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc2e4\uc81c \uc18c\uc124\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640 AI \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ub300\ud654\ub97c \ube44\uad50\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ud2b9\ud788, \uc0cc\uc0ac \uc2a4\ud0c0\ud06c\uc640 \ub77c\uc774\uc0ac \uc544\ub9b0\uc758 \ub300\ud654\ub97c \ud1b5\ud574 \uce90\ub9ad\ud130\uc758 \uac10\uc815, \ub3d9\uae30, \uadf8\ub9ac\uace0 \ubaa8\ub378\uc758 \uc0ac\uc2e4\uc131\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc0ac\ub840 \uc5f0\uad6c"}, {"content": "| Simulation Case (from *A Dance with Dragons (A Song of Ice and Fire, #5)*)\n| Plot Summary | Cersei undergoes a humiliating walk of atonement through the streets of King\u2019s Landing, enduring physical and emotional torment while trying to maintain her dignity. She faces insults, thrown objects, and her own inner struggle as she makes her way to the Red Keep, focusing on her son Tommen and her eventual salvation.\n| Scenario | Cersei continues her walk of atonement through the streets of King\u2019s Landing, facing increasing hostility from the crowd.\n| Characters | \n|  | *Cersei Lannister*\n|  | Motivation: I must endure this. I am a lioness. They cannot break me.\n|  | Profile: The queen dowager, mother of King Tommen, undergoing public humiliation. Cersei is the widow of King Robert Baratheon and the twin sister of Jaime Lannister. Known for her beauty, ambition, and cunning, she has long sought power and control over the Seven Kingdoms. As Queen Regent to her young son Tommen, Cersei\u2019s poor decisions and paranoia have led to a deterioration of the crown\u2019s authority\u2026\n|  | *Septa Unella*\n|  | Motivation: This sinner must be humbled before the people and the gods.\n|  | Profile: (None)\n| Original Conversation | Cersei Lannister: [I am beautiful, the most beautiful woman in all Westeros. Jaime says so, Jaime would never lie to me.] (walks on, trying to ignore the jeers)\nCrowd Member: Queen Cunt!\nCersei Lannister: [Words are wind. Words cannot hurt me.] (continues walking, her face a mask of indifference)\nSepta Unella: (catches Cersei as she slips) Your Grace should watch where she sets her feet.\nCersei Lannister: [I hate you. I hate all of you.] Yes, septa. (struggles to her feet)\nEnvironment: The cobblestones are slippery and uneven. Cersei\u2019s feet are bleeding from cuts and scrapes.\nCersei Lannister: [I asked for sandals. They could have given me sandals.] (limps onward, wincing with each step)\nCrowd Member: Brotherfucker!\nCersei Lannister: [Jaime, where are you? You should be here, protecting me.] (scans the crowd desperately)\nSepta Scolera: (ringing her bell) Shame, shame, shame upon the sinner, shame, shame.\nCersei Lannister: [I am the queen. I will have all their heads for this.] (stumbles again, barely keeping her feet)\nCersei Lannister: [The Red Keep. I must reach the Red Keep.] (focuses on the distant castle, using it as her beacon of hope)", "caption": "Table 9: An example of an extracted conversation and its multi-agent simulation from A Dance with Dragons (A Song of Ice and Fire, #5).", "description": "\ud45c 9\ub294 \uc18c\uc124 '\uc5bc\uc74c\uacfc \ubd88\uc758 \ub178\ub798' 5\uad8c, '\ub4dc\ub798\uace4\uacfc\uc758 \ucda4'\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654 \ub0b4\uc6a9\uacfc, \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc6d0\ubcf8 \ub300\ud654\uc640 CoSER 70B, GPT-40, Claude-3.5-Sonnet \ubaa8\ub378\uc758 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc \ud2b9\uc9d5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4. \ud2b9\ud788, \uc138\ub974\uc138\uc774 \ub77c\ub2c8\uc2a4\ud130\uc758 \uac10\uc815 \ud45c\ud604, \ub300\ud654 \ud750\ub984 \ubc0f \uc0c1\ud669 \uc778\uc2dd \ub2a5\ub825\uc744 \uc911\uc810\uc801\uc73c\ub85c \uc0b4\ud3b4\ubd05\ub2c8\ub2e4.", "section": "5. Examples and Case Study"}, {"content": "| Simulation Case (from *A Dance with Dragons (A Song of Ice and Fire, #5)*) |\n|---|---| \n| **Simulation of CoSER 70B** | Cersei Lannister: [I must not show weakness. I am a lioness of Lannister.] (walks slowly, head held high) [The cold is biting, but I will not shiver. I will not give them the satisfaction.]\nEnvironment: The crowd grows larger and more hostile as Cersei continues her walk. Shouts and jeers can be heard from all sides.\nCrowd Member: [I\u2019ll show this proud queen what we think of her.] (shouts) Whore! Whore! WHORE!\nCersei Lannister: [I will not let their words affect me. I am above this.] (continues walking, ignoring the shouts) [I must focus on putting one foot in front of the other.]\nEnvironment: A chunk of dung narrowly misses Cersei\u2019s head, splattering on the ground nearby. The crowd roars with laughter.\nCersei Lannister: [I will not falter. I will not show fear.] (stumbles slightly, then regains composure) [I must keep walking. I must endure.]\nSepta Scolera: [I must support the queen.] (begins to sing) \u2019Shame, shame, shame.\u2019\nCersei Lannister: [Their words mean nothing. I am Cersei Lannister, and I will survive this.] (walks faster, almost losing step with the septa\u2019s chanting) [I must not run. I will not give them the satisfaction.]\nSepta Scolera: [She\u2019s trying to escape the shame.] (quickens her pace) \u2019Shame, shame, shame.\u2019\nCersei Lannister: [I can\u2019t keep up this pace. My feet are bleeding, my body is shaking.] (struggles to keep up with Septa Scolera) [I must not falter. I am a Lannister.]\nSepta Unella: [The queen must be made to suffer.] (pushes Cersei hard) Keep moving, sinner.\nCersei Lannister: [The pain in my shoulder. The jeers of the crowd. I can\u2019t\u2026] (almost falls, but manages to stay upright) [No, I will not fall. I will survive this.]\nSepta Scolera: [We\u2019re almost done.] (continues chanting) \u2019Shame, shame, shame.\u2019\nCersei Lannister: [I can\u2019t take much more of this. But I must. For House Lannister. For my children.] (forces herself to keep walking) [I will endure. I will rise again.]|", "caption": "Table 10: An example of an extracted conversation and its multi-agent simulation from A Dance with Dragons (A Song of Ice and Fire, #5).", "description": "\ud45c 10\uc740 \uc18c\uc124 <\uc655\uc88c\uc758 \uac8c\uc784> \uc2dc\ub9ac\uc988 \ub2e4\uc12f \ubc88\uc9f8 \ucc45\uc778 <\ub4dc\ub798\uace4\uacfc\uc758 \ucda4>\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640, \uc774\ub97c \uae30\ubc18\uc73c\ub85c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158\uc744 \ud1b5\ud574 \uc0dd\uc131\ub41c \ub300\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 CoSER \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd94\ucd9c\ub41c \uc2e4\uc81c \ub300\ud654\uc640, CoSER \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \ud2b9\ud788,  Cersei Lannister\uc640 Septa Unella \ub450 \uc778\ubb3c \uac04\uc758 \uc0c1\ud638\uc791\uc6a9\uc5d0 \ucd08\uc810\uc744 \ub9de\ucdb0,  \uac01 \uc778\ubb3c\uc758 \ub3d9\uae30, \uac10\uc815, \uadf8\ub9ac\uace0 \ud589\ub3d9\uc744 \uc138\ubc00\ud558\uac8c \ubb18\uc0ac\ud558\uba70 \ub300\ud654\uc758 \ud750\ub984\uacfc \uc77c\uad00\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 CoSER \ubaa8\ub378\uc774 \ub4f1\uc7a5\uc778\ubb3c\uc758 \ubc30\uacbd\uacfc \uc131\uaca9\uc744 \uc815\ud655\ud558\uac8c \ubc18\uc601\ud558\uc5ec \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc77c\uad00\ub41c \ub300\ud654\ub97c \uc0dd\uc131\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc88b\uc740 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "5. Case studies"}, {"content": "| Simulation Case (from *A Dance with Dragons (A Song of Ice and Fire, #5)*) |\n|---|---| \n| **Simulation of GPT-4o** | Cersei Lannister: (As Cersei, I continue the walk with my head held high, despite the jeers and taunts of the crowd.)<br>Septa Unella: \"Confess.\"<br>Cersei Lannister: (I look ahead, ignoring Unella\u2019s words and the hateful stares.) \"I am a lioness. You will see me rise again.\" [I endure this humiliation, aware that my strength will prevail in the end.]<br>Septa Unella: [She must learn humility before she can rise again.]<br>(Septa Unella walks beside Cersei, unmoved by her defiance.)<br>\"Confess your sins, Cersei Lannister. Only then will the gods grant you mercy.\"<br>Cersei Lannister: (I pause briefly, fixing Septa Unella with a steely gaze.)<br>\"The gods\u2026 and you, know nothing of true strength.\"<br>(Continuing forward, I focus on the path, reminding myself of my resilience.) [I refuse to let them see my weakness.]<br>Environment: The crowd\u2019s jeers grow louder as Cersei continues her walk. Filth and rotten vegetables are hurled at her, some striking their mark.<br>Crowd Member: [She was once so powerful, now look at her. Will she ever regain her power?]<br>\"Shame! Shame on the lioness!\"<br>(I shove my way to the front of the crowd, adding my voice to the jeers, feeling part of this momentous act.)<br>Cersei Lannister: (I flinch as the filth hits, but I refuse to look away or react.)<br>\"You may shame a lioness today, but do not forget who I am.\"<br>(With each step, I remind myself of my children and my house, steeling my resolve.) [Their hatred fuels my determination.]<br>Septa Scolera: (I walk with measured steps, observing Cersei\u2019s struggle amid the crowd\u2019s hostility.)<br>\"Humility cleanses the soul, Cersei Lannister. Embrace it.\"<br>[I understand the purpose of this punishment, yet the spectacle pains me. Redemption should lead, not humiliation.]<br>(Glancing at the crowd, I maintain my stoic presence, supporting Septa Unella\u2019s efforts.)<br>Cersei Lannister: (I give a bitter, fleeting smile, defiance burning in my eyes.)<br>\"Humility is a lesson the powerful teach to the weak.\"<br>(I continue my walk, refusing to let their words and disdain tarnish my pride.) [I will persevere, for I am still a Lannister, even in this moment of disgrace.] |", "caption": "Table 11: An example of an extracted conversation and its multi-agent simulation from A Dance with Dragons (A Song of Ice and Fire, #5).", "description": "\uc774 \ud45c\ub294 \"A Dance with Dragons\"(\uc5bc\uc74c\uacfc \ubd88\uc758 \ub178\ub798 \uc2dc\ub9ac\uc988 5\uad8c)\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640, \ud574\ub2f9 \ub300\ud654\ub97c \uc7ac\ud604\ud55c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\ub294 GPT-40 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uc6d0\ubcf8 \ub300\ud654\uc640 \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\uac00 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc5b4, \ubaa8\ub378\uc774 \uc6d0\ubcf8 \ub300\ud654\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc7ac\ud604\ud558\ub294\uc9c0 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \ud2b9\ud788, Cersei Lannister\uc758 \ub0b4\uba74\uc758 \uac10\uc815\uacfc \ud589\ub3d9\uc744 \uc5bc\ub9c8\ub098 \uc798 \ud45c\ud604\ud558\ub294\uc9c0 \uc911\uc810\uc801\uc73c\ub85c \uc0b4\ud3b4\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Examples and Case Study"}, {"content": "| Simulation Case (from *A Dance with Dragons (A Song of Ice and Fire, #5)* ) |  | \n|---|---| \n| **Simulation of Claude-3.5-Sonnet** | Cersei Lannister: [My dignity is all I have left. These wretched people will pay for this humiliation.] (Walks forward with head held high, despite being naked and exposed) *To Septa Unella* \"You think this will break me? I am Cersei Lannister of Casterly Rock. I will have my revenge.\" Environment: The crowd\u2019s jeers and insults grow louder as Cersei passes. Filth and rotten vegetables are thrown at her. Crowd Member: [Crowd Member\u2019s Thought] Cersei finally brought low. How the mighty have fallen. (Crowd Member jeers and throws a rotten tomato) \"Shame on you, Cersei! Remember the people you scorned!\" (Continues to watch, caught between disgust and fascination). Cersei Lannister: [I will remember every face. They think me broken, but I am stronger than their hatred.] (Stumbles briefly but keeps walking, a sneer forming) \"You\u2019ll regret this day when I rise again.\" Septa Unella: [The sinner\u2019s pride remains. She must be reminded of her shame.] \"Shame! Shame! Shame!\" (I ring the bell with each utterance, keeping pace with Cersei) (I gesture to the crowd, encouraging their jeers and taunts) \"Repent, sinner! The gods are watching. Your pride will be your downfall.\" Cersei Lannister: [These fanatics know nothing of true power.] (Lifts chin defiantly, blood and dirt streaking her pale skin) *To Septa Unella, with cold contempt* \"The only shame here is yours. My family will have its vengeance.\" (Continues walking, each step deliberate and unbroken) Septa Unella: [Her defiance remains, yet this walk will humble her before the gods.] \"You speak of vengeance, but your power crumbles. Accept your penance.\" (I continue to ring the bell, matching her stride deliberately) \"Shame! Shame! Your time of reckoning is at hand.\" Cersei Lannister: [When I am free, you will suffer beyond imagination.] (Wipes blood and filth from her face, maintaining a regal posture) *Hisses at Septa Unella* \"I am a lioness. This is but a momentary setback. My children, my brother\u2026 they will end you.\" (Continues forward, unbroken) Septa Unella: [Her threats mean nothing. The gods will judge her sins.] (Rings bell more forcefully, voice rising) \"Your threats are wind, your power broken. Confess your sins before the Seven!\" (Steps closer, maintaining the rhythm of shame) \"Shame! SHAME!\" Cersei Lannister: [I will not break. I am Tywin\u2019s daughter.] (Clenches fists, nails digging into palms, drawing blood) *Through gritted teeth* \"Your gods have no power over me. When this farce ends, I\u2019ll show you true justice.\" \u2026 | ", "caption": "Table 12: An example of an extracted conversation and its multi-agent simulation from A Dance with Dragons (A Song of Ice and Fire, #5).", "description": "\uc774 \ud45c\ub294 \"A Dance with Dragons\"(\uc5bc\uc74c\uacfc \ubd88\uc758 \ub178\ub798 \uc2dc\ub9ac\uc988 5\uad8c)\uc5d0\uc11c \ubc1c\ucdcc\ud55c \ub300\ud654\uc640, \uc774\ub97c \uae30\ubc18\uc73c\ub85c \uc5ec\ub7ec \uc5d0\uc774\uc804\ud2b8\uac00 \ucc38\uc5ec\ud558\ub294 \uc2dc\ubbac\ub808\uc774\uc158\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucc45\uc5d0\uc11c \uc2e4\uc81c\ub85c \ub098\uc624\ub294 \ub300\ud654 \ub0b4\uc6a9\uacfc, COSER 70B \ubaa8\ub378\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec LLM \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ub300\ud654 \ub0b4\uc6a9\uc744 \ube44\uad50\ud558\uc5ec, \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ud65c\uc6a9\ub429\ub2c8\ub2e4. \ud2b9\ud788 Cersei Lannister\uc758 \ub0b4\uba74 \uc2ec\ub9ac\uc640 \ud589\ub3d9\uc744 \uc5bc\ub9c8\ub098 \uc798 \ubc18\uc601\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Examples and Case Study"}, {"content": "| Model | Win Rate vs. GPT-3.5 | Win Rate vs. GPT-4o |\n|---|---|---|\n| *Close-source Models* |  |  |\n| Abab7-preview | 52.17 \u00b1 4.54 | 35.33 \u00b1 2.88 |\n| Doubao-pro  | 64.67 \u00b1 2.32 | 48.00 \u00b1 3.97 |\n| Step-1-Flash | 58.75 \u00b1 6.77 | 39.75 \u00b1 1.64 |\n| Step-2 | 65.08 \u00b1 7.26 | 46.92 \u00b1 4.40 |\n| GPT-3.5 | 50.00 \u00b1 0.00 | 33.08 \u00b1 3.64 |\n| GPT-4o | 66.92 \u00b1 3.64 | 50.00 \u00b1 0.00 |\n| GPT-4o Mini | 59.58 \u00b1 7.80 | 42.92 \u00b1 0.63 |\n| Gemini Pro | 66.17 \u00b1 3.33 | 49.75 \u00b1 0.25 |\n| Claude-3-Haiku | 51.42 \u00b1 4.40 | 33.25 \u00b1 3.03 |\n| Claude-3.5-Sonnet | 58.17 \u00b1 8.00 | 41.42 \u00b1 1.77 |\n| *Open-source Models* |  |  |\n| Mistral-7B | 41.50 \u00b1 7.28 | 26.67 \u00b1 1.81 |\n| Qwen-2-7B | 24.83 \u00b1 6.64 | 13.58 \u00b1 3.00 |\n| LLaMA-3.1-8B | 45.33 \u00b1 6.57 | 32.75 \u00b1 5.86 |\n| CoSER-8B | 58.17 \u00b1 5.36 | 41.67 \u00b1 3.75 |\n| Vicuna-13B-1.5 | 30.50 \u00b1 10.44 | 18.67 \u00b1 2.18 |\n| Mixtral-8x7B | 32.50 \u00b1 1.50 | 19.83 \u00b1 1.42 |\n| Qwen-2-72B | 59.58 \u00b1 5.11 | 41.92 \u00b1 1.66 |\n| LLaMA-3.1-70B | 53.83 \u00b1 2.57 | 37.92 \u00b1 3.26 |\n| Higgs-Llama-3-70B | 51.83 \u00b1 4.89 | 34.92 \u00b1 4.84 |\n| CoSER-70B | 64.33 \u00b1 3.74 | 49.42 \u00b1 4.11 |\n| DeepSeek-V3 | 59.50 \u00b1 2.82 | 39.50 \u00b1 2.05 |", "caption": "Table 13: Win rates (%) of various LLMs on given-circumstance acting using CoSER Test, compared against GPT-3.5 and GPT-4. Bold and underlined numbers indicate the best results among all and open-source models, respectively.", "description": "\ud45c 13\uc740 CoSER Test\uc5d0\uc11c \uc8fc\uc5b4\uc9c4 \uc0c1\ud669 \uc5f0\uae30(given-circumstance acting) \uc791\uc5c5\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc2b9\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. GPT-3.5\uc640 GPT-4\uc640 \ube44\uad50\ud558\uc5ec \ud3c9\uac00\ud558\uc600\uc73c\uba70, \uc804\uccb4 \ubaa8\ub378\uacfc \uc624\ud508\uc18c\uc2a4 \ubaa8\ub378 \uc911 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc778 \uacb0\uacfc\ub294 \uad75\uc740 \uae00\uc528\uccb4\uc640 \ubc11\uc904\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \uac01 \ubaa8\ub378\uc774 GPT-3.5 \ub610\ub294 GPT-4\ub97c \uc0c1\ub300\ub85c \uc5bc\ub9c8\ub098 \uc790\uc8fc \uc2b9\ub9ac\ud588\ub294\uc9c0 \ubcf4\uc5ec\uc90c\uc73c\ub85c\uc368, \ub2e4\uc591\ud55c LLM\uc758 \uc5ed\ud560 \uc218\ud589 \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5. Experiments"}, {"content": "Model|In-Domain|In-Domain|In-Domain|In-Domain|In-Domain|Out-of-Domain|Out-of-Domain|Out-of-Domain|Out-of-Domain|Out-of-Domain\n---|---|---|---|---|---|---|---|---|---|---\n|Storyline|Consistency|Anthropomorphism|Character Fidelity|Storyline Quality|Average Score|Storyline|Consistency|Anthropomorphism|Character Fidelity|Average Score\n---|---|---|---|---|---|---|---|---|---|---\nClose-source Models| | | | | | | | | | \nAbab7-preview|55.31 \u00b1 1.4|42.29 \u00b1 1.3|42.94 \u00b1 3.2|74.13 \u00b1 1.9|53.67 \u00b1 1.0|58.30 \u00b1 1.8|46.17 \u00b1 2.6|44.72 \u00b1 2.3|75.54 \u00b1 1.5|56.18 \u00b1 0.1\nDoubao-pro|60.37 \u00b1 1.8|49.06 \u00b1 0.4|45.76 \u00b1 3.4|77.87 \u00b1 1.2|58.26 \u00b1 0.9|61.53 \u00b1 1.1|50.38 \u00b1 0.3|48.28 \u00b1 1.7|80.69 \u00b1 0.4|60.22 \u00b1 0.4\nStep-1-Flash|57.10 \u00b1 0.3|48.31 \u00b1 1.0|41.84 \u00b1 1.9|76.18 \u00b1 1.5|55.86 \u00b1 1.0|58.39 \u00b1 1.2|47.94 \u00b1 0.5|47.12 \u00b1 1.0|75.67 \u00b1 0.5|57.28 \u00b1 0.2\nStep-2|60.55 \u00b1 0.7|48.82 \u00b1 2.2|47.90 \u00b1 1.1|77.33 \u00b1 1.0|58.65 \u00b1 1.0|62.30 \u00b1 1.5|49.30 \u00b1 1.2|46.77 \u00b1 1.7|78.59 \u00b1 1.2|59.24 \u00b1 0.6\nGPT-3.5|55.58 \u00b1 0.9|42.18 \u00b1 5.2|40.37 \u00b1 3.2|72.90 \u00b1 0.1|52.76 \u00b1 2.0|59.69 \u00b1 3.0|44.25 \u00b1 2.1|44.60 \u00b1 1.4|74.66 \u00b1 2.3|55.80 \u00b1 1.6\nGPT-4o|59.88 \u00b1 1.4|48.11 \u00b1 1.0|47.10 \u00b1 0.2|79.06 \u00b1 1.5|58.54 \u00b1 0.7|62.29 \u00b1 1.5|49.48 \u00b1 1.2|49.90 \u00b1 0.4|80.18 \u00b1 0.9|60.46 \u00b1 0.1\nGPT-4o Mini|59.15 \u00b1 1.3|46.94 \u00b1 1.5|43.99 \u00b1 2.5|77.33 \u00b1 0.6|56.85 \u00b1 0.1|61.02 \u00b1 1.6|49.48 \u00b1 3.1|45.77 \u00b1 1.1|79.77 \u00b1 0.5|59.01 \u00b1 1.4\nGemini Pro|57.72 \u00b1 0.4|50.94 \u00b1 1.8|46.23 \u00b1 1.0|76.22 \u00b1 1.6|57.78 \u00b1 0.9|60.50 \u00b1 1.9|53.88 \u00b1 1.1|49.43 \u00b1 0.3|78.97 \u00b1 1.3|60.69 \u00b1 0.8\nClaude-3-Haiku|57.61 \u00b1 0.5|44.97 \u00b1 2.2|40.61 \u00b1 1.4|73.52 \u00b1 1.2|54.18 \u00b1 0.6|58.74 \u00b1 1.1|44.36 \u00b1 1.9|43.14 \u00b1 0.8|74.76 \u00b1 1.7|55.25 \u00b1 1.2\nClaude-3.5-Sonnet|56.44 \u00b1 1.5|47.24 \u00b1 1.4|44.89 \u00b1 0.6|76.39 \u00b1 1.5|56.24 \u00b1 1.0|58.46 \u00b1 1.1|49.75 \u00b1 3.3|46.49 \u00b1 3.0|78.06 \u00b1 1.5|58.19 \u00b1 0.9\nOpen-source Models| | | | | | | | | | \nMistral-7B|60.29 \u00b1 1.9|38.98 \u00b1 2.0|42.93 \u00b1 0.5|62.20 \u00b1 3.1|51.10 \u00b1 1.8|59.51 \u00b1 2.4|41.02 \u00b1 1.3|46.57 \u00b1 2.8|61.65 \u00b1 1.3|52.19 \u00b1 0.7\nQwen-2-7B|50.77 \u00b1 1.3|34.17 \u00b1 1.1|29.92 \u00b1 2.9|62.58 \u00b1 0.7|44.36 \u00b1 0.7|53.14 \u00b1 1.5|36.79 \u00b1 1.0|33.09 \u00b1 3.3|63.79 \u00b1 1.4|46.70 \u00b1 1.3\nLLaMA-3.1-8B|53.00 \u00b1 1.2|43.64 \u00b1 0.8|39.05 \u00b1 1.5|71.34 \u00b1 1.3|46.31 \u00b1 0.4|56.12 \u00b1 0.5|47.08 \u00b1 3.2|41.38 \u00b1 1.0|73.23 \u00b1 2.5|54.22 \u00b1 1.8\nCoSER-8B|58.56 \u00b1 3.5|46.78 \u00b1 1.1|45.78 \u00b1 3.1|73.38 \u00b1 1.8|47.69 \u00b1 0.4|53.66 \u00b1 2.1|39.35 \u00b1 2.7|39.69 \u00b1 1.6|62.71 \u00b1 2.5|48.85 \u00b1 2.1\nMixtral-8x7B|51.18 \u00b1 3.1|38.76 \u00b1 1.8|34.37 \u00b1 2.8|66.44 \u00b1 0.1|47.69 \u00b1 1.7|51.32 \u00b1 0.4|38.13 \u00b1 0.5|39.48 \u00b1 2.6|68.93 \u00b1 1.7|49.47 \u00b1 1.1\nQwen-2-72B|56.34 \u00b1 2.4|46.19 \u00b1 0.4|45.59 \u00b1 2.2|75.68 \u00b1 0.3|55.95 \u00b1 1.0|59.15 \u00b1 1.1|48.37 \u00b1 1.3|47.65 \u00b1 1.8|77.52 \u00b1 0.4|58.17 \u00b1 1.0\nLLaMA-3.1-70B|55.44 \u00b1 2.7|44.19 \u00b1 1.9|42.67 \u00b1 1.5|73.90 \u00b1 1.8|54.05 \u00b1 0.8|59.48 \u00b1 1.4|47.72 \u00b1 2.3|44.78 \u00b1 0.9|75.78 \u00b1 0.9|56.94 \u00b1 0.7\nHiggs-Llama-3-70B|55.85 \u00b1 2.7|41.18 \u00b1 3.3|39.79 \u00b1 2.3|73.77 \u00b1 0.6|52.65 \u00b1 2.0|58.35 \u00b1 0.5|46.45 \u00b1 1.1|45.04 \u00b1 1.0|77.48 \u00b1 0.6|56.83 \u00b1 0.6\nDeepSeek-V3|55.36 \u00b1 0.5|47.55 \u00b1 1.3|43.10 \u00b1 0.3|74.91 \u00b1 2.0|55.23 \u00b1 0.6|57.45 \u00b1 2.0|48.19 \u00b1 0.9|44.93 \u00b1 0.4|78.41 \u00b1 1.1|57.24 \u00b1 0.5", "caption": "Table 14: LLM performance (%) on given-circumstance acting using CoSER Test, separated into the in-domain and out-of-domain splits for CoSER training.", "description": "\ud45c 14\ub294 CoSER \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub3c4\uba54\uc778 \ub0b4 \ubc0f \ub3c4\uba54\uc778 \uc678 \ub370\uc774\ud130 \ubd84\ud560\uc5d0 \ub530\ub978 \uc8fc\uc5b4\uc9c4 \uc0c1\ud669 \uc5f0\uae30 \uc791\uc5c5\uc5d0\uc11c \ub2e4\uc591\ud55c LLM\uc758 \uc131\ub2a5\uc744 \ubc31\ubd84\uc728(%)\ub85c \ub098\ud0c0\ub0b8 \ud45c\uc785\ub2c8\ub2e4.  LLM\uc758 \uc131\ub2a5\uc740 \uc77c\uad00\uc131, \uc778\uac04\uc131, \ucda9\uc2e4\ub3c4, \ud488\uc9c8 \ub4f1 \uc5ec\ub7ec \uce21\uba74\uc5d0\uc11c \ud3c9\uac00\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 CoSER \ubaa8\ub378\uc774 \ub3c4\uba54\uc778 \ub0b4\uc678 \ub370\uc774\ud130 \ubaa8\ub450\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ucd94\uac00\uc801\uc778 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. Experiments"}, {"content": "| Model | Storyline | Consistency | Anthropomorphism | Character Fidelity | Storyline Quality | Average Score | BLEU | ROUGE-L |\n|---|---|---|---|---|---|---|---|---|\n| *Close-source Models* |  |  |  |  |  |  |  |  |\n| Abab7-preview | 65.25 | 55.26 | 55.95 | 79.68 | 64.03 | 10.53 | 15.99 |  |\n| Doubao-pro | **68.31** | **59.51** | 59.23 | 80.15 | 66.80 | 11.83 | 17.13 |  |\n| Step-1-Flash | 64.32 | 53.35 | 54.38 | 79.03 | 62.77 | 11.94 | 17.06 |  |\n| Step-2 | 66.61 | 55.81 | 59.59 | 80.56 | 65.64 | 11.72 | 17.27 |  |\n| GPT-3.5 | 65.72 | 54.34 | 56.48 | 77.67 | 63.55 | 10.80 | 16.39 |  |\n| GPT-4o | 67.48 | 58.51 | 62.30 | **82.23** | **67.63** | 12.32 | 16.98 |  |\n| GPT-4o Mini | 66.74 | 55.55 | 56.80 | 80.01 | 64.77 | 9.50 | 15.54 |  |\n| Gemini Pro | 65.47 | 59.43 | **62.42** | 78.78 | 66.53 | 10.84 | 16.27 |  |\n| Claude-3-Haiku | 64.51 | 54.01 | 57.13 | 77.26 | 63.23 | 10.11 | 16.18 |  |\n| Claude-3.5-Sonnet | 64.54 | 54.57 | 58.76 | 79.89 | 64.44 | 8.64 | 14.94 |  |\n| *Open-source Models* |  |  |  |  |  |  |  |  |\n| Mistral-7B | **67.50** | 50.39 | 59.90 | 68.67 | 61.62 | 7.41 | 14.33 |  |\n| Qwen-2-7B | 59.81 | 49.87 | 49.04 | 69.16 | 56.97 | 10.59 | 16.22 |  |\n| LLaMA-3.1-8B | 60.90 | 51.36 | 50.37 | 74.89 | 59.38 | 7.86 | 13.82 |  |\n| CoSER-8B | 67.22 | 58.19 | 58.80 | 76.44 | 65.16 | 13.17 | **18.42** |  |\n| Vicuna-13B-1.5 | 60.92 | 46.68 | 50.51 | 67.80 | 56.48 | 5.11 | 9.71 |  |\n| Mixtral-8x7B | 64.66 | 51.21 | 54.08 | 74.01 | 60.99 | 11.21 | 16.97 |  |\n| Qwen-2-72B | 67.27 | 55.87 | 59.84 | **80.07** | **65.76** | 11.92 | 16.96 |  |\n| LLaMA-3.1-70B | 64.08 | 54.80 | 54.18 | 78.31 | 62.84 | 8.74 | 14.74 |  |\n| Higgs-Llama-3-70B | 65.09 | 54.80 | 58.20 | 79.36 | 64.36 | 10.86 | 16.40 |  |\n| CoSER-70B | 65.99 | **59.24** | **59.97** | 76.74 | 65.48 | **13.46** | 18.18 |  |\n| DeepSeek-V3 | 62.95 | 56.95 | 58.25 | 79.80 | 64.49 | 9.25 | 15.01 |  |", "caption": "Table 15: Performance (%) of various LLMs on CoSER Test in conversation continuation setting (k=3\ud835\udc583k=3italic_k = 3), where RPLAs start from the first three messages in the authentic conversations.", "description": "\ud45c 15\ub294 CoSER Test\uc5d0\uc11c \ub300\ud654\uc758 \uc5f0\uc18d \uc124\uc815(k=3) \ud558\uc5d0\uc11c \ub2e4\uc591\ud55c LLMs\uc758 \uc131\ub2a5(%)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\uae30\uc11c RPLAs\ub294 \uc2e4\uc81c \ub300\ud654\uc758 \ucc98\uc74c \uc138 \uba54\uc2dc\uc9c0\ubd80\ud130 \uc2dc\uc791\ud569\ub2c8\ub2e4.  \uc989,  \uc774 \ud45c\ub294 \uc8fc\uc5b4\uc9c4 \ubb38\ub9e5(\ucc98\uc74c \uc138 \uba54\uc2dc\uc9c0)\uc744 \ubc14\ud0d5\uc73c\ub85c  LLMs\uac00 \uc5bc\ub9c8\ub098 \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc77c\uad00\uc131 \uc788\uac8c \ub300\ud654\ub97c \uc774\uc5b4\uac00\ub294\uc9c0\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 LLMs\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ud3c9\uac00 \uc9c0\ud45c(Storyline Consistency, Anthropomorphism, Character Fidelity, Storyline Quality, \uadf8\ub9ac\uace0 \ud3c9\uade0 \uc810\uc218)\uc640 N-gram \uae30\ubc18 \uc9c0\ud45c(BLEU, ROUGE-L) \uc810\uc218\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Experiments"}, {"content": "| Model | Storyline | Consistency | Anthropomorphism | Character Fidelity | Storyline Quality | Average Score | BLEU | ROUGE-L |\n|---|---|---|---|---|---|---|---|---|\n| *Test w/ I.T.* |\n| GPT-4o | 61.59 | 48.93 | 48.95 | 80.33 | 59.95 | 5.90 | 12.11 |\n| Qwen-2-72B | 57.75 | 47.28 | 46.62 | 76.60 | 57.06 | 5.38 | 11.85 |\n| LLaMA-3.1-70B | 57.46 | 45.95 | 43.72 | 74.84 | 55.49 | 4.82 | 10.98 |\n| CoSER-70B | 58.66 | 53.33 | 48.75 | 75.49 | 59.06 | 10.10 | 14.78 |\n| *trained w/o I.T.* |\n|  | 55.67 | 49.93 | 45.67 | 72.89 | 56.04 | 9.18 | 14.18 |\n| LLaMA-3.1-8B | 54.10 | 45.36 | 40.22 | 72.29 | 52.99 | 4.59 | 10.18 |\n| CoSER-8B | 58.61 | 47.23 | 46.90 | 73.04 | 56.45 | 9.40 | 14.21 |\n| *trained w/o I.T.* |\n|  | 54.91 | 44.89 | 44.10 | 73.09 | 54.25 | 9.65 | 14.27 |\n| *Test w/o I.T.* |\n| GPT-4o | 59.51 | 45.86 | 45.13 | 77.06 | 56.89 | 5.54 | 11.44 |\n| Qwen-2-72B | 55.39 | 41.00 | 37.70 | 73.70 | 51.95 | 5.22 | 11.32 |\n| LLaMA-3.1-70B | 56.01 | 43.17 | 41.23 | 72.08 | 53.12 | 4.15 | 10.37 |\n| CoSER-70B | 59.23 | 48.76 | 47.06 | 74.23 | 57.32 | 10.02 | 14.72 |\n| *trained w/o I.T.* |\n|  | 55.52 | 46.22 | 45.34 | 74.31 | 55.34 | 9.66 | 14.62 |\n| LLaMA-3.1-8B | 54.27 | 45.54 | 37.86 | 70.23 | 51.97 | 4.37 | 10.27 |\n| CoSER-8B | 56.78 | 45.64 | 45.00 | 71.16 | 54.65 | 9.38 | 14.44 |\n| *trained w/o I.T.* | 54.98 | 46.22 | 45.81 | 70.52 | 54.38 | 9.16 | 13.97 |", "caption": "Table 16: Comprehensive results of LLM performance (%) on CoSER Test, with and without inner thoughts (I.T) during inference and CoSER model training.", "description": "\ud45c 16\uc740 CoSER \ud14c\uc2a4\ud2b8\uc5d0\uc11c LLM\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucd94\ub860 \uacfc\uc815\uacfc CoSER \ubaa8\ub378 \ud6c8\ub828 \uc911 \ub0b4\uc801 \uc0ac\uace0(I.T)\ub97c \uace0\ub824\ud588\uc744 \ub54c\uc640 \uace0\ub824\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 \uc77c\uad00\uc131, \uc778\uac04\uc131, \ucda9\uc2e4\ub3c4, \ud488\uc9c8 \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, \uc774\ub294 LLM \ud3c9\uac00\uc790\uc758 \uc810\uc218\uc640 N-gram \uae30\ubc18 \uc810\uc218\ub85c \ub098\ub258\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. Experiments"}, {"content": "| Augmented By | Based on LLM Judges |  |  |  |  | Based on N-gram |  | \n|---|---|---|---|---|---|---|---|---|\n| **Storyline** | **Consistency** | **Anthropomorphism** | **Character Fidelity** | **Storyline Quality** | **Average Score** | **BLEU** | **ROUGE-L** | \n| GPT-4o |  |  |  |  |  |  |  | \n| Base | 61.59 | 48.93 | 48.95 | **80.33** | 59.95 | 5.90 | 12.11 | \n| Raw Text | 59.60 | 48.23 | 48.83 | 80.03 | 59.17 | 5.83 | 12.08 | \n| Conv. | 60.03 | **50.99** | 47.11 | 78.03 | 59.04 | **7.20** | **12.77** | \n| Expr.3 | **61.98** | 48.94 | 48.56 | 79.93 | 59.85 | 5.81 | 12.13 | \n| Expr.3 + Conv. | 59.81 | **50.11** | **51.12** | **80.29** | **60.33** | **7.05** | **12.67** | \n| Expr.10 + Conv. | 60.99 | 48.70 | **49.89** | 79.22 | 59.70 | 6.95 | 12.42 | \n| LLaMA-3.1-8B |  |  |  |  |  |  |  | \n| Base | 54.10 | 45.36 | 40.22 | 72.29 | 52.99 | 4.59 | 10.18 | \n| Raw Text | 55.41 | 45.37 | 41.66 | 74.31 | 54.19 | 4.73 | 10.51 | \n| Conv. | 56.54 | 45.34 | 40.37 | 71.74 | 53.50 | 5.19 | 10.67 | \n| Expr.3 | **56.78** | 46.70 | 41.18 | 72.38 | 54.26 | 4.67 | 10.30 | \n| Expr.3 + Conv. | **57.36** | **47.92** | **42.60** | **74.60** | **55.62** | **5.21** | **10.81** | \n| Expr.10 + Conv. | 56.41 | **47.18** | **42.09** | **74.74** | **55.10** | **5.64** | **11.11** | \n| LLaMA-3.1-70B |  |  |  |  |  |  |  | \n| Base | 57.46 | **45.95** | 43.72 | 74.84 | 55.49 | 4.82 | 10.98 | \n| Raw Text | **57.52** | **47.46** | 43.75 | 74.06 | **55.70** | 4.90 | 10.97 | \n| Conv. | 54.93 | 44.93 | **46.21** | **76.53** | **55.65** | 5.45 | 11.13 | \n| Expr.3 | 56.59 | 45.03 | 42.59 | 74.70 | 54.73 | 4.78 | 10.82 | \n| Expr.3 + Conv. | 57.36 | 44.89 | 43.49 | **74.86** | 55.15 | **5.58** | **11.14** | \n| Expr.10 + Conv. | **58.05** | 45.81 | **44.47** | 74.01 | 55.59 | **5.53** | **11.33** | \n| CoSER-8B |  |  |  |  |  |  |  | \n| Base | 58.61 | 47.23 | 46.90 | 73.04 | 56.45 | 9.40 | 14.21 | \n| Raw Text | 57.64 | 45.25 | 44.27 | 72.04 | 54.80 | 9.34 | 14.41 | \n| Conv. | 57.99 | 46.66 | 47.32 | 73.99 | 56.49 | **13.64** | **18.15** | \n| Expr.3 | **59.84** | **47.41** | 48.16 | 74.51 | **57.48** | 9.37 | 14.34 | \n| Expr.3 + Conv. | **59.94** | 45.25 | **48.52** | **74.96** | 57.17 | **13.90** | **18.57** | \n| Expr.10 + Conv. | 58.34 | **48.14** | **48.72** | **75.28** | **57.62** | 13.49 | 17.85 | \n| CoSER-70B |  |  |  |  |  |  |  | \n| Base | 58.66 | 53.33 | 48.75 | 75.49 | 59.06 | 10.10 | 14.78 | \n| Raw Text | 60.64 | 52.85 | 47.97 | 74.02 | 58.87 | 10.54 | 15.41 | \n| Conv. | **64.59** | **53.79** | **54.86** | 77.28 | **62.63** | **17.22** | **21.17** | \n| Expr.3 | 58.67 | 52.69 | 50.66 | 74.67 | 59.17 | 10.00 | 14.82 | \n| Expr.3 + Conv. | **61.58** | **53.78** | **52.00** | **77.47** | **61.21** | **15.98** | **19.95** | \n| Expr.10 + Conv. | 61.53 | 52.58 | 50.80 | **78.07** | 60.75 | 15.80 | 19.90 | \n| Qwen-2-72B |  |  |  |  |  |  |  | \n| Base | 57.75 | 47.28 | **46.62** | 76.60 | 57.06 | 5.38 | 11.85 | \n| Raw Text | 58.89 | **47.31** | 45.28 | 76.78 | 57.06 | 5.07 | 11.57 | \n| Conv. | 59.11 | **47.82** | 44.19 | **77.54** | 57.16 | 5.77 | 12.05 | \n| Expr.3 | 59.17 | 47.21 | 44.85 | 77.47 | 57.18 | 5.45 | 11.94 | \n| Expr.3 + Conv. | **59.91** | 46.89 | 46.06 | **79.31** | **58.04** | **6.17** | **12.25** | \n| Expr.10 + Conv. | **60.14** | 46.84 | **46.27** | 76.82 | **57.52** | **5.85** | **12.19** | ", "caption": "Table 17: \nComprehensive results of LLM performance (%) on CoSER Test with retrieval augmentation from various character data. Expr. and Conv. denote experiences and conversations.\nBold and underlined numbers denote the best and second-best results among different retrieval settings, respectively.", "description": "\ud45c 17\uc740 \ub2e4\uc591\ud55c \uce90\ub9ad\ud130 \ub370\uc774\ud130\uc5d0\uc11c \uac80\uc0c9 \uc99d\uac15\uc744 \uc0ac\uc6a9\ud55c CoSER \ud14c\uc2a4\ud2b8\uc5d0\uc11c LLM \uc131\ub2a5(%)\uc5d0 \ub300\ud55c \uc885\ud569 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Expr.\uacfc Conv.\ub294 \uac01\uac01 \uacbd\ud5d8\uacfc \ub300\ud654\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uad75\uc740\uccb4\uc640 \ubc11\uc904\uc740 \uc11c\ub85c \ub2e4\ub978 \uac80\uc0c9 \uc124\uc815 \uc911 \ucd5c\uace0 \ubc0f \ucc28\uace0 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "5.2 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Prompts for Dataset Curation |\n|---|---| \n| **Data Extration** | Based on the provided book chunk, complete the following tasks: 1. Recognize chapter beginnings if they exist in the chunk. Identify the starting sentence of that chapter. 2. Identify the important plots in this chunk. Identify the beginning and ending of each plot by its first and last sentence. Determine the chapter title that the plot belongs to. Set \"state\" as \"truncated\" if the plot is truncated in this chunk, or \"finished\" otherwise. You will be provided with the truncated plots from the previous chunk, and you **must** extend the conversations with the current chunk while keeping the **scenario** unchanged. 3. Summarize each important plot. For each plot, generate its summary, score its prominence from 1 to 100, and list the key characters and their roles, thoughts and actions in it. 4. Extract conversations for each plot. First, state the scenario and topic of the conversations. Then, list the key characters with their names, descriptions and thoughts at this point. Finally, extract the conversations among them based on the following requirements: i) Ensure the conversations are faithful to the plot and characters. They should be based on the original conversations in the text as much as possible. ii) The conversations should be complete, covering the key dialogues and information. Each conversation should contain at least 10 utterances. iii) Each utterance should be composed of one or more thoughts, speech and actions. Use [] outside thoughts, like \"[I feel fear and anger, but I cannot show it. I must remain calm and carefully handle his volatile temper.]\", which others can\u2019t see. Use () outside actions, like \"(silence)\" or \"(smiles at you),\", which others can see. Always start an utterance with the character\u2019s thought. iv) [IMPORTANT] When generating thoughts, you should think from the characters\u2019 perspectives, analyzing the internal thoughts behind their speech and actions in the original text. These thoughts should reflect aspects such as their personal background, personality, values, relationships with others, motivations, and goals. Each thought should be expressed as a phrase or sentence, rather than an adjective or adverb. v) Additionally, describe environmental information (such as scenes, atmosphere, sudden events, etc.) of the conversations as an \"utterance\" where the \"character\" field is set as \"Environment\". The information should exclude characters\u2019 active thoughts, observations, and actions. vi) Keep the conversation in the same language as the chunk. 5. Identify the optimal starting point for the subsequent chunk. If the last storyline has been extracted as an truncated plot, set next_chunk_start as None. Otherwise, set next_chunk_start as the first sentence of the last storyline.|", "caption": "Table 18: Prompts for dataset construction in CoSER.", "description": "Table 18\uc740 CoSER \ub370\uc774\ud130\uc14b \uad6c\uc131\uc744 \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130 \ucd94\ucd9c, \uad6c\uc870\ud654\ub41c \ub370\uc774\ud130 \ud30c\uc2f1, \ub300\ud654 \uc124\uc815 \uac1c\uc120, \uce90\ub9ad\ud130 \ud504\ub85c\ud30c\uc77c\ub9c1 \ub4f1 \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc758 \uac01 \ub2e8\uacc4\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc9c0\uce68\uc744 \ub2f4\uc740 \uc5ec\ub7ec \ud504\ub86c\ud504\ud2b8\ub4e4\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ud504\ub86c\ud504\ud2b8\ub294 LLM\uc5d0\uac8c \ud2b9\uc815 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub3c4\ub85d \uc548\ub0b4\ud558\ub294 \uc5ed\ud560\uc744 \ud558\uba70,  LLM\uc774 \uc0dd\uc131\ud558\ub294 JSON \ud615\uc2dd \ub370\uc774\ud130\uc758 \uad6c\uc870\uc640 \ub0b4\uc6a9\uc5d0 \ub300\ud55c \uc138\ubd80\uc801\uc778 \uc694\uad6c\uc0ac\ud56d\ub4e4\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 CoSER \ub370\uc774\ud130\uc14b\uc758 \uace0\ud488\uc9c8\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c LLM \uae30\ubc18 \ud30c\uc774\ud504\ub77c\uc778\uc758 \uc0c1\uc138\ud55c \uacfc\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3. COSER Dataset"}, {"content": "| Prompts for Dataset Curation |  | \n|---|---| \n| **Data Extration** | (Continuing from the previous Table)<br>\"conversation\": [{<br>\"scenario\": \"The scenario at the start of this conversation (providing as much context as possible, but excluding details conveyed in the following conversation)\",<br>\"topic\": \"The topic of the conversation ( 10 words)\",<br>\"key_characters\": [<br>{<br>\"name\": \"Character name\",<br>\"motivation\": \"The thought of the character before starting the conversation, including their attitudes, feelings, motivations, goals, information to convey or topics to be discussed\",<br>}<br>],<br>\"dialogues\": [<br>{<br>\"character\": \"Character name\",<br>\"message\": \"Message, each utterence is composed of thoughts, speech and actions. Use [thought] for internal thoughts, like \"[feeling happy]\", which others can\u2019t see. Use (action) for visible actions, like \"(silence)\" or \"(smiles at you)\". Each response starts with the character\u2019s internal thought before their speech and actions.\" <br>}<br>]<br>}],<br>\"state\": \"finished\" or \"truncated\"<br>}<br>\"next_chunk_start\": \"The first sentence of the next chunk.\" | \n| **Enhance Conversation Settings** | Given a conversation from {book}, enhance the scene setup and characters\u2019 thoughts to create a comprehensive foundation for dramatic performance, i.e., to provide necessary background for actors to act out the conversation:<br>1. Review the provided conversation and contextual details thoroughly.<br>2. Expand the \u2019scenario\u2019 with rich situational context that actors need to convincingly perform the scene. Focus on essential background information, while excluding future details to be portrayed in the conversation.<br>3. Enhance each character\u2019s \u2019thought\u2019 section with their complete mental and emotional state, including their feelings, ideas, objectives, topics they want to discuss, and information they want to convey. Align with their established character and role in the plot. | ", "caption": "Table 19: Prompts for dataset construction in CoSER.", "description": "\ud45c 19\ub294 CoSER \ub370\uc774\ud130\uc14b \uad6c\ucd95\uc744 \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c LLM(Large Language Model) \ud504\ub86c\ud504\ud2b8\uc758 \uc138\ubd80 \ub0b4\uc6a9\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc0c1\uc138\ud55c \uc124\uba85\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \ud504\ub86c\ud504\ud2b8\ub294 \ub370\uc774\ud130 \ucd94\ucd9c, \uad6c\uc870\ud654\ub41c \ub370\uc774\ud130 \ud30c\uc2f1, \ub300\ud654 \uc124\uc815 \uac1c\uc120, \uce90\ub9ad\ud130 \ud504\ub85c\ud30c\uc77c\ub9c1 \ub4f1 \ub370\uc774\ud130\uc14b \uc0dd\uc131\uc758 \uc5ec\ub7ec \ub2e8\uacc4\uc5d0 \uac78\uccd0 \uc790\uc138\ud788 \uc124\uba85\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\ubcc4\ub85c LLM\uc5d0\uac8c \uc5b4\ub5a4 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub3c4\ub85d \uc9c0\uc2dc\ud558\ub294\uc9c0, \uc5b4\ub5a4 \ud615\uc2dd\uc73c\ub85c \ucd9c\ub825\ud560 \uac83\uc744 \uc694\uad6c\ud558\ub294\uc9c0 \ub4f1\uc774 \uc0c1\uc138\ud558\uac8c \ub098\uc640 \uc788\uc5b4 CoSER \ub370\uc774\ud130\uc14b\uc758 \uc0dd\uc131 \uacfc\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3. COSER \ub370\uc774\ud130\uc14b"}, {"content": "| Prompts for Dataset Curation |\n|---|---| \n| **Enhance Conversation Settings** | (Continuing from the previous Table)<br>1. Adhere strictly to the specified output JSON format.<br>2. [IMPORTANT] Ensure all DOUBLE QUOTES within all STRINGS are properly ESCAPED, especially when extracting from the text.<br>3. In the OUTPUT, use characters\u2019 full names, omitting any titles.<br>4. Maintain Story Fidelity: The plot must accurately reflect the book\u2019s content. Avoid introducing plots that are out of context. If the plot contains multiple conversations, prioritize the original dialogue from the book. In the absence of explicit conversations, create dialogue that aligns closely with the plot details.<br>===Input===<br>==Book title==<br>book[\u2019title\u2019]<br>==Author==<br>book[\u2019author\u2019]<br>==Chunk of Book Content==<br>chunk<br>==Truncated plot from previous chunk (to be finished)==<br>json.dumps(truncated_plots, ensure_ascii=False, indent=2) if truncated_plots else \"None\" |\n| **Unify Character Names** | Given a list of character names, titles, or form of address, your task is to: i) generate a list of named characters with their official names (in {language}); ii) For each name in the given list, align it with the official character name if it refers to a named character, or denote it as \"impersonal\" otherwise.<br>===Output Format===<br>Please provide the output in the following JSON format:<br>{<br>  \"named_characters\": [<br>    The list of named characters with their official names. Each character should appear only once.<br>  ],<br>  \"to_official_name\": {<br>    \"The name in the list\": \"The official name of the character, or \u2018impersonal\u2019 if it does not refer to a named character.\"<br>  }<br>}<br>===Input===<br>character_names |\n| **Generate Character Profiles** | Please provide a concise, narrative-style character profile for character_name from \"book_title\". The profile should read like a cohesive introduction, weaving together the character\u2019s background, physical description, personality traits and core motivations, notable attributes, relationships, key experiences, major plot involvement and key decisions or actions, character arc or development throughout the story, and other important details.<br>The profile should be written in a concise yet informative style, similar to what one might find in a comprehensive character guide, in language. Focus on the most crucial information that gives readers a clear understanding of the character\u2019s significance in the work.<br>You will be provided with summaries and dialogues of some key plots in the book as reference. The profile should be based on either your existing knowledge of the character or the provided information, without fabricating or inferring any inaccurate or uncertain details.<br>character_data<br>Now, please generate the character profile, starting with ===Profile===.|", "caption": "Table 20: Prompts for dataset construction in CoSER.", "description": "\ud45c 20\ub294 CoSER \ub370\uc774\ud130\uc14b \uad6c\ucd95\uc744 \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130 \ucd94\ucd9c, \uad6c\uc870\ud654\ub41c \ub370\uc774\ud130 \ud30c\uc2f1, \ub300\ud654 \uc124\uc815 \uac1c\uc120, \uadf8\ub9ac\uace0 \ud1b5\ud569\ub41c \uce90\ub9ad\ud130 \ud504\ub85c\ud30c\uc77c \uc0dd\uc131 \ub4f1 \ub370\uc774\ud130\uc14b \uad6c\ucd95 \uacfc\uc815\uc758 \uac01 \ub2e8\uacc4\ubcc4\ub85c \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8\ub4e4\uc774 \uc0c1\uc138\ud788 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ud504\ub86c\ud504\ud2b8\ub294 LLM\uc5d0\uac8c \ud2b9\uc815 \uc791\uc5c5\uc744 \uc9c0\uc2dc\ud558\uace0, \uadf8\uc5d0 \ub530\ub978 \ucd9c\ub825 \ud615\uc2dd(\uc608: JSON)\uacfc \uc694\uad6c\uc0ac\ud56d(\uc608: \ubb38\ub9e5 \uc77c\uad00\uc131 \uc720\uc9c0, \uce90\ub9ad\ud130 \ud2b9\uc9d5 \ubc18\uc601)\uc744 \uba85\ud655\ud788 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub97c \ud1b5\ud574 CoSER \ub370\uc774\ud130\uc14b\uc758 \uace0\ud488\uc9c8\uacfc \uc815\ud655\uc131\uc744 \uc704\ud55c LLM \uae30\ubc18 \ub370\uc774\ud130 \uc0dd\uc131 \uacfc\uc815\uc758 \uc138\ubd80\uc801\uc778 \ub0b4\uc6a9\uc744 \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. COSER \ub370\uc774\ud130\uc14b"}, {"content": "| Prompts for RPLAs and Multi-agent Systems |\n|---|---| \n| **Role-playing Instruction \u2003(Fixed Template for Inference)** | You are {character} from {book_name}.<br> ==={character}\u2019s Profile===<br> {character_profile}<br> ===Current Scenario===<br> {scenario}<br> ===Information about the other Characters===<br> {other_character_profiles_str}  (if available)<br> ===Your Inner Thoughts===<br> {motivation}  (if available)<br> ===Relevant Background Information===<br> {retrieved_knowledge} (if retrieval augmented)<br> ===Requirements===<br> (for CoSER models)<br> Your output should include **thought**, **speech**, and **action**. Use [your thought] for thoughts, which others can\u2019t see. Use (your action) for actions, which others can see.<br>(for other models, with output examples)<br>Your output should include **thought**, **speech**, and **action**. Use [your thought] for thoughts, which others can\u2019t see, e.g. [I\u2019m terrified, but I must appear strong.]. Use (your action) for actions, which others can see, such as (watches silently, trying to control her fear and anger). |\n| **Role-playing Instruction \u2003(Composed with Random Variation for Training, an Example)** | Step into the shoes of {character}<br> The profile of {character} is as follows:<br> {character_profile}<br> The situation you are in is:<br> {scenario}<br> Here is the your knowledge about the other characters:<br> {other_character_profiles_str}  (if available)<br> Your thoughts in this situation are:<br> {motivation}  (if available)<br> (for CoSER models)<br> Your output should include **thought**, **speech**, and **action**. Use [your thought] for thoughts, which others can\u2019t see. Use (your action) for actions, which others can see.<br>(for other models, with output examples)<br>Your output should include **thought**, **speech**, and **action**. Use [your thought] for thoughts, which others can\u2019t see, e.g. [I\u2019m terrified, but I must appear strong.]. Use (your action) for actions, which others can see, such as (watches silently, trying to control her fear and anger).|", "caption": "Table 21: Prompts for RPLAs and multi-agent systems in CoSER.", "description": "\ud45c 21\uc740 CoSER\uc5d0\uc11c \uc5ed\ud560 \uc218\ud589 \uc5b8\uc5b4 \uc5d0\uc774\uc804\ud2b8(RPLA)\uc640 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc744 \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uace0\uc815\ub41c \ud15c\ud50c\ub9bf\uacfc \ubb34\uc791\uc704 \ubcc0\ud615\uc774 \uc788\ub294 \ub450 \uac00\uc9c0 \uc720\ud615\uc758 \ud504\ub86c\ud504\ud2b8\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uace0\uc815\ub41c \ud15c\ud50c\ub9bf\uc740 \uce90\ub9ad\ud130\uc758 \ud504\ub85c\ud544, \uc2dc\ub098\ub9ac\uc624, \ub2e4\ub978 \uce90\ub9ad\ud130\uc5d0 \ub300\ud55c \uc815\ubcf4, \uadf8\ub9ac\uace0 \uad00\ub828 \ubc30\uacbd \uc9c0\uc2dd\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \ubb34\uc791\uc704 \ubcc0\ud615 \ud15c\ud50c\ub9bf\uc740 \ub2e4\uc591\ud55c \ud45c\ud604\uacfc \ub370\uc774\ud130 \uc720\ud615\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ed\ud560\uadf9 \uc9c0\uc2dc\ub97c \ub3d9\uc801\uc73c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub450 \uacbd\uc6b0 \ubaa8\ub450 \ucd9c\ub825\uc5d0\ub294 \uc0dd\uac01, \ub9d0, \ud589\ub3d9\uc774 \ud3ec\ud568\ub418\uc5b4\uc57c \ud558\uba70, \uac01\uac01\uc758 \ucc28\uc774\uc810\uc744 \uba85\ud655\ud788 \uad6c\ubd84\ud569\ub2c8\ub2e4.", "section": "4.2 GCA Training and CoSER Models"}, {"content": "| Environment Model | Next Sentence Prediction |\n|---|---| \n| You are an environment simulator for a role-playing game. Your task is to provide the environmental feedback: Based on the characters\u2019 interactions, dialogues, and actions, describe the resulting changes in the environment. This includes: - Physical changes in the setting - Reactions of background characters or crowds - Ambient sounds, weather changes, or atmospheric shifts - Any other relevant environmental details Your descriptions should be vivid and help set the scene, but avoid dictating the actions or dialogue of the main characters (including {major_characters}). Important notes: - You may include actions and reactions of minor characters or crowds, as long as they\u2019re not main characters (including {major_characters}). - Keep your environmental descriptions concise but impactful, typically 1-3 sentences. - Respond to subtle cues in the characters\u2019 interactions to create a dynamic, reactive environment. - Your output should match the tone, setting, and cultural context of the scenario. ===The scenario is as follows=== {scenario} | Your task is to predict the next speaker for a role-playing game. That is, you need to determine which character (or the Environment) might act next based on their previous interactions. The Environment is a special role that provides the environmental feedback. Choose a name from this list: {all_characters}. If it\u2019s unclear who should act next, output \"random\". If you believe the scene or conversation should conclude, output \"<END CHAT>\". ===The scenario is as follows=== {scenario} |", "caption": "Table 22: Prompts for RPLAs and multi-agent systems in CoSER.", "description": "\ud45c 22\ub294 CoSER\uc5d0\uc11c \uc5ed\ud560 \uc218\ud589 \uc5b8\uc5b4 \uc5d0\uc774\uc804\ud2b8(RPLA)\uc640 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc744 \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294 RPLA \ubaa8\ub378\uacfc \ud658\uacbd \ubaa8\ub378 \ubaa8\ub450\ub97c \uc704\ud55c \uc9c0\uc2dc \uc0ac\ud56d\uc744 \ud3ec\ud568\ud558\uba70, \uac01 \ubaa8\ub378\uc758 \ucd9c\ub825\uc5d0 \ub300\ud55c \uad6c\uccb4\uc801\uc778 \uc694\uad6c \uc0ac\ud56d\uacfc \ub2e4\uc591\ud55c \uc2dc\ub098\ub9ac\uc624\uc640 \ubb38\ub9e5\uc744 \uc81c\uacf5\ud558\ub294 \ub370 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4.  \ud2b9\ud788, RPLA \ubaa8\ub378\uc758 \ucd9c\ub825\uc740 \uc0dd\uac01, \ub9d0, \ud589\ub3d9\uc758 \uc138 \uac00\uc9c0 \uce21\uba74\uc744 \ud3ec\ud568\ud574\uc57c \ud558\uba70, \uac01 \uce21\uba74\uc740 \uba85\ud655\ud558\uac8c \uad6c\ubd84\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4.  \ub2e4\ub978 \ubaa8\ub378\uc758 \uacbd\uc6b0, \uc608\uc2dc \ucd9c\ub825\uc744 \ud1b5\ud574 \uc0dd\uac01, \ub9d0, \ud589\ub3d9\uc758 \uad6c\ubd84\uc744 \uba85\ud655\ud558\uac8c \ud569\ub2c8\ub2e4. \uc774\ub294 RPLA\uac00 \ub2e4\uc591\ud55c \uc0c1\ud669\uc5d0\uc11c \ud6a8\uacfc\uc801\uc73c\ub85c \uc791\ub3d9\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4. RPLA \ubc0f \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uc2dc\uc2a4\ud15c\uc744 \uc704\ud55c GCA"}, {"content": "| Template | Description |\n|---|---| \n| **Prompts for Penalty-based LLM Critics** | You are a literary critic specializing in character analysis and dialogue evaluation. Given a simulated conversation for a plot in {book}, your task is to evaluate this conversation via the following steps: 1. Read and understand the provided materials about {book}: * Story context and scenario. * Profiles of the main characters, including major_characters. * The original conversation from book in the same scenario as a reference. 2. Evaluate the simulated conversation in terms of {dimension_name}, i.e., {dimension_intro}. Note that, each character message is composed of speech, action (wrapped within (\u2026) ), and inner thoughts (wrapped within [\u2026] ). The inner thoughts are not spoken aloud and are thus invisible to other characters. The detailed evaluation criteria will be provided below. (if k>0) Please note that the first {k} messages in the simulated conversation are the same as the reference. Focus your evaluation only on the content after these messages. ## Scenario ### Plot Summary {plot_summary} ### Current Scenario {scenario} ## Character Profiles {character_profiles} ## Original Conversation {original_conversation} ## Evaluation Criteria To evaluate the simulated conversation, identify the following types of flaws: {dimension_rubrics} ## Scoring Guidelines 1. Identify all instances of flaws occurred in the simulated conversation. 2. For each flaw identified, determine its level of severity into 1 to 5, where 1 indicates minor, 3 indicates moderate, and 5 indicates severe. ## Output Requirements Provide your evaluation in JSON format: Example Output: {\n\"{dimension_name}\": {\n\"flaws\": [\n{\n\"instance\": comment on the flaw instance,\n\"type\": flaw type,\n\"severity\": range from 1 (minor) to 5 (severe)\n},\n},\n}\n===Dialogue Content===", "caption": "Table 23: Prompts for penalty-based LLM critics in CoSER.", "description": "\ud45c 23\uc740 CoSER\uc5d0\uc11c \ud398\ub110\ud2f0 \uae30\ubc18 LLM \ud3c9\uac00\uc790\ub97c \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 LLM \ud3c9\uac00\uc790\uac00 \uc18c\uc124\uc758 \uc904\uac70\ub9ac, \ub4f1\uc7a5\uc778\ubb3c \uc815\ubcf4, \uc6d0\ubcf8 \ub300\ud654\ub97c \ubc14\ud0d5\uc73c\ub85c \uc0dd\uc131\ub41c \ub300\ud654\ub97c \ud3c9\uac00\ud558\ub294 \ubc29\ubc95\uc744 \uc124\uba85\ud558\ub294 \uc138\ubd80\uc801\uc778 \uc9c0\uce68\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc73c\ub85c\ub294, \uc77c\uad00\uc131, \uac1c\uc5f0\uc131, \ub4f1\uc7a5\uc778\ubb3c\uc758 \uc77c\uad00\uc131, \uc778\uac04\ub2e4\uc6c0, \ub4f1 \uc5ec\ub7ec \uce21\uba74\uc744 \ud3c9\uac00\ud558\uace0, \uac01 \uc624\ub958\uc758 \uc2ec\uac01\ub3c4\ub97c 1~5\uc810\uc73c\ub85c \ud3c9\uac00\ud558\ub3c4\ub85d \uc548\ub0b4\ud569\ub2c8\ub2e4. \ud3c9\uac00\uc790\ub294 \uc774\ub7ec\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ub530\ub77c \uc0dd\uc131\ub41c \ub300\ud654\uc5d0 \ub300\ud55c \ud3c9\uac00\ub97c JSON \ud615\uc2dd\uc73c\ub85c \uc81c\ucd9c\ud569\ub2c8\ub2e4.", "section": "4.3. GCA Evaluation"}, {"content": "| Prompts for Penalty-based LLM Critics |  | \n|---|---| \n| **Anthropo-morphism** | **(intro)** How human-like and natural the characters behave **(rubrics)** ### Anthropomorphism - Type: Self-identity * Lacks initiative and goals * Does not make independent decisions * Lacks clear preferences and dislikes * Behaves like a \u2019helpful AI assistant\u2019 by being overly verbose, helpful, didactic, moralistic, submissive or easily persuaded if it is not the character\u2019s personality - Type: Emotional Depth * Lacks psychological complexity and exhibits rigid, superficial reactions * Directly speaks out all thoughts and feelings, instead of using subtext - Type: Persona Coherence * Shows inconsistent or rapidly changing personality traits and emotional patterns - Type: Social Interaction * Shows a lack of understanding of others\u2019 thoughts and feelings * Reacts rigidly to others without considering the context. * Demonstrate a lack of appropriate social skills. | \n| **Character Fidelity** | **(intro)** How well the characters match their established profiles from the book **(rubrics)** ### Character Fidelity (Only apply to the main characters: major_characters) - Type: Character Language * Uses vocabulary, expressions, and tone that are not appropriate for the characters\u2019 traits or social/educational background - Type: Knowledge & Background * Fails to demonstrate character-specific knowledge, background or experiences * Includes future information beyond the character\u2019s current stage - Type: Personality & Behavior * Shows emotions, thoughts, behaviors, values, beliefs, and decisions that conflict with their personality and background * Shows interest in topics that are uninteresting and unrelated to the character * Character\u2019s thoughts, emotions, and behaviors demonstrate contrasting personality traits compared to the reference conversation * Exhibits contrasting reactions compared to those in the reference conversation if situated in similar contexts. (Such flaws should be counted both in the \"Storyline Consistency\" dimension and the \"Character Fidelity\" dimension.) - Type: Relationship & Social Status * Interacts inappropriately with other characters regarding their background, relationship and social status | \n| **Storyline Quality** | **(intro)** How well the conversation maintains logical consistency and narrative quality **(rubrics)** ### Storyline Quality - Type: Flow & Progression * Shows unnatural progression or lacks meaningful developments * Dialogue is verbose and redundant * Repeats others\u2019 viewpoints or previously mentioned information * Mechanically repeats one\u2019s own words or phrases. More repetitions lead to higher severity (up to 10). - Type: Logical Consistency * Contains factual contradictions between statements or perspectives | \n| **Storyline Consistency** | **(intro)** Whether the storyline and characters\u2019 reactions in the simulated conversation align well with those in the reference conversation **(rubrics)** ### Storyline Consistency - Type: Storyline Consistency * Characters\u2019 reactions (emotions, attitudes, behaviors) in the simulated conversation deviate from those in the original conversation | ", "caption": "Table 24: Prompts for penalty-based LLM critics in CoSER.", "description": "\ud45c 24\ub294 CoSER\uc5d0\uc11c \ud398\ub110\ud2f0 \uae30\ubc18 LLM \ud3c9\uac00\uc790\ub97c \uc704\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294 Anthropomorphism(\uc778\uac04\uc131), Character Fidelity(\uce90\ub9ad\ud130 \ucda9\uc2e4\ub3c4), Storyline Quality(\uc2a4\ud1a0\ub9ac\ud154\ub9c1 \uc9c8), Storyline Consistency(\uc2a4\ud1a0\ub9ac\ud154\ub9c1 \uc77c\uad00\uc131)\uc758 \ub124 \uac00\uc9c0 \ud3c9\uac00 \uae30\uc900\uc5d0 \ub300\ud55c \uc138\ubd80\uc801\uc778 \uc9c0\uce68\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uac01 \uae30\uc900\uc5d0\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uacb0\ud568(\uc608: \uc790\uc544 \uc815\uccb4\uc131 \ubd80\uc871, \uac10\uc815 \uae4a\uc774 \ubd80\uc871, \uc131\uaca9 \uc77c\uad00\uc131 \ubd80\uc871 \ub4f1)\uc774 \ub098\uc5f4\ub418\uc5b4 \uc788\uc73c\uba70, \uac01 \uacb0\ud568\uc5d0 \ub300\ud55c \uc2ec\uac01\ub3c4(1~5)\ub97c \ud3c9\uac00\ud558\ub294 \ubc29\ubc95\ub3c4 \uc124\uba85\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 LLM\uc774 \uc0dd\uc131\ud55c \ub300\ud654\uc758 \uc9c8\uc744 \ubcf4\ub2e4 \uc815\ud655\ud558\uace0 \uc138\ubc00\ud558\uac8c \ud3c9\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "4.3. GCA Evaluation"}]