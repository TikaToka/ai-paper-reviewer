{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model for multimodal learning that significantly influenced the development of MLLMs and is frequently cited in related works."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduced the Chain-of-Thought prompting technique, which is a crucial method used for improving reasoning capabilities in LLMs and is directly relevant to the study of multimodal reasoning."}, {"fullname_first_author": "OpenAI", "paper_title": "GPT-4 system card", "publication_date": "2024-10-01", "reason": "GPT-4 is a leading state-of-the-art LLM used as a benchmark model in this paper, and its capabilities are important to contextualize the findings of the study."}, {"fullname_first_author": "OpenAI", "paper_title": "OpenAI o1 system card", "publication_date": "2024-12-01", "reason": "The o1 model is another leading multimodal reasoning model used for the benchmark, and its advanced capabilities shape the results and analysis of the study."}, {"fullname_first_author": "Yue Fan", "paper_title": "Muffin or chihuahua? challenging multimodal large language models with multipanel vqa", "publication_date": "2024-07-01", "reason": "This paper introduces a benchmark related to multimodal reasoning, demonstrating the ongoing interest in and challenges related to creating robust benchmarks for multimodal models."}]}