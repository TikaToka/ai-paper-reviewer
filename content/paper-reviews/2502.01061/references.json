{"references": [{"fullname_first_author": "Alexei Baevski", "paper_title": "wav2vec 2.0: A framework for self-supervised learning of speech representations", "publication_date": "2020-12-01", "reason": "This paper introduces wav2vec 2.0, a crucial framework for self-supervised learning of speech representations, which is directly used in OmniHuman's audio processing and feature extraction."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This foundational paper introduces denoising diffusion probabilistic models (DDPMs), the core technology behind the OmniHuman model architecture and the training strategy."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-01-01", "reason": "This paper introduces a highly efficient model architecture based on rectified flow transformers, forming the basis for the high-resolution video generation capability of OmniHuman."}, {"fullname_first_author": "Jianwen Jiang", "paper_title": "Loopy: Taming audio-driven portrait avatar with long-term motion dependency", "publication_date": "2024-01-01", "reason": "As a closely related work by the same research team, Loopy provides a crucial foundation for portrait animation, which OmniHuman significantly improves upon with its enhanced data scaling and multi-condition design."}, {"fullname_first_author": "Gaojie Lin", "paper_title": "CyberHost: Taming audio-driven avatar diffusion model with region codebook attention", "publication_date": "2024-01-01", "reason": "CyberHost, another relevant work from the same team, is used as a baseline model for comparison, indicating OmniHuman's significant advancements in addressing the limitations of existing audio-driven human animation methods."}]}