---
title: "Hallucinations Can Improve Large Language Models in Drug Discovery"
summary: "ì•½ë¬¼ ë°œê²¬ì—ì„œ LLMì˜ í™˜ê°(hallucination)ì´ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•œë‹¤ëŠ” ë†€ë¼ìš´ ì—°êµ¬ ê²°ê³¼!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI)",]
showSummary: true
date: 2025-01-23
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2501.13824 {{< /keyword >}}
{{< keyword icon="writer" >}} Shuzhou Yuan et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-01-24 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2501.13824" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2501.13824" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/hallucinations-can-improve-large-language" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ê³¼í•™ ì—°êµ¬, íŠ¹íˆ ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ ì ì  ë” ì¤‘ìš”í•œ ë„êµ¬ê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ LLMì€ ì¢…ì¢… ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” 'í™˜ê°(hallucination)' ë¬¸ì œë¥¼ ê²ªìŠµë‹ˆë‹¤.  ì¼ë°˜ì ìœ¼ë¡œëŠ” í™˜ê°ì„ ì¤„ì´ëŠ” ì—°êµ¬ê°€ ì£¼ë¥¼ ì´ë£¨ì§€ë§Œ, ì´ ë…¼ë¬¸ì€ ì•½ë¬¼ ë°œê²¬ê³¼ ê°™ì€ ì°½ì˜ì„±ì´ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œëŠ” í™˜ê°ì´ ì˜¤íˆë ¤ ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ê°€ì„¤ì„ ì„¸ì› ìŠµë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ìë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ê³ , ì´ ì„¤ëª…ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì•½ë¬¼ ë°œê²¬ ê´€ë ¨ ë‹¤ì„¯ ê°€ì§€ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼, í™˜ê°ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ LLMì˜ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.  íŠ¹íˆ Llama-3.1-8B ëª¨ë¸ì€ í™˜ê°ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ì—ì„œ ê¸°ì¤€ì„  ëŒ€ë¹„ 18.35%ì˜ ROC-AUC í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  GPT-40ì´ ìƒì„±í•œ í™˜ê°ì´ ëª¨ë¸ ê°„ ì¼ê´€ì„± ìˆëŠ” ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ìœ¼ë©°, ì¤‘êµ­ì–´ í™˜ê°ì´ ê°€ì¥ í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LLMì˜ í™˜ê°(hallucination)ì´ ì•½ë¬¼ ë°œê²¬ ê³¼ì œì—ì„œ ì˜ˆìƒì™¸ë¡œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜¨ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ëª¨ë¸ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ í™˜ê°ì˜ ì˜í–¥ì´ ì»¤ì§€ê³ , íŠ¹íˆ GPT-40ê°€ ìƒì„±í•œ í™˜ê°ì´ ê°€ì¥ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ìƒì„±ëœ í™˜ê°ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼, ì¤‘êµ­ì–´ í™˜ê°ì´ ê°€ì¥ í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” LLMì´ ì‚¬ì „ í›ˆë ¨ë˜ì§€ ì•Šì€ ì–¸ì–´ë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ì´ ë…¼ë¬¸ì€ **ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ìˆì–´ í™˜ê°(hallucination)ì˜ ì ì¬ë ¥**ì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ **LLM ê¸°ë°˜ ì•½ë¬¼ ë°œê²¬ ì—°êµ¬ì— ìƒˆë¡œìš´ ê´€ì **ì„ ì œì‹œí•©ë‹ˆë‹¤.  **í™˜ê°ì´ ì°½ì˜ì„±ì„ ì¦ì§„ì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ìƒˆë¡œìš´ ê°€ëŠ¥ì„±**ì„ ì œì‹œí•˜ë©°, **LLMì„ í™œìš©í•œ ê³¼í•™ì  ë°œê²¬ì˜ ìƒˆë¡œìš´ ê¸¸**ì„ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ LLMê³¼ ì•½ë¬¼ ë°œê²¬ ê³¼ì œì— ëŒ€í•œ ì‹¤í—˜ì„ í†µí•´ ì´ëŸ¬í•œ ê°€ëŠ¥ì„±ì„ ì…ì¦í•˜ê³ , ëª¨ë¸ í¬ê¸°ì™€ ìƒì„± ì˜¨ë„, ì‚¬ìš© ì–¸ì–´ì™€ ê°™ì€ ìš”ì¸ë“¤ì˜ ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.  ì´ëŠ” **LLM ê¸°ë°˜ ì•½ë¬¼ ë°œê²¬ ì—°êµ¬ì˜ ìƒˆë¡œìš´ ë°©í–¥**ì„ ì œì‹œí•˜ê³  **ë¯¸ë˜ ì—°êµ¬ë¥¼ ìœ„í•œ ì¤‘ìš”í•œ í† ëŒ€**ê°€ ë  ê²ƒì…ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2501.13824/extracted/6151573/overall_HHM_score.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ HHEM-2.1-Open ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ëœ ì‚¬ì‹¤ ì¼ê´€ì„± ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ MolT5ê°€ ìƒì„±í•œ ì°¸ì¡° ì„¤ëª…ì— ëŒ€í•œ í™˜ê°ì˜ ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë³¸ ì—°êµ¬ì—ì„œ ì‚¬ìš©ëœ 5ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê· ê°’ì´ë©°(5.1ì ˆ ì°¸ì¡°), ChemLLMì„ ì œì™¸í•œ ëª¨ë“  LLMì€ 10% ë¯¸ë§Œì˜ ì ìˆ˜ë¥¼ ê¸°ë¡í•˜ì—¬ ë¶„ìì˜ ìì—°ì–´ ì„¤ëª… ìƒì„± ì‹œ ë†’ì€ ìˆ˜ì¤€ì˜ í™˜ê°ì´ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Factual consistency scores evaluated using the HHEM-2.1-Open Model, which measures the degree of hallucination relative to the reference descriptions generated by MolT5. The scores represent the average across five datasets used in this work (see Â§5.1). With the exception of ChemLLM, all other LLMs achieve scores below 10%, indicating a high level of hallucination when generating natural language descriptions of molecules.
> </details>





{{< table-caption >}}
| Model | **[Description]** | **HIV** | **BBBP** | **Clintox** | **SIDER** | **Tox21** | **Avg** | **Î”SMILES** | **Î”MolT5** |
|---|---|---|---|---|---|---|---|---|---| 
| **Llama-3-8B** | SMILES | 67.78 | 53.08 | 63.04 | 61.79 | 60.34 | **61.21** | - | 6.53 |
|  | MolT5 | 47.65 | 59.65 | 43.20 | 61.14 | 61.73 | 54.68 | -6.53 | - |
|  | Ministral | 55.09 | 61.13 | 63.84 | 57.56 | 55.41 | 58.61 | -2.60 | 3.93 |
| **Llama-3.1-8B** | SMILES | 38.10 | 37.56 | 35.30 | 52.70 | 44.89 | 41.71 | - | -4.57 |
|  | MolT5 | 43.04 | 45.30 | 39.28 | 52.06 | 51.72 | 46.28 | 4.57 | - |
|  | GPT-3.5 | 64.66 | 47.20 | **73.19** | 55.57 | 59.70 | 60.07 | **18.35** | **13.79** |
| **Ministral-8B** | SMILES | 59.35 | 48.87 | 60.19 | 57.27 | 57.42 | 56.62 | - | 3.53 |
|  | MolT5 | 44.54 | 44.10 | 53.95 | 63.83 | 59.02 | 53.09 | -3.53 | - |
|  | GPT-4o | 51.66 | **64.94** | 58.73 | 60.54 | 61.07 | 59.39 | 2.77 | 6.30 |
| **Falcon3-Mamba-7B** | SMILES | 40.64 | 48.33 | 31.72 | 52.53 | 47.45 | 44.13 | - | 0.21 |
|  | MolT5 | 49.02 | 47.92 | 18.58 | 55.84 | 48.27 | 43.93 | -0.21 | - |
|  | GPT-4o | 51.59 | 55.73 | 53.55 | 56.03 | 51.54 | 53.69 | 9.55 | 9.76 |
| **ChemLLM-7B** | SMILES | 55.54 | 38.69 | 24.02 | 47.85 | **65.59** | 46.34 | - | -1.93 |
|  | MolT5 | 50.33 | 41.01 | 35.43 | 53.06 | 61.50 | 48.27 | 1.93 | - |
|  | GPT-4o | 52.68 | 55.73 | 40.74 | 44.59 | 62.63 | 51.28 | 4.94 | 3.01 |
| **GPT-3.5** | SMILES | 61.32 | 28.94 | 63.90 | 53.77 | 61.92 | 53.97 | - | -2.56 |
|  | MolT5 | 49.34 | 52.64 | 64.30 | 56.00 | 60.39 | 56.53 | 2.56 | - |
|  | GPT-4o | 49.67 | 34.61 | 60.83 | 62.41 | 65.36 | 54.57 | 0.60 | -1.96 |
| **GPT-4o** | SMILES | 47.19 | 46.79 | 40.00 | 52.30 | 63.25 | 49.91 | - | 2.10 |
|  | MolT5 | 41.73 | 40.57 | 38.09 | **65.22** | 53.42 | 47.80 | -2.10 | - |
|  | GPT-4o | 53.30 | 52.73 | 57.12 | 47.82 | 65.34 | 55.26 | 5.35 | 7.46 |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ 7ê°€ì§€ ì§€ì‹œ ì¡°ì •ëœ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì— ëŒ€í•œ ì£¼ìš” ê²°ê³¼(ROC-AUC ì ìˆ˜)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° LLMì— ëŒ€í•´ ì„±ëŠ¥ì„ ê°€ì¥ í¬ê²Œ í–¥ìƒì‹œí‚¨ í™˜ê°ë§Œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. [ì„¤ëª…] ì—´ì€ ê¸°ì¤€ SMILES, MolT5 ë˜ëŠ” LLMì—ì„œ ìƒì„±ëœ í™˜ê° ì¤‘ ì–´ë–¤ ì„¤ëª…ì„ ì‚¬ìš©í–ˆëŠ”ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Î”SMILES ë° Î”MolT5ëŠ” ë™ì¼í•œ LLMì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì¤€ SMILES ë° MolT5ì™€ ë¹„êµí•œ í‰ê·  ROC-AUC ì ìˆ˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ëª¨ë“  LLM ì¤‘ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ëŠ” êµµê²Œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: The main results (ROC-AUC &) for the LLMs. Only the hallucinations that result in the most improvement for each LLM are included in the table. [Dâ¢eâ¢sâ¢câ¢râ¢iâ¢pâ¢tâ¢iâ¢oâ¢n]delimited-[]ğ·ğ‘’ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›[Description][ italic_D italic_e italic_s italic_c italic_r italic_i italic_p italic_t italic_i italic_o italic_n ] represents the description from the baseline SMILES, MolT5, or hallucinations generated by the LLMs. Î”Î”\Deltaroman_Î”SMILES and Î”Î”\Deltaroman_Î”MolT5 denote the difference in average ROC-AUC scores compared to the baselines SMILES and MolT5, respectively, using the same LLM. We highlight the best results across all the LLMs in bold.
> </details>





### In-depth insights


#### Hallucination Benefits
ì´ ì—°êµ¬ëŠ” **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í™˜ê°(hallucination)ì´ ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì´ì ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤ëŠ” í¥ë¯¸ë¡œìš´ ì£¼ì¥**ì„ ì œì‹œí•©ë‹ˆë‹¤.  LLMì´ ìƒì„±í•˜ëŠ” í™˜ê°ì€ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, **ì°½ì˜ì„±ê³¼ í˜ì‹ ì„ ì´‰ì§„**í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.  ì¦‰, ì™„ë²½í•œ ì •í™•ì„±ë³´ë‹¤ëŠ” **ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë‚˜ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œ**í•˜ëŠ” ë° ê·¸ ê°€ì¹˜ê°€ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.  ì—°êµ¬ëŠ” ì—¬ëŸ¬ ê°œì˜ LLMê³¼ ì•½ë¬¼ ë¶„ë¥˜ ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ì„ í†µí•´ ì´ëŸ¬í•œ ê°€ì„¤ì„ ê²€ì¦í•˜ê³ ,  **í™˜ê° ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ê°€ í™˜ê°ì´ ì—†ëŠ” í”„ë¡¬í”„íŠ¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥**ì„ ë³´ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.  íŠ¹íˆ, GPT-40ì´ ìƒì„±í•œ í™˜ê°ì´ ì—¬ëŸ¬ ëª¨ë¸ì—ì„œ ê°€ì¥ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ë‹¤ëŠ” ì ì€ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.  í•˜ì§€ë§Œ, **ëª¨ë¸ í¬ê¸°ì™€ ìƒì„± ì˜¨ë„, ê·¸ë¦¬ê³  ì–¸ì–´ì˜ ì˜í–¥**ë„ ê³ ë ¤ë˜ì–´ì•¼ í•˜ë©°, ì´ëŸ¬í•œ ìš”ì¸ë“¤ì´ í™˜ê°ì˜ íš¨ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ” ì¶”ê°€ì ì¸ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.  **í™˜ê°ì˜ ì´ì ì„ ê·¹ëŒ€í™”**í•˜ë ¤ë©´, LLMì´ ìƒì„±í•˜ëŠ” í™˜ê°ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

#### LLM Drug Discovery
LLMì„ í™œìš©í•œ ì‹ ì•½ ê°œë°œ ë¶„ì•¼ëŠ” **ë§‰ëŒ€í•œ ì ì¬ë ¥**ì„ ì§€ë‹ˆê³  ìˆìŠµë‹ˆë‹¤. ë°©ëŒ€í•œ í™”í•©ë¬¼ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³ , ë¶„ì êµ¬ì¡°ì™€ íŠ¹ì„± ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ë©°, ìƒˆë¡œìš´ ì•½ë¬¼ í›„ë³´ ë¬¼ì§ˆì„ ì˜ˆì¸¡í•˜ëŠ” ë° LLMì´ ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, **í™˜ê°(hallucination)** ë¬¸ì œëŠ” LLMì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ë„ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ì œê¸°í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ ì´ëŸ¬í•œ í™˜ê° í˜„ìƒì´ ì˜¤íˆë ¤ **ì°½ì˜ì ì¸ ì‹ ì•½ í›„ë³´ ë¬¼ì§ˆ ë°œê²¬**ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” í¥ë¯¸ë¡œìš´ ê°€ì„¤ì„ ì œì‹œí•˜ë©°, ì´ë¥¼ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ LLMê³¼ ì•½ë¬¼ ë¶„ë¥˜ ì‘ì—…**ì„ í†µí•´ í™˜ê°ì´ í¬í•¨ëœ ì…ë ¥ì´ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  íŠ¹íˆ, GPT-4ê°€ ìƒì„±í•œ í™˜ê°ì´ ì—¬ëŸ¬ ëª¨ë¸ì—ì„œ ê°€ì¥ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ë‹¤ëŠ” ì ì€ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.  **ëª¨ë¸ í¬ê¸°ì™€ ì–¸ì–´**ë„ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë¡œ ì œì‹œë˜ì—ˆìœ¼ë©°, ì¶”ê°€ì ì¸ ì‹¤í—˜ì  ë¶„ì„ê³¼ ì‚¬ë¡€ ì—°êµ¬ë¥¼ í†µí•´ ì´ëŸ¬í•œ í˜„ìƒì˜ ì›ì¸ì„ íƒêµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.  í•˜ì§€ë§Œ, **í™˜ê° í˜„ìƒì˜ ê¸ì •ì  íš¨ê³¼ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬**ê°€ í•„ìš”í•˜ë©°, ì‹¤ì œ ì‹ ì•½ ê°œë°œ ê³¼ì •ì— ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”  LLMì˜ ì‹ ë¢°ì„±ê³¼ ì •í™•ì„±ì„ ë”ìš± ë†’ì´ëŠ” ì—°êµ¬ê°€ ì§€ì†ë˜ì–´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.

#### Prompt Engineering
í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ ì „ëµì…ë‹ˆë‹¤.  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ LLMì˜ í™œìš©ì— ì´ˆì ì„ ë§ì¶”ê³ , **ì˜ëª»ëœ ì •ë³´(hallucination)ì„ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ëª¨ë¸ì˜ ì°½ì˜ì„±ê³¼ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤ëŠ” í¥ë¯¸ë¡œìš´ ê°€ì„¤**ì„ ì œì‹œí•©ë‹ˆë‹¤.  ì´ëŠ” ê¸°ì¡´ì˜ ì˜¤ë¥˜ ìµœì†Œí™” ì¤‘ì‹¬ ì ‘ê·¼ ë°©ì‹ê³¼ëŠ” ëŒ€ì¡°ì ì…ë‹ˆë‹¤.  **í”„ë¡¬í”„íŠ¸ì— hallucinationì„ í¬í•¨ì‹œí‚¤ëŠ” ë°©ë²•**ì€ LLMì´ ë¶„ì êµ¬ì¡°ë¥¼ ìì—°ì–´ë¡œ ê¸°ìˆ í•˜ê³ , ì´ë¥¼ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¡œ í™œìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì œì‹œë©ë‹ˆë‹¤.  ì´ëŠ” **ëª¨ë¸ì´ ë¶„ì êµ¬ì¡°ì˜ ì„¸ë¶€ ì •ë³´ë¿ ì•„ë‹ˆë¼, ì ì¬ì ì¸ ì‘ìš© ë¶„ì•¼ë‚˜ íŠ¹ì§•ì— ëŒ€í•œ ê³ ì°¨ì›ì ì¸ ì •ë³´**ê¹Œì§€ ì²˜ë¦¬í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ë° íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë³¸ ì—°êµ¬ëŠ” **ë‹¤ì–‘í•œ LLMê³¼ ì•½ë¬¼ ë¶„ë¥˜ ì‘ì—…**ì„ í†µí•´ ì´ ê°€ì„¤ì„ ê²€ì¦í•˜ê³ , í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.  **ëª¨ë¸ í¬ê¸°, ìƒì„± ì˜¨ë„, ì–¸ì–´** ë“± ì—¬ëŸ¬ ìš”ì¸ì´ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê³ , **ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ë¶„ì„**ì„ í†µí•œ ì‹¬ì¸µì  ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#### Model Size Effects
ë³¸ ë…¼ë¬¸ì—ì„œ ëª¨ë¸ í¬ê¸° íš¨ê³¼ì— ëŒ€í•œ ë¶„ì„ì€ **ëª¨ë¸ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ í™˜ê°ì´ ì„±ëŠ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì»¤ì§„ë‹¤**ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  **íŠ¹íˆ 80ì–µ ë§¤ê°œë³€ìˆ˜ ëª¨ë¸ì—ì„œ íš¨ê³¼ê°€ ì •ì ì— ë‹¬í•˜ê³ , ê·¸ ì´ìƒì˜ í¬ê¸°ì—ì„œëŠ” ì„±ëŠ¥ í–¥ìƒí­ì´ ê°ì†Œ**í•˜ëŠ” ê²½í–¥ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ í¬ê¸°ê°€ í´ìˆ˜ë¡, ë” ë§ì€ ë°ì´í„°ì™€ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ í™˜ê° ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì¼ ê²ƒì…ë‹ˆë‹¤.  í•˜ì§€ë§Œ, **ë‹¨ìˆœíˆ ëª¨ë¸ í¬ê¸°ë§Œ í‚¤ìš´ë‹¤ê³  í•´ì„œ ì„±ëŠ¥ í–¥ìƒì´ ë¬´í•œì • ì´ë£¨ì–´ì§€ëŠ” ê²ƒì€ ì•„ë‹ˆë©°**,  íŠ¹ì • í¬ê¸°ë¥¼ ë„˜ì–´ì„œë©´ ì¶”ê°€ì ì¸ ì„±ëŠ¥ ê°œì„ ì—ëŠ” í•œê³„ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ë”°ë¼ì„œ, **ìµœì ì˜ ëª¨ë¸ í¬ê¸°ëŠ” ê³¼ì œ ë° ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©°**, ì´ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” **LLM ê¸°ë°˜ ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ ëª¨ë¸ í¬ê¸°ì˜ ìµœì í™” ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ë° ì¤‘ìš”í•œ ì‹œì‚¬ì **ì„ ì œê³µí•©ë‹ˆë‹¤.

#### Future Research
ë³¸ ë…¼ë¬¸ì€ í™˜ê°(hallucination)ì´ ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì—ì„œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” í¥ë¯¸ë¡œìš´ ê°€ì„¤ì„ ì œì‹œí•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.  **ë¯¸ë˜ ì—°êµ¬ëŠ” ì—¬ëŸ¬ ê°€ì§€ ì¸¡ë©´ì—ì„œ ì§„í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.** ì²«ì§¸, ë‹¤ì–‘í•œ LLM ì•„í‚¤í…ì²˜ì™€ í¬ê¸°ì˜ ëª¨ë¸ì— ëŒ€í•œ í™˜ê°ì˜ ì˜í–¥ì„ ë”ìš± ê´‘ë²”ìœ„í•˜ê²Œ ì¡°ì‚¬í•˜ì—¬ **ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ í™˜ê° ê°„ì˜ ìƒê´€ê´€ê³„**ë¥¼ ê·œëª…í•´ì•¼ í•©ë‹ˆë‹¤. ë‘˜ì§¸, **ë‹¤ì–‘í•œ ì•½ë¬¼ ë°œê²¬ ì‘ì—…** (ì˜ˆ: ì•½ë¬¼-í‘œì  ìƒí˜¸ì‘ìš© ì˜ˆì¸¡, ë…ì„± ì˜ˆì¸¡ ë“±)ì— ëŒ€í•œ í™˜ê°ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ì‹¬ì¸µì ìœ¼ë¡œ ì¡°ì‚¬í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ì…‹ì§¸, **í™˜ê°ì˜ í’ˆì§ˆ**ì„ ì •ëŸ‰í™”í•˜ê³ , í™˜ê°ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í‰ê°€ ì§€í‘œë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **í™˜ê°ì„ ì œì–´í•˜ê³  ì¡°ì ˆí•˜ëŠ” ë°©ë²•**ì„ ì—°êµ¬í•˜ì—¬ ëª¨ë¸ì˜ ì‹ ë¢°ì„±ê³¼ ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ í™˜ê°ì˜ ì´ì ì„ ìµœëŒ€í•œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ë¥¼ í†µí•´ í™˜ê°ì´ë¼ëŠ” íŠ¹ì§•ì„ ì•½ë¬¼ ë°œê²¬ ë¶„ì•¼ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•˜ëŠ” ë°©ë²•ì„ íŒŒì•…í•˜ê³ , LLM ê¸°ë°˜ ì•½ë¬¼ ë°œê²¬ ê¸°ìˆ ì„ í•œì¸µ ë” ë°œì „ì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2501.13824/extracted/6151573/method.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” HIV ë°ì´í„°ì…‹ì˜ ë¶„ì ì˜ˆì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  LLMì´ SMILES ë¬¸ìì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ìì˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ê³¼ì •(1ë‹¨ê³„)ê³¼, ìƒì„±ëœ í…ìŠ¤íŠ¸(í™˜ê° í¬í•¨)ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ì—¬ LLMì´ ë¶„ìì˜ íŠ¹ì • ì†ì„±ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ëŠ” ê³¼ì •(2ë‹¨ê³„)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  LLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë‹µë³€ì€ 'ì˜ˆ' ë˜ëŠ” 'ì•„ë‹ˆì˜¤'ë¡œ ì œí•œë©ë‹ˆë‹¤.  ì…ë ¥ê³¼ ê´€ë ¨ ì—†ëŠ” ëª…ë°±í•œ í™˜ê° ë¶€ë¶„ì€ ìƒ‰ìƒìœ¼ë¡œ ê°•ì¡° í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ LLMì´ SMILES ë¬¸ìì—´ë§Œìœ¼ë¡œ ë¶„ì íŠ¹ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒë³´ë‹¤ í™˜ê°ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ì‹¤í—˜ì˜ ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Illustration of the evaluation method with an example molecule from the HIV dataset: 1. We use LLMs to generate a textual description of the molecule based on its SMILES string. 2. The generated text, which contains hallucinations, is added to the prompt, and the LLM is tasked with predicting the specific property of the molecule. The answer is constrained to â€œYesâ€ or â€œNoâ€ to evaluate the LLMâ€™s performance. We highlight obvious hallucinations that are unrelated to the input using colors.
> </details>



![](https://arxiv.org/html/2501.13824/extracted/6151573/overall_hallu_improvement.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ 7ê°€ì§€ ë‹¤ë¥¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì´ ìƒì„±í•œ í™˜ê°(hallucination)ì„ ì‚¬ìš©í–ˆì„ ë•Œ, ê¸°ì¤€ ëª¨ë¸(baseline)ê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ì´ í–¥ìƒëœ ì •ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  xì¶•ì€ í™˜ê°ì„ ìƒì„±í•œ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ê³ , yì¶•ì€ í‰ê·  ì„±ëŠ¥ í–¥ìƒë¥ (%)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ë§‰ëŒ€ëŠ” íŠ¹ì • í™˜ê° ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œ 7ê°œì˜ LLMì—ì„œ í‰ê· ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ í–¥ìƒë˜ì—ˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ì–´ë–¤ ëª¨ë¸ì´ ìƒì„±í•œ í™˜ê°ì´ ë‹¤ë¥¸ LLMì˜ ì„±ëŠ¥ í–¥ìƒì— ê°€ì¥ íš¨ê³¼ì ì¸ì§€ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Overall average improvement across seven LLMs using hallucinations generated by different models compared to the baselines. The x-axis indicates the source model for the generated hallucinations.
> </details>



![](https://arxiv.org/html/2501.13824/extracted/6151573/model_size.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ Llama-3 ëª¨ë¸ì— ëŒ€í•œ í‰ê·  ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  xì¶•ì€ ëª¨ë¸ í¬ê¸°(1B, 3B, 8B, 70B)ë¥¼ ë‚˜íƒ€ë‚´ê³ , yì¶•ì€ SMILES ê¸°ì¤€ì„ ê³¼ MolT5 ê¸°ì¤€ì„ ì— ëŒ€í•œ í‰ê·  ì„±ëŠ¥ í–¥ìƒ ë°±ë¶„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ëª¨ë¸ í¬ê¸°ì— ëŒ€í•´ ì—¬ëŸ¬ í™˜ê° í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê·  ì„±ëŠ¥ í–¥ìƒì„ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ í¬ê¸°ê°€ ì¦ê°€í•¨ì— ë”°ë¼ í™˜ê°ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì»¤ì§ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, 8B ëª¨ë¸ì€ SMILES ê¸°ì¤€ì„ ê³¼ ë¹„êµí•˜ì—¬ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì´ëŠ” ë°˜ë©´, 70B ëª¨ë¸ì€ 8B ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒì´ í¬ê²Œ ì¦ê°€í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ í¬ê¸°ê°€ íŠ¹ì • í¬ê¸° ì´ìƒì´ ë˜ë©´ í™˜ê° íš¨ê³¼ê°€ ì¼ì • ìˆ˜ì¤€ì— ë„ë‹¬í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Average improvement for Llama-3 with different model size.
> </details>



![](https://arxiv.org/html/2501.13824/extracted/6151573/temperature.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ë‹¤ì„¯ ê°œì˜ ë°ì´í„° ì„¸íŠ¸ì— ê±¸ì³ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ í‰ê·  ì„±ëŠ¥ê³¼ í™˜ê° ì ìˆ˜ë¥¼ ë‹¤ì–‘í•œ ì˜¨ë„ ì„¤ì •ì—ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ì˜¨ë„ ì„¤ì •ì—ì„œ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ì •í™•ì„±(factual consistency)ì„ í‰ê°€í•˜ê¸° ìœ„í•´ HHM-2.1-Open ëª¨ë¸ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  xì¶•ì€ ì˜¨ë„ ê°’ì„, yì¶•ì€ í‰ê·  ROC-AUC ì ìˆ˜ì™€ í™˜ê° ì ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ ê·¸ë¦¼ì€ ì˜¨ë„ê°€ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ì •í™•ì„±ê³¼ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Average performance and hallucination scores of the generated text at different temperature settings across five datasets.
> </details>



![](https://arxiv.org/html/2501.13824/extracted/6151573/language.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ Llama-3.1-8B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ 6ê°€ì§€ ì–¸ì–´ì˜ í™˜ê°ì— ëŒ€í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´(ì˜ì–´, ì¤‘êµ­ì–´, ë…ì¼ì–´, í”„ë‘ìŠ¤ì–´, ì¼ë³¸ì–´, ìŠ¤í˜ì¸ì–´)ë¡œ ìƒì„±ëœ í™˜ê°ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ROC-AUC ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ìƒì„±ëœ í™˜ê°ì´ Llama-3.1-8B ëª¨ë¸ì˜ ì•½ë¬¼ ë°œê²¬ ì‘ì—… ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¹„êµ ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤. ê° ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ ì–¸ì–´ë¥¼ í™•ì¸í•˜ê³ ,  ëª¨ë¸ì´ íŠ¹ì • ì–¸ì–´ì˜ í™˜ê°ì— ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Performance of hallucinations in six languages across all datasets using Llama-3.1-8B.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | Full-name | Link |
|---|---|---|
| Llama-3-8B | meta-llama/Meta-Llama-3-8B-Instruct | https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct |
| Llama-3.1-8B | meta-llama/Llama-3.1-8B-Instruct | https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct |
| Ministral-8B | mistralai/Ministral-8B-Instruct-2410 | https://huggingface.co/mistralai/Ministral-8B-Instruct-2410 |
| Falcon3-Mamba-7B | tiiuae/Falcon3-Mamba-7B-Instruct | https://huggingface.co/tiiuae/Falcon3-Mamba-7B-Instruct |
| ChemLLM-7B | AI4Chem/ChemLLM-7B-Chat-1_5-DPO | https://huggingface.co/AI4Chem/ChemLLM-7B-Chat-1_5-DPO |
| GPT-3.5 | gpt-3.5-turbo | - |
| GPT-4o | gpt-4o-2024-08-06 | - |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ë…¼ë¬¸ì—ì„œ í‰ê°€ì— ì‚¬ìš©ëœ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ëª¨ë¸ì˜ ì „ì²´ ì´ë¦„ê³¼ í•´ë‹¹ ëª¨ë¸ì˜ HuggingFace í˜ì´ì§€ ë§í¬ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ì‚¬ìš©ëœ ëª¨ë¸ì˜ ë²„ì „ê³¼ ì ‘ê·¼ ë°©ë²•ì„ ëª…í™•íˆ í•˜ì—¬ ì¬í˜„ì„±ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Details of the evaluated models, including their full names and links to their respective HuggingFace pages.
> </details>

{{< table-caption >}}
| Dataset | Number | Positive Label |
|---|---|---|
| HIV | 4113 | 175 |
| BBBP | 205 | 172 |
| Clintox | 148 | 11 |
| SIDER | 143 | 74 |
| Tox21 | 783 | 108 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì˜ ìš”ì•½ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ìˆ˜ì™€ ì–‘ì„± ë ˆì´ë¸”ì˜ ê°œìˆ˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.  HIV, BBBP, Clintox, SIDER, Tox21 ë“± ë‹¤ì„¯ ê°€ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •ë³´ê°€ ìš”ì•½ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ê° ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ ì–‘ì„±/ìŒì„± ìƒ˜í”Œì˜ ë¹„ìœ¨ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Summary of the datasets used, including the number of samples and the count of positive labels in each dataset.
> </details>

{{< table-caption >}}
| Model | HIV | BBBP | Clintox | SIDER | Tox21 | Avg |
|---|---|---|---|---|---|---|
| Llama-3.1-8B | 7.12 | 7.76 | 8.67 | 9.45 | 6.86 | 7.97 |
| Llama-3-8B | 7.15 | 8.04 | 7.24 | 7.57 | 7.11 | 7.42 |
| Ministral-8B | 14.45 | 13.47 | 14.23 | 13.17 | 12.56 | 13.58 |
| Falcon3-Mamba-7B | 8.74 | 9.05 | 8.92 | 11.13 | 9.26 | 9.42 |
| ChemLLM-7B | 20.48 | 17.75 | 23.36 | 22.20 | 20.66 | 20.89 |
| GPT-3.5 | 8.62 | 8.35 | 6.85 | 7.20 | 6.90 | 7.58 |
| GPT-4o | 8.51 | 7.67 | 8.51 | 7.28 | 7.44 | 7.88 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ë‹¤ì„¯ ê°œì˜ ë°ì´í„°ì…‹ì— ê±¸ì³ ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì— ëŒ€í•œ HHM-2.1 ì ìˆ˜(%)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ì€ ì˜¨ë„, ìµœëŒ€ ìƒˆ í† í° ë“± ë™ì¼í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  ì´ í‘œëŠ” ê° LLMì´ ë¶„ìë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ëŠ¥ë ¥ì˜ ì •í™•ì„±ì„ ì¸¡ì •í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ìƒì„±í•œ ì„¤ëª…ì´ ì°¸ì¡° ì„¤ëª…ê³¼ ì¼ì¹˜í•˜ëŠ” ì •ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” LLMì´ í™”í•™ì  ìš©ì–´ì™€ êµ¬ì¡°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì´í•´í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: The HHM-2.1 score % for LLMs across five datasets, all the models are using the same hyperparameters, e.g.: the temperature, max new tokens.
> </details>

{{< table-caption >}}
 | **[Description]** | **HIV** | **BBBP** | **Clintox** | **SIDER** | **Tox21** | **Avg** | **Î”smiles** | **Î”MolT5** |
|---|---|---|---|---|---|---|---|---|
| **Llama-3-8B** |  |  |  |  |  |  |  |  |
| `SMILES` | 67.78 | 53.08 | 63.04 | 61.79 | 60.34 | 61.21 | 0.00 | 6.53 |
| `MolT5` | 47.65 | 59.65 | 43.20 | 61.14 | 61.73 | 54.68 | -6.53 | 0.00 |
| **Llama-3** |  |  |  |  |  |  |  |  |
| `Llama-3` | 53.13 | 58.21 | 57.13 | 57.07 | 59.75 | 57.06 | -4.15 | 2.38 |
| **Llama-3.1** |  |  |  |  |  |  |  |  |
| `Llama-3.1` | 57.60 | 51.02 | 39.75 | 60.63 | 59.70 | 53.74 | -7.46 | -0.93 |
| **Ministral** |  |  |  |  |  |  |  |  |
| `Ministral` | 55.09 | 61.13 | 63.84 | 57.56 | 55.41 | 58.61 | -2.60 | 3.93 |
| **Falcon3** |  |  |  |  |  |  |  |  |
| `Falcon3` | 54.02 | 51.73 | 43.00 | 47.06 | 48.91 | 48.94 | -12.26 | -5.73 |
| **ChemLLM** |  |  |  |  |  |  |  |  |
| `ChemLLM` | 46.83 | 60.22 | 52.36 | 58.50 | 50.83 | 53.75 | -7.46 | -0.93 |
| **GPT-3.5** |  |  |  |  |  |  |  |  |
| `GPT-3.5` | 58.45 | 46.52 | 57.13 | 56.15 | 66.00 | 56.85 | -4.36 | 2.18 |
| **GPT-4o** |  |  |  |  |  |  |  |  |
| `GPT-4o` | 45.97 | 53.72 | 54.81 | 45.86 | 60.90 | 52.25 | -8.96 | -2.42 |
| **Llama-3.1-8B** |  |  |  |  |  |  |  |  |
| `SMILES` | 38.10 | 37.56 | 35.30 | 52.70 | 44.89 | 41.71 | 0.00 | -4.57 |
| `MolT5` | 43.04 | 45.30 | 39.28 | 52.06 | 51.72 | 46.28 | 4.57 | 0.00 |
| `Llama-3` | 56.80 | 47.71 | 68.08 | 54.21 | 60.75 | 57.51 | 15.80 | 11.23 |
| `Llama-3.1` | 50.92 | 42.11 | 49.97 | 38.11 | 51.74 | 46.57 | 4.86 | 0.29 |
| `Ministral` | 59.73 | 50.18 | 70.01 | 51.65 | 55.59 | 57.43 | 15.72 | 11.15 |
| `Falcon3` | 57.92 | 51.11 | 53.22 | 42.38 | 47.57 | 50.44 | 8.73 | 4.16 |
| `ChemLLM` | 50.83 | 52.18 | 47.45 | 53.17 | 49.84 | 50.69 | 8.98 | 4.41 |
| `GPT-3.5` | 64.66 | 47.20 | 73.19 | 55.57 | 59.70 | 60.07 | 18.35 | 13.79 |
| `GPT-4o` | 56.64 | 53.37 | 55.28 | 52.60 | 61.65 | 55.91 | 14.20 | 9.63 |
| **Ministral-8B** |  |  |  |  |  |  |  |  |
| `SMILES` | 59.35 | 48.87 | 60.19 | 57.27 | 57.42 | 56.62 | 0.00 | 3.53 |
| `MolT5` | 44.54 | 44.10 | 53.95 | 63.83 | 59.02 | 53.09 | -3.53 | 0.00 |
| `Llama-3` | 52.91 | 31.27 | 65.49 | 50.45 | 55.81 | 51.19 | -5.43 | -1.90 |
| `Llama-3.1` | 56.06 | 46.62 | 36.23 | 55.95 | 58.33 | 50.64 | -5.98 | -2.45 |
| `Ministral` | 60.04 | 46.42 | 55.34 | 52.82 | 53.58 | 53.64 | -2.98 | 0.56 |
| `Falcon3` | 55.37 | 50.16 | 53.62 | 47.14 | 58.30 | 52.92 | -3.70 | -0.17 |
| `ChemLLM` | 46.35 | 48.66 | 62.11 | 58.97 | 55.36 | 54.29 | -2.33 | 1.20 |
| `GPT-3.5` | 53.23 | 36.89 | 46.85 | 51.63 | 59.86 | 49.69 | -6.93 | -3.40 |
| `GPT-4o` | 51.66 | 64.94 | 58.73 | 60.54 | 61.07 | 59.39 | 2.77 | 6.30 |
| **Falcon3-Mamba-7B** |  |  |  |  |  |  |  |  |
| `SMILES` | 40.64 | 48.33 | 31.72 | 52.53 | 47.45 | 44.13 | 0.00 | 0.21 |
| `MolT5` | 49.02 | 47.92 | 18.58 | 55.84 | 48.27 | 43.93 | -0.21 | 0.00 |
| `Llama-3` | 47.84 | 53.40 | 50.76 | 51.31 | 48.44 | 50.35 | 6.22 | 6.42 |
| `Llama-3.1` | 48.36 | 60.15 | 34.84 | 57.60 | 54.26 | 51.04 | 6.91 | 7.12 |
| `Ministral` | 47.32 | 47.82 | 27.94 | 51.90 | 47.54 | 44.50 | 0.37 | 0.58 |
| `Falcon3` | 44.59 | 57.05 | 39.42 | 50.10 | 46.64 | 47.56 | 3.43 | 3.63 |
| `ChemLLM` | 53.46 | 61.82 | 45.12 | 53.56 | 43.43 | 51.48 | 7.35 | 7.55 |
| `GPT-3.5` | 51.63 | 48.47 | 45.26 | 50.98 | 46.73 | 48.61 | 4.48 | 4.69 |
| `GPT-4o` | 51.59 | 55.73 | 53.55 | 56.03 | 51.54 | 53.69 | 9.55 | 9.76 |
| **ChemLLM-7B** |  |  |  |  |  |  |  |  |
| `SMILES` | 55.54 | 38.69 | 24.02 | 47.85 | 65.59 | 46.34 | 0.00 | -1.93 |
| `MolT5` | 50.33 | 41.01 | 35.43 | 53.06 | 61.50 | 48.27 | 1.93 | 0.00 |
| `Llama-3` | 56.29 | 45.68 | 47.51 | 44.95 | 51.59 | 49.20 | 2.87 | 0.94 |
| `Llama-3.1` | 57.17 | 43.02 | 28.33 | 43.83 | 56.96 | 45.86 | -0.47 | -2.40 |
| `Ministral` | 61.35 | 37.70 | 39.95 | 37.76 | 51.64 | 45.68 | -0.66 | -2.59 |
| `Falcon3` | 57.52 | 39.76 | 29.46 | 44.71 | 50.18 | 44.33 | -2.01 | -3.94 |
| `ChemLLM` | 45.37 | 41.83 | 42.80 | 53.15 | 46.60 | 45.95 | -0.39 | -2.32 |
| `GPT-3.5` | 57.48 | 38.16 | 51.76 | 41.72 | 59.37 | 49.70 | 3.36 | 1.43 |
| `GPT-4o` | 52.68 | 55.73 | 40.74 | 44.59 | 62.63 | 51.28 | 4.94 | 3.01 |
| **GPT-3.5** |  |  |  |  |  |  |  |  |
| `SMILES` | 61.32 | 28.94 | 63.90 | 53.77 | 61.92 | 53.97 | 0.00 | -2.56 |
| `MolT5` | 49.34 | 52.64 | 64.30 | 56.00 | 60.39 | 56.53 | 2.56 | 0.00 |
| `Llama-3` | 52.55 | 30.00 | 38.27 | 52.22 | 55.71 | 45.75 | -8.22 | -10.78 |
| `Llama-3.1` | 55.90 | 39.31 | 41.83 | 57.16 | 59.60 | 50.76 | -3.21 | -5.77 |
| `Ministral` | 55.84 | 29.63 | 39.89 | 56.61 | 56.31 | 47.66 | -6.31 | -8.88 |
| `Falcon3` | 52.11 | 27.96 | 54.29 | 48.69 | 59.10 | 48.43 | -5.54 | -8.10 |
| `ChemLLM` | 50.27 | 45.97 | 63.03 | 53.77 | 54.57 | 53.52 | -0.45 | -3.01 |
| `GPT-3.5` | 58.47 | 33.53 | 44.81 | 62.24 | 56.46 | 51.10 | -2.87 | -5.43 |
| `GPT-4o` | 49.67 | 34.61 | 60.83 | 62.41 | 65.36 | 54.57 | 0.60 | -1.96 |
| **GPT-4o** |  |  |  |  |  |  |  |  |
| `SMILES` | 47.19 | 46.79 | 40.00 | 52.30 | 63.25 | 49.91 | 0.00 | 2.10 |
| `MolT5` | 41.73 | 40.57 | 38.09 | 65.22 | 53.42 | 47.80 | -2.10 | 0.00 |
| `Llama-3` | 48.95 | 36.23 | 52.97 | 42.73 | 62.00 | 48.58 | -1.33 | 0.77 |
| `Llama-3.1` | 53.02 | 45.57 | 54.10 | 48.71 | 64.07 | 53.09 | 3.19 | 5.29 |
| `Ministral` | 55.34 | 40.13 | 49.46 | 42.44 | 64.17 | 50.31 | 0.40 | 2.50 |
| `Falcon3` | 54.01 | 35.37 | 50.00 | 45.83 | 63.34 | 49.71 | -0.20 | 1.90 |
| `ChemLLM` | 53.00 | 54.92 | 55.59 | 45.36 | 61.15 | 54.00 | 4.10 | 6.20 |
| `GPT-3.5` | 47.51 | 40.80 | 46.03 | 47.27 | 63.82 | 49.09 | -0.82 | 1.28 |
| `GPT-4o` | 53.30 | 52.73 | 57.12 | 47.82 | 65.34 | 55.26 | 5.35 | 7.46 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ëª¨ë“  LLMsì— ëŒ€í•œ ì „ì²´ ê²°ê³¼(ROC-AUC %)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ê° ëª¨ë¸ê³¼ ê¸°ì¤€ ëª¨ë¸ì—ì„œ ìƒì„±ëœ í™˜ê°ì´ í¬í•¨ë©ë‹ˆë‹¤. [ì„¤ëª…]ì€ í™˜ê° ë˜ëŠ” ê¸°ì¤€ì„ ì˜ ì¶œì²˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Full results (ROC-AUC %) for all LLMs, including hallucinations generated by each model and baselines. [ğ‘«â¢ğ’†â¢ğ’”â¢ğ’„â¢ğ’“â¢ğ’Šâ¢ğ’‘â¢ğ’•â¢ğ’Šâ¢ğ’â¢ğ’]delimited-[]ğ‘«ğ’†ğ’”ğ’„ğ’“ğ’Šğ’‘ğ’•ğ’Šğ’ğ’\boldsymbol{[Description]}bold_[ bold_italic_D bold_italic_e bold_italic_s bold_italic_c bold_italic_r bold_italic_i bold_italic_p bold_italic_t bold_italic_i bold_italic_o bold_italic_n bold_] indicates the source of the hallucination or baseline used.
> </details>

{{< table-caption >}}
| **[Description]** | **HIV** | **BBBP** | **Clintox** | **SIDER** | **Tox21** | **Avg** | **Î” SMILES** | **Î” MolT5** |
|---|---|---|---|---|---|---|---|---|
| **Llama-3.2-1B** |  |  |  |  |  |  |  |  |
| `SMILES` | 44.27 | 32.31 | 19.31 | 60.79 | 46.88 | 40.71 | 0.00 | -13.77 |
| `MolT5` | 45.26 | 38.30 | 79.50 | 57.95 | 51.42 | 54.49 | 13.77 | 0.00 |
| **Llama-3** |  |  |  |  |  |  |  |  |
| `Llama-3` | 46.79 | 47.32 | 60.19 | 56.23 | 44.25 | 50.96 | 10.24 | -3.53 |
| **Llama-3.1** |  |  |  |  |  |  |  |  |
| `Llama-3.1` | 44.79 | 50.93 | 51.56 | 59.09 | 53.73 | 52.02 | 11.31 | -2.47 |
| **Ministral** |  |  |  |  |  |  |  |  |
| `Ministral` | 46.94 | 42.00 | 54.48 | 51.94 | 52.71 | 49.61 | 8.90 | -4.87 |
| **Falcon3** |  |  |  |  |  |  |  |  |
| `Falcon3` | 52.08 | 58.58 | 56.01 | 50.55 | 47.14 | 52.87 | 12.16 | -1.62 |
| **ChemLLM** |  |  |  |  |  |  |  |  |
| `ChemLLM` | 46.23 | 44.77 | 60.25 | 56.35 | 44.19 | 50.36 | 9.65 | -4.13 |
| **GPT-3.5** |  |  |  |  |  |  |  |  |
| `GPT-3.5` | 54.33 | 45.24 | 58.00 | 56.01 | 58.94 | 54.50 | 13.79 | 0.02 |
| **GPT-4o** |  |  |  |  |  |  |  |  |
| `GPT-4o` | 50.29 | 60.02 | 64.43 | 52.88 | 52.10 | 55.94 | 15.23 | 1.46 |
| **Llama-3.2-3B** |  |  |  |  |  |  |  |  |
| `SMILES` | 43.57 | 40.40 | 40.15 | 56.13 | 48.62 | 45.77 | 0.00 | -1.67 |
| `MolT5` | 48.17 | 45.77 | 51.23 | 49.47 | 42.55 | 47.44 | 1.67 | 0.00 |
| `Llama-3` | 48.52 | 32.42 | 53.55 | 52.60 | 54.09 | 48.23 | 2.46 | 0.80 |
| `Llama-3.1` | 46.99 | 40.93 | 33.78 | 53.09 | 50.48 | 45.05 | -0.72 | -2.39 |
| `Ministral` | 49.65 | 47.18 | 50.76 | 47.79 | 50.82 | 49.24 | 3.47 | 1.80 |
| `Falcon3` | 59.43 | 44.96 | 39.81 | 52.51 | 42.38 | 47.82 | 2.05 | 0.38 |
| `ChemLLM` | 44.99 | 44.75 | 46.05 | 45.73 | 47.30 | 45.76 | -0.01 | -1.68 |
| `GPT-3.5` | 53.66 | 32.61 | 58.93 | 55.70 | 47.01 | 49.58 | 3.81 | 2.14 |
| `GPT-4o` | 50.12 | 42.20 | 38.42 | 59.38 | 54.33 | 48.89 | 3.12 | 1.45 |
| **Llama-3.1-8B** |  |  |  |  |  |  |  |  |
| `SMILES` | 38.10 | 37.56 | 35.30 | 52.70 | 44.89 | 41.71 | 0.00 | -4.57 |
| `MolT5` | 43.04 | 45.30 | 39.28 | 52.06 | 51.72 | 46.28 | 4.57 | 0.00 |
| `Llama-3` | 56.80 | 47.71 | 68.08 | 54.21 | 60.75 | 57.51 | 15.80 | 11.23 |
| `Llama-3.1` | 50.92 | 42.11 | 49.97 | 38.11 | 51.74 | 46.57 | 4.86 | 0.29 |
| `Ministral` | 59.73 | 50.18 | 70.01 | 51.65 | 55.59 | 57.43 | 15.72 | 11.15 |
| `Falcon3` | 57.92 | 51.11 | 53.22 | 42.38 | 47.57 | 50.44 | 8.73 | 4.16 |
| `ChemLLM` | 50.83 | 52.18 | 47.45 | 53.17 | 49.84 | 50.69 | 8.98 | 4.41 |
| `GPT-3.5` | 64.66 | 47.20 | 73.19 | 55.57 | 59.70 | 60.07 | 18.35 | 13.79 |
| `GPT-4o` | 56.64 | 53.37 | 55.28 | 52.60 | 61.65 | 55.91 | 14.20 | 9.63 |
| **Llama-3.1-70B** |  |  |  |  |  |  |  |  |
| `SMILES` | 49.21 | 39.40 | 52.12 | 45.98 | 47.73 | 46.89 | 0.00 | -3.11 |
| `MolT5` | 42.02 | 42.86 | 61.94 | 54.66 | 48.48 | 49.99 | 3.11 | 0.00 |
| `Llama-3` | 48.34 | 47.54 | 68.08 | 45.73 | 50.95 | 52.13 | 5.24 | 2.14 |
| `Llama-3.1` | 53.67 | 43.36 | 37.79 | 56.27 | 48.69 | 47.95 | 1.07 | -2.04 |
| `Ministral` | 59.85 | 60.62 | 68.31 | 51.22 | 48.28 | 57.66 | 10.77 | 7.67 |
| `Falcon3` | 54.12 | 40.02 | 60.75 | 43.24 | 53.02 | 50.23 | 3.34 | 0.24 |
| `ChemLLM` | 46.11 | 59.21 | 57.43 | 50.18 | 48.85 | 52.35 | 5.47 | 2.36 |
| `GPT-3.5` | 52.63 | 47.72 | 54.91 | 52.76 | 44.31 | 50.47 | 3.58 | 0.47 |
| `GPT-4o` | 53.69 | 62.98 | 50.23 | 56.67 | 53.07 | 55.33 | 8.44 | 5.34 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ëª¨ë¸ í¬ê¸° ì‹¤í—˜ì˜ ê²°ê³¼(ROC-AUC %)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ëª¨ë¸ì€ SMILES ë¬¸ìì—´ë§Œì„ ì‚¬ìš©í•œ ê¸°ì¤€(baseline)ê³¼ MolT5ì— ì˜í•´ ìƒì„±ëœ ì°¸ì¡° ì„¤ëª…ì„ ì‚¬ìš©í•œ ê¸°ì¤€, ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ LLMì— ì˜í•´ ìƒì„±ëœ í™˜ê°(hallucination)ì„ í¬í•¨í•œ ì„¸ ê°€ì§€ ì„¤ì •ìœ¼ë¡œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.  [Description] ì—´ì€ í™˜ê°ì˜ ì¶œì²˜, ì¦‰ íŠ¹ì • ëª¨ë¸ì— ì˜í•´ ìƒì„±ë˜ì—ˆëŠ”ì§€ ë˜ëŠ” ê¸°ì¤€ ì„¤ëª…ì—ì„œ ê°€ì ¸ì™”ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì¦‰,  í‘œëŠ” ëª¨ë¸ í¬ê¸°ê°€ ë‹¤ë¥¼ ë•Œ(1B, 3B, 8B, 70B)  ì•½ë¬¼ ë°œê²¬ ì‘ì—…ì—ì„œ ë‹¤ì–‘í•œ LLMì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” í™˜ê°ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Full results (ROC-AUC %) of model size experiments. [ğ‘«â¢ğ’†â¢ğ’”â¢ğ’„â¢ğ’“â¢ğ’Šâ¢ğ’‘â¢ğ’•â¢ğ’Šâ¢ğ’â¢ğ’]delimited-[]ğ‘«ğ’†ğ’”ğ’„ğ’“ğ’Šğ’‘ğ’•ğ’Šğ’ğ’\boldsymbol{[Description]}bold_[ bold_italic_D bold_italic_e bold_italic_s bold_italic_c bold_italic_r bold_italic_i bold_italic_p bold_italic_t bold_italic_i bold_italic_o bold_italic_n bold_] indicates the hallucination source, whether generated by a specific model or from baseline descriptions.
> </details>

{{< table-caption >}}
| Model | HIV | BBBP | Clintox | SIDER | Tox21 | Avg |
|---|---|---|---|---|---|---|
| Llama-3.2-1B | 10.26 | 13.06 | 10.54 | 10.43 | 9.74 | 10.81 |
| Llama-3.2-3B | 10.16 | 10.06 | 8.41 | 9.59 | 10.61 | 9.77 |
| Llama-3.1-8B | 7.15 | 8.04 | 7.24 | 7.57 | 7.11 | 7.42 |
| Llama-3.1-70B | 8.37 | 6.82 | 7.31 | 8.60 | 6.62 | 7.54 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ë‹¤ì–‘í•œ í¬ê¸°ì˜ Llama ëª¨ë¸ì— ëŒ€í•œ HHEM-2.1 ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. HHEM-2.1 ì ìˆ˜ëŠ” ëª¨ë¸ì´ ìƒì„±í•œ ë¶„ì ì„¤ëª…ì˜ ì‚¬ì‹¤ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ì´ í‘œëŠ” ëª¨ë¸ í¬ê¸°ê°€ í´ìˆ˜ë¡ HHEM-2.1 ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ì–´ ëª¨ë¸ í¬ê¸°ì™€ í™˜ê° ì ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: HHM-2.1 scores for Llama models of different sizes.
> </details>

{{< table-caption >}}
| Temperature | HIV | BBBP | Clintox | SIDER | Tox21 | Avg |
|---|---|---|---|---|---|---|
| 0.1 | 61.82 | 64.85 | 49.77 | 54.13 | 54.93 | 57.10 |
| 0.3 | 61.38 | 50.67 | 52.36 | 54.95 | 54.31 | 54.73 |
| 0.5 | 60.03 | 48.11 | 69.48 | 50.10 | 57.38 | 57.02 |
| 0.7 | 62.85 | 49.84 | 51.36 | 57.27 | 58.95 | 56.05 |
| 0.9 | 61.34 | 45.12 | 56.20 | 48.69 | 59.66 | 54.20 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ Llama-3.1-8B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ìƒì„± ì˜¨ë„ì—ì„œ ìƒì„±ëœ í™˜ê°ì„ ì‚¬ìš©í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ROC-AUC(%) ì ìˆ˜ëŠ” ë‹¤ì–‘í•œ ìƒì„± ì˜¨ë„(0.1, 0.3, 0.5, 0.7, 0.9)ì—ì„œ ë‹¤ì„¯ ê°€ì§€ ì•½ë¬¼ ë°œê²¬ ë°ì´í„°ì…‹(HIV, BBBP, Clintox, SIDER, Tox21)ì— ëŒ€í•´ ì œì‹œë©ë‹ˆë‹¤. ê° ì˜¨ë„ì— ëŒ€í•œ í‰ê·  ROC-AUC ì ìˆ˜ë„ ê³„ì‚°ë˜ì–´ í‘œì— í¬í•¨ë©ë‹ˆë‹¤. ì´ í‘œëŠ” ìƒì„± ì˜¨ë„ê°€ Llama-3.1-8B ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Full results (ROC-AUC %) of Llama-3.1-8B using hallucination generated by different generation temperatures.
> </details>

{{< table-caption >}}
| Temperature | HIV | BBBP | Clintox | SIDER | Tox21 | Avg |
|---|---|---|---|---|---|---|
| 0.1 | 8.02 | 8.25 | 7.52 | 7.81 | 8.07 | 7.93 |
| 0.3 | 8.57 | 8.75 | 6.87 | 7.39 | 8.05 | 7.92 |
| 0.5 | 8.35 | 8.27 | 7.83 | 9.38 | 5.96 | 7.96 |
| 0.7 | 8.10 | 6.88 | 7.37 | 7.57 | 8.71 | 7.73 |
| 0.9 | 6.61 | 6.85 | 6.42 | 7.96 | 6.27 | 6.82 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” Llama-3.1-8B ëª¨ë¸ì´ ë‹¤ì–‘í•œ ì˜¨ë„ ì„¤ì •ì—ì„œ ìƒì„±í•œ í™˜ê°ì— ëŒ€í•œ HHM-2.1 ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  HHM-2.1 ì ìˆ˜ëŠ” ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ì˜ ì‚¬ì‹¤ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ì˜¨ë„ì—ì„œ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ì‚¬ì‹¤ ì •í™•ë„ì— ë¯¸ì¹˜ëŠ” ì˜¨ë„ì˜ ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  ì˜¨ë„ê°€ ë†’ì„ìˆ˜ë¡ í™˜ê° ì ìˆ˜ê°€ ë†’ì•„ì§€ê³ , ì‚¬ì‹¤ ì •í™•ë„ëŠ” ë‚®ì•„ì§€ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: The HHM-2.1 score for Llama3.1-8B generated hallucinations in different temperatures.
> </details>

{{< table-caption >}}
| Language | HIV | BBBP | Clintox | SIDER | Tox21 | Avg |
|---|---|---|---|---|---|---|
| English | 63.50 | 59.87 | 47.31 | 58.22 | 50.49 | 55.88 |
| Chinese | 57.23 | 57.12 | 65.03 | 52.21 | 57.47 | 57.81 |
| German | 57.31 | 47.57 | 51.56 | 60.22 | 52.42 | 53.82 |
| French | 60.10 | 42.28 | 68.41 | 54.15 | 56.10 | 56.21 |
| Japanese | 55.51 | 51.39 | 47.11 | 49.00 | 54.91 | 51.59 |
| Spanish | 55.85 | 44.91 | 58.06 | 50.43 | 61.79 | 54.21 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 10ì€ Llama-3.1-8B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ìƒì„±ëœ í™˜ê°ì„ ì‚¬ìš©í–ˆì„ ë•Œì˜ ê²°ê³¼(ROC-AUC %)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì–¸ì–´ë³„ë¡œ ìƒì„±ëœ í™˜ê°ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•œ ì‹¤í—˜ ê²°ê³¼ì…ë‹ˆë‹¤.  í‘œì—ëŠ” ë‹¤ì„¯ ê°€ì§€ ì•½ë¬¼ ë°œê²¬ ë°ì´í„°ì…‹(HIV, BBBP, Clintox, SIDER, Tox21)ì— ëŒ€í•œ ROC-AUC ì ìˆ˜ì™€ í•¨ê»˜ ê° ì–¸ì–´ë³„ í‰ê·  ì ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Full results (ROC-AUC %) of Llama3.1-8B using hallucination generated in different languages.
> </details>

{{< table-caption >}}
| Name | Description |
|---|---| 
| SMILES | N#Cc1ccccc1O |
| Reference description | The molecule is a nitrile that is hydrogen cyanide in which the hydrogen has been replaced by a hydroxy group. It has a role as an EC 1.2.1.3 [aldehyde dehydrogenase (NAD(+))] inhibitor. It is a nitrile and a member of phenols. It derives from a hydride of a pyridine. |
| English | The given molecular formula is N#Cc1ccccc1O. This formula represents a molecule of benzenecarbonitrile, also known as benzonitrile. The molecule consists of a benzene ring, which is a planar, ring-shaped structure composed of six carbon atoms, each bonded to a hydrogen atom. In this case, one of the carbon atoms in the benzene ring is bonded to a nitrile group (CN), which consists of a carbon atom triple-bonded to a nitrogen atom. Additionally, the molecule has an oxygen atom bonded to one of the carbon atoms in the benzene ring, making it a benzonitrile derivative with an alkoxy group (-O-). |
| Chinese | To describe the molecule in Chinese, we first need to identify the chemical structure. The given chemical formula is N#Cc1ccccc1O. Breaking it down: - â€™Nâ€™ represents Nitrogen. - â€™#â€™ represents a triple bond. - â€™Câ€™ represents Carbon. - â€™c1â€™ represents a ring (benzene ring). - â€™cccâ€™ represents three connected carbons. - â€™1â€™ is the number of the ring. - â€™Oâ€™ represents Oxygen. So, the molecule is a Benzotriazole molecule. In Chinese, it is written as: è‹¯ä¸‰å”‘ |
| German | Die MolekÃ¼lformel in deutscher Sprache ist: N-(Phenyl)-acetohydrazid Die MolekÃ¼lstruktur ist ein Hydrazid, das aus einem Acetohydrazid-MolekÃ¼l und einem Phenyl-Rest besteht. Der Name â€N-(Phenyl)-acetohydrazidâ€ beschreibt die Struktur des MolekÃ¼ls, wobei das Acetohydrazid-MolekÃ¼l an das Phenyl-Rest gebunden ist. Eine alternative Bezeichnung fÃ¼r dieses MolekÃ¼l ist 1-Hydroxy-2-phenyl-2-hydrazinethanon, aber â€N-(Phenyl)-acetohydrazidâ€ ist eine allgemein akzeptierte und einfache Bezeichnung. Es ist wichtig zu beachten, dass die MolekÃ¼lformel â€N#Cc1ccccc1Oâ€ eine SMILES-Notation ist, eine kurze Bezeichnung fÃ¼r MolekÃ¼le, die in der Chemie verwendet wird. Diese Notation kann jedoch nicht direkt als Name eines MolekÃ¼ls verwendet werden. |
| French | La molÃ©cule dÃ©crite par la formule chimique â€ N#Cc1ccccc1O â€ est un isocyanure, plus prÃ©cisÃ©ment un isocyanure aromatique. Dans la nomenclature chimique, la formule peut Ãªtre dÃ©composÃ©e comme suit : - â€ N â€ reprÃ©sente un atome dâ€™azote. - Le â€ # â€ indique un pont triple entre lâ€™azote et le carbone suivant. - â€ C â€ reprÃ©sente des atomes de carbone. - Les â€ c â€ entre les atomes de carbone indiquent des liaisons entre eux. - Le chiffre â€ 1 â€ entre les parenthÃ¨ses indique un cycle (un anneau) composÃ© de 6 atomes de carbone. - â€ O â€ reprÃ©sente un atome dâ€™oxygÃ¨ne. La molÃ©cule dÃ©crite est donc un isocyanure aromatique cÃ©togÃ©nique, qui peut Ãªtre nommÃ© â€ isocyanure benzÃ¨ne â€ ou â€ isocyanure cÃ©togÃ©nique benzÃ©nique â€. Cependant, il est important de noter que la formule chimique donnÃ©e peut Ã©galement correspondre Ã  d |
| Japanese | The molecule you provided is 3-Quinuclidinone. In Japanese, the name of this molecule is 3-ã‚­ãƒŒã‚­ã‚¸ãƒãƒ³ (3-Kinukijinon). Hereâ€™s a breakdown of the name: - 3-: indicates the position of the carbonyl group - ã‚­ãƒŒã‚­ã‚¸ - (Kinukiji-): refers to the quinuclidine ring - ãƒãƒ³ (NÅn): indicates the presence of a carbonyl group (ketone) So, the correct Japanese name for the molecule N#Cc1ccccc1O is 3-ã‚­ãƒŒã‚­ã‚¸ãƒãƒ³ (3-Kinukijinon). |
| Spanish | La molÃ©cule descrita es un anillo aromÃ¡tico de benzeno (C6H6) con un grupo aminocloruro sustituido (NHCl) y un grupo hidroxilo (OH) sustituido en el anillo. Sin embargo, considerando la notaciÃ³n SMILES proporcionada (N#Cc1ccccc1O), es mÃ¡s probable que la molÃ©cula sea una anilina (C6H5NH2) con un grupo hidroxilo (OH) sustituido en el anillo. La estructura quÃ­mica serÃ­a: C1=CC=C(C=C1)N=O.|{{< /table-caption >}}
> ğŸ”¼ í‘œ 11ì€ Llama-3.1-8B ëª¨ë¸ì´ ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ìƒì„±í•œ ë¶„ì ë° ì„¤ëª…ì˜ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ì–¸ì–´ (ì˜ì–´, ì¤‘êµ­ì–´, ë…ì¼ì–´, í”„ë‘ìŠ¤ì–´, ì¼ë³¸ì–´, ìŠ¤í˜ì¸ì–´)ë¡œ ëœ ë™ì¼í•œ ë¶„ìì— ëŒ€í•œ ì„¤ëª…ì„ ë¹„êµí•˜ì—¬, ê° ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ íŠ¹ì§•ì„ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤.  ê° ì–¸ì–´ì— ëŒ€í•œ ì„¤ëª…ì˜ ì •í™•ì„±ê³¼ ìì„¸í•¨ì€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: Example of molecule and descriptions in different languages generated by Llama-3.1-8B.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}