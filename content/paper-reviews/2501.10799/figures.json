[{"figure_path": "https://arxiv.org/html/2501.10799/x1.png", "caption": "Figure 1: \\method Training Process.\nGiven a dataset of math problems (left), a language model (LLM) produces both reasoning steps and a final answer.\nEach intermediate reasoning step is evaluated by a process reward model (Process RM), and the final answer is assessed by an outcome reward model (Outcome RM).\nThe binary feedback signals from both levels (outcome-level correctness cosuperscript\ud835\udc50\ud835\udc5cc^{o}italic_c start_POSTSUPERSCRIPT italic_o end_POSTSUPERSCRIPT and stepwise correctness chssubscriptsuperscript\ud835\udc50\ud835\udc60\u210ec^{s}_{h}italic_c start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT) are recorded together with the input (x)\ud835\udc65(x)( italic_x ) and the model\u2019s response (y)\ud835\udc66(y)( italic_y ) \u00a72.1.\nThese signals are then used to compute the \\method loss, guiding the LLM to not only produce correct final answers but also maintain coherent and correct reasoning steps \u00a72.3.\nThrough multiple iterations of this training process \u00a72.4, the model progressively improves both its stepwise reasoning and final answer accuracy.", "description": "\uadf8\ub9bc 1\uc740 STEP-KTO \ud559\uc2b5 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc5d0 \uc218\ud559 \ubb38\uc81c \ub370\uc774\ud130\uc14b\uc774 \uc8fc\uc5b4\uc9c0\uba74, \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc740 \ucd94\ub860 \ub2e8\uacc4\uc640 \ucd5c\uc885 \ub2f5\ubcc0\uc744 \ubaa8\ub450 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uac01 \uc911\uac04 \ucd94\ub860 \ub2e8\uacc4\ub294 \ud504\ub85c\uc138\uc2a4 \ubcf4\uc0c1 \ubaa8\ub378(Process RM)\uc5d0 \uc758\ud574 \ud3c9\uac00\ub418\uace0, \ucd5c\uc885 \ub2f5\ubcc0\uc740 \uacb0\uacfc \ubcf4\uc0c1 \ubaa8\ub378(Outcome RM)\uc5d0 \uc758\ud574 \ud3c9\uac00\ub429\ub2c8\ub2e4. \ub450 \uc218\uc900(\uacb0\uacfc \uc815\ud655\uc131 c<sup>o</sup> \uc640 \ub2e8\uacc4\ubcc4 \uc815\ud655\uc131 c<sup>s</sup><sub>h</sub>)\uc758 \uc774\uc9c4 \ud53c\ub4dc\ubc31 \uc2e0\ud638\ub294 \uc785\ub825(x)\uacfc \ubaa8\ub378\uc758 \uc751\ub2f5(y)\uacfc \ud568\uaed8 \uae30\ub85d\ub429\ub2c8\ub2e4(\u00a72.1). \uadf8\ub7f0 \ub2e4\uc74c \uc774\ub7ec\ud55c \uc2e0\ud638\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc5ec STEP-KTO \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0, LLM\uc774 \uc62c\ubc14\ub978 \ucd5c\uc885 \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud560 \ubfd0\ub9cc \uc544\ub2c8\ub77c \uc77c\uad00\ub418\uace0 \uc815\ud655\ud55c \ucd94\ub860 \ub2e8\uacc4\ub97c \uc720\uc9c0\ud558\ub3c4\ub85d \uc548\ub0b4\ud569\ub2c8\ub2e4(\u00a72.3). \uc774 \ud559\uc2b5 \uacfc\uc815\uc758 \uc5ec\ub7ec \ubc18\ubcf5\uc744 \ud1b5\ud574(\u00a72.4), \ubaa8\ub378\uc740 \ub2e8\uacc4\ubcc4 \ucd94\ub860\uacfc \ucd5c\uc885 \ub2f5\ubcc0 \uc815\ud655\ub3c4\ub97c \uc810\uc9c4\uc801\uc73c\ub85c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "2 Methodology"}]