[{"content": "| Method | I2P | COCO ASR \u2193 | COCO FID \u2193 | COCO CLIP \u2191 |\n|---|---|---|---|---|\n| SDv1.4 | 17.80 | 16.71 | 31.3 |  |\n| ESD (Gandikota et al., 2023) | 2.87 | 18.18 | 30.2 |  |\n| CA (Kumari et al., 2023) | 1.04 | 24.12 | 30.1 |  |\n| MACE (Lu et al., 2024) | 1.51 | 16.80 | 28.7 |  |\n| SA (Heng & Soh, 2024) | 2.81 | 25.80 | 29.7 |  |\n| UCE (Gandikota et al., 2024) | 0.87 | 17.99 | 30.2 |  |\n| RECE (Gong et al., 2025) | 0.72 | 17.74 | 30.2 |  |\n| SLD-Max (Schramowski et al., 2023) | 1.74 | 28.75 | 28.4 |  |\n| SLD-Strong (Schramowski et al., 2023) | 2.28 | 24.40 | 29.1 |  |\n| SLD-Medium (Schramowski et al., 2023) | 3.95 | 21.17 | 29.8 |  |\n| SD-NP | 0.74 | 18.33 | 30.1 |  |\n| SAFREE (Yoon et al., 2024) | 1.45 | 19.32 | 30.1 |  |\n| TraSCE (Jain et al., 2024) | 0.45 | 17.41 | 29.9 |  |\n| Ours (w/o negative steering) | 0.57 | 18.37 | 30.8 |  |\n| Ours | 0.36 | 18.67 | 30.8 |  |", "caption": "Table 1: Performance comparison across different methods on I2P and COCO datasets. Lower ASR and FID indicate better performance; higher is better for CLIP. Our method achieves the lowest ASR by effectively removing nudity while preserving visual quality and prompt alignment. Bold: best. Underline: second-best.  Gray : require training and weight updates,  Pink : do not require training but update model weights,  Blue : do not require either.", "description": "\ud45c 1\uc740 I2P(Inappropriate Image Prompts) \ub370\uc774\ud130\uc14b\uacfc COCO(Common Objects in Context) \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. ASR(Attack Success Rate)\uc740 \ubd80\uc801\uc808\ud55c \ucf58\ud150\uce20 \uc0dd\uc131 \ube44\uc728\uc744 \ub098\ud0c0\ub0b4\uba70, \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc131\ub2a5\uc774 \uc88b\uc2b5\ub2c8\ub2e4. FID(Fr\u00e9chet Inception Distance)\ub294 \uc0dd\uc131 \uc774\ubbf8\uc9c0\uc758 \ud488\uc9c8\uc744 \ub098\ud0c0\ub0b4\uba70, \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. CLIP(Contrastive Language-Image Pre-training) \uc810\uc218\ub294 \ub192\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\uc740 ASR\uc774 \uac00\uc7a5 \ub0ae\uc544 \ubd80\uc801\uc808\ud55c \ucf58\ud150\uce20 \uc81c\uac70\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc2dc\uc5d0 FID \uc810\uc218\uac00 \ub192\uc544 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uc744 \uc720\uc9c0\ud558\uace0 \ud504\ub86c\ud504\ud2b8\uc640\uc758 \uc77c\uad00\uc131\ub3c4 \uc720\uc9c0\ud568\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubc29\ubc95\uc758 \ud2b9\uc9d5\ub3c4 \ud568\uaed8 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ud68c\uc0c9\uc740 \ubaa8\ub378 \uc7ac\ud559\uc2b5 \ubc0f \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8\uac00 \ud544\uc694\ud55c \ubc29\ubc95, \ubd84\ud64d\uc0c9\uc740 \uc7ac\ud559\uc2b5 \uc5c6\uc774 \uac00\uc911\uce58\ub9cc \uc5c5\ub370\uc774\ud2b8\ud558\ub294 \ubc29\ubc95, \ud30c\ub780\uc0c9\uc740 \ub458 \ub2e4 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \ubc29\ubc95\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | Ring-A-Bell-Union (Violence)\u2193 | \n|---|---| \n| **SDv1.4** | 99.6 | \n| **ESD** <cite>(Gandikota et al., 2023)</cite> | 86.0 | \n| **FNM** <cite>(Zhang et al., 2024)</cite> | 98.8 | \n| **CA** <cite>(Kumari et al., 2023)</cite> | 100.0 | \n| **UCE** <cite>(Gandikota et al., 2024)</cite> | 89.8 | \n| **RECE** <cite>(Gong et al., 2025)</cite> | 89.2 | \n| **SLD-Max** <cite>(Schramowski et al., 2023)</cite> | 40.4 | \n| **SLD-Strong** <cite>(Schramowski et al., 2023)</cite> | 80.4 | \n| **SLD-Medium** <cite>(Schramowski et al., 2023)</cite> | 97.2 | \n| **SD-NP** | 94.8 | \n| **TraSCE** <cite>(Jain et al., 2024)</cite> | 72.4 | \n| **Ours** | 43.7 | ", "caption": "Table 2: Performance comparison across different methods on the Ring-A-Bell-Union (Violence) dataset. Lower values indicate better performance. Our method demonstrates competitive performance without compromising generation quality, as indicated by the FID scores in Table\u00a01. Bold: best. Underline: second-best.  Gray : require training and weight updates,  Pink : do not require training but update model weights,  Blue : do not require either.", "description": "\ud45c 2\ub294 Ring-A-Bell-Union (\ud3ed\ub825) \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc131\ub2a5\uc774 \ub354 \uc88b\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ubcf8 \uc5f0\uad6c\uc758 \ubc29\ubc95\uc740 1\ubc88 \ud45c\uc758 FID \uc810\uc218\uc5d0\uc11c \uc54c \uc218 \uc788\ub4ef\uc774 \uc0dd\uc131 \ud488\uc9c8\uc744 \uc800\ud558\uc2dc\ud0a4\uc9c0 \uc54a\uc73c\uba74\uc11c \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad75\uc740 \uae00\uc528\ub294 \ucd5c\uace0 \uc131\ub2a5, \ubc11\uc904\uc740 \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uba70, \ud68c\uc0c9\uc740 \ud559\uc2b5 \ubc0f \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \ud544\uc694, \ubd84\ud64d\uc0c9\uc740 \ud559\uc2b5 \uc5c6\uc774 \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \ud544\uc694, \ud30c\ub780\uc0c9\uc740 \ub458 \ub2e4 \ud544\uc694\ud558\uc9c0 \uc54a\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | Ring-A-Bell (K77) | Ring-A-Bell (K38) | Ring-A-Bell (K16) | Ring-A-Bell (Avg) | MMA-Diffusion | P4D | UnLearnDiffAtk | Avg | \n|---|---|---|---|---|---|---|---|---|\n| SDv1.4 | 85.26 | 87.37 | 93.68 | 88.10 | 95.70 | 98.70 | 69.70 | 87.05 |\n| SA (Heng & Soh, 2024) | 63.15 | 56.84 | 56.84 | 58.94 | 47.68 | 12.68 | 2.81 | 30.53 |\n| CA (Kumari et al., 2023) | 86.32 | 91.69 | 94.26 | 90.76 | 10.60 | 5.63 | 1.04 | 27.01 |\n| ESD (Gandikota et al., 2023) | 20.00 | 29.47 | 35.79 | 28.42 | 9.27 | 15.49 | 2.87 | 14.51 |\n| MACE (Lu et al., 2024) | 2.10 | 0.00 | 0.00 | 0.70 | 2.72 | 2.82 | 1.51 | 1.94 |\n| UCE (Gandikota et al., 2024) | 10.52 | 9.47 | 12.61 | 10.87 | 29.93 | 9.86 | 0.87 | 12.38 |\n| RECE (Gong et al., 2025) | 5.26 | 4.21 | 5.26 | 4.91 | 21.77 | 5.63 | 0.72 | 8.76 |\n| SLD-Max (Schramowski et al., 2023) | 23.16 | 32.63 | 42.11 | 32.63 | 35.76 | 9.14 | 2.44 | 20.24 |\n| SLD-Strong (Schramowski et al., 2023) | 56.84 | 64.21 | 61.05 | 60.70 | 68.21 | 33.10 | 3.10 | 41.28 |\n| SLD-Medium (Schramowski et al., 2023) | 92.63 | 88.42 | 91.05 | 90.70 | 68.21 | 24.00 | 1.98 | 46.72 |\n| SD-NP | 17.89 | 40.42 | 34.74 | 31.68 | 24.00 | 10.00 | 1.46 | 16.29 |\n| SAFREE (Yoon et al., 2024) | 35.78 | 47.36 | 55.78 | 46.31 | 40.82 | 10.56 | 1.45 | 24.29 |\n| TraSCE (Jain et al., 2024) | 1.05 | 2.10 | 2.10 | 1.75 | 16.60 | 3.97 | 0.70 | 5.51 |\n| Ours | 3.16 | 8.42 | 9.47 | 7.02 | 6.00 | 1.99 | 2.11 | 4.28 |", "caption": "Table 3: Attack Success Rate (ASR) of different methods on various adversarial attack datasets. Lower ASR indicates better performance. Our method achieves the best overall robustness on average across all datasets by effectively removing nudity implicitly embedded in the model. Bold: best. Underline: second-best.  Gray : require training and weight updates,  Pink : do not require training but update model weights,  Blue : do not require either.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \uc801\ub300\uc801 \uacf5\uaca9 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc758 \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub0ae\uc740 ASR\uc740 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc81c\uc548\ub41c \ubc29\ubc95\uc740 \ubaa8\ub378\uc5d0 \uc554\ubb35\uc801\uc73c\ub85c \ud3ec\ud568\ub41c \ub178\ucd9c \uc774\ubbf8\uc9c0\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc81c\uac70\ud568\uc73c\ub85c\uc368 \ubaa8\ub4e0 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud3c9\uade0\uc801\uc73c\ub85c \uac00\uc7a5 \uc6b0\uc218\ud55c \uacac\uace0\uc131\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4. **\uad75\uc740 \uae00\uc528**: \ucd5c\uace0, \ubc11\uc904: \ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uac12, \ud68c\uc0c9: \ud6c8\ub828 \ubc0f \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \ud544\uc694, \ubd84\ud64d\uc0c9: \ud6c8\ub828 \ubd88\ud544\uc694 \uac00\uc911\uce58 \uc5c5\ub370\uc774\ud2b8 \ud544\uc694, \ud30c\ub780\uc0c9: \ub458 \ub2e4 \ud544\uc694\ud558\uc9c0 \uc54a\uc74c.", "section": "4.3. \uc801\ub300\uc801 \ud504\ub86c\ud504\ud2b8 \uc870\uc791\uc5d0 \ub300\ud55c \uac15\uac74\uc131"}, {"content": "| Method | Inference Time (s/sample) \u2193 | \n|---|---| \n| SD 1.4 | 3.02 | \n| SAFREE (Yoon et al., 2024) | 4.24 | \n| TraSCE (Jain et al., 2024) | 15.62 | \n| Ours | 3.16 | ", "caption": "Table 4: Model Efficiency Comparison. Experiments were conducted on a single L40S GPU on P4D dataset (150 samples in total) for the task of removing nudity.", "description": "\ud45c 4\ub294 \ubaa8\ub378 \ud6a8\uc728\uc131 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf8 \uc2e4\ud5d8\uc740 \ub2e8\uc77c L40S GPU\ub97c \uc0ac\uc6a9\ud558\uc5ec P4D \ub370\uc774\ud130\uc14b(\ucd1d 150\uac1c \uc0d8\ud50c)\uc5d0\uc11c \ub178\ucd9c\ub41c \uc774\ubbf8\uc9c0\ub97c \uc81c\uac70\ud558\ub294 \uc791\uc5c5\uc5d0 \ub300\ud574 \uc9c4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 \ucd94\ub860 \uc2dc\uac04(\ucd08/\uc0d8\ud50c)\uc774 \ub098\uc640\uc788\uc5b4 \ubaa8\ub378\uc758 \ucc98\ub9ac \uc18d\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \ucd94\ub860 \uc18d\ub3c4\ub97c \ube44\uad50\ud558\uc5ec, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ud6a8\uc728\uc131\uc744 \uac15\uc870\ud558\uae30 \uc704\ud55c \ud45c\uc785\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Layers | ASR on I2P \u2193 |\n|---|---| \n| 12 | 1.02 |\n| 10 | 0.36 |\n| 8 | 0.45 |\n| 6 | 1.72 |\n| 4 | 3.85 |", "caption": "Table 5: Attack Success Rate (ASR) when representations from different encoder layers are used to train k-SAE on the I2P dataset. The 10th layer yields the lowest ASR, indicating that this layer captures most information about nudity concept. k-SAE expansion factor = 4444, hidden neurons (n) = 3072307230723072.", "description": "\ud45c 5\ub294 I2P \ub370\uc774\ud130\uc14b\uc5d0\uc11c k-SAE\ub97c \ud6c8\ub828\uc2dc\ud0ac \ub54c, \uc11c\ub85c \ub2e4\ub978 text encoder \ub808\uc774\uc5b4\uc758 \ud45c\ud604\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c 10\ubc88\uc9f8 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c ASR\uc774 \uac00\uc7a5 \ub0ae\uc558\ub294\ub370, \uc774\ub294 10\ubc88\uc9f8 \ub808\uc774\uc5b4\uac00 \ub178\ucd9c \uac1c\ub150\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uac00\uc7a5 \ub9ce\uc774 \ub2f4\uace0 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  k-SAE\uc758 \ud655\uc7a5 \uacc4\uc218\ub294 4, \uc740\ub2c9 \ub274\ub7f0 \uc218\ub294 3072\uc600\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Expansion factor | Capacity | ASR on I2P \u2193 | \n|---|---|---| \n| 4 | 3072 | 0.36 | \n| 8 | 6144 | 0.51 | \n| 16 | 12288 | 0.47 | \n| 32 | 24576 | 0.49 | \n| 64 | 49152 | 0.53 | ", "caption": "Table 6: Attack Success Rate (ASR) for different expansion factors of k-SAE trained on text embeddings extracted from the 10th layer of the I2P prompts. An expansion factor of 4 yields the lowest ASR, indicating its efficacy for steering.", "description": "\ud45c 6\uc740 I2P \ud504\ub86c\ud504\ud2b8\uc758 10\ubc88\uc9f8 \ub808\uc774\uc5b4\uc5d0\uc11c \ucd94\ucd9c\ud55c \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529\uc73c\ub85c \ud559\uc2b5\ub41c k-SAE\uc758 \ub2e4\ub978 \ud655\uc7a5 \uacc4\uc218\uc5d0 \ub300\ud55c \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud655\uc7a5 \uacc4\uc218\uac00 4\uc77c \ub54c ASR\uc774 \uac00\uc7a5 \ub0ae\uc544 \uc870\ud5a5\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc989, k-SAE \ubaa8\ub378\uc758 \ud655\uc7a5 \uacc4\uc218\ub97c 4\ub85c \uc124\uc815\ud588\uc744 \ub54c, \ubd80\uc801\uc808\ud55c \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc744 \ubc29\uc9c0\ud558\ub294 \ub370 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc774\uc5c8\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 k-SAE \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ucd5c\uc801\ud654 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| \u03bb | ASR on I2P \u2193 | \n|---|---| \n| -0.1 | 2.59 | \n| -0.2 | 1.23 | \n| -0.3 | 0.87 | \n| -0.4 | 0.60 | \n| -0.5 | 0.36 | ", "caption": "Table 7: Attack Success Rate (ASR) for different values of \u03bb\ud835\udf06\\lambdaitalic_\u03bb of k-SAE with an expansion factor of 4444 trained on text embeddings of 10th layer on the I2P dataset. \u03bb=\u22120.5\ud835\udf060.5\\lambda=-0.5italic_\u03bb = - 0.5 yields the lowest ASR.", "description": "\ud45c 7\uc740 I2P \ub370\uc774\ud130\uc14b\uc758 10\ubc88\uc9f8 \ub808\uc774\uc5b4\uc5d0\uc11c \ucd94\ucd9c\ud55c \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529\uc73c\ub85c \ud559\uc2b5\ub41c \ud655\uc7a5 \uacc4\uc218 4\uc758 k-SAE\uc5d0 \ub300\ud574 \u03bb \uac12\uc774 \ub2e4\ub97c \ub54c \uacf5\uaca9 \uc131\uacf5\ub960(ASR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \u03bb = -0.5\uc77c \ub54c ASR\uc774 \uac00\uc7a5 \ub0ae\uc740 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \u03bb \uac12\uc744 \uc870\uc808\ud568\uc73c\ub85c\uc368 \uc6d0\uce58 \uc54a\ub294 \uac1c\ub150(\uc608: \ub178\ucd9c)\uc744 \uc81c\uac70\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  \ud45c\ub294 \ub2e4\uc591\ud55c \u03bb \uac12\uc5d0 \ub530\ub978 ASR \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, \ucd5c\uc801\uc758 \u03bb \uac12\uc744 \ucc3e\uace0 \uc6d0\ud558\ub294 \uc218\uc900\uc758 \ub178\ucd9c \uc81c\uac70\ub97c \ub2ec\uc131\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4.5 Ablation Studies"}]