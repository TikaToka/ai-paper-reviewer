{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report describing the GPT-4 model, a state-of-the-art large language model used extensively in the study for hallucination detection and evaluation."}, {"fullname_first_author": "Mikel Artetxe", "paper_title": "Revisiting machine translation for cross-lingual classification", "publication_date": "2023-12-01", "reason": "This work proposes a translate-train approach for multilingual tasks, which is directly relevant to the paper's methodology of building a multilingual hallucination detection model."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The Llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This paper introduces the Llama 3 family of LLMs, several of which are used in the study to measure hallucination rates across languages."}, {"fullname_first_author": "Nuno M Guerreiro", "paper_title": "Hallucinations in large multilingual translation models", "publication_date": "2023-11-01", "reason": "This study focuses on hallucination in machine translation, which is a related area to the paper's focus on hallucination in knowledge-intensive question answering across multiple languages."}, {"fullname_first_author": "Ziwei Ji", "paper_title": "Survey of hallucination in natural language generation", "publication_date": "2023-11-01", "reason": "This paper provides a comprehensive overview of the existing research on hallucination in natural language generation (NLG), which is highly relevant to the study's broader investigation of hallucination in LLMs."}]}