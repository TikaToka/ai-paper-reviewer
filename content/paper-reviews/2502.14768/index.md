---
title: "Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning"
summary: "ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµìœ¼ë¡œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¨ Logic-RLì„ ì†Œê°œí•©ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Microsoft Research",]
showSummary: true
date: 2025-02-20
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.14768 {{< /keyword >}}
{{< keyword icon="writer" >}} Tian Xie et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-21 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.14768" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.14768" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/logic-rl-unleashing-llm-reasoning-with-rule" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì€ ì¸ê³µì§€ëŠ¥ ì—°êµ¬ì˜ ì£¼ìš” ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë³µì¡í•˜ê±°ë‚˜ ì¬í˜„ì„±ì´ ë–¨ì–´ì§€ëŠ” í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµ(Logic-RL)**ì„ ì‚¬ìš©í•˜ì—¬ LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ, **ì œì–´ ê°€ëŠ¥í•œ ë³µì¡ì„±ì„ ê°€ì§„ í•©ì„± ë…¼ë¦¬ í¼ì¦ì„ í›ˆë ¨ ë°ì´í„°**ë¡œ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì´ê³  íš¨ìœ¨ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤. 



Logic-RLì€ **ìƒê° ê³¼ì •ì„ ê°•ì¡°í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì§€ë¦„ê¸¸ì„ ë°©ì§€í•˜ëŠ” ì—„ê²©í•œ í˜•ì‹ ë³´ìƒ í•¨ìˆ˜, ê·¸ë¦¬ê³  ì•ˆì •ì ì¸ ìˆ˜ë ´ì„ ë‹¬ì„±í•˜ëŠ” ê°„ë‹¨í•œ í›ˆë ¨ ì ˆì°¨**ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼, 7B ëª¨ë¸ì€ ê¸°ì¡´ ë…¼ë¦¬ ë°ì´í„°ì…‹ì—ì„œëŠ” ê´€ì°°ë˜ì§€ ì•Šì•˜ë˜ **ë°˜ì„±, ê²€ì¦, ìš”ì•½ê³¼ ê°™ì€ ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥**ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤.  ë”ìš± ë†€ë¼ìš´ ê²ƒì€, ë‹¨ 5,000ê°œì˜ ë…¼ë¦¬ ë¬¸ì œë¡œ í•™ìŠµì‹œí‚¨ í›„ì—ë„ **AIME ë° AMCì™€ ê°™ì€ ì–´ë ¤ìš´ ìˆ˜í•™ ë¬¸ì œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì¼ë°˜í™” ëŠ¥ë ¥**ì„ ë³´ì˜€ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ëŠ” Logic-RLì´ ë‹¨ìˆœ íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ ì¶”ìƒì  ë¬¸ì œ í•´ê²° ì²´ê³„ë¥¼ í•™ìŠµí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} í•©ì„± ë…¼ë¦¬ í¼ì¦ ë°ì´í„°ì…‹ì„ ì´ìš©í•œ ì•ˆì •ì ì¸ í•™ìŠµ ë° ì¼ë°˜í™” ì„±ëŠ¥ í™•ì¸ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ìˆ˜í•™ ë¬¸ì œ ë²¤ì¹˜ë§ˆí¬(AIME, AMC)ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ìœ¼ë¡œ ì‹¤ìš©ì„± ì…ì¦ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•**ì„ ì œì‹œí•©ë‹ˆë‹¤.  ì´ëŠ” í˜„ì¬ ì—°êµ¬ ë™í–¥ê³¼ ë°€ì ‘í•˜ê²Œ ì—°ê´€ë˜ì–´ ìˆìœ¼ë©°, ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì— ëŒ€í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, **ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì—°êµ¬ìë“¤ì—ê²Œ ì˜í–¥**ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **í•©ì„± ë…¼ë¦¬ í¼ì¦ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ í›ˆë ¨ì„ ë‹¬ì„±í•œ ì **ê³¼ **ìˆ˜í•™ ë¬¸ì œ ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ì¼ë°˜í™” ì„±ëŠ¥**ì€ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.  ì´ëŠ” í–¥í›„ ì—°êµ¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°©í–¥ì„ ì œì‹œí•  ë¿ ì•„ë‹ˆë¼, **ì‹¤ì œ ì‘ìš© ë¶„ì•¼ì—ì„œë„ ìœ ìš©ì„±**ì„ ê°€ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.14768/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ê°•í™” í•™ìŠµ(RL) í›ˆë ¨ ì¤‘ ëª¨ë¸ì˜ ê²€ì¦ ì •í™•ë„ì™€ í‰ê·  ì‘ë‹µ ê¸¸ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ëª¨ë¸ì´ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ë” ë§ì€ 'ìƒê°' ì—°ì‚°ì„ ìë™ìœ¼ë¡œ í• ë‹¹í•˜ëŠ” í•™ìŠµ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  í¥ë¯¸ë¡­ê²Œë„, ëª¨ë¸ì€ ì™„ì „íˆ ìƒˆë¡œìš´ ë°ì´í„°ì…‹(AIME, AMC)ì—ì„œë„ ë†€ë¼ìš´ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, í›ˆë ¨ ë°ì´í„°ë¡œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ë¬¸ì œ ìœ í˜•ì—ë„ ì˜ ì ìš©ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ì‘ë‹µ ê¸¸ì´ê°€ ê¸¸ì–´ì§ì— ë”°ë¼ ê²€ì¦ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ” ê²½í–¥ì„ ë³´ì´ëŠ”ë°, ì´ëŠ” ëª¨ë¸ì´ ë” ë³µì¡í•œ ì¶”ë¡  ê³¼ì •ì„ ê±°ì¹ ìˆ˜ë¡ ì •ë‹µë¥ ì´ ë†’ì•„ì§ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Validation accuracy and mean response length during RL training, illustrating how the model autonomously learns to allocate more thinking compute for improved performance. Remarkably, the model also demonstrates impressive generalization on completely unseen datasets (AIME, AMC).
> </details>





{{< table-caption >}}
| Algorithm | Train Batch Size | Rollout N | KL Coef | Max Response Len |
|---|---|---|---|---|
| REINFORCE++ | 8 | 8 | 0.001 | 4096 |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ë…¼ë¬¸ì˜ 2.4ì ˆ(í›ˆë ¨ ì¼ì •)ì—ì„œ Logic-RL ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©ëœ ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” í›ˆë ¨ ê³¼ì •ì˜ ì•ˆì •ì„± ë° íš¨ìœ¨ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. REINFORCE++ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ í›ˆë ¨ì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ì—¬ê¸°ì—ëŠ” ë°°ì¹˜ í¬ê¸°(Batch Size), ë¡¤ì•„ì›ƒ ìˆ˜(Rollout N), KL ê³„ìˆ˜(KL Coef), ìµœëŒ€ ì‘ë‹µ ê¸¸ì´(Max Response Len) ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ì´ í‘œëŠ” ë…¼ë¬¸ì—ì„œ ì œì‹œëœ í›ˆë ¨ ì„¤ì •ì„ ì´í•´í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Important Training Parameters
> </details>





### In-depth insights


#### Logic-RL: Rule-Based RL
ë…¼ë¬¸ì—ì„œ ì œì‹œëœ Logic-RL: Rule-Based RL ì ‘ê·¼ ë°©ì‹ì€ **ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµ**ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤.  í•©ì„± ë…¼ë¦¬ í¼ì¦ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ **ì œì–´ ê°€ëŠ¥í•œ ë³µì¡ì„±**ê³¼ **ëª…í™•í•œ ì •ë‹µ ê²€ì¦**ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.  **íš¨ìœ¨ì ì¸ í•™ìŠµì„ ìœ„í•´**, ìƒê° ê³¼ì •ì„ ê°•ì¡°í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì§€ë¦„ê¸¸ì„ ë°©ì§€í•˜ëŠ” ì—„ê²©í•œ í˜•ì‹ ë³´ìƒ í•¨ìˆ˜, ê·¸ë¦¬ê³  ì•ˆì •ì ì¸ ìˆ˜ë ´ì„ ë‹¬ì„±í•˜ëŠ” ê°„ë‹¨í•œ í•™ìŠµ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. Logic-RLì€ ë‹¨ìˆœí•œ íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ **ì¶”ìƒì ì¸ ë¬¸ì œ í•´ê²° ì²´ê³„**ë¥¼ ê°œë°œí•˜ì—¬ AIME ë° AMCì™€ ê°™ì€ ì–´ë ¤ìš´ ìˆ˜í•™ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. **ê¸´ ì‘ë‹µì´ í•­ìƒ ë” ë‚˜ì€ ì¶”ë¡ ì„ ë³´ì¥í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë©°**, ì˜¤íˆë ¤ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì€ ê°€ì¥ ì§§ì€ ê²½ë¡œì—ì„œ ë‚˜ì˜¨ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, **ì–¸ì–´ í˜¼í•©ì€ ì¶”ë¡ ì„ ë°©í•´**í•˜ê³ , 'ìƒê°' í† í°ì˜ ì¦ê°€ëŠ” ì„±ëŠ¥ í–¥ìƒê³¼ ìƒê´€ê´€ê³„ê°€ ìˆë‹¤ëŠ” ì ë„ í¥ë¯¸ë¡œìš´ ë°œê²¬ì…ë‹ˆë‹¤.  **SFTì™€ ë‹¬ë¦¬ RLì€ ì¼ë°˜í™” ëŠ¥ë ¥**ì´ ë›°ì–´ë‚˜ë©°, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ ì—¬ì „íˆ RLì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

#### Reward Design Refinement
ë³´ìƒ ì„¤ê³„ ê°œì„ ì€ ë…¼ë¬¸ì—ì„œ ê°•ì¡°í•˜ëŠ” í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤. **ì´ˆê¸° ë³´ìƒ ì„¤ê³„ëŠ” ëª¨ë¸ì´ ì§€ë¦„ê¸¸ì„ ì°¾ê±°ë‚˜, í˜•ì‹ì„ ì¡°ì‘í•˜ëŠ” ë“±ì˜ ë¬¸ì œë¥¼ ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤.** ë”°ë¼ì„œ ì—°êµ¬ìë“¤ì€ **ì—„ê²©í•œ í˜•ì‹ ë³´ìƒ ë° ê°„ê²°í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**ë¥¼ ë„ì…í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤. ì—„ê²©í•œ í˜•ì‹ ë³´ìƒì€ ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ê³¼ êµ¬ì¡°ë¥¼ ì¤€ìˆ˜í•˜ë„ë¡ ìœ ë„í•˜ê³ , ì§€ë¦„ê¸¸ì„ í†µí•œ ë³´ìƒ íšë“ì„ ë°©ì§€í•©ë‹ˆë‹¤. ê°„ê²°í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì˜ ì‚¬ê³  ê³¼ì •ì„ ëª…í™•íˆ ì œì‹œí•˜ê³ , ë‹¨ìˆœí•œ ë‹µë³€ë³´ë‹¤ëŠ” ì¶”ë¡  ê³¼ì •ì— ì¤‘ì ì„ ë‘ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. **ë³´ìƒ ì„¤ê³„ì˜ ë°˜ë³µì ì¸ ê°œì„ ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ , í›ˆë ¨ì˜ ì•ˆì •ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.** ë˜í•œ, ë³´ìƒ ì„¤ê³„ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ í–‰ë™ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë°œìƒ ê°€ëŠ¥í•œ ë¬¸ì œì ë“¤ì„ ì‚¬ì „ì— ì˜ˆë°©í•˜ê³ , ê°œì„ ì— ë°˜ì˜í•˜ëŠ” ê³¼ì •ì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.  **ì´ëŸ¬í•œ ë³´ìƒ ì„¤ê³„ ê°œì„ ì€ ê¶ê·¹ì ìœ¼ë¡œ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼œ, í›ˆë ¨ ë°ì´í„°ì— ì—†ëŠ” ìƒˆë¡œìš´ ë¬¸ì œì—ë„ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.**

#### Emergent Reasoning Skills
ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¬ 'Emergent Reasoning Skills'ëŠ” **ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµ(rule-based reinforcement learning)**ì„ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ ì¶”ë¡  ëŠ¥ë ¥ì˜ ì¶œí˜„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  ë‹¨ìˆœíˆ í›ˆë ¨ ë°ì´í„°ë¥¼ ì•”ê¸°í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ëª¨ë¸ì´ **ì¶”ìƒì ì¸ ë¬¸ì œ í•´ê²° ì „ëµ(abstract problem-solving schemata)**ì„ ìŠ¤ìŠ¤ë¡œ ê°œë°œí•˜ê³ , **ë°˜ì„±(reflection), ê²€ì¦(verification), ìš”ì•½(summarization)**ê³¼ ê°™ì€ ê³ ì°¨ì›ì  ì‚¬ê³  ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ëŠ¥ë ¥ì´ ìë°œì ìœ¼ë¡œ ìƒê²¨ë‚˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ **ì œí•œëœ í›ˆë ¨ ë°ì´í„°(5,000ê°œì˜ ë…¼ë¦¬ í¼ì¦)**ë§Œìœ¼ë¡œë„ ì–´ë ¤ìš´ ìˆ˜í•™ ë¬¸ì œ(AIME, AMC)ì— ì¼ë°˜í™”í•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ì ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹™ë‹ˆë‹¤.  **ë‹¨ìˆœíˆ ë‹µì„ ë§ì¶”ëŠ” ê²ƒì„ ë„˜ì–´ì„œ, ì¶”ë¡  ê³¼ì •ì„ ìƒì„¸íˆ ë³´ì—¬ì£¼ê³ (chain-of-thought), ìŠ¤ìŠ¤ë¡œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ (back-tracking) ì—¬ëŸ¬ê°€ì§€ ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•˜ëŠ”(multi-path exploration)** ëª¨ìŠµì€ ì¸ê°„ì˜ ì¶”ë¡  ê³¼ì •ê³¼ ìœ ì‚¬í•˜ë©°, LLMì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ê°•ë ¥í•œ ì¦ê±°ì…ë‹ˆë‹¤.  í•˜ì§€ë§Œ, ì‘ë‹µ ê¸¸ì´ê°€ ê¸¸ë‹¤ê³  í•´ì„œ ì¶”ë¡  ëŠ¥ë ¥ì´ í•­ìƒ í–¥ìƒë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë©°, **íš¨ìœ¨ì ì¸ ì¶”ë¡ (efficient reasoning)**ì´ ë” ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  **ì¶”ë¡  ê³¼ì •ì— íŠ¹ì • ë‹¨ì–´(ì˜ˆ: verify, re-evaluate)**ì˜ ì‚¬ìš©ì´ ì„±ëŠ¥ í–¥ìƒê³¼ ì—°ê´€ë˜ì–´ ìˆìŒì„ ë°œê²¬í•˜ì˜€ì§€ë§Œ, ëª¨ë“  ë³µì¡í•œ ì‚¬ê³  ë‹¨ì–´ê°€ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•˜ëŠ” ê²ƒì€ ì•„ë‹˜ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.  ì•ìœ¼ë¡œ ì´ëŸ¬í•œ **ìƒˆë¡œìš´ ì¶”ë¡  ëŠ¥ë ¥ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±(generalization ability)**ì„ ë” í° ê·œëª¨ì˜ ì‹¤ì œ ë¬¸ì œì— ì ìš©í•˜ëŠ” ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

#### Generalization to OOD
ë³¸ ë…¼ë¬¸ì—ì„œ ë‹¤ë£¬ Logic-RL ëª¨ë¸ì˜ í•µì‹¬ ê°•ì  ì¤‘ í•˜ë‚˜ëŠ” **ë¶„í¬ ì™¸(Out-of-Distribution, OOD) ì¼ë°˜í™” ëŠ¥ë ¥**ì…ë‹ˆë‹¤.  í•©ì„± ë°ì´í„°ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ì‹¤ì œ ìˆ˜í•™ ë¬¸ì œ ë²¤ì¹˜ë§ˆí¬ì¸ AIMEê³¼ AMCì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ ê²ƒì€ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ì•”ê¸°ê°€ ì•„ë‹Œ, **ì¶”ë¡  ëŠ¥ë ¥ ìì²´ì˜ í–¥ìƒ**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  **í•©ì„± ë°ì´í„°ì˜ ì œì–´ ê°€ëŠ¥ì„±** ë•ë¶„ì—, ë³µì¡ë„ë¥¼ ì¡°ì ˆí•˜ë©° í›ˆë ¨ ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ë„“í ìˆ˜ ìˆì—ˆê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ í›ˆë ¨ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë„˜ì–´ì„œëŠ” ì¶”ë¡  ëŠ¥ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.  **ë‹¨ìˆœ íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ ì¶”ìƒì ì¸ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**ì„ íšë“í–ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  í•˜ì§€ë§Œ, í•©ì„± ë°ì´í„° ê¸°ë°˜ì˜ OOD ì¼ë°˜í™” ëŠ¥ë ¥ì´ ì‹¤ì œ ë³µì¡í•œ ë¬¸ì œì— ì–¼ë§ˆë‚˜ ì˜ ì ìš©ë ì§€ëŠ” ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.  **ì‹¤ì œ ì„¸ê³„ ë¬¸ì œì— ëŒ€í•œ ì ìš©ì„±**ì„ ê²€ì¦í•˜ê³ , ê·¸ í•œê³„ë¥¼ íŒŒì•…í•˜ëŠ” í›„ì† ì—°êµ¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.  Logic-RL ëª¨ë¸ì˜ ì„±ê³µì€ ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì‚¬ë¡€ì´ë©°,  ì•ìœ¼ë¡œ ë”ìš± ë°œì „ëœ  **ê°•í™” í•™ìŠµ ê¸°ë°˜ì˜ ì¶”ë¡  ëª¨ë¸ ê°œë°œ**ì— ëŒ€í•œ ê¸°ëŒ€ê°ì„ ë†’ì…ë‹ˆë‹¤.

#### SFT vs. RL Generalization
ë³¸ ë…¼ë¬¸ì€ SFT(Supervised Fine-Tuning)ì™€ RL(Reinforcement Learning)ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. **SFTëŠ” ê¸°ì¡´ ë°ì´í„°ì— ê³¼ì í•©ë˜ëŠ” ê²½í–¥ì´ ê°•í•˜ì§€ë§Œ, RLì€ ìƒˆë¡œìš´ ë°ì´í„°ì—ë„ ì˜ ì ì‘í•˜ëŠ” ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.**  ì´ëŠ” RLì´ ë‹¨ìˆœíˆ íŒ¨í„´ì„ ì•”ê¸°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì¶”ë¡  ëŠ¥ë ¥ ìì²´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  **SFTëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì˜ êµ¬ì¡°ì— ì˜ì¡´í•˜ì—¬ í•™ìŠµí•˜ì§€ë§Œ, RLì€ ë³´ìƒ í•¨ìˆ˜ë¥¼ í†µí•´ ëª©í‘œ ì§€í–¥ì ì¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, ë°ì´í„° ë¶„í¬ì˜ ë³€í™”ì— ê°•ê±´í•©ë‹ˆë‹¤.** ë”°ë¼ì„œ, ìƒˆë¡œìš´ ìœ í˜•ì˜ ë¬¸ì œë‚˜ ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•œ ìƒí™©ì—ì„œëŠ” RL ê¸°ë°˜ ëª¨ë¸ì´ SFT ê¸°ë°˜ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  **íŠ¹íˆ, ì œí•œëœ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì˜ ê²½ìš° RLì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì€ ë§¤ìš° ì¤‘ìš”í•œ ì¥ì **ì´ ë©ë‹ˆë‹¤.  í•˜ì§€ë§Œ, RLì€ í•™ìŠµ ê³¼ì •ì´ ë³µì¡í•˜ê³  ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆë‹¤ëŠ” ë‹¨ì ì´ ì¡´ì¬í•©ë‹ˆë‹¤.  ë”°ë¼ì„œ, ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” SFTì™€ RLì˜ ì¥ì ì„ ê²°í•©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ë°©ì‹ì´ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq1.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” ì„¸ ê°€ì§€ ê°•í™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì¸ GRPO, REINFORCE++, PPOì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤. 50ê°œì˜ ë°ì´í„°ë¥¼ ë¬¶ì–´ í‰ê· ì„ ë‚¸ ì´ë™ í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„, ì •í™•ë„, ë³´ìƒ ì¦ê°€ ì¸¡ë©´ì—ì„œ ì•Œê³ ë¦¬ì¦˜ ê°„ì˜ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. GRPOëŠ” íŒŒë€ìƒ‰, REINFORCE++ëŠ” ë¹¨ê°„ìƒ‰, PPOëŠ” ì´ˆë¡ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ê° ê·¸ë˜í”„ëŠ” í•™ìŠµ ë‹¨ê³„ì— ë”°ë¥¸ ì‹œê°„, ì •í™•ë„, ë³´ìƒì˜ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ì–´ ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Comparison of GRPO (Blue), REINFORCE++ (Red), and PPO (Green) performance (averaged by sliding window = 50) in terms of training speed, accuracy, and reward gain.
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq7.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ë³µì¡í•œ ì¶”ë¡  í–‰ìœ„ì™€ ì–¸ì–´ í˜¼ìš©ì´ ì¶”ë¡  ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ ê·¸ë¦¼ì€ íŠ¹ì • ë‹¨ì–´ë¥¼ í¬í•¨í•œ ì‘ë‹µì— ëŒ€í•œ ëª¨ë¸ì˜ í‰ê·  ì ìˆ˜ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.  'verify'ì™€ 're-evaluate'ì™€ ê°™ì€ ë‹¨ì–´ë¥¼ í¬í•¨í•œ ì‘ë‹µì€ í•´ë‹¹ ë‹¨ì–´ê°€ ì—†ëŠ” ì‘ë‹µë³´ë‹¤ ì ìˆ˜ê°€ í›¨ì”¬ ë†’ì•˜ìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ ë‹¤ë¥¸ ì–¸ì–´ì˜ ë‹¨ì–´ë¥¼ í¬í•¨í•œ ì‘ë‹µì€ ì ìˆ˜ê°€ ë‚®ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ 'verify'ë‚˜ 're-evaluate'ì™€ ê°™ì€ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ë©° ë”ìš± ì‹¬ë„ìˆëŠ” ì¶”ë¡  ê³¼ì •ì„ ê±°ì¹˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë°˜ë©´, ë‹¤ë¥¸ ì–¸ì–´ì˜ ë‹¨ì–´ í˜¼ìš©ì€ ì˜¤íˆë ¤ ì¶”ë¡  ì„±ëŠ¥ì„ ì €í•´í•˜ëŠ” ìš”ì†Œë¡œ ì‘ìš©í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Impact of complex reasoning behaviours and language mixing on reasoning performance. We analyzed the modelâ€™s answer rewards for responses containing the tokens shown in the figure. Responses with 'verify' and 're-evaluate' scored significantly higher than those without these words. Conversely, responses containing certain tokens from other languages generally received lower scores.
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/verify.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê°•í™” í•™ìŠµ ê³¼ì •ì—ì„œ íŠ¹ì • ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ì¶”ì í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤.  (a)ëŠ” 'verify' ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •ì—ì„œ ê²€ì¦ í–‰ìœ„ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë¹ˆë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, í•™ìŠµ ì´ˆê¸°ì— ë‚®ì€ ë¹ˆë„ë¥¼ ë³´ì´ë‹¤ê°€ ì ì°¨ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ì¶”ë¡  ê³¼ì •ì„ ë”ìš± ì² ì €í•˜ê²Œ ê²€ì¦í•˜ëŠ” ëŠ¥ë ¥ì„ í•™ìŠµí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì¦‰, ë‹¨ìˆœíˆ ë‹µì„ ë§íˆëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼, ê·¸ ë‹µì— ë„ë‹¬í•˜ëŠ” ê³¼ì •ì— ëŒ€í•œ ì‹ ë¢°ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ìŠ¤ìŠ¤ë¡œ ê²€ì¦í•˜ëŠ” í–‰ìœ„ë¥¼ í•™ìŠµí•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.  ë‹¨ìˆœíˆ ì •ë‹µë¥  í–¥ìƒë¿ ì•„ë‹ˆë¼,  ì¶”ë¡ ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ë³µì¡í•œ ì‚¬ê³  ê³¼ì •ì˜ ë°œë‹¬ì„ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Verify
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/re-evaluate.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ íŠ¹ì • ë‹¨ì–´ì˜ í¬í•¨ ì—¬ë¶€ì— ë”°ë¥¸ ì¶”ë¡  ì„±ëŠ¥ì— ëŒ€í•œ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  're-evaluate' ë‹¨ì–´ê°€ í¬í•¨ëœ ì‘ë‹µì€ í¬í•¨ë˜ì§€ ì•Šì€ ì‘ë‹µë³´ë‹¤ ìƒë‹¹íˆ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ìì‹ ì˜ ë‹µë³€ì„ ì¬ê²€í† í•˜ê³  ì¬í‰ê°€í•˜ëŠ” ë³µì¡í•œ ì¶”ë¡  í–‰ë™ì„ ìˆ˜í–‰í•  ë•Œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ë°˜ëŒ€ë¡œ, ë‹¤ë¥¸ ì–¸ì–´ì˜ íŠ¹ì • í† í°ì´ í¬í•¨ëœ ì‘ë‹µì€ ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ì–¸ì–´ í˜¼ìš©ì´ ì¶”ë¡  ëŠ¥ë ¥ì„ ì €í•´í•œë‹¤ëŠ” ì ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Re-evaluate
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/check.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ íŠ¹ì • ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ì¶”ì í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤.  (c) CheckëŠ” 'í™•ì¸'ì´ë¼ëŠ” ì˜ë¯¸ì˜ ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê·¸ë˜í”„ë¥¼ í†µí•´ í›ˆë ¨ ì´ˆê¸°ì— 'í™•ì¸'ê³¼ ê°™ì€ ë‹¨ì–´ê°€ ë“œë¬¼ê²Œ ë‚˜íƒ€ë‚˜ë‹¤ê°€ í›ˆë ¨ì´ ì§„í–‰ë ìˆ˜ë¡ ë¹ˆë„ê°€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ê³¼ì •ì—ì„œ ìì²´ì ìœ¼ë¡œ ì¶”ë¡  ê³¼ì •ì„ ê²€ì¦í•˜ê³  í™•ì¸í•˜ëŠ” í–‰ìœ„ë¥¼ ì ì  ë” ë§ì´ ìˆ˜í–‰í•˜ê²Œ ë˜ì—ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì¦‰, ë‹¨ìˆœíˆ ë‹µì„ ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¶”ë¡  ê³¼ì •ì˜ ì •í™•ì„±ì„ ìŠ¤ìŠ¤ë¡œ í™•ì¸í•˜ê³  ê²€ì¦í•˜ëŠ” ëŠ¥ë ¥ì´ í–¥ìƒë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (c) Check
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/yet.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê°•í™” í•™ìŠµ ê³¼ì • ë™ì•ˆ íŠ¹ì • ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ì¶”ì í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤.  'verify'ì™€ ê°™ì€ ë°˜ì„±ì  ë‹¨ì–´ì™€ 'yet'ì´ë‚˜ 'let's'ì™€ ê°™ì€ ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ë‹¨ì–´, ê·¸ë¦¬ê³  ì¤‘êµ­ì–´ ë‹¨ì–´ì˜ ì‚¬ìš© ë¹ˆë„ê°€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™” ì—†ì´ ì ì§„ì ìœ¼ë¡œ ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°œë°œí–ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì¦‰, 'aha moment' ì™€ ê°™ì€ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë°œê²¬ì´ ì—†ì—ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (d) Yet
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/lets.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê°•í™” í•™ìŠµ ê³¼ì •ì—ì„œ íŠ¹ì • ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ë¥¼ ì¶”ì í•œ ê²ƒì…ë‹ˆë‹¤.  (a)ë¶€í„° (c)ê¹Œì§€ëŠ” 'verify', 're-evaluate', 'check' ì™€ ê°™ì´ ì‚¬ê³  ê³¼ì •ì„ ë°˜ì˜í•˜ëŠ” ë‹¨ì–´ì˜ ë¹ˆë„ê°€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  (d)ì™€ (e)ëŠ” 'yet', 'let's' ì™€ ê°™ì€ ë‹¨ì–´ ë˜ëŠ” ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ì–´ì¡°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ì˜ ë¹ˆë„ê°€ ì¦ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  (f)ëŠ” ì˜ì–´ ì‘ë‹µì— ì¤‘êµ­ì–´ ë‹¨ì–´ê°€ ë“±ì¥í•˜ê¸° ì‹œì‘í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ë‹¨ì–´ì˜ ë¹ˆë„ ë³€í™”ëŠ” ê¸‰ê²©í•œ ë³€í™” ì—†ì´ ê¾¸ì¤€íˆ ì¦ê°€í•˜ë©°, ì´ëŠ” 'aha moment' ì™€ ê°™ì€ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì „í™˜ì ì´ ì—†ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì¦‰, ëª¨ë¸ì´ ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°‘ìê¸° íšë“í•˜ëŠ” ì‹œì ì€ ì—†ìœ¼ë©°, ì ì§„ì ìœ¼ë¡œ ë°œì „í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (e) Letâ€™s
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/word_frequency_charts/chinese_yes.png)

> ğŸ”¼ ê·¸ë¦¼ì€ ê°•í™” í•™ìŠµ í›ˆë ¨ ê³¼ì • ë™ì•ˆ ì˜ì–´ ì‘ë‹µì—ì„œ ì¤‘êµ­ì–´ ë‹¨ì–´ì˜ ë¹ˆë„ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. í›ˆë ¨ ì´ˆê¸° ë‹¨ê³„ì—ì„œëŠ” ì¤‘êµ­ì–´ ë‹¨ì–´ê°€ ê±°ì˜ ë‚˜íƒ€ë‚˜ì§€ ì•Šì§€ë§Œ, í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ ì¤‘êµ­ì–´ ë‹¨ì–´ì˜ ë¹ˆë„ê°€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •ì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ì  í‘œí˜„ì„ í™œìš©í•¨ìœ¼ë¡œì¨ ë³´ë‹¤ ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (f) Chinese word
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/limem_rl32.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê°•í™” í•™ìŠµ ê³¼ì •ì—ì„œ ì²˜ìŒ 1800ë‹¨ê³„ ë™ì•ˆ ë‹¨ì–´ ë¹ˆë„ ë³€í™”ë¥¼ ì¶”ì í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤. (a)-(c)ëŠ” 'í™•ì¸', 'ê²€ì¦'ê³¼ ê°™ì€ ë°˜ì„±ì  ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ê°€ ì„œì„œíˆ ì¦ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (d)-(e)ëŠ” 'Letâ€™s', 'yet'ê³¼ ê°™ì€ ëŒ€í™”ì²´ í‘œí˜„ê³¼ ì‹ ì¤‘í•œ í‘œí˜„ì˜ ë¹ˆë„ê°€ ì¦ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (f)ëŠ” ì˜ì–´ ì‘ë‹µì— ì¤‘êµ­ì–´ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚˜ê¸° ì‹œì‘í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë“  ë‹¨ì–´ë“¤ì˜ ë¹ˆë„ëŠ” ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™” ì—†ì´ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ì—¬, ê°‘ì‘ìŠ¤ëŸ¬ìš´ 'aha moment'ê°€ ì—†ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì¦‰, ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì´ ê°‘ì‘ìŠ¤ëŸ½ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì ì§„ì ìœ¼ë¡œ ë°œì „í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Tracking the frequency of words in the first 1,800 training steps. 1. Reflective words like 'check' and 'verify' slowly increased (a)-(c). 2. Conversational phrases (e.g., 'Letâ€™s') and cautious terms (e.g., 'yet') became more frequent (d)-(e), 3. Chinese words began appearing in English responses (f). The frequency of all these words developed steadily without sudden jumps, suggesting that there may not be a distinct 'aha moment.'
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/limem_rft32.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” Logic-RL ëª¨ë¸ì´ AIME(2021-2024) ë° AMC(2022-2023) ë°ì´í„°ì…‹ì—ì„œì˜ ì •í™•ë„ë¥¼ í›ˆë ¨ ë‹¨ê³„ì— ë”°ë¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ ê·¸ë¦¼ì€ Logic-RL ëª¨ë¸ì´ í•´ë‹¹ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµí•œ ì¶”ë¡  ëŠ¥ë ¥ì´ ì–¼ë§ˆë‚˜ ì˜ ì¼ë°˜í™”ë˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤.  í›ˆë ¨ ë‹¨ê³„ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ëª¨ë¸ì˜ AIME ë° AMC ë°ì´í„°ì…‹ì— ëŒ€í•œ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” Logic-RL ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµí•œ ì¶”ë¡  ì „ëµì´ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì—ë„ íš¨ê³¼ì ìœ¼ë¡œ ì ìš©ë¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì´ ë‹¨ìˆœíˆ ì•”ê¸°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì‹¤ì œë¡œ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼°ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Training Step vs. Accuracy on AIME (2021-2024) and AMC (2022-2023) Datasets.
> </details>



![](https://arxiv.org/html/2502.14768/x4.png)

> ğŸ”¼ ê·¸ë¦¼ì€ ê°•í™” í•™ìŠµ(RL) ê¸°ë°˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  RL ê¸°ë°˜ ëª¨ë¸ì€ ë…¼ë¦¬ í¼ì¦ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì—ˆìœ¼ë©°,  ê·¸ë¦¼ì€ í›ˆë ¨ ë‹¨ê³„ì— ë”°ë¥¸ ê²€ì¦ ì •í™•ë„, í‰ê·  ì‘ë‹µ ê¸¸ì´, ê·¸ë¦¬ê³  ë³´ìƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  íŠ¹íˆ, ëª¨ë¸ì´ í›ˆë ¨ ì¤‘ì— ììœ¨ì ìœ¼ë¡œ ë” ë§ì€ ì‚¬ê³  ì—°ì‚°ì„ í• ë‹¹í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  í¥ë¯¸ë¡­ê²Œë„, ì´ ëª¨ë¸ì€ ì™„ì „íˆ ìƒˆë¡œìš´ ë°ì´í„°ì…‹(AIME, AMC)ì—ì„œë„ ìš°ìˆ˜í•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) RL
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/rq3.png)

> ğŸ”¼ ê·¸ë¦¼ 6(b)ëŠ” Reject Sampling Fine-Tuning(RFT) ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. RFTëŠ” ê¸°ì¡´ ëª¨ë¸ì— Reject Sampling ê¸°ë²•ì„ ì ìš©í•˜ê³ , ê·œì¹™ ê¸°ë°˜ Best-of-N ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì •ë‹µì´ë©´ì„œ ê°€ì¥ ì§§ì€ ì‘ë‹µì„ ìˆ˜ì§‘í•˜ì—¬ ì¶”ê°€ ë¯¸ì„¸ ì¡°ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ í›ˆë ¨ ë°ì´í„°ì˜ ë³€í˜•ì— ë”°ë¥¸ í…ŒìŠ¤íŠ¸ ì •í™•ë„ì™€ í›ˆë ¨ ë°ì´í„° ì•”ê¸° ì •ë„ì˜ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. RFTëŠ” í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ì•½ê°„ í–¥ìƒë˜ì§€ë§Œ, í›ˆë ¨ ë°ì´í„°ë¥¼ ê³¼ë„í•˜ê²Œ ì•”ê¸°í•˜ëŠ” ê²½í–¥(LiMem(f, Tr) ê¸‰ê²©í•œ ì¦ê°€)ì„ ë³´ì—¬ì£¼ë©°, ì§„ì •í•œ ì¶”ë¡  ëŠ¥ë ¥ë³´ë‹¤ëŠ” í‘œë©´ì ì¸ ë‹µë³€ í˜•ì‹ì„ í•™ìŠµí•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë°˜ë©´, RL ê¸°ë°˜ ë°©ë²•ì€ LiMem(f, Tr) ì¦ê°€ê°€ ìµœì†Œí™”ë˜ê±°ë‚˜ ì‹¬ì§€ì–´ ê°ì†Œí•˜ë©´ì„œ í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ë†’ì•„ì§€ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì£¼ì–´ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ë” ìš°ìˆ˜í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) RFT
> </details>



![](https://arxiv.org/html/2502.14768/extracted/6220745/figure/base_instruct/base_length.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ RFT(Reject sampling Fine-Tuning)ì™€ RL(ê°•í™” í•™ìŠµ)ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. RFTëŠ” í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ì•½ê°„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, LiMem(f;Tr) ì§€í‘œê°€ ê¸‰ê²©íˆ ì¦ê°€í•˜ì—¬ í˜•ì‹ì ì¸ ë‹µë³€ë§Œ í•™ìŠµí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°˜ë©´ RLì€ LiMem(f;Tr)ì˜ ì¦ê°€ê°€ ìµœì†Œí™”ë˜ê±°ë‚˜ ì‹¬ì§€ì–´ ê°ì†Œí•˜ë©´ì„œ ë” ë†’ì€ í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ë™ì¼í•œ LiMem(f;Tr) ë²”ìœ„ ë‚´ì—ì„œ RLì´ RFTë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ë³´ì´ëŠ” ê²ƒì€ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ë” ë›°ì–´ë‚¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: RFT memorizes while RL generalizes. RFT (Reject sampling Fine-Tuning) slightly improves test accuracy at the expense of rapidly increasing Lâ¢iâ¢Mâ¢eâ¢mâ¢(f;Tâ¢r)ğ¿ğ‘–ğ‘€ğ‘’ğ‘šğ‘“ğ‘‡ğ‘ŸLiMem(f;Tr)italic_L italic_i italic_M italic_e italic_m ( italic_f ; italic_T italic_r ), indicating it mainly learns superficial answer format than geniue reasoning. In contrast, RL achieves higher test accuracy with minimal or even negative increase in Lâ¢iâ¢Mâ¢eâ¢mâ¢(f;Tâ¢r)ğ¿ğ‘–ğ‘€ğ‘’ğ‘šğ‘“ğ‘‡ğ‘ŸLiMem(f;Tr)italic_L italic_i italic_M italic_e italic_m ( italic_f ; italic_T italic_r ). Within the same Lâ¢iâ¢Mâ¢eâ¢mğ¿ğ‘–ğ‘€ğ‘’ğ‘šLiMemitalic_L italic_i italic_M italic_e italic_m interval, RL outperform RFT in test acc greatly, suggesting better generalization ability.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | 2 | 3 | 4 | 5 | 6 | 7 | 8 | Avg. |
|---|---|---|---|---|---|---|---|---|
| **o3-mini-high** | 0.99 | 0.98 | 0.97 | 0.95 | 0.94 | 0.89 | 0.83 | 0.94 |
| **o1-2024-12-17** | 0.83 | 0.51 | 0.38 | 0.38 | 0.35 | 0.30 | 0.20 | 0.42 |
| **Deepseek-R1** | 0.91 | 0.73 | 0.77 | 0.78 | 0.75 | 0.88 | 0.83 | 0.81 |
| **GPT-4o** | 0.68 | 0.57 | 0.49 | 0.32 | 0.23 | 0.21 | 0.11 | 0.37 |
| **GPT-4o-mini** | 0.63 | 0.42 | 0.34 | 0.17 | 0.09 | 0.10 | 0.01 | 0.25 |
| **NuminaMath-7B-CoT** | 0.28 | 0.13 | 0.12 | 0.05 | 0.01 | 0.00 | 0.00 | 0.08 |
| **Deepseek-Math-7B** | 0.35 | 0.21 | 0.08 | 0.06 | 0.02 | 0.00 | 0.00 | 0.10 |
| **Qwen2.5-Base-7B** | 0.41 | 0.34 | 0.16 | 0.09 | 0.00 | 0.00 | 0.00 | 0.14 |
| **Qwen2.5-7B-Instruct-1M** | 0.49 | 0.40 | 0.25 | 0.11 | 0.06 | 0.02 | 0.01 | 0.19 |
| + **Logic-RL** | 0.99<sup>â†‘0.50</sup> | 0.99<sup>â†‘0.59</sup> | 0.94<sup>â†‘0.69</sup> | 0.92<sup>â†‘0.81</sup> | 0.91<sup>â†‘0.85</sup> | 0.80<sup>â†‘0.78</sup> | 0.67<sup>â†‘0.48</sup> | 0.89<sup>â†‘0.70</sup> |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ë‹¤ì–‘í•œ ë‚œì´ë„ì˜ K&K ë…¼ë¦¬ í¼ì¦ì— ëŒ€í•´ ì¶”ë¡  ëª¨ë¸ ë° ì¼ë°˜ ëª¨ë¸ì„ í¬í•¨í•œ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ìˆ˜ì˜ ë“±ì¥ì¸ë¬¼(2ëª…ì—ì„œ 8ëª…)ì„ ê°€ì§„ í¼ì¦ì— ëŒ€í•œ ê° ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ì–´, ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‹¤ì–‘í•œ ë³µì¡ë„ ìˆ˜ì¤€ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤.  ì´ í‘œëŠ” Logic-RL ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ë¥¸ ê¸°ì¡´ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Comparison of different models including reasoning models and general models on K&K logic puzzle across various difficulty.
> </details>

{{< table-caption >}}
| Question | Response |
|---|---| 
| A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. Five residents (William, Chloe, Lily, Jack, and Logan) made the following statements: (1) William said: "William is a knight and Chloe is a knight." (2) Chloe said: "Lily is a knight." (3) Lily said: "William is a knave and Jack is a knight." (4) Jack said: "William is a knave." (5) Logan said: "Lily is a knave if and only if William is a knave." So who is a knight and who is a knave? | To solve this, letâ€™s start analyzing the statements one by one, beginning with Williamâ€™s statement since itâ€™s a good starting point due to its self-referential nature. Williamâ€™s statement: "William is a knight and Chloe is a knight." If William is telling the truth (i.e., he is a knight), then both parts of his statement must be true. However, if William is a knight, the statement "William is a knight" is true, but the statement "Chloe is a knight" cannot determine the truth about Chloe at this point since we havenâ€™t analyzed Chloeâ€™s statement yet. Therefore, William cannot be a knight because it would lead to a contradiction. Letâ€™s test both possibilities. Testing Chloe as a knight: If Chloe is a knight, then her statement "Lily is a knight" is true, so Lily is a knight. Analyzing Lilyâ€™s statement: "William is a knave and Jack is a knight." Now, we have determined: - William is a knave. - Chloe is a knight. Letâ€™s verify all statements: - "William is a knight and Chloe is a knight" (False, since William is a knave). - "Lily is a knight" (True).  |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ê°•í™” í•™ìŠµì„ í†µí•´ í›ˆë ¨ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•Šì•˜ë˜ ì£¼ì €, íƒìƒ‰, ìš”ì•½, ê²€ì¦ê³¼ ê°™ì€ ì¶”ë¡  ë™ì‘ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì´ëŠ” ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í‘œì—ëŠ” ì§ˆë¬¸ê³¼ ì‘ë‹µì˜ í˜•íƒœë¡œ ë¬¸ì œ í’€ì´ ê³¼ì •ì´ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, ëª¨ë¸ì´ ë¬¸ì œ í•´ê²° ê³¼ì •ì—ì„œ ì—¬ëŸ¬ ê°€ì§€ ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•˜ê³ , ê·¸ ê³¼ì •ì„ ìš”ì•½í•˜ê³ , ìµœì¢… ë‹µë³€ì„ ë‚´ë¦¬ê¸° ì „ì— ì¤‘ê°„ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ì•”ê¸°ê°€ ì•„ë‹Œ ì‹¤ì œ ì¶”ë¡  ëŠ¥ë ¥ì´ í–¥ìƒë˜ì—ˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: An example of a large language model trained through reinforcement learning naturally exhibiting reasoning behaviors such as hesitation, exploration, summarization, and verification, even though these behaviors were not present in the training data.
> </details>

{{< table-caption >}}
| Question | Response |
|---|---| 
| A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. Three residents (Jack, Samuel, Lily) made the following statements: (1) Jack said, "If Samuel is a knight, then Lily is a knave." (2) Samuel said, "If Jack is a knight, then Lily is a knave." (3) Lily said, "Jack is a knight." So who is a knight and who is a knave? | Letâ€™s analyze the statements step by step.  1. Jackâ€™s statement is: "If Samuel is a knight then Lily is a knave." ... Now that we know Samuel is a knave, letâ€™s analyze Samuelâ€™s statement again: - Samuelâ€™s statement: "If Jack is a knight then Lily is a knave." - An implication "If P then Q" is false only when P is true and Q is false. (Formula Application) Here, "If Jack is a knight then Lily is a knave" is false when Jack is a knight and Lily is not a knave. This is consistent with our previous conclusion that Jack is a knight and Lily is a knight. ... |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ê¸°ì‚¬ì™€ ì•…ë‹¹ í¼ì¦ì„ í‘¸ëŠ” ë° ë…¼ë¦¬ ê³µì‹ì„ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê·œì¹™ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í†µí•´ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •ì—ì„œ ë…¼ë¦¬ì  ê³µì‹ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì ìš©í•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ë¥¼ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.  ì´ í‘œëŠ” ëª¨ë¸ì´ ë‹¨ìˆœíˆ íŒ¨í„´ ë§¤ì¹­ì„ í†µí•´ ë‹µì„ ì°¾ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,  ë…¼ë¦¬ì  ì¶”ë¡  ê³¼ì •ì„ ê±°ì³ ë¬¸ì œë¥¼ í•´ê²°í•¨ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ê·¼ê±° ìë£Œë¡œ í™œìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: An example of using logical formulas to solve a Knights and Knaves puzzle.
> </details>

{{< table-caption >}}
| Question | Response |
|---|---| 
| A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. Six residents (Benjamin, Michael, Evelyn, Sophia, James, and Jacob) made the following statements: (1) Benjamin said, "If Sophia is a knight, then Evelyn is also a knight." (2) Michael said, "Benjamin is a knave, or James is a knight." (3) Evelyn said, "Sophia is a knight, or James is a knave." (4) Sophia said, "If Michael is a knave, then James is a knight." (5) James said, "Sophia is a knight, or Evelyn is a knight." (6) Jacob said, "Benjamin is a knave, and Sophia is a knight." So who is a knight and who is a knave? | <think> Letâ€™s analyze each statement step-by-step based on whether the speaker is a knight or a knave. 1. Benjamin: "If Sophia is a knight then Evelyn is a knight" - If Benjamin is a knight, then the statement must be true. Thus, if Sophia is a knight, Evelyn has to be a knight. 2. Michael: "Benjamin is a knave or James is a knight" â€¦ From Jacobâ€™s statement, if Jacob is a knight then Sophia must be a knight and Benjamin must be a knave.  â€¦ - å‡è®¾ Jacob æ˜¯éª‘å£«ï¼Œé‚£ä¹ˆ Jacob çš„å£°æ˜ "Benjamin æ˜¯èƒŒå›è€…ä¸” Sophia æ˜¯éª‘å£«" å°±æ˜¯çœŸçš„ã€‚è¿™æ„å‘³ç€ Benjamin æ˜¯èƒŒå›è€…è€Œ Sophia æ˜¯éª‘å£«ã€‚ - æ—¢ç„¶ Sophia æ˜¯éª‘å£«ï¼Œæ ¹æ® Benjamin çš„å£°æ˜ "å¦‚æœ Sophia æ˜¯éª‘å£«é‚£ä¹ˆ Evelyn ä¹Ÿæ˜¯éª‘å£«"ï¼ŒEvelyn ä¹Ÿæ˜¯éª‘å£«ã€‚ â€¦ ç»¼ä¸Šæ‰€è¿°ï¼ŒSophia, Evelyn, å’Œ Jacob æ˜¯éª‘å£«ï¼Œè€Œ Benjamin, Michael, å’Œ James æ˜¯èƒŒå›è€…ã€‚  (Language Switching) â€¦ |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ëª¨ë¸ì´ ê¸°ì‚¬ì™€ ì•…ë‹¹ í¼ì¦ì„ í’€ê¸° ìœ„í•´ ì–¸ì–´ ì „í™˜ì„ ì‚¬ìš©í•œ ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í‘œëŠ” ëª¨ë¸ì´ ì¶”ë¡  ê³¼ì •ì—ì„œ ì˜ì–´ì™€ ì¤‘êµ­ì–´ë¥¼ í˜¼ìš©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ” í•˜ë‚˜ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì„ ë³´ì—¬ì£¼ë©°, ì¶”ë¡  ê³¼ì •ì˜ ë³µì¡ì„±ê³¼ ìœµí†µì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  íŠ¹íˆ, ëª¨ë¸ì´ ì¤‘êµ­ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„ì€ ëª¨ë¸ì˜ ë‚´ë¶€ì ì¸ ì‚¬ê³  ê³¼ì •ì´ ë³µì¡í•˜ê³  ë‹¤ì¸µì ì„ì„ ë³´ì—¬ì£¼ëŠ” ë‹¨ì„œê°€ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: An example of our model used language switching to solve a Knights and Knaves puzzle.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}