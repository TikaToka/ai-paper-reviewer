[{"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/denoising.png", "caption": "Figure 1: Text-to-video (first row) and image-to-video samples (last 2 rows, conditioned on the left frame) generated by LTX-Video, highlighting our model\u2019s high level of prompt adherence, visual quality and motion fidelity. Each row shows evenly-spaced frames from a generated 5-second video.", "description": "\ubcf8 \uadf8\ub9bc\uc740 LTX-Video \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ud14d\uc2a4\ud2b8-\ud22c-\ube44\ub514\uc624 \ubc0f \uc774\ubbf8\uc9c0-\ud22c-\ube44\ub514\uc624 \uc0d8\ud50c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud589\uc740 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c 5\ucd08\uc9dc\ub9ac \ube44\ub514\uc624\uc758 \uc77c\ubd80 \ud654\uba74\uc785\ub2c8\ub2e4. \ub098\uba38\uc9c0 \ub450 \ud589\uc740 \uc67c\ucabd \ud504\ub808\uc784\uc744 \uc870\uac74\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c 5\ucd08\uc9dc\ub9ac \ube44\ub514\uc624\uc758 \uc77c\ubd80 \ud654\uba74\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ubaa8\ub378\uc758 \ud504\ub86c\ud504\ud2b8 \ucda9\uc2e4\ub3c4, \uc2dc\uac01\uc801 \ud488\uc9c8, \uadf8\ub9ac\uace0 \ub3d9\uc791\uc758 \uc815\ud655\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. \uac01 \ud589\uc740 \uc0dd\uc131\ub41c 5\ucd08 \ube44\ub514\uc624\uc5d0\uc11c \uade0\uc77c\ud558\uac8c \uac04\uaca9\uc744 \ub454 \ud504\ub808\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.00103/x1.png", "caption": "Figure 2: LTX-Video holistic denoising strategy \u2013 latent-to-latent diffusion denoising steps + final latent-to-pixels denoising step.", "description": "\uadf8\ub9bc 2\ub294 LTX-Video\uc758 \ud640\ub9ac\uc2a4\ud2f1(\uc804\uccb4\ub860\uc801) \uc7a1\uc74c \uc81c\uac70 \uc804\ub7b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874\uc758 \uc7a0\uc7ac \ubca1\ud130(latent) \uac04\uc758 \ud655\uc0b0(diffusion) \ub2e8\uacc4\ub97c \uac70\uce5c \ud6c4, \ucd5c\uc885\uc801\uc73c\ub85c \uc7a0\uc7ac \ubca1\ud130\ub97c \ud53d\uc140\ub85c \ubcc0\ud658\ud558\ub294 \ub2e8\uacc4\uc5d0\uc11c \ucd94\uac00\uc801\uc778 \uc7a1\uc74c \uc81c\uac70\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uace0\ud574\uc0c1\ub3c4\uc758 \uc138\ubd80\uc801\uc778 \ub514\ud14c\uc77c\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \uc5f0\uc0b0 \ube44\uc6a9\uc774 \ub9ce\uc774 \ub4dc\ub294 \ubcc4\ub3c4\uc758 \uc5c5\uc0d8\ud50c\ub9c1(upsampling) \ubaa8\ub4c8 \uc5c6\uc774\ub3c4 \uace0\ud488\uc9c8\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc7a0\uc7ac \ubca1\ud130 \uac04\uc758 \ub2e8\uacc4\ub294 transformer \uae30\ubc18\uc758 diffusion model\uc5d0\uc11c \uc774\ub904\uc9c0\uace0, \ucd5c\uc885 \ub2e8\uacc4\ub294 VAE decoder\uac00 \uc7a0\uc7ac \ubca1\ud130\ub97c \ud53d\uc140 \uacf5\uac04\uc73c\ub85c \ubcc0\ud658\ud558\uba74\uc11c \ub3d9\uc2dc\uc5d0 \uc7a1\uc74c \uc81c\uac70\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/vae_encoder.png", "caption": "(a) Latent channels cumulative explained variance at different training steps.", "description": "\uc774 \uadf8\ub9bc\uc740 LTX-Video \ubaa8\ub378\uc758 VAE(Variational Autoencoder)\uc5d0\uc11c \ud559\uc2b5 \uc9c4\ud589 \ub2e8\uacc4\uc5d0 \ub530\ub978 \uc7a0\uc7ac \uacf5\uac04(latent space)\uc758 \uc124\uba85\ub41c \ubd84\uc0b0(explained variance)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uace1\uc120\uc740 \ud559\uc2b5 \uacfc\uc815\uc758 \ud2b9\uc815 \uc2dc\uc810(2%, 4%, 8%, 16%, 25%, 50%, 70%, 100%)\uc5d0\uc11c \uc7a0\uc7ac \ucc44\ub110(latent channels)\ub4e4\uc774 \ub370\uc774\ud130\uc758 \ubd84\uc0b0\uc744 \uc5bc\ub9c8\ub098 \uc798 \uc124\uba85\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \ud559\uc2b5\uc774 \uc9c4\ud589\ub420\uc218\ub85d \uc7a0\uc7ac \ucc44\ub110\ub4e4\uc774 \ub370\uc774\ud130\uc758 \ubd84\uc0b0\uc744 \ub354 \ud6a8\uc728\uc801\uc73c\ub85c \uc124\uba85\ud558\uace0, \uc989, \uc911\ubcf5\uc131(redundancy)\uc774 \uac10\uc18c\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 VAE\uac00 \uace0\ud6a8\uc728 \uc555\ucd95\uc744 \ub2ec\uc131\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/vae_decoder.png", "caption": "(b) Correlation at 4%", "description": "\uadf8\ub9bc 3(b)\ub294 \ud6c8\ub828 \uacfc\uc815\uc758 4% \uc2dc\uc810\uc5d0\uc11c \uc7a0\uc7ac \uacf5\uac04\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uc2dc\uc810\uc5d0\uc11c \uc7a0\uc7ac \ucc44\ub110\ub4e4 \uac04\uc758 \ub192\uc740 \uc0c1\uad00\uad00\uacc4\ub294 \uc7a0\uc7ac \uacf5\uac04\uc5d0 \uc911\ubcf5\ub41c \uc815\ubcf4\uac00 \ub9ce\uc774 \uc874\uc7ac\ud568\uc744 \uc2dc\uc0ac\ud558\uba70, \uc774\ub294 \ud6a8\uc728\uc801\uc778 \uc555\ucd95\uc5d0 \ubc29\ud574\uac00 \ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uace0\ucc28\uc6d0 \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c\uc758 \uc815\ubcf4 \uc911\ubcf5 \ubb38\uc81c\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/default-gan.png", "caption": "(c) Final Correlation", "description": "\uadf8\ub9bc 3(c)\ub294 VAE \ud559\uc2b5\uc774 \uc644\ub8cc\ub41c \ud6c4 \uc7a0\uc7ac \uacf5\uac04\uc758 \ucd5c\uc885 \uc0c1\uad00 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud6c8\ub828 \ucd08\uae30\uc5d0 \ube44\ud574 \uc7a0\uc7ac \ucc44\ub110 \uac04\uc758 \uc0c1\uad00 \uad00\uacc4\uac00 \ud06c\uac8c \uac10\uc18c\ud558\uc5ec, \uac01 \ucc44\ub110\uc774 \ub370\uc774\ud130 \ubd84\uc0b0\uc5d0 \uace0\ub974\uac8c \uae30\uc5ec\ud568\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 VAE\uac00 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \uc7a0\uc7ac \uacf5\uac04\uc758 \uc911\ubcf5\uc131\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc904\uc774\uace0, \uc815\ubcf4\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \ud45c\ud604\ud558\ub3c4\ub85d \ud559\uc2b5\ub418\uc5c8\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uace0\ucc28\uc6d0\uc758 \uc7a0\uc7ac \uacf5\uac04\uc744 \uc0ac\uc6a9\ud558\ub354\ub77c\ub3c4 \uc815\ubcf4 \uc190\uc2e4 \uc5c6\uc774 \uace0\ud6a8\uc728\uc758 \uc555\ucd95\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/rel-gan.png", "caption": "Figure 3: Latent-space redundancy. (a) Cumulative explained-variance of latent channels at different training steps (2% - 100% of training). As training progresses, the redundancy reduces and components contribute more evenly to the variance. (b, c) Latent channels auto-correlation matrices: high off-diagonal values early (at 4% of total training steps) and near-zero at training completion.", "description": "\uadf8\ub9bc 3\uc740 \uc7a0\uc7ac \uacf5\uac04\uc758 \uc911\ubcf5\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ud559\uc2b5 \ub2e8\uacc4(\ud559\uc2b5\uc758 2%\uc5d0\uc11c 100%)\uc5d0\uc11c \ub2e4\uc591\ud55c \uc7a0\uc7ac \ucc44\ub110\uc758 \ub204\uc801 \uc124\uba85 \ubd84\uc0b0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud559\uc2b5\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \uc911\ubcf5\uc131\uc774 \uac10\uc18c\ud558\uace0 \uad6c\uc131 \uc694\uc18c\uac00 \ubd84\uc0b0\uc5d0 \ubcf4\ub2e4 \uace0\ub974\uac8c \uae30\uc5ec\ud569\ub2c8\ub2e4. (b, c)\ub294 \uc7a0\uc7ac \ucc44\ub110\uc758 \uc790\ub3d9 \uc0c1\uad00 \ud589\ub82c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud559\uc2b5 \ucd08\uae30(\uc804\uccb4 \ud559\uc2b5 \ub2e8\uacc4\uc758 4% \uc2dc\uc810)\uc5d0\ub294 \ub300\uac01\uc120 \uac12\uc774 \ub192\uace0, \ud559\uc2b5\uc774 \uc644\ub8cc\ub418\uba74 0\uc5d0 \uac00\uae4c\uc6cc\uc9d1\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uace0\ucc28\uc6d0 \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c\uc758 \uc815\ubcf4 \uc911\ubcf5\uc131\uc744 \ubd84\uc11d\ud558\uace0, \uc81c\uc548\ub41c \ubaa8\ub378\uc758 VAE(Variational Autoencoder)\uac00 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c \uc774\ub7ec\ud55c \uc911\ubcf5\uc131\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc904\uc774\uace0 \uc7a0\uc7ac \uacf5\uac04\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/transformer_architecture.png", "caption": "(a) Causal Encoder", "description": "\uadf8\ub9bc 4(a)\ub294 LTX-Video \ubaa8\ub378\uc758 \ube44\ub514\uc624 VAE(Variational Autoencoder) \uc544\ud0a4\ud14d\ucc98 \uc911 \uc778\ucf54\ub354 \ubd80\ubd84\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uc778\ucf54\ub354\ub294 3\ucc28\uc6d0(3D) \uc778\uacfc\uc801 \ud569\uc131\uacf1(Causal Convolution)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ube44\ub514\uc624 \ud504\ub808\uc784\uc744 \ucc98\ub9ac\ud558\uba70, 32 x 32 x 8 \ud53d\uc140\uc758 \uacf5\uac04-\uc2dc\uac04\uc801 \ub2e4\uc6b4\uc0d8\ud50c\ub9c1\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc740 \ubcc4\ub3c4\uc758 \uc7a0\uc7ac \ubca1\ud130\ub85c \uc778\ucf54\ub529\ub418\uace0, \uc774\ud6c4 \ud504\ub808\uc784\ub4e4\uc740 \uc21c\ucc28\uc801\uc73c\ub85c \ucc98\ub9ac\ub429\ub2c8\ub2e4. \uc5ec\ub7ec \uac1c\uc758 \uc794\ucc28 \ube14\ub85d(ResBlock)\uacfc \uc870\uac74\ubd80 \uc794\ucc28 \ube14\ub85d(CondResBlock)\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, \ud53d\uc140 \uc815\uaddc\ud654(PixelNorm), SILU \ud65c\uc131\ud654 \ud568\uc218 \ub4f1\uc774 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ucd5c\uc885\uc801\uc73c\ub85c \uc555\ucd95\ub41c \uc7a0\uc7ac \ud45c\ud604(latent representation) Z\uac00 \uc0dd\uc131\ub429\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/absolute_coordinates.jpeg", "caption": "(b) Denoising Decoder", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 2.1 Video VAE \uc139\uc158\uc5d0 \uc18d\ud558\uba70, LTX-Video \ubaa8\ub378\uc758 \ube44\ub514\uc624 VAE \uc544\ud0a4\ud14d\ucc98 \uc911 \ub514\ub178\uc774\uc9d5 \ub514\ucf54\ub354(Denoising Decoder) \ubd80\ubd84\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub514\ucf54\ub354\ub294 \uc555\ucd95\ub41c \uc7a0\uc7ac \uacf5\uac04(latent space)\uc758 \uc815\ubcf4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uace0\ud574\uc0c1\ub3c4\uc758 \ube44\ub514\uc624 \ud504\ub808\uc784\uc744 \uc0dd\uc131\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \uadf8\ub9bc\uc5d0\ub294 3D \ud569\uc131\uacf1(Causal Conv3D), \uc794\ucc28 \ube14\ub85d(ResBlock), \uc5c5\uc0d8\ud50c\ub9c1(Upsample), \uc870\uac74\ubd80 \uc794\ucc28 \ube14\ub85d(CondResBlock), \uadf8\ub9ac\uace0 \ub178\uc774\uc988 \uc8fc\uc785(Noise Inject) \ub4f1\uc758 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\ub4e4\uc774 \uc790\uc138\ud788 \ud45c\ud604\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ub514\ucf54\ub354\ub294 \ub2e8\uc21c\ud788 \uc7a0\uc7ac \ubca1\ud130\ub97c \ud53d\uc140\ub85c \ubcc0\ud658\ud558\ub294 \uac83 \uc774\uc0c1\uc73c\ub85c, \ub9c8\uc9c0\ub9c9 \ub514\ub178\uc774\uc9d5 \ub2e8\uacc4\ub3c4 \uc218\ud589\ud558\uc5ec \uace0\ud488\uc9c8 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \uae30\uc5ec\ud569\ub2c8\ub2e4.  \uc989, \uc555\ucd95\ub41c \uc815\ubcf4\ub97c \uace0\ud574\uc0c1\ub3c4\ub85c \ubcf5\uc6d0\ud558\uace0 \ub3d9\uc2dc\uc5d0 \ub178\uc774\uc988\ub97c \uc81c\uac70\ud558\ub294 \uc5ed\ud560\uc744 \uc218\ud589\ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/fractional_coordinates.jpeg", "caption": "Figure 4: The LTX-Video Video-VAE architecture: (a) Causal Encoder utilizing 3D Causal Convolutions, applying 32\u00d732\u00d783232832\\times 32\\times 832 \u00d7 32 \u00d7 8 compression (except the first frame, which is encoded as a separate latent frame). (b) Denoising Decoder with diffusion-timestep conditioning and multi-layer noise injection.", "description": "\uadf8\ub9bc 4\ub294 \ub17c\ubb38\uc758 2.1\uc808(Video VAE)\uc5d0\uc11c \uc18c\uac1c\ud558\ub294 LTX-Video \ubaa8\ub378\uc758 Video VAE \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 3D Causal Convolution\uc744 \uc0ac\uc6a9\ud558\ub294 Causal Encoder\ub97c \ub098\ud0c0\ub0b4\uba70, \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc744 \uc81c\uc678\ud558\uace0 32x32x8\uc758 \uacf5\uac04-\uc2dc\uac04 \uc555\ucd95\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc740 \ubcc4\ub3c4\uc758 \uc7a0\uc7ac \ubca1\ud130\ub85c \uc778\ucf54\ub529\ub429\ub2c8\ub2e4. (b)\ub294 diffusion timestep \uc870\uac74\uacfc \ub2e4\uce35 \ub178\uc774\uc988 \uc8fc\uc785\uc744 \uc0ac\uc6a9\ud558\ub294 Denoising Decoder\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc804\uccb4\uc801\uc73c\ub85c, \uc774 \uadf8\ub9bc\uc740 LTX-Video \ubaa8\ub378\uc774 \uace0\ud574\uc0c1\ub3c4 \ube44\ub514\uc624\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc0dd\uc131\ud558\uae30 \uc704\ud574 \uace0\uc548\ub41c \uace0\ub3c4\ub85c \uc555\ucd95\ub41c \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c \uc5b4\ub5bb\uac8c \ub3d9\uc791\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Causal Encoder\ub294 \uc785\ub825 \ube44\ub514\uc624\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc555\ucd95\ub41c \uc7a0\uc7ac \ud45c\ud604\uc73c\ub85c \ubcc0\ud658\ud558\uace0, Denoising Decoder\ub294 \uc774 \uc7a0\uc7ac \ud45c\ud604\uc744 \uace0\ud574\uc0c1\ub3c4 \ube44\ub514\uc624\ub85c \ubcf5\uc6d0\ud558\uba74\uc11c, diffusion timestep\uc744 \ud1b5\ud574 \ub178\uc774\uc988 \uc81c\uac70 \ubc0f \ub514\ud14c\uc77c\ud55c \uc601\uc0c1 \uc815\ubcf4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/norm_fractional_coordinates.jpeg", "caption": "(a) Traditional GAN", "description": "\uadf8\ub9bc 5(a)\ub294 \uae30\uc874 GAN\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud310\ubcc4\uc790\ub294 \uc2e4\uc81c \uc774\ubbf8\uc9c0 \ub610\ub294 \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0 \uc911 \ud558\ub098\ub97c \uc785\ub825\ubc1b\uc544 \uc9c4\uc9dc \uc774\ubbf8\uc9c0\uc778\uc9c0 \uac00\uc9dc \uc774\ubbf8\uc9c0\uc778\uc9c0 \ud310\ubcc4\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \uc774\uc640 \ub300\uc870\uc801\uc73c\ub85c \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ubc29\uc2dd\uc740 \uadf8\ub9bc 5(b)\uc5d0\uc11c \ubcf4\uc5ec\uc8fc\ub4ef \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc640 \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0\ub97c \ud568\uaed8 \uc785\ub825\ubc1b\uc544 \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc640 \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0 \uc911 \uc5b4\ub5a4 \uac83\uc774 \uc6d0\ubcf8\uc778\uc9c0 \ud310\ubcc4\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4.", "section": "2.1.2 Reconstruction GAN (rGAN)"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/exp_vs_inv_exp_shared_y_axis_heatmap.png", "caption": "(b) Reconstruction GAN", "description": "\uadf8\ub9bc 5(b)\ub294 \ubcf8 \ub17c\ubb38\uc758 2.1.2\uc808 \"Reconstruction GAN (rGAN)\"\uc5d0\uc11c \uc81c\uc2dc\ub41c \uc0c8\ub85c\uc6b4 GAN \uc190\uc2e4 \ud568\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 GAN\uacfc \ub2ec\ub9ac, \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0\uc640 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\ub97c \ubaa8\ub450 \ud310\ubcc4\uc790\uc5d0 \uc785\ub825\ud558\uc5ec \uc6d0\ubcf8\uacfc \uc7ac\uad6c\uc131 \uc774\ubbf8\uc9c0\ub97c \uad6c\ubd84\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774\ub294 \ud310\ubcc4\uc790\uc758 \uc791\uc5c5\uc744 \ub2e8\uc21c\ud654\ud558\uace0 \uc0dd\uc131\uae30\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc548\ub0b4\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \ud2b9\ud788 \ud328\uce58 \uae30\ubc18 \ud310\ubcc4\uc790\uc758 \uacbd\uc6b0, \uacf5\uac04\uc801 \ub9e5\ub77d\uc774 \uc81c\ud55c\uc801\uc774\uae30 \ub54c\ubb38\uc5d0 \uc7ac\uad6c\uc131 \uc791\uc5c5\uc5d0 \uc801\ud569\ud55c \ud310\ubcc4 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc785\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/image-to-video.png", "caption": "Figure 5: Our novel Reconstruction GAN loss. (a) Traditional GAN \u2013 the discriminator sees either a real or a reconstructed image. (b) Reconstruction GAN \u2013 the discriminator sees both versions of the same sample (concatenated) and needs to decide which is the original and which is the reconstructed version.", "description": "\uadf8\ub9bc 5\ub294 \ub17c\ubb38\uc758 2.1.2\uc808 \"Reconstruction GAN (rGAN)\"\uc5d0\uc11c \uc81c\uc2dc\ub41c \uc0c8\ub85c\uc6b4 GAN \uc190\uc2e4 \ud568\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uae30\uc874 GAN\uc758 \uad6c\uc870\ub97c, (b)\ub294 \uc81c\uc548\ub41c Reconstruction GAN\uc758 \uad6c\uc870\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uae30\uc874 GAN\uc740 \ud310\ubcc4\uc790\uac00 \uc2e4\uc81c \uc774\ubbf8\uc9c0 \ub610\ub294 \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0 \uc911 \ud558\ub098\ub9cc\uc744 \uc785\ub825\ubc1b\uc544 \uc9c4\uc704 \uc5ec\ubd80\ub97c \ud310\ubcc4\ud558\ub294 \ubc18\uba74, Reconstruction GAN\uc740 \ub3d9\uc77c\ud55c \uc0d8\ud50c\uc758 \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc640 \uc7ac\uad6c\uc131\ub41c \uc774\ubbf8\uc9c0\ub97c \uc5f0\uacb0\ud558\uc5ec \uc785\ub825\ubc1b\uc2b5\ub2c8\ub2e4. \ub530\ub77c\uc11c \ud310\ubcc4\uc790\ub294 \uc5b4\ub5a4 \uc774\ubbf8\uc9c0\uac00 \uc6d0\ubcf8\uc774\uace0 \uc5b4\ub5a4 \uc774\ubbf8\uc9c0\uac00 \uc7ac\uad6c\uc131\ub41c \uac83\uc778\uc9c0 \ud310\ubcc4\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc0c1\ub300\uc801\uc778 \ube44\uad50\ub97c \ud1b5\ud574 \ud310\ubcc4\uc790\uc758 \uc791\uc5c5\uc774 \ub2e8\uc21c\ud654\ub418\uace0, \uc0dd\uc131\uc790\ub97c \ubcf4\ub2e4 \ud6a8\uacfc\uc801\uc73c\ub85c \uc548\ub0b4\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/x4.png", "caption": "Figure 6: The LTX-Video 3D transformer-block architecture. Our architecture builds upon Pixart-\u03b1\ud835\udefc\\alphaitalic_\u03b1\u00a0[8], replacing LayerNorm with RMSNorm and incorporating QK-normalization and RoPE positional embeddings.", "description": "\uadf8\ub9bc 6\uc740 LTX-Video \ubaa8\ub378\uc758 3D \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ube14\ub85d \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uc544\ud0a4\ud14d\ucc98\ub294 Pixart-\u03b1 [8]\ub97c \uae30\ubc18\uc73c\ub85c \ud558\uba70, LayerNorm\uc744 RMSNorm\uc73c\ub85c \ub300\uccb4\ud558\uace0 QK \uc815\uaddc\ud654 \ubc0f RoPE \uc704\uce58 \uc778\ucf54\ub529\uc744 \ud1b5\ud569\ud588\uc2b5\ub2c8\ub2e4.  Pixart-\u03b1\uc5d0\uc11c \uac1c\uc120\ub41c \uc810\uc740 \uc8fc\ub85c \uc815\uaddc\ud654 \uae30\ubc95\uacfc \uc704\uce58 \uc778\ucf54\ub529 \ubc29\uc2dd\uc5d0 \uc788\uc2b5\ub2c8\ub2e4.  RMSNorm\uc740 LayerNorm\ubcf4\ub2e4 \uc548\uc815\uc801\uc774\uace0 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\uba70, RoPE\ub294 \uc808\ub300\uc801 \uc704\uce58 \uc778\ucf54\ub529\ubcf4\ub2e4 \ub3d9\uc801\uc774\uace0 \ubb38\ub9e5\uc5d0 \ub9de\ub294 \uc704\uce58 \uc815\ubcf4 \ud45c\ud604\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. QK \uc815\uaddc\ud654\ub294 \uc5b4\ud150\uc158 \uac00\uc911\uce58\uc758 \uc5d4\ud2b8\ub85c\ud53c\ub97c \ub192\uc5ec \ubaa8\ub378\uc758 \uc548\uc815\uc131\uacfc \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c \uc774\ub7ec\ud55c \uac1c\uc120\uc810\ub4e4\uc740 \ube44\ub514\uc624 \uc0dd\uc131 \uc791\uc5c5\uc5d0\uc11c \ubc1c\uc0dd\ud558\ub294 \uace0\uc720\ud55c \uc5b4\ub824\uc6c0\uc744 \ud574\uacb0\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "2.2 \ube44\ub514\uc624 \ud2b8\ub79c\uc2a4\ud3ec\uba38"}, {"figure_path": "https://arxiv.org/html/2501.00103/x5.png", "caption": "(a)", "description": "\uadf8\ub9bc (a)\ub294 LTX-Video\uc758 \ube44\ub514\uc624 VAE \uc544\ud0a4\ud14d\ucc98\uc758 \uc778\ucf54\ub354 \ubd80\ubd84\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 3D \uc778\uacfc\uc801 \ud569\uc131\uacf1\uc744 \uc0ac\uc6a9\ud558\uc5ec 32x32x8 \uc555\ucd95(\uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc740 \ubcc4\ub3c4\uc758 \uc7a0\uc7ac \uacf5\uac04\uc73c\ub85c \uc778\ucf54\ub529\ub428)\uc744 \uc218\ud589\ud558\ub294 \uc778\uacfc\uc801 \uc778\ucf54\ub354\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc591\ud55c ResBlock, Downsample \ubc0f CausalConv3D \ub808\uc774\uc5b4\ub97c \ud1b5\ud574 \uc785\ub825 \ube44\ub514\uc624\ub97c \uace0\ucc28\uc6d0 \uc7a0\uc7ac \uacf5\uac04\uc73c\ub85c \ub9e4\ud551\ud569\ub2c8\ub2e4. Patchify \ub808\uc774\uc5b4\ub294 \ube44\ub514\uc624 \ud328\uce58\ub97c \ud1a0\ud070\uc73c\ub85c \ubcc0\ud658\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/x6.png", "caption": "(b)", "description": "\uadf8\ub9bc 3(b)\ub294 \ud6c8\ub828 \uacfc\uc815\uc758 4% \uc2dc\uc810\uc5d0\uc11c\uc758 \uc7a0\uc7ac \uacf5\uac04 \uc790\uae30 \uc0c1\uad00 \ud589\ub82c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub192\uc740 \ube44\ub300\uac01\uc120 \uac12\uc740 \uc7a0\uc7ac \uacf5\uac04\uc5d0 \uc911\ubcf5\uc131\uc774 \uc874\uc7ac\ud568\uc744 \ub098\ud0c0\ub0b4\uba70, \uc774\ub294 \uace0\ud574\uc0c1\ub3c4 \uc601\uc0c1 \uc0dd\uc131\uc758 \uc5b4\ub824\uc6c0\uc73c\ub85c \uc774\uc5b4\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 \ud6c8\ub828\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c(\uadf8\ub9bc 3(c) \ucc38\uc870) \uc790\uae30 \uc0c1\uad00\uc774 \uac10\uc18c\ud558\uace0 \ucc44\ub110\ub4e4\uc774 \ubd84\uc0b0\ub418\uc5b4 \uc0ac\uc6a9\ub428\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc 3(a)\uc758 \uacb0\uacfc\uc640 \ub300\uc870\uc801\uc785\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/x7.png", "caption": "(c)", "description": "\uadf8\ub9bc 3 (c)\ub294 \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc5d0 \uc788\uc5b4\uc11c \uc7a0\uc7ac \uacf5\uac04\uc758 \uc0c1\uad00 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud6c8\ub828 \ucd08\uae30\uc5d0 \uace0\ucc28\uc6d0 \uc7a0\uc7ac \uacf5\uac04\uc5d0\ub294 \uc0c1\ub2f9\ud55c \uc911\ubcf5\uc774 \uc788\uc9c0\ub9cc, \ud6c8\ub828\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c VAE\uac00 \uc7a0\uc7ac \ubcc0\uc218\ub4e4\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uc5ec \uc911\ubcf5\uc131\uc744 \uc904\uc774\uace0, \uace0\uc720\ud55c \uc815\ubcf4\ub97c \ub354 \uc798 \ud45c\ud604\ud558\ub3c4\ub85d \ud559\uc2b5\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \ud6c8\ub828 \uc804\uc5d0\ub294 \uc7a0\uc7ac \ucc44\ub110 \uac04 \uc0c1\uad00 \uad00\uacc4\uac00 \ub192\uc558\uc9c0\ub9cc(b), \ud6c8\ub828 \ud6c4\uc5d0\ub294 \uc0c1\uad00 \uad00\uacc4\uac00 \uac70\uc758 0\uc5d0 \uac00\uae4c\uc6cc\uc9d0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4(c). \uc774\ub294 VAE\uac00 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \uc7a0\uc7ac \uacf5\uac04\uc758 \ud6a8\uc728\uc131\uc744 \ub192\uc774\uace0 \uc911\ubcf5\uc131\uc744 \uc81c\uac70\ud558\ub294 \uacfc\uc815\uc744 \uc131\uacf5\uc801\uc73c\ub85c \uc218\ud589\ud588\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc99d\uba85\ud558\ub294 \ubd80\ubd84\uc785\ub2c8\ub2e4.", "section": "2.1 Video VAE"}, {"figure_path": "https://arxiv.org/html/2501.00103/x8.png", "caption": "Figure 7: Positional encoding options: (a) Absolute positional encoding. (b) Fractional positional encoding. (c) Relative fractional positional encoding. Our experiments showed that relative-fractional positional embedding (option c) works best.", "description": "\uadf8\ub9bc 7\uc740 \ube44\ub514\uc624 \ubcc0\ud658\uae30\uc758 \uc704\uce58 \uc778\ucf54\ub529 \ubc29\uc2dd \uc138 \uac00\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a) \uc808\ub300 \uc704\uce58 \uc778\ucf54\ub529\uc740 \uac01 \ud1a0\ud070\uc5d0 \uace0\uc720\ud55c \uc815\uc218 \uc778\ub371\uc2a4\ub97c \ud560\ub2f9\ud569\ub2c8\ub2e4. \uc774 \ubc29\uc2dd\uc740 \uac04\ub2e8\ud558\uc9c0\ub9cc \uc2dc\ud000\uc2a4 \uae38\uc774\uac00 \uae38\uc5b4\uc9c0\uba74 \uc131\ub2a5\uc774 \uc800\ud558\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (b) \ubd84\uc218 \uc704\uce58 \uc778\ucf54\ub529\uc740 \uac01 \ud1a0\ud070\uc5d0 0\uacfc 1 \uc0ac\uc774\uc758 \uc2e4\uc218 \uac12\uc744 \ud560\ub2f9\ud558\uc5ec \ubcf4\ub2e4 \ubbf8\uc138\ud55c \uc704\uce58 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc5ec\uc804\ud788 \uc808\ub300\uc801\uc778 \uc704\uce58 \uc815\ubcf4\uc5d0 \uc758\uc874\ud569\ub2c8\ub2e4. (c) \uc0c1\ub300\uc801 \ubd84\uc218 \uc704\uce58 \uc778\ucf54\ub529\uc740 \ud1a0\ud070 \uac04\uc758 \uc0c1\ub300\uc801 \uc704\uce58\ub97c \uc778\ucf54\ub529\ud558\uc5ec \uc2dc\ud000\uc2a4 \uae38\uc774\uc5d0 \ub300\ud55c \ubbfc\uac10\ub3c4\ub97c \uc904\uc785\ub2c8\ub2e4. \uc2e4\ud5d8 \uacb0\uacfc \uc0c1\ub300\uc801 \ubd84\uc218 \uc704\uce58 \uc778\ucf54\ub529\uc774 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.", "section": "2.2 Video Transformer"}, {"figure_path": "https://arxiv.org/html/2501.00103/x9.png", "caption": "Figure 8: Different options for RoPE frequency spacing \u2013 exponential (left) and inverse-exponential (right). LTX-Video uses exponential spacing. See also section\u00a04.3.2.", "description": "\uadf8\ub9bc 8\uc740 RoPE(Rotary Positional Embedding)\uc758 \uc8fc\ud30c\uc218 \uac04\uaca9 \uc124\uc815\uc5d0 \ub300\ud55c \ub450 \uac00\uc9c0 \ubc29\ubc95, \uc989 \uc9c0\uc218\uc801 \uc99d\uac00(\uc67c\ucabd)\uc640 \uc9c0\uc218\uc801 \uac10\uc18c(\uc624\ub978\ucabd)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LTX-Video \ubaa8\ub378\uc740 \uc9c0\uc218\uc801 \uc99d\uac00 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 RoPE\uc758 \uc8fc\ud30c\uc218 \uac04\uaca9 \uc124\uc815\uc774 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc73c\ub85c, 4.3.2\uc808\uc5d0\uc11c \uc790\uc138\ud788 \uc124\uba85\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  x\ucd95\uc740 \uc8fc\ud30c\uc218 \uc778\ub371\uc2a4, y\ucd95\uc740 \uc8fc\ud30c\uc218 \uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub450 \uadf8\ub798\ud504\ub97c \ube44\uad50\ud558\uba74, \uc9c0\uc218\uc801 \uc99d\uac00 \ubc29\uc2dd\uc774 \uc9c0\uc218\uc801 \uac10\uc18c \ubc29\uc2dd\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.2 Rotary Positional Embedding (RoPE)"}, {"figure_path": "https://arxiv.org/html/2501.00103/extracted/6102773/assets/figures/compare_gan_results.png", "caption": "Figure 9: LTX-Video image-to-video inference pipeline \u2013 first-frame conditioning. The diffusion timestep and corresponding noise level is defined per-token. For example, conditioning tokens can have diffusion timesteps of tc=0subscript\ud835\udc61\ud835\udc500t_{c}=0italic_t start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 0 and contain un-noised encoded tokens.", "description": "\uadf8\ub9bc 9\ub294 LTX-Video \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0 \ud22c \ube44\ub514\uc624 \ucd94\ub860 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc744 \uc870\uac74\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ubc29\uc2dd\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uae30\uc874\uc758 \ud14d\uc2a4\ud2b8-\ud22c-\ube44\ub514\uc624 \ubaa8\ub378\uacfc \ub2ec\ub9ac, \uac01 \ud1a0\ud070\uc5d0 \ub300\ud574 \uace0\uc720\ud55c \ud655\uc0b0 \uc2dc\uac04 \ub2e8\uacc4(diffusion timestep)\uc640 \ud574\ub2f9 \ub178\uc774\uc988 \ub808\ubca8\uc744 \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uccab \ud504\ub808\uc784\uc758 \uc815\ubcf4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uc5ec \ube44\ub514\uc624 \uc0dd\uc131\uc758 \ud488\uc9c8\uc744 \ub192\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \uc870\uac74 \ud1a0\ud070(conditioning tokens)\uc758 \uacbd\uc6b0, \ud655\uc0b0 \uc2dc\uac04 \ub2e8\uacc4\ub294 0\uc73c\ub85c \uc124\uc815\ub420 \uc218 \uc788\uc73c\uba70, \ub178\uc774\uc988\uac00 \uc5c6\ub294 \uc778\ucf54\ub529\ub41c \ud1a0\ud070\uc744 \ud3ec\ud568\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uc758 \uc815\ubcf4\uac00 \ub178\uc774\uc988 \uc5c6\uc774 \uc9c1\uc811\uc801\uc73c\ub85c \ubaa8\ub378\uc5d0 \uc804\ub2ec\ub428\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "2.4 \uc774\ubbf8\uc9c0 \uc870\uac74\ud654"}, {"figure_path": "https://arxiv.org/html/2501.00103/x10.png", "caption": "Figure 10: Timestep t\ud835\udc61titalic_t sampling distribution during training, shown with two shifting parameters \u03bc\ud835\udf07\\muitalic_\u03bc. We use the distributions shown in blue, which prevent near-zero probability at the tails.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e0\uacbd\ub9dd \ud6c8\ub828 \uc911\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uc2dc\uac04 \ub2e8\uacc4(timestep, t)\uc758 \ud45c\ubcf8 \ucd94\ucd9c \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uac1c\uc758 \uc774\ub3d9 \ub9e4\uac1c\ubcc0\uc218(\u03bc)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uac04 \ub2e8\uacc4\uc758 \ubd84\ud3ec\ub97c \uc870\uc815\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud30c\ub780\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \ubd84\ud3ec\ub294 \uaf2c\ub9ac \ubd80\ubd84\uc5d0\uc11c \ud655\ub960\uc774 \uac70\uc758 0\uc5d0 \uac00\uae4c\uc6cc\uc9c0\ub294 \uac83\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc989, \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ub2e4\uc591\ud55c \uc2dc\uac04 \ub2e8\uacc4\uac00 \uace0\ub974\uac8c \uace0\ub824\ub420 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub178\uc774\uc988 \ub808\ubca8\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uace0 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "2.5 Rectified-Flow Training"}]