{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-MM-DD", "reason": "This paper introduces Chain-of-Thought prompting, a foundational technique for enhancing LLM reasoning abilities, which is central to the current work."}, {"fullname_first_author": "Alan Wake", "paper_title": "Yi-lightning technical report", "publication_date": "2024-MM-DD", "reason": "This paper presents Yi-lightning, a state-of-the-art LLM used in the experiments, making it crucial for evaluating the proposed method."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-MM-DD", "reason": "This paper introduces the GSM8K benchmark dataset, which is used for evaluating the performance of LLMs in mathematical reasoning tasks."}, {"fullname_first_author": "Cheng-Han Chiang", "paper_title": "Over-reasoning and redundant calculation of large language models", "publication_date": "2024-MM-DD", "reason": "This paper addresses the issue of token redundancy in LLMs, a key problem the current research seeks to improve."}, {"fullname_first_author": "Sania Nayab", "paper_title": "Concise thoughts: Impact of output length on llm reasoning and cost", "publication_date": "2024-MM-DD", "reason": "This paper explores the relationship between output length and cost in LLMs, providing insights relevant to the token budget optimization strategy proposed in the current work."}]}