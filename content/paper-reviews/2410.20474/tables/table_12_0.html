<table id='0' style='font-size:14px'><tr><td>[20]</td><td>Amir Hertz, Andrey Voynov, Shlomi Fruchter, and Daniel Cohen-Or. Style aligned image generation via shared attention. In CVPR, 2024.</td></tr><tr><td>[21]</td><td>Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. CLIPScore: a reference-free evaluation metric for image captioning. In EMNLP, 2021.</td></tr><tr><td>[22]</td><td>Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In NeurIPS, 2020.</td></tr><tr><td>[23]</td><td>Hyeonho Jeong and Jong Chul Ye. Ground-a-video: Zero-shot grounded video editing using text-to-image diffusion models. In ICLR, 2024.</td></tr><tr><td>[24]</td><td>Gwanghyun Kim, Hayeon Kim, Hoigi Seo, Dong Un Kang, and Se Young Chun. Beyondscene: Higher- resolution human-centric scene generation with pretrained diffusion. arXiv preprint arXiv:2404.04544, 2024.</td></tr><tr><td>[25]</td><td>Jaihoon Kim, Juil Koo, Kyeongmin Yeo, and Minhyuk Sung. Synctweedies: A general generative framework based on synchronized diffusions. arXiv preprint arXiv:2403.14370, 2024.</td></tr><tr><td>[26]</td><td>Yunji Kim, Jiyoung Lee, Jin-Hwa Kim, Jung- Woo Ha, and Jun- Yan Zhu. Dense text-to-image generation with attention modulation. In ICCV, 2023.</td></tr><tr><td>[27]</td><td>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In ICLR, 2014.</td></tr><tr><td>[28]</td><td>Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, and Omer Levy. Pick-a-pic: An open dataset of user preferences for text-to-image generation. In NeurIPS, 2023.</td></tr><tr><td>[29]</td><td>Yuseung Lee, Kunho Kim, Hyunjin Kim, and Minhyuk Sung. SyncDiffusion: Coherent montage via synchronized joint diffusions. In NeurIPS, 2023.</td></tr><tr><td>[30]</td><td>Yuseung Lee and Minhyuk Sung. Reground: Improving textual and spatial grounding at no cost. arXiv preprint arXiv:2403.13589, 2024.</td></tr><tr><td>[31]</td><td>Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. Gligen: Open-set grounded text-to-image generation. In CVPR, 2023.</td></tr><tr><td>[32]</td><td>Long Lian, Boyi Li, Adam Yala, and Trevor Darrell. Llm-grounded diffusion: Enhancing prompt understanding of text-to-image diffusion models with large language models. TMLR, 2024.</td></tr><tr><td>[33]</td><td>Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Doll�r. Microsoft coco: Common objects in context, 2015.</td></tr><tr><td>[34]</td><td>Yuxin Liu, Minshan Xie, Hanyuan Liu, and Tien-Tsin Wong. Text-guided texturing by synchronized multi-view diffusion. arXiv preprint arXiv:2311.12891, 2023.</td></tr><tr><td>[35]</td><td>Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. In NeurIPS, 2022.</td></tr><tr><td>[36]</td><td>Wan-Duo Kurt Ma, Avisek Lahiri, JP Lewis, Thomas Leung, and W Bastiaan Kleijn. Directed diffusion: Direct control of object placement through attention guidance. In AAAI, 2024.</td></tr><tr><td>[37]</td><td>William Peebles and Saining Xie. Scalable diffusion models with transformers. In ICCV, 2023.</td></tr><tr><td>[38]</td><td>Quynh Phung, Songwei Ge, and Jia-Bin Huang. Grounded text-to-image synthesis with attention refocusing. arXiv preprint arXiv:2306.05427, 2023.</td></tr><tr><td>[39]</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M�ller, Joe Penna, and Robin Rombach. Sdxl: Improving latent diffusion models for high-resolution image synthesis. arXiv preprint arXiv:2307.01952, 2023.</td></tr><tr><td>[40]</td><td>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021.</td></tr><tr><td>[41]</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022.</td></tr><tr><td>[42]</td><td>Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, 2015.</td></tr><tr><td>[43]</td><td>Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In NeurIPS, 2022.</td></tr><tr><td>[44]</td><td>Takahiro Shirakawa and Seiichi Uchida. Noisecollage: A layout-aware text-to-image diffusion model based on noise cropping and merging. In CVPR, 2024.</td></tr></table>