{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "This paper introduces InstructPix2Pix, a foundational model for instruction-based image editing that the current paper builds upon and improves."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a crucial model for aligning image and text features that the current paper leverages for its cycle edit consistency mechanism."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces Stable Diffusion, the underlying latent diffusion model used in the current paper for image generation and manipulation."}, {"fullname_first_author": "Amir Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2022-08-01", "reason": "This paper introduces Prompt-to-Prompt, a method for image editing used in the current paper's baseline and for data generation; understanding this is critical to evaluating the improvements."}, {"fullname_first_author": "Kai Zhang", "paper_title": "MagicBrush: A manually annotated dataset for instruction-guided image editing", "publication_date": "2023-00-00", "reason": "This paper introduces a high-quality dataset for image editing, which serves as a strong baseline against which the unsupervised approach of the current paper is compared."}]}