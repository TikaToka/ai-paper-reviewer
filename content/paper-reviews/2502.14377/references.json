{"references": [{"fullname_first_author": "Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023", "reason": "This paper introduces the Diffusion Transformer (DiT) architecture, which is the foundation upon which the RelaCtrl method is built and significantly improved."}, {"fullname_first_author": "Chen", "paper_title": "PixArt-a: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "publication_date": "2023", "reason": "This work is the main baseline model compared against RelaCtrl throughout the paper, demonstrating the method's effectiveness in improving upon a state-of-the-art model."}, {"fullname_first_author": "Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023", "reason": "This paper introduces ControlNet, a crucial technique for controllable image generation that RelaCtrl builds upon and significantly optimizes."}, {"fullname_first_author": "Yu", "paper_title": "Metaformer is actually what you need for vision", "publication_date": "2022", "reason": "This paper's introduction of the Metaformer architecture is referenced to support the design choices within RelaCtrl, specifically the Two-Dimensional Shuffle Mixer (TDSM)."}, {"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This paper introduces the CLIP model, which is used for image quality and consistency assessment in RelaCtrl, highlighting its role in evaluating the method's performance."}]}