[{"content": "Methods|LLM|Res.|#Vision|Tokens|VQA<sup>v2</sup>|GQA|VisWiz|SciQA|VQA<sup>T</sup>|POPE|MME|MMB|SEED|LLaVA<sup>W</sup>|MM-|Avg. (%)|\n---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n**BLIP-2**|Vicuna-13B|224|32|65.0|41.0|19.6|61.0|42.5|85.3|1293.8|\u2013|46.4|38.1|22.4|\u2013|\n**InstructBLIP**|Vicuna-7B|224|32|\u2013|49.2|34.5|60.5|50.1|\u2013|\u2013|36.0|53.4|60.9|26.2|\u2013|\n**IDEFICS-9B**|LLaMA-7B|224|64|50.9|38.4|35.5|\u2013|25.9|\u2013|\u2013|48.2|\u2013|\u2013|\u2013|\u2013|\n**IDEFICS-80B**|LLaMA-65B|224|64|60.0|45.2|36.0|\u2013|30.9|\u2013|\u2013|54.5|\u2013|\u2013|\u2013|\u2013|\n**Qwen-VL**|Qwen-7B|448|256|78.8|59.3|35.2|67.1|63.8|\u2013|\u2013|38.2|56.3|\u2013|\u2013|\u2013|\n**Qwen-VL-Chat**|Qwen-7B|448|256|78.2|57.5|38.9|68.2|61.5|\u2013|1487.5|60.6|58.2|\u2013|\u2013|\u2013|\n**SPHINX**|LLaMA-13B|224|289|78.1|62.6|39.9|69.3|51.6|80.7|1476.1|66.9|56.2|73.5|36.0|56.0|\n**SPHINX-2k**|LLaMA-13B|762|2890|80.7|63.1|44.9|70.6|61.2|87.2|1470.6|65.9|57.9|76.9|40.2|59.0|\n**mPLUG-Owl2**|LLaMA-7B|448|1024|79.4|56.1|54.5|68.7|54.3|\u2013|1450.2|64.5|57.8|\u2013|36.2|\u2013|\n**Video-LLaVA**|Vicuna-7B|224|256|74.7|60.3|48.1|66.4|51.8|84.4|\u2013|60.9|\u2013|73.1|32.0|\u2013|\n**LLaVA-v1.5**|Vicuna-7B|336|576|78.5|62.0|50.0|66.8|58.2|85.9|1510.7|64.3|58.6|63.4|30.5|56.3|\n<span style=\"font-weight:bold; font-style:italic;\">LMMs with fewer vision tokens</span>|| || || || || || || || || || || || || ||\n**MQT-LLaVA**|Vicuna-7B|336|2|61.0|50.8|48.5|65.0|\u2013|74.5|1144.0|54.4|\u2013|41.7|19.5|\u2013|\n**MQT-LLaVA**|Vicuna-7B|336|36|73.7|58.8|51.0|66.8|\u2013|81.9|1416.3|63.4|\u2013|59.6|27.8|\u2013|\n**MQT-LLaVA**|Vicuna-7B|336|256|76.8|61.6|53.1|67.6|\u2013|84.4|1434.5|64.3|\u2013|64.6|29.8|\u2013|\n**PruMerge**|Vicuna-7B|336|32|72.0|\u2013|\u2013|68.5|56.0|76.3|1350.3|60.9|\u2013|\u2013|\u2013|\u2013|\n**PruMerge++**|Vicuna-7B|336|144|76.8|\u2013|\u2013|68.3|57.1|84.0|1462.4|64.9|\u2013|\u2013|\u2013|\u2013|\n**LLaMA-VID**|Vicuna-7B|336|2|\u2013|55.5|\u2013|68.8|49.0|83.1|\u2013|\u2013|\u2013|\u2013|\u2013|\u2013|\n**VoCo-LLaMA**|Vicuna-7B|336|1|72.3|57.0|\u2013|65.4|\u2013|81.4|1323.3|58.8|53.7|\u2013|\u2013|\u2013|\n**TokenPacker**|Vicuna-7B|336|36|75.0|59.6|50.2|\u2013|\u2013|86.2|\u2013|62.8|\u2013|\u2013|29.6|\u2013|\n<span style=\"font-weight:bold; font-style:italic;\">Ours</span>|| || || || || || || || || || || || || ||\n**LLaVA-Mini**|Vicuna-7B|336|1|77.6|60.9|56.2|70.4|57.0|84.4|1466.0|65.6|58.5|68.9|36.6|57.9|\n\u0394 compare to LLaVA-v1.5| |0.17%|-0.9|-1.1|+6.1|+3.6|-1.3|-1.5|-44.7|+1.3|-0.1|+5.5|+6.1|+1.6|\n**LLaVA-Mini-HD**|Vicuna-7B|672|64|78.9|61.8|58.5|69.7|59.1|85.3|1476.8|67.5|60.2|69.3|33.9|58.6|\n\u0394 compare to LLaVA-v1.5|11.1%|+0.4|-0.2|+8.5|+2.9|+0.9|+0.6|+33.9|+3.2|+1.6|+5.9|+3.4|+2.4|\n**LLaVA-Mini* (Image & Video)**|LLaMA-3.1-8B-Instruct|336|1|79.0|61.3|57.4|83.1|58.5|85.3|1522.7|71.6|63.0|70.2|37.2|60.7|", "caption": "Table 1: Performance on 11 image-based benchmarks. \u2018Res.\u2019 is resolution and \u2018#Vision Tokens\u2019 is the number of vision tokens fed to LLM backbone. \u2018*\u2019 indicates that involving extra training data.", "description": "\ud45c 1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c LLaVA-Mini \ubaa8\ub378\uc758 \uc774\ubbf8\uc9c0 \uae30\ubc18 \ubca4\uce58\ub9c8\ud06c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 11\uac00\uc9c0 \uc774\ubbf8\uc9c0 \ubca4\uce58\ub9c8\ud06c \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uac01 \ubaa8\ub378\uc758 \ud574\uc0c1\ub3c4(Res.), LLM \ubc31\ubcf8\uc5d0 \uc785\ub825\ub418\ub294 \ube44\uc804 \ud1a0\ud070 \uc218(#Vision Tokens), \uadf8\ub9ac\uace0 \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \ud2b9\ud788, \ucd94\uac00\uc801\uc778 \ud6c8\ub828 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc5d0\ub294 '*' \ud45c\uc2dc\uac00 \ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 LLaVA-Mini\uac00 \uc801\uc740 \ube44\uc804 \ud1a0\ud070\ub9cc\uc73c\ub85c\ub3c4 \uae30\uc874\uc758 \ub300\uaddc\ubaa8 \ub2e4\uc911 \ubaa8\ub2ec \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud568\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc8fc\uc694 \uacb0\uacfc \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.", "section": "5.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| #Vision |\n|---|---| \n| Tokens |", "caption": "Table 2: Performance on video-based open-ended generative benchmarks. We report accuracy (%) for question-answer, and scores (1-5, higher is better) for question-answer and generative performance. Results marked with bold and underlined indicate the best and second best, respectively.", "description": "\ud45c 2\ub294 \ube44\ub514\uc624 \uae30\ubc18 \uac1c\ubc29\ud615 \uc0dd\uc131 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc9c8\ubb38 \ub2f5\ubcc0 \uc815\ud655\ub3c4(%)\uc640 \uc9c8\ubb38 \ub2f5\ubcc0 \ubc0f \uc0dd\uc131 \uc131\ub2a5 \uc810\uc218(1~5\uc810, \ub192\uc744\uc218\ub85d \uc88b\uc74c)\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uac00\uc7a5 \uc6b0\uc218\ud55c \uacb0\uacfc\uc640 \ub450 \ubc88\uc9f8\ub85c \uc6b0\uc218\ud55c \uacb0\uacfc\ub294 \uad75\uc740 \ubc11\uc904\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc5d0 \uac78\uccd0 \uc5ec\ub7ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\uace0, \ud5a5\ud6c4 \uc5f0\uad6c \ubc29\ud5a5\uc744 \uc81c\uc2dc\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ud2b9\ud788, \uc9c8\ubb38 \ub2f5\ubcc0 \uc815\ud655\ub3c4\uc640 \uc0dd\uc131 \uc131\ub2a5 \uc810\uc218\ub97c \ud568\uaed8 \uc81c\uc2dc\ud568\uc73c\ub85c\uc368, \ubaa8\ub378\uc758 \uc885\ud569\uc801\uc778 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uace0, \uac1c\ubc29\ud615 \uc0dd\uc131 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \ubaa8\ub378 \uc131\ub2a5\uc744 \ub354\uc6b1 \uc815\ud655\ud558\uac8c \ube44\uad50\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "5 \uc2e4\ud5d8"}, {"content": "| Methods | #Frames | #Vision Tokens per Frame | Video-based Question-Answer |  |  |  | Video-based Generative Performance |  |  |  |  |  | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  |  |  | MSVD-QA |  | MSRVTT-QA |  | ActivityNet-QA | Correctness | Detail | Contextual | Temporal | Consistency | Avg. |\n|  |  |  | Acc. | Score | Acc. | Score | Acc. | Score |  |  |  |  |  |\n| **LLaMA Adapter** | 5 | 256 | 54.9 | 3.1 | 43.8 | 2.7 | 34.2 | 2.7 | 2.03 | 2.32 | 2.30 | 1.98 | 2.15 | 2.19 |\n| **VideoChat** | 16 | 32 | 56.3 | 2.8 | 45.0 | 2.5 | 26.5 | 2.2 | 2.23 | 2.50 | 2.53 | 1.94 | 2.24 | 2.30 |\n| **Video-LLaMA** | 16 | 64 | 51.6 | 2.5 | 29.6 | 1.8 | 12.4 | 1.1 | 1.96 | 2.18 | 2.16 | 1.82 | 1.79 | 1.99 |\n| **Video-ChatGPT** | 100 | ~3.6 | 64.9 | 3.3 | 49.3 | 2.8 | 35.2 | 2.7 | 2.40 | 2.52 | 2.62 | 1.98 | 2.37 | 2.37 |\n| **BT-Adapter** | 100 | ~2.6 | 67.5 | 3.7 | 57.0 | 3.2 | 45.7 | 3.2 | 2.68 | 2.69 | 3.27 | 2.34 | 2.46 | 2.69 |\n| **MovieChat** | 2048 | 32 | **75.2** | 3.8 | 52.7 | 2.6 | 45.7 | **3.4** | 2.76 | 2.93 | 3.01 | 2.24 | 2.42 | 2.65 |\n| **LLaMA-VID** | 1fps | 2 | 69.7 | 3.7 | 57.7 | 3.2 | **47.4** | 3.3 | **2.96** | **3.00** | **3.53** | **2.46** | **2.51** | **2.88** |\n| **Video-LLaVA** | 8 | 256 | 70.7 | **3.9** | **59.2** | **3.5** | 45.3 | 3.3 | 2.87 | 2.94 | 3.44 | 2.45 | **2.51** | 2.84 |\n| **LLaVA-Mini** | 1fps | **1** | **70.9** | 4.0 | 59.5 | 3.6 | 53.5 | 3.5 | 2.97 | **2.99** | **3.61** | 2.48 | 2.67 | **2.94** |", "caption": "Table 3: Performance on MVBench (accuracy). Detailed scores are reported in Appendix H.", "description": "\ud45c 3\uc740 MVBench \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c LLaVA-Mini\uc758 \uc815\ud655\ub3c4 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MVBench\ub294 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc744 \ud3ec\ud568\ud558\ub294 \ud3ec\uad04\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ud558\uc704 \ubca4\uce58\ub9c8\ud06c(\uc561\uc158, \uac1c\uccb4, \uc704\uce58, \uc7a5\uba74, \uac1c\uc218, \uc18d\uc131, \ud3ec\uc988, \ubb38\uc790, \uc778\uc9c0)\uc5d0 \ub300\ud55c LLaVA-Mini\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc138\ubd84\ud654\ub41c \uc810\uc218\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \uc810\uc218\ub294 \ubd80\ub85d H\uc5d0 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Methods | Action | Object | Position | Scene | Count | Attribute | Pose | Character | Cognition | Avg. | \n|---|---|---|---|---|---|---|---|---|---|---|\n| **mPLUG-Owl** | 28.4 | 33.0 | 25.0 | 29.0 | 29.3 | 42.0 | 24.0 | 31.0 | 25.3 | 29.7 | \n| **Video-ChatGPT** | 32.1 | 40.7 | 21.5 | 31.0 | 28.0 | 44.0 | 29.0 | 33.0 | 30.3 | 32.7 | \n| **Video-LLaMA** | 34.4 | 42.2 | 22.5 | 43.0 | 28.3 | 39.0 | 32.5 | 40.0 | 29.3 | 34.1 | \n| **VideoChat** | 38.0 | 41.2 | 26.3 | 48.5 | 27.8 | 44.3 | 26.5 | 41.0 | 27.7 | 35.5 | \n| **LLaMA-VID** | 43.4 | 36.7 | 39.8 | 22.0 | 36.5 | 37.3 | 37.5 | 34.0 | 60.5 | 41.4 | \n| **Video-LLaVA** | 48.0 | 46.5 | 27.8 | 84.5 | 35.5 | 45.8 | 34.0 | 42.5 | 34.2 | 43.1 | \n| **LLaVA-Mini** | 52.1 | 43.2 | 31.8 | 85.5 | 37.5 | 44.5 | 29.5 | 52.0 | 35.0 | 44.5 |", "caption": "Table 8: Effect of query-based compression.", "description": "\ud45c 8\uc740 \ucffc\ub9ac \uae30\ubc18 \uc555\ucd95\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucffc\ub9ac \uae30\ubc18 \uc555\ucd95\uc740 \uc774\ubbf8\uc9c0\uc758 \uc911\uc694\ud55c \ud2b9\uc9d5\uc744 \uc120\ud0dd\uc801\uc73c\ub85c \ucd94\ucd9c\ud558\uc5ec \ube44\uc804 \ud1a0\ud070\uc758 \uc218\ub97c \uc904\uc774\ub294 \uae30\ubc95\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ucffc\ub9ac \uae30\ubc18 \uc555\ucd95\uacfc \ud3c9\uade0 \ud480\ub9c1 \ubc29\uc2dd\uc744 \ube44\uad50\ud558\uc5ec, \ucffc\ub9ac \uae30\ubc18 \uc555\ucd95\uc774 \ube44\uc804 \ud1a0\ud070\uc758 \uc218\ub97c \uc904\uc774\uba74\uc11c\ub3c4 \uc131\ub2a5 \uc800\ud558\ub97c \ucd5c\uc18c\ud654\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \ube44\uc804 \ud1a0\ud070\uc758 \uc218\uac00 \uc801\uc744 \ub54c \ucffc\ub9ac \uae30\ubc18 \uc555\ucd95\uc758 \ud6a8\uacfc\uac00 \ub354\uc6b1 \ub450\ub4dc\ub7ec\uc9c0\uac8c \ub098\ud0c0\ub0a9\ub2c8\ub2e4. VQA, GQA, MMB \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. FLOPs(\uc5f0\uc0b0\ub7c9) \ubc0f \uc131\ub2a5(\uc815\ud655\ub3c4)\uc744 \ud568\uaed8 \ube44\uad50\ud558\uc5ec \ud6a8\uc728\uc131\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "6.2 \uc555\ucd95 \ud6a8\uacfc"}, {"content": "| Methods | #Frames | Holistic TR | Holistic AR | Single Detail NQA | Single Detail ER | Single Detail PQA | Multi Detail AO | Multi Detail AC | Avg. | Avg. Video Duration (minute) | 7 | 10 | 14 | 10 | 8 | 16 | 13 | 11 | Max Video Duration (minute) | 20 | 543 | 139 | 20 | 13 | 137 | 130 | 143 | Video-ChatGPT | 100 | 26.9 | 24.0 | 40.3 | 42.0 | 29.9 | 25.1 | 31.1 | 31.3 | MovieChat | 2048 | 29.5 | 25.0 | 24.2 | 24.7 | 25.8 | 28.6 | 22.8 | 25.8 | Movie-LLM | 1fps | 30.0 | 29.0 | 29.6 | 24.7 | 24.1 | 20.5 | 24.8 | 26.1 | TimeChat | 96 | 23.1 | 27.0 | 24.5 | 28.4 | 25.8 | 24.7 | 32.0 | 30.9 | LLaMA-VID | 1fps | 50.8 | 34.5 | 30.1 | 32.7 | 32.5 | 23.9 | 27.8 | 33.2 | MA-LMM | 1000 | 51.9 | 35.5 | 43.1 | 38.9 | 35.8 | 25.1 | 24.3 | 36.4 | LLaVA-Mini | 1fps | 76.0 | 50.0 | 44.5 | 37.5 | 49.0 | 24.3 | 18.4 | 42.8 |", "caption": "Table 9: Training details of LLaVA-Mini.", "description": "\ubcf8 \ud45c\ub294 \ub17c\ubb38\uc758 LLaVA-Mini \ubaa8\ub378 \ud559\uc2b5 \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Stage 1(Vision-Language Pretraining)\uacfc Stage 2(Instruction Tuning) \ub450 \ub2e8\uacc4\ub85c \ub098\ub258\uc5b4 \uac01 \ub2e8\uacc4\ubcc4\ub85c Vision Encoder, Projection, Compression, Modality Pre-fusion, Batch Size, Learning Rate, Optimizer, Epoch \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815 \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub4c8\uc758 \ud559\uc2b5 \uc5ec\ubd80(Trainable/Frozen)\ub3c4 \ud568\uaed8 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc5b4, LLaVA-Mini \ubaa8\ub378 \ud559\uc2b5 \uacfc\uc815\uc5d0 \ub300\ud55c \uc0c1\uc138\ud55c \uc774\ud574\ub97c \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "4.3 Training"}, {"content": "| Methods | #Frames | EgoSchema |\n|---|---|---:|\n| **Random** | - | 20 |\n| **mPLUG-Owl** | 16 | 31.1 |\n| **InternVideo** | 16 | 32.1 |\n| **Video-ChatGPT** | 100 | 36.2 |\n| **VideoChat** | 16 | **42.2** |\n| **TimeChat** | 96 | 33.0 |\n| **LLaMA-VID** | 1fps | 38.5 |\n| **Video-LLaVA** | 8 | 38.4 |\n| **LLaVA-Mini** | 1fps | **51.2** |", "caption": "Table 10: Comparison of LLaVA-Mini with previous token merging methods.", "description": "\uc774 \ud45c\ub294 LLaVA-Mini\uc640 \uae30\uc874\uc758 \ud1a0\ud070 \ubcd1\ud569 \ubc29\uc2dd\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaVA-Mini\ub294 \ud558\ub098\uc758 \ube44\uc804 \ud1a0\ud070\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc9c0\ub9cc, \uae30\uc874 \ubc29\uc2dd\ub4e4 (MQT-LLaVA, PruMerge, PruMerge++) \ubcf4\ub2e4 VQA, GQA, MMB \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c \ubaa8\ub450\uc5d0\uc11c \ub354 \ub192\uc740 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4.  \uc774\ub294 LLaVA-Mini\uac00 \ube44\uc804 \ud1a0\ud070\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \uc555\ucd95\ud558\uace0 \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \uc720\uc9c0\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ube44\uc804 \ud1a0\ud070\uc758 \uac1c\uc218\ub97c \ub298\ub824\uac00\uba70 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ube44\uad50 \uc2e4\ud5d8 \uacb0\uacfc\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.2 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Methods | Pre-fusion#Layers | #VisionTokens | FLOPs(T) | VQA<sup>v2</sup> | GQA | MMB |\n|---|---|---|---|---|---|---|\n| **LLaVA-v1.5** | - | 576 | 8.55 | 78.5 | 62.0 | 64.3 |\n| **LLaVA-Mini (w/o pre-fusion)** | 0 | 1 | 0.96 | 72.4 | 54.2 | 57.7 |\n|  | 0 | 16 | 1.16 | 74.1 | 55.4 | 59.2 |\n|  | 0 | 64 | 1.79 | 75.3 | 56.7 | 62.1 |\n|  | 0 | 144 | 2.85 | 76.9 | 58.9 | 64.9 |\n| **LLaVA-Mini (w/ pre-fusion)** | 1 | 1 | 1.21 | 74.8 | 55.5 | 60.4 |\n|  | 2 | 1 | 1.46 | 76.0 | 57.6 | 63.1 |\n|  | 3 | 1 | 1.81 | 76.9 | 59.1 | 64.9 |\n|  | 4 | 1 | 1.96 | 77.6 | 60.9 | 65.6 |", "caption": "Table 11: Performance of LLaVA-Mini when using only pre-fusion module without compression.", "description": "\ubcf8 \ud45c\ub294 \uc555\ucd95 \ubaa8\ub4c8 \uc5c6\uc774 \uc804\uc6a9 \ubaa8\ub4dc \ud4e8\uc804 \ubaa8\ub4c8\ub9cc \uc0ac\uc6a9\ud588\uc744 \ub54c LLaVA-Mini\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaVA-Mini\ub294 \ube44\uc804 \ud1a0\ud070\uc744 \uc555\ucd95\ud558\uc9c0 \uc54a\uace0\ub3c4 LLaVA-v1.5\uc640 \ube44\uad50\ud558\uc5ec \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub4dc \uc804 \ud4e8\uc804 \ubaa8\ub4c8\uc774 \ube44\uc804 \uc815\ubcf4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud14d\uc2a4\ud2b8 \ud1a0\ud070\uc5d0 \uc735\ud569\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "5.3 \ud6a8\uc728\uc131 \ubd84\uc11d"}, {"content": "| Methods | Res. | #Vision Tokens | VQA<sup>v2</sup> | GQA | MMB |\n|---|---|---|---|---|---| \n| **LLaVA-v1.5** | 336 | 576 | 78.5 | 62.0 | 64.3 |\n| **LLaVA-Mini** | 336 | 1 | 77.6 | 60.9 | 65.6 |\n|  | 336 | 4 | 77.7 | 60.9 | 66.7 |\n|  | 336 | 16 | 78.1 | 61.3 | 66.6 |\n|  | 336 | 64 | **78.5** | **61.6** | **67.5** |\n|  | 672 | 16 | 78.5 | 61.5 | 67.4 |\n|  | 672 | 64 | 78.9 | 61.8 | 67.5 |\n|  | 672 | 144 | 79.3 | 62.3 | 67.9 |\n|  | 672 | 576 | **80.0** | **62.9** | **68.1** |", "caption": "Table 12: Comparison of performing compression and pre-fusion outside or within LLM backbone.", "description": "\ubcf8 \ud45c\ub294 LLaVA-Mini \ubaa8\ub378\uc758 \ud575\uc2ec \uad6c\uc131 \uc694\uc18c\uc778 \uc555\ucd95 \ubc0f \ubaa8\ub2ec\ub9ac\ud2f0 \uc0ac\uc804 \uc735\ud569 \uacfc\uc815\uc744 LLM \ubc31\ubcf8 \uc678\ubd80\uc5d0\uc11c \uc218\ud589\ud558\ub294 \uac83\uacfc \ub0b4\ubd80\uc5d0\uc11c \uc218\ud589\ud558\ub294 \uac83\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLM \ubc31\ubcf8 \uc678\ubd80\uc5d0\uc11c \uc555\ucd95\uacfc \ubaa8\ub2ec\ub9ac\ud2f0 \uc0ac\uc804 \uc735\ud569\uc744 \uc218\ud589\ud588\uc744 \ub54c\uc758 \uc131\ub2a5(VQAv2, GQA, MMB)\uc744 LLM \ubc31\ubcf8 \ub0b4\ubd80\uc5d0\uc11c \uc218\ud589\ud588\uc744 \ub54c\uc640 \ube44\uad50\ud558\uc5ec \ud6a8\uc728\uc131\uacfc \uc131\ub2a5\uc758 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 LLaVA-Mini\uc758 \uc124\uacc4 \uc120\ud0dd\uc774 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "5.3 \ud6a8\uc728\uc131"}, {"content": "| Compression | #VisionTokens | FLOPs | VQA<sup>v2</sup> | GQA | MMB |\n|---|---|---|---|---|---| \n| **Average Pooling** | 1 | 1.96T | 76.1 | 59.8 | 64.0 |\n| **Query-based** |  | +2.42G | **77.6** | **60.9** | **65.6** |\n| **Average Pooling** | 4 | 2.01T | 76.9 | 60.3 | 65.1 |\n| **Query-based** |  | +2.44G | **77.7** | **60.9** | **66.7** |", "caption": "Table 13: Inference latency (millisecond) of LLaVA-Mini on various hardware platforms.", "description": "\ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ud558\ub4dc\uc6e8\uc5b4 \ud50c\ub7ab\ud3fc(RTX 3090, A100, A800)\uc5d0\uc11c LLaVA-Mini\uc758 \ucd94\ub860 \uc9c0\uc5f0 \uc2dc\uac04(\ubc00\ub9ac\ucd08)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaVA-Mini\ub294 \ube44\uc804 \ud1a0\ud070\uc758 \uc218\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \ub2ec\ub77c\uc9c0\ub294\ub370, \ube44\uc804 \ud1a0\ud070\uc774 1\uac1c\uc77c \ub54c \uac00\uc7a5 \ube60\ub978 \uc18d\ub3c4\ub97c \ubcf4\uc774\uba70, \ud1a0\ud070 \uc218\uac00 \uc99d\uac00\ud560\uc218\ub85d \uc9c0\uc5f0 \uc2dc\uac04\uc774 \uc99d\uac00\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 LLaVA-Mini\uc758 \ud6a8\uc728\uc131\uacfc \ud655\uc7a5\uc131\uc744 \ub2e4\uc591\ud55c \ud558\ub4dc\uc6e8\uc5b4 \ud658\uacbd\uc5d0\uc11c \ud3c9\uac00\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "5.3 \ud6a8\uc728\uc131"}, {"content": "| Settings | Stage1 | Stage2 |\n|---|---|---|\n| **Vision-Language Pretraining** | Vision-Language Pretraining | Instruction Turning |\n| **Modules** |  |  |\n| Vision Encoder | Frozen | Frozen |\n| Projection | Trainable | Trainable |\n| Large Language Model | Frozen | Trainable |\n| Compression | N/A | Trainable |\n| Modality Pre-fusion | N/A | Trainable |\n| **Hyperparameters** |  |  |\n| Batch Size | 256 | 256 |\n| Learning Rate | - | 1e-4 |\n| MM Learning Rate | 1e-3 | 1e-5 |\n| Schedule | Cosine decay | Cosine decay |\n| Warmup Ratio | 0.03 | 0.03 |\n| Optimizer | AdamW | AdamW |\n| Epoch | 1 | 2 |", "caption": "Table 14: Computational overhead (FLOPs) of each component in LLaVA-Mini.", "description": "\uc774 \ud45c\ub294 LLaVA-Mini\uc758 \uac01 \uad6c\uc131 \uc694\uc18c(\ube44\uc804 \uc778\ucf54\ub354, \ud504\ub85c\uc81d\uc158, \uc555\ucd95, \ubaa8\ub2ec\ub9ac\ud2f0 \uc0ac\uc804 \uc735\ud569, LLM)\uc758 \uacc4\uc0b0 \ube44\uc6a9(FLOPs)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaVA-Mini\ub294 \uae30\uc874\uc758 LLaVA-v1.5\uc640 \ube44\uad50\ud558\uc5ec, \ud2b9\ud788 LLM \ubc31\ubcf8\uc758 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ud06c\uac8c \uc904\uc5ec \uc804\uccb4\uc801\uc778 \ud6a8\uc728\uc131\uc744 \ub192\uc600\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  336x336 \ud574\uc0c1\ub3c4\uc640 672x672 \ud574\uc0c1\ub3c4\uc758 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubaa8\ub450 \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.3 \ud6a8\uc728\uc131"}, {"content": "| Methods | #Vision Tokens | VQA<sup>v2</sup> | GQA | MMB |\n|---|---|---|---|---|\n| **MQT-LLaVA** | 2 | 61.0 | 50.8 | 54.4 |\n| **MQT-LLaVA** | 36 | 73.7 | 58.8 | 63.4 |\n| **MQT-LLaVA** | 256 | 76.8 | 61.6 | 64.3 |\n| **PruMerge** | 32 | 72.0 | - | 60.9 |\n| **PruMerge++** | 144 | 76.8 | - | 64.9 |\n| **LLaVA-Mini** | 1 | 72.4 | 54.2 | 57.7 |\n| **LLaVA-Mini** | 16 | 74.1 | 55.4 | 59.2 |\n| **LLaVA-Mini** | 64 | 75.3 | 56.7 | 62.1 |\n| **LLaVA-Mini** | 144 | 76.9 | 58.9 | 64.9 |", "caption": "Table 15: Detailed results on 20 subsets of MVBench.", "description": "\ud45c 15\ub294 MVBench\uc758 20\uac1c \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MVBench\ub294 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \uc885\ud569\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\ub85c, \ud589\ub3d9, \uac1d\uccb4, \uc704\uce58, \uc7a5\uba74, \uac1c\uc218, \uc18d\uc131, \uc790\uc138, \ubb38\uc790, \uc778\uc9c0 \ub4f1 \uc5ec\ub7ec \uce21\uba74\uc744 \ub2e4\ub8f9\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c LLaVA-Mini\uc640 \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \ube44\ub514\uc624 LMM \ubaa8\ub378(mPLUG-Owl, Video-ChatGPT, Video-LLaMA, VideoChat, LLaMA-VID, Video-LLaVA)\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, LLaVA-Mini\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubcf4\ub2e4 \uc790\uc138\ud788 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \uac01 \ud558\uc704 \ub370\uc774\ud130\uc14b\uc758 \uc815\ud655\ub3c4 \uc810\uc218\ub294 \ud574\ub2f9 \uc791\uc5c5\uc758 \ub09c\uc774\ub3c4\uc640 LMM \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubc18\uc601\ud569\ub2c8\ub2e4. \ud2b9\ud788, LLaVA-Mini\ub294 \uc5ec\ub7ec \ud558\uc704 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\ub978 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\ub370, \uc774\ub294 LLaVA-Mini\uc758 \ud6a8\uc728\uc131\uacfc \uc815\ud655\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc99d\uac70\uc785\ub2c8\ub2e4.", "section": "5.2 \uc8fc\uc694 \uacb0\uacfc"}]