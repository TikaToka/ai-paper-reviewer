[{"content": "| Method | MSE \u2193 | ID \u2191 | C-T \u2191 | TC \u2191 |\n|---|---|---|---|---|\n| LoRA-1 | 0.0432 | 0.622 | 0.226 | **0.9974** |\n| LoRA-8 | **0.0223** | **0.703** | 0.224 | 0.9969 |\n| + Two-Stage | 0.0461 | 0.629 | **0.250** | 0.9971 |\n| + Reg | **0.0221** | **0.680** | **0.239** | **0.9972** |", "caption": "Table 1. Ablation of Baselines. Table evaluating Mean Square Error (MSE), Identity Preservation (ID), CLIP-T (C-T), and Temporal Coherency (TC) on the editing task. Our method demonstrates better reconstruction-edibility trade-off.", "description": "\ud45c 1\uc740 \uae30\uc900 \ubaa8\ub378\ub4e4\uc5d0 \ub300\ud55c \uc5d0\uc774\ube14\ub808\uc774\uc158 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud3b8\uc9d1 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc81c\uacf1 \uc624\ucc28(MSE), \uc815\uccb4\uc131 \ubcf4\uc874(ID), CLIP-T(C-T), \uc2dc\uac04\uc801 \uc77c\uad00\uc131(TC)\uc744 \ud3c9\uac00\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\ub860\uc740 \uc7ac\uad6c\uc131\uacfc \ud3b8\uc9d1\uc131 \uac04\uc758 \uade0\ud615\uc744 \ub354 \uc798 \ub9de\ucd94\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MSE\ub294 \uc7ac\uad6c\uc131 \ud488\uc9c8\uc744, ID\ub294 \uc6d0\ubcf8 \ube44\ub514\uc624\uc758 \uc815\uccb4\uc131\uc774 \uc5bc\ub9c8\ub098 \uc798 \uc720\uc9c0\ub418\uc5c8\ub294\uc9c0\ub97c, C-T\ub294 \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc640 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8 \uac04\uc758 \uc758\ubbf8\uc801 \uc77c\uce58\ub3c4\ub97c, TC\ub294 \ube44\ub514\uc624 \ud504\ub808\uc784 \uac04\uc758 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \uce21\uc815\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc7ac\uad6c\uc131\uacfc \ud3b8\uc9d1\uc131 \uce21\uba74\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \ud3c9\uac00 \uc9c0\ud45c"}, {"content": "| Method | MSE \u2193 | ID \u2191 | C-T \u2191 | TC \u2191 |\n|---|---|---|---|---|\n| Tex-Inv | 0.0714 | 0.145 | 0.201 | 0.9927 |\n| DB-LoRA | 0.0223 | 0.703 | 0.224 | 0.9969 |\n| NewMove | 0.2223 | 0.270 | 0.204 | 0.9914 |\n| DreamVideo | 0.2021 | 0.118 | 0.218 | 0.9657 |\n| DreamMix | 0.0429 | 0.579 | 0.226 | 0.9965 |\n| Ours | 0.0221 | 0.680 | 0.239 | 0.9972 |", "caption": "Table 2. Editing Task Evaluation. Table evaluating Mean Square Error (MSE), Identity Preservation (ID), CLIP-T (C-T), and Temporal Coherency (TC) on the editing task. Our method achieves a superior reconstruction-editability trade-off compared to the competing approaches.", "description": "\ud45c 2\ub294 \ube44\ub514\uc624 \ud3b8\uc9d1 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud3c9\uac00 \uc9c0\ud45c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud3c9\uac00 \uc9c0\ud45c\ub294 \ud3c9\uade0 \uc81c\uacf1 \uc624\ucc28(MSE), \uc2e0\uc6d0 \ubcf4\uc874(ID), CLIP-T(C-T), \uc2dc\uac04\uc801 \uc77c\uad00\uc131(TC)\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uacbd\uc7c1 \uae30\ubc95\uc5d0 \ube44\ud574 \uc7ac\uad6c\uc131\uacfc \ud3b8\uc9d1\uc131 \uac04\uc758 \uade0\ud615\uc744 \ub354 \uc798 \ub9de\ucd98\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989,  MSE\ub294 \ub0ae\uac8c \uc720\uc9c0\ud558\uba74\uc11c \ub3d9\uc2dc\uc5d0 ID, C-T, TC \uc810\uc218\ub294 \ub192\uac8c \uc720\uc9c0\ud558\uc5ec \uc6d0\ubcf8 \ube44\ub514\uc624\uc758 \ud2b9\uc9d5\uc744 \uc798 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \uc790\uc720\ub86d\uac8c \ud3b8\uc9d1\ud560 \uc218 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Method | IP | MP | AP | OP |\n|---|---|---|---|---|\n| Ours *vs* DreamMix | 87% | 88% | 98% | 100% |\n| Ours *vs* LoRA-1 | 99% | 95% | 94% | 100% |\n| Ours *vs* LoRA-8 (DB-LoRA) | 78% | 75% | 98% | 98% |\n| Ours *vs* Two-Stage | 86% | 97% | 76% | 90% |", "caption": "Table 3. User Study. User study results comparing methods on Identity Preservation (ID), Motion Preservation (MP), Adherence to Prompt (AP), and Overall Preference of the edits (OP). Preference is computed in percentages.", "description": "\uc774 \ud45c\ub294 \uc0ac\uc6a9\uc790 \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc0ac\uc6a9\uc790\ub4e4\uc740 \ub2e4\uc591\ud55c \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\ub41c \ube44\ub514\uc624 \uc30d\uc744 \ubcf4\uace0, \uac01 \ubc29\ubc95\uc758 \uc2e0\uc6d0 \ubcf4\uc874(ID), \ubaa8\uc158 \ubcf4\uc874(MP), \ud504\ub86c\ud504\ud2b8 \uc900\uc218(AP) \ubc0f \ud3b8\uc9d1\uc758 \uc804\ubc18\uc801\uc778 \uc120\ud638\ub3c4(OP)\ub97c \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4.  \uc120\ud638\ub3c4\ub294 \ubc31\ubd84\uc728\ub85c \uacc4\uc0b0\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uc989, \uc0ac\uc6a9\uc790\ub4e4\uc774 \uac01 \ubc29\ubc95\uc774 \uc5bc\ub9c8\ub098 \uc798 \uc791\ub3d9\ud558\ub294\uc9c0\uc5d0 \ub300\ud574 \uc8fc\uad00\uc801\uc778 \uc758\uacac\uc744 \uc81c\uc2dc\ud55c \uacb0\uacfc\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.", "section": "5.3 \uc0ac\uc6a9\uc790 \uc5f0\uad6c"}, {"content": "| Autoencoder | MAGVIT |\n|---|---| \n| Base channels | 16 |\n| Channel multiplier | [1, 4, 16, 32, 64] |\n| Encoder blocks count | [1, 1, 2, 8, 8] |\n| Decoder blocks count | [4, 4, 4, 4, 4] |\n| Stride of frame | [1, 2, 2, 2, 1] |\n| Stride of h and w | [2, 2, 2, 2, 1] |\n| Padding mode | replicate |\n| Compression rate | 8x16x16 |\n| Bottleneck channels | 32 |\n| Use KL divergence | \u2713 |\n| Use adaptive norm | \u2713(decoder only) |", "caption": "Table 4. Autoencoder and MAGVIT specifications.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \"8 Architecture and Training Details\" \uc139\uc158\uc5d0 \uc788\ub294 MAGVIT \uae30\ubc18\uc758 \ube44\ub514\uc624 \uc624\ud1a0\uc778\ucf54\ub354\uc758 \uad6c\uccb4\uc801\uc778 \uc0ac\uc591\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc790\uc138\ud788\ub294 \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354 \ube14\ub85d\uc758 \uc218, \ucc44\ub110 \uc218, \uc2a4\ud2b8\ub77c\uc774\ub4dc, \ud328\ub529 \ubc29\uc2dd, \uc555\ucd95 \ube44\uc728, bottleneck \ucc44\ub110 \uc218, KL divergence \ubc0f \uc801\uc751\ud615 \uc815\uaddc\ud654 \uc0ac\uc6a9 \uc5ec\ubd80 \ub4f1\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "8 Architecture and Training Details"}, {"content": "| Backbone | DiT |\n|---|---| \n| Input channels | 32 |\n| Patch size | 1 \u00d7 2 \u00d7 2 |\n| Latent token channels | 4096 |\n| Positional embeddings | 3D-RoPE |\n| DiT blocks count | 32 |\n| Attention heads count | 32 |\n| Window size | 6144 (center) |\n| Normalization | Layer normalization |\n| Use flash attention | \u2713 |\n| Use QK-normalization | \u2713 |\n| Use self conditioning | \u2713 |\n| Self conditioning prob. | 0.9 |\n| Context channels | 1024 |", "caption": "Table 5. Backbone and DiT specifications.", "description": "\ud45c 5\ub294 \ub17c\ubb38\uc758 DiT(Diffusion Transformer) \uae30\ubc18 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ubc31\ubcf8(backbone)\uacfc DiT \uc0ac\uc591\uc5d0 \ub300\ud55c \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc790\uc138\ud558\uac8c\ub294, \uc785\ub825 \ucc44\ub110 \uc218, \ud328\uce58 \ud06c\uae30, \uc7a0\uc7ac \ud1a0\ud070 \ucc44\ub110, \uc704\uce58 \uc784\ubca0\ub529 \ubc29\uc2dd, DiT \ube14\ub85d \uc218, \uc5b4\ud150\uc158 \ud5e4\ub4dc \uc218, \uc5b4\ud150\uc158 \uc708\ub3c4\uc6b0 \ud06c\uae30, \uc815\uaddc\ud654 \uae30\ubc95, \ud50c\ub798\uc2dc \uc5b4\ud150\uc158 \uc0ac\uc6a9 \uc5ec\ubd80, QK \uc815\uaddc\ud654 \uc0ac\uc6a9 \uc5ec\ubd80, \uc140\ud504 \ucee8\ub514\uc154\ub2dd \uc0ac\uc6a9 \uc5ec\ubd80, \ucee8\ud14d\uc2a4\ud2b8 \ucc44\ub110 \uc218 \ub4f1 DiT \uc544\ud0a4\ud14d\ucc98\uc758 \uc8fc\uc694 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uad6c\uc870\uc640 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "3.1 \uc608\ube44\uc0ac\ud56d"}, {"content": "| Optimizer | AdamW |\n|---|---| \n| Learning rate | $1\\times 10^{-4}$ |\n| LR scheduler | constant |\n| Beta | [0.9, 0.99] |\n| Weight decay | 0.01 |\n| Gradient clipping | 0.05 |\n| Dropout (Stage I) | 0.8 |\n| Dropout (Stage II) | 0.5 |", "caption": "Table 6. Training stages and optimization settings.", "description": "\ud45c 6\uc740 \ub17c\ubb38\uc758 \ud6c8\ub828 \uacfc\uc815\uc5d0 \ub300\ud55c \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \ub2e8\uacc4\ub85c \uc9c4\ud589\ub418\ub294 \ud6c8\ub828 \uacfc\uc815(Identity Basis \ud559\uc2b5 \ubc0f Motion Residual Encoding)\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ucd5c\uc801\ud654 \uc124\uc815, \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(\ud559\uc2b5\ub960, \uac00\uc911\uce58 \uac10\uc18c, \uadf8\ub798\ub514\uc5b8\ud2b8 \ud074\ub9ac\ud551 \ub4f1), \ub4dc\ub86d\uc544\uc6c3 \ube44\uc728, \uadf8\ub9ac\uace0 \uac01 \ub2e8\uacc4\uc758 \ubc18\ubcf5 \ud69f\uc218 \ub4f1\uc744 \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ubcf8 \uc5f0\uad6c\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud6c8\ub828 \uc804\ub7b5\uc744 \uba85\ud655\ud788 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3.4 Regularization"}]