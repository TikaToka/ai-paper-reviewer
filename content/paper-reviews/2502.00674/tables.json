[{"content": "|                 | Model Configuration                | LC Win Rate |\n|-----------------|------------------------------------|--------------|\n| Individual      | WizardLM-2-8x22B                   | 53.1         |\n|                 | Qwen1.5-110B-Chat                  | 43.9         |\n|                 | LLaMA-3-70B-Instruct                | 34.4         |\n|                 | Qwen1.5-72B-Chat                    | 36.6         |\n|                 | Mixtral-8x22B-Instruct-v0.1         | 30.2         |\n|                 | dbrx-instruct                       | 25.4         |\n| Mixed-MoA       | 2-Layer MoA [Wang et al., 2024a]   | 59.1         |\n| Self-MoA       | 2-Layer Self-MoA + WizardLM         | **65.7**     |", "caption": "Table 1: Comparison of Self-MoA and Mixed-MoA on AlpacaEval 2.0 leaderboard. We use Qwen1.5-110B-Chat as the aggregator.", "description": "\ud45c 1\uc740 AlpacaEval 2.0 \ub9ac\ub354\ubcf4\ub4dc\uc5d0\uc11c Self-MoA\uc640 Mixed-MoA\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  Qwen1.5-110B-Chat \ubaa8\ub378\uc744 \uc9d1\uacc4\uc790(aggregator)\ub85c \uc0ac\uc6a9\ud588\uc73c\uba70, \uac1c\ubcc4 \ubaa8\ub378(Individual)\uc758 \uc131\ub2a5, Mixed-MoA(\uc5ec\ub7ec \ubaa8\ub378\uc758 \ucd9c\ub825\uc744 \uacb0\ud569), \uadf8\ub9ac\uace0 Self-MoA(\ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc758 \uc5ec\ub7ec \ucd9c\ub825\uc744 \uacb0\ud569)\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LC Win Rate\ub294 \uae38\uc774\ub97c \uace0\ub824\ud55c \uc2b9\ub960\uc744 \ub098\ud0c0\ub0b4\uba70, Self-MoA\uac00 Mixed-MoA\ubcf4\ub2e4 \ub192\uc740 \uc2b9\ub960\uc744 \uae30\ub85d\ud55c \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.1 AlpacaEval 2.0\ub97c \uc0ac\uc6a9\ud55c \uc77c\ubc18 \ubaa9\uc801 \ubaa8\ub378 \uc2e4\ud5d8"}, {"content": "| Model Configuration | LC Win Rate |\n|---|---|---|\n| Individual | gemma-2-9b-it-WPO-HB | 76.7 |\n| Individual | gemma-2-9b-it-SimPO | 72.4 |\n| Self-MoA | Self-MoA + gemma-2-9b-it-WPO-HB | **78.5** |\n| Self-MoA | Self-MoA + gemma-2-9b-it-SimPO | 75.0 |", "caption": "Table 2: Self-MoA achieves state-of-the-art performance on the AlpacaEval 2.0 leaderboard when using top-performing models as both proposers and aggregators. We only ensemble 4 outputs due to context window constraints.", "description": "\ud45c 2\ub294 \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc744 \uc81c\uc548\uc790\uc640 \uc9d1\uacc4\uc790 \ubaa8\ub450\ub85c \uc0ac\uc6a9\ud558\uc5ec AlpacaEval 2.0 \ub9ac\ub354\ubcf4\ub4dc\uc5d0\uc11c Self-MoA\uac00 \ucd5c\ucca8\ub2e8 \uc131\ub2a5\uc744 \ub2ec\uc131\ud588\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucee8\ud14d\uc2a4\ud2b8 \ucc3d \ud06c\uae30 \uc81c\uc57d\uc73c\ub85c \uc778\ud574 \ucd9c\ub825 4\uac1c\ub9cc \uc559\uc0c1\ube14\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378 \uad6c\uc131(\uac1c\ubcc4 \ubaa8\ub378, Mixed-MoA, Self-MoA)\uc5d0 \ub530\ub978 AlpacaEval 2.0\uc758 LC \uc2b9\ub960\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \ud2b9\ud788 Self-MoA\ub294 \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc744 \ubc18\ubcf5\uc801\uc73c\ub85c \uc0d8\ud50c\ub9c1\ud558\uc5ec \ubaa8\ub378 \ub0b4 \ub2e4\uc591\uc131\uc744 \ud65c\uc6a9\ud558\uba70, \uae30\uc874\uc758 \uc5ec\ub7ec \ubaa8\ub378\uc744 \ud63c\ud569\ud558\ub294 \ubc29\uc2dd\uc778 Mixed-MoA\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ucee8\ud14d\uc2a4\ud2b8 \ucc3d \uc81c\uc57d\uc744 \uace0\ub824\ud558\uc5ec \ucd9c\ub825 \uac1c\uc218\ub97c 4\uac1c\ub85c \uc81c\ud55c\ud55c \uc810\ub3c4 \uc911\uc694\ud55c \ud2b9\uc9d5\uc785\ub2c8\ub2e4.", "section": "3.1 AlpacaEval 2.0\uc5d0\uc11c\uc758 \uc77c\ubc18 \ubaa9\uc801 \ubaa8\ub378\uc744 \uc774\uc6a9\ud55c \uc2e4\ud5d8"}, {"content": "|   | Aggregator | Proposer | MMLU | CRUX | MATH |\n|---|---|---|---|---|---| \n| Individual | - | i | 66.16 | 36.25 | 53.81 |\n|  | - | d | 60.91 | 49.51 | 53.82 |\n|  | - | m | 54.36 | 27.88 | 69.57<sup class=\"ltx_note_mark\">4</sup> |\n| Mixed-MoA | i | iimmdd | 67.89 | 42.88 | 64.38 |\n|  |  | imdddd | 67.42 | 44.50 | 63.90 |\n|  |  | iiiimd | 68.90 | 41.25 | 63.00 |\n|  |  | immmmd | 66.63 | 42.75 | 66.02 |\n|  |  | iimmmm | 66.23 | 39.25 | 66.10 |\n|  |  | iiimmm | 67.49 | 38.25 | 64.16 |\n|  |  | iiiimm | 68.00 | 37.00 | 62.92 |\n|  |  | iidddd | 68.21 | 45.50 | 62.56 |\n|  |  | iiiddd | 68.21 | 42.88 | 62.38 |\n|  |  | iiiidd | 68.47 | 40.75 | 61.24 |\n|  |  | mmdddd | 66.34 | 46.75 | 66.48 |\n|  |  | mmmddd | 65.80 | 47.00 | 67.32 |\n|  |  | mmmmdd | 65.44 | 42.50 | 67.62 |\n| Self-MoA | i | 6 \u00d7 TaskBest | **69.01** | 50.75 | 68.42 |\n|  | TaskBest | 6 \u00d7 TaskBest | **69.01** | **52.62** | 69.80<sup class=\"ltx_sup\"><a class=\"ltx_ref ltx_font_medium\" href=\"https://arxiv.org/html/2502.00674v1#footnote4\" title=\"Footnote 4 \u2023 Table 3 \u2023 Evaluation datasets. \u2023 3.2 Experiments on Multiple Datasets with Specialized Models \u2023 3 Is Ensembling Different LLMs Beneficial? \u2023 Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?\"><span class=\"ltx_text ltx_ref_tag\">4</span></a></sup> |", "caption": "Table 3: Comparison of Self-MoA and Mixed-MoA in MMLU, CRUX, and MATH.\nThe labels i, m, and d refer to Qwen2-7B-Instruct, DeepSeek-Coder-V2-Lite-Instruct, and Qwen2-Math-7B-Instruct, respectively. The average performance represents the mean accuracy across MMLU, CRUX, and MATH. TaskBest indicates that we use the strongest model for each task as both proposer and aggregator.", "description": "\ud45c 3\uc740 MMLU, CRUX, MATH \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Self-MoA\uc640 Mixed-MoA\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. i, m, d\ub294 \uac01\uac01 Qwen2-7B-Instruct, DeepSeek-Coder-V2-Lite-Instruct, Qwen2-Math-7B-Instruct \ubaa8\ub378\uc744 \ub098\ud0c0\ub0b4\uba70, \uac01 \ubaa8\ub378\uc740 \ud2b9\uc815 \uc791\uc5c5\uc5d0 \ud2b9\ud654\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ud3c9\uade0 \uc131\ub2a5\uc740 \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. TaskBest\ub294 \uac01 \uc791\uc5c5\uc5d0 \uac00\uc7a5 \uc801\ud569\ud55c \ubaa8\ub378\uc744 \uc81c\uc548\uc790\uc640 \uc9d1\uacc4\uc790\ub85c \ubaa8\ub450 \uc0ac\uc6a9\ud588\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378 \uc870\ud569\uacfc \uc124\uc815 \ud558\uc5d0\uc11c Self-MoA\uac00 Mixed-MoA\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud2b9\uc218 \ubaa9\uc801 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8"}, {"content": "| Dataset | \\alpha Coefficient | \\alpha P-value | \\beta Coefficient | \\beta P-value | R<sup>2</sup> |\n|---|---|---|---|---|---| \n| MMLU | 2.558 \u00b1 0.176 | &lt;0.001 | 1.841 \u00b1 0.176 | &lt;0.001 | 0.771 |\n| CRUX | 4.548 \u00b1 0.459 | &lt;0.001 | 1.421 \u00b1 0.459 | &lt;0.001 | 0.685 |\n| MATH | 4.719 \u00b1 0.416 | &lt;0.001 | 2.839 \u00b1 0.416 | &lt;0.001 | 0.760 |", "caption": "Table 4: Linear regression (Equation\u00a01) of MoA\u2019s performance t\ud835\udc61titalic_t on diversity d\ud835\udc51ditalic_d and quality q\ud835\udc5eqitalic_q.", "description": "\ud45c 4\ub294 \ub2e4\uc591\uc131(d)\uacfc \ud488\uc9c8(q)\uc5d0 \ub530\ub978 MoA \uc131\ub2a5(t)\uc758 \uc120\ud615 \ud68c\uadc0 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc758 4\uc7a5 \"The Quality-Diversity Trade-off\" \uc139\uc158\uc5d0\uc11c MoA\uc758 \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ub2e4\uc591\uc131\uacfc \ud488\uc9c8\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubd84\uc11d\ud558\uae30 \uc704\ud574 \uc120\ud615 \ud68c\uadc0 \ubd84\uc11d\uc744 \uc2e4\uc2dc\ud558\uc600\uc73c\uba70,  \uadf8 \uacb0\uacfc\ub97c \ud45c 4\uc5d0 \uc81c\uc2dc\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b(MMLU, CRUX, MATH)\uc5d0 \ub300\ud574 \uacc4\uc218(\u03b1, \u03b2), p-\uac12, \uadf8\ub9ac\uace0 \uacb0\uc815\uacc4\uc218(R\u00b2)\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \ub2e4\uc591\uc131\uacfc \ud488\uc9c8\uc774 MoA \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc758 \ud06c\uae30\uc640 \ud1b5\uacc4\uc801 \uc720\uc758\uc131\uc744 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "4\uc7a5 The Quality-Diversity Trade-off"}, {"content": "| Dataset | Method | Avg. (K=1) | K=2 | K=3 | K=4 |  |\n|---|---|---|---|---|---|---|\n| MMLU | K-Norm | 0.771 | 0.809 | 0.832 | 0.845 |  |\n|  | Centered-1/K-Norm | 0.771 | 0.881 | 0.902 | 0.903 |  |\n| CRUX | K-Norm | 0.685 | 0.736 | 0.765 | 0.779 |  |\n|  | Centered-1/K-Norm | 0.685 | 0.753 | 0.758 | 0.753 |  |\n| MATH | K-Norm | 0.760 | 0.720 | 0.692 | 0.672 |  |\n|  | Centered-1/K-Norm | 0.760 | 0.720 | 0.692 | 0.672 |  |", "caption": "Table 5: The R2superscript\ud835\udc452R^{2}italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of the linear regression when we use different quality measurement methods. We find using Centered-1/K-Norm with K=2 can achieve good performance among all these three datasets.", "description": "\ud45c 5\ub294 \ub2e4\uc591\ud55c \ud488\uc9c8 \uce21\uc815 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c \uc120\ud615 \ud68c\uadc0 \ubd84\uc11d\uc758 R \uc81c\uacf1 \uac12\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc138 \uac00\uc9c0 \ub370\uc774\ud130 \uc138\ud2b8 \ubaa8\ub450\uc5d0\uc11c \uc911\uc559 1/K-\ub188(K=2)\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ub0b8\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  R \uc81c\uacf1 \uac12\uc740 \ub3c5\ub9bd \ubcc0\uc218(\ub2e4\uc591\uc131 \ubc0f \ud488\uc9c8)\uac00 \uc885\uc18d \ubcc0\uc218(MoA \uc131\ub2a5)\uc744 \uc5bc\ub9c8\ub098 \uc798 \uc124\uba85\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4.  R \uc81c\uacf1 \uac12\uc774 \ub192\uc744\uc218\ub85d \ub3c5\ub9bd \ubcc0\uc218\uac00 \uc885\uc18d \ubcc0\uc218\uc758 \ubcc0\ub3d9\uc744 \ub354 \uc798 \uc124\uba85\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774, \uc911\uc559 1/K-\ub188(K=2)\uc744 \uc0ac\uc6a9\ud558\uba74 \uc138 \uac00\uc9c0 \ub370\uc774\ud130 \uc138\ud2b8 \ubaa8\ub450\uc5d0\uc11c R \uc81c\uacf1 \uac12\uc774 \uac00\uc7a5 \ub192\uc544\uc9d1\ub2c8\ub2e4. \uc774\ub294 \uc911\uc559 1/K-\ub188(K=2) \ubc29\ubc95\uc774 MoA\uc758 \uc131\ub2a5\uc744 \uac00\uc7a5 \uc798 \uc124\uba85\ud558\ub294 \ud488\uc9c8 \uce21\uc815 \ubc29\ubc95\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.2 When Mixed-MoA Outperforms Self-MoA?"}, {"content": "|   | Aggregator | Proposer | Average |\n|---|---|---|---|\n| Individual | - | i | 52.07 |\n|  | - | d | 54.74 |\n|  | - | m | 50.60 |\n| Mixed-MoA | i | iimmdd | 58.38 |\n|  |  | imdddd | 58.61 |\n|  |  | iiiimd | 57.72 |\n|  |  | immmmd | 58.47 |\n|  |  | iimmmm | 57.19 |\n|  |  | iiimmm | 56.63 |\n|  |  | iiiimm | 55.97 |\n|  |  | iidddd | 58.76 |\n|  |  | iiiddd | 57.82 |\n|  |  | iiiidd | 56.82 |\n|  |  | mmdddd | 59.86 |\n|  |  | mmmddd | 60.04 |\n|  |  | mmmmdd | 58.52 |\n| Self-MoA | i | dddddd | 59.69 |\n|  | i | 6 \u00d7 TaskBest | 62.73 |\n|  | TaskBest | 6 \u00d7 TaskBest | 63.81 |", "caption": "Table 6: Comparison of Self-MoA and Mixed-MoA on the mixture task of MMLU, CRUX, and MATH, measured by the average performance of three tasks from Table\u00a03. Mixed-MoA models with top two average performances are highlighted by underline.", "description": "\ud45c 6\uc740 \uc138 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c(MMLU, CRUX, MATH)\ub97c \ud63c\ud569\ud55c \ud63c\ud569 \uacfc\uc81c\uc5d0\uc11c Self-MoA\uc640 Mixed-MoA\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \uacfc\uc81c\uc758 \ud3c9\uade0 \uc131\ub2a5\uc73c\ub85c \uce21\uc815\ub418\uba70, \ud45c 3\uc758 \uacb0\uacfc\ub97c \uae30\ubc18\uc73c\ub85c \ud569\ub2c8\ub2e4. \uc0c1\uc704 \ub450 \uac1c\uc758 \ud3c9\uade0 \uc131\ub2a5\uc744 \uac00\uc9c4 Mixed-MoA \ubaa8\ub378\uc740 \ubc11\uc904\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378 \uc870\ud569\uc744 \uc0ac\uc6a9\ud55c MoA \uc804\ub7b5\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec, \ub2e8\uc77c \ucd5c\uace0 \uc131\ub2a5 \ubaa8\ub378\uc744 \ubc18\ubcf5\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 Self-MoA \uc804\ub7b5\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788,  \uac01 \uacfc\uc81c\uc5d0 \ud2b9\ud654\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5 \ucc28\uc774\ub97c \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "3.2 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud2b9\ud654\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8"}, {"content": "|       | Aggregator | Proposer | MMLU |\n|---|---|---|---|\n| Individual | - | i | 66.16 |\n|  | - | l | 66.40 |\n| Mixed-MoA | i | iiilll | 70.73 |\n| Self-MoA | i | iiiiii | 69.01 |\n|  | i | llllll | 71.27 |", "caption": "Table 7: MoA of Llama-3.1-8B-Instruct and Qwen2-7B-Instruct. l is short for Llama-3.1-8B-Instruct and i is short for Qwen2-7B-Instruct.", "description": "\ud45c 7\uc740 Llama-3.1-8B-Instruct\uc640 Qwen2-7B-Instruct \ub450 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c MoA(Mixture-of-Agents)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Llama-3.1-8B-Instruct\ub294 'l'\ub85c, Qwen2-7B-Instruct\ub294 'i'\ub85c \uc57d\uce6d\ud558\uc5ec \ud45c\uc5d0 \ud45c\uae30\ud588\uc2b5\ub2c8\ub2e4. \ud45c\ub294 \uac1c\ubcc4 \ubaa8\ub378\uc758 \uc131\ub2a5,  \ub2e4\uc591\ud55c \ube44\uc728\ub85c \ub450 \ubaa8\ub378\uc744 \ud63c\ud569\ud558\uc5ec \uc0ac\uc6a9\ud55c MoA\uc758 \uc131\ub2a5, \uadf8\ub9ac\uace0 Self-MoA (\ub2e8\uc77c \ubaa8\ub378 \ubc18\ubcf5 \uc0ac\uc6a9)\uc758 \uc131\ub2a5\uc744 MMLU \ubca4\uce58\ub9c8\ud06c \uae30\uc900\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. Self-MoA\uac00 \ud63c\ud569 \ubc29\uc2dd\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4.2 When Mixed-MoA Outperforms Self-MoA?"}, {"content": "| Model Configuration | LC Win Rate | # Forward Passes |\n|---|---|---|\n| Mixed-MoA | 65.4 | 13 |\n| Self-MoA<br>2-Layer Self-MoA + WizardLM-2-8x22B | **65.7** | 7 |", "caption": "Table 8: Results of 3-Layer Mixed-MoA.", "description": "\ud45c 8\uc740 3-\ub808\uc774\uc5b4 \ud63c\ud569 MoA(Mixture-of-Agents)\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ubaa8\ub378 \uad6c\uc131, LC \uc2b9\ub960, \uadf8\ub9ac\uace0 \uc21c\ubc29\ud5a5 \ud328\uc2a4 \uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ubaa8\ub378 \uad6c\uc131\uc740 \uc0ac\uc6a9\ub41c \ubaa8\ub378\uc758 \uc885\ub958\uc640 \ub808\uc774\uc5b4 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. LC \uc2b9\ub960\uc740 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc774\uace0, \uc21c\ubc29\ud5a5 \ud328\uc2a4 \uc218\ub294 \ubaa8\ub378 \ucd94\ub860\uc5d0 \ud544\uc694\ud55c \uacc4\uc0b0\ub7c9\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 Self-MoA\uc640 \ube44\uad50\ud558\uc5ec 3-\ub808\uc774\uc5b4 \ud63c\ud569 MoA\uc758 \ud6a8\uc728\uc131\uc744 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "A.1 Multi-Layer MoA"}, {"content": "| R-square | Level |\n|---|---| \n| [0,0.2) | Very weak |\n| [0.2,0.4) | Weak |\n| [0.4,0.6) | Median |\n| [0.6,0.8) | Strong |\n| [0.8,1.0] | Very Strong |", "caption": "Table 9: The interpretation of R-square", "description": "\ud45c 9\ub294 R-\uc81c\uacf1 \uac12\uc758 \ud574\uc11d\uc5d0 \ub300\ud55c \ud45c\uc785\ub2c8\ub2e4. R-\uc81c\uacf1 \uac12\uc740 \ub3c5\ub9bd \ubcc0\uc218\uac00 \uc885\uc18d \ubcc0\uc218\ub97c \uc5bc\ub9c8\ub098 \uc798 \uc124\uba85\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\uc11c\ub294 R-\uc81c\uacf1 \uac12\uc758 \ubc94\uc704\uc5d0 \ub530\ub77c \uc601\ud5a5\ub825\uc758 \uc815\ub3c4\ub97c '\ub9e4\uc6b0 \uc57d\ud568', '\uc57d\ud568', '\uc911\uac04', '\uac15\ud568', '\ub9e4\uc6b0 \uac15\ud568' \ub4f1\uc758 \uc218\uc900\uc73c\ub85c \ubd84\ub958\ud558\uc5ec \uc124\uba85\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  R-\uc81c\uacf1 \uac12\uc774 0\uc5d0 \uac00\uae4c\uc6b8\uc218\ub85d \ub3c5\ub9bd \ubcc0\uc218\uc758 \uc124\uba85\ub825\uc774 \ub0ae\uace0, 1\uc5d0 \uac00\uae4c\uc6b8\uc218\ub85d \ub3c5\ub9bd \ubcc0\uc218\uc758 \uc124\uba85\ub825\uc774 \ub192\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4.1 \ud1b5\uacc4\uc801 \ubd84\uc11d"}, {"content": "|                       | Model Configuration | Avg. | 1st turn | 2nd turn | # Forward Passes |\n| :-------------------- | :-------------------- | :---- | :-------- | :-------- | :----------------- |\n| Individual            | WizardLM-2-8x22B       | 8.99  | 9.05      | 8.93      | 1                  |\n|                       | Qwen1.5-110B-Chat     | 8.61  | 8.77      | 8.45      | 1                  |\n|                       | LLaMA-3-70B-Instruct   | 8.84  | 9.14      | 8.54      | 1                  |\n|                       | Qwen1.5-72B-Chat      | 8.62  | 8.66      | 8.58      | 1                  |\n|                       | Mixtral-8x22B-Instruct-v0.1 | 8.49  | 8.89      | 8.09      | 1                  |\n|                       | dbrx-instruct          | 7.82  | 8.21      | 7.43      | 1                  |\n| Mixed-MoA            | 2-Layer MoA            | 9.06  | 9.23      | 8.89      | 7                  |\n|                       | 2-Layer MoA w/ GPT-4o  | 9.39  | 9.40      | 9.37      | 7                  |\n|                       | 3-Layer MoA            | 9.25  | 9.44      | 9.07      | 13                 |\n|                       | 3-Layer MoA w/ GPT-4o  | 9.40  | 9.49      | 9.31      | 13                 |\n| Self-MoA + WizardLM-2-8x22B | 2-Layer Self-MoA      | 9.13  | 9.36      | 8.89      | 7                  |\n|                       | 2-Layer Self-MoA w/ GPT-4o | **9.52** | 9.56      | 9.47      | 7                  |", "caption": "Table 10: Comparison of Self-MoA and Mixed-MoA on MT-Bench. We use Qwen1.5-110B-Chat and GPT-4o as the aggregator.", "description": "\ud45c 10\uc740 MT-Bench \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Self-MoA\uc640 Mixed-MoA\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Qwen1.5-110B-Chat\uacfc GPT-4o\ub97c \uc9d1\uacc4 \ubaa8\ub378(aggregator)\ub85c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378 \uad6c\uc131(Individual, Mixed-MoA, Self-MoA)\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218, 1\ucc28 \uc2dc\ub3c4 \uc810\uc218, 2\ucc28 \uc2dc\ub3c4 \uc810\uc218, \uadf8\ub9ac\uace0 \uac01 \ubaa8\ub378\uc774 \uc751\ub2f5\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud574 \ud544\uc694\ud55c \uc804\ub2ec \ub2e8\uacc4(forward passes) \uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  Self-MoA\uac00 Mixed-MoA\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 GPT-4o\ub97c \uc9d1\uacc4\uae30\ub85c \uc0ac\uc6a9\ud558\ub294 Self-MoA\ub294 3-Layer MoA\ubcf4\ub2e4 \uc801\uc740 \uc804\ub2ec \ub2e8\uacc4\ub85c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "3.1 AlpacaEval 2.0\ub97c \uc0ac\uc6a9\ud55c \uc77c\ubc18 \ubaa9\uc801 \ubaa8\ub378 \uc2e4\ud5d8"}, {"content": "|       | Aggregator | Proposer | MMLU | CRUX | MATH | Average | WeightedAvg |\n| :---- | :----------: | :-------: | :----: | :----: | :----: | :------: | :---------: |\n| Individual | - | `i` | 66.16 | 36.25 | 53.81 | 52.07 | 54.46 |\n| Individual | - | `d` | 60.91 | 49.51 | 53.82 | 54.74 | 55.65 |\n| Individual | - | `m` | 54.36 | 27.88 | 69.57 | 50.60 | 52.80 |\n| Mixed-MoA | `i` | `iimmdd` | 67.89 | 42.88 | 64.38 | 58.38 | 60.40 |\n| Mixed-MoA | `i` | `imdddd` | 67.42 | 44.50 | 63.90 | 58.61 | 60.46 |\n| Mixed-MoA | `i` | `iiiimd` | 68.90 | 41.25 | 63.00 | 57.72 | 59.94 |\n| Mixed-MoA | `i` | `immmmd` | 66.63 | 42.75 | 66.02 | 58.47 | 60.40 |\n| Mixed-MoA | `i` | `iimmmm` | 66.23 | 39.25 | 66.10 | 57.19 | 59.38 |\n| Mixed-MoA | `i` | `iiimmm` | 67.49 | 38.25 | 64.16 | 56.63 | 59.00 |\n| Mixed-MoA | `i` | `iiiimm` | 68.00 | 37.00 | 62.92 | 55.97 | 58.47 |\n| Mixed-MoA | `i` | `iidddd` | 68.21 | 45.50 | 62.56 | 58.76 | 60.58 |\n| Mixed-MoA | `i` | `iiiddd` | 68.21 | 42.88 | 62.38 | 57.82 | 59.86 |\n| Mixed-MoA | `i` | `iiiidd` | 68.47 | 40.75 | 61.24 | 56.82 | 59.05 |\n| Mixed-MoA | `i` | `mmdddd` | 66.34 | 46.75 | 66.48 | 59.86 | 61.45 |\n| Mixed-MoA | `i` | `mmmddd` | 65.80 | 47.00 | 67.32 | 60.04 | 61.57 |\n| Mixed-MoA | `i` | `mmmmdd` | 65.44 | 42.50 | 67.62 | 58.52 | 60.39 |\n| Self-MoA | `i` | `dddddd` | 65.23 | 50.75 | 63.08 | 59.69 | 60.86 |\n| Self-MoA | `i` | 6\u00d7TaskBest | 69.01 | 50.75 | 68.42 | 62.73 | 64.21 |\n| Self-MoA | `i` | TaskBest | 69.01 | 52.62 | 69.80 | 63.81 | 65.14 |", "caption": "Table 11: This table compares Self-MoA and Mixed-MoA using a weighted composition of three sub-tasks. The weights are assigned to each sub-task to prevent a high-variance task, such as CRUX, from disproportionately influencing the overall performance metrics. This approach ensures a more balanced evaluation, allowing for a fairer comparison between the two models.", "description": "\ud45c 11\uc740 \uc138 \uac00\uc9c0 \ud558\uc704 \uc791\uc5c5\uc758 \uac00\uc911\uce58 \ud569\uc131\uc744 \uc0ac\uc6a9\ud558\uc5ec Self-MoA\uc640 Mixed-MoA\ub97c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. CRUX\uc640 \uac19\uc774 \ubd84\uc0b0\uc774 \ud070 \uc791\uc5c5\uc774 \uc804\ubc18\uc801\uc778 \uc131\ub2a5 \uc9c0\ud45c\uc5d0 \ubd88\uade0\ud615\uc801\uc778 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uac83\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \uac01 \ud558\uc704 \uc791\uc5c5\uc5d0 \uac00\uc911\uce58\uac00 \ud560\ub2f9\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc811\uadfc \ubc29\uc2dd\uc744 \ud1b5\ud574 \ubcf4\ub2e4 \uade0\ud615 \uc7a1\ud78c \ud3c9\uac00\uac00 \ubcf4\uc7a5\ub418\uc5b4 \ub450 \ubaa8\ub378 \uac04\uc758 \uacf5\uc815\ud55c \ube44\uad50\uac00 \uac00\ub2a5\ud574\uc9d1\ub2c8\ub2e4.", "section": "4.2 When Mixed-MoA Outperforms Self-MoA?"}, {"content": "| Model Configuration | LC Win Rate | # Forward Passes |\n|---|---|---|\n| Mixed-MoA | 59.1 | 7 |\n| Self-MoA | 65.7 | 7 |\n| Mixed-USC | 53.8 | 7 |\n| Self-USC + WizardLM-2-8x22B | 60.2 | 7 |", "caption": "Table 12: Comparison of Self-MoA, Mixed-MoA, and Universal Self-Consistency (USC) on AlpacaEval 2.0 leaderboard. We use Qwen1.5-110B-Chat as the aggregator.", "description": "\ud45c 12\ub294 AlpacaEval 2.0 \ub9ac\ub354\ubcf4\ub4dc\uc5d0\uc11c Self-MoA, Mixed-MoA \ubc0f Universal Self-Consistency(USC)\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  Qwen1.5-110B-Chat \ubaa8\ub378\uc744 \uc9d1\uacc4\uc790(Aggregator)\ub85c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378 \uad6c\uc131\uc5d0 \ub300\ud55c LC \uc2b9\ub960(LC Win Rate)\uacfc \uc21c\ubc29\ud5a5 \ud328\uc2a4 \uc218(Forward Passes)\uac00 \ub098\ud0c0\ub098 \uc788\uc2b5\ub2c8\ub2e4. LC \uc2b9\ub960\uc740 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc774\uba70, \uc21c\ubc29\ud5a5 \ud328\uc2a4 \uc218\ub294 \ubaa8\ub378\uc758 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4.  \uc774 \ud45c\ub294 Self-MoA\uac00 \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc5d0 \ube44\ud574 AlpacaEval 2.0\uc5d0\uc11c \ub354 \ub192\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 Is Ensembling Different LLMs Beneficial?"}]