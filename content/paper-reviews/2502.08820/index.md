---
title: "Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model"
summary: "ë‹¨ì¼ ëª¨ë¸ë¡œ ë‹¤íšŒì°¨ ëŒ€í™”ì™€ ë„êµ¬ ì‚¬ìš© ëª¨ë‘ë¥¼ ë§ˆìŠ¤í„°í•˜ëŠ” CoALM: í†µí•©ì  ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ì–¸ì–´ ëª¨ë¸"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Dialogue Systems", "ğŸ¢ University of Illinois Urbana-Champaign",]
showSummary: true
date: 2025-02-12
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.08820 {{< /keyword >}}
{{< keyword icon="writer" >}} Emre Can Acikgoz et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-18 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.08820" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.08820" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/can-a-single-model-master-both-multi-turn" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

í˜„ì¡´í•˜ëŠ” ëŒ€í™”í˜• ì‹œìŠ¤í…œì€ **ë‹¤íšŒì°¨ ëŒ€í™” ê´€ë¦¬**ì™€ **ë„êµ¬(API) í™œìš©** ëŠ¥ë ¥ ì¤‘ í•˜ë‚˜ì—ë§Œ íŠ¹í™”ë˜ì–´, ë‘ ê°€ì§€ ëŠ¥ë ¥ ëª¨ë‘ë¥¼ ê³ ë£¨ ê°–ì¶˜ ì‹œìŠ¤í…œ ê°œë°œì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë‹¤íšŒì°¨ ëŒ€í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ë©´ì„œ ë™ì‹œì— ë‹¤ì–‘í•œ APIë¥¼ ììœ ë¡­ê²Œ í™œìš©í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ë‹¤íšŒì°¨ ëŒ€í™”ì™€ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì„ í†µí•©í•œ ìƒˆë¡œìš´ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ì–¸ì–´ ëª¨ë¸ì¸ CoALM**ì„ ì œì‹œí•©ë‹ˆë‹¤.  CoALMì€ **ìƒˆë¡­ê²Œ ê°œë°œëœ CoALM-IT ë°ì´í„°ì…‹**ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ì—ì„œ **ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ë›°ì–´ë„˜ëŠ” ê²°ê³¼**ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.  CoALMì˜ ê°œë°œ ë° ê³µê°œë¥¼ í†µí•´, **ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ í–¥ìƒ ë° ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ ë°œì „**ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} ë‹¨ì¼ ëª¨ë¸ë¡œ ë‹¤íšŒì°¨ ëŒ€í™”ì™€ ë„êµ¬ ì‚¬ìš©ì„ í†µí•©ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì¸ CoALM ì œì‹œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ë‹¤íšŒì°¨ ëŒ€í™”ì™€ API ì‚¬ìš©ì„ ê²°í•©í•œ ìƒˆë¡œìš´ ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ ë°ì´í„°ì…‹ì¸ CoALM-IT ê°œë°œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} CoALMì€ ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì„ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ëŒ€í™”í˜• ì—ì´ì „íŠ¸** ë¶„ì•¼ì˜ í•µì‹¬ì ì¸ ë¬¸ì œì ì¸ **ë‹¤íšŒì°¨ ëŒ€í™” ê´€ë¦¬ ë° ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥**ì„ ë™ì‹œì— í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ëª¨ë¸ì„ ì œì‹œí•˜ì—¬, **ê°œë°©í˜• ëŒ€í™” ì‹œìŠ¤í…œ** ì—°êµ¬ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•©ë‹ˆë‹¤.  ë˜í•œ, ì œì‹œëœ ëª¨ë¸ì€ **ì˜¤í”ˆì†ŒìŠ¤**ë¡œ ê³µê°œë˜ì–´, ë‹¤ë¥¸ ì—°êµ¬ìë“¤ì˜ **í›„ì† ì—°êµ¬ ë° ë°œì „**ì„ ìœ„í•œ ê¸°ë°˜ì„ ë§ˆë ¨í•©ë‹ˆë‹¤. ì´ëŠ” **ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì˜ ë°œì „**ì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•˜ë©°, íŠ¹íˆ **ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ**ì˜ ì‹¤ìš©ì„±ì„ ë†’ì´ëŠ” ë° í° ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤. 

------
#### Visual Insights



![](https://arxiv.org/html/2502.08820/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ TOD ì‹œìŠ¤í…œê³¼ ì–¸ì–´ ì—ì´ì „íŠ¸(LA)ì˜ ê¸°ëŠ¥ì„ í†µí•©ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. TOD ì‹œìŠ¤í…œì€ í„´ì´ ë§ì€ ëŒ€í™”ì™€ ì‘ì—… ì™„ë£Œì— ë›°ì–´ë‚˜ì§€ë§Œ ê³ ê¸‰ API ê¸°ëŠ¥ì´ ë¶€ì¡±í•œ ë°˜ë©´, LAëŠ” APIë¥¼ ì˜ ì²˜ë¦¬í•˜ì§€ë§Œ ì¼ê´€ì„± ìˆëŠ” ë‹¤í„´ ëŒ€í™”ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, TOD ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ í„´ì— ê±¸ì¹œ ëŒ€í™”ë¥¼ ì˜ ì²˜ë¦¬í•˜ê³  ì‘ì—…ì„ ì™„ë£Œí•˜ì§€ë§Œ, ìƒˆë¡œìš´ APIì— ëŒ€í•œ ê¸°ëŠ¥ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°˜ë©´ LAëŠ” API í™œìš© ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ì§€ë§Œ,  ì¼ê´€ì„± ìˆëŠ” ë‹¤í„´ ëŒ€í™”ë¥¼ ìƒì„±í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Unifying Capabilities of TOD Systems and LAs. TOD systems excel in multi-turn conversations and task completion but lack advanced API capabilities, while LA handle APIs well but struggle with coherent multi-turn dialogue.
> </details>





{{< table-caption >}}
| Data Domain | Data Type | Data Name | Data Format | # of Data Samples | # of Total Tokens | Avg. Tokens Per Sample |
|---|---|---|---|---|---|---|
| **TOD** | Single-Turn | SNIPS | State Tracking | 13,028 | 12,278,780 | 942.49 |
| **LA** | Single-Turn | Hammer | API Call | 13,819 | 10,199,147 | 738.05 |
|  | Multi-Turn | ToolAce | API Call | 202,500 | 129,001,612 | 637.04 |
| **CRA** | Multi-Turn | SGD | ReAct API Call | 82,236 | 59,704,782 | 726.02 |
| **Total** |  |  |  | 311,583 | 211,184,321 | 760.90 |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” CoALM-IT ë°ì´í„°ì…‹ì˜ í†µê³„ì  ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  CoALM-IT ë°ì´í„°ì…‹ì€ ëŒ€í™” ìƒíƒœ ì¶”ì , ë³µì¡í•œ í•¨ìˆ˜ í˜¸ì¶œ, ReAct ìŠ¤íƒ€ì¼ì˜ ë©€í‹°í„´ ëŒ€í™”ë¥¼ í¬í•¨í•˜ëŠ” ì„¸ ê°€ì§€ ì°¨ì›ì„ ë‹¤ë£¹ë‹ˆë‹¤.  ì´ í‘œëŠ” ê° ë°ì´í„° ìœ í˜•(TOD, LA, CRA)ì˜ ë°ì´í„° ìƒ˜í”Œ ìˆ˜, ì´ í† í° ìˆ˜, ìƒ˜í”Œë‹¹ í‰ê·  í† í° ìˆ˜ë¥¼ ë³´ì—¬ì£¼ì–´ í•™ìŠµ ë°ì´í„°ì˜ êµ¬ì„±ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.  'Generated CRA'ëŠ” ëŒ€í™”í˜• ReAct API ë°ì´í„°ì…‹ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: CoALM-IT Dataset Details. Statistical details of our proposed CoALM-IT dataset showcasing the training mixtures. Generated CRA denotes the Conversational ReAct API dataset.
> </details>





### In-depth insights


#### Unified Agent Vision
í†µí•© ì—ì´ì „íŠ¸ ë¹„ì „ì€ **ë‹¨ì¼ ëª¨ë¸ì´ ë‹¤ì¤‘ í„´ ëŒ€í™”ì™€ ë„êµ¬ ì‚¬ìš©ì„ ëª¨ë‘ ë§ˆìŠ¤í„°í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±**ì„ íƒêµ¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ì˜ íŠ¹ì • ì‘ì—…ì— ì´ˆì ì„ ë§ì¶˜ ëŒ€í™” ì‹œìŠ¤í…œê³¼ ë„êµ¬ ì‚¬ìš©ì— íŠ¹í™”ëœ ì–¸ì–´ ì—ì´ì „íŠ¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ì‹œë„ì…ë‹ˆë‹¤.  **ê°•ë ¥í•œ ë‹¤ì¤‘ í„´ ê´€ë¦¬ì™€ ê³ ê¸‰ ê¸°ëŠ¥ í˜¸ì¶œì€ íš¨ê³¼ì ì¸ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì— í•„ìˆ˜ì **ì´ë©°, ì´ ë¹„ì „ì€ ì´ ë‘ ê°€ì§€ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ìœ ì§€í•˜ê³  ë‹¤ì–‘í•œ APIë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” **í†µí•©ëœ ëŒ€í™”í˜• ì—ì´ì „íŠ¸**ë¥¼ êµ¬ì¶•í•˜ëŠ” ë° ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” **ë‹¤ì¤‘ ì‘ì—… ë°ì´í„°ì…‹ì„ ì´ìš©í•œ í›ˆë ¨**ì´ ì¤‘ìš”í•˜ë©°,  **ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì ì‘ë ¥**ê³¼ **ë‹¤ì–‘í•œ API ì ‘ê·¼**ì´ ê°€ëŠ¥í•´ì•¼ í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  **ê°œë°©í˜• ì ‘ê·¼ ë°©ì‹**ì„ ì±„íƒí•˜ì—¬  ë” ë§ì€ ì—°êµ¬ê°€ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì´ëŠ” **ë‹¨ì¼ ëª¨ë¸ ì ‘ê·¼ ë°©ì‹ì˜ ì‹¤í˜„ ê°€ëŠ¥ì„±**ì„ ë³´ì—¬ì£¼ê³  ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### CoALM-IT Dataset
CoALM-IT ë°ì´í„°ì…‹ì€ **ëŒ€í™” ìƒíƒœ ì¶”ì , ë³µì¡í•œ í•¨ìˆ˜ í˜¸ì¶œ, ReAct ìŠ¤íƒ€ì¼ì˜ ë‹¤íšŒì°¨ ëŒ€í™”** ì„¸ ê°€ì§€ ì°¨ì›ì„ ì•„ìš°ë¥´ëŠ” í†µí•©ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•©ë‹ˆë‹¤.  ê¸°ì¡´ TOD ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì **ReAct ì¶”ë¡ ê³¼ API ì‚¬ìš©ì„ ê²°í•©**í•œ ìƒˆë¡œìš´ ë°ì´í„° ìƒì„± ë°©ì‹ì„ í†µí•´,  **ì‹¤ì œ í™˜ê²½ì— ê°€ê¹Œìš´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. íŠ¹íˆ, **GPT-4ë¥¼ í™œìš©**í•˜ì—¬ ìƒì„±ëœ ëŒ€í™”í˜• ReAct API(CRA) ì¸ìŠ¤í„´ìŠ¤ëŠ” **ë‹¤ì¤‘ ì‚¬ê³  ë‹¨ê³„ë¥¼ í†µí•©**í•˜ì—¬, ëª¨ë¸ì´ API í˜¸ì¶œ ì—¬ë¶€ ë° ì‚¬ìš©ì ì‘ë‹µ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ê³¼ì •ì„ ë°˜ì˜í•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ê¸°ì¡´ì˜ íŠ¹ì • APIì— êµ­í•œëœ TOD ì‹œìŠ¤í…œ ë° ë‹¨ì¼ í„´ í•¨ìˆ˜ í˜¸ì¶œì— ì´ˆì ì„ ë§ì¶˜ LA ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´, **í†µí•©ì ì¸ ëŒ€í™”í˜• ì—ì´ì „íŠ¸** ê°œë°œì„ ìœ„í•œ ì¤‘ìš”í•œ í† ëŒ€ê°€ ë©ë‹ˆë‹¤.  **ê°œë°©í˜• ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒ**ì— ê¸°ì—¬í•  ë¿ ì•„ë‹ˆë¼, í–¥í›„ ì—°êµ¬ì— í™œìš©ë  ìˆ˜ ìˆëŠ” ê·€ì¤‘í•œ ìì›ì´ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Benchmark Results
ë³¸ ë…¼ë¬¸ì˜ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ëŠ” **CoALM ëª¨ë¸ì´ ê¸°ì¡´ì˜ TOD ì‹œìŠ¤í…œ ë° LA ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„**ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, **ë‹¤ì¤‘ í„´ ëŒ€í™” ë° API í˜¸ì¶œ ëŠ¥ë ¥ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥**ì„ ê¸°ë¡í•˜ì—¬, **ë‹¨ì¼ ëª¨ë¸ë¡œ ë‹¤ì¤‘ ì‘ì—…ì„ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ**ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.  **MultiWOZ, API-Bank, BFCL V3 ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ëª¨ë‘ì—ì„œ CoALM ëª¨ë¸ì€ ìµœì²¨ë‹¨ ì„±ëŠ¥**ì„ ë‹¬ì„±í•˜ì˜€ê³ , íŠ¹íˆ ëŒ€ê·œëª¨ ëª¨ë¸ì¼ìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒì´ ë‘ë“œëŸ¬ì¡ŒìŠµë‹ˆë‹¤. ì´ëŠ” **CoALMì´ ëŒ€í™” ê´€ë¦¬ì™€ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ì„ í†µí•©**í•˜ì—¬ ìƒí˜¸ë³´ì™„ì ìœ¼ë¡œ ì‘ìš©í•¨ìœ¼ë¡œì¨ ê¸°ì¡´ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí–ˆìŒì„ ì‹œì‚¬**í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ì œí•œëœ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì‚¬ìš© ë° íŠ¹ì • ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜ì¡´ì„± ë“±ì˜ í•œê³„ì ë„ ì¡´ì¬í•©ë‹ˆë‹¤.**

#### Open-Source Impact
ë³¸ ë…¼ë¬¸ì—ì„œ **ì˜¤í”ˆì†ŒìŠ¤ì˜ ì˜í–¥**ì— ëŒ€í•œ ë…¼ì˜ëŠ” ì£¼ë¡œ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ ì ‘ê·¼ì„±ê³¼ ì—°êµ¬ í™•ì¥ì„±ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  **ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ê³µê°œ**ë¥¼ í†µí•´ ë” ë§ì€ ì—°êµ¬ìë“¤ì´ ìµœì²¨ë‹¨ ê¸°ìˆ ì— ì ‘ê·¼í•˜ì—¬ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê³ , **ëª¨ë¸ ê°œì„ **ì— ê¸°ì—¬í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìƒìš© ëª¨ë¸ì— ë¹„í•´ **ë¹„ìš© íš¨ìœ¨ì **ì´ë©°, **íˆ¬ëª…ì„±**ì„ í™•ë³´í•˜ê³  **ê³µë™ ì—°êµ¬**ë¥¼ ì´‰ì§„í•˜ëŠ” ê¸ì •ì  ì¸¡ë©´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  í•˜ì§€ë§Œ **ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸**ì˜ ì„±ëŠ¥ì´ ìƒìš© ëª¨ë¸ì— ë¹„í•´ ë‹¤ì†Œ ë–¨ì–´ì§€ëŠ” ì¸¡ë©´ë„ ì¡´ì¬í•˜ë©°, ì´ëŸ¬í•œ ì„±ëŠ¥ ì°¨ì´ëŠ”  **ë°ì´í„°ì…‹ ê·œëª¨ì™€ í’ˆì§ˆ**, **ëª¨ë¸ í•™ìŠµ ë°©ì‹**, **ì»´í“¨íŒ… ìì›** ë“± ì—¬ëŸ¬ ìš”ì†Œì— ê¸°ì¸í•©ë‹ˆë‹¤. ë”°ë¼ì„œ **ì˜¤í”ˆì†ŒìŠ¤ LLM ìƒíƒœê³„**ì˜ ì§€ì†ì ì¸ ì„±ì¥ê³¼ ë°œì „ì„ ìœ„í•´ì„œëŠ” **ë°ì´í„°ì…‹ êµ¬ì¶•**, **ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ **, **í•™ìŠµ íš¨ìœ¨ í–¥ìƒ** ë“± ë‹¤ë°©ë©´ì˜ ë…¸ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤. **ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸**ì˜ ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ì—¬, **ì—°êµ¬ ë° ìƒìš©í™”** ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

#### Future Work
ë³¸ ë…¼ë¬¸ì˜ "ë¯¸ë˜ ì—°êµ¬ ë°©í–¥" ë¶€ë¶„ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ í–¥ìƒ**ì— ì´ˆì ì„ ë§ì¶°ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.  íŠ¹íˆ, **ë³µì¡í•œ ë©€í‹°í„´ ëŒ€í™”ì™€ ë‹¤ì–‘í•œ API í˜¸ì¶œì˜ í†µí•©**ì„ ë”ìš± íš¨ìœ¨ì ì´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬í•˜ëŠ” ë°©ì•ˆì„ ëª¨ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.  ê°•í™” í•™ìŠµ(RL)ì„ í™œìš©í•˜ì—¬ LLMì´ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ë°œì „í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì—°êµ¬ê°€ í•„ìš”í•˜ë©°, **ì œë¡œìƒ· ë˜ëŠ” ê·¹ì†Œìˆ˜ ìƒ· í•™ìŠµ** ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ì—°êµ¬ë„ ì¤‘ìš”í•©ë‹ˆë‹¤.  ë˜í•œ, **ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ í›ˆë ¨ ì „ëµ**ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ CoALM ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë”ìš± ê°•ë ¥í•œ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ë¥¼ ê°œë°œí•˜ëŠ” ë° ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.  ë‚˜ì•„ê°€, ê°œë°œëœ ëª¨ë¸ì˜ **ì‹¤ì œ í™˜ê²½ ì ìš©ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë° í‰ê°€**ë¥¼ í†µí•´ ì‹¤ìš©ì„±ì„ ë†’ì´ê³ , ìœ¤ë¦¬ì  ë¬¸ì œì ì„ í•´ê²°í•˜ëŠ” ë°©ì•ˆì„ ë§ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤.  **ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì˜ ì°¸ì—¬**ë¥¼ í™•ëŒ€í•˜ì—¬ ì—°êµ¬ì˜ ì§€ì†ê°€ëŠ¥ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒ ë˜í•œ ì¤‘ìš”í•œ ë¯¸ë˜ ì—°êµ¬ ê³¼ì œì…ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.08820/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” CoALM íŒŒì´í”„ë¼ì¸ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°ì´í„° ë³€í™˜ ê³¼ì •ê³¼ ë¯¸ì„¸ ì¡°ì • í”„ë ˆì„ì›Œí¬ë¥¼ ë³´ì—¬ì£¼ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ìœ„ìª½ ì„¸ ì¤„ì€ ë°ì´í„° ë³€í™˜ ê³¼ì •ì„ ë‚˜íƒ€ë‚´ë©°, ì˜¤ë¥¸ìª½ì—ëŠ” í•´ë‹¹ ì˜ˆì‹œê°€ ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤. ê° í›ˆë ¨ ìƒ˜í”Œì—ì„œ ë…¹ìƒ‰ í…ìŠ¤íŠ¸ëŠ” ì§€ì‹œì–´ ìƒ˜í”Œì˜ ì…ë ¥ êµ¬ì„± ìš”ì†Œë¥¼ ê°•ì¡°í•˜ê³ , ë³´ë¼ìƒ‰ í…ìŠ¤íŠ¸ëŠ” ë¯¸ì„¸ ì¡°ì • ì¤‘ì— ìµœì í™”ëœ ëŒ€ìƒ ì¶œë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ê·¸ë¦¼ 4~7ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Overview of the CoALM Pipeline. This figure illustrates our dataset generation and fine-tuning framework. The top three rows depict the data transformation processes, along with a corresponding sample shown on the right. In each training sample, green text highlights the input components of the instruction sample, while purple text indicates the target outputs optimized during fine-tuning. For detailed examples, refer to Figures 4 - 7.
> </details>



![](https://arxiv.org/html/2502.08820/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ CoALM ëª¨ë¸ê³¼ ë‹¤ë¥¸ ê¸°ì¤€ ëª¨ë¸ë“¤ì˜ í•¨ìˆ˜ í˜¸ì¶œ ì„±ëŠ¥ì„ API-Bank L1(ìœ„ìª½) ë° BFCL V3 ë³‘ë ¬ í•¨ìˆ˜ í˜¸ì¶œ(ì•„ë˜ìª½) ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  API-Bank L1ì€ ë‹¨ì¼ í•¨ìˆ˜ í˜¸ì¶œ, BFCL V3ëŠ” ë³‘ë ¬ í•¨ìˆ˜ í˜¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ê° ëª¨ë¸ì˜ ì¶œë ¥ ê²°ê³¼ì™€ ì •ë‹µì„ ì œì‹œí•˜ì—¬, CoALM ëª¨ë¸ì´ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ë¹„í•´ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.  íŠ¹íˆ, ë‹¤ë¥¸ ëª¨ë¸ë“¤ì´ êµ¬ë¬¸ ì˜¤ë¥˜, í•¨ìˆ˜ ëˆ„ë½, ì˜ëª»ëœ ê°’ ë“±ì˜ ë¬¸ì œë¥¼ ë³´ì´ëŠ” ë°˜ë©´, CoALMì€ ì •í™•í•œ í•¨ìˆ˜ í˜¸ì¶œê³¼ ë§¤ê°œë³€ìˆ˜ë¥¼ ì œê³µí•˜ì—¬ ì •ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Error Analysis of Function-Calling Results. Illustrated performance comparison on function calling benchmarks API-Bank L1 (top) and BFCL V3 parallel function call (bottom). Results demonstrate CoALMâ€™s consistent performance compared to other baselines.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Method | Success | JGA |
|---|---|---|
| CoALM 8B (ours) | 51.6 | 30.4 |
| CoALM 70B (ours) | 69.4 | 43.8 |
| CoALM 405B (ours)<sup>*</sup> | 66.7 | 38.8 |
| Hammer 2.0 7B | 23.5 | 21.7 |
| ToolAce | 18.0 | 34.4 |
| Granite-20B-Code | 10.7 | 21.8 |
| CodeActAgent | 9.5 | 20.2 |
| Llama 3.1 8B Instruct | 19.9 | 26.3 |
| Llama 3.3 70B Instruct | 67.6 | 40.8 |
| Mistral-7B-Instruct-v0.3 | 31.2 | 27.0 |
| FNCTOD [Li et al. (2024)](<https://arxiv.org/pdf/2502.08820.pdf>) | 44.4 | 37.9 |
| NC-Latent-TOD [King and Flanigan (2024)](<https://arxiv.org/pdf/2502.08820.pdf>) | 68.3 | 39.7 |
| GPT 3.5 Turbo [HudeÄek and Dusek (2023)](<https://arxiv.org/pdf/2502.08820.pdf>) | - | 13.5 |
| GPT4o-mini | 69.9 | 38.4 |
| GPT4o | 75.5 | 36.9 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” MultiWOZ 2.4 ëŒ€í™” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. MultiWOZ 2.4ëŠ” í˜¸í…” ì˜ˆì•½, ì‹ë‹¹ ì˜ˆì•½, êµí†µí¸ ì˜ˆì•½ ë“± ì—¬ëŸ¬ ë„ë©”ì¸ì— ê±¸ì¹œ ë³µì¡í•œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ê° ëª¨ë¸ì˜ ì„±ê³µë¥ (Success)ê³¼ ê³µë™ ëª©í‘œ ë‹¬ì„±ë¥ (JGA)ì´ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, ê°€ì¥ ë†’ì€ ì ìˆ˜ëŠ” êµµì€ ê¸€ì”¨ì²´ë¡œ ê°•ì¡° í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  CoALM 405B ëª¨ë¸ì˜ ê²½ìš° ì•„ì§ í›ˆë ¨ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ì¤‘ê°„ ì§€ì (checkpoint)ì˜ ê²°ê³¼ì´ë¯€ë¡œ, (*) í‘œì‹œë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: MultiWOZ 2.4 Benchmark Results. Performance comparison across models on MultiWOZ 2.4 dialogue benchmark. Best scores are highlighted with bold. The asterisk (*) on CoALM 405B denotes the checkpoint from one completed epoch, as the model is still under training.
> </details>

{{< table-caption >}}
| Model | Rouge-L* (L-1) | Rouge-L* (L-2) | Rouge-1 (L-1) | Rouge-1 (L-2) | Rouge-2 (L-1) | Rouge-2 (L-2) | BLEU-4 (L-1) | BLEU-4 (L-2) |
|---|---|---|---|---|---|---|---|---|
| CoALM 8B (ours) | 92.8 | 81.9 | 94.1 | 81.2 | 91.9 | 76.4 | 89.4 | 69.7 |
| CoALM 70B (ours) | 92.7 | 83.2 | 94.5 | 82.7 | 92.5 | 78.9 | 89.5 | 72.4 |
| CoALM 405B (ours)* | 93.4 | 77.8 | 94.5 | 77.1 | 92.4 | 71.9 | 90.3 | 64.4 |
| Llama 3.1 8B Instruct | 72.7 | 75.2 | 84.0 | 81.4 | 79.8 | 76.3 | 62.3 | 65.1 |
| Qwen2.5 7B Instruct | 84.3 | 73.9 | 88.9 | 78.5 | 84.6 | 71.2 | 76.4 | 64.2 |
| Hammer 2.0 7B | 90.1 | 74.0 | 92.3 | 74.1 | 89.9 | 68.5 | 85.4 | 58.4 |
| ToolAce | 81.5 | 63.6 | 88.8 | 71.3 | 85.0 | 63.0 | 76.1 | 67.0 |
| Granite-20B-Code | 60.3 | 45.7 | 64.7 | 48.9 | 59.5 | 43.4 | 43.8 | 29.3 |
| Fnc-TOD 13B | 3.9 | 3.3 | 22.1 | 23.4 | 8.0 | 9.2 | 1.5 | 1.1 |
| LDST | 8.3 | 7.1 | 12.8 | 11.6 | 2.7 | 2.4 | 6.2 | 5.7 |
| tod-zero-bqag3oyb | 3.7 | 4.2 | 11.5 | 12.4 | 1.1 | 2.2 | 1.0 | 0.9 |
| nc-latent-tod-step-2 | 3.2 | 3.2 | 14.3 | 13.3 | 3.2 | 1.5 | 0.8 | 0.8 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” API-Bank ê¸°ëŠ¥ í˜¸ì¶œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  MultiWOZì™€ ë‹¬ë¦¬ API í˜¸ì¶œì— ì´ˆì ì„ ë§ì¶˜ API-Bank ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ê¸°ëŠ¥ í˜¸ì¶œ ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.  Rouge-L, Rouge-1, Rouge-2, BLEU-4 ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ê°ì ìœ¼ë¡œ í‰ê°€í•˜ë©°,  ìµœê³  ì ìˆ˜ëŠ” êµµì€ ê¸€ì”¨ì²´ë¡œ, ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ì ìˆ˜ëŠ” ë°‘ì¤„ ì¹œ ê¸€ì”¨ì²´ë¡œ í‘œì‹œë©ë‹ˆë‹¤.  CoALM 405B ëª¨ë¸ì€ ì•„ì§ í›ˆë ¨ ì¤‘ì´ë¯€ë¡œ í•œ ì—í¬í¬ ì™„ë£Œ ì‹œì ì˜ ê²°ê³¼ë§Œ ì œì‹œë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: API-Bank Benchmark Results. Performance comparison across models on API-Bank function calling benchmark. Best scores are highlighted with bold and the second-best results are underlined. The asterisk (*) on CoALM 405B denotes one completed epoch, as the model is still in the training process.
> </details>

{{< table-caption >}}
| Model | Overall Acc | Non-Live AST Acc | Non-Live Exec Acc | Live Acc | Multi Turn Acc | Relevance Detection | Irrelevance Detection |
|---|---|---|---|---|---|---|---| 
| Mistral-7B-Instruct-v0.3 | 38.35% | 56.33% | 63.77% | 57.31% | 0.25% | 77.78% | 41.84% |
| Llama-3.1-8B-Instruct | 49.84% | 84.25% | 79.75% | 60.33% | 10.25% | 75.61% | 47.92% |
| Llama-3.3-70B-Instruct | 51.36% | 84.85% | 90.05% | 62.51% | 7.25% | 95.12% | 48.33% |
| ToolAce | 52.55% | 82.19% | 86.98% | 71.08% | 0.88% | 70.73% | 87.29% |
| Hammer2.0-7b | 52.13% | 86.94% | 83.66% | 71.17% | 0.38% | 95.12% | 73.20% |
| Llama-3.1-405B-Instruct | 56.38% | 89.71% | 84.70% | 70.77% | 11.75% | 88.89% | 70.86% |
| GPT-4o-mini (2024-07-18) | 59.40% | 86.52% | 85.05% | 73.26% | 19.00% | 78.05% | 76.97% |
| GPT-4o (2024-08-06) | 59.83% | 70.08% | 60.79% | 76.41% | 34.62% | 51.22% | 87.34% |
| CoALM 8B (ours) | 54.11% | 85.17% | 78.61% | 72.59% | 7.00% | 77.78% | 83.00% |
| CoALM 70B (ours) | 60.49% | 82.94% | 81.36% | 72.19% | 26.25% | 72.22% | 85.36% |
| CoALM 405B (ours)<sup>âˆ—</sup> | 63.34% | 90.46% | 84.75% | 74.59% | 28.25% | 100.00% | 72.26% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” BFCL V3 ê¸°ëŠ¥ í˜¸ì¶œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  CoALM ëª¨ë¸ì´ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ë¹„í•´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤.  íŠ¹íˆ, CoALM 405BëŠ” ì•„ì§ í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì€ ìƒíƒœì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ìƒìœ„ê¶Œ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.  í‘œì—ëŠ” ì •í™•ë„, AST ì •í™•ë„, ì‹¤í–‰ ê°€ëŠ¥í•œ í•¨ìˆ˜ ì •í™•ë„, ë‹¤ì¤‘ í„´ ì •í™•ë„, ê´€ë ¨ì„± ê°ì§€, ë¬´ê´€ì„± ê°ì§€ ë“± ì—¬ëŸ¬ ì§€í‘œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¢‹ì€ ê²°ê³¼ëŠ” êµµê²Œ í‘œì‹œí•˜ê³ , ë‘ ë²ˆì§¸ë¡œ ì¢‹ì€ ê²°ê³¼ëŠ” ë°‘ì¤„ì´ ê·¸ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: BFCL V3 Benchmark Results. Performance comparison on the BFCL V3 function-calling benchmark. The best results are highlighted in bold, while the second-best results are underlined. The asterisk (*) on CoALM 405B denotes one completed epoch, as the model continues training.
> </details>

{{< table-caption >}}
| Model | TOD Task |  | Function Calling Tasks |  |  |  | 
|---|---|---|---|---|---|---| 
|  | **MultiWOZ 2.4** |  | **API-Bank** |  | **BFCL-V3** |  | 
|  | **Success** | **DST** | **Rouge-L1** | **Rouge-L2** | **Overall Success** |  | 
| Llama 3.1 8B Instruct | 19.9 | 26.3 | 72.7 | 75.2 | 49.8 |  | 
|  + CoALM-IT w/o LA | 46.0 (26.1 â†‘, 5.6 â†“) | 28.5 (2.2 â†‘, 1.9 â†“) | 45.5 (27.2 â†“, 47.3 â†“) | 48.8 (26.4 â†“, 33.1 â†“) | 35.4 (14.4 â†“, 18.3 â†“) |  | 
|  + CoALM-IT w/o TOD | 42.0 (22.1 â†‘, 9.6 â†“) | 19.4 (6.9 â†“, 11.0 â†“) | 92.7 (20.0 â†‘, 0.1 â†“) | 78.9 (13.7 â†‘, 3.0 â†“) | 54.1 (4.3 â†‘, 0.4 â†‘) |  | 
|  + CoALM-IT w/o CRA | 50.0 (30.1 â†‘, 1.6 â†“) | **34.5** (8.2 â†‘, 4.1 â†‘) | 91.3 (18.6 â†‘, 1.5 â†“) | 78.8 (3.6 â†‘, 3.1 â†“) | **56.6** (10.6 â†‘, 2.9 â†‘) |  | 
| CoALM 8B | **51.6** | 30.4 | **92.8** | **81.9** | 53.7 |  | {{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” CoALM ë¯¸ì„¸ ì¡°ì • ì¤‘ íŠ¹ì • ë„ë©”ì¸ ë°ì´í„°ì…‹ì„ ì œì™¸í–ˆì„ ë•Œì˜ ì˜í–¥ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'w/o'ëŠ” ë¯¸ì„¸ ì¡°ì • ì¤‘ í•´ë‹¹ ë°ì´í„°ì…‹ì„ ì œì™¸í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê° í–‰ì€ ê¸°ì¤€ ëª¨ë¸(Llama) ë° ìµœì¢… ëª¨ë¸(CoALM)ê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê´„í˜¸ ì•ˆì˜ ê°’ì€ Llama ëª¨ë¸ê³¼ CoALM ëª¨ë¸ì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ê°ê° ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì„±ëŠ¥ í–¥ìƒì€ ë…¹ìƒ‰ìœ¼ë¡œ, ì„±ëŠ¥ ì €í•˜ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.  ì¦‰, ì´ í‘œëŠ” CoALM ëª¨ë¸ì˜ ì„±ëŠ¥ì— ê° ë°ì´í„°ì…‹(TOD, LA, CRA)ì´ ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤. 
> <details>
> <summary>read the caption</summary>
> Table 5: Dataset Domain Effects. Experimental results highlighting the impact of excluding specific domain datasets during CoALM fine-tuning. w/o indicates excluding the corresponding dataset during fine-tuning. Each row displays performance changes in parentheses with respect to base model (Llama) and final model (CoALM), i.e. (Î”Î”\Deltaroman_Î” Llama, Î”Î”\Deltaroman_Î” CoALM). Performance gains are highlighted in green, while drops are marked in red.
> </details>

{{< table-caption >}}
| User | Thought1 | API | API Input Arguments | API Result | Thought2 | System |
|---|---|---|---|---|---|---|
| You are an advanced AI assistant specializing in conversational dialogues. |  |  |  |  |  |  |
| You have access to a variety of services and APIs to assist users with their requests and your goal is to provide helpful and informative responses to user queries and commands. |  |  |  |  |  |  |
| You can interact with multiple services and APIs to fulfill user requests. |  |  |  |  |  |  |
| Your responses should be natural, informative, and tailored to the userâ€™s needs. |  |  |  |  |  |  |
| # Task Information: |  |  |  |  |  |  |
| - You are asked to create a dataset in the format: User - Thought1 - API - API Input Arguments - API Result - Thought2 - System, or User - Thought - System. |  |  |  |  |  |  |
| - For the given # User Input, generate a multi-turn dialogue that follows this format, with each turn exhibiting realistic context reasoning, thought processes, and API interaction where applicable. |  |  |  |  |  |  |
| - The dialogues should be converted to follow a specific # Output Format, which includes reasoning on whether an API call is needed or if the system can respond directly. |  |  |  |  |  |  |
| - If the system decides that an API call is necessary, use this format: User - Thought1 - API - API Input Arguments - API Result - Thought2 - System. |  |  |  |  |  |  |
| - Call the right API from # Avaliable Functions and provide the necessary input arguments to fulfill the userâ€™s request. |  |  |  |  |  |  |
| - If you think a function argument is not necessary, you can skip it. Donâ€™t provide unnecessary arguments and None values. |  |  |  |  |  |  |
| - Ensure that the API calls are used logically and that the dialogue remains coherent and natural throughout the exchange. |  |  |  |  |  |  |
| - If the system determines that an API call is not necessary, use this format: User - Thought - System. |  |  |  |  |  |  |
| - Include intermediate thoughts where appropriate to capture the modelâ€™s internal reasoning, and clearly separate the different components of the format. |  |  |  |  |  |  |
| # Available Functions: |  |  |  |  |  |  |
| 1. CheckBalance(account_type) |  |  |  |  |  |  |
| 2. TransferMoney(account_type, amount, recipient_account_name) |  |  |  |  |  |  |
| . |  |  |  |  |  |  |
| . |  |  |  |  |  |  |
| . |  |  |  |  |  |  |
| 52. FindAttractions(location) |  |  |  |  |  |  |
| 53. GetWeather(city) |  |  |  |  |  |  |
| # Output Format: |  |  |  |  |  |  |
| - If an API Call is Needed: |  |  |  |  |  |  |
| â€ƒUser: [User Input] |  |  |  |  |  |  |
| â€ƒThought1: [I need to call an API] |  |  |  |  |  |  |
| â€ƒAPI Name: [API Call Name: CheckBalance(), TransferMoney(),..., FindAttractions(), GetWeather()] |  |  |  |  |  |  |
| â€ƒAPI Input: [The input parameters for the API] |  |  |  |  |  |  |
| â€ƒAPI Result: [API output result] |  |  |  |  |  |  |
| â€ƒThought2: [2nd thought after API Result that ensure if the information is enough before the system response] |  |  |  |  |  |  |
| â€ƒSystem: [Your system response here] |  |  |  |  |  |  |
| - If an API Call is Not Needed: |  |  |  |  |  |  |
| â€ƒUser: [User Input] |  |  |  |  |  |  |
| â€ƒThought: [I donâ€™t need an API and I want to respond to the user] |  |  |  |  |  |  |
| â€ƒSystem: [Your system response here] |  |  |  |  |  |  |
| Below is an example of the format: |  |  |  |  |  |  |
| # Example: |  |  |  |  |  |  |
| User: Add Don and Sherri to my "Meditate to Sounds of Nature" playlist. | Thought1: The user wants to add two artists to a specific playlist. Iâ€™ll need to extract the playlist name and the artistsâ€™ names. | API Name: AddToPlaylist | API Input: 'playlist_name': 'Meditate to Sounds of Nature', 'artists': Don Sherri | API Result: 'status': 'success', 'message': 'Don and Sherri have been added to your playlist.' | Thought2: The API call was successful, and the artists were added to the playlist. I need to inform the user about this. | System: Don and Sherri have been successfully added to your "Meditate to Sounds of Nature" playlist. Enjoy your music! |
| User: Thank you for adding them. I think I can add more songs to the playlist. | Thought: I donâ€™t need an API call for that, I want to respond to the user. |  |  |  |  | System: Would you like to add more songs? |
| User: Yes, please add "Calm River" to the playlist. | Thought1: The user wants to add another song to the playlist. Iâ€™ll note the song title and proceed with the request. | API Name: AddToPlaylist | API Input: 'playlist_name': 'Meditate to Sounds of Nature', 'songs': Calm River | API Result: 'status': 'success', 'message': 'Calm River has been added to your playlist.' | Thought2: The song was successfully added. I should let the user know. | System: "Calm River" has been successfully added to your "Meditate to Sounds of Nature" playlist. Would you like to do anything else? |
| User: No, thatâ€™s all for now. Thank you! | Thought: The user is satisfied and doesnâ€™t need further assistance. I should acknowledge their gratitude. |  |  |  |  | System: Youâ€™re welcome! If you need anything else, feel free to ask. Enjoy your relaxing music! |
| # User Input: |  |  |  |  |  |  |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 4.1ì ˆ 'ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ë°ì´í„°ì…‹ ìƒì„±'ì—ì„œ ì‚¬ìš©ëœ, GPT-4ë¥¼ ì´ìš©í•´ ìƒì„±ëœ SGD(Stochastic Gradient Descent) íŒŒì¸íŠœë‹ ìƒ˜í”Œ ìƒì„±ì„ ìœ„í•œ API ê¸°ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í‘œì—ëŠ” ëª¨ë“  ëŒ€í™”ì—ì„œ ì‚¬ìš©ëœ í•¨ìˆ˜ë§Œ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, í•¨ìˆ˜ì˜ ê°œìˆ˜ê°€ ë§ê¸° ë•Œë¬¸ì— ëª¨ë“  í•¨ìˆ˜ë¥¼ ë‹¤ í¬í•¨í•˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.  í”„ë¡¬í”„íŠ¸ëŠ” ì‚¬ìš©ìì˜ ì§ˆì˜ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ APIì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë°©ë²•ì„ ëª¨ë¸ì—ê²Œ ê°€ë¥´ì¹˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  ì—¬ê¸°ì—ëŠ” ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ì ì ˆí•œ APIë¥¼ ì„ íƒí•˜ê³ , í•„ìš”í•œ ì¸ìˆ˜ë¥¼ ì œê³µí•˜ëŠ” ë°©ë²•, ê·¸ë¦¬ê³  ì¼ê´€ì„± ìˆê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ëŠ” ë°©ë²• ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ê²°ê³¼ì ìœ¼ë¡œ, ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ì–‘í•œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ì—¬ ëª¨ë¸ì˜ ëŒ€í™” ëŠ¥ë ¥ê³¼ API í™œìš© ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: API-driven conversation prompt to generate SGD fine-tuning samples with GPT4-o. Only functions used across all dialogues are included due to their large number.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}