[{"figure_path": "https://arxiv.org/html/2502.14892/x1.png", "caption": "Figure 1: EgoSpeak\u00a0models speech initiation in real time from the camera wearer\u2019s (camera icon) egocentric video stream, mirroring how a real-world agent would perceive and engage in dynamic, multi-speaker environments.", "description": "\uadf8\ub9bc 1\uc740 EgoSpeak \ubaa8\ub378\uc774 \uce74\uba54\ub77c \ucc29\uc6a9\uc790\uc758 \uc2dc\uc810(\uce74\uba54\ub77c \uc544\uc774\ucf58)\uc5d0\uc11c \uc5bb\uc740 \uc601\uc0c1 \uc2a4\ud2b8\ub9bc\uc744 \uc2e4\uc2dc\uac04\uc73c\ub85c \ucc98\ub9ac\ud558\uc5ec \ubc1c\ud654 \uc2dc\uc810\uc744 \uc608\uce21\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\uc81c \uc0ac\ub78c\ucc98\ub7fc \ub2e4\uc591\ud55c \ubc1c\ud654\uc790\ub4e4\uc774 \uc788\ub294 \uc5ed\ub3d9\uc801\uc778 \ud658\uacbd\uc5d0\uc11c \uc0c1\ud669\uc744 \uc778\uc9c0\ud558\uace0 \ucc38\uc5ec\ud558\ub294 \ubc29\uc2dd\uc744 \ubc18\uc601\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \uce74\uba54\ub77c \ucc29\uc6a9\uc790\uac00 \uc5b8\uc81c \ub9d0\uc744 \uc2dc\uc791\ud574\uc57c \ud560\uc9c0 \uace0\ubbfc\ud558\ub294 \ubaa8\uc2b5\uacfc \uc8fc\ubcc0 \uc0c1\ud669(\ub2e4\ub978 \uc0ac\ub78c\ub4e4\uc758 \ubc1c\ud654 \uc5ec\ubd80)\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uc2dc\ub098\ub9ac\uc624\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.14892/x2.png", "caption": "Figure 2: Overview of the EgoSpeak framework. At each time step, the model processes an untrimmed egocentric video and audio stream, classifying them in real time into three categories: background (no speech), other person speaking, and target speaker (camera wearer) speaking. These probabilities are visualized at the bottom, where the model anticipates near-future frames and enables proactive speech initiation for conversational agents.", "description": "\uadf8\ub9bc 2\ub294 EgoSpeak \ud504\ub808\uc784\uc6cc\ud06c\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ubaa8\ub378\uc740 \ub2e4\ub4ec\uc5b4\uc9c0\uc9c0 \uc54a\uc740 \uc2dc\uc810 \uc911\uc2ec\uc758 \ube44\ub514\uc624 \ubc0f \uc624\ub514\uc624 \uc2a4\ud2b8\ub9bc\uc744 \ucc98\ub9ac\ud558\uc5ec \uc2e4\uc2dc\uac04\uc73c\ub85c \uc138 \uac00\uc9c0 \ubc94\uc8fc(\ubc30\uacbd(\uc74c\uc131 \uc5c6\uc74c), \ub2e4\ub978 \uc0ac\ub78c\uc774 \ub9d0\ud558\ub294 \uc911, \ub300\uc0c1 \ud654\uc790(\uce74\uba54\ub77c \ucc29\uc6a9\uc790)\uac00 \ub9d0\ud558\ub294 \uc911)\ub85c \ubd84\ub958\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ud655\ub960\uc740 \uc544\ub798\ucabd\uc5d0 \uc2dc\uac01\ud654\ub418\uc5b4 \uc788\uc73c\uba70, \ubaa8\ub378\uc740 \uac00\uae4c\uc6b4 \ubbf8\ub798\uc758 \ud504\ub808\uc784\uc744 \uc608\uc0c1\ud558\uace0 \ub300\ud654\ud615 \uc5d0\uc774\uc804\ud2b8\uc758 \uc0ac\uc804\uc801\uc778 \ub9d0\ud558\uae30 \uc2dc\uc791\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.  \uc989,  EgoSpeak \ubaa8\ub378\uc774 \ud604\uc7ac \uc2dc\uc810\uc758 \ube44\ub514\uc624\uc640 \uc624\ub514\uc624 \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c \ub2e4\uc74c \uba87 \ud504\ub808\uc784 \ub0b4\uc5d0 \uc790\uc2e0(\uce74\uba54\ub77c \ucc29\uc6a9\uc790)\uc774 \ub9d0\ud560\uc9c0, \ub2e4\ub978 \uc0ac\ub78c\uc774 \ub9d0\ud560\uc9c0, \uc544\ub2c8\uba74 \uc544\ubb34\ub3c4 \ub9d0\ud558\uc9c0 \uc54a\uc744\uc9c0\uc5d0 \ub300\ud55c \ud655\ub960\uc744 \uacc4\uc0b0\ud558\uace0, \uadf8 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c \uc2e4\uc2dc\uac04\uc73c\ub85c \ub9d0\ud560 \uc2dc\uc810\uc744 \uacb0\uc815\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 EgoSpeak Framework"}, {"figure_path": "https://arxiv.org/html/2502.14892/x3.png", "caption": "Figure 3: \nConverting Transcript to Per-Frame Labels. Colors indicate: gray - background, orange - target speaker speaking, purple - other speaker speaking. Labels are one-hot encoded for classification.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc5b4\ub178\ud14c\uc774\uc158 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub300\ud654\uc758 \uc804\uc0ac(transcript)\ub97c \uac01 \ud504\ub808\uc784\uc5d0 \ub300\ud55c \ub808\uc774\ube14\ub85c \ubcc0\ud658\ud558\ub294 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc124\uba85\ud569\ub2c8\ub2e4. \ud68c\uc0c9\uc740 \ubc30\uacbd, \uc8fc\ud669\uc0c9\uc740 \ub300\uc0c1 \ud654\uc790(\uce74\uba54\ub77c \ucc29\uc6a9\uc790)\uac00 \ub9d0\ud558\ub294 \ud504\ub808\uc784, \ubcf4\ub77c\uc0c9\uc740 \ub2e4\ub978 \uc0ac\ub78c\uc774 \ub9d0\ud558\ub294 \ud504\ub808\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ud504\ub808\uc784\uc740 \uc774 \uc138 \uac00\uc9c0 \uce74\ud14c\uace0\ub9ac \uc911 \ud558\ub098\uc5d0 \uc18d\ud558\ub294 one-hot \uc778\ucf54\ub529 \ub808\uc774\ube14\uc744 \ubc1b\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uc2e4\uc2dc\uac04\uc73c\ub85c \uc74c\uc131 \uac1c\uc2dc \uc2dc\uc810\uc744 \uc608\uce21\ud560 \uc218 \uc788\ub3c4\ub85d \ub3d5\uc2b5\ub2c8\ub2e4. ", "section": "3 EgoSpeak Framework"}, {"figure_path": "https://arxiv.org/html/2502.14892/x4.png", "caption": "Figure 4: Sample frames from YT-Conversation dataset. The dataset includes a diverse range of conversational scenarios from YouTube, such as podcasts, interviews, and informal dialogues, representing various real-world conversation formats.", "description": "\uadf8\ub9bc 4\ub294 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c YT-Conversation \ub370\uc774\ud130\uc14b\uc758 \uc0d8\ud50c \ud504\ub808\uc784\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. YT-Conversation \ub370\uc774\ud130\uc14b\uc740 \uc720\ud29c\ube0c\uc758 \ub2e4\uc591\ud55c \ub300\ud654 \uc2dc\ub098\ub9ac\uc624(\ud31f\uce90\uc2a4\ud2b8, \uc778\ud130\ubdf0, \ube44\uacf5\uc2dd \ub300\ud654 \ub4f1)\ub97c \ud3ec\ud568\ud558\uba70, \uc2e4\uc81c \uc138\uc0c1\uc758 \ub2e4\uc591\ud55c \ub300\ud654 \ud615\uc2dd\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub370\uc774\ud130\uc14b\uc758 \ub2e4\uc591\uc131\uacfc \uc2e4\uc81c \ub300\ud654 \uc0c1\ud669\uc744 \ubc18\uc601\ud558\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc601\uc0c1\ub4e4\uc744 \ubcf4\uc5ec\uc90c\uc73c\ub85c\uc368,  EgoSpeak \ubaa8\ub378\uc758 \ud6c8\ub828 \ubc0f \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \ud2b9\uc9d5\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc124\uba85\ud569\ub2c8\ub2e4.", "section": "3.3 YT-Conversation: Multimodal Conversation Pretraining"}, {"figure_path": "https://arxiv.org/html/2502.14892/x5.png", "caption": "Figure 5: Video duration distribution for YT-Conversation. Our online formulation allows the use of long video clips, some even exceeding 900 seconds.", "description": "YT-Conversation \ub370\uc774\ud130\uc14b\uc5d0 \ud3ec\ud568\ub41c \ube44\ub514\uc624\uc758 \uae38\uc774 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc785\ub2c8\ub2e4.  \uac00\ub85c\ucd95\uc740 \ube44\ub514\uc624 \uae38\uc774(\ucd08)\uc774\uace0, \uc138\ub85c\ucd95\uc740 \ud574\ub2f9 \uae38\uc774\ub97c \uac00\uc9c4 \ube44\ub514\uc624\uc758 \uc0c1\ub300\uc801 \ube48\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  EgoSpeak \ubaa8\ub378\uc740 \uc628\ub77c\uc778 \ubc29\uc2dd\uc73c\ub85c \ub3d9\uc791\ud558\uae30 \ub54c\ubb38\uc5d0 900\ucd08\ub97c \ub118\ub294 \uae34 \ube44\ub514\uc624 \ud074\ub9bd\ub3c4 \ucc98\ub9ac\ud560 \uc218 \uc788\ub2e4\ub294 \uc810\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. \ud3c9\uade0 \uae38\uc774\ub294 \uc57d 372\ucd08, \ud45c\uc900\ud3b8\ucc28\ub294 \uc57d 244\ucd08\ub85c \ub2e4\uc591\ud55c \uae38\uc774\uc758 \ube44\ub514\uc624\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 YT-Conversation: Multimodal Conversation Pretraining"}, {"figure_path": "https://arxiv.org/html/2502.14892/x6.png", "caption": "Figure 6: Utterance initiation prediction with varying transformer memory length. a shorter context window for short-term memory and a longer context window for long-term memory generally show better results.", "description": "\uadf8\ub9bc 6\uc740 Transformer \ubaa8\ub378\uc758 \ub2e8\uae30 \ubc0f \uc7a5\uae30 \uba54\ubaa8\ub9ac \uae38\uc774\ub97c \ub2e4\ub974\uac8c \ud558\uc5ec \ubc1c\ud654 \uac1c\uc2dc \uc2dc\uc810 \uc608\uce21 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \ub2e8\uae30 \uba54\ubaa8\ub9ac\uc5d0\ub294 \uc9e7\uc740 \ubb38\ub9e5 \ucc3d\uc744, \uc7a5\uae30 \uba54\ubaa8\ub9ac\uc5d0\ub294 \uae34 \ubb38\ub9e5 \ucc3d\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \ucd5c\uadfc\uc758 \uc9e7\uc740 \ub300\ud654 \ub0b4\uc6a9\uacfc \uacfc\uac70\uc758 \uae34 \ub300\ud654 \ub9e5\ub77d\uc744 \ubaa8\ub450 \uace0\ub824\ud558\ub294 \uac83\uc774 \ubc1c\ud654 \uc2dc\uc810 \uc608\uce21\uc5d0 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.", "section": "5.3 Models Do Not Exploit Short-Term Information Well"}, {"figure_path": "https://arxiv.org/html/2502.14892/x7.png", "caption": "Figure 7: Qualitative results on EasyCom. The predicted scores are shown in lines and the ground-truth label is shown in regions. The blue line represents a model with RGB input, the red line represents a model with audio input, and the purple line represents a model with audio and visual input.", "description": "\uadf8\ub9bc 7\uc740 EasyCom \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc81c\uc548\ub41c EgoSpeak \ubaa8\ub378\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub77c\uc778\uc740 \ubaa8\ub378\uc758 \uc608\uce21 \uc810\uc218\ub97c \ub098\ud0c0\ub0b4\uace0, \uc601\uc5ed\uc740 \uc2e4\uc81c \uc815\ub2f5 \ub808\uc774\ube14\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud30c\ub780\uc0c9 \uc120\uc740 RGB \uc785\ub825\ub9cc \uc0ac\uc6a9\ud55c \ubaa8\ub378, \ube68\uac04\uc0c9 \uc120\uc740 \uc624\ub514\uc624 \uc785\ub825\ub9cc \uc0ac\uc6a9\ud55c \ubaa8\ub378, \ubcf4\ub77c\uc0c9 \uc120\uc740 \uc624\ub514\uc624\uc640 \ube44\uc8fc\uc5bc \uc785\ub825\uc744 \ubaa8\ub450 \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \uac01\uac01 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc785\ub825 \ubaa8\ub4dc\ub97c \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \ub2e4\uc911 \ubaa8\ub2ec \uc785\ub825\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.5 Qualitative Results"}, {"figure_path": "https://arxiv.org/html/2502.14892/x8.png", "caption": "Figure 8: Attention weight of a transformer encoders. Transformer models focus on mostly local context for utterance initiation.", "description": "\uadf8\ub9bc 8\uc740 Transformer \ubaa8\ub378\uc758 \uc5b4\ud150\uc158 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Transformer \ubaa8\ub378\uc740 \ubc1c\ud654 \uac1c\uc2dc\ub97c \uc704\ud574 \uc8fc\ub85c \uc9c0\uc5ed\uc801 \ub9e5\ub77d\uc5d0 \uc9d1\uc911\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc740 Transformer \uc778\ucf54\ub354\uc758 \uc5b4\ud150\uc158 \uac00\uc911\uce58 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. \uc608\uce21 \ud504\ub808\uc784\uc73c\ub85c\ubd80\ud130\uc758 \uac70\ub9ac\uc5d0 \ub530\ub978 \uac00\uc911\uce58\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uc608\uce21 \ud504\ub808\uc784\uc5d0 \uac00\uae4c\uc6b8\uc218\ub85d \uac00\uc911\uce58\uac00 \ub192\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 Transformer \ubaa8\ub378\uc774 \ubc1c\ud654 \uac1c\uc2dc \uc2dc\uc810 \uc608\uce21\uc744 \uc704\ud574 \ucd5c\uadfc \ud504\ub808\uc784\uc758 \uc815\ubcf4\uc5d0 \ub354\uc6b1 \uc9d1\uc911\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "A Implementation Details"}, {"figure_path": "https://arxiv.org/html/2502.14892/x9.png", "caption": "Figure 9: Failure case on EasyCom. The orange region represents the target speaker speaking, and the red region represents the target speaker\u2019s backchanneling.", "description": "\uadf8\ub9bc 9\ub294 EasyCom \ub370\uc774\ud130\uc14b\uc5d0\uc11c EgoSpeak \ubaa8\ub378\uc774 \uc81c\ub300\ub85c \uc791\ub3d9\ud558\uc9c0 \uc54a\uc740 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc8fc\ud669\uc0c9 \uc601\uc5ed\uc740 \ubaa9\ud45c \ud654\uc790(\uce74\uba54\ub77c \ucc29\uc6a9\uc790)\uac00 \ub9d0\ud558\ub294 \uad6c\uac04\uc744 \ub098\ud0c0\ub0b4\uace0, \ube68\uac04\uc0c9 \uc601\uc5ed\uc740 \ubaa9\ud45c \ud654\uc790\uac00 \ub2e4\ub978 \ud654\uc790\uc758 \ub9d0\uc5d0 \ub300\ud55c \ubc18\uc751\uc73c\ub85c \uc9e7\uac8c \ubc1c\ud654\ud558\ub294 \uad6c\uac04(backchanneling)\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ubaa8\ub378\uc774 backchanneling\uacfc \uac19\uc740 \uc9e7\uace0 \ube44\uc815\ud615\uc801\uc778 \ubc1c\ud654\ub97c \uc815\ud655\ud558\uac8c \uc608\uce21\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uc744 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.3 \ubaa8\ub378\uc740 \ub2e8\uae30 \uc815\ubcf4\ub97c \uc798 \ud65c\uc6a9\ud558\uc9c0 \ubabb\ud568"}]