{"references": [{"fullname_first_author": "Micheli", "paper_title": "Transformers are sample-efficient world models", "publication_date": "2023-09-08", "reason": "This paper proposes a transformer-based world model that is highly sample-efficient, a key problem addressed in this work."}, {"fullname_first_author": "Hafner", "paper_title": "Mastering diverse domains through world models", "publication_date": "2024-01-04", "reason": "This paper focuses on learning world models that generalize across a variety of tasks, a major theme of this research."}, {"fullname_first_author": "Hafner", "paper_title": "Mastering Atari with discrete world models", "publication_date": "2022-10-02", "reason": "This paper shows the potential of model-based reinforcement learning in solving complex control tasks, relevant to the approach here."}, {"fullname_first_author": "Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-04-14", "reason": "This paper introduces DINO, a self-supervised learning method that provides the visual features used in this work."}, {"fullname_first_author": "Ko", "paper_title": "Learning to act from actionless videos through dense correspondences", "publication_date": "2023-10-08", "reason": "This paper uses a generative model for video prediction, an approach that is similar to, but differs in several ways from, the method presented here."}]}