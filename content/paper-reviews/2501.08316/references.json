{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models, a foundational work for many of the diffusion models used in image and video generation."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-01-01", "reason": "This paper is highly relevant as it explores the capabilities of video generation models, which are central to the topic of one-step video generation discussed in the target paper."}, {"fullname_first_author": "Shanchuan Lin", "paper_title": "Animatediff-lightning: Cross-model diffusion distillation", "publication_date": "2024-03-15", "reason": "This work directly addresses the challenges of one-step video generation, making it highly relevant and important to the context of the target paper."}, {"fullname_first_author": "Axel Sauer", "paper_title": "Fast high-resolution image synthesis with latent adversarial diffusion distillation", "publication_date": "2024-10-01", "reason": "This paper introduces a technique for efficient image generation using adversarial training and diffusion models, which is highly relevant to the proposed method in the target paper."}, {"fullname_first_author": "Tero Karras", "paper_title": "A style-based generator architecture for generative adversarial networks", "publication_date": "2018-06-01", "reason": "This highly influential paper introduces StyleGAN, a significant advancement in GAN-based image generation, providing valuable background for the adversarial techniques used in the target paper."}]}