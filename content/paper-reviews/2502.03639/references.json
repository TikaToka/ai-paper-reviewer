{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-00-00", "reason": "This paper is foundational for the current work, introducing the use of latent diffusion models for high-quality video generation, a method that is further developed and improved in the current research."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen video: High definition video generation with diffusion models", "publication_date": "2022-00-00", "reason": "This paper is highly influential as it demonstrates the effectiveness of using diffusion models for high-resolution video generation, which is an important area that the current research builds upon."}, {"fullname_first_author": "Uriel Singer", "paper_title": "Make-a-video: Text-to-video generation without text-video data", "publication_date": "2023-00-00", "reason": "This paper is significant for its innovative approach to text-to-video generation, which directly impacts the area of the current research and provides a benchmark to compare results."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70M: Captioning 70M videos with multiple cross-modality teachers", "publication_date": "2024-00-00", "reason": "This paper is crucial for providing the dataset used in the current research, which is essential for the results and conclusions drawn."}, {"fullname_first_author": "Hritik Bansal", "paper_title": "Videophy: Evaluating physical commonsense for video generation", "publication_date": "2024-00-00", "reason": "This paper is important because it introduces a benchmark for evaluating the physical realism of generated videos, enabling a quantitative comparison and evaluation of the proposed method."}]}