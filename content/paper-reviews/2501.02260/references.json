{"references": [{"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces the foundational CLIP model, which is crucial to MagicFace's architecture and functionality for image generation and condition embedding."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces Stable Diffusion, the core image generation model upon which MagicFace is built, defining its high-fidelity image generation capabilities."}, {"fullname_first_author": "P. Ekman", "paper_title": "The facial action coding system: A technique for the measurement of facial movement", "publication_date": "1978-00-00", "reason": "This paper introduces FACS, the fundamental system for describing and encoding facial expressions, directly impacting MagicFace's design and AU-based expression control."}, {"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces denoising diffusion probabilistic models (DDPM), which are critical to the training and functionality of MagicFace's diffusion model architecture."}, {"fullname_first_author": "A. Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-00-00", "reason": "This paper details the vision transformer (ViT) architecture which is relevant to the ID encoder and self-attention mechanism used in MagicFace for identity preservation."}]}