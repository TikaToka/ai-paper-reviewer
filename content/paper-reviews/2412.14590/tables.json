[{"content": "| Model | Size | Llama 3.1/3.2 1B | Llama 3.1/3.2 8B | Llama 3.1/3.2 70B | Qwen2.5 0.5B | Qwen2.5 1.5B | Qwen2.5 7B | Qwen2.5 32B | Mistral 7B v0.3 |\n|---|---|---|---|---|---|---|---|---|\n| baselines |  | 9.75/12.72 | 6.24/8.95 | 2.81/6.68 | 13.07/17.55 | 9.26/13.11 | 6.85/10.44 | 5.02/8.95 | 5.32/7.84 |\n| float16 |  | 9.75/12.72 | 6.24/8.95 | 2.81/6.68 | 13.07/17.55 | 9.26/13.11 | 6.85/10.44 | 5.02/8.95 | 5.32/7.84 |\n| W4A16 |  | 11.72/15.56 | 6.82/9.72 | 3.55/7.43 | 15.54/20.55 | 10.35/14.35 | 7.23/10.88 | 5.27/9.14 | 5.51/8.04 |\n| RTN<br>W5A16 |  | 10.15/13.25 | 6.40/9.15 | 3.16/9.52 | 13.61/18.17 | 9.52/13.38 | 6.95/10.53 | 5.09/8.99 | 5.38/7.91 |\n| GPTQ<br>W4A16 |  | 10.38/14.15 | 6.52/9.55 | Abn/Abn | 14.01/19.04 | 9.64/13.75 | 7.09/10.75 | 5.20/9.08 | 5.49/8.19 |\n| AWQ<br>W4A16 |  | 10.81/14.12 | 6.65/9.48 | 3.28/6.96 | 15.04/19.75 | 9.95/13.85 | 7.10/10.71 | 5.23/9.08 | 5.44/7.98 |\n| SmoothQuant<br>W8A8 |  | 9.89/12.91 | 6.34/9.08 | 2.92/6.77 | 13.84/18.40 | 9.63/13.49 | 7.17/10.85 | 5.12/9.04 | 5.35/7.88 |\n| QoQ<br>W4A8 |  | Abn/Abn | 6.64/9.49 | 3.49/7.07 | Abn/Abn | Abn/Abn | 7.39/11.06 | 5.55/9.31 | 5.44/7.98 |\n| W4A4 |  | Abn/Abn | 8.34/11.95 | 6.16/9.91 | NA/NA | Abn/Abn | 8.15/12.05 | 6.26/9.98 | 5.83/8.50 |\n| QuaRot<br>W4A8 |  | Abn/Abn | 6.60/9.67 | 3.43/7.10 | NA/NA | Abn/Abn | 7.03/10.68 | 5.23/9.10 | 5.40/7.99 |\n| W4A8 (p0) |  | 10.36/14.09 | 6.54/9.62 | 3.30/7.24 | 14.43/19.61 | 9.66/13.79 | 7.03/10.75 | 5.21/9.08 | 5.42/8.02 |\n| W4.4A8 (p10) |  | 10.05/13.51 | 6.42/9.33 | 3.02/6.83 | 13.42/18.13 | 9.44/13.43 | 6.92/10.57 | 5.12/9.01 | 5.36/7.93 |\n| W4.8A8 (p20) |  | 9.95/13.25 | 6.37/9.22 | 2.97/6.79 | 13.32/17.99 | 9.40/13.35 | 6.90/10.53 | 5.09/9.00 | 5.35/7.90 |\n| W6A8 (p50) |  | 9.85/12.98 | 6.30/9.09 | 2.86/6.73 | 13.21/17.78 | 9.33/13.25 | 6.88/10.49 | 5.05/8.98 | 5.33/7.87 |\n| MixLLM<br>W8A8 (p100) |  | 9.76/12.75 | 6.25/8.97 | 2.81/6.68 | 13.12/17.60 | 9.28/13.14 | 6.86/10.45 | 5.02/8.96 | 5.32/7.84 |", "caption": "Table 1: Perplexity evaluation (\u2193\u2193\\downarrow\u2193) on wikitext2/c4 (gray for c4), sequence length 2048.\nNA means no support.\nAbn means the value is too large (>105absentsuperscript105>10^{5}> 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT).\nFor MixLLM, pn means n%percent\ud835\udc5bn\\%italic_n % 8-bit.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc5b8\uc5b4 \ubaa8\ub378\ub4e4\uc5d0 \ub300\ud574, wikitext2\uc640 c4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc2dc\ud000\uc2a4 \uae38\uc774 2048\uc744 \uc0ac\uc6a9\ud558\uc5ec perplexity\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'NA'\ub294 \ud574\ub2f9 \ubc29\ubc95\uc774 \uc9c0\uc6d0\ud558\uc9c0 \uc54a\ub294\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uba70, 'Abn'\uc740 \uac12\uc774 10\uc758 5\uc81c\uacf1\ubcf4\ub2e4 \ud06c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. MixLLM\uc758 \uacbd\uc6b0, 'pn'\uc740 8\ube44\ud2b8 \uc815\ubc00\ub3c4\ub97c \uc0ac\uc6a9\ud558\ub294 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4 (\uc608: p10\uc740 10%\uc758 \ud53c\ucc98\uc5d0 8\ube44\ud2b8\ub97c \uc0ac\uc6a9). \uc774 \ud45c\ub294 \uc5ec\ub7ec \uac00\uc9c0 \uc591\uc790\ud654 \ubc29\ubc95\ub4e4\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubaa8\ub378 \ud06c\uae30(1B, 8B, 70B \ub4f1)\uc640 \uc591\uc790\ud654 \uae30\ubc95(GPTQ, AWQ, SmoothQuant \ub4f1)\uc758 perplexity\ub97c \ube44\uad50\ud558\uc5ec \uac01 \uae30\ubc95\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 Perplexity Evaluation"}, {"content": "| LLaMA 2 | FP16 | SqueezeLLM | OminiQuant | AfineQuant | Atom | SpinQuant | MixLLM |\n|---|---|---|---|---|---|---|---| \n| 7B | 5.47 | 5.57 | 5.58/14.26 | 5.58/12.69 | 6.03 | 5.7 | 5.55 |\n| 13B | 4.88 | 4.96 | 4.95/12.30 | 4.95/11.45 | 5.27 | 5.0 | 4.93 |", "caption": "Table 2: PPL (wikitext2) comparison with the reported numbers in the related works.", "description": "\ud45c 2\ub294 \ub17c\ubb38\uc5d0\uc11c \ub2e4\ub8ec \ub2e4\uc591\ud55c \uad00\ub828 \uc5f0\uad6c\ub4e4\uc758 \uacb0\uacfc\uc640 \ube44\uad50\ud558\uc5ec, Wikitext2 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c perplexity(PPL) \uac12\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uac01 \ubc29\ubc95(Weight-only, Weight-activation, MixLLM \ub4f1)\uc758 \uc131\ub2a5\uc744 4-bit \ubc0f 8-bit \uc591\uc790\ud654 \uc124\uc815 \ud558\uc5d0 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, MixLLM\uc758 \uc815\ud655\ub3c4 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378 \ud06c\uae30(7B, 13B \ub4f1)\uc640 \uc0ac\uc6a9\ub41c \uc591\uc790\ud654 \uae30\uc220\uc758 \uc885\ub958\uc5d0 \ub530\ub978 PPL \uac12\uc758 \ubcc0\ud654\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uae30\uc874 \uc5f0\uad6c\ub4e4\uacfc\uc758 \uc815\ub7c9\uc801 \ube44\uad50\ub97c \ud1b5\ud574 MixLLM\uc758 \uc131\ub2a5\uc744 \uba85\ud655\ud558\uac8c \uc81c\uc2dc\ud558\ub294 \ud45c\uc785\ub2c8\ub2e4.", "section": "4.2 Perplexity Evaluation"}, {"content": "| Model | Result |\n|---|---| \n| SqueezeLLM | W4A16 0.45% |", "caption": "Table 3: Downstream tasks evaluation (\u2191\u2191\\uparrow\u2191) on Llama-3.1-8B/Qwen2.5-7B/Mistral-7B-v0.3.\nThe above is the average of the three models.\nBBH is 3 shot, MMLU pro is 5 shot, and others are zero shot.", "description": "\ud45c 3\uc740 Llama-3.1-8B, Qwen2.5-7B, Mistral-7B-v0.3 \uc138 \uac00\uc9c0 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud558\ub958 \uc791\uc5c5 \ud3c9\uac00 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. BBH\ub294 3\uc0f7, MMLU pro\ub294 5\uc0f7, \uae30\ud0c0 \uc791\uc5c5\uc740 \uc81c\ub85c\uc0f7\uc73c\ub85c \ud3c9\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc5ec\ub7ec \uac00\uc9c0 \uc591\uc790\ud654 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 \ud558\ub958 \uc791\uc5c5 \ud3c9\uac00"}, {"content": "| Model | Architecture |\n|---|---| \n| OminiQuant | W4A16/W4A4 |\n", "caption": "Table 4: The average percentage of 8-bit out features in the seven classes of linear layers in Llama 3.1 8B, with 10% global 8-bit out features in MixLLM.", "description": "\ud45c 4\ub294 MixLLM\uc5d0\uc11c \uc804\uc5ed\uc801\uc73c\ub85c 10%\uc758 8\ube44\ud2b8 \ucd9c\ub825 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c, Llama 3.1 8B \ubaa8\ub378\uc758 7\uac00\uc9c0 \uc120\ud615 \ub808\uc774\uc5b4 \uc885\ub958\uc5d0\uc11c \ud3c9\uade0\uc801\uc73c\ub85c 8\ube44\ud2b8 \ucd9c\ub825 \ud2b9\uc9d5\uc774 \ucc28\uc9c0\ud558\ub294 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub808\uc774\uc5b4 \uc885\ub958\ubcc4 (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj) \ub85c \ub098\ub258\uc5b4 8\ube44\ud2b8 \ucd9c\ub825 \ud2b9\uc9d5\uc758 \ube44\uc728\uc774 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 MixLLM\uc758 \ud63c\ud569 \uc815\ubc00\ub3c4 \uc591\uc790\ud654 \uc804\ub7b5\uc774 \ubaa8\ub378\uc758 \uac01 \ubd80\ubd84\uc5d0 \uc5b4\ub5bb\uac8c \uc801\uc6a9\ub418\ub294\uc9c0\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.5.2 \uace0\uc815\ubc00\ub3c4 \ubd84\ud3ec"}, {"content": "| AfineQuant | W4A16/W4A4 |\n|---|---|", "caption": "Table 5: The overhead of global precision search in MixLLM.", "description": "\ud45c 5\ub294 MixLLM\uc5d0\uc11c \uc804\uc5ed \uc815\ubc00\ub3c4 \ud0d0\uc0c9\uc5d0 \ud544\uc694\ud55c \uc2dc\uac04\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub378 \ud06c\uae30\ubcc4\ub85c \uc18c\uc694 \uc2dc\uac04\uc774 \ub2e4\ub974\uba70, 1.5B, 7B, 8B \ubaa8\ub378\uc740 \ub2e8\uc77c A100 GPU\uc5d0\uc11c \uac01\uac01 7\ubd84 \uc815\ub3c4 \uc18c\uc694\ub418\uc5c8\uace0, 70B \ubaa8\ub378\uc740 4\uac1c\uc758 A100 GPU\ub97c \uc0ac\uc6a9\ud558\uc5ec 60\ubd84 \ubbf8\ub9cc\uc774 \uc18c\uc694\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ud55c \ubc88\ub9cc \uc218\ud589\ub418\ub294 \uc791\uc5c5\uc774\uae30 \ub54c\ubb38\uc5d0 \uc2e4\uc81c \uc791\uc5c5 \ud658\uacbd\uc5d0\uc11c\ub3c4 \uc2e4\uc6a9\uc801\uc778 \uc2dc\uac04\uc785\ub2c8\ub2e4.", "section": "4.5.4 \uc804\uc5ed \uc815\ubc00\ub3c4 \ud0d0\uc0c9\uc758 \uc624\ubc84\ud5e4\ub4dc"}]