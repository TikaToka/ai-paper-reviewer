---
title: "HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation"
summary: "LLMì˜ ì ì§„ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ HumanEval Pro, MBPP Pro, BigCodeBench-Lite Pro ì œì‹œ!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Tsinghua University",]
showSummary: true
date: 2024-12-30
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2412.21199 {{< /keyword >}}
{{< keyword icon="writer" >}} Zhaojian Yu et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2024-12-31 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2412.21199" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2412.21199" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/humaneval-pro-and-mbpp-pro-evaluating-large" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ê¸°ì¡´ì˜ ì½”ë“œ ìƒì„± í‰ê°€ ë²¤ì¹˜ë§ˆí¬ëŠ” LLMì˜ ì‹¤ì œ ì½”ë”© ëŠ¥ë ¥ì„ ì™„ë²½íˆ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” ë¬¸ì œì ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ë³µì¡í•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì—¬ëŸ¬ í•¨ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ëŠ¥ë ¥**ì€ ì œëŒ€ë¡œ í‰ê°€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  ë”°ë¼ì„œ, LLMì´ ìŠ¤ìŠ¤ë¡œ ìƒì„±í•œ ì½”ë“œë¥¼ í™œìš©í•˜ëŠ” ëŠ¥ë ¥ì„ ì¤‘ì ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ì—ì„œëŠ” **ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„±**ì´ë¼ëŠ” ìƒˆë¡œìš´ í‰ê°€ ë°©ì‹ì„ ì œì•ˆí•˜ê³ , HumanEval Pro, MBPP Pro, BigCodeBench-Lite Pro ì„¸ ê°œì˜ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤.  ì‹¤í—˜ ê²°ê³¼, ìµœì²¨ë‹¨ LLMë“¤ë„ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” LLMì˜ ì½”ë“œ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ë©°, ë”ìš± **í˜„ì‹¤ì ì¸ ì½”ë”© ëŠ¥ë ¥ í‰ê°€**ì™€ **ì‹¤ìš©ì ì¸ ì½”ë“œ ìƒì„± ëª¨ë¸ ê°œë°œ**ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LLMì˜ ì ì§„ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œì¸ "ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„±"ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ê¸°ì¡´ ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ í›¨ì”¬ ì–´ë ¤ìš´ ìƒˆë¡œìš´ ì„¸ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} LLMì´ ìì²´ ìƒì„± ì½”ë“œë¥¼ í™œìš©í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ë°í˜”ê³ , í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ ì½”ë“œ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•˜ì—¬, ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  **ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤**ì— ë”ìš± ê·¼ì ‘í•œ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” LLMì˜ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ê³ , **ì‹¤ìš©ì ì¸ ì½”ë“œ ìƒì„± ëª¨ë¸ ê°œë°œ**ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  **ìì²´ ìƒì„± í•¨ìˆ˜ë¥¼ í˜¸ì¶œ**í•˜ëŠ” ì½”ë“œ ìƒì„± ê³¼ì œì— ëŒ€í•œ ìƒˆë¡œìš´ í‰ê°€ ë°©ë²•ì„ ì œì•ˆí•˜ë©°,  **ì‹¤ì œ ì½”ë”© ëŠ¥ë ¥**ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2412.21199/x1.png)

> ğŸ”¼  ê·¸ë¦¼ 1ì€ HumanEval Proì™€ MBPP Proì—ì„œ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„±ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°ë³¸ ë¬¸ì œì™€ ê´€ë ¨ëœ ë” ë³µì¡í•œ ë¬¸ì œê°€ ì£¼ì–´ì§€ë©´ ëª¨ë¸ì€ ê¸°ë³¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ê·¸ í•´ê²°ì±…ì„ ì‚¬ìš©í•˜ì—¬ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœí•œ ì½”ë“œ ìƒì„±ì„ ë„˜ì–´, ëª¨ë¸ì´ ìƒì„±í•œ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì˜ í•µì‹¬ ê°œë…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ëª¨ë¸ì€ ì…ë ¥ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸(Prompt)ë¥¼ ë°›ê³ , ê¸°ë³¸ ë¬¸ì œì™€ ìê¸° í˜¸ì¶œ ë¬¸ì œë¥¼ í’€ì–´ì•¼ í•©ë‹ˆë‹¤. ê¸°ë³¸ ë¬¸ì œë¥¼ ë¨¼ì € í’€ê³ , ê·¸ í•´ê²°ì±…ì„ ì´ìš©í•´ì„œ ìê¸° í˜¸ì¶œ ë¬¸ì œë¥¼ í’€ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œëŠ” ê¸°ë³¸ ë¬¸ì œì˜ ì†”ë£¨ì…˜ì„ ìƒì„±í•˜ê³ , ê·¸ ì†”ë£¨ì…˜ì„ ìê¸° í˜¸ì¶œ ë¬¸ì œì—ì„œ í™œìš©í•˜ëŠ” ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: The overview of self-invoking code generation in HumanEval Pro and MBPP Pro. Given a base problem and a related, more complex problem, they are required to solve the base problem and use its solution to address the complex problems.
> </details>





{{< table-caption >}}
| Iteration | HumanEval Pro (%) | MBPP Pro (%) |
|---|---|---|
| Round 1 | 64.0 | 84.7 |
| Round 2 | 98.8 | 99.7 |
| Round 3 | 100.0 | 100.0 |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ì •ë‹µ ì½”ë“œì™€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ê³¼ì •ì—ì„œ ì‚¬ëŒì˜ ê²€í† ë¥¼ ê±°ì¹œ í›„ ì—¬ëŸ¬ ë°˜ë³µ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ í›„ë³´ ì†”ë£¨ì…˜ì˜ ì •í™•ë„(Pass@1)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë°˜ë³µ ë‹¨ê³„ì—ì„œì˜ ì •í™•ë„ í–¥ìƒì„ í†µí•´, ì‚¬ëŒì˜ ê²€í† ë¥¼ í¬í•¨í•œ ì—„ê²©í•œ ê²€ì¦ ê³¼ì •ì„ ê±°ì³ ìƒì„±ëœ ë²¤ì¹˜ë§ˆí¬ì˜ ë†’ì€ í’ˆì§ˆì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Pass@1 (%) of candidate solutions across different iteration rounds for canonical solution and test case generation with human manual review.
> </details>





### In-depth insights


#### Self-Invoking Code
ìê¸° í˜¸ì¶œ ì½”ë“œ(Self-Invoking Code)ëŠ” ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ ì½”ë“œ ìƒì„± ë¬¸ì œë¥¼ ë„˜ì–´, **ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ìƒì„±í•œ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥**ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œì…ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ë¿ ì•„ë‹ˆë¼, **ìƒì„±ëœ ì½”ë“œì— ëŒ€í•œ ì´í•´ì™€ í™œìš© ëŠ¥ë ¥**ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•œë‹¤ëŠ” ì ì—ì„œ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì™€ ì°¨ë³„í™”ë©ë‹ˆë‹¤.  ì—°êµ¬ì—ì„œëŠ” HumanEval Pro, MBPP Proì™€ ê°™ì´ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•˜ê³ , ë‹¤ì–‘í•œ LLMë“¤ì„ í‰ê°€í•˜ì—¬ **ê¸°ì¡´ ëª¨ë¸ë“¤ì´ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ì **ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” **LLMì˜ ì½”ë“œ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ**ì„ ìœ„í•œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•˜ë©°,  ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í™˜ê²½ì— ë” ê°€ê¹Œìš´ í‰ê°€ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.  ë˜í•œ, instruction-tuningê³¼ ê°™ì€ ê¸°ì¡´ì˜ í•™ìŠµ ë°©ì‹ì´ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ê³¼ì œì— ëŒ€í•œ ì„±ëŠ¥ í–¥ìƒì—ëŠ” ì œí•œì ì¸ íš¨ê³¼ë¥¼ ë³´ì¸ë‹¤ëŠ” ì ì„ ë°íˆê³ ,  **ìƒˆë¡œìš´ í•™ìŠµ ë°©ë²• ë° ëª¨ë¸ ê°œì„ **ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.  ê²°ë¡ ì ìœ¼ë¡œ, ìê¸° í˜¸ì¶œ ì½”ë“œëŠ” LLMì˜ ì½”ë“œ ì´í•´, í™œìš©, ê·¸ë¦¬ê³  ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ìœ ìš©í•œ ë„êµ¬ì´ë©°, í–¥í›„ LLM ë°œì „ì— ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Benchmark Creation
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ë²¤ì¹˜ë§ˆí¬ ìƒì„± ë°©ë²•ì€ ê¸°ì¡´ HumanEval ë° MBPPì™€ ê°™ì€ ë²¤ì¹˜ë§ˆí¬ì˜ ë¬¸ì œë“¤ì„ **ìì²´ì ìœ¼ë¡œ ìƒì„±í•œ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ëŠ” ìê¸° í˜¸ì¶œ ë°©ì‹**ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  ì´ëŠ” ë‹¨ìˆœí•œ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ì„ ë„˜ì–´, ëª¨ë¸ì˜ **ì¶”ë¡  ëŠ¥ë ¥ ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. **DeepSeek-V2.5ì™€ ê°™ì€ ëª¨ë¸**ì„ ì´ìš©í•˜ì—¬ ê¸°ì¡´ ë¬¸ì œë“¤ì„ ë”ìš± ë³µì¡í•œ ìê¸° í˜¸ì¶œ ë¬¸ì œë¡œ ë³€í™˜í•˜ëŠ”ë°, ì´ëŠ” ë‹¨ìˆœíˆ ë¬¸ì œì˜ ë³µì¡ì„±ì„ ë†’ì´ëŠ” ê²ƒ ë¿ë§Œ ì•„ë‹ˆë¼, ê¸°ì¡´ ë¬¸ì œì™€ì˜ **ì—°ê´€ì„±ì„ ìœ ì§€**í•˜ë©° ì ì§„ì ì¸ ì¶”ë¡  ëŠ¥ë ¥ì„ ìš”êµ¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  **ì •í™•ì„± ê²€ì¦ì„ ìœ„í•œ ë°˜ë³µì  í…ŒìŠ¤íŠ¸ ë° ìˆ˜ë™ ê²€í† ** ê³¼ì •ì„ í†µí•´ ë†’ì€ í’ˆì§ˆì˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ êµ¬ì¶•í•˜ê³ , ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°ê´€ì ìœ¼ë¡œ ë¹„êµí•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ë§ˆë ¨í•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ë²¤ì¹˜ë§ˆí¬ ìƒì„± ê³¼ì •ì€ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , **ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í™˜ê²½**ì— ë”ìš± ê°€ê¹Œìš´ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

#### LLM Evaluation
ë³¸ ë…¼ë¬¸ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ í‰ê°€ì— ëŒ€í•´ ì‹¬ë„ ìˆê²Œ ë…¼ì˜í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë²¤ì¹˜ë§ˆí¬ë“¤ì€ ë‹¨ì¼ ê¸°ëŠ¥ ì½”ë“œ ìƒì„±ì— ì´ˆì ì„ ë§ì¶”ì–´ í˜„ì‹¤ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, **ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„±(self-invoking code generation)**ì´ë¼ëŠ” ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì œì‹œí•˜ì—¬ LLMì˜ ì ì§„ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ê³ ì í•©ë‹ˆë‹¤.  ì´ëŠ” ê¸°ë³¸ ë¬¸ì œì™€ ê´€ë ¨ëœ ë³µì¡í•œ ë¬¸ì œë¥¼ ì œì‹œí•˜ê³ , ëª¨ë¸ì´ ê¸°ë³¸ ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ê·¸ í•´ê²°ì±…ì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.  **HumanEval Pro, MBPP Pro, BigCodeBench-Lite Pro** ì™€ ê°™ì€ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ì´ëŸ¬í•œ í‰ê°€ê°€ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.  ì‹¤í—˜ ê²°ê³¼, ëŒ€ë¶€ë¶„ì˜ LLMì€ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ ìì²´ í˜¸ì¶œ ê³¼ì œì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë˜í•œ, ì§€ì‹œì–´ ë¯¸ì„¸ ì¡°ì • ëª¨ë¸ì€ ê¸°ë³¸ ëª¨ë¸ì— ë¹„í•´ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ë¯¸ë¯¸í•œ ê°œì„ ë§Œ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜, í–¥í›„ **ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ê³¼ì œì˜ ë°œì „ ë° LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ**ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.  **ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜**ë¥¼ í†µí•´ LLMì˜ í•œê³„ì ì„ ë°íˆê³ ,  **Chain-of-Thought í”„ë¡¬í”„íŒ… ê¸°ë²•ì˜ íš¨ê³¼**ì— ëŒ€í•´ì„œë„ ë…¼ì˜í•©ë‹ˆë‹¤.

#### Instruction Tuning
ì§€ì‹œ ì¡°ì •(Instruction Tuning)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì¤‘ìš”í•œ ë°©ë²•ì…ë‹ˆë‹¤.  **ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì— ì¶”ê°€ì ì¸ ì§€ì‹œ ë°ì´í„°ë¥¼ ì œê³µí•˜ì—¬ íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ ì„±ëŠ¥ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ì‹**ì…ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì§€ì‹œì–´ì— ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ ë°˜ì‘í•˜ê³  ë³´ë‹¤ ì •í™•í•˜ê³  ì¼ê´€ëœ ì¶œë ¥ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„±(self-invoking code generation)ê³¼ ê°™ì€ ë³µì¡í•œ ì‘ì—…ì—ì„œëŠ” **ì§€ì‹œ ì¡°ì •ì˜ íš¨ê³¼ê°€ ì œí•œì **ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. **ê¸°ì¡´ì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ì§€ì‹œ ì¡°ì •ì´ í° ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ì§€ë§Œ, ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„±ê³¼ ê°™ì´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ê³¼ ì—°ì‡„ì ì¸ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ìš”êµ¬í•˜ëŠ” ì‘ì—…ì—ì„œëŠ” í•œê³„ê°€ ë“œëŸ¬ë‚©ë‹ˆë‹¤.**  ì´ëŠ” ë‹¨ìˆœíˆ ì§€ì‹œì–´ì— ëŒ€í•œ ë°˜ì‘ ëŠ¥ë ¥ í–¥ìƒì„ ë„˜ì–´, **ëª¨ë¸ì˜ ê·¼ë³¸ì ì¸ ì´í•´ì™€ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”**í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ì§€ì‹œ ì¡°ì • ì™¸ì—ë„ ëª¨ë¸ì˜ ë‚´ë¶€ì ì¸ ì¶”ë¡  ë©”ì»¤ë‹ˆì¦˜ê³¼ ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ê°œì„ í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì—°êµ¬ê°€ ì§„í–‰ë˜ì–´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.  **ë”ìš± ë³µì¡í•˜ê³  í˜„ì‹¤ì ì¸ ë¬¸ì œì— ëŒ€í•œ ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì˜ ê°œë°œ ë˜í•œ ì¤‘ìš”**í•œ ê³¼ì œì…ë‹ˆë‹¤.

#### Future Work
ë³¸ ë…¼ë¬¸ì€ **ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„±**ì´ë¼ëŠ” ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì œì‹œí•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì ì§„ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” HumanEval Pro, MBPP Pro, BigCodeBench-Lite Pro ì„¸ ê°€ì§€ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.  í–¥í›„ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œëŠ” **ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì§€ì› ë° ë³´ë‹¤ ë‹¤ì–‘í•œ ìì²´ í˜¸ì¶œ ë¬¸ì œì˜ ì¶”ê°€**ê°€ ì œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í˜„ì¬ ë²¤ì¹˜ë§ˆí¬ëŠ” íŒŒì´ì¬ì— êµ­í•œë˜ì–´ ìˆê³ , ìì²´ í˜¸ì¶œ ë¬¸ì œì˜ ë‹¤ì–‘ì„±ì´ ì œí•œì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ë˜í•œ, **LLMì˜ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ í›ˆë ¨ ë°©ë²•ë¡ **ì— ëŒ€í•œ ì—°êµ¬ë„ ì¤‘ìš”í•˜ë©°, **ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°˜ì˜í•œ ë³´ë‹¤ í˜„ì‹¤ì ì¸ ë¬¸ì œ**ë¥¼ í¬í•¨í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤.  **ë‹¤êµ­ì–´ ì§€ì›**ì„ í†µí•´  LLMì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë”ìš± ì‹¬ë„ ìˆê²Œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, **ì‹¤íŒ¨ ì‚¬ë¡€ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„**ì„ í†µí•´ LLMì˜ í•œê³„ë¥¼ íŒŒì•…í•˜ê³  ê°œì„  ë°©í–¥ì„ ëª¨ìƒ‰í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2412.21199/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ë¦¼ 8ì— ì˜ˆì‹œê°€ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤. ì „ì²´ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 1ë‹¨ê³„ëŠ” DeepSeek-V2.5ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë¬¸ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ë¬¸ì œë¥¼ ìƒì„±í•˜ê³ , í›„ë³´ ì†”ë£¨ì…˜ ë° í…ŒìŠ¤íŠ¸ ì…ë ¥ê°’ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 2ë‹¨ê³„ëŠ” ì œì–´ëœ íŒŒì´ì¬ í™˜ê²½ì—ì„œ ìƒì„±ëœ ì†”ë£¨ì…˜ì„ í…ŒìŠ¤íŠ¸ ì…ë ¥ê°’ê³¼ í•¨ê»˜ ì‹¤í–‰í•˜ì—¬ ì‹¤ì œ ê²°ê³¼ë¥¼ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤. 3ë‹¨ê³„ëŠ” íŒŒì´ì¬ ì‹¤í–‰ í™•ì¸ ë° ìˆ˜ë™ ê²€í† ë¥¼ í¬í•¨í•œ ë°˜ë³µì ì¸ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ê°€ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í•˜ë„ë¡ í•˜ì—¬ ìµœì¢… ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ assert ëª…ë ¹ì–´ê°€ í¬í•¨ëœ ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ êµ¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: The overview of benchmark construction. An example is shown in FigureÂ 8. We summarize the entire benchmark construction process as follows: (1) Self-invoking problem Generation: We use Deepseek-V2.5 to generate the self-invoking problems, as well as their candidate solutions and test inputs. (2) Solutions Generation: We execute the generated solution with the test inputs in a controlled Python environment to obtain ground truth outputs. (3) Test Cases Generation: We employ an iterative method involving Python execution check and manual review to ensure that all test cases pass successfully. The final execution results are then used to construct complete test cases with assert command.
> </details>



![](https://arxiv.org/html/2412.21199/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ HumanEval ë° MBPPì™€ HumanEval Pro ë° MBPP Proì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ë§‰ëŒ€ ê·¸ë˜í”„ì…ë‹ˆë‹¤. HumanEval ë° MBPPëŠ” ê¸°ì¡´ì˜ ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ì´ê³ , HumanEval Pro ë° MBPP ProëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ê° ëª¨ë¸ì˜ HumanEval ë° MBPPì— ëŒ€í•œ 0-shot ë° 1-shot Pass@1 ì ìˆ˜ì™€ HumanEval Pro ë° MBPP Proì— ëŒ€í•œ 0-shot ë° 1-shot Pass@1 ì ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì˜ ì–´ë ¤ì›€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—¬ëŸ¬ ëª¨ë¸ë“¤ì´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ìê¸° í˜¸ì¶œ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Performance Comparison: HumanEval Pro (and MBPP Pro) vs. HumanEval (and MBPP).
> </details>



![](https://arxiv.org/html/2412.21199/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê¸°ì¡´ HumanEval ë° MBPP ë²¤ì¹˜ë§ˆí¬ì™€ ìƒˆë¡­ê²Œ ì œì•ˆëœ HumanEval Pro ë° MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•œ ì‚°ì ë„ì…ë‹ˆë‹¤. xì¶•ì€ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬(HumanEval, MBPP)ì—ì„œì˜ ì •í™•ë„ë¥¼, yì¶•ì€ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬(HumanEval Pro, MBPP Pro)ì—ì„œì˜ ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê° ì ì€ íŠ¹ì • ì–¸ì–´ ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ë©°, ìƒ‰ê¹”ì€ ê¸°ë³¸ ëª¨ë¸(base model)ê³¼ ì§€ì‹œì‚¬í•­ íŠœë‹ ëª¨ë¸(instruction-tuned model)ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì„ í†µí•´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë˜ ëª¨ë¸ë“¤ë„ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„±(self-invoking code generation) ì‘ì—…ì—ì„œëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì €í•˜ë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ì§€ì‹œì‚¬í•­ íŠœë‹ì´ ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì œí•œì ì„ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: HumanEval (or MBPP) scores against the results on HumanEval Pro and MBPP Pro (HumanEval+ and MBPP+). We presents the comparison between base model and instruct model.
> </details>



![](https://arxiv.org/html/2412.21199/x5.png)

> ğŸ”¼ ê·¸ë¦¼ì€ HumanEval ë° MBPPì™€ HumanEval Pro ë° MBPP Proì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” í˜¼ë™ í–‰ë ¬ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. íŠ¹íˆ Qwen2.5-Coder-7B-base ëª¨ë¸ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  HumanEval ë° MBPPì—ì„œ ì„±ê³µí–ˆì§€ë§Œ HumanEval Pro ë° MBPP Proì—ì„œëŠ” ì‹¤íŒ¨í•œ ìƒ˜í”Œì˜ ìˆ˜ë¥¼ ë³´ì—¬ì£¼ëŠ” í˜¼ë™ í–‰ë ¬ì„ í†µí•´ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì˜ ì–´ë ¤ì›€ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë‹¨ì¼ ê¸°ëŠ¥ ì½”ë“œ ìƒì„±ì—ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ, ìì²´ ìƒì„± í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë³´ë‹¤ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Qwen2.5-Coder-7B-base
> </details>



![](https://arxiv.org/html/2412.21199/x6.png)

> ğŸ”¼ ê·¸ë¦¼ì€ HumanEval Proì™€ MBPP Proì—ì„œ Qwen2.5-Coder-32B-base ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” í˜¼ë™ í–‰ë ¬(confusion matrix)ì…ë‹ˆë‹¤.  ê° ì…€ì€ HumanEval ë˜ëŠ” MBPPì—ì„œ ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ì™€ HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œ ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ì— ë”°ë¥¸ ìƒ˜í”Œ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬(HumanEval, MBPP)ì—ì„œ ì„±ê³µí–ˆì§€ë§Œ, ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…(HumanEval Pro, MBPP Pro)ì—ì„œëŠ” ì‹¤íŒ¨í•œ ìƒ˜í”Œì˜ ìˆ˜ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Qwen2.5-Coder-32B-base
> </details>



![](https://arxiv.org/html/2412.21199/x7.png)

> ğŸ”¼ ê·¸ë¦¼ì€ HumanEval Proì™€ MBPP Proì—ì„œ Qwen2.5-Coder-7B-instruct ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” í˜¼ë™ í–‰ë ¬(confusion matrix)ì…ë‹ˆë‹¤.  í–‰ì€ HumanEval ë˜ëŠ” MBPPì—ì„œì˜ ê²°ê³¼(í†µê³¼/ì‹¤íŒ¨), ì—´ì€ HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œì˜ ê²°ê³¼(í†µê³¼/ì‹¤íŒ¨)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ì…€ì˜ ìˆ«ìëŠ” í•´ë‹¹ ë²”ì£¼ì— ì†í•˜ëŠ” ìƒ˜í”Œì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë¹„ìœ¨ì€ ê´„í˜¸ ì•ˆì— í‘œì‹œë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ì„±ê³µí•˜ì§€ë§Œ, ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì—ì„œëŠ” ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°(Failed, Passed)ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë˜í•œ, ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì™€ ìì²´ í˜¸ì¶œ ë²¤ì¹˜ë§ˆí¬ ëª¨ë‘ì—ì„œ ì„±ê³µí•˜ê±°ë‚˜ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ê°•ì ê³¼ ì•½ì ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (c) Qwen2.5-Coder-7B-instruct
> </details>



![](https://arxiv.org/html/2412.21199/x8.png)

> ğŸ”¼ ê·¸ë¦¼ (d)ëŠ” HumanEval Pro ë° MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ Qwen2.5-Coder-32B-instruct ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” í˜¼ë™ í–‰ë ¬(Confusion Matrix)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ì…€ì€ HumanEval ë˜ëŠ” MBPPì™€ HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œì˜ ë¬¸ì œ í†µê³¼/ì‹¤íŒ¨ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìƒ˜í”Œì˜ ê°œìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ì˜ ìˆ˜í–‰í•˜ì§€ë§Œ, ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì—ì„œëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ HumanEval ë˜ëŠ” MBPPì—ì„œëŠ” ì„±ê³µí•œ ìƒ˜í”Œì˜ ë¹„ìœ¨ì´ ëˆˆì— ë„ê²Œ ë†’ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (d) Qwen2.5-Coder-32B-instruct
> </details>



![](https://arxiv.org/html/2412.21199/x9.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ í˜¼ë™ í–‰ë ¬ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. HumanEval ë˜ëŠ” MBPPì—ì„œ ì„±ê³µí–ˆì§€ë§Œ HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œëŠ” ì‹¤íŒ¨í•œ ìƒ˜í”Œë“¤ì„ (ì‹¤íŒ¨, ì„±ê³µ)ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤. ê° í–‰ë ¬ì€ íŠ¹ì • ëª¨ë¸ì˜ HumanEval Pro ë° MBPP Proì—ì„œì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°,  ê° ì…€ì€ HumanEval ë˜ëŠ” MBPPì—ì„œì˜ ê²°ê³¼ì™€ HumanEval Pro ë˜ëŠ” MBPP Proì—ì„œì˜ ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ê¸°ì¡´ì˜ ì½”ë“œ ìƒì„± ë¬¸ì œì—ì„œëŠ” ì˜ í•´ê²°í•˜ì§€ë§Œ, ìì²´ ìƒì„± ì½”ë“œë¥¼ í™œìš©í•˜ëŠ” ë³µì¡í•œ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ë¬¸ì œì—ì„œëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ì ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: The confusion matrix of different models. We use (Failed, Passed) to indicate samples that fail in HumanEval Pro (or MBPP Pro) but pass in HumanEval (or MBPP).
> </details>



![](https://arxiv.org/html/2412.21199/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ HumanEval Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ Chain-of-Thought (CoT) ì¶”ë¡ ì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œ GPT-40 ëª¨ë¸ì˜ ì˜¤ë¥˜ ìœ í˜• ë¶„í¬ë¥¼ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. CoT ì¶”ë¡ ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œì™€ ë¹„êµí•˜ì—¬ CoT ì¶”ë¡ ì„ ì‚¬ìš©í–ˆì„ ë•Œ íŠ¹ì • ì˜¤ë¥˜ ìœ í˜•(ì˜ˆ: AssertionError)ì˜ ë°œìƒ ë¹ˆë„ê°€ ê°ì†Œí•œ ê²ƒì„ ë³´ì—¬ì£¼ì–´, CoT ì¶”ë¡ ì´ ì½”ë“œ ìƒì„±ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Error types of GPT-4o with and without CoT reasoning on HumanEval Pro.
> </details>



![](https://arxiv.org/html/2412.21199/x11.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì˜¤ë¥˜ ìœ í˜• í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ë²¤ì¹˜ë§ˆí¬ì˜ ëª¨ë“  ì˜¤ë¥˜ ìœ í˜•ì„ í•©ì‚°í•˜ì—¬ ê° ëª¨ë¸ì˜ ì˜¤ë¥˜ ë°œìƒ ë¹ˆë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.  ìì„¸í•œ ì˜¤ë¥˜ ìˆ˜ëŠ” í‘œ 9ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.  AssertionError, NameError, ValueError, IndexError, TypeError ë° ê¸°íƒ€ ì˜¤ë¥˜ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìœ í˜•ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ì–´, ê° ëª¨ë¸ì˜ ì„±ëŠ¥ ë° ì·¨ì•½ì ì„ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  HumanEval Proì™€ MBPP Pro ëª¨ë‘ì—ì„œ ê°€ì¥ ë§ì€ ì˜¤ë¥˜ ìœ í˜•ì€ AssertionErrorì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Statistics of error type across different LLMs on HumanEval Pro and MBPP Pro. We sum up all kinds of errors on the two benchmarks. Exact number is shown in TableÂ 9.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | Params | HumanEval (+) | HumanEval Pro (0-shot) | HumanEval Pro (1-shot) | MBPP (+) | MBPP Pro (0-shot) | MBPP Pro (1-shot) |
|---|---|---|---|---|---|---|---| 
| **Proprietary Models** |  |  |  |  |  |  |  |
| o1-mini | - | 97.6 (90.2) | 76.2 | 84.8 | 93.9 (78.3) | 68.3 | 81.2 |
| GPT-4o | - | 90.2 (86.0) | 75.0 | 77.4 | 86.8 (72.5) | 70.9 | 80.2 |
| GPT-4-Turbo | - | 90.2 (86.6) | 72.0 | 76.2 | 85.7 (73.3) | 69.3 | 73.3 |
| Claude-3.5-sonnet | - | 92.1 (86.0) | 72.6 | 79.9 | 91.0 (74.6) | 66.4 | 76.2 |
| **Open-source Models** |  |  |  |  |  |  |  |
| Deepseek-V2.5 | - | 90.2 (83.5) | 73.8 | 76.8 | 87.6 (74.1) | 71.2 | 77.5 |
| DeepseekCoder-V2-instruct | 21/236B | 90.2 (84.8) | 77.4 | 82.3 | 89.4 (76.2) | 71.4 | 76.5 |
| Qwen2.5-Coder-1.5B-base | 1.5B | 43.9 (36.6) | 37.2 | 39.6 | 69.2 (58.6) | 48.4 | 51.3 |
| Qwen2.5-Coder-1.5B-instruct | 1.5B | 70.7 (66.5) | 33.5 | 37.8 | 69.2 (59.4) | 42.1 | 43.7 |
| DeepseekCoder-6.7B-base | 6.7B | 49.4 (39.6) | 35.4 | 36.6 | 70.2 (51.6) | 50.5 | 55.0 |
| DeepseekCoder-6.7B-instruct | 6.7B | 78.6 (71.3) | 55.5 | 61.6 | 74.9 (65.6) | 57.1 | 58.2 |
| Magicoder-S-DS-6.7B | 6.7B | 76.8 (70.7) | 54.3 | 56.7 | 75.7 (64.4) | 58.7 | 64.6 |
| WaveCoder-Ultra-6.7B | 6.7B | 78.6 (69.5) | 54.9 | 59.8 | 74.9 (63.5) | 60.1 | 64.6 |
| Qwen2.5-Coder-7B-base | 7B | 61.6 (53.0) | 54.9 | 56.1 | 76.9 (62.9) | 61.4 | 68.0 |
| Qwen2.5-Coder-7B-instruct | 7B | 88.4 (84.1) | 65.9 | 67.1 | 83.5 (71.7) | 64.8 | 69.8 |
| OpenCoder-8B-base | 8B | 66.5 (63.4) | 39.0 | 42.1 | 79.9 (70.4) | 52.4 | 53.7 |
| OpenCoder-8B-instruct | 8B | 83.5 (78.7) | 59.1 | 54.9 | 79.1 (69.0) | 57.9 | 61.4 |
| Yi-Coder-9B-base | 9B | 53.7 (46.3) | 42.7 | 50.0 | 78.3 (64.6) | 60.3 | 61.4 |
| Yi-Coder-9B-chat | 9B | 85.4 (74.4) | 59.8 | 64.0 | 81.5 (69.3) | 64.8 | 71.7 |
| Codestral-22B-v0.1 | 22B | 81.1 (73.2) | 59.1 | 65.9 | 78.2 (62.2) | 63.8 | 71.2 |
| DeepseekCoder-33B-base | 33B | 56.1 (47.6) | 49.4 | 49.4 | 74.2 (60.7) | 59.0 | 65.1 |
| DeepseekCoder-33B-instruct | 33B | 79.3 (75.0) | 56.7 | 62.8 | 80.4 (70.1) | 64.0 | 68.3 |
| Qwen2.5-Coder-32B-base | 32B | 65.9 (60.4) | 61.6 | 67.1 | 83.0 (68.2) | 67.7 | 73.3 |
| Qwen2.5-Coder-32B-instruct | 32B | 92.7 (87.2) | 70.1 | 80.5 | 90.2 (75.1) | 69.8 | 77.5 |
| LLaMA3-70B-instruct | 70B | 81.7 (72.0) | 60.4 | 64.6 | 82.3 (69.0) | 63.5 | 70.4 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ì£¼ìš” ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í‘œì—ëŠ” ê° ëª¨ë¸ì˜ HumanEval Proì™€ MBPP Proì—ì„œì˜ Pass@1, Pass@5, Pass@10 ì ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°,  ì†ŒìŠ¤ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ëœ ë§¤ê°œë³€ìˆ˜ ìˆ˜ì™€ ëª¨ë¸ ìœ í˜•(ë…ì  ëª¨ë¸, ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸)ë„ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤. ë³´ë‹¤ ìì„¸í•œ ê²°ê³¼ëŠ” ë¶€ë¡ Aì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ê·œëª¨ì™€ ì¢…ë¥˜ì˜ ì–¸ì–´ ëª¨ë¸ë“¤ì´ ì œì‹œëœ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Main result of different models on HumanEval Pro and MBPP Pro. More results is shown in AppendixÂ A.
> </details>

{{< table-caption >}}
| Error Type | Description | Examples |
|---|---|---|
| AssertionError | Failing to pass the test cases. | Examples in Section G.1 |
| NameError | The code includes undefined variables. | Examples in Section G.2 |
| ValueError | Unaware of the value of variables | Examples in Section G.3 |
| IndexError | Array out of bounds | Examples in Section G.4 |
| TypeError | Incorrect variable type usage. | Examples in Section G.5 |
| Other Errors | KeyError, SyntaxError, ZeroDivisionError, IndentationError, etc. | â€“ |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ëª¨ë¸ í‰ê°€ ê²°ê³¼ì— ë‚˜íƒ€ë‚œ ì‹¤í–‰ ì˜¤ë¥˜ì˜ ì¢…ë¥˜ì™€ ì„¤ëª…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì˜¤ë¥˜ ìœ í˜•(AssertionError, NameError, ValueError, IndexError, TypeError, ê¸°íƒ€ ì˜¤ë¥˜)ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬, ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ì˜ ì›ì¸ì„ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: The execution error types and their descriptions in our evaluation results.
> </details>

{{< table-caption >}}
| Model | CoT | HE Pro | MBPP Pro |
|---|---|---|---|
| GPT-4o | âœ˜ | 75.0 | 70.9 |
| GPT-4o | âœ” | 78.0 | 70.9 |
| DeepseekV2.5 | âœ˜ | 73.8 | 71.2 |
| DeepseekV2.5 | âœ” | 74.4 | 71.4 |
| Qwen2.5-Coder-32B-ins | âœ˜ | 70.1 | 69.8 |
| Qwen2.5-Coder-32B-ins | âœ” | 72.0 | 70.1 |
| Qwen2.5-Coder-7B-ins | âœ˜ | 65.9 | 64.8 |
| Qwen2.5-Coder-7B-ins | âœ” | 71.3 | 64.8 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ê²°ê³¼ì—ì„œ ë°œìƒí•œ ì‹¤í–‰ ì˜¤ë¥˜ì˜ ì¢…ë¥˜ì™€ ì„¤ëª…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì˜¤ë¥˜ ìœ í˜•(AssertionError, NameError, ValueError, IndexError, TypeError, ê¸°íƒ€ ì˜¤ë¥˜)ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ê³¼ í•¨ê»˜, ê° ì˜¤ë¥˜ ìœ í˜•ì´ ë‚˜íƒ€ë‚œ íšŸìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ëª¨ë¸ì˜ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ìˆì–´ì„œ ì–´ë–¤ ìœ í˜•ì˜ ì˜¤ë¥˜ê°€ ë” ìì£¼ ë°œìƒí•˜ëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: The execution error types and their descriptions in our evaluation results.
> </details>

{{< table-caption >}}
| Model | BCB-Lite | Pro (%) |
|---|---|---|
| GPT-4o | 64.9 | 52.6 |
| GPT4-Turbo | 61.4 | 52.6 |
| Claude-3.5-sonnet | 73.7 | 50.9 |
| DeepseekV2.5 | 80.7 | 50.9 |
| Qwen2.5Coder-1.5B-base | 50.9 | 15.8 |
| Qwen2.5Coder-1.5B-instruct | 50.9 | 10.5 |
| OpenCoder-8B-base | 56.1 | 10.5 |
| OpenCoder-8B-instruct | 75.4 | 22.8 |
| DeepseekCoder-6.7B-base | 59.6 | 35.1 |
| DeepseekCoder-6.7B-instruct | 56.1 | 35.1 |
| WaveCoder-Ultra-6.7B | 61.4 | 26.3 |
| Magicoder-S-DS-6.7B | 50.9 | 33.3 |
| Yi-Coder-9B | 57.9 | 21.1 |
| Yi-Coder-9B-Chat | 66.7 | 31.6 |
| Qwen2.5Coder-7B-base | 59.6 | 38.6 |
| Qwen2.5Coder-7B-instruct | 64.9 | 35.1 |
| DeepseekCoder-33B-base | 71.9 | 38.6 |
| DeepseekCoder-33B-instruct | 80.7 | 43.9 |
| Qwen2.5Coder-32B-base | 68.4 | 49.1 |
| Qwen2.5Coder-32B-instruct | 80.7 | 52.6 |
| Codestral-22B | 78.9 | 54.4 |
| QwQ-32B-preview | 86.0 | 59.6 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” BigCodeBench-Liteì™€ BCB-Lite-Proì— ëŒ€í•œ LLMsì˜ í†µê³¼ìœ¨(%)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  BCB-LiteëŠ” BigCodeBenchì—ì„œ ë¬¸ì œ í•´ê²° ì„±ê³µë¥ ì´ 50~70%ì¸ ë¬¸ì œ 57ê°œë¥¼ ì„ ë³„í•˜ì—¬ êµ¬ì„±ë˜ì—ˆê³ , ê° ë¬¸ì œì— ëŒ€í•´ ìì²´ í˜¸ì¶œ ë¬¸ì œì™€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì¶”ê°€í•˜ì—¬ BCB-Lite-Proë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. í‘œëŠ” ë‹¤ì–‘í•œ LLMsì˜ ë‘ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬, ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì— ë¹„í•´ ìì²´ í˜¸ì¶œ ì½”ë“œ ìƒì„± ì‘ì—…ì˜ ì–´ë ¤ì›€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  G.6ì ˆì—ì„œëŠ” BCB-Lite-Pro ë°ì´í„°ì…‹ì˜ ì˜ˆì‹œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Passing rate (%) of LLMs on BigCodeBench (BCB)-Lite and BCB-Lite-Pro. A dataset example of BCB-Lite-Pro is shown in SectionÂ G.6.
> </details>

{{< table-caption >}}
| Model | HumanEval Pro (0-shot) | MBPP Pro (0-shot) |
|---|---|---|
| LLaMA-3.1-8B-base | 25.0 | 36.5 |
| LLaMA-3.1-8B-instruct | 45.7 | 53.7 |
| LLaMA-3.1-70B-base | 40.9 | 57.4 |
| LLaMA-3.1-70B-instruct | 60.4 | 63.8 |
| Qwen-2.5-72B-base | 62.2 | 65.3 |
| Qwen-2.5-72B-instruct | 68.9 | 68.8 |
| QwQ-32B-preview | 72.0 | 67.5 |
| LLaMA-3.3-70B-instruct | 67.1 | 64.6 |
| Mistral-Large-instruct-2411 | 75.0 | 69.3 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  Greedy decoding ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ì—ˆìœ¼ë©°, HumanEval Proì™€ MBPP Proì—ì„œ ê° ëª¨ë¸ì˜ 0-shot(ì œë¡œìƒ·) ì„±ëŠ¥(pass@1)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ì—¬ëŸ¬ í‘œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.  ë‹¤ë¥¸ í‘œë“¤ê³¼ í•¨ê»˜ í•´ë‹¹ ëª¨ë¸ì˜ ì½”ë“œ ìƒì„± ëŠ¥ë ¥, íŠ¹íˆ ìê¸° í˜¸ì¶œ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Results of Other LLMs on HumanEval Pro and MBPP Pro (greedy decoding).
> </details>

{{< table-caption >}}
| Model | HumanEval Pro pass@1 | HumanEval Pro pass@5 | HumanEval Pro pass@10 | MBPP Pro pass@1 | MBPP Pro pass@5 | MBPP Pro pass@10 |
|---|---|---|---|---|---|---|
| DeepseekCoder-6.7B-base | 38.0 | 50.9 | 54.7 | 51.6 | 60.4 | 63.1 |
| DeepseekCoder-6.7B-instruct | 55.9 | 64.1 | 66.5 | 55.2 | 62.6 | 64.9 |
| Magicoder-S-DS-6.7B | 55.1 | 62.7 | 65.1 | 57.7 | 64.9 | 67.2 |
| WaveCoder-Ultra-6.7B | 55.7 | 61.4 | 63.0 | 58.2 | 64.4 | 66.3 |
| DeepseekCoder-33B-base | 49.4 | 60.8 | 65.2 | 59.1 | 67.2 | 69.3 |
| DeepseekCoder-33B-instruct | 59.1 | 68.6 | 71.3 | 63.4 | 70.6 | 72.9 |
| Qwen2.5-Coder-7B-base | 51.8 | 62.1 | 66.2 | 61.3 | 69.9 | 72.3 |
| Qwen2.5-Coder-7B-instruct | 65.7 | 72.5 | 75.0 | 64.2 | 70.5 | 72.6 |
| OpenCoder-9B-base | 44.5 | 56.2 | 59.9 | 54.8 | 62.9 | 65.0 |
| OpenCoder-9B-instruct | 59.8 | 68.5 | 70.8 | 58.1 | 63.7 | 65.1 |
| Yi-Coder-9B-base | 47.9 | 59.0 | 61.9 | 59.6 | 67.7 | 69.7 |
| Yi-Coder-9B-chat | 59.7 | 66.4 | 67.9 | 65.0 | 69.8 | 71.2 |
| Codestral-22B | 59.5 | 66.2 | 67.7 | 63.2 | 67.7 | 68.9 |
| Qwen2.5-Coder-32B-base | 62.4 | 70.3 | 72.2 | 67.6 | 75.0 | 76.9 |
| Qwen2.5-Coder-32B-instruct | 69.2 | 72.3 | 73.3 | 70.6 | 74.7 | 76.0 |
| QwQ-32B-preview | 70.9 | 77.7 | 79.5 | 67.0 | 73.0 | 74.5 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë¬¸ì œì— ëŒ€í•´ ì˜¨ë„ 0.2, top_p 0.95ì˜ ëœë¤ ìƒ˜í”Œë§ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ 20ê°œì˜ ìƒ˜í”Œì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. í‘œì—ëŠ” ê° ëª¨ë¸ì˜ HumanEval Proì™€ MBPP Proì— ëŒ€í•œ pass@1, pass@5, pass@10 ì ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê° ë¬¸ì œì— ëŒ€í•œ ì •ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì„±ê³µí•œ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: The results of different models on HumanEval Pro and MBPP Pro . We generate 20 samples for each problems with random sampling strategy where temperature is set to 0.2 and top_p is set to 0.95.
> </details>

{{< table-caption >}}
| Model Name | API Name |
|---|---| 
| O1-mini | `o1-mini-2024-09-12` |
| GPT-4o | `gpt-4o-2024-08-06` |
| GPT-4-Turbo | `gpt-4-turbo-2024-04-09` |
| Claude-3.5-sonnet | `claude-3-5-sonnet-20241022` |
| Deepseek-V2.5 | `deepseek-chat` |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ ë…¼ë¬¸ì˜ í‘œ 2ì— ë‚˜ì—´ëœ í‰ê°€ ëŒ€ìƒ ëª¨ë¸ë“¤ì— ëŒ€í•œ API ì´ë¦„ê³¼ HuggingFace ëª¨ë¸ URLì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë” ìì„¸íˆ ì„¤ëª…í•˜ìë©´, ê° ëª¨ë¸ì˜ ê³ ìœ  ì‹ë³„ì(API ì´ë¦„)ì™€ ëª¨ë¸ ì ‘ê·¼ì„ ìœ„í•œ HuggingFace ì €ì¥ì†Œ ì£¼ì†Œ(URL)ê°€ ë§¤í•‘ë˜ì–´ ìˆì–´,  ì—°êµ¬ì˜ ì¬í˜„ì„±ì„ ë†’ì´ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.  ì´ ì •ë³´ë¥¼ í†µí•´ ì—°êµ¬ìë“¤ì€ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë™ì¼í•œ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ì„ ë°˜ë³µí•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: The corresponding API names and HuggingFace model URLs for the evaluated models are listed in TableÂ 2.
> </details>

{{< table-caption >}}
| Model Name | HuggingFace URL |
|---|---| 
| DeepseekCoder-V2-instruct | https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct |
| Qwen2.5-Coder-1.5B-base | https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B |
| Qwen2.5-Coder-1.5B-instruct | https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct |
| DeepseekCoder-6.7B-base | https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base |
| DeepseekCoder-6.7B-instruct | https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct |
| Magicoder-S-DS-6.7B | https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B |
| WaveCoder-Ultra-6.7B | https://huggingface.co/microsoft/wavecoder-ultra-6.7b |
| Qwen2.5-Coder-7B-base | https://huggingface.co/Qwen/Qwen2.5-Coder-7B |
| Qwen2.5-Coder-7B-instruct | https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct |
| OpenCoder-8B-base | https://huggingface.co/infly/OpenCoder-8B-Base |
| OpenCoder-8B-instruct | https://huggingface.co/infly/OpenCoder-8B-Instruct |
| Yi-Coder-9B-base | https://huggingface.co/01-ai/Yi-Coder-9B |
| Yi-Coder-9B-chat | https://huggingface.co/01-ai/Yi-Coder-9B-Chat |
| Codestral-22B-v0.1 | https://huggingface.co/mistralai/Codestral-22B-v0.1 |
| DeepseekCoder-33B-base | https://huggingface.co/deepseek-ai/deepseek-coder-33b-base |
| DeepseekCoder-33B-instruct | https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct |
| Qwen2.5-Coder-32B-base | https://huggingface.co/Qwen/Qwen2.5-Coder-32B |
| Qwen2.5-Coder-32B-instruct | https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct |
| LLaMA3-70B-instruct | https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct |
| QwQ-32B-Preview | https://huggingface.co/Qwen/QwQ-32B-Preview |
| LLaMA3.1-8B-base | https://huggingface.co/meta-llama/Llama-3.1-8B |
| LLaMA3.1-8B-instruct | https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct |
| LLaMA3.1-70B-base | https://huggingface.co/meta-llama/Llama-3.1-70B |
| LLaMA3.1-70B-instruct | https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct |
| Qwen2.5-72B-base | https://huggingface.co/Qwen/Qwen2.5-72B |
| Qwen2.5-72B-instruct | https://huggingface.co/Qwen/Qwen2.5-72B-Instruct |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” HumanEval Proì™€ MBPP Pro ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ì˜ ì˜¤ë¥˜ ìœ í˜•ë³„ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ëª¨ë¸ì— ëŒ€í•´ HumanEval Proì™€ MBPP Proì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ì˜ ìˆ˜ë¥¼ Assertion Error, Name Error, ValueError, IndexError, TypeError, ê¸°íƒ€ ì˜¤ë¥˜ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë” ì˜ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ìì„¸í•œ ì˜¤ë¥˜ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Error type of Different Models on HumanEval Pro and MBPP Pro.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}