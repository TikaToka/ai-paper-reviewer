[{"content": "| LongBench V2 | Overall | Easy | Hard | Short | Medium | Long |\n|---|---|---|---|---|---|---|\n| Standard 25K | 28.4 | 30.2 | 27.3 | 33.9 | 25.1 | 25.9 |\n| Chunked Prefill 30K | 28.2 | 27.1 | 28.9 | 32.8 | 25.6 | 25.9 |\n| Layer-wise offload 45K | 29.0 | 29.2 | 28.9 | 36.1 | 24.2 | 26.9 |\n| HeadInfer 1024K | 30.2 | 31.2 | 29.6 | 33.9 | 27.0 | 30.6 |", "caption": "Table 1: Performance(benchmark score) of different methods on LongBench v2 on a single RTX-4090 GPU, under different task difficulties (Easy/Hard) and context lengths (Short/Medium/Long). Overall performance is average scores on all questions.", "description": "\uc774 \ud45c\ub294 LongBench v2 \ubca4\uce58\ub9c8\ud06c\ub97c \uc0ac\uc6a9\ud558\uc5ec RTX 4090 GPU\uc5d0\uc11c \ub2e4\uc591\ud55c \ubc29\ubc95(\ud45c\uc900 \ucd94\ub860, \uccad\ud06c \uc0ac\uc804 \ucc44\uc6b0\uae30, \uacc4\uce35\ubcc4 \uc624\ud504\ub85c\ub4dc, HEADINFER)\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uacfc\uc81c \ub09c\uc774\ub3c4(\uc26c\uc6c0/\uc5b4\ub824\uc6c0)\uc640 \ubb38\ub9e5 \uae38\uc774(\uc9e7\uc74c/\uc911\uac04/\uae40)\ub97c \ubcc0\uc218\ub85c \ud558\uc5ec \ubca4\uce58\ub9c8\ud06c \uc810\uc218\ub97c \uce21\uc815\ud558\uc600\uc73c\uba70, \uc804\uccb4 \uc131\ub2a5\uc740 \ubaa8\ub4e0 \uc9c8\ubb38\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubb38\ub9e5 \uae38\uc774\uc640 \ub09c\uc774\ub3c4\uc5d0\uc11c \uac01 \ubc29\ubc95\uc758 \uc0c1\ub300\uc801 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec HEADINFER\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6. \uc131\ub2a5 \ud3c9\uac00"}, {"content": "| SCBench | kv | prefix-suffix | vt | qa-chn | qa-eng | choice-eng | mf | many-shot | summary |\n|---|---|---|---|---|---|---|---|---|---| \n| Standard 25K | 15.8 | 9.6 | 4.6 | 9.4 | 13.3 | 36.5 | 2.6 | 16.3 | 32.3 |\n| Chunked Prefill 30K | 21.4 | 10.4 | 6.9 | 9.4 | 15.5 | 38.6 | 2.2 | 25.2 | 33.5 |\n| Layer-wise offload 45K | 22.6 | 12.8 | 8.4 | 10.4 | 15.7 | 37.8 | 2.2 | 25.9 | 33.6 |\n| **HeadInfer** 1024K | **28** | **17.2** | **42** | **11.9** | **23.0** | **59.8** | **9.4** | **25.9** | **37.1** |", "caption": "Table 2: Performance(benchmark score) of different methods on SCBench on a single RTX-4090 GPU. kv and prefix-suffix are string retrieval in key-value and prefix-suffix scenarios. vt is variable tracking. qa-chn, qa-eng, and choice-eng are English/Chinese question answering. mf is finding the math answer. many-shot is finding multiple shots in context. summary is document summarization.", "description": "\ud45c 2\ub294 \ub2e8\uc77c RTX 4090 GPU\uc5d0\uc11c \ub2e4\uc591\ud55c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec SCBench \ubca4\uce58\ub9c8\ud06c\ub97c \uc218\ud589\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc5f4\uc740 \ud2b9\uc815 \uc791\uc5c5 \uc720\ud615\uc758 \uc131\ub2a5 \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  kv \ubc0f prefix-suffix\ub294 \ud0a4-\uac12 \ubc0f \uc811\ub450\uc0ac-\uc811\ubbf8\uc0ac \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \ubb38\uc790\uc5f4 \uac80\uc0c9 \uc791\uc5c5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. vt\ub294 \ubcc0\uc218 \ucd94\uc801 \uc791\uc5c5, qa-chn \ubc0f qa-eng\ub294 \uac01\uac01 \uc911\uad6d\uc5b4 \ubc0f \uc601\uc5b4 \uc9c8\ubb38 \ub2f5\ubcc0 \uc791\uc5c5, choice-eng\ub294 \uc601\uc5b4 \uc120\ud0dd\ud615 \uc9c8\ubb38 \ub2f5\ubcc0 \uc791\uc5c5, mf\ub294 \uc218\ud559 \ubb38\uc81c \ud480\uc774 \uc791\uc5c5, many-shot\uc740 \ubb38\ub9e5 \ub0b4\uc5d0\uc11c \uc5ec\ub7ec \uc0f7\uc744 \ucc3e\ub294 \uc791\uc5c5, summary\ub294 \ubb38\uc11c \uc694\uc57d \uc791\uc5c5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ud45c\ub294 \ub2e4\uc591\ud55c \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774(25K, 30K, 45K, 1024K \ud1a0\ud070)\uc5d0 \ub300\ud55c \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uc5b4\ub5a4 \ubc29\ubc95\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc7a5\ubb38 \uc774\ud574 \uc791\uc5c5\uc5d0\uc11c \uac00\uc7a5 \ud6a8\uc728\uc801\uc778\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6. \uc131\ub2a5 \ud3c9\uac00"}, {"content": "| Context Length | Llama-3-8B | Llama-2-7B | Mistral-7B | Qwen2-7B | Gemma-2-9b |\n|---|---|---|---|---|---| \n| Standard | 25K | 10K | 30K | 35K | 10K |\n| Chunked Prefill | 30K | 20K | 40K | 70K | 10K |\n| 4-bit KV-quant | 45K | 30K | 40K | 50K | 20K |\n| Layer-wise offload | 45K | 60K | 45K | 50K | 35K |\n| **HeadInfer** | **4096K** | **1024K** | **4096K** | **4200K** | **1300K** |", "caption": "Table 3: Comparison of maximum context length with system optimization methods on various models inference. All experiments within this table run on a single RTX-4090 GPU with 24GB and AMD EPYC 7V12 CPUs with 1TB memory.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \ubaa8\ub378 \ucd94\ub860\uc5d0\uc11c \uc2dc\uc2a4\ud15c \ucd5c\uc801\ud654 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud55c \ucd5c\ub300 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\ub97c \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\uc5d0 \uc788\ub294 \ubaa8\ub4e0 \uc2e4\ud5d8\uc740 24GB\uc758 \uba54\ubaa8\ub9ac\ub97c \uac00\uc9c4 \ub2e8\uc77c RTX-4090 GPU\uc640 1TB \uba54\ubaa8\ub9ac\ub97c \uac00\uc9c4 AMD EPYC 7V12 CPU\uc5d0\uc11c \uc2e4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ud45c\uc900 \ucd94\ub860, \uccad\ud06c \ucc44\uc6b0\uae30, \uacc4\uce35\ubcc4 \uc624\ud504\ub85c\ub4dc, HEADINFER\uc758 \ub124 \uac00\uc9c0 \ubc29\ubc95\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \ucd5c\ub300 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec HEADINFER\uac00 \uac00\uc7a5 \uae34 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\ub97c \uc9c0\uc6d0\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Context Length | Llama-3-70B |\n|---|---| \n| Standard | 10K |\n| **HeadInfer**<span class=\"ltx_text ltx_font_upright\"> + 10k chunk size</span> | **950K** |\n| **HeadInfer**<span class=\"ltx_text ltx_font_upright\"> + 5k chunk size</span> | **1000K** |", "caption": "Table 4:  Llama3-70B Inference with long context input.", "description": "\ud45c 4\ub294 \uae34 \uc785\ub825 \ucee8\ud14d\uc2a4\ud2b8\ub97c \uc0ac\uc6a9\ud55c Llama3-70B \ubaa8\ub378 \ucd94\ub860 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ud45c\uc900 \ucd94\ub860, HEADINFER \ubc0f HEADINFER\uc758 \ub2e4\uc591\ud55c \uccad\ud06c \ud06c\uae30 \ubcc0\ud615\uc744 \uc0ac\uc6a9\ud55c \ucd94\ub860 \uacb0\uacfc\uc758 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774(\ud1a0\ud070 \uc218)\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.  HEADINFER\ub294 \uae34 \ucee8\ud14d\uc2a4\ud2b8 \ucd94\ub860\uc5d0\uc11c \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, 10K \uccad\ud06c \ud06c\uae30\ub97c \uc0ac\uc6a9\ud55c HEADINFER\ub294 950K \ud1a0\ud070\uc758 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\ub97c \ub2ec\uc131\ud558\uace0, 5K \uccad\ud06c \ud06c\uae30\ub85c\ub294 1000K \ud1a0\ud070\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "6. \uc131\ub2a5 \ud3c9\uac00"}, {"content": "| Context Length | Llama-3-8B |\n|---|---| \n| Standard | 25K |\n| Layer-wise Offload | 45K |\n| Chunked Prefill | 30K |\n| HeadInfer Head=8 Group = 1 | 550K |\n| HeadInfer Head=4 Group = 2 | 1100K |\n| HeadInfer Head=2 Group = 4 | 2100K |\n| **HeadInfer** | **4096K** |", "caption": "Table 5:  Ablation study of HeadInfer on Llama-3-8B.", "description": "\ud45c 5\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 HeadInfer \ubaa8\ub378\uc758 \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud574 Llama-3-8B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  HeadInfer \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \uad6c\uc131 \uc694\uc18c(sequence, layer, head)\ub4e4\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uae30 \uc704\ud55c ablation study \uacb0\uacfc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uad6c\uc131 \uc694\uc18c\ubcc4 granularity\ub97c \uc870\uc808\ud558\uba70 context length \ud655\uc7a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec HeadInfer \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uacfc \ud655\uc7a5\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c context \uae38\uc774\uc5d0 \ub300\ud55c \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \uc218\uce58\ub85c \ub098\ud0c0\ub0b4\uc5b4 HeadInfer\uac00 \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc5d0 \ube44\ud574 \uc5bc\ub9c8\ub098 \ud6a8\uacfc\uc801\uc73c\ub85c context length\ub97c \ud655\uc7a5\ud560 \uc218 \uc788\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "7. Ablation Study"}, {"content": "| Prefill Latency(s) | 1K | 10K | 20K | 40K | 100K | 200K | 400K | 1M | 2M | 4M |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Standard | 0.11 | 1.23 | 2.83 | - | - | - | - | - | - | - |\n| Chunked Prefill | 0.11 | 1.23 | 2.83 | - | - | - | - | - | - | - |\n| Layer-offload | 0.12 | 1.24 | 2.84 | 6.93 | - | - | - | - | - | - |\n| HeadInfer (head=8/group=1) | 0.12 | 1.24 | 2.84 | 7.11 | 30.2 | 100 | 357 | - | - | - |\n| HeadInfer (head=4/group=2) | 0.13 | 1.23 | 2.89 | 7.26 | 30.2 | 99 | 351 | 2033 | - | - |\n| HeadInfer (head=2/group=4) | 0.14 | 1.23 | 2.94 | 7.54 | 30.5 | 100 | 353 | 2035 | 7952 | - |\n| HeadInfer (head=1/group=8) | 0.21 | 1.27 | 3.06 | 7.77 | 31.2 | 101 | 356 | 2054 | 7975 | 27114 |\n| HeadInfer Adaptive | 0.13 | 1.24 | 2.84 | 7.11 | 30.2 | 99 | 351 | 2033 | 7952 | 27114 |", "caption": "Table 6: Prefill overhead (in seconds) of Llama3-8B under different context lengths.", "description": "\ud45c 6\uc740 \ub2e4\uc591\ud55c \ubb38\ub9e5 \uae38\uc774\uc5d0 \ub530\ub978 Llama-3-8B \ubaa8\ub378\uc758 prefill \uc624\ubc84\ud5e4\ub4dc(\ucd08 \ub2e8\uc704)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\ub294 \ud45c\uc900, \uccad\ud06c \uc0ac\uc804 \ucc44\uc6b0\uae30, \uacc4\uce35 \uc624\ud504\ub85c\ub529, HEADINFER \ubc0f HEADINFER \uc801\uc751\ud615 \ubc29\ubc95\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec \uac00\uc9c0 \ubc29\ubc95\uc5d0 \ub300\ud55c prefill \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubb38\ub9e5 \uae38\uc774(1K, 10K, 20K, 40K, 100K, 200K, 400K, 1M, 2M, 4M \ud1a0\ud070)\uc5d0 \ub300\ud55c \uac01 \ubc29\ubc95\uc758 prefill \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec,  HEADINFER\uac00 \ud2b9\ud788 \uae34 \ubb38\ub9e5\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ud6a8\uc728\uc801\uc778\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. HEADINFER\ub97c \uc0ac\uc6a9\ud55c \uba54\ubaa8\ub9ac \ud6a8\uc728\uc801\uc778 \ucd94\ub860"}, {"content": "| Decoding Latency(s) | 1K | 10K | 20K | 40K | 100K | 200K | 400K | 1M | 2M | 4M |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Standard | 0.03 | 0.03 | 0.03 | 0.04 | - | - | - | - | - | - |\n| Chunked Prefill | 0.03 | 0.03 | 0.03 | 0.04 | - | - | - | - | - | - |\n| Layer-offload | 0.03 | 0.09 | 0.17 | 0.28 | 0.66 | 1.3 | 2.58 | - | - | - |\n| HeadInfer (head=8/group=1) | 0.03 | 0.09 | 0.17 | 0.28 | 0.66 | 1.3 | 2.58 | - | - | - |\n| HeadInfer (head=4/group=2) | 0.04 | 0.10 | 0.16 | 0.28 | 0.67 | 1.31 | 2.58 | 6.41 | - | - |\n| HeadInfer (head=2/group=4) | 0.06 | 0.11 | 0.17 | 0.30 | 0.68 | 1.32 | 2.59 | 6.46 | 13.7 | - |\n| HeadInfer (head=1/group=8) | 0.10 | 0.14 | 0.21 | 0.33 | 0.71 | 1.33 | 2.61 | 6.51 | 13.8 | 27.2 |\n| HeadInfer Adaptive | 0.03 | 0.09 | 0.17 | 0.28 | 0.66 | 1.73 | 3.03 | 6.41 | 13.7 | 27.2 |", "caption": "Table 7: Decoding overhead (in seconds per generated token) of Llama3-8B under different KV cache (context) sizes.", "description": "\ud45c 7\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 KV \uce90\uc2dc(\ucee8\ud14d\uc2a4\ud2b8)\uc5d0\uc11c Llama3-8B \ubaa8\ub378\uc758 \ub514\ucf54\ub529 \uc624\ubc84\ud5e4\ub4dc(\ucd08\ub2f9 \uc0dd\uc131\ub41c \ud1a0\ud070)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\ub294 \ud45c\uc900 \ubc29\uc2dd, \uccad\ud06c \uc804\ucc98\ub9ac, \uacc4\uce35\ubcc4 \uc624\ud504\ub85c\ub529, HEADINFER \ubc0f \uc801\uc751\ud615 HEADINFER\ub97c \ud3ec\ud568\ud55c \uc5ec\ub7ec \uac00\uc9c0 \ubc29\ubc95\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc5d0 \ub300\ud55c \ucd08\ub2f9 \uc0dd\uc131 \ud1a0\ud070 \uc218\uac00 1K, 10K, 20K, 40K, 100K, 200K, 400K, 1M, 2M, 4M \ud1a0\ud070\uc758 \ub2e4\uc591\ud55c \ucee8\ud14d\uc2a4\ud2b8 \ud06c\uae30\uc5d0 \ub300\ud574 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc11c\ub85c \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc774 \uae34 \ucee8\ud14d\uc2a4\ud2b8\uc5d0\uc11c \uc5b4\ub5bb\uac8c \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uba54\ubaa8\ub9ac \ud6a8\uc728\uc801\uc778 \ucd94\ub860\uc744 \uc704\ud55c HEADINFER"}, {"content": "| Method | Supported Sequence Length within Ruler |\n|---|---| \n| Standard Inference | 16K |\n| Chunked-Prefill | 32K |\n| Layer-wise Offload | 32K |\n| HeadInfer | 128K |", "caption": "Table 8: Maximum achievable sequence lengths for different inference methods", "description": "\ud45c 8\uc740 Ruler \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \ucd94\ub860 \ubc29\ubc95\uc5d0 \ub300\ud574 \ub2ec\uc131 \uac00\ub2a5\ud55c \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc900 \ucd94\ub860\uc740 \uba54\ubaa8\ub9ac \uc81c\uc57d\uc73c\ub85c \uc778\ud574 16K \ud1a0\ud070\uc73c\ub85c \uc81c\ud55c\ub418\ub294 \ubc18\uba74, \uccad\ud06c \uc0ac\uc804 \ucc44\uc6b0\uae30\uc640 \uacc4\uce35\uc801 \uc624\ud504\ub85c\ub4dc\ub294 \uac01\uac01\uc758 \ucd5c\uc801\ud654 \uc804\ub7b5\uc744 \ud1b5\ud574 \uc774\ub97c \ub450 \ubc30\uc778 32K \ud1a0\ud070\uc73c\ub85c \ud655\uc7a5\ud569\ub2c8\ub2e4. HEADINFER\ub294 \ub2e4\ub978 \uc624\ud504\ub85c\ub4dc \ubc29\ubc95\ubcf4\ub2e4 4\ubc30 \ud5a5\uc0c1\ub41c 128K \ud1a0\ud070\uc73c\ub85c \uc2dc\ud000\uc2a4 \ucc98\ub9ac\ub97c \uac00\ub2a5\ud558\uac8c \ud558\uc5ec \uc0c1\ub2f9\ud55c \ubc1c\uc804\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc2dc\ud000\uc2a4 \uae38\uc774 \ud655\uc7a5\uc740 HEADINFER\uc758 \uc0c8\ub85c\uc6b4 \ud5e4\ub4dc\ubcc4 \uc624\ud504\ub85c\ub4dc \uc804\ub7b5\uc744 \ud1b5\ud574 \ub354\uc6b1 \ud6a8\uc728\uc801\uc73c\ub85c GPU \uba54\ubaa8\ub9ac\ub97c \uad00\ub9ac\ud558\uae30 \ub54c\ubb38\uc5d0 \uac00\ub2a5\ud569\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Context | NIAH | MK-2 | MK-3 | VT | CWE | FWE | QA-1 | QA-2 |\n|---|---|---|---|---|---|---|---|---|\n| Length | (%) | (%) | (%) | (%) | (%) | (%) | (%) | (%) |\n| 4K | 100.0 | 99.6 | 100.0 | 99.20 | 99.38 | 94.53 | 84.6 | 59.8 |\n| 8K | 100.0 | 99.8 | 99.6 | 99.08 | 94.68 | 84.93 | 79.2 | 56.2 |\n| 16K | 100.0 | 100.0 | 99.4 | 98.72 | 56.90 | 90.60 | 79.6 | 53.2 |\n| 32K | 100.0 | 99.6 | 99.8 | 97.32 | 2.78 | 93.20 | 77.2 | 50.4 |\n| 64K<sup></sup> | 100.0 | 97.4 | 97.8 | 92.48 | 0.10 | 84.27 | 76.0 | 49.4 |\n| 128K<sup></sup> | 100.0 | 75.2 | 56.6 | 54.68 | 0.10 | 74.8 | 71.8 | 41.2 |\n|  |  |  |  |  |  |  |  |  |\n| HeadInfer only |  |  |  |  |  |  |  |  |", "caption": "Table 9: Performance on Ruler benchmark tasks across different context lengths", "description": "\ud45c 9\ub294 Ruler \ubca4\uce58\ub9c8\ud06c\uc758 \ub2e4\uc591\ud55c \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\uc5d0 \ub530\ub978 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Ruler \ubca4\uce58\ub9c8\ud06c\ub294 \ub2e4\uc591\ud55c \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774(4K, 8K, 16K, 32K, 64K, 128K \ud1a0\ud070)\uc5d0\uc11c 13\uac00\uc9c0 \ubcf5\uc7a1\ud55c \uc791\uc5c5\uc744 \ud3ec\ud568\ud558\ub294 \uc885\ud569\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\ub85c, \ubaa8\ub378\uc758 \uc7a5\ubb38 \ucee8\ud14d\uc2a4\ud2b8 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uace0\uc548\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \uc791\uc5c5(Needle-in-a-Haystack, Multi-hop Tracing, Aggregation, Question Answering)\uacfc \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\uc5d0 \ub530\ub978 \uc815\ud655\ub3c4(%)\uac00 \ub098\ud0c0\ub098 \uc788\uc2b5\ub2c8\ub2e4.  HEADINFER\uac00 \ub2e4\uc591\ud55c \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\uc640 \uc791\uc5c5 \uc720\ud615\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc, \uc7a5\ubb38 \ucee8\ud14d\uc2a4\ud2b8 \uc791\uc5c5(Multi-hop Tracing, Aggregation, Question Answering)\uc758 \uacbd\uc6b0 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\uac00 \uae38\uc5b4\uc9c8\uc218\ub85d \uc815\ud655\ub3c4\uac00 \ub2e4\uc18c \uac10\uc18c\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Method | Weight | KV-cache | Activation | Total | Total KV cache<sup>*</sup> |\n|---|---|---|---|---|---| \n| Standard | 15.08 | 128 | 64 | 207 | 128 |\n| Chunked Prefill | 15.08 | 128 | 0.625 | 143 | 128 |\n| 4bit-KV-quant | 15.08 | 32 | 64 | 111 | 32 |\n| layer-wise-offload | 15.08 | 8 | 64 | 87 | 128 |\n| HeadInfer | 15.08 | 1 | 0.625 | 16.7 | 128 |\n\n<sup>*</sup>Total KV cache includes both GPU and CPU memory for offloading methods", "caption": "Table 10: Memory usage comparison for Llama3-8B with 1 million context length", "description": "\ud45c 10\uc740 100\ub9cc \ud1a0\ud070\uc758 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\ub97c \uac00\uc9c4 Llama3-8B \ubaa8\ub378\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ucd94\ub860 \ubc29\ubc95\ub4e4\uc758 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ud45c\uc900 \ubc29\ubc95, \uccad\ud06c \uc804\ucc98\ub9ac, 4\ube44\ud2b8 KV \uc591\uc790\ud654, \uacc4\uce35\ubcc4 \uc624\ud504\ub85c\ub4dc, HEADINFER\uc758 \uac00\uc911\uce58, KV \uce90\uc2dc, \ud65c\uc131\ud654 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9, \uadf8\ub9ac\uace0 \ucd1d \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 GPU \uba54\ubaa8\ub9ac\uc640 CPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\uc5ec \ucd1d KV \uce90\uc2dc \uc0ac\uc6a9\ub7c9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 HEADINFER\uac00 \ub2e4\ub978 \ubc29\ubc95\uc5d0 \ube44\ud574 \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131\uc774 \ub6f0\uc5b4\ub0a8\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uadfc\uac70\uac00 \ub429\ub2c8\ub2e4.", "section": "6.3 \uba54\ubaa8\ub9ac \ubc0f \ucc98\ub9ac\ub7c9\uc758 \ud6a8\uc728\uc131 \uacb0\uacfc"}, {"content": "| Method | Weights | KV cache | Activation | Total | Total KV cache * |\n|---|---|---|---|---|---| \n| Standard-25K | 15.08 | 3.13 | 1.56 | 19.77 | 3.13 |\n| Chunked-Prefill-30K | 15.08 | 3.75 | 0.63 | 19.46 | 3.75 |\n| 4bit-KV-Quant-45K | 15.08 | 1.41 | 2.81 | 19.30 | 1.41 |\n| Layer-Wise-Offload-45K | 15.08 | 0.35 | 2.81 | 18.25 | 5.63 |\n| HeadInfer-4000K | 15.08 | 3.91 | 0.63 | 19.61 | 500 |\n\n*Total KV cache includes both GPU and CPU memory for offloading methods", "caption": "Table 11: Memory consumption analysis for different inference methods (in GB) on Llama-3-8B", "description": "\ud45c 11\uc740 100\ub9cc \ud1a0\ud070\uc758 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774\ub97c \uac00\uc9c4 Llama-3-8B \ubaa8\ub378\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ucd94\ub860 \ubc29\ubc95\uc758 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ud45c\uc900 \ucd94\ub860, \uccad\ud06c \uc0ac\uc804 \ucc44\uc6b0\uae30, 4\ube44\ud2b8 KV \uc591\uc790\ud654, \uacc4\uce35\ubcc4 \uc624\ud504\ub85c\ub529 \ubc0f HEADINFER\ub97c \ud3ec\ud568\ud55c \ub2e4\uc12f \uac00\uc9c0 \ub300\ud45c\uc801\uc778 \uc804\ub7b5\uc5d0 \ub300\ud55c \uac00\uc911\uce58, KV \uce90\uc2dc \ubc0f \ud65c\uc131\ud654 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \uc804\ub7b5\uc5d0 \ub300\ud55c \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 \ubd84\uc11d\uc744 \ud1b5\ud574 \ucee8\ud14d\uc2a4\ud2b8 \uae38\uc774 \ud655\uc7a5\uc5d0 \ub530\ub978 \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131\uc744 \ube44\uad50\ud558\uace0 HEADINFER\uc758 \ud6a8\uacfc\ub97c \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Operator | Regular |  |  |  |  | Offload |  |  |  |\n|---|---|---|---|---|---|---|---|---|---| \n|  | Ops | Memory | Arithmetic Intensity | FLOPS | Bound | Memory (KV cache) | Arithmetic Intensity | FLOPS | Bound |\n|---|---|---|---|---|---|---|---|---|---| \n| **Prefill** |  |  |  |  |  |  |  |  |  |\n| flashattention (1k) | 17G | 21M | 820 | 165T | compute | 4.2M | 4100 | 102T | memory |\n| flashattention (10k) | 1.7T | 209M | 8200 | 165T | compute | 42M | 41000 | 165T | compute |\n| flashattention (100k) | 172T | 2.1G | 82000 | 165T | compute | 419M | 410000 | 165T | compute |\n| head-wise (1k) | 2.1G | 2.6M | 820 | 165T | compute | 0.5M | 4100 | 102T | memory |\n| head-wise (10k) | 215G | 26M | 8200 | 165T | compute | 5.2M | 41000 | 312T | compute |\n| head-wise (100k) | 21T | 262M | 82000 | 165T | compute | 52M | 410000 | 312T | compute |\n| **Decode** |  |  |  |  |  |  |  |  |  |\n| flashattention (1k) | 17M | 17M | 1 | 1T | memory | 17M | 1 | 13G | memory |\n| flashattention (10k) | 168M | 168M | 1 | 1T | memory | 168M | 1 | 13G | memory |\n| flashattention (100k) | 1.7G | 1.7G | 1 | 1T | memory | 1.7G | 1 | 13G | memory |\n| head-wise (1k) | 2.1M | 2.1M | 1 | 1T | memory | 2.1M | 1 | 13G | memory |\n| head-wise (10k) | 21M | 21M | 1 | 1T | memory | 21M | 1 | 13G | memory |\n| head-wise (100k) | 210M | 210M | 1 | 1T | memory | 210M | 1 | 13G | memory |", "caption": "Table 12: Performance comparison of different attention mechanisms under RTX-4090 setting", "description": "\ud45c 12\ub294 RTX 4090 \uc124\uc815 \ud558\uc5d0\uc11c \ub2e4\uc591\ud55c \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  Prefill \ubc0f Decode \ub2e8\uacc4 \ubaa8\ub450\uc5d0\uc11c  flashattention \ubc0f head-wise \uc811\uadfc \ubc29\uc2dd\uc758 \uc5f0\uc0b0 \uc18d\ub3c4\uc640 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \uc5f0\uc0b0 \uac15\ub3c4(Arithmetic Intensity)\uc640 \ud568\uaed8 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 GPU\uc758 \uba54\ubaa8\ub9ac \ub300\uc5ed\ud3ed\uacfc \uacc4\uc0b0 \uc131\ub2a5\uc758 \ud55c\uacc4\ub97c \uace0\ub824\ud558\uc5ec, \uac01 \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc131\ub2a5 \ubcd1\ubaa9 \ud604\uc0c1(compute-bound \ub610\ub294 memory-bound)\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788, context \uae38\uc774\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubd84\uc11d\ud558\uc5ec  head-wise \ubc29\uc2dd\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. HEADINFER: Head-wise Offload"}, {"content": "| Arithmetic | Intensity |\n|---|---|", "caption": "Table 13: Performance comparison of different attention mechanisms under A100 setting", "description": "\ud45c 13\uc740 A100 \uc124\uc815 \ud558\uc5d0\uc11c \ub2e4\uc591\ud55c \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  'Regular' \uc5f4\uc740 \uc77c\ubc18\uc801\uc778 \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0, 'Offload' \uc5f4\uc740 KV \uce90\uc2dc \uc624\ud504\ub85c\ub529\uc744 \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'Prefill'\uc740 \uc785\ub825 \ud1a0\ud070 \ucc98\ub9ac \ub2e8\uacc4, 'Decode'\ub294 \ud1a0\ud070 \uc0dd\uc131 \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \uc5f4\uc740 \uc5f0\uc0b0 \uc218 (Ops), \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 (Memory), \uc5f0\uc0b0 \uac15\ub3c4 (Arithmetic Intensity), FLOPS (\ucc98\ub9ac \uc131\ub2a5), FLOPS \uacbd\uacc4 (FLOPS Bound), \uba54\ubaa8\ub9ac \ud06c\uae30 (Memory), \uc5f0\uc0b0 \uac15\ub3c4 (Arithmetic Intensity) \ub4f1\uc758 \uc815\ubcf4\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 HEADINFER\uc758 \uc131\ub2a5\uc744 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "C. Roofline Model for head-wise flash attention"}, {"content": "| Memory |\n|---|---| \n| (KV cache) |", "caption": "Table 14: Prefill 1M, Decoding with 1M KV cache performance comparison", "description": "\ud45c 14\ub294 1M \ud1a0\ud070\uc758 \uc785\ub825\uc5d0 \ub300\ud55c prefill \ub2e8\uacc4\uc640 1M KV \uce90\uc2dc\ub97c \uc0ac\uc6a9\ud55c decoding \ub2e8\uacc4\uc5d0\uc11c HEADINFER \ubaa8\ub378\uacfc HEADINFER\uc5d0 50% sparsity \uae30\ubc95\uc744 \uc801\uc6a9\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  \ub450 \ubaa8\ub378 \ubaa8\ub450 prefill\uacfc decoding\uc5d0\uc11c \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, HEADINFER + 50% sparsity \ubaa8\ub378\uc740 decoding\uc5d0\uc11c \uc57d 2\ubc30\uc758 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4.", "section": "E. HEADINFER\uc758 \uac04\ud3b8\ud55c \uad6c\ud604 \ubc0f \uc774\uc2dd\uc131"}]