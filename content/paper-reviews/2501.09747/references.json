{"references": [{"fullname_first_author": "Kevin Black", "paper_title": "pi_0: A vision-language-action flow model for general robot control", "publication_date": "2024-10-24", "reason": "This paper introduces a state-of-the-art diffusion-based vision-language-action model for robot control, which the current paper uses as a comparison and achieves similar performance with increased training efficiency."}, {"fullname_first_author": "Anthony Brohan", "paper_title": "RT-1: Robotics Transformer for real-world control at scale", "publication_date": "2022-12-06", "reason": "This is a foundational paper in vision-language-action models for robotics, establishing the effectiveness of transformer models for generalizable robot control, which the current paper builds upon and improves upon."}, {"fullname_first_author": "Moo Jin Kim", "paper_title": "OpenVLA: An open-source vision-language-action model", "publication_date": "2024-06-09", "reason": "This paper provides an open-source vision-language-action model (OpenVLA), serving as a direct comparison and baseline for the current paper's proposed FAST method."}, {"fullname_first_author": "Alexander Khazatsky", "paper_title": "DROID: A large-scale in-the-wild robot manipulation dataset", "publication_date": "2024-MM-DD", "reason": "This paper introduces a large-scale, real-world dataset for robot manipulation, which is crucial for training and evaluating generalist robot policies. The current work uses this dataset for training and evaluation."}, {"fullname_first_author": "Lucas Beyer", "paper_title": "Paligemma: A versatile 3B VLM for transfer", "publication_date": "2024-07-07", "reason": "This paper introduces a large vision-language model (Paligemma) used as the backbone for the current paper's VLA model, demonstrating the effectiveness of large language models in robot control."}]}