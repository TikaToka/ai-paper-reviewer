{"references": [{"fullname_first_author": "R. S. Johansson", "paper_title": "Coding and use of tactile signals from the fingertips in object manipulation tasks", "publication_date": "2009-05-01", "reason": "This paper is foundational in understanding the importance of tactile feedback in object manipulation, providing context for the current research that explores multi-sensory robot interaction."}, {"fullname_first_author": "R. Calandra", "paper_title": "More than a feeling: Learning to grasp and regrasp using vision and touch", "publication_date": "2018-01-01", "reason": "This paper is highly influential as it demonstrates the integration of vision and touch for robotic grasping, a key concept that the current work builds upon and extends to multiple modalities."}, {"fullname_first_author": "Octo Model Team", "paper_title": "Octo: An open-source generalist robot policy", "publication_date": "2024-01-01", "reason": "This paper introduces Octo, a generalist robot policy that serves as a baseline and a starting point for the current research, demonstrating the significance of generalist policies in robotics."}, {"fullname_first_author": "O. X.-E. Collaboration", "paper_title": "Open X-Embodiment: Robotic learning datasets and RT-X models", "publication_date": "2024-01-01", "reason": "This paper introduces the Open X-Embodiment dataset, a crucial resource for training and evaluating generalist robot policies that forms the basis for the current study."}, {"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-01-01", "reason": "CLIP, introduced in this paper, is fundamental to the approach used for multimodal grounding in this research, showcasing the power of natural language as a bridge between different modalities."}]}