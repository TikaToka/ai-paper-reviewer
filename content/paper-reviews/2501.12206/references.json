{"references": [{"fullname_first_author": "Wenbin An", "paper_title": "AGLA: Mitigating object hallucinations in large vision-language models with assembly of global and local attention", "publication_date": "2024-00-00", "reason": "This paper proposes a method to reduce hallucinations in large vision-language models by assembling global and local attention, addressing a key challenge discussed in the main paper."}, {"fullname_first_author": "Alessandro Favero", "paper_title": "Multi-modal hallucination control by visual information grounding", "publication_date": "2024-00-00", "reason": "This paper focuses on managing visual attention to reduce hallucinations, a core theme of the main paper, suggesting methods to improve the balance between visual and textual information."}, {"fullname_first_author": "Yichen Gong", "paper_title": "Figstep: Jailbreaking large vision-language models via typographic visual prompts", "publication_date": "2023-00-00", "reason": "This paper explores techniques to control hallucinations by manipulating visual inputs, providing insights relevant to the main paper's approach of enhancing visual attention."}, {"fullname_first_author": "Jiaxing Huang", "paper_title": "Visual instruction tuning towards general-purpose multimodal model: A survey", "publication_date": "2023-12-00", "reason": "This survey paper provides a comprehensive overview of multimodal large language models, offering valuable context for understanding the challenges and approaches related to hallucination mitigation discussed in the main paper."}, {"fullname_first_author": "Shi Liu", "paper_title": "Paying more attention to image: A training-free method for alleviating hallucination in LVLMs", "publication_date": "2024-07-00", "reason": "This paper presents a training-free method to address the imbalanced attention problem in LVLMs, directly addressing a similar challenge and providing a relevant baseline for comparison in the main paper."}]}