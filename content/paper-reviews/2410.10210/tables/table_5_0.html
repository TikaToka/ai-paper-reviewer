<table id='1' style='font-size:18px'><tr><td></td><td>Training data and epoch setup</td><td>s (avg) SL SQ</td><td>Improvement</td></tr><tr><td>GLM4-9b-Chat</td><td>-</td><td>67.8 52.8 82.78</td><td>-</td></tr><tr><td>LongWriter-GLM4-9B[7, 8]</td><td>Trained from GLM-4-9B[11] with LongWrite-6k plus 1:30 mixing ratio using entire GLM chat SFT dataset (180k), trained for 4 epochs</td><td>80.5 78.6 82.3</td><td>+12.7 pt</td></tr><tr><td>Setup 4</td><td>LongWriter-6k-filtered with 1:20 mixing ratio of alignment data (13k), trained for 2 epochs</td><td>79.88 77.42 82.33</td><td>+12.08 pt</td></tr></table>