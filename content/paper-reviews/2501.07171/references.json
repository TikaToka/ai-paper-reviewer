{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational vision-language model that heavily influences the current work's methodology and benchmarks."}, {"fullname_first_author": "Karan Desai", "paper_title": "Redcaps: Web-curated image-text data created by the people, for the people", "publication_date": "2021-11-16", "reason": "This paper introduces a large-scale, diverse image-text dataset that serves as a benchmark and inspiration for the construction of BIOMEDICA."}, {"fullname_first_author": "George Shih", "paper_title": "Augmenting the national institutes of health chest radiograph dataset with expert annotations of possible pneumonia", "publication_date": "2019-01-01", "reason": "This paper is a key source of data for the evaluation benchmarks, especially those in radiology, making it crucial to the work's comparative analysis."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-01", "reason": "This paper introduces DINO, a self-supervised vision transformer model, used in the BIOMEDICA pipeline for image feature extraction."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "Laion-5b: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-12-01", "reason": "This paper introduces LAION-5B, a massive image-text dataset that provides context for the scale and scope of BIOMEDICA relative to other vision-language datasets."}]}