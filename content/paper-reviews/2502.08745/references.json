{"references": [{"fullname_first_author": "Yann Dubois", "paper_title": "AlpacaFarm: A simulation framework for methods that learn from human feedback", "publication_date": "2023-12-01", "reason": "This paper is foundational for instruction-following evaluation, and its methodology of using an expert LM to holistically judge model responses directly influenced the IHEval benchmark."}, {"fullname_first_author": "Eric Wallace", "paper_title": "The instruction hierarchy: Training LLMs to prioritize privileged instructions", "publication_date": "2024-04-13", "reason": "This paper introduced the instruction hierarchy concept, which is the core focus of the IHEval benchmark, and proposed a method for training LLMs to follow it."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA 2: Open Foundation and Fine-Tuned Chat Models", "publication_date": "2023-07-09", "reason": "As a recent prominent open-source LLM, LLaMA 2's performance on IHEval provides insights into the instruction hierarchy capabilities of state-of-the-art open models."}, {"fullname_first_author": "Jeffrey Zhou", "paper_title": "Instruction-following evaluation for large language models", "publication_date": "2023-11-07", "reason": "This paper provides a detailed evaluation methodology for instruction following, focusing on strict rule adherence, directly informing and influencing the IHEval methodology and metrics."}, {"fullname_first_author": "Sam Toyer", "paper_title": "TensorTrust: Interpretable Prompt Injection Attacks from an Online Game", "publication_date": "2024-04-13", "reason": "This paper focuses on evaluating LLM safety, which is closely related to instruction hierarchy. The dataset and approach are directly referenced in the safety aspects of the IHEval benchmark."}]}