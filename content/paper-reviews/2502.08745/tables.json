[{"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Injected | Mean | Abs. | \u0394 | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | reference | 89.0 | 86.5 | 90.0 | 78.0 | 100 | 99.5 | 100 | 90.2 | 94.0 | 91.9 | - |  | \n|  | aligned | 85.6 | 86.8 | 87.3 | 73.9 | 100 | 99.2 | 98.7 | 88.6 | 99.0 | 91.0 | -0.9 | 2.1 | \n| GPT-4o (2024-0806) | conflict | 49.5 | 51.0 | 77.2 | 38.3 | 99.7 | 91.2 | 96.7 | 63.8 | 62.5 | 70.0 | -21.9 | 21.9 | \n|  | reference | 84.5 | 86.1 | 90.5 | 78.4 | 99.6 | 99.1 | 99.4 | 89.3 | 79.0 | 89.6 | - |  | \n|  | aligned | 82.3 | 80.2 | 84.0 | 72.0 | 100 | 98.6 | 98.7 | 82.7 | 59.0 | 84.2 | -5.4 | 5.5 | \n| GPT-4o mini (2024-0718) | conflict | 33.9 | 35.7 | 47.7 | 31.1 | 41.1 | 70.3 | 95.5 | 43.6 | 0 | 44.3 | -45.2 | 45.2 | \n|  | reference | 80.9 | 83.9 | 84.9 | 76.9 | 100 | 87.1 | 85.5 | 87.1 | 87.0 | 85.9 | - |  | \n|  | aligned | 68.4 | 69.5 | 77.4 | 79.8 | 100 | 97.6 | 97.2 | 85.3 | 91.0 | 85.1 | -0.8 | 7.2 | \n| Claude-3 Sonnet | conflict | 10.8 | 21.1 | 2.3 | 29.7 | 9.8 | 46.6 | 60.1 | 56.9 | 39.0 | 30.7 | -55.2 | 55.2 | \n|  | reference | 88.3 | 88.4 | 89.1 | 77.0 | 100 | 99.3 | 99.7 | 89.0 | 100 | 92.3 | - |  | \n|  | aligned | 82.9 | 76.6 | 84.3 | 59.5 | 100 | 95.8 | 96.2 | 20.3 | 94.0 | 78.8 | -13.5 | 13.5 | \n| LLaMA-3.1 70B | conflict | 14.3 | 24.3 | 0 | 15.2 | 6.2 | 24.4 | 25.2 | 2.2 | 14.0 | 14.0 | -78.3 | 78.3 | \n|  | reference | 83.6 | 85.2 | 85.2 | 78.5 | 100 | 99.2 | 98.4 | 88.3 | 69.0 | 87.5 | - |  | \n|  | aligned | 81.7 | 87.1 | 76.0 | 78.3 | 100 | 97.7 | 99.1 | 77.9 | 79.0 | 86.3 | -1.2 | 4.0 | \n| Mistral-Large (2407) | conflict | 25.2 | 60.0 | 11.0 | 20.2 | 78.4 | 23.9 | 18.8 | 13.9 | 13.5 | 29.4 | -58.1 | 58.1 | \n|  | reference | 81.4 | 85.0 | 74.9 | 75.0 | 100 | 97.6 | 98.4 | 83.9 | 92.0 | 87.6 | - |  | \n|  | aligned | 82.1 | 81.3 | 73.4 | 75.3 | 100 | 97.5 | 97.8 | 77.6 | 86.0 | 85.7 | -1.9 | 2.1 | \n| Qwen-2 72B | conflict | 35.8 | 39.5 | 53.7 | 58.4 | 99.5 | 36.8 | 34.7 | 26.2 | 46.0 | 47.8 | -39.7 | 39.7 | ", "caption": "Table 1: Results of select LMs on IHEval. Full results are in Tables\u00a05~10. \u0394\u0394\\Deltaroman_\u0394 is the score difference from the reference setting, including both the mean difference (signed) and the mean absolute difference. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5. Single. and Multi. refer to single-turn and multi-turn tasks in the Rule Following category. Ext., Gen., and Class. refer to extraction, generation, and classification tasks in Task Execution. The best performance in the conflict setting is marked as bold and the second-best is underlined.", "description": "\ud45c 1\uc740 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc8fc\uc694 \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\ub4e4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc804\uccb4 \uacb0\uacfc\ub294 \ud45c 5~10\uc5d0 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.  \u0394 \uc5f4\uc740 \uae30\uc900 \uc124\uc815(\ub2e8\uc77c \uc785\ub825)\uacfc\uc758 \uc810\uc218 \ucc28\uc774\ub97c \ub098\ud0c0\ub0b4\uba70, \ud3c9\uade0 \ucc28\uc774(\ubd80\ud638 \ud3ec\ud568)\uc640 \ud3c9\uade0 \uc808\ub300 \ucc28\uc774\ub97c \ubaa8\ub450 \ud3ec\ud568\ud569\ub2c8\ub2e4.  \ube68\uac04\uc0c9 \uc810\uc218\ub294 \uc808\ub300 \uc810\uc218 \ucc28\uc774\uac00 5\ubcf4\ub2e4 \ud070 \uacbd\uc6b0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uaddc\uce59 \uc900\uc218 \ubc94\uc8fc\uc5d0\uc11c\ub294 \ub2e8\uc77c \ud134\uacfc \ub2e4\uc911 \ud134 \uc791\uc5c5\uc744 \uad6c\ubd84\ud558\uace0, \uc791\uc5c5 \uc2e4\ud589 \ubc94\uc8fc\uc5d0\uc11c\ub294 \ucd94\ucd9c, \uc0dd\uc131, \ubd84\ub958 \uc791\uc5c5\uc744 \uad6c\ubd84\ud569\ub2c8\ub2e4.  \ucda9\ub3cc \uc124\uc815\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc740 \uad75\uac8c \ud45c\uc2dc\ud558\uace0, \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uc131\ub2a5\uc740 \ubc11\uc904\uc744 \ucce4\uc2b5\ub2c8\ub2e4.", "section": "4.1 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| ![Main](https://arxiv.org/html/2502.08745/main.png) | **Rule** | **Task Execution** | **Safety** | **Tool Use** |\n|---|---|---|---|---|\n| **Ins.** | Multi-turn | Extract. | Gen. | Class. | Hijack | Extract | Instrinsic | Inject |\n|  | First. | Both. | _weak_ | _strong_ | _weak_ | _strong_ | _weak_ | _strong_ | _weak_ | _strong_ | _weak_ | _strong_ |\n| _weak_ | 41.0 | 12.3 | 31.8 | 9.3 | 28.3 | 10.4 | 25.9 | 21.5 | 30.6 | 33.3 | 33.3 | 13.1 |\n| _strong_ | 55.4 | 16.1 | 37.1 | 16.3 | 50.6 | 24.5 | 47.0 | 38.8 | 43.7 | 45.2 |  | 18.7 | 36.5 | } 36.5", "caption": "Table 2: Model performance in conflict settings with different strictness of instructions. \u201cMain Ins.\u201d and \u201cConflict Ins.\u201d refer to the main instruction and the conflicting instruction, respectively. In multi-turn Rule Following, \u201cFirst.\u201d and \u201cBoth.\u201d are settings where conflict instructions appear in the first turn or both turns (see Figure\u00a09 for examples).", "description": "\ud45c 2\ub294 \ubaa8\uc21c\ub418\ub294 \uc9c0\uc2dc\uc0ac\ud56d\uc774 \uc788\ub294 \uc0c1\ud669\uc5d0\uc11c \uc9c0\uc2dc\uc0ac\ud56d\uc758 \uc5c4\uaca9\uc131\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \"\uc8fc\uc694 \uc9c0\uc2dc\uc0ac\ud56d\"\uacfc \"\uc0c1\ucda9\ub418\ub294 \uc9c0\uc2dc\uc0ac\ud56d\"\uc740 \uac01\uac01 \uc8fc\uc694 \uc9c0\uc2dc\uc0ac\ud56d\uacfc \uc0c1\ucda9\ub418\ub294 \uc9c0\uc2dc\uc0ac\ud56d\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub2e4\ud68c\ucc28 \uaddc\uce59 \uc900\uc218\uc758 \uacbd\uc6b0, \"\uccab \ubc88\uc9f8\"\uc640 \"\ubaa8\ub450\"\ub294 \uc0c1\ucda9\ub418\ub294 \uc9c0\uc2dc\uc0ac\ud56d\uc774 \uccab \ubc88\uc9f8 \ucc28\ub840 \ub610\ub294 \ub450 \ucc28\ub840 \ubaa8\ub450\uc5d0 \ub098\ud0c0\ub098\ub294 \uc124\uc815\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4(\uc608\uc2dc\ub294 \uadf8\ub9bc 9 \ucc38\uc870).", "section": "4.3 \uc9c0\uc2dc\uc0ac\ud56d\uc758 \uc5c4\uaca9\uc131\uc5d0 \ub530\ub978 \uc131\ub2a5"}, {"content": "| Model | IPP | Rule | Task | Safety | Tool | Avg |\n|---|---|---|---|---|---|---|\n|  | \u2717 | 50.3 | 71.7 | 94.0 | 63.2 | 70.0 |\n| GPT-4o (0806) | \u2714 | 54.6 | 65.7 | 93.1 | 56.0 | 67.2 |\n|  | \u2717 | 19.3 | 7.1 | 24.8 | 8.1 | 14.0 |\n| LLaMA 3.1-70B | \u2714 | 19.6 | 13.8 | 28.5 | 8.1 | 17.1 |\n|  | \u2717 | 42.6 | 36.5 | 21.4 | 13.7 | 29.4 |\n| Mistral Large | \u2714 | 39.6 | 34.6 | 21.2 | 14.6 | 28.3 |", "caption": "Table 3: Performance with or without the additional instruction priority prompt (IPP). Improved scores are in green, while decreased scores are in red.", "description": "\ud45c 3\uc740 \ucd94\uac00\uc801\uc778 \uba85\ub839\uc5b4 \uc6b0\uc120\uc21c\uc704 \ud504\ub86c\ud504\ud2b8(IPP)\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c\uc640 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc810\uc218\uac00 \ud5a5\uc0c1\ub41c \uacbd\uc6b0 \ub179\uc0c9\uc73c\ub85c, \uc810\uc218\uac00 \uac10\uc18c\ud55c \uacbd\uc6b0 \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc8fc\uc694 \uc5b8\uc5b4 \ubaa8\ub378\uc774 \uacc4\uce35\uc801 \uba85\ub839\uc5b4\ub97c \ub530\ub974\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 IHEval \ubca4\uce58\ub9c8\ud06c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  IPP\ub97c \ucd94\uac00\ud558\uba74 \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub420 \uc218 \uc788\uc9c0\ub9cc, \uc77c\ubd80 \ubaa8\ub378\uc5d0\uc11c\ub294 \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uacc4\uce35\uc801 \uba85\ub839\uc5b4 \ucc98\ub9ac\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \ucde8\uc57d\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4. ", "section": "4.4 Prompting LMs to Follow the Hierarchy"}, {"content": "| Setting | Alignment with Main Instruction | GPT-4 | Claude 3 | All Models |\n|---|---|---|---|---|\n| **Reference** | - | GPT<br>4o | Claude3<br>Sonnet | All<br>Models | M | 86.5 | 83.9 | 85.9 |\n| **Aligned** | - | - | - | \u2714 | M | 86.7 | 73.7 | 83.5 |\n|  | \u2714 | \u2714 | \u2714 | M | 86.8 | 69.5 | 79.6 |\n| **Conflict** | \u2714 | \u2717 | \u2714 | M | 78.1 | 57.2 | 68.9 |\n|  | \u2717 | \u2717 | \u2714 | M | 73.2 | 35.9 | 59.5 |\n|  | \u2717 | \u2717 | \u2717 | M | 28.6 | 6.3 | 17.7 |\n|  | \u2717 | \u2717 | - | M | 86.6 | 84.7 | 84.2 |", "caption": "Table 4: Results on variants of the Multi-turn Rule Following task. M: Main instruction, I1subscript\ud835\udc3c1I_{1}italic_I start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: User instruction in the 1st turn, R1subscript\ud835\udc451R_{1}italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: Model response in the 1st turn, I2subscript\ud835\udc3c2I_{2}italic_I start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT: User instruction in the 2nd turn. \u2714\u00a0and \u2717\u00a0indicate whether the input aligns or conflicts with the main instruction. All Models refers to the average performance of all models listed in Table\u00a01. A conflicting R1subscript\ud835\udc451R_{1}italic_R start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT means its response format does not follow the main instruction.", "description": "\ud45c 4\ub294 \ub2e4\ud68c\ucc28 \uaddc\uce59 \uc900\uc218 \uc791\uc5c5\uc758 \ubcc0\ud615\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. M\uc740 \uc8fc\uc694 \uc9c0\uce68, \ud835\udc3c\u2081\uc740 \uccab \ubc88\uc9f8 \ud134\uc758 \uc0ac\uc6a9\uc790 \uc9c0\uce68, \ud835\udc45\u2081\uc740 \uccab \ubc88\uc9f8 \ud134\uc758 \ubaa8\ub378 \uc751\ub2f5, \ud835\udc3c\u2082\ub294 \ub450 \ubc88\uc9f8 \ud134\uc758 \uc0ac\uc6a9\uc790 \uc9c0\uce68\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \u2713 \ubc0f \u2717\ub294 \uc785\ub825\uc774 \uc8fc\uc694 \uc9c0\uce68\uacfc \uc77c\uce58\ud558\ub294\uc9c0 \ub610\ub294 \ucda9\ub3cc\ud558\ub294\uc9c0 \uc5ec\ubd80\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ubaa8\ub4e0 \ubaa8\ub378\uc740 \ud45c 1\uc5d0 \ub098\uc5f4\ub41c \ubaa8\ub4e0 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucda9\ub3cc\ud558\ub294 \ud835\udc45\u2081\uc740 \uc751\ub2f5 \ud615\uc2dd\uc774 \uc8fc\uc694 \uc9c0\uce68\uc744 \ub530\ub974\uc9c0 \uc54a\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4.5 Model Performance in Different Conflicts"}, {"content": "| Alignment with | Main Instruction |\n|---|---|", "caption": "Table 5: Results of GPT models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5.", "description": "\ud45c 5\ub294 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c GPT \uc5b8\uc5b4 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc740 \ucc38\uc870 \uc124\uc815(\uacc4\uce35\uc801 \uc785\ub825 \uc5c6\uc74c), \uc815\ub82c \uc124\uc815(\uacc4\uce35\uc801 \uc785\ub825\uc774 \uc77c\uce58), \ucda9\ub3cc \uc124\uc815(\uacc4\uce35\uc801 \uc785\ub825\uc774 \uc0c1\ucda9) \uc138 \uac00\uc9c0 \uc124\uc815\uc5d0\uc11c \ud3c9\uac00\ub429\ub2c8\ub2e4.  \uac01 \uc124\uc815\uc5d0 \ub300\ud55c \uc810\uc218\ub294 \uaddc\uce59 \uc900\uc218, \uc791\uc5c5 \uc2e4\ud589, \uc548\uc804 \ubc29\uc5b4, \ub3c4\uad6c \uc0ac\uc6a9 \ub124 \uac00\uc9c0 \ubc94\uc8fc\ub85c \ub098\ub258\uc5b4 \ud45c\uc2dc\ub429\ub2c8\ub2e4.  |\u0394| > 5 \ub85c \ud45c\uc2dc\ub41c \ube68\uac04\uc0c9 \uc810\uc218\ub294 \uacc4\uce35\uc801 \uc785\ub825\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c \uc131\ub2a5 \uc800\ud558\uac00 5\uc810 \uc774\uc0c1\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d \uc900\uc218 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Inject | Mean | Abs. | \u0394 | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | reference | 70.1 | 69.4 | 79.6 | 76.7 | 100 | 88.8 | 87.7 | 85.9 | 98.0 | 84.0 | - |  | \n|  | aligned | 70.3 | 72.9 | 78.0 | 80.3 | 100 | 94.7 | 97.2 | 78.3 | 92.0 | 84.8 | +0.8 | 4.2 | \n| GPT-3.5-turbo (2024-0125) | conflict | 26.5 | 25.9 | 34.0 | 57.7 | 2.3 | 43.3 | 29.0 | 20.2 | 66.0 | 33.9 | -50.1 | 50.1 | \n|  | reference | 84.5 | 86.1 | 90.5 | 78.4 | 99.6 | 99.1 | 99.4 | 89.3 | 79.0 | 89.6 | - |  | \n|  | aligned | 82.3 | 80.2 | 84.0 | 72.0 | 100 | 98.6 | 98.7 | 82.7 | 59.0 | 84.2 | -5.4 | 5.4 | \n| GPT-4o mini (2024-0718) | conflict | 33.9 | 35.7 | 47.7 | 31.1 | 41.1 | 70.3 | 95.5 | 43.6 | 0 | 44.3 | -45.2 | 45.2 | \n|  | reference | 89.0 | 86.5 | 90.0 | 78.0 | 100 | 99.5 | 100 | 90.2 | 94.0 | 91.9 | - |  | \n|  | aligned | 85.6 | 86.8 | 87.3 | 73.9 | 100 | 99.2 | 98.7 | 88.6 | 99.0 | 91.0 | -0.9 | 2.1 | \n| GPT-4o (2024-0806) | conflict | 49.5 | 51.0 | 77.2 | 38.3 | 99.7 | 91.2 | 96.7 | 63.8 | 62.5 | 70.0 | -21.9 | 21.9 | ", "caption": "Table 6: Results of Claude models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5.", "description": "\ud45c 6\uc740 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Claude \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5(\uaddc\uce59 \uc900\uc218, \uc791\uc5c5 \uc2e4\ud589, \uc548\uc804 \ubc29\uc5b4, \ub3c4\uad6c \uc0ac\uc6a9)\uc5d0 \uac78\uccd0 Claude \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc791\uc5c5\uc740 \uacc4\uce35\uc801 \uc785\ub825(\uc0c1\ud638 \uc77c\uce58 \ub610\ub294 \uc0c1\ucda9\ud558\ub294 \uc9c0\uce68)\uc774 \uc788\ub294 \uc124\uc815\uacfc \uacc4\uce35\uc801 \uc785\ub825\uc774 \uc5c6\ub294 \uae30\uc900 \uc124\uc815\uc73c\ub85c \ub098\ub269\ub2c8\ub2e4. \ube68\uac04\uc0c9 \uc810\uc218\ub294 \uae30\uc900 \uc124\uc815\uacfc \uacc4\uce35\uc801 \uc785\ub825 \uc124\uc815 \uac04\uc758 \uc131\ub2a5 \ucc28\uc774(|\u0394|)\uac00 5\ubcf4\ub2e4 \ud070 \uacbd\uc6b0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub294 Claude \ubaa8\ub378\uc774 \uacc4\uce35\uc801 \uc9c0\uce68\uc744 \ub530\ub974\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Inject | Mean | Abs. |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | reference | 77.8 | 78.9 | 84.5 | 77.3 | 100 | 97.4 | 97.5 | 87.6 | 69.0 | 85.6 | - |\n|  | aligned | 68.3 | 71.0 | 71.8 | 74.7 | 100 | 90.3 | 94.0 | 80.2 | 33.0 | 75.9 | -9.7 |\n| Claude-3<br>Haiku | conflict | 15.4 | 23.4 | 7.3 | 23.6 | 26.0 | 42.2 | 52.4 | 59.1 | 1.5 | 27.9 | -57.7 |\n|  | reference | 80.9 | 83.9 | 84.9 | 76.9 | 100 | 87.1 | 85.5 | 87.1 | 87.0 | 85.9 | - |\n|  | aligned | 68.4 | 69.5 | 77.4 | 79.8 | 100 | 97.6 | 97.2 | 85.3 | 91.0 | 85.1 | -0.8 |\n| Claude-3<br>Sonnet | conflict | 10.8 | 21.1 | 2.3 | 29.7 | 9.8 | 46.6 | 60.1 | 56.9 | 39.0 | 30.7 | -55.2 |", "caption": "Table 7: Results of LLaMA-3.1 models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5.", "description": "\ud45c 7\uc740 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c LLaMA-3.1 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5(\uaddc\uce59 \uc900\uc218, \uc791\uc5c5 \uc2e4\ud589, \uc548\uc804 \ubc29\uc5b4, \ub3c4\uad6c \uc0ac\uc6a9)\uacfc \uac01 \uc791\uc5c5\uc758 \uc138 \uac00\uc9c0 \uc124\uc815(\uae30\uc900, \uc815\ub82c, \ucda9\ub3cc)\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uc124\uc815\uc5d0\uc11c \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uc640 \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d\uc744 \ub530\ub974\uc9c0 \ubabb\ud55c \uc815\ub3c4\ub97c \ub098\ud0c0\ub0b4\ub294 \u0394 \uac12\uc774 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \ube68\uac04\uc0c9 \uc810\uc218\ub294 \uc808\ub300 \u0394 \uac12\uc774 5\ubcf4\ub2e4 \ud070 \uacbd\uc6b0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc989, \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d\uc774 \uc788\uc744 \ub54c \ubaa8\ub378 \uc131\ub2a5\uc758 \ud070 \ubcc0\ud654\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Inject | Mean | Abs. | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | reference | 80.7 | 79.6 | 84.4 | 72.5 | 100 | 70.2 | 68.2 | 85.1 | 91.0 | 81.3 | - |\n|  | aligned | 71.1 | 68.1 | 77.1 | 48.9 | 96.9 | 66.2 | 64.1 | 7.9 | 0.0 | 55.6 | -25.7 |\n| LLaMA-3.1 8B | conflict | 14.5 | 20.1 | 21.8 | 7.1 | 0.1 | 19.2 | 11.3 | 7.8 | 0.0 | 11.3 | -70.0 |\n|  | reference | 88.3 | 88.4 | 89.1 | 77.0 | 100 | 99.3 | 99.7 | 89.0 | 100 | 92.3 | - |\n|  | aligned | 82.9 | 76.6 | 84.3 | 59.5 | 100 | 95.8 | 96.2 | 20.3 | 94.0 | 78.8 | -13.5 |\n| LLaMA-3.1 70B | conflict | 14.3 | 24.3 | 0 | 15.2 | 6.2 | 24.4 | 25.2 | 2.2 | 14.0 | 14.0 | -78.3 |", "caption": "Table 8: Results of LLaMA-3 models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5. As LLaMA-3 models do not officially support tool calling, we skip the Tool Use setting for them.", "description": "\ud45c 8\uc740 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c LLaMA-3 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc774 Rule Following, Task Execution, Safety Defense \uc138 \uac00\uc9c0 \ubc94\uc8fc\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc798 \uc9c0\uc2dc \uc0ac\ud56d \uacc4\uce35 \uad6c\uc870\ub97c \ub530\ub974\ub294\uc9c0 \ud3c9\uac00\ud55c \uacb0\uacfc\uac00 \ub2f4\uaca8 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubc94\uc8fc \ub0b4\uc5d0\uc11c\ub3c4 \uc5ec\ub7ec \ud558\uc704 \uc791\uc5c5\ub4e4\uc774 \uc788\uace0, \uc774\ub4e4 \uac01\uac01\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  |\u0394| > 5 \ub85c \ud45c\uc2dc\ub41c \ubd89\uc740\uc0c9 \uc810\uc218\ub294 \uae30\uc900 \uc124\uc815(\ub2e8\uc77c \uc785\ub825 \uc124\uc815)\uacfc \uacc4\uce35\uc801 \uc785\ub825 \uc124\uc815(\uacc4\uce35\uc801 \uc9c0\uc2dc\uc0ac\ud56d\uc774 \ud3ec\ud568\ub41c \uc124\uc815) \uac04\uc758 \uc131\ub2a5 \ucc28\uc774\uac00 5%p\ub97c \ub118\ub294\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc989, \ubd89\uc740\uc0c9\uc740 \ubaa8\ub378\uc774 \uacc4\uce35\uc801 \uc9c0\uc2dc\uc0ac\ud56d \ucc98\ub9ac\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294\ub2e4\ub294 \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. LLaMA-3 \ubaa8\ub378\ub4e4\uc740 \ud234 \ud638\ucd9c \uae30\ub2a5\uc744 \uacf5\uc2dd\uc801\uc73c\ub85c \uc9c0\uc6d0\ud558\uc9c0 \uc54a\uc73c\ubbc0\ub85c, \ud234 \uc0ac\uc6a9 \uc124\uc815(Tool Use) \uacb0\uacfc\ub294 \ud45c\uc5d0 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Inject | Mean | \u0394 | Abs. |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | reference | 77.0 | 74.6 | 79.7 | 73.5 | 100.0 | 93.2 | 92.8 | - | - | 84.4 | - | - |\n|  | aligned | 71.4 | 57.7 | 72.0 | 57.2 | 100.0 | 82.2 | 78.9 | - | - | 74.2 | -10.2 | 10.2 |\n| LLaMA-3<br>8B | conflict | 22.7 | 22.6 | 20.0 | 15.6 | 0.2 | 22.0 | 23.6 | - | - | 18.1 | -66.3 | 66.3 |\n|  | reference | 83.8 | 84.3 | 85.4 | 74.9 | 99.6 | 98.8 | 99.7 | - | - | 89.5 | - | - |\n|  | aligned | 81.5 | 69.8 | 79.8 | 64.4 | 99.4 | 97.9 | 97.2 | - | - | 84.3 | -5.2 | 5.2 |\n| LLaMA-3<br>70B | conflict | 15.0 | 23.9 | 2.0 | 24.5 | 33.2 | 32.9 | 37.4 | - | - | 24.2 | -65.3 | 65.3 |", "caption": "Table 9: Results of Mistral models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5.", "description": "\ud45c 9\ub294 Mistral \uc5b8\uc5b4 \ubaa8\ub378\uc758 IHEval \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uae30\ubcf8 \uc131\ub2a5(Reference), \uacc4\uce35\uc801 \uc785\ub825\uc774 \uc77c\uce58\ud558\ub294 \uacbd\uc6b0(Aligned), \uadf8\ub9ac\uace0 \uacc4\uce35\uc801 \uc785\ub825\uc774 \ucda9\ub3cc\ud558\ub294 \uacbd\uc6b0(Conflict)\uc758 \uc138 \uac00\uc9c0 \uc124\uc815\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uacfc\uc81c(Rule Following, Task Execution, Safety Defense, Tool Use)\ubcc4 \uc810\uc218\uc640 \uc804\uccb4 \ud3c9\uade0 \uc810\uc218, \uadf8\ub9ac\uace0 Reference \uc124\uc815\uacfc \ub2e4\ub978 \uc124\uc815 \uac04\uc758 \uc810\uc218 \ucc28\uc774(\u0394)\uc640 \uc808\ub300 \uc810\uc218 \ucc28\uc774\uc758 \ud3c9\uade0\uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  |\u0394| \uac12\uc774 5\ubcf4\ub2e4 \ud070 \uc810\uc218\ub294 \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub418\uc5b4, \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d\uc744 \ub530\ub974\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \ubd80\ubd84\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 Mistral \ubaa8\ub378\uc758 \ud06c\uae30(7B, Large)\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Setting | Single. | Multi. | Ext. | Gen. | Class. | Hijack | Extract | Intrinsic | Inject | Mean | Abs. | \u0394 | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | reference | 53.9 | 54.4 | 44.8 | 61.1 | 42.9 | 63.0 | 61.3 | 54.0 | 51.0 | 54.0 | - |  | \n|  | aligned | 54.7 | 63.6 | 42.5 | 39.1 | 88.5 | 58.1 | 60.1 | 30.6 | 0.0 | 48.6 | -5.4 | 17.9 | \n| Mistral-7B <br> Instruct-v0.3 | conflict | 22.6 | 39.7 | 15.8 | 15.2 | 12.4 | 18.6 | 8.6 | 2.0 | 0.0 | 15.0 | -39.0 | 39.0 | \n|  | reference | 83.6 | 85.2 | 85.2 | 78.5 | 100 | 99.2 | 98.4 | 88.3 | 69.0 | 87.5 | - |  | \n|  | aligned | 81.7 | 87.1 | 76.0 | 78.3 | 100 | 97.7 | 99.1 | 77.9 | 79.0 | 86.3 | -1.2 | 4.0 | \n| Mistral-Large <br> (2407) | conflict | 25.2 | 60.0 | 11.0 | 20.2 | 78.4 | 23.9 | 18.8 | 13.9 | 13.5 | 29.4 | -58.1 | 58.1 |", "caption": "Table 10: Results of Qwen-2 models on IHEval. Red scores indicate |\u0394|>5\u03945|\\Delta|>5| roman_\u0394 | > 5.", "description": "\ud45c 10\uc740 IHEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Qwen-2 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5(\uaddc\uce59 \uc900\uc218, \uc791\uc5c5 \uc2e4\ud589, \uc548\uc804 \ubc29\uc5b4, \ub3c4\uad6c \uc0ac\uc6a9)\uacfc \uc124\uc815(\ucc38\uc870, \uc815\ub82c, \ucda9\ub3cc)\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uc124\uc815\uc5d0\uc11c \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uc640 \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d\uc744 \ub530\ub974\uc9c0 \ubabb\ud55c \uc815\ub3c4(\u0394)\uac00 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \ube68\uac04\uc0c9 \uc810\uc218\ub294 \uc808\ub300\uac12\uc774 5\ubcf4\ub2e4 \ud070 \u0394\uac12\uc744 \ub098\ud0c0\ub0b4\uba70, \ubaa8\ub378\uc774 \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d\uc744 \ucc98\ub9ac\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uc5c8\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc8fc\ub85c \ubaa8\ub378\uc758 \uaddc\ubaa8\uc640 \uacc4\uce35\uc801 \uc9c0\uc2dc \uc0ac\ud56d \uc900\uc218 \ub2a5\ub825 \uc0ac\uc774\uc758 \uad00\uacc4\ub97c \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4. \uacb0\uacfc"}]