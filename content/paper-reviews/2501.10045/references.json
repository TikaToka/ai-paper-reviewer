{"references": [{"fullname_first_author": "H. Liu", "paper_title": "Neural vocoder is all you need for speech super-resolution", "publication_date": "2022-XX-XX", "reason": "This paper proposes a significant approach using neural vocoders for speech super-resolution, which is directly relevant to the current work and serves as a strong baseline."}, {"fullname_first_author": "J. Kong", "paper_title": "HiFi-GAN: Generative adversarial networks for efficient and high fidelity speech synthesis", "publication_date": "2020-XX-XX", "reason": "The HiFi-GAN generator is a core component of the proposed model, making this a crucial foundational paper."}, {"fullname_first_author": "J. Lee", "paper_title": "Nu-wave: A diffusion probabilistic model for neural audio upsampling", "publication_date": "2021-XX-XX", "reason": "This paper introduces a diffusion probabilistic model for audio upsampling, a key technique related to speech super-resolution."}, {"fullname_first_author": "K. Zhang", "paper_title": "WSRGlow: A glow-based waveform generative model for audio super-resolution", "publication_date": "2021-XX-XX", "reason": "This paper presents another relevant generative model for audio super-resolution, offering a comparison point for the proposed method."}, {"fullname_first_author": "S. Zhao", "paper_title": "MossFormer2: Combining transformer and RNN-free recurrent network for enhanced time-domain monaural speech separation", "publication_date": "2023-XX-XX", "reason": "The MossFormer2 block is a key component of the proposed model's architecture, making this paper essential for understanding the core methodology."}]}