[{"content": "| Dataset | Multimodal | Cover holistic dimensions (e.g. reasoning, safety) | Human expert annotated / High inter-annotator agreement |\n|---|---|---|---| \n| Anthropic HH<br>OpenAI Summarization<br>JudgeBench |  |  |  |\n| RewardBench |  | \u2714 |  |\n| Prometheus-Vision<br>Llava-critic<br>VLRewardBench<br>MLLM-as-a-Judge | \u2714 |  |  |\n| Multimodal-RewardBench (Ours) | \u2714 | \u2714 | \u2714 |", "caption": "Table 1: Comparison with existing evaluation data for reward models. Our Multimodal RewardBench is the first holistic benchmark for evaluating reward models for multimodal LLMs (vision-language models).", "description": "\ud45c 1\uc740 \uae30\uc874\uc758 \ubcf4\uc0c1 \ubaa8\ub378 \ud3c9\uac00 \ub370\uc774\ud130\uc640 \uc81c\uc548\ud558\ub294 \ub2e4\uc911 \ubaa8\ub4dc RewardBench\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4. \uae30\uc874 \uc5f0\uad6c\ub4e4\uc740 \uc77c\ubc18\uc801\uc778 VQA \uc791\uc5c5\uc5d0 \uad6d\ud55c\ub418\uac70\ub098, \uc0ac\ub78c\uc774 \uc9c1\uc811 \uc8fc\uc11d\uc744 \ub2ec\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\ub294 \ub4f1 \ud55c\uacc4\uc810\uc744 \uc9c0\ub2c8\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ubc18\uba74, RewardBench\ub294 \ucd94\ub860, \uc548\uc804, VQA\ub97c \ud3ec\ud568\ud55c 6\uac00\uc9c0 \uc601\uc5ed\uc744 \ub2e4\ub8e8\ub294 \uc885\ud569\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\ub85c, \uc804\ubb38\uac00\uac00 \uc9c1\uc811 \uc8fc\uc11d\uc744 \ub2ec\uc544 \uc2e0\ub8b0\ub3c4\ub97c \ub192\uc600\uc2b5\ub2c8\ub2e4.  \ub530\ub77c\uc11c \ub2e4\uc591\ud55c \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378(VLMs)\uc758 \ubcf4\uc0c1 \ubaa8\ub378\uc744 \ud3c9\uac00\ud558\ub294 \ucd5c\ucd08\uc758 \uc885\ud569\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\uc784\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "2 Related works"}, {"content": "| Cover holistic dimensions |\n|---|---| \n| (e.g. reasoning, safety) |", "caption": "Table 2: Summary of Multimodal RewardBench, a holistic benchmark for evaluating reward models for vision-language models (VLMs). We cover six key areas relevant to VLMs: general correctness, general preference, knowledge, reasoning, safety, and VQA. We cover both long and short response formats, and assess both types of judge tasks: \u2019correct vs incorrect response\u2019 and \u2019human-preferred vs non-preferred\u2019 (provided both responses are either correct or incorrect). Our judge labels for long-form responses are collected by high-quality annotation from human experts.", "description": "\ud45c 2\ub294 \uc2dc\uac01 \uc5b8\uc5b4 \ubaa8\ub378(VLMs)\uc744 \uc704\ud55c \ubcf4\uc0c1 \ubaa8\ub378 \ud3c9\uac00\ub97c \uc704\ud55c \uc885\ud569\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\uc778 Multimodal RewardBench\uc758 \uc694\uc57d\uc785\ub2c8\ub2e4. \uc774 \ubca4\uce58\ub9c8\ud06c\ub294 VLMs\uc640 \uad00\ub828\ub41c \uc5ec\uc12f \uac00\uc9c0 \uc8fc\uc694 \uc601\uc5ed(\uc77c\ubc18 \uc815\ud655\uc131, \uc77c\ubc18 \uc120\ud638\ub3c4, \uc9c0\uc2dd, \ucd94\ub860, \uc548\uc804, VQA)\uc744 \ub2e4\ub8f9\ub2c8\ub2e4. \uae34 \uc751\ub2f5\uacfc \uc9e7\uc740 \uc751\ub2f5 \ud615\uc2dd \ubaa8\ub450\ub97c \ub2e4\ub8e8\uace0 \uc788\uc73c\uba70, \ub450 \uac00\uc9c0 \uc720\ud615\uc758 \ud310\uc815 \uc791\uc5c5('\uc815\ub2f5 \ub300 \uc624\ub2f5' \ubc0f '\uc0ac\ub78c\uc774 \uc120\ud638\ud558\ub294 \uc751\ub2f5 \ub300 \ube44\uc120\ud638 \uc751\ub2f5'(\ub450 \uc751\ub2f5 \ubaa8\ub450 \uc815\ub2f5\uc774\uac70\ub098 \uc624\ub2f5\uc778 \uacbd\uc6b0))\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uae34 \ud615\uc2dd \uc751\ub2f5\uc5d0 \ub300\ud55c \ud310\uc815 \ub808\uc774\ube14\uc740 \uc804\ubb38\uac00\uc758 \uace0\ud488\uc9c8 \uc8fc\uc11d\uc744 \ud1b5\ud574 \uc218\uc9d1\ub429\ub2c8\ub2e4.", "section": "3 Multimodal RewardBench"}, {"content": "| Human expert annotated / | High inter-annotator agreement |\n|---|---|", "caption": "Table 3: Accuracy of various VLM judges on Multimodal RewardBench, with a breakdown across task categories. The top-performing models, Claude 3.5 Sonnet, Gemini 1.5 Pro and GPT-4o, achieve only 72% overall accuracy, suggesting that the benchmark offers a challenging testbed for reward model development.\nFor the data source and task definitions of each category, see Table 2.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c VLMs(Vision Language Model)\uc744 Multimodal RewardBench\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc804\ubc18\uc801\uc778 \uc815\ud655\ub3c4\uc640 \uc5ec\uc12f \uac00\uc9c0 \ud558\uc704 \uc791\uc5c5(\uc77c\ubc18\uc801\uc778 \uc815\ud655\uc131, \uc77c\ubc18\uc801\uc778 \uc120\ud638\ub3c4, \uc9c0\uc2dd, \ucd94\ub860, \uc548\uc804, VQA)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \uc138\ubd84\ud654\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uc0c1\uc704 \uc138 \uac1c\uc758 \ubaa8\ub378(Claude 3.5 Sonnet, Gemini 1.5 Pro, GPT-4o)\uc758 \uc804\ubc18\uc801\uc778 \uc815\ud655\ub3c4\ub294 72%\uc5d0 \ubd88\uacfc\ud558\uc5ec, Multimodal RewardBench\uac00 \ubcf4\uc0c1 \ubaa8\ub378 \uac1c\ubc1c\uc5d0 \uc788\uc5b4 \uc0c1\ub2f9\ud788 \uc5b4\ub824\uc6b4 \ubca4\uce58\ub9c8\ud06c\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uac01 \ud558\uc704 \uc791\uc5c5\uc5d0 \ub300\ud55c \ub370\uc774\ud130 \ucd9c\ucc98\uc640 \uc791\uc5c5 \uc815\uc758\ub294 \ud45c 2\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4. \uacb0\uacfc"}]