[{"content": "| Aspect | General Alignment (LIMA) | Complex Reasoning (LIMO) |\n|---|---|---|\n| **Core Capability** | Response format and style adaptation for general-purpose interaction | Multi-step logical inference and complex cognitive reasoning |\n| **Knowledge Foundation** | * General text corpus sufficient<br>* Social interaction patterns<br>* Basic world knowledge | * Diverse reasoning paradigms and problem-solving approaches<br>* Rich context for exploring alternative solutions<br>* Deep conceptual connections across domains |\n| **Computation Requirements** | * Fixed-length generation sufficient<br>* Single-pass processing adequate<br>* Limited context window acceptable | * Scalable inference-time computation essential<br>* Extended reasoning chain support required<br>* Large cognitive workspace necessary |\n| **Historical Prerequisites** | Emerged in 2023, requiring only:<br>* Base models with general knowledge<br>* Basic prompt engineering techniques | Emerged in 2025, requiring convergence of:<br>* Advanced reasoning architectures<br>* Inference-time scaling revolution |\n| **Training Data Quality** | * **Question Design:**<br>\u2013 Common interaction scenarios<br>\u2013 Standard task diversity<br>\u2013 Basic instruction following<br>* **Solution Quality:**<br>\u2013 Clear communication style<br>\u2013 Format consistency<br>\u2013 Appropriate tone | * **Question Design:**<br>\u2013 High-difficulty problems fostering complex reasoning<br>\u2013 Problems deviating from training distribution<br>\u2013 Cross-domain knowledge integration challenges<br>* **Solution Quality:**<br>\u2013 Optimal structure with adaptive step granularity<br>\u2013 Strategic cognitive scaffolding for reasoning<br>\u2013 Rigorous verification throughout solution |", "caption": "Table 1: Comparative Analysis: Less-is-More Phenomena in Language Models", "description": "\ubcf8 \ud45c\ub294 \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uc5d0\uc11c\uc758 'Less-is-More' \ud604\uc0c1\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  'Less-is-More' \ud604\uc0c1\uc774\ub780, \ubcf5\uc7a1\ud55c \ucd94\ub860 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \ubc29\ub300\ud55c \uc591\uc758 \ub370\uc774\ud130\uac00 \ud544\uc694\ud558\ub2e4\ub294 \uae30\uc874\uc758 \ud1b5\ub150\uacfc \ub2ec\ub9ac, \uc801\uc740 \uc591\uc758 \ub370\uc774\ud130\ub9cc\uc73c\ub85c\ub3c4 \ud6a8\uacfc\uc801\uc73c\ub85c \ucd94\ub860 \ub2a5\ub825\uc744 \uc774\ub04c\uc5b4\ub0bc \uc218 \uc788\ub2e4\ub294 \ud604\uc0c1\uc744 \ub9d0\ud569\ub2c8\ub2e4.  \ud45c\ub294 \uc77c\ubc18\uc801\uc778 \uc815\ub82c(Alignment) \uc791\uc5c5\uacfc \ubcf5\uc7a1\ud55c \ucd94\ub860(Reasoning) \uc791\uc5c5\uc5d0\uc11c\uc758 'Less-is-More' \ud604\uc0c1\uc744 \ube44\uad50\ud558\uc5ec, \uac01 \uc791\uc5c5\uc758 \ud575\uc2ec \uae30\ub2a5, \uc9c0\uc2dd \uae30\ubc18, \uacc4\uc0b0 \uc694\uad6c\uc0ac\ud56d, \uc0ac\uc804 \uc870\uac74, \ud559\uc2b5 \ub370\uc774\ud130\uc758 \uc9c8\uc801 \ucc28\uc774 \ub4f1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \uc791\uc5c5 \uac04\uc758 \ucc28\uc774\uc810\uc744 \uba85\ud655\ud788 \ud558\uc5ec 'Less-is-More' \ud604\uc0c1\uc774 \uc5b4\ub5bb\uac8c \ub098\ud0c0\ub098\ub294\uc9c0\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "1 Introduction"}, {"content": "| Aspect | RL Scaling (e.g., o1, R1) | LIMO |\n|---|---|---|\n| **First Principle** | An implementation of the general principle: searching for optimal reasoning trajectories through RL | The fundamental principle: reasoning capabilities exist and need to be activated by high-quality reasoning trajectories |\n| **Solution Nature** | Discovers reasoning trajectories through extensive RL-based exploration | Directly constructs high-quality reasoning trajectories based on cognitive understanding |\n| **Core Challenge** | How to efficiently search for effective reasoning trajectories in a large solution space | How to identify and construct optimal reasoning trajectories that activate existing capabilities |\n| **Methodology** | Implicit trajectory discovery through large-scale RL optimization | Explicit trajectory design through cognitive templates |\n| **Search Strategy** | Broad exploration of solution space using computational resources | Targeted exploration guided by cognitive principles |\n| **Resource\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Efficiency** | Resource-intensive search process | Resource-efficient direct construction |\n| **Generalization** | Through extensive sampling of trajectory space | Through understanding of fundamental reasoning patterns |", "caption": "Table 2: Comparative Analysis of LIMO and RL Scaling Approaches", "description": "\ud45c 2\ub294 \uac15\ud654 \ud559\uc2b5(RL) \uae30\ubc18\uc758 \ud655\uc7a5 \uc811\uadfc \ubc29\uc2dd\uacfc LIMO(Less-Is-More Optimization) \uc811\uadfc \ubc29\uc2dd\uc758 \ucc28\uc774\uc810\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  \ub450 \uc811\uadfc \ubc29\uc2dd\uc758 \uae30\ubcf8 \uc6d0\ub9ac, \ud574\uacb0\ucc45\uc758 \ud2b9\uc9d5, \uc8fc\uc694 \uacfc\uc81c, \ud0d0\uc0c9 \uc804\ub7b5, \uc790\uc6d0 \ud6a8\uc728\uc131 \ubc0f \uc77c\ubc18\ud654 \ub2a5\ub825 \ub4f1 \uc5ec\ub7ec \uce21\uba74\uc5d0\uc11c \ube44\uad50\ud558\uc5ec \uac01 \uc811\uadfc \ubc29\uc2dd\uc758 \ud2b9\uc9d5\uacfc \ucc28\uc774\uc810\uc744 \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, RL \uae30\ubc18 \ud655\uc7a5\uc740 \ucd5c\uc801\uc758 \ucd94\ub860 \uacbd\ub85c\ub97c \ucc3e\uae30 \uc704\ud574 \uad11\ubc94\uc704\ud55c \ud0d0\uc0c9\uc744 \uc218\ud589\ud558\ub294 \ubc18\uba74, LIMO\ub294 \uae30\uc874\uc758 \uc0ac\uc804 \ud559\uc2b5\ub41c \uc9c0\uc2dd\uc744 \ud65c\uc6a9\ud558\uc5ec \ud6a8\uc728\uc801\uc73c\ub85c \uace0\ud488\uc9c8 \ucd94\ub860 \uacbd\ub85c\ub97c \uad6c\uc131\ud558\ub294 \ubc29\uc2dd\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd98\ub2e4\ub294 \uc810\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "2 \ud604\uc0c1 \uc7ac\uace0\ucc30: Less-is-More \ubc0f RL \ud655\uc7a5"}, {"content": "| Datasets | OpenAI-o1-preview | Qwen2.5-32B-Instruct | QwQ-32B-preview | OpenThoughts(114k) | NuminaMath(100k) | LIMO ours(817) |\n|---|---|---|---|---|---|---|\n| In Domain |  |  |  |  |  |  |\n| AIME24 | 44.6 | 16.5 | 50.0 | 50.2 | 6.5 | **57.1** |\n| MATH500 | 85.5 | 79.4 | 89.8 | 80.6 | 59.2 | **94.8** |\n| AMC23 | 81.8 | 64.0 | 83.6 | 80.5 | 40.6 | **92.0** |\n| Out of Domain |  |  |  |  |  |  |\n| OlympiadBench | 52.1 | 45.3 | 58.5 | 56.3 | 36.7 | **66.8** |\n| CHMath | 50.0 | 27.3 | 68.5 | 74.1 | 11.2 | **75.4** |\n| Gaokao | 62.1 | 72.1 | 80.1 | 63.2 | 49.4 | **81.0** |\n| Kaoyan | 51.5 | 48.2 | 70.3 | 54.7 | 32.7 | **73.4** |\n| GradeSchool | 62.8 | 56.7 | 63.8 | 39.0 | 36.2 | **76.2** |\n| Minerva | **47.1** | 41.2 | 39.0 | 41.1 | 24.6 | 44.9 |\n| GPQA | **73.3** | 48.0 | 65.1 | 42.9 | 25.8 | 66.7 |\n| AVG. | 61.1 | 49.9 | 66.9 | 58.3 | 32.3 | **72.8** |", "caption": "Table 3: \nComparison of model performance (pass@1) across various mathematical reasoning benchmarks Models include state-of-the-art LLMs (OpenAI-o1-preview, QwQ-32B-Preview), our base model (Qwen2.5-32B-Instruct), and models fine-tuned on different datasets. Training data sizes are shown in parentheses.\nBest results for each benchmark are shown in bold. Our proposed LIMO model (highlighted in blue) achieves superior performance despite using significantly fewer training examples (817) compared to other fine-tuned models (more than 100k).", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \uc218\ud559\uc801 \ucd94\ub860 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ubaa8\ub378 \uc131\ub2a5(pass@1)\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \ucd5c\ucca8\ub2e8 LLMs(OpenAI-o1-preview, QwQ-32B-Preview), \uae30\ubcf8 \ubaa8\ub378(Qwen2.5-32B-Instruct) \ubc0f \uc5ec\ub7ec \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uad04\ud638 \uc548\uc5d0\ub294 \ud559\uc2b5 \ub370\uc774\ud130 \ud06c\uae30\ub97c \ud45c\uc2dc\ud558\uba70, \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub294 \uad75\uac8c \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4. \uc81c\uc548\ub41c LIMO \ubaa8\ub378(\ud30c\ub780\uc0c9\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc)\uc740 \ub2e4\ub978 \ubbf8\uc138 \uc870\uc815 \ubaa8\ub378(10\ub9cc \uac1c \uc774\uc0c1)\uc5d0 \ube44\ud574 \ud6e8\uc52c \uc801\uc740 \ud559\uc2b5 \uc608\uc81c(817\uac1c)\ub97c \uc0ac\uc6a9\ud588\uc74c\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4.", "section": "5.2 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Data Quality Level | Avg. Tokens per response | Avg. Lines per response | Top 10 Frequently Occurring Keywords (in order) |\n|---|---|---|---| \n| Level 1 | 230 | 9.21 | since, however, number, let, thus, which, get, two, triangle, theta |\n| Level 2 | 444.88 | 50.68 | number, need, times, which, find, list, thus, since, triangle, sum |\n| Level 3 | 4956.11 | 375.60 | perhaps, alternatively, consider, number, wait, which, sides, need, equal, seems |\n| Level 4 | 4726.97 | 354.87 | wait, which, number, perhaps, therefore, let, since, maybe, sides, two |\n| Level 5 | 5290.26 | 239.29 | wait, therefore, which, number, since, lets, two, sides, let, maybe |", "caption": "Table 4: \nStatistical analysis of models trained with examples of varying data quality. This table presents three key metrics: average token count per response, average line count per response, and frequently occurring keywords in model-generated responses. Keywords associated with reasoning transitions and uncertainty are highlighted in bold, with common stop words (e.g., \u201ca\u201d, \u201cthe\u201d) excluded to focus on substantive language patterns. Notable differences in response length and keyword usage patterns suggest varying levels of reasoning complexity.", "description": "\ud45c 4\ub294 \ub2e4\uc591\ud55c \ud488\uc9c8\uc758 \uc608\uc2dc\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc5d0 \ub300\ud55c \ud1b5\uacc4\uc801 \ubd84\uc11d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc751\ub2f5\ub2f9 \ud3c9\uade0 \ud1a0\ud070 \uc218, \uc751\ub2f5\ub2f9 \ud3c9\uade0 \uc904 \uc218, \uadf8\ub9ac\uace0 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc751\ub2f5\uc5d0\uc11c \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294 \ud0a4\uc6cc\ub4dc\ub77c\ub294 \uc138 \uac00\uc9c0 \uc8fc\uc694 \uc9c0\ud45c\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \ucd94\ub860 \uc804\ud658 \ubc0f \ubd88\ud655\uc2e4\uc131\uacfc \uad00\ub828\ub41c \ud0a4\uc6cc\ub4dc\ub294 \uad75\uac8c \ud45c\uc2dc\ub418\uba70, \uc77c\ubc18\uc801\uc778 \ubd88\uc6a9\uc5b4(\uc608: \u201ca\u201d, \u201cthe\u201d)\ub294 \uc2e4\uc9c8\uc801\uc778 \uc5b8\uc5b4 \ud328\ud134\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uae30 \uc704\ud574 \uc81c\uc678\ub429\ub2c8\ub2e4. \uc751\ub2f5 \uae38\uc774\uc640 \ud0a4\uc6cc\ub4dc \uc0ac\uc6a9 \ud328\ud134\uc758 \ud604\uc800\ud55c \ucc28\uc774\ub294 \ub2e4\uc591\ud55c \uc218\uc900\uc758 \ucd94\ub860 \ubcf5\uc7a1\uc131\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "6.3 \ub370\uc774\ud130 \ud6a8\uc728\uc131: \uc5b8\uc5b4 \ubaa8\ub378"}]