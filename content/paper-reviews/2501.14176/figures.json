[{"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/improvement/1.png", "caption": "(a) Early inference", "description": "\uadf8\ub9bc 1\uc740 ICRL\ub85c \ud559\uc2b5\ub41c Llama 3.1\uc774 \uc774\uc804\uc5d0 \ubcf8 \uc801 \uc5c6\ub294 Frozen Lake \ud658\uacbd\uc5d0\uc11c \ubb38\uc81c\ub97c \ud478\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ucd08\uae30 \ucd94\ub860 \ub2e8\uacc4\ub85c, \uc5d0\uc774\uc804\ud2b8\uac00 \ubaa9\ud45c\uc5d0 \ub3c4\ub2ec\ud558\uae30 \uc704\ud55c \uacbd\ub85c\ub97c \ucc3e\ub294 \uacfc\uc815\uc5d0\uc11c \uc5ec\ub7ec \uc2e4\uc218\ub97c \ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 \uc911\uac04 \ucd94\ub860 \ub2e8\uacc4\ub85c, \uc5d0\uc774\uc804\ud2b8\uac00 \uacbd\ud5d8\uc744 \ud1b5\ud574 \uc2e4\uc218\ub97c \uc904\uc774\uace0 \ub354 \ud6a8\uc728\uc801\uc778 \uacbd\ub85c\ub97c \ucc3e\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (c)\ub294 \ud6c4\uae30 \ucd94\ub860 \ub2e8\uacc4\ub85c, \uc5d0\uc774\uc804\ud2b8\uac00 \uac70\uc758 \uc644\ubcbd\ud558\uac8c \ubaa9\ud45c\uc5d0 \ub3c4\ub2ec\ud558\ub294 \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 ICRL\uc774 \uc5d0\uc774\uc804\ud2b8\uac00 \ubc18\ubcf5\uc801\uc778 \uc2dc\ud589\ucc29\uc624\ub97c \ud1b5\ud574 \ud559\uc2b5\ud558\uace0 \uac1c\uc120\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/improvement/2.png", "caption": "(b) Mid inference", "description": "\uadf8\ub9bc\uc740 ICRL\ub85c \ud6c8\ub828\ub41c Llama 3.1 \ubaa8\ub378\uc774 \uc774\uc804\uc5d0 \ubcf8 \uc801 \uc5c6\ub294 Frozen Lake \ud658\uacbd\uc744 \ud478\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  (b) Mid inference \ub294 \ud559\uc2b5 \ucd08\uae30 \ub2e8\uacc4\ubcf4\ub2e4 \ub098\uc544\uc84c\uc9c0\ub9cc, \uc5ec\uc804\ud788 \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\uc9c0 \ubabb\ud558\uace0 \uc2e4\uc218\ub97c \ud558\ub294 \uc911\uac04 \ub2e8\uacc4\uc758 \ucd94\ub860 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ucd08\uae30 \ucd94\ub860 \ub2e8\uacc4\ubcf4\ub2e4 \ud6a8\uc728\uc131\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc9c0\ub9cc, \uc644\ubcbd\ud55c \ud574\uacb0\ucc45\uc5d0 \ub3c4\ub2ec\ud558\uc9c0\ub294 \ubabb\ud588\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/improvement/3.png", "caption": "(c) Late inference", "description": "\uadf8\ub9bc 1(c)\ub294 ICRL\ub85c \ud6c8\ub828\ub41c Llama 3.1 \ubaa8\ub378\uc774 \uc774\uc804\uc5d0 \ubcf8 \uc801 \uc5c6\ub294 Frozen Lake \ud658\uacbd\uc5d0\uc11c \ubb38\uc81c \ud574\uacb0 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucd08\uae30 \uc2dc\ub3c4(a)\uc5d0\uc11c\ub294 \uc2e4\uc218\uac00 \ub9ce\uc9c0\ub9cc(\uc608: \uad6c\uba4d\uc5d0 \ube60\uc9d0), \ud559\uc2b5\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c(b, c) \uc815\ud655\ub3c4\uac00 \ub192\uc544\uc9c0\uace0 \ud6a8\uc728\uc801\uc778 \uacbd\ub85c\ub97c \ucc3e\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uacbd\ud5d8\uc744 \ud1b5\ud574 \ubb38\uc81c \ud574\uacb0 \uc804\ub7b5\uc744 \uac1c\uc120\ud558\uace0 \uc801\uc751\ud558\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/Transformer.png", "caption": "Figure 1: ICRL-trained Llama 3.1 learns to solve an unseen Frozen Lake environment. The trajectories in early (1(a)), mid (1(b)), and late (1(c)) interactions show solution refinement. Mistakes in early inference (e.g., falling into holes) disappear with experience in late inference.", "description": "\uadf8\ub9bc 1\uc740 ICRL(In-Context Reinforcement Learning) \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5\ub41c Llama 3.1 \uc5b8\uc5b4 \ubaa8\ub378\uc774 \uc774\uc804\uc5d0 \ubcf8 \uc801 \uc5c6\ub294 Frozen Lake \ud658\uacbd(\uac8c\uc784)\uc744 \ud559\uc2b5\ud558\uace0 \ud478\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  (a)\ub294 \ucd08\uae30 \uc2dc\ub3c4, (b)\ub294 \uc911\uac04 \ub2e8\uacc4, (c)\ub294 \ud559\uc2b5 \ud6c4\ubc18\ubd80\uc758 \uc774\ub3d9 \uacbd\ub85c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucd08\uae30\uc5d0\ub294 \uae38\uc744 \uc798\ubabb \ucc3e\uc544 \uad6c\uba4d\uc5d0 \ube60\uc9c0\ub294 \uc2e4\uc218\ub97c \ud558\uc9c0\ub9cc, \uacbd\ud5d8\uc774 \uc313\uc774\uba74\uc11c(\ubc18\ubcf5 \ud559\uc2b5) \ud6a8\uc728\uc801\uc778 \uacbd\ub85c\ub97c \ucc3e\uc544 \ubaa9\ud45c\uc5d0 \ub3c4\ub2ec\ud558\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 ICRL\uc774 \ubaa8\ub378\uc774 \uc0c8\ub85c\uc6b4 \ubb38\uc81c\uc5d0 \uc801\uc751\ud558\uace0 \ud574\uacb0\ucc45\uc744 \uac1c\uc120\ud574 \ub098\uac00\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc88b\uc740 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/chaining/1.png", "caption": "Figure 2: Fine-tuning LLaMA 3.1 8B Instruct with IA3 Adapters and a reinforcement learning objective. The model is fed sequences of states, actions, and (if nonzero) rewards, with every episode prefixed by the <|begin_of_text|> (BOT) token and terminated by the <|end_of_text|> (EOT) token. Tokens like <|start_header_id|> (SHI), <|end_header_id|> (EHI), and <|eot_id|> (EID) separate the state, action, and reward, mirroring how instruct models delineate user and assistant roles. The model predicts the Q-value of the current state for every action, updating the Q-values during training using the Bellman backup equation.", "description": "\ubcf8 \uadf8\ub9bc\uc740 IA3 \uc5b4\ub311\ud130\uc640 \uac15\ud654 \ud559\uc2b5 \ubaa9\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ub41c LLaMA 3.1 8B Instruct \ubaa8\ub378\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378\uc740 <|begin_of_text|> (BOT) \ud1a0\ud070\uc73c\ub85c \uc2dc\uc791\ud558\uace0 <|end_of_text|> (EOT) \ud1a0\ud070\uc73c\ub85c \ub05d\ub098\ub294 \uc5d0\ud53c\uc18c\ub4dc\ub85c \uad6c\uc131\ub41c \uc0c1\ud0dc, \ud589\ub3d9, \uadf8\ub9ac\uace0 \ubcf4\uc0c1(0\uc774 \uc544\ub2cc \uacbd\uc6b0) \uc2dc\ud000\uc2a4\ub97c \uc785\ub825\ubc1b\uc2b5\ub2c8\ub2e4. <|start_header_id|> (SHI), <|end_header_id|> (EHI), <|eot_id|> (EID) \uc640 \uac19\uc740 \ud1a0\ud070\uc740 \uc0c1\ud0dc, \ud589\ub3d9, \ubcf4\uc0c1\uc744 \uad6c\ubd84\ud558\uba70, \uc774\ub294 \uc9c0\uc2dc \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\uc790\uc640 \uc5b4\uc2dc\uc2a4\ud134\ud2b8\uc758 \uc5ed\ud560\uc744 \uad6c\ubd84\ud558\ub294 \ubc29\uc2dd\uc744 \ubc18\uc601\ud569\ub2c8\ub2e4. \ubaa8\ub378\uc740 \ud604\uc7ac \uc0c1\ud0dc\uc758 \uac01 \ud589\ub3d9\uc5d0 \ub300\ud55c Q-\uac12\uc744 \uc608\uce21\ud558\uace0, \ubca8\ub9cc \ubc31\uc5c5 \ubc29\uc815\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5 \uc911\uc5d0 Q-\uac12\uc744 \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.", "section": "3 Methodology"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/chaining/2.png", "caption": "Figure 3: Mean cumulative reward over 50 trials as an ICRL-trained transformer improves its score on unseen environments. Maps (i.e. environment parametrization) have never been trained on but are chosen from the same distribution as training examples. Significant improvement (approximately 900% when \u03b1=0.1\ud835\udefc0.1\\alpha=0.1italic_\u03b1 = 0.1) can be observed as the agent demonstrates that it has learned to solve unseen maps. Also, \u03b1=0.1\ud835\udefc0.1\\alpha=0.1italic_\u03b1 = 0.1 significantly outperforms \u03b1=0.01\ud835\udefc0.01\\alpha=0.01italic_\u03b1 = 0.01.", "description": "\uadf8\ub9bc 3\uc740 ICRL\ub85c \ud559\uc2b5\ub41c \ud2b8\ub79c\uc2a4\ud3ec\uba38\uac00 \uc774\uc804\uc5d0 \ubcf8 \uc801 \uc5c6\ub294 \ud658\uacbd\uc5d0\uc11c \uc810\uc218\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uacfc\uc815\uc744 50\ubc88\uc758 \uc2dc\ub3c4\uc5d0 \uac78\uccd0 \ud3c9\uade0 \ub204\uc801 \ubcf4\uc0c1\uc73c\ub85c \ub098\ud0c0\ub0b8 \uac83\uc785\ub2c8\ub2e4.  \ub9f5(\ud658\uacbd \ub9e4\uac1c\ubcc0\uc218\ud654)\uc740 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \uc801\uc774 \uc5c6\uc9c0\ub9cc \ud559\uc2b5 \ub370\uc774\ud130\uc640 \uac19\uc740 \ubd84\ud3ec\uc5d0\uc11c \uc120\ud0dd\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \u03b1=0.1\uc77c \ub54c \uc57d 900%\uc758 \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc774 \uad00\ucc30\ub418\ub294\ub370, \uc774\ub294 \uc5d0\uc774\uc804\ud2b8\uac00 \ubcf4\uc9c0 \ubabb\ud588\ub358 \ub9f5\uc744 \ud574\uacb0\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud588\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c \u03b1=0.1\uc774 \u03b1=0.01\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ud2b8\ub79c\uc2a4\ud3ec\uba38\uac00 \uc0c8\ub85c\uc6b4 \ud658\uacbd\uc5d0 \uc801\uc751\ud558\uace0 \ubb38\uc81c \ud574\uacb0 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1 \ubbf8\ub4f1\ub85d \ubd84\ud3ec \ub0b4 \ud658\uacbd \ud574\uacb0"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/chaining/3.png", "caption": "Figure 4: Mean cumulative reward over 50 trials as an ICRL-trained transformer improves its score on unseen and out-of-distribution environments. Generated maps are larger than anything ever seen during training. Improvement can be observed (though not as significant as in the in-distribution case) as the agent demonstrates that it has learned useful behaviors even for environments outside the distribution of its training data.", "description": "\uadf8\ub9bc 4\ub294 ICRL\ub85c \ud559\uc2b5\ub41c \ud2b8\ub79c\uc2a4\ud3ec\uba38\uac00 \ud6c8\ub828 \uc911\uc5d0 \ubcf8 \uc801 \uc5c6\ub294, \ubd84\ud3ec \ubc16 \ud658\uacbd\uc5d0\uc11c \uc810\uc218\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uacfc\uc815\uc744 50\ubc88\uc758 \uc2dc\ub3c4\uc5d0 \uac78\uccd0 \ub204\uc801 \ubcf4\uc0c1\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0dd\uc131\ub41c \uc9c0\ub3c4\ub294 \ud6c8\ub828 \uc911\uc5d0 \ubcf4\uc558\ub358 \uac83\ubcf4\ub2e4 \ud06c\uae30\uac00 \ub354 \ud07d\ub2c8\ub2e4. \ud6c8\ub828 \ub370\uc774\ud130\uc758 \ubd84\ud3ec\ub97c \ubc97\uc5b4\ub09c \ud658\uacbd\uc5d0\uc11c\ub3c4 \uc720\uc6a9\ud55c \ud589\ub3d9\uc744 \ud559\uc2b5\ud588\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac1c\uc120\uc774 \uad00\ucc30\ub418\uc9c0\ub9cc, \ubd84\ud3ec \ub0b4 \ud658\uacbd\uc5d0\uc11c\ub9cc\ud07c \ub450\ub4dc\ub7ec\uc9c0\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "4.2 \ubd84\ud3ec \ubc16 \ud658\uacbd \ud480\uae30"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/chaining/4.png", "caption": "(a) Example 1", "description": "\uadf8\ub9bc 5(a)\ub294 \ub17c\ubb38\uc758 4.3\uc808 \"\ubb38\ub9e5 \ub0b4 \ud589\ub3d9 \uc5f0\uacb0\"\uc5d0\uc11c \uc124\uba85\ud558\ub294, \uc5d0\uc774\uc804\ud2b8\uac00 \uacbd\ud5d8\uc744 \ud1b5\ud574 \ud559\uc2b5\ud55c \uc5ec\ub7ec \uacbd\ub85c\ub4e4\uc744 \uc870\ud569\ud558\uc5ec \ubcf5\uc7a1\ud55c \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc \uc911 \ud558\ub098\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \uc5d0\uc774\uc804\ud2b8\uac00 \ubaa9\ud45c\uc5d0 \ub3c4\ub2ec\ud558\uae30 \uc704\ud574 \ub450 \uac00\uc9c0 \uc11c\ub85c \ub2e4\ub978 \uacbd\ub85c\ub97c \uc870\ud569\ud558\uc5ec \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uacbd\ub85c\ub294 \uc11c\ub85c \ub2e4\ub978 \uc2dc\uc791\uc810\uacfc \uc7a5\uc560\ubb3c\uc744 \uac00\uc9c0\uace0 \uc788\uc73c\uba70, \uc5d0\uc774\uc804\ud2b8\ub294 \uc774\ub7ec\ud55c \uacbd\ud5d8\ub4e4\uc744 \uacb0\ud569\ud558\uc5ec \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\uc544\ub0c5\ub2c8\ub2e4.", "section": "4.3 \ubb38\ub9e5 \ub0b4 \ud589\ub3d9 \uc5f0\uacb0"}, {"figure_path": "https://arxiv.org/html/2501.14176/extracted/6152569/img/chaining/5.png", "caption": "(b) Example 2", "description": "\uadf8\ub9bc (b)\ub294 \ub17c\ubb38\uc758 4.3\uc808 \"\ubb38\ub9e5 \ub0b4 \ud589\ub3d9 \uc5f0\uacb0(In-Context Behavior Stitching)\"\uc5d0\uc11c \uc124\uba85\ud558\ub294 \ub0b4\uc6a9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \uc5d0\uc774\uc804\ud2b8\uac00 \uacbd\ud5d8\uc744 \ud1b5\ud574 \ubc30\uc6b4 \uc5ec\ub7ec\uac00\uc9c0 \uacbd\ub85c\ub4e4\uc744 \uc870\ud569\ud558\uc5ec \uc0c8\ub85c\uc6b4 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc \uc911 \ud558\ub098\uc785\ub2c8\ub2e4. \uadf8\ub9bc (a)\uc640 \ud568\uaed8 \ub450 \uac00\uc9c0 \ub2e4\ub978 \uacbd\ub85c\ub97c \ubcf4\uc5ec\uc8fc\uace0, \uc774\ub97c \ubc14\ud0d5\uc73c\ub85c \uc5d0\uc774\uc804\ud2b8\uac00 \uc5b4\ub5bb\uac8c \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\uc544\uac00\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, (b)\ub294 \uc5d0\uc774\uc804\ud2b8\uac00 \ubaa9\ud45c\uc5d0 \ub3c4\ub2ec\ud558\ub294 \ub450 \ubc88\uc9f8 \uc608\uc2dc \uacbd\ub85c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  (a)\uc640 (b)\uc758 \uacbd\ub85c\ub97c \ud568\uaed8 \ud65c\uc6a9\ud558\uc5ec (c), (d), (e)\uc5d0\uc11c \ubcf4\uc5ec\uc9c0\ub294 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uc2dc\ub3c4\uc5d0\uc11c \uc5d0\uc774\uc804\ud2b8\uac00 \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\uc544\uac00\ub294 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \ubb38\ub9e5 \ub0b4 \ud589\ub3d9 \uc5f0\uacb0"}]