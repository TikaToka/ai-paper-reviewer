[{"content": "| # | Method (M<sup>2</sup>@ 128) | PSNR<sub>val</sub> \u2191 | PSNR<sub>train</sub> \u2191 |\n|---|---|---|---|\n| 1. | Mid-trained (No Overfitting) | 19.23 | 19.70 |\n| 2. | + Camera (w/ MLP) [47, 73] | 17.95<sub>-1.28</sub> | 19.92<sub>+0.22</sub> |\n| 3. | + Pl\u00fccker (w/ MLP) [8, 75, 37, 27] | 18.89<sub>-0.34</sub> | 20.74<sub>+1.04</sub> |\n| 4. | + ControlMLP | 19.45<sub>+0.22</sub> | 29.36<sub>+9.66</sub> |\n| 5. | + SIREN | 20.13<sub>+0.90</sub> | 30.19<sub>+10.49</sub> |\n| 6. | + Spatial Anchor (Ours) | 22.60<sub>+3.37</sub> | 30.49<sub>+10.79</sub> |", "caption": "Table 1: \nEvaluating and Designing Spatial Controls (Sec.\u00a03.3). We overfit our multi-view model for 10101010K iterations on 100 views of a single scene from our Head-only dataset, and evaluate on 60 novel views of this scene by only varying the spatial controls (camera and Spatial Anchor). We use this setup to test the modulation strength of different spatial controls. Subscript values green/red show deviations from Row 1.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 3.3\uc808 \"Understanding and Improving Spatial Control\"\uc5d0\uc11c \ub2e4\uc591\ud55c \uacf5\uac04 \uc81c\uc5b4 \ubc29\uc2dd\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc218\ud589\ub41c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Head-only \ub370\uc774\ud130\uc14b\uc758 \ub2e8\uc77c \uc7a5\uba74\uc5d0 \ub300\ud574 100\uac1c\uc758 \ubdf0\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc744 \uacfc\uc801\ud569(overfitting) \ud559\uc2b5\uc2dc\ud0a8 \ud6c4, \uacf5\uac04 \uc81c\uc5b4 \ubc29\uc2dd(\uce74\uba54\ub77c \ubc0f \uacf5\uac04 \uc575\ucee4)\ub9cc \ubcc0\uacbd\ud558\uc5ec 60\uac1c\uc758 \uc0c8\ub85c\uc6b4 \ubdf0\uc5d0 \ub300\ud574 \uc131\ub2a5\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4.  1\ud589\uc758 \uacb0\uacfc\ub97c \uae30\uc900\uc73c\ub85c \uac01 \ubc29\uc2dd\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \uc591\uc218(+) \ub610\ub294 \uc74c\uc218(-)\ub85c \ud45c\uc2dc\ud558\uc5ec, \uac01 \uacf5\uac04 \uc81c\uc5b4 \ubc29\uc2dd\uc758 \ubcc0\uc870 \uac15\ub3c4(modulation strength)\ub97c \ud14c\uc2a4\ud2b8\ud588\uc2b5\ub2c8\ub2e4.", "section": "3.3 Understanding and Improving Spatial Control"}, {"content": "| # | Method (Stage @ Resolution) | FID \u2193 | \n|---|---|---|\n| 1. | Pippo (P1@512) | **51.164** | \n| 2. | Human-centric Filtering (P1@128) | **75.639** | \n| 3. | No Filtering (P1@128) | 86.838 | \n| 4. | Image-conditioned (P1@128) | **75.639** | \n| 5. | Text-conditioned (P1@128) | 109.720 | ", "caption": "Table 2: \nPretraining and Data Filtering. We report results of the full pretrained model P1111@512, and compare\nseveral variants of P1111@128 models. We report FID on iPhone dataset (1k samples).", "description": "\ud45c 2\ub294 \ubaa8\ub378 \uc804\ud6c8\ub828 \ubc0f \ub370\uc774\ud130 \ud544\ud130\ub9c1\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc804\uccb4 \uc804\ud6c8\ub828\ub41c \ubaa8\ub378 P1@512\uc758 \uacb0\uacfc\uc640 \uc5ec\ub7ec \uac00\uc9c0 P1@128 \ubaa8\ub378\uc758 \ube44\uad50 \uacb0\uacfc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. FID\ub294 iPhone \ub370\uc774\ud130\uc14b(1,000\uac1c \uc0d8\ud50c)\uc744 \uae30\ubc18\uc73c\ub85c \uacc4\uc0b0\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc804\ud6c8\ub828 \ubc0f \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc758 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4.", "section": "3.1 \uae30\ubcf8 \ubaa8\ub378"}, {"content": "|                   | # | Split & Resolution | RE@SG \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | Face \u2191 | Body \u2191 |\n|-------------------|----|----------------------|---------|---------|---------|---------|---------|--------|\n| Head-only          | 1. | Studio (128)        | 3.3<sub>+0.8</sub> | 21.0    | 67.6    | 14.8    | 62.0<sub>-13.3</sub> | 61.5<sub>-16.2</sub> |\n|                   | 2. | Studio (1K)         | 3.4<sub>+0.5</sub> | 20.3    | 72.0    | 26.2    | 73.5<sub>-2.5</sub>  | 79.4<sub>-0.1</sub>  |\n|                   | 3. | iPhone Face (1K)     | 3.0      | -       | -       | -       | 67.6    | -      |\n| Full-body         | 4. | Studio (128)        | 3.6<sub>+0.1</sub> | 22.8    | 84.0    | 10.0    | 41.7<sub>-8.5</sub>  | 67.1<sub>-9.4</sub>  |\n|                   | 5. | Studio (1K)         | 1.5<sub>+0.1</sub> | 22.4    | 91.7    | 11.1    | 64.7<sub>-6.0</sub>  | 74.1<sub>-2.2</sub>  |\n|                   | 6. | iPhone (1K)         | 1.7      | -       | -       | -       | 58.0    | 68.1   |", "caption": "Table 3: \nResults on Unseen Studio and iPhone data (Sec.\u00a04.3.) We report results on Post-trained Pippo models at three different resolutions. We report 3D metrics PSNR, SSIM, and LPIPS; as well as our proposed Reprojection Error (RE@SG) under SuperGlue estimation which does not require ground truth (Sec.\u00a03.5). We report 2D Face and Body similarities. Red subscript show deviation against ground truth value.", "description": "\ud45c 3\uc740 \uc0ac\uc804\uc5d0 \ubcf4\uc9c0 \ubabb\ud55c \uc2a4\ud29c\ub514\uc624 \ubc0f \uc544\uc774\ud3f0 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \ud574\uc0c1\ub3c4(128, 512, 1024)\uc5d0\uc11c \uc0ac\ud6c4 \ud559\uc2b5\ub41c Pippo \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4. 3D \uc9c0\ud45c(PSNR, SSIM, LPIPS)\uc640 \uc81c\uc548\ub41c Reprojection Error (RE@SG)\ub97c \uce21\uc815\ud558\uc5ec \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uc640 3D \uc77c\uad00\uc131\uc744 \ud3c9\uac00\ud558\uc600\uc2b5\ub2c8\ub2e4. RE@SG\ub294 SuperGlue \ucd94\uc815 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uba70, \uae30\uc900 \uc9c4\uc2e4 \ub370\uc774\ud130\uac00 \ud544\uc694\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc5bc\uad74\uacfc \uc2e0\uccb4 \uc720\uc0ac\uc131(2D \uc9c0\ud45c)\uc744 \uce21\uc815\ud558\uc5ec \uc2e0\uc6d0 \ubcf4\uc874 \ub2a5\ub825\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\uc11c \ube68\uac04\uc0c9 \ubc11\uc904\uc740 \uae30\uc900 \uc9c4\uc2e4 \uac12\uacfc\uc758 \ud3b8\ucc28\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.3 \uacb0\uacfc"}, {"content": "| # | Method & Resolution | RE@SG \u2193 | Face \u2191 | Body \u2191 |\n|---|---|---|---|---|\n| 1. | MV-Adapter [32] (768) | 4.7 | 43.0 | 64.1 |\n| 2. | Era3D [44] (512) | 4.1 | 38.1 | 64.4 |\n| 3. | Wonder3D [48] (256) | 5.3 | 34.7 | 58.8 |\n| 4. | Pippo (P3@1K) | 3.0 | 58.0 | 68.1 |", "caption": "Table 4: Quantitative comparison with SoTA multi-view models. We quantitatively compare Pippo against state-of-the-art multi-view diffusion models. We find that Pippo preserves identity (i.e.,\u00a0face and body similarity) and 3D consistency (RE) better while operating at a higher resolution compared to baselines.", "description": "\ubcf8 \ud45c\ub294 \ucd5c\ucca8\ub2e8 \ub2e4\uc911 \ubdf0 \ud655\uc0b0 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec Pippo\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Pippo\ub294 \uae30\uc874 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ub192\uc740 \ud574\uc0c1\ub3c4\uc5d0\uc11c \ub3d9\uc791\ud558\uba74\uc11c\ub3c4 \uc5bc\uad74\uacfc \uc2e0\uccb4 \uc720\uc0ac\uc131(\uc815\uccb4\uc131 \ubcf4\uc874) \ubc0f 3D \uc77c\uad00\uc131(RE@SG)\uc744 \ub354 \uc798 \uc720\uc9c0\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, Pippo\uac00 \ub354\uc6b1 \uc0ac\uc2e4\uc801\uc774\uace0 \uc77c\uad00\uc131 \uc788\ub294 \ub2e4\uc911 \ubdf0 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4.3 \uacb0\uacfc"}, {"content": "| # | Dataset (P3@1K) | RE@SG \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | Face \u2191 | Body \u2191 |\n|---|---|---|---|---|---|---|---| \n| 1. | Ava-256 (Head-only) | 3.8 | 20.1 | 68.7 | 26.6 | 72.9 | 76.8 |\n| 2. | Goliath (Full-body) | 1.2 | 20.4 | 89.7 | 15.5 | 87.5 | 77.7 |", "caption": "Table 5: Benchmarking Pippo on public Ava-256 and Goliath datasets. We find that Pippo\u2019s performance on these datasets is inline with its performance on internal studio datasets. This will aid future comparisons against Pippo.", "description": "\ud45c 5\ub294 \uacf5\uac1c\uc801\uc73c\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud55c Ava-256 \ubc0f Goliath \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec Pippo \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubca4\uce58\ub9c8\ud0b9\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294 Pippo \ubaa8\ub378\uc774 \ub0b4\ubd80 \uc2a4\ud29c\ub514\uc624 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubcf4\uc5ec\uc900 \uc131\ub2a5\uacfc \uc720\uc0ac\ud55c \uc218\uc900\uc758 \uc131\ub2a5\uc744 \uacf5\uac1c \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub3c4 \ub2ec\uc131\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \ud5a5\ud6c4 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uacfc Pippo \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\ub294 \ub370 \uc720\uc6a9\ud55c \uae30\uc900\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  Ava-256 \ub370\uc774\ud130\uc14b\uc740 \uba38\ub9ac \ubd80\ubd84\ub9cc \ud3ec\ud568\ud55c \ub370\uc774\ud130\uc774\uace0 Goliath \ub370\uc774\ud130\uc14b\uc740 \uc804\uc2e0 \ub370\uc774\ud130\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.  Pippo \ubaa8\ub378\uc740 \ub450 \ub370\uc774\ud130\uc14b \ubaa8\ub450\uc5d0\uc11c \ub0b4\ubd80 \uc2a4\ud29c\ub514\uc624 \ub370\uc774\ud130\uc14b\uacfc \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uc5b4 \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a8\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 \uacb0\uacfc (Results)"}, {"content": "| # | Method (Stage @ Res.) | RE@SG \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | Face \u2191 | Body \u2191 |\n|---|---|---|---|---|---|---|---| \n| 1. | Pippo (P<sup>3</sup>@512) | 2.7<sub>+0.7</sub> | 21.7 | 71.7 | 21.5 | 74.1<sub>-2.0</sub> | 77.4<sub>-2.4</sub> |\n| 2. | Pippo Face-only (P<sup>3</sup>@512) | 2.4<sub>+0.4</sub> | 20.5 | 70.3 | 25.3 | 74.3<sub>-1.7</sub> | 75.8<sub>-4.0</sub> |\n| 3. | No Mid-train (P<sup>3</sup>@512) | 5.6<sub>+3.6</sub> | 14.5 | 59.5 | 44.2 | 20.4<sub>-55.6</sub> | 63.4<sub>-16.4</sub> |\n| 4. | Pippo (P<sup>3</sup>@128) | 3.3<sub>+0.8</sub> | 21.0 | 67.6 | 14.8 | 62.0<sub>-13.3</sub> | 61.5<sub>-16.2</sub> |\n| 5. | No Anchor (P<sup>3</sup>@128) | 11.5<sub>+9.0</sub> | 17.1 | 54.0 | 21.1 | 63.1<sub>-12.2</sub> | 68.3<sub>-9.3</sub> |\n| 6. | No Pl\u00fccker (P<sup>3</sup>@128) | 4.2<sub>+1.7</sub> | 20.2 | 64.5 | 16.1 | 63.5<sub>-11.8</sub> | 66.1<sub>-11.5</sub> |\n| 7. | Pippo (M<sup>2</sup>@128) | 3.4<sub>+0.9</sub> | 19.1 | 61.4 | 17.2 | 60.0<sub>-15.3</sub> | 62.6<sub>-15.0</sub> |\n| 8. | No Pre-train (M<sup>2</sup>@128) | 5.9<sub>+3.4</sub> | 13.1 | 39.3 | 44.9 | 19.5<sub>-55.8</sub> | 49.0<sub>-28.6</sub> |\n| 9. | Cross-Attn (M<sup>2</sup>@128) | 3.5<sub>+1.0</sub> | 18.0 | 59.2 | 22.1 | 66.2<sub>-9.1</sub> | 70.7<sub>-7.0</sub> |\n| 10. | Non-frontal (M<sup>2</sup>@128) | 5.8<sub>+3.3</sub> | 15.2 | 52.4 | 30.1 | 49.2<sub>-26.1</sub> | 60.7<sub>-16.9</sub> |", "caption": "Table 6: \nAblation on design choices and training stages.\nWe evaluate several multi-view models at 128\u00d7128128128128\\times 128128 \u00d7 128\u00a0and 512\u00d7512512512512\\times 512512 \u00d7 512\u00a0resolution at different training stages on Head-only dataset. We ablate the choice of doing Mid-training and Pre-training, along with different spatial controls and reference conditioning methods..The training stages are labeled as M2222\u00a0(Mid-training) and P3333\u00a0(Post-training), followed by @ specified resolution.", "description": "\ud45c 6\uc740 \ub17c\ubb38\uc758 \ubc29\ubc95\ub860 \uc139\uc158(Method)\uc5d0 \uc788\ub294 \ud45c\ub85c, \ub2e4\uc591\ud55c \ub514\uc790\uc778 \uc120\ud0dd\uacfc \ud559\uc2b5 \ub2e8\uacc4\uc5d0 \ub530\ub978 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Head-only \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec 128x128\uacfc 512x512 \ud574\uc0c1\ub3c4\uc5d0\uc11c \uc5ec\ub7ec \ub2e4\uc911 \ubdf0 \ubaa8\ub378\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4.  Mid-training \ubc0f Pre-training\uc758 \uc5ec\ubd80, \uacf5\uac04 \uc81c\uc5b4 \ubc29\uc2dd, \ucc38\uc870 \uc870\uac74\ud654 \ubc29\ubc95 \ub4f1\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uac01 \uc694\uc18c\uc758 \uc601\ud5a5\uc744 \ud655\uc778\ud569\ub2c8\ub2e4. \ud559\uc2b5 \ub2e8\uacc4\ub294 M2(Mid-training)\uc640 P3(Post-training)\uc73c\ub85c \ud45c\uae30\ub418\uace0, @ \uae30\ud638 \ub4a4\uc5d0 \ud574\uc0c1\ub3c4\uac00 \uba85\uc2dc\ub429\ub2c8\ub2e4.", "section": "3 Method"}, {"content": "| # | Pretrain Data (M\u00b2@128) | RE@SG \u2193 | PSNR \u2191 | SSIM \u2191 | LPIPS \u2193 | Face \u2191 | Body \u2191 |\n|---|---|---|---|---|---|---|---| \n| 1. | 30M (1% HQ) | 3.8 | 21.3 | 81.8 | 13.3 | 30.6 | 66.2 |\n| 2. | 900M (30% Random) | 4.0 | 21.6 | 82.0 | 12.1 | 30.6 | 67.2 |\n| 3. | 2.1B (70% Random) | 3.7 | 21.6 | 82.1 | 12.1 | 37.6 | 67.5 |\n| 4. | Humans-3B (100%) | 3.7 | 21.9 | 82.3 | 12.7 | 41.7 | 67.2 |", "caption": "Table 7: Ablating the size of pre-training dataset on Humans-3B. We conduct Full-body mid-training with pretrained checkpoints trained on 1%, 30%, 70%, and 100% subsets of Humans-3B dataset. We found large-scale data is crucial for generalization to novel identities (i.e.,\u00a0face similarity).", "description": "\ubcf8 \ud45c\ub294 Humans-3B \ub370\uc774\ud130\uc14b\uc758 \uc11c\ube0c\uc14b \ud06c\uae30 \ubcc0\ud654\uc5d0 \ub530\ub978 \uc0ac\uc804 \ud6c8\ub828 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc758 1%, 30%, 70%, 100%\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804 \ud6c8\ub828\ub41c \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc774\uc6a9, \ubcf8 \ub17c\ubb38\uc758 Full-body \uc911\uac04 \ud6c8\ub828\uc744 \uc218\ud589\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc758 \uacb0\uacfc\ub294 \ub300\uaddc\ubaa8 \ub370\uc774\ud130\uac00 \uc0c8\ub85c\uc6b4 \uc2e0\uc6d0(\uc989, \uc5bc\uad74 \uc720\uc0ac\uc131)\uc5d0 \ub300\ud55c \uc77c\ubc18\ud654\uc5d0 \ub9e4\uc6b0 \uc911\uc694\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 \uacb0\uacfc"}, {"content": "| # | Method (Stage @ Resolution) | Views | Speed (sec) \u2193 | \n|---|---|---|---| \n| 1. | Pretrained (P1@256) | 1 | 2.51 | \n| 2. | Pretrained (P1@512) | 1 | 2.59 | \n| 3. | Mid-trained (M2@128) | 4 | 6 | \n| 4. | Mid-trained (M2@128) | 48 | 14 | \n| 5. | Post-trained (P3@512) | 4 | 40 | \n| 6. | Post-trained (P3@512) | 48 | 490 | \n| 7. | Post-trained (P3@1K) | 4 | 185 | \n| 8. | Post-trained (P3@1K) | 12 | 622 | ", "caption": "Table 8: \nInference Speed of Pippo. We show inference speed without any optimizations (using bfloat16) against varying resolution and number of views being generated.", "description": "\ud45c 8\uc740 Pippo \ubaa8\ub378\uc758 \ucd94\ub860 \uc18d\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc591\ud55c \ud574\uc0c1\ub3c4\uc640 \uc0dd\uc131\ub418\ub294 \ubdf0\uc758 \uc218\uc5d0 \ub530\ub978 \ucd94\ub860 \uc18d\ub3c4\ub97c bfloat16\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc801\ud654 \uc5c6\uc774 \uce21\uc815\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ubaa8\ub378\uc758 \uc885\ub958, \ud574\uc0c1\ub3c4, \uc0dd\uc131\ub41c \ubdf0\uc758 \uc218, \uadf8\ub9ac\uace0 \uac01 \uc870\uac74\uc5d0\uc11c\uc758 \ucd94\ub860\uc5d0 \uac78\ub9b0 \uc2dc\uac04(\ucd08)\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc0ac\uc6a9\uc790\uac00 Pippo \ubaa8\ub378\uc744 \uc2e4\uc81c\ub85c \uc0ac\uc6a9\ud560 \ub54c \uc608\uc0c1\ub418\ub294 \ucd94\ub860 \uc2dc\uac04\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 \uae30\ubcf8 \ubaa8\ub378"}]