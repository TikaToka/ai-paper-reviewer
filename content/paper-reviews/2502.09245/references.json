{"references": [{"fullname_first_author": "Arefin", "paper_title": "Seq-VCR: Preventing collapse in intermediate transformer representations for enhanced reasoning", "publication_date": "2024-11-01", "reason": "This paper introduces the concept of representation collapse in transformers and proposes a method to mitigate it, which is directly relevant to the core topic of the current paper."}, {"fullname_first_author": "Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This is the seminal paper introducing the Transformer architecture, which forms the basis for the model discussed in the current paper."}, {"fullname_first_author": "Voita", "paper_title": "The bottom-up evolution of representations in the transformer: A study with machine translation and language modeling objectives", "publication_date": "2019-11-01", "reason": "This paper analyzes the representational dynamics within the Transformer architecture, providing insights into how representations evolve across layers and highlighting the problem of representation collapse."}, {"fullname_first_author": "Zhu", "paper_title": "Hyper-connections", "publication_date": "2024-09-01", "reason": "This paper proposes Hyper-connections, a method to improve the performance of Transformers, which is compared against in the current paper."}, {"fullname_first_author": "Srivastava", "paper_title": "Highway networks", "publication_date": "2015-05-01", "reason": "This paper introduced highway networks, which are relevant to the design and understanding of residual connections in Transformers, a key component discussed in the current paper."}]}