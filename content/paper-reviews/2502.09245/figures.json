[{"figure_path": "https://arxiv.org/html/2502.09245/x1.png", "caption": "Figure 1: Training loss per FLOPs for Llama, Static LIMe, and Dynamic LIMe. LIMe has a substantially lower loss with a similar amount of FLOPs. See Section 5.1 for more details.", "description": "\uadf8\ub9bc 1\uc740 Llama, Static LIMe, Dynamic LIMe \uc138 \uac00\uc9c0 \ubaa8\ub378\uc5d0 \ub300\ud55c \ud559\uc2b5 \uc190\uc2e4(loss) \ub300\ube44 FLOPs(floating point operations) \uadf8\ub798\ud504\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  FLOPs\ub294 \ubaa8\ub378\uc758 \uacc4\uc0b0\ub7c9\uc744 \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\uc774\uba70, \uc190\uc2e4\uc740 \ubaa8\ub378\uc758 \uc608\uce21 \uc815\ud655\ub3c4\uc640 \ubc18\ube44\ub840\ud558\ub294 \uac12\uc785\ub2c8\ub2e4. \uadf8\ub798\ud504\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\ub4ef\uc774, LIMe \ubaa8\ub378 (Static\uacfc Dynamic \ubaa8\ub450)\uc740 Llama \ubaa8\ub378\ubcf4\ub2e4 \ud6e8\uc52c \ub0ae\uc740 \uc190\uc2e4\uc744 \ubcf4\uc774\ub294\ub370, \uc774\ub294 \ub3d9\uc77c\ud55c \uacc4\uc0b0\ub7c9(FLOPs)\uc73c\ub85c \ud6e8\uc52c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud568\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc989, LIMe\ub294 Llama\ubcf4\ub2e4 \ud6a8\uc728\uc131\uc774 \ud6e8\uc52c \ub192\uc740 \ubaa8\ub378\uc784\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4. 5.1\uc808\uc5d0\uc11c \ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.1 Language Modeling"}, {"figure_path": "https://arxiv.org/html/2502.09245/x2.png", "caption": "Figure 2: Mean retrieval weight for each representation (m\ud835\udc5amitalic_m) among later layers (r\ud835\udc5fritalic_r). In both cases, in the last layers, models tend to retrieve information from previous layers rather than from the current one. In the case of Dynamic LIMe, there is a clear bump in retrieving from the first layer. See Section 5.2 for more details.", "description": "\uadf8\ub9bc 2\ub294 \uc5ec\ub7ec \uce35(r)\uc5d0\uc11c \uc774\uc804 \uce35(m)\uc758 \ud45c\ud604\uc5d0 \ub300\ud55c \ud3c9\uade0 \uac80\uc0c9 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \uacbd\uc6b0 \ubaa8\ub450, \ub9c8\uc9c0\ub9c9 \uce35\uc5d0\uc11c\ub294 \ubaa8\ub378\uc774 \ud604\uc7ac \uce35\uc774 \uc544\ub2cc \uc774\uc804 \uce35\uc758 \uc815\ubcf4\ub97c \uac80\uc0c9\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4.  \ub3d9\uc801 LIMe\uc758 \uacbd\uc6b0, \uccab \ubc88\uc9f8 \uce35\uc5d0\uc11c \uc815\ubcf4\ub97c \uac80\uc0c9\ud558\ub294 \ube44\uc728\uc774 \ud655\uc2e4\ud788 \ub192\uc544\uc9c0\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.2\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.2. Analysing Learned Routings in LIMe"}, {"figure_path": "https://arxiv.org/html/2502.09245/x3.png", "caption": "Figure 3: Self Retrieval weights for each head of Static and Dynamic LIMe. Both models assign higher weights to the latest representation in the middle layers, but tend to retrieve lower-level features later. The depicted weights decrease significantly in almost all heads, although some of them still use self-retrieval paths, suggesting the outputs\u2019 refinement stage. Moreover, we can see that Dynamic LIMe\u2019s first layers heavily rely on low-level features due to their sequence conditioning. See Section 5.2 for more details.", "description": "\uadf8\ub9bc 3\uc740 \uc815\uc801 \ubc0f \ub3d9\uc801 LIMe\uc758 \uac01 \ud5e4\ub4dc\uc5d0 \ub300\ud55c \uc790\uae30 \uac80\uc0c9 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubaa8\ub378 \ubaa8\ub450 \uc911\uac04 \uacc4\uce35\uc5d0\uc11c \ucd5c\uc2e0 \ud45c\ud604\uc5d0 \ub354 \ub192\uc740 \uac00\uc911\uce58\ub97c \ud560\ub2f9\ud558\uc9c0\ub9cc, \ub098\uc911\uc5d0\ub294 \uc800\uc218\uc900 \uae30\ub2a5\uc744 \uac80\uc0c9\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \ubb18\uc0ac\ub41c \uac00\uc911\uce58\ub294 \uac70\uc758 \ubaa8\ub4e0 \ud5e4\ub4dc\uc5d0\uc11c \ud06c\uac8c \uac10\uc18c\ud558\uc9c0\ub9cc, \uc77c\ubd80 \ud5e4\ub4dc\ub294 \uc5ec\uc804\ud788 \uc790\uae30 \uac80\uc0c9 \uacbd\ub85c\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd9c\ub825\uc744 \uac1c\uc120\ud558\ub294 \ub2e8\uacc4\ub97c \uc81c\uc548\ud569\ub2c8\ub2e4. \ub610\ud55c \ub3d9\uc801 LIMe\uc758 \uccab \ubc88\uc9f8 \uacc4\uce35\uc740 \uc2dc\ud000\uc2a4 \uc870\uac74 \uc9c0\uc815\uc73c\ub85c \uc778\ud574 \uc800\uc218\uc900 \uae30\ub2a5\uc5d0 \ud06c\uac8c \uc758\uc874\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.2\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.2 Analysing Learned Routings in LIMe"}, {"figure_path": "https://arxiv.org/html/2502.09245/x4.png", "caption": "Figure 4: Expected retrieved representation for each LIMe layer (r\ud835\udc5fritalic_r). Both static and dynamic variants tend to retrieve information from early layers. See Section 5.2 for more details.", "description": "\uadf8\ub9bc 4\ub294 LIMe\uc758 \uac01 \ub808\uc774\uc5b4(r)\uc5d0 \ub300\ud574 \uae30\ub300\ub418\ub294 \uac80\uc0c9\ub41c \ud45c\ud604\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc815\uc801 \ubc0f \ub3d9\uc801 \ubcc0\ud615 \ubaa8\ub450 \ucd08\uae30 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \uac80\uc0c9\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 LIMe\uac00 \uc774\uc804 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \ud45c\ud604\uc758 \ubd95\uad34\ub97c \ubc29\uc9c0\ud558\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uba54\ucee4\ub2c8\uc998\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.2\uc808\uc744 \ucc38\uc870\ud558\uc138\uc694.", "section": "5.2. Analysing Learned Routings in LIMe"}, {"figure_path": "https://arxiv.org/html/2502.09245/x5.png", "caption": "Figure 5: Values\u2019 matrix entropy on FineWeb Edu subset by layers. Both Dynamic and Static LIMe have more diverse values than LLaMa, which indicates more information stored in LIMe.", "description": "\uadf8\ub9bc 5\ub294 FineWeb Edu \ub370\uc774\ud130\uc14b \ud558\uc704 \uc9d1\ud569\uc5d0 \ub300\ud55c \uac01 \uacc4\uce35\ubcc4 \uac12 \ud589\ub82c \uc5d4\ud2b8\ub85c\ud53c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc801 \ubc0f \uc815\uc801 LIMe \ubaa8\ub450 LLaMa\ubcf4\ub2e4 \ub354 \ub2e4\uc591\ud55c \uac12\uc744 \uac00\uc9c0\uba70, \uc774\ub294 LIMe\uac00 \ub354 \ub9ce\uc740 \uc815\ubcf4\ub97c \uc800\uc7a5\ud558\uace0 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  \uc989, \uac01 \ub808\uc774\uc5b4\uc5d0\uc11c \uac12(Value)\ub4e4\uc758 \ub2e4\uc591\uc131\uc744 \uce21\uc815\ud55c \uac83\uc73c\ub85c, \ub2e4\uc591\uc131\uc774 \ud074\uc218\ub85d \ubaa8\ub378\uc774 \ub354 \ub9ce\uc740 \uc815\ubcf4\ub97c \ud45c\ud604\ud558\uace0 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  LLaMa\uc5d0 \ube44\ud574 LIMe(\ub3d9\uc801 \ubc0f \uc815\uc801)\uc758 \uac12\ub4e4\uc774 \ub354 \ub2e4\uc591\ud558\uac8c \ubd84\ud3ec\ub418\uc5b4 \uc788\uc5b4, LIMe\uac00 \ub354\uc6b1 \ud48d\ubd80\ud55c \uc815\ubcf4\ub97c \ud45c\ud604\ud558\uace0 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.3. Representation collapse analysis"}, {"figure_path": "https://arxiv.org/html/2502.09245/x6.png", "caption": "Figure 6: t-SNE of similar tokens\u2019 values among layers. Values obtained from LIMe are separable in later layers, while values in LLaMA become mixed and lose information about tokens. See Section 5.3 for more details.", "description": "\uadf8\ub9bc 6\uc740 \uc720\uc0ac\ud55c \ud1a0\ud070\ub4e4\uc758 \uac12\ub4e4\uc744 \uc5ec\ub7ec \uacc4\uce35\uc5d0 \uac78\uccd0 t-SNE \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. LIMe\uc5d0\uc11c \uc5bb\uc740 \uac12\ub4e4\uc740 \ud6c4\ubc18\ubd80 \uacc4\uce35\uc5d0\uc11c\ub3c4 \uad6c\ubd84 \uac00\ub2a5\ud558\uc9c0\ub9cc, LLaMA\uc5d0\uc11c\ub294 \ud63c\ud569\ub418\uc5b4 \ud1a0\ud070\uc5d0 \ub300\ud55c \uc815\ubcf4\uac00 \uc190\uc2e4\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 LIMe\uac00 \ub2e4\uce35 \uba54\ubaa8\ub9ac \uc811\uadfc\uc744 \ud1b5\ud574 \ud45c\ud604\uc758 \ubd95\uad34\ub97c \ubc29\uc9c0\ud558\uc5ec \ub354\uc6b1 \ud48d\ubd80\ud558\uace0 \uad6c\ubcc4\ub418\ub294 \ud45c\ud604\uc744 \uc0dd\uc131\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.3\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.3 Representation collapse analysis"}, {"figure_path": "https://arxiv.org/html/2502.09245/x7.png", "caption": "Figure 7: Values classification accuracy measured with standard deviation over 5 cross-validation folds. Values in later layers obtained from LIMe can be linearly separated with nearly 1.0 accuracy, while accuracy for values from LLaMA is much lower. See Section 5.3 for more details.", "description": "\uadf8\ub9bc 7\uc740 5\uac1c\uc758 \uad50\ucc28 \uac80\uc99d \ud3f4\ub4dc\uc5d0 \uac78\uccd0 \uce21\uc815\ub41c \uac12 \ubd84\ub958 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LIMe\uc5d0\uc11c \uc5bb\uc740 \ud6c4\uae30 \ub808\uc774\uc5b4\uc758 \uac12\ub4e4\uc740 \uac70\uc758 1.0\uc758 \uc815\ud655\ub3c4\ub85c \uc120\ud615\uc801\uc73c\ub85c \ubd84\ub9ac\ub420 \uc218 \uc788\uc9c0\ub9cc, LLaMA\uc758 \uac12\ub4e4\uc740 \ud6e8\uc52c \ub0ae\uc740 \uc815\ud655\ub3c4\ub97c \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 LIMe\uac00 LLaMA\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ud6a8\uacfc\uc801\uc73c\ub85c \ud1a0\ud070 \uac04\uc758 \ubbf8\ubb18\ud55c \ucc28\uc774\ub97c \uc720\uc9c0\ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.3\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.3. Representation collapse analysis"}, {"figure_path": "https://arxiv.org/html/2502.09245/x8.png", "caption": "Figure 8: Training losses for deep architectures. The LIMe architecture significantly outperforms the baseline, especially in the case of 128128128128 layers. See Section 5.4 for more details.", "description": "\uadf8\ub9bc 8\uc740 \ub2e4\uc591\ud55c \uae4a\uc774\uc758 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \uc544\ud0a4\ud14d\ucc98\uc5d0 \ub300\ud55c \ud6c8\ub828 \uc190\uc2e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788 128\uac1c\uc758 \ub808\uc774\uc5b4\ub97c \uac00\uc9c4 \ubaa8\ub378\uc5d0\uc11c LIMe \uc544\ud0a4\ud14d\ucc98\uac00 \uae30\uc900 \ubaa8\ub378\ubcf4\ub2e4 \ud6e8\uc52c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 LIMe\uac00 \ub2e4\uce35 \uba54\ubaa8\ub9ac \uc811\uadfc \ubc29\uc2dd\uc744 \ud1b5\ud574 \uae4a\uc740 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \ub098\ud0c0\ub098\ub294 \ud45c\ud604 \ubd95\uad34 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uc644\ud654\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ud6c8\ub828 \uc190\uc2e4 \uace1\uc120\uc744 \ud1b5\ud574 LIMe\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uba70, \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ubcf8 \ub17c\ubb38 5.4\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.4 Deep networks performance"}, {"figure_path": "https://arxiv.org/html/2502.09245/x9.png", "caption": "Figure 9: Retrieval weights statistics for a 128-layer LIMe model trained with top-p\ud835\udc5dpitalic_p pruning. The mean retrieval weight from subsequent layers (green curve) displays several distinct peaks, indicating that the model acquires multiple information streams in a self-supervised fashion. The mean self-retrieval weight (orange curve), where 1.0 denotes self-attention, decreases across later layers, forming three consecutive layer groups with different information-processing patterns. See Section\u00a05.4 for further details.", "description": "\uadf8\ub9bc 9\ub294 top-p \uac00\uc9c0\uce58\uae30\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ub41c 128\uacc4\uce35 LIMe \ubaa8\ub378\uc758 \uac80\uc0c9 \uac00\uc911\uce58 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud6c4\uc18d \uacc4\uce35\uc73c\ub85c\ubd80\ud130\uc758 \ud3c9\uade0 \uac80\uc0c9 \uac00\uc911\uce58(\ub179\uc0c9 \uace1\uc120)\ub294 \uc5ec\ub7ec \uac1c\uc758 \uc815\ubcf4 \uc2a4\ud2b8\ub9bc\uc744 \uc790\uae30 \uc9c0\ub3c4 \ubc29\uc2dd\uc73c\ub85c \ubaa8\ub378\uc774 \ud68d\ub4dd\ud55c\ub2e4\ub294 \uac83\uc744 \ub098\ud0c0\ub0b4\ub294 \uc5ec\ub7ec \uac1c\uc758 \ub69c\ub837\ud55c \ud53c\ud06c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc790\uae30 \uac80\uc0c9 \uac00\uc911\uce58(\uc624\ub80c\uc9c0\uc0c9 \uace1\uc120)\uc758 \ud3c9\uade0\uc740 1.0\uc774 \uc790\uae30 \uc8fc\uc758\ub97c \ub098\ud0c0\ub0b4\uba70, \ud6c4\uc18d \uacc4\uce35\uc5d0\uc11c \uac10\uc18c\ud558\uc5ec \uc815\ubcf4 \ucc98\ub9ac \ud328\ud134\uc774 \ub2e4\ub978 \uc138 \uac1c\uc758 \uc5f0\uc18d\uc801\uc778 \uacc4\uce35 \uadf8\ub8f9\uc744 \ud615\uc131\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.4\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.4. \uc2ec\uce35 \ub124\ud2b8\uc6cc\ud06c \uc131\ub2a5"}, {"figure_path": "https://arxiv.org/html/2502.09245/x10.png", "caption": "Figure 10: Self Retrieval weights averaged across heads for each LIMe layer.", "description": "\uadf8\ub9bc 10\uc740 \uac01 LIMe \uacc4\uce35\uc5d0 \ub300\ud574 \ud5e4\ub4dc\uc5d0 \uac78\uccd0 \ud3c9\uade0\ud654\ub41c \uc790\uae30 \uac80\uc0c9 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uac01 LIMe \uacc4\uce35\uc5d0\uc11c \uc774\uc804 \uacc4\uce35\uc758 \ud45c\ud604\uc5d0 \ub300\ud55c \uac01 \ud5e4\ub4dc\uc758 \ud3c9\uade0 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac04\ub2e8\ud788 \ub9d0\ud574, \uc774 \uadf8\ub9bc\uc740 LIMe \ubaa8\ub378\uc758 \uac01 \uacc4\uce35\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc790\uc8fc \uc774\uc804 \uacc4\uce35\uc758 \uc815\ubcf4\ub97c \ucc38\uc870\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \ud45c\ud604\uc785\ub2c8\ub2e4.  x\ucd95\uc740 LIMe \uacc4\uce35\uc758 \ubc88\ud638\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \ud3c9\uade0 \uac00\uc911\uce58\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac00\uc911\uce58\uac00 \ub192\uc744\uc218\ub85d \ud574\ub2f9 \uacc4\uce35\uc774 \uc774\uc804 \uacc4\uce35\uc758 \uc815\ubcf4\ub97c \ub354 \ub9ce\uc774 \ud65c\uc6a9\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774\ub294 LIMe \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uacc4\uce35\uc758 \uc815\ubcf4\ub97c \ud1b5\ud569\ud558\uc5ec \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\ub294 \ubc29\ubc95\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5.2. Analysing Learned Routings in LIMe"}, {"figure_path": "https://arxiv.org/html/2502.09245/x11.png", "caption": "Figure 11: Hiddens\u2019 matrix entropy on FineWeb Edu subset by layers. We can see that hidden states in LIMe can be not very diverse for the model to provide better performance on language tasks. For details, see Section\u00a05.3.", "description": "\uadf8\ub9bc 11\uc740 FineWeb Edu \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac01 \uacc4\uce35\ubcc4 \uc740\ub2c9 \uc0c1\ud0dc\uc758 \ub9e4\ud2b8\ub9ad\uc2a4 \uc5d4\ud2b8\ub85c\ud53c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LIMe\uc758 \uc740\ub2c9 \uc0c1\ud0dc\ub294 \uc5b8\uc5b4 \uc791\uc5c5\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \uc81c\uacf5\ud558\uae30 \uc704\ud574 \ub2e4\uc591\uc131\uc774 \ubd80\uc871\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.3\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "5.3. Representation collapse analysis"}, {"figure_path": "https://arxiv.org/html/2502.09245/x12.png", "caption": "Figure 12: Hidden states classification accuracy measured with standard deviation over 5 cross-validation folds. Although LLaMa\u2019s deeper layers maintain stronger linear separability, LIMe\u2019s hidden states become slightly harder to cluster in later layers due to its ability to smoothly move on to predicting the next token using the full hidden states\u2019 dimensionality.", "description": "\uadf8\ub9bc 12\ub294 5\uac1c\uc758 \uad50\ucc28 \uac80\uc99d \uc138\ud2b8\uc5d0 \ub300\ud55c \ud45c\uc900 \ud3b8\ucc28\ub97c \uce21\uc815\ud558\uc5ec \uc228\uaca8\uc9c4 \uc0c1\ud0dc \ubd84\ub958 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LLaMA\uc758 \uacbd\uc6b0 \uc2ec\uce35 \ub808\uc774\uc5b4\uc5d0\uc11c \uc120\ud615 \ubd84\ub9ac \uac00\ub2a5\uc131\uc774 \ub354 \uac15\ud558\uc9c0\ub9cc, LIMe\ub294 \uc804\uccb4 \uc228\uaca8\uc9c4 \uc0c1\ud0dc\uc758 \ucc28\uc6d0\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc74c \ud1a0\ud070 \uc608\uce21\uc73c\ub85c \uc6d0\ud65c\ud558\uac8c \uc774\ub3d9\ud558\uae30 \ub54c\ubb38\uc5d0 \ud6c4\ubc18 \ub808\uc774\uc5b4\uc5d0\uc11c \ud074\ub7ec\uc2a4\ud130\ub9c1\uc774 \ub2e4\uc18c \uc5b4\ub824\uc6cc\uc9d1\ub2c8\ub2e4.", "section": "5.3. Representation collapse analysis"}, {"figure_path": "https://arxiv.org/html/2502.09245/x13.png", "caption": "Figure 13: Learned static weights and dynamic prior distribution calculated on a subset of Fineweb Edu. Each cell represents retrieval probability for each layer in the specific head.", "description": "\uadf8\ub9bc 13\uc740 Fineweb Edu \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ub41c \uc815\uc801 \uac00\uc911\uce58\uc640 \ub3d9\uc801 \uc0ac\uc804 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc140\uc740 \ud2b9\uc815 \ud5e4\ub4dc \ub0b4 \uac01 \ub808\uc774\uc5b4\uc758 \uac80\uc0c9 \ud655\ub960\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc989, \uac01 \ub808\uc774\uc5b4\uc758 \uc5b4\ud150\uc158 \ud5e4\ub4dc\uac00 \uc774\uc804 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \uc5bc\ub9c8\ub098 \ud65c\uc6a9\ud558\ub294\uc9c0\ub97c \uac00\uc911\uce58\uc758 \ud615\ud0dc\ub85c \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4.  \uc815\uc801 \uac00\uc911\uce58\ub294 \ubaa8\ub4e0 \ud1a0\ud070\uc5d0 \ub300\ud574 \ub3d9\uc77c\ud558\uac8c \uc801\uc6a9\ub418\ub294 \ubc18\uba74, \ub3d9\uc801 \uc0ac\uc804 \ubd84\ud3ec\ub294 \ud1a0\ud070\ub9c8\ub2e4 \ub2e4\ub974\uac8c \uc801\uc6a9\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 LIMe \ubaa8\ub378\uc758 \ub2e4\uce35 \uba54\ubaa8\ub9ac \uc811\uadfc \ubc29\uc2dd\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc2dc\uac01\uc801 \uc790\ub8cc\uc785\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ub808\uc774\uc5b4\uc5d0\uc11c \uc5b4\ud150\uc158 \ud5e4\ub4dc\uac00 \uacfc\uac70 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \uc120\ud0dd\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\ub294 \ud328\ud134\uc744 \ubcf4\uc5ec\uc8fc\uba70, LIMe \ubaa8\ub378\uc758 \ub3d9\uc791 \uba54\ucee4\ub2c8\uc998\uc744 \uc790\uc138\ud788 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "5.2. Analysing Learned Routings in LIMe"}, {"figure_path": "https://arxiv.org/html/2502.09245/x14.png", "caption": "Figure 14: All weights for deep static LIMe with 128 layers. We can see explicitly the repeated routing patterns resembling a refinement process.", "description": " \uadf8\ub9bc 14\ub294 128\uac1c\uc758 \ub808\uc774\uc5b4\ub97c \uac00\uc9c4 \uc2ec\uce35 \uc815\uc801 LIMe\uc5d0 \ub300\ud55c \ubaa8\ub4e0 \uac00\uc911\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc18\ubcf5\uc801\uc778 \ub77c\uc6b0\ud305 \ud328\ud134\uc774 \uc815\uc81c \ud504\ub85c\uc138\uc2a4\ub97c \ub2ee\uc558\ub2e4\ub294 \uac83\uc744 \uba85\ud655\ud558\uac8c \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc989, \uc774 \uadf8\ub9bc\uc740 \uc2ec\uce35 \uc2e0\uacbd\ub9dd\uc5d0\uc11c LIMe\uac00 \uc774\uc804 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc7ac\ud65c\uc6a9\ud558\uc5ec \ud2b9\uc9d5\uc744 \uc815\uc81c\ud558\ub294 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc140\uc740 \ud2b9\uc815 \ud5e4\ub4dc\uc5d0 \ub300\ud55c \ud2b9\uc815 \ub808\uc774\uc5b4\uc758 \uac80\uc0c9 \ud655\ub960\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ub808\uc774\uc5b4\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \ub098\ud0c0\ub098\ub294 \ud328\ud134\uc740 LIMe\uc758 \ud6a8\uc728\uc801\uc778 \ub2e4\uce35 \uba54\ubaa8\ub9ac \uc811\uadfc \ubc29\uc2dd\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "5.4. Deep networks performance"}, {"figure_path": "https://arxiv.org/html/2502.09245/x15.png", "caption": "Figure 15: t-SNE of similar tokens\u2019 hidden states among layers. Although hidden states are not separable in later layers for both models, unlike LLaMA, LIMe can make updates attending to the previous representations, which leads to high values\u2019 separability. See Section 5.3 for more details.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \uc720\uc0ac\ud55c \ud1a0\ud070\ub4e4\uc758 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ub2e4\uc591\ud55c \ub808\uc774\uc5b4\uc5d0\uc11c t-SNE \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. LLaMA \ubaa8\ub378\uacfc \ub2ec\ub9ac LIMe \ubaa8\ub378\uc740 \uc774\uc804 \ub808\uc774\uc5b4\uc758 \ud45c\ud604\uc744 \ucc38\uc870\ud558\uc5ec \uc5c5\ub370\uc774\ud2b8\ub97c \uc218\ud589\ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub294 \ud6c4\ubc18 \ub808\uc774\uc5b4\uc5d0\uc11c \uac12\ub4e4\uc758 \ubd84\ub9ac\uc131\uc744 \ub192\uc774\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4. \uc989, LLaMA\ub294 \ud6c4\ubc18 \ub808\uc774\uc5b4\uc5d0\uc11c \uc720\uc0ac\ud55c \ud1a0\ud070\ub4e4\uc774 \uc11c\ub85c \uad6c\ubd84\uc774 \uc5b4\ub835\uac8c \uc11e\uc774\ub294 \ubc18\uba74, LIMe\ub294 \uc774\uc804 \ub808\uc774\uc5b4\uc758 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \uac01 \ud1a0\ud070\ub4e4\uc744 \ubcf4\ub2e4 \uba85\ud655\ud558\uac8c \uad6c\ubd84\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 5.3\uc808\uc744 \ucc38\uc870\ud558\uc138\uc694.", "section": "5.3 Representation collapse analysis"}]