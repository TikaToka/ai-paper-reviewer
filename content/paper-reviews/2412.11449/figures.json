[{"figure_path": "https://arxiv.org/html/2412.11449/extracted/6065548/paperwhisper.png", "caption": "Fig.\u00a01:  (Left) Whisper Architecture proposed by OpenAI [26] which treats ASR as a sequence to sequence which takes in mel-spectrogram slices and decodes it token by token. It has a Transformer Encoder stack on the spectrogram followed by a Transformer decoder, trained for the shift-by-one token prediction, and the cross-attention module on learned spectrogram representation. (Right) Our generative model combines both continuous and discrete representations. We align the spectrogram and ENCODEC coarse tokens. Instead of a Transformer encoder, we pass spectrogram slices through lightweight decoder blocks. The learned representation per-token slice is concatenated with discrete tokens corresponding to the spectrogram slice to have a decoder Transformer stack, trained on shift by one next token prediction, similar to a typical LLM pre-training.", "description": "\uc774 \uadf8\ub9bc\uc740 Whisper \uc544\ud0a4\ud14d\ucc98\uc640 \uc81c\uc548\ub41c \uc0dd\uc131 \ubaa8\ub378\uc778 Whisper-GPT \uc544\ud0a4\ud14d\ucc98\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc758 Whisper \uc544\ud0a4\ud14d\ucc98\ub294 mel-\uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8 \uc2ac\ub77c\uc774\uc2a4\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \ud1a0\ud070\ubcc4\ub85c \ub514\ucf54\ub529\ud558\ub294 seq2seq \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8\uc5d0 Transformer Encoder \uc2a4\ud0dd\uc744 \uc801\uc6a9\ud55c \ud6c4, shift-by-one \ud1a0\ud070 \uc608\uce21\uc744 \uc704\ud574 \ud6c8\ub828\ub41c Transformer Decoder\uc640 \ud559\uc2b5\ub41c \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8 \ud45c\ud604\uc5d0 \ub300\ud55c cross-attention \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc624\ub978\ucabd\uc758 Whisper-GPT \uc544\ud0a4\ud14d\ucc98\ub294 \uc5f0\uc18d\uc801\uc778 mel-\uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8 \ud45c\ud604\uacfc \uc774\uc0b0\uc801\uc778 ENCODEC \ud1a0\ud070\uc744 \uacb0\ud569\ud55c \ud558\uc774\ube0c\ub9ac\ub4dc \uc0dd\uc131 \ubaa8\ub378\uc785\ub2c8\ub2e4. Transformer Encoder \ub300\uc2e0, \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8 \uc2ac\ub77c\uc774\uc2a4\ub97c \uacbd\ub7c9 \ub514\ucf54\ub354 \ube14\ub85d\uc5d0 \ud1b5\uacfc\uc2dc\ud0b5\ub2c8\ub2e4. \ud1a0\ud070 \uc2ac\ub77c\uc774\uc2a4\ubcc4\ub85c \ud559\uc2b5\ub41c \ud45c\ud604\uc740 \ud574\ub2f9 \uc2a4\ud399\ud2b8\ub85c\uadf8\ub7a8 \uc2ac\ub77c\uc774\uc2a4\uc5d0 \ud574\ub2f9\ud558\ub294 \uc774\uc0b0 \ud1a0\ud070\uacfc \uc5f0\uacb0\ub418\uc5b4 \ub514\ucf54\ub354 Transformer \uc2a4\ud0dd\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4. \uc774 \uc2a4\ud0dd\uc740 \uc77c\ubc18\uc801\uc778 LLM \uc0ac\uc804 \ud6c8\ub828\uacfc \uc720\uc0ac\ud558\uac8c shift-by-one \ub2e4\uc74c \ud1a0\ud070 \uc608\uce21 \ubc29\uc2dd\uc73c\ub85c \ud6c8\ub828\ub429\ub2c8\ub2e4.", "section": "Whisper ASR Architecture"}, {"figure_path": "https://arxiv.org/html/2412.11449/extracted/6065548/fig_music.png", "caption": "Fig.\u00a02: Comparison of GPT on coarse acoustic tokens with i) GPT-L ii) Our hybrid continuous-discrete representation.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc74c\uc545 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 GPT-L(\ub300\ud615 GPT \ubaa8\ub378)\uacfc \uc81c\uc548\ub41c Whisper-GPT(\ud558\uc774\ube0c\ub9ac\ub4dc \uc5f0\uc18d-\uc774\uc0b0 \ud45c\ud604) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Whisper-GPT\ub294 \uac70\uce5c \uc74c\ud5a5 \ud1a0\ud070\uc5d0 \ub300\ud55c GPT\uc640 \ube44\uad50\ud588\uc744 \ub54c \ub354 \ub0ae\uc740 \uac80\uc99d \uc190\uc2e4\uc744 \ub2ec\uc131\ud558\uc5ec \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. x\ucd95\uc740 \uc5d0\ud3ec\ud06c \uc218\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \uac80\uc99d \uc190\uc2e4\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. \uacb0\uacfc \ubc0f \ub17c\uc758"}, {"figure_path": "https://arxiv.org/html/2412.11449/extracted/6065548/whisper-GPT.png", "caption": "Fig.\u00a03: Comparison of GPT on coarse acoustic tokens with i) GPT-L ii) Our hybrid continuous-discrete representation.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc74c\uc131 \ub370\uc774\ud130\uc14b LibriSpeech\uc5d0\uc11c \uc5bb\uc740 \uc74c\ud5a5 \ud1a0\ud070\uc5d0 \ub300\ud55c GPT, GPT-L, \uadf8\ub9ac\uace0 \ud558\uc774\ube0c\ub9ac\ub4dc \uc5f0\uc18d-\uc774\uc0b0 \ud45c\ud604(Whisper-GPT)\uc758 \ub85c\uadf8 \uc6b0\ub3c4 \uc810\uc218\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Whisper-GPT\ub294 GPT-L\ubcf4\ub2e4 \uc801\uc740 \ud30c\ub77c\ubbf8\ud130\ub97c \uc0ac\uc6a9\ud558\uba74\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4. \uacb0\uacfc \ubc0f \ub17c\uc758 (4. RESULTS AND DISCUSSION)"}]