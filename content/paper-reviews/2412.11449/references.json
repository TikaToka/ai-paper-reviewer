{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduced the Transformer model, a foundational architecture for LLMs, including those used in audio and speech processing like WHISPER-GPT."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-05-28", "reason": "This work introduced GPT-3 and demonstrated the power of large language models in few-shot learning, impacting various fields, including speech and music generation."}, {"fullname_first_author": "Aaron van den Oord", "paper_title": "Neural Discrete Representation Learning", "publication_date": "2017-11-06", "reason": "This work introduces Vector Quantized Variational Autoencoders (VQ-VAE), a crucial technique for learning discrete representations from continuous data like audio, used extensively in speech and music generation models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Robust Speech Recognition via Large-Scale Weak Supervision", "publication_date": "2023-01-01", "reason": "This work introduces Whisper, a model for robust speech recognition that uses a sequence-to-sequence architecture with a mel-spectrogram input and discrete token output, a key inspiration for WHISPER-GPT."}, {"fullname_first_author": "Alexandre D\u00e9fossez", "paper_title": "High Fidelity Neural Audio Compression", "publication_date": "2022-10-26", "reason": "This work introduced EnCodec, a neural audio codec that provides high-fidelity audio compression and generates discrete tokens, which are used as input features in many recent speech and music models including WHISPER-GPT."}]}