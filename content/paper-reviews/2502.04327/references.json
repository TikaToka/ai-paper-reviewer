{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "Gpt-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is cited as a significant work in the field of large language models and their scaling properties, which are relevant to the current research on scaling in deep reinforcement learning."}, {"fullname_first_author": "Jared Kaplan", "paper_title": "Scaling laws for neural language models", "publication_date": "2020-01-30", "reason": "This paper is considered a foundational work on scaling laws, providing a theoretical framework for understanding how the performance of neural networks scales with model size and training data, and offering inspiration and methods applicable to the current study on deep reinforcement learning."}, {"fullname_first_author": "Jordan Hoffmann", "paper_title": "Training compute-optimal large language models", "publication_date": "2022-03-22", "reason": "This paper introduces methods for training compute-optimal large language models and proposes scaling laws specifically for LLMs, which have direct relevance to the current work's approach on value-based deep RL and resource optimization."}, {"fullname_first_author": "Sergey Levine", "paper_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems", "publication_date": "2020-05-04", "reason": "This work provides a comprehensive overview and analysis of offline reinforcement learning, which forms the basis for the current paper\u2019s focus on scaling value-based off-policy methods."}, {"fullname_first_author": "Aviral Kumar", "paper_title": "Implicit under-parameterization inhibits data-efficient deep reinforcement learning", "publication_date": "2021-04-01", "reason": "This paper explores the phenomenon of implicit under-parameterization in deep RL, establishing relationships between the hyperparameters and data efficiency that are highly relevant to the problem being addressed in the current research."}]}