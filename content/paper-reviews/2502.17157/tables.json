[{"content": "| Method | Training | KITTI [32] |  | NYUv2 [74] |  | ScanNet [23] |  | DIODE [102] |  | ETH3D [92] |  |\n|---|---|---|---|---|---|---|---|---|---|---|---| \n| MiDaS [86] | 2M | 0.236 | 0.630 | 0.111 | 0.885 | 0.121 | 0.846 | 0.332 | 0.715 | 0.184 | 0.752 |\n| Omnidata [27] | 12.2M | 0.149 | 0.835 | 0.074 | 0.945 | 0.075 | 0.936 | 0.339 | 0.742 | 0.166 | 0.778 |\n| DPT-large [85] | 1.4M | 0.100 | 0.901 | 0.098 | 0.903 | 0.082 | 0.934 | 0.182 | 0.758 | 0.078 | 0.946 |\n| DepthAnything\u2020 [118] | 63.5M | 0.080 | 0.946 | 0.043 | 0.980 | 0.043 | 0.981 | 0.261 | 0.759 | 0.058 | **0.984** |\n| DepthAnything v2\u2020 [119] | 62.6M | 0.080 | 0.943 | 0.043 | 0.979 | 0.042 | 0.979 | 0.321 | 0.758 | 0.066 | 0.983 |\n| Depth Pro\u2020 [7] | - | 0.055 | 0.974 | 0.042 | 0.977 | 0.041 | 0.978 | 0.217 | 0.764 | 0.043 | 0.974 |\n| Metric3D v2\u2020 [43] | 16M | **0.052** | **0.979** | **0.039** | **0.979** | **0.023** | **0.989** | **0.147** | **0.892** | **0.040** | 0.983 |\n| DiverseDepth [125] | 320K | 0.190 | 0.704 | 0.117 | 0.875 | 0.109 | 0.882 | 0.376 | 0.631 | 0.228 | 0.694 |\n| LeReS [126] | 354K | 0.149 | 0.784 | 0.090 | 0.916 | 0.091 | 0.917 | 0.271 | 0.766 | 0.171 | 0.777 |\n| HDN [128] | 300K | 0.115 | 0.867 | 0.069 | 0.948 | 0.080 | 0.939 | 0.246 | 0.780 | 0.121 | 0.833 |\n| GeoWizard [31] | 280K | 0.097 | 0.921 | 0.052 | 0.966 | 0.061 | 0.953 | 0.297 | 0.792 | 0.064 | 0.961 |\n| DepthFM [33] | 63K | 0.083 | 0.934 | 0.065 | 0.956 | - | - | 0.225 | 0.800 | - | - |\n| Marigold\u2020 [47] | 74K | 0.099 | 0.916 | 0.055 | 0.964 | 0.064 | 0.951 | 0.308 | 0.773 | 0.065 | 0.960 |\n| DMP Official\u2020 [54] | - | 0.240 | 0.622 | 0.109 | 0.891 | 0.146 | 0.814 | 0.361 | 0.706 | 0.128 | 0.857 |\n| GeoWizard\u2020 [31] | 280K | 0.129 | 0.851 | 0.059 | 0.959 | 0.066 | 0.953 | 0.328 | 0.753 | 0.077 | 0.940 |\n| DepthFM\u2020 [33] | 63K | 0.174 | 0.718 | 0.082 | 0.932 | 0.095 | 0.903 | 0.334 | 0.729 | 0.101 | 0.902 |\n| Genpercept\u2020 [114] | 90K | 0.094 | 0.923 | 0.091 | 0.932 | 0.056 | 0.965 | 0.302 | 0.767 | 0.066 | 0.957 |\n| Painter\u2020 [109] | 24K | 0.324 | 0.393 | **0.046** | **0.979** | 0.083 | 0.927 | 0.342 | 0.534 | 0.203 | 0.644 |\n| Unified-IO\u2020 [69] | 48K | 0.188 | 0.699 | 0.059 | 0.970 | **0.063** | **0.965** | 0.369 | 0.906 | 0.103 | 0.906 |\n| 4M-XL\u2020 [72] | 759M | 0.105 | 0.896 | 0.068 | 0.951 | 0.065 | 0.955 | 0.331 | 0.734 | 0.070 | 0.953 |\n| OneDiffusion\u2020 [53] | 500K | 0.101 | 0.908 | 0.087 | 0.924 | 0.094 | 0.906 | 0.399 | 0.661 | 0.072 | 0.949 |\n| Ours-single\u2020 | 500K | 0.081 | 0.942 | 0.068 | 0.949 | 0.078 | 0.945 | 0.267 | 0.709 | 0.059 | 0.969 |\n| Ours\u2020 | 500K | 0.075 | 0.945 | 0.072 | 0.939 | 0.075 | 0.938 | 0.243 | 0.741 | 0.053 | **0.967** |", "caption": "Table 1: Quantitative comparison of depth estimation with both specialized models and multi-task models on zero-shot datasets. Our visual generalist model can perform on par with state-of-the-art models.\nWe use the same evaluation protocal (\u2020\u2020\\dagger\u2020) as Genpercept\u00a0[114].", "description": "\ud45c 1\uc740 \uc81c\ub85c\uc0f7 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc804\ubb38 \ubaa8\ub378\uacfc \ub2e4\uc911 \uc791\uc5c5 \ubaa8\ub378 \ubaa8\ub450\ub97c \uc0ac\uc6a9\ud558\uc5ec \uae4a\uc774 \ucd94\uc815\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 DICEPTION \ubaa8\ub378\uc740 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\ub4e4\uacfc \ub3d9\ub4f1\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Genpercept [114]\uc640 \ub3d9\uc77c\ud55c \ud3c9\uac00 \ud504\ub85c\ud1a0\ucf5c(\u2020)\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uae4a\uc774 \ucd94\uc815 \uc815\ud655\ub3c4\ub97c \uac1d\uad00\uc801\uc778 \uc9c0\ud45c(AbsRel, \u03b41, ...)\ub85c \ube44\uad50\ud558\uc5ec DICEPTION\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud559\uc2b5 \ub370\uc774\ud130 \ud06c\uae30\uc640 \uc131\ub2a5 \uc9c0\ud45c\ub97c \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec DICEPTION\uc758 \ud6a8\uc728\uc131\uacfc \uacbd\uc7c1\ub825\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "Method | Training | NYUv2 [74] |  |  |  |  | ScanNet [23] |  |  |  |  | DIODE-indoor [102] |  |  |  |  |  \n---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---\nSamples | mean \u2193 | med \u2193 | 11.25\u00b0 \u2191 | 22.5\u00b0 \u2191 | 30\u00b0 \u2191 | mean \u2193 | med \u2193 | 11.25\u00b0 \u2191 | 22.5\u00b0 \u2191 | 30\u00b0 \u2191 | mean \u2193 | med \u2193 | 11.25\u00b0 \u2191 | 22.5\u00b0 \u2191 | 30\u00b0 \u2191\nDINSE [3] | 160K | 18.572 | 10.845 | **54.732** | 74.146 | 80.256 | 18.610 | 9.885 | 56.132 | 76.944 | 82.606 | 18.453 | 13.871 | 36.274 | 77.527 | 86.976\nGeowizard [31] | 280K | 20.363 | 11.898 | 46.954 | 73.787 | 80.804 | 19.748 | 9.702 | 58.427 | 77.616 | 81.575 | 19.371 | 15.408 | 30.551 | 75.426 | 86.357\nGenPercept [114] | 90K | 20.896 | 11.516 | 50.712 | 73.037 | 79.216 | 18.600 | 8.293 | 64.697 | 79.329 | 82.978 | 18.348 | 13.367 | 39.178 | 79.819 | 88.551\nMarigold [47] | 90K | 20.864 | 11.134 | 50.457 | 73.003 | 79.332 | 18.463 | 8.442 | 64.727 | 79.559 | 83.199 | 16.671 | 12.084 | 45.776 | 82.076 | 89.879\nStableNormal [123] | 250K | 19.707 | **10.527** | 53.042 | **75.889** | **81.723** | **17.248** | **8.057** | **66.655** | **81.134** | **84.632** | **13.701** | **9.460** | **63.447** | **86.309** | **92.107**\nUnified-IO [68] | 210K | 28.547 | 14.637 | 39.907 | 63.912 | 71.240 | 17.955 | 10.269 | 54.120 | 77.617 | 83.728 | 31.576 | 16.615 | 27.855 | 64.973 | 73.445\n4M-XL [72] | 759M | 37.278 | 13.661 | 44.660 | 60.553 | 65.327 | 30.700 | 11.614 | 48.743 | 68.867 | 73.623 | 18.189 | 12.979 | 36.622 | 81.844 | 87.050\nOurs-single | 500K | 18.267 | 10.238 | 52.393 | 76.802 | 83.113 | 19.892 | 12.424 | 45.930 | 74.341 | 81.965 | 17.611 | 8.912 | 62.030 | 80.827 | 86.474\nOurs | 500K | **18.302** | 10.538 | 52.533 | 75.977 | 82.573 | 19.348 | 12.129 | 46.410 | 74.805 | 82.176 | 17.946 | 8.686 | 62.641 | 81.152 | 85.398", "caption": "Table 2: \nQuantitative comparison of surface normal estimation with both specialized models and multi-task models. All methods are evaluated with the same evaluation protocol of StableNormal\u00a0[123].", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \ub2e8\uc77c \uc791\uc5c5 \ubaa8\ub378\uacfc \ub2e4\uc911 \uc791\uc5c5 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ud45c\uba74 \ub178\uba40 \ucd94\uc815 \uacb0\uacfc\uc5d0 \ub300\ud55c \uc815\ub7c9\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \ubc29\ubc95\uc740 StableNormal [123]\uacfc \ub3d9\uc77c\ud55c \ud3c9\uac00 \ud504\ub85c\ud1a0\ucf5c\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \ud3c9\uade0 \ubc0f \uc911\uc559\uac12 \uc624\ucc28, \uadf8\ub9ac\uace0 11.25\u00b0, 22.5\u00b0, 30\u00b0 \uac01\ub3c4\uc758 \uc815\ud655\ub3c4\ub97c \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\ub4e4\uc774 NYUv2 [74], ScanNet [23], DIODE-indoor [102] \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 DICEPTION \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec  \ub2e4\uc911 \uc791\uc5c5 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2. \uad00\ub828 \uc5f0\uad6c"}, {"content": "| Method | AR-small\u2191 | AR-medium\u2191 | AR-large\u2191 |\n|---|---|---|---|\n| EntityV2 [81] | **0.313** | **0.551** | **0.683** |\n| Ours-single | 0.123 | 0.424 | 0.648 |\n| Ours | 0.121 | 0.439 | 0.637 |", "caption": "Table 3: Average recall (AR) of entity segmentation on the MS COCO validation set.", "description": "\ud45c 3\uc740 MS COCO \uac80\uc99d \uc138\ud2b8\uc5d0\uc11c \uac1c\uccb4 \ubd84\ud560\uc758 \ud3c9\uade0 \uc7ac\ud604\uc728(AR)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294 DICEPTION \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \uc8fc\uc694 \uc9c0\ud45c \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.  AR\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uac1c\uccb4(\uc791\uc740, \uc911\uac04, \ud070)\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc138 \uac00\uc9c0 \uc9c0\ud45c\ub85c \ub098\ub269\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uac1c\uccb4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \ubd84\ud560\ud558\ub294\uc9c0\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \ub2e8\uc21c\ud788 \uc804\uccb4 \uc815\ud655\ub3c4\ub9cc\uc744 \uc81c\uc2dc\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, \uac1c\uccb4\uc758 \ud06c\uae30\uc5d0 \ub530\ub978 \uc131\ub2a5 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90c\uc73c\ub85c\uc368 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ub354\uc6b1 \uc790\uc138\ud788 \ubd84\uc11d\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "|               | HRNet[96] | HRFormer[129] | ViTPose[115] | Painter[109] | Ours |\n| :------------ | :--------: | :----------: | :---------: | :----------: | :----: |\n| AP<img src=\"https://arxiv.org/html/2502.17157/uparrow.png\"> |    76.3    |     77.2     |     78.3     |     72.5     |  57.8  |", "caption": "Table 4: Evaluation of human keypoints estimation on MS COCO.", "description": "\ud45c 4\ub294 MS COCO \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc0ac\ub78c \uc790\uc138 \ucd94\uc815 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4(AP) \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, DICEPTION \ubaa8\ub378\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \uc0ac\ub78c \uc790\uc138 \ucd94\uc815 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, DICEPTION \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uae30\uc874\uc758 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud558\uc5ec DICEPTION\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ud65c\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "4.2. \uae30\uc874 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"content": "| Method | SparK [98] | OneFormer [44] | Mask2Former [18] | Ours |\n|---|---|---|---|---|\n| AP\u2191 | 45.1 | 49.2 | **50.1** | 33.2 |", "caption": "Table 5: Evaluation of semantic segmentation on the MS COCO (with category ID).", "description": "\ud45c 5\ub294 MS COCO \ub370\uc774\ud130\uc14b(\ubc94\uc8fc ID \ud3ec\ud568)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub41c \uc758\ubbf8\ub860\uc801 \ubd84\ud560(semantic segmentation) \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec DICEPTION \ubaa8\ub378\uc758 \uc758\ubbf8\ub860\uc801 \ubd84\ud560 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294, \uac01 \ubc29\ubc95\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc815\ubc00\ub3c4(Average Precision, AP) \uc810\uc218\ub97c \ubc94\uc8fc\ubcc4\ub85c \uc81c\uc2dc\ud558\uc5ec DICEPTION \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Training |  |  |\n|---|---|---|\n| Task | Data Samples | Dataset |\n| Depth | 500K | OpenImages [51] + Depth Pro [7] |\n| Normal | 500K | OpenImages [51] + StableNormal [123] |\n| Point Segmentation | 400K | SA-1B [49] |\n| Point Segmentation | 200K | P3M-10K [55], AIM500 [57] and AM2K [56] |\n| Human Pose | 42K | MS COCO 2017 [62] |\n| Semantic Segmentation | 120K | COCO-Rem [94] |\n| Entity Segmentation | 32K | EntityV2 [81] |\n| Validation |  |  |\n| Task |  | Dataset |\n| Depth |  | NYUv2 [74], KITTI [32], ScanNet [23], DIODE [102], ETH3D [92] |\n| Normal |  | NYUv2 [74], ScanNet [23], DIODE [102] |\n| Point Segmentation |  | PPDLS [71], DOORS [79], TimberSeg [30], NDD20 [101] |\n|  |  | STREETS [95], iShape [120], ADE20K [134], OVIS [80] |\n|  |  | Plittersdorf [37], EgoHOS [131], IBD [15], WoodScape [127] |\n|  |  | TrashCan [41], GTEA [29, 60], NDISPark [20, 19], VISOR [24, 25] |\n|  |  | LVIS [36], Hypersim [90], Cityscapes [22], DRAM [21] |\n|  |  | BBBC038v1 [10], ZeroWaste [5], PIDRay [103] |\n| Entity Segmentation |  | MS COCO 2017 [62] |\n| Semantic Segmentation |  | MS COCO 2017 [62] |\n| Human Keypoints |  | MS COCO 2017 [62] |", "caption": "Table S1: Dataset detail.", "description": "\ud45c S1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc758 \uc885\ub958, \ud574\ub2f9 \ub370\uc774\ud130\uc14b\uc774 \uc0ac\uc6a9\ub41c \uc791\uc5c5(\uacfc\uc81c), \uadf8\ub9ac\uace0 \uac01 \uc791\uc5c5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130 \uc0d8\ud50c\uc758 \uac1c\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc608\ub97c \ub4e4\uc5b4, \uae4a\uc774(Depth)\uc640 \ud45c\uba74 \ubc95\uc120(Normal) \ucd94\uc815 \uc791\uc5c5\uc5d0\ub294 OpenImages \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ud55c 50\ub9cc \uac1c\uc758 \uc774\ubbf8\uc9c0\uac00 \uc0ac\uc6a9\ub418\uc5c8\uace0, \uc810 \ud504\ub86c\ud504\ud2b8 \uc138\ubd84\ud654(Point Segmentation) \uc791\uc5c5\uc5d0\ub294 SA-1B \ub370\uc774\ud130\uc14b\uc5d0\uc11c 40\ub9cc \uac1c\uc758 \uc774\ubbf8\uc9c0\uc640 \ud569\uc131 \uc774\ubbf8\uc9c0 20\ub9cc \uac1c\uac00 \uc0ac\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ub098\uba38\uc9c0 \uc791\uc5c5\ub4e4(\uc790\uc138 \ucd94\uc815, \uc758\ubbf8\ub860\uc801 \uc138\ubd84\ud654, \uac1c\uccb4 \uc138\ubd84\ud654 \ub4f1)\uc5d0\ub3c4 \uac01\uac01 COCO, COCO-Rem, EntityV2 \ub4f1\uc758 \ub370\uc774\ud130\uc14b\uacfc \uadf8\uc5d0 \ub530\ub978 \uc0d8\ud50c \uac1c\uc218\uac00 \uba85\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac80\uc99d(Validation) \ubd80\ubd84\uc5d0\uc11c\ub294 \uac01 \uacfc\uc81c\ubcc4 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uacfc \uac80\uc99d\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130 \uc218\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 \uad6c\ud604 \uc138\ubd80 \uc815\ubcf4 (Implementation Details)"}, {"content": "| Category | AP \u2191 | \n|---|---| \n| Bear | 76.3 | \n| Dog | 68.9 | \n| Cat | 71.7 | \n| Person | 18.6 | \n| Bird | 10.4 | \n| Book | 10.8 | ", "caption": "Table S2: When post-processing RGB masks, small regions and excessive numbers of objects significantly lead to performance degradation.", "description": "\ud45c S2\ub294 RGB \ub9c8\uc2a4\ud06c \ud6c4\ucc98\ub9ac \uacfc\uc815\uc5d0\uc11c \uc791\uc740 \uc601\uc5ed\uacfc \uacfc\ub3c4\ud55c \uac1c\uccb4 \uc218\uac00 \uc131\ub2a5 \uc800\ud558\ub85c \uc774\uc5b4\uc9c0\ub294 \ud604\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc791\uc740 \uc601\uc5ed\uc740 \ub178\uc774\uc988\ub85c \uac04\uc8fc\ub418\uc5b4 \uc81c\uac70\ub420 \uc218 \uc788\uc73c\uba70, \uac1c\uccb4 \uc218\uac00 \uacfc\ub2e4\ud558\uba74 \uc720\uc0ac\ud55c \uc0c9\uc0c1\uc758 \uac1c\uccb4\ub4e4\uc774 \uc798\ubabb \uadf8\ub8f9\ud551\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ud2b9\ud788 \uc0ac\ub78c\uc774\ub098 \uc0c8\ucc98\ub7fc \uc791\uace0 \uc5ec\ub7ec \uac1c\uac00 \uc788\ub294 \uac1c\uccb4\uc758 \uacbd\uc6b0 \uc815\ubc00\ub3c4(AP)\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce69\ub2c8\ub2e4. \ud45c\ub294 \ub2e4\uc591\ud55c \ubc94\uc8fc(\uacf0, \uac1c, \uace0\uc591\uc774, \uc0ac\ub78c, \uc0c8, \ucc45)\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc815\ubc00\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \uc774\ub7ec\ud55c \ud6c4\ucc98\ub9ac \uacfc\uc815\uc758 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "B. Post-processing"}]