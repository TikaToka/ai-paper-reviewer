{"references": [{"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis.", "publication_date": "2024-01-01", "reason": "This paper introduces the core model architecture, Rectified Flow Transformers (Flux), that serves as the foundation for FluxSpace."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers.", "publication_date": "2023-01-01", "reason": "This work introduces the Multi-Modal Diffusion Transformer (MM-DiT) architecture, which is adapted by Flux and crucial for the editing mechanism of FluxSpace."}, {"fullname_first_author": "Dustin Podell", "paper_title": "SDXL: Improving latent diffusion models for high-resolution image synthesis.", "publication_date": "2023-07-01", "reason": "This paper introduces SDXL, a state-of-the-art diffusion model often used in comparison with or adapted for use with Flux, influencing the context of the FluxSpace application."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision.", "publication_date": "2021-01-01", "reason": "This paper introduces CLIP, which is essential for text-image alignment in both Flux and FluxSpace, playing a central role in guiding the edits semantically."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models.", "publication_date": "2022-01-01", "reason": "This paper presents Latent Diffusion Models (LDMs), a dominant approach in image generation that provides a comparative backdrop for the flow-based methods used in FluxSpace, highlighting the novel application of disentangled editing within this newer architecture."}]}