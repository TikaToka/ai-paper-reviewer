[{"content": "| Model | Base Model | HumanEval Base | HumanEval Plus | MBPP Base | MBPP Plus | Average |\n|---|---|---|---|---|---|---|\n| **Closed-source Model** |\n| GPT-4-Turbo (April 2024) | - | 90.2 | 86.6 | 85.7 | 73.3 | 84.0 |\n| GPT-4 (May 2023) | - | 88.4 | 79.3 | - | - | - |\n| GPT-3.5-Turbo (Nov 2023) | - | 76.8 | 70.7 | 82.5 | 69.7 | 75.0 |\n| claude-3-opus (Mar 2024) | - | 82.9 | 77.4 | 89.4 | 73.3 | 80.8 |\n| claude-3-sonnet (Mar 2024) | - | 70.7 | 64.0 | 83.6 | 69.3 | 71.9 |\n| claude-3-haiku (Mar 2024) | - | 76.8 | 68.9 | 80.2 | 68.8 | 73.7 |\n| **7B+ Scale** |\n| Qwen2.5-Coder-32B-Instruct | - | 92.1 | 87.2 | 90.5 | 77.0 | 86.7 |\n| DeepSeek-Coder-V2-Instruct | - | 85.4 | 82.3 | 89.4 | 75.1 | 83.1 |\n| OpenCoder-8B-Instruct | - | 81.7 | 77.4 | 82.0 | 71.4 | 78.1 |\n| DeepSeek-Coder-33B-instruct | - | 81.1 | 75.0 | 80.4 | 70.1 | 76.7 |\n| Codestral-22B-v0.1 | - | 79.9 | 73.8 | 72.5 | 61.9 | 72.0 |\n| **~7B Scale** |\n| ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) DSCoder-6.7B-Base | - | 47.6 | 39.6 | 72.0 | 58.7 | 54.5 |\n| DeepSeekCoder-6.7b-Instruct | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 74.4 | 71.3 | 74.9 | 65.6 | 71.6 |\n| Magicoder-S-DS | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 76.8 | 71.3 | 79.4 | 69.0 | 74.1 |\n| WaveCoder-Ultra-6.7B | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 75.0 | 69.5 | 74.9 | 63.5 | 70.7 |\n| OpenCodeInterpreter-DS-6.7B | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 77.4 | 72.0 | 76.5 | 66.4 | 73.1 |\n| **EpiCoder-DS-6.7B** | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 80.5 | 76.8 | 81.5 | 68.3 | 76.8 |\n| ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) Qwen2.5-Coder-7B-Base | - | 61.6 | 53.0 | 76.9 | 62.9 | 63.6 |\n| Qwen2.5-Coder-7B-Instruct | ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) | 88.4 | 84.1 | 83.5 | 71.7 | 81.9 |\n| **EpiCoder-Qwen-7B** | ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) | 89.0 | 82.3 | 84.1 | 71.4 | 81.7 |", "caption": "Table 1: Pass@1 (%) results of different LLMs on HumanEval (+) and MBPP (+) computed with greedy decoding. We report the results uniformly from the EvalPlus Leaderboard 444https://evalplus.github.io/leaderboard.html.", "description": "\uc774 \ud45c\ub294 HumanEval\uacfc MBPP \ucf54\ub4dc \uc0dd\uc131 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  greedy decoding \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ub418\uc5c8\uc73c\uba70, EvalPlus \ub9ac\ub354\ubcf4\ub4dc\uc758 \uacb0\uacfc\ub97c \ud1b5\uc77c\uc801\uc73c\ub85c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  HumanEval(+) \ubc0f MBPP(+)\ub294 \uac01 \ubca4\uce58\ub9c8\ud06c\uc758 \ud655\uc7a5 \ubc84\uc804\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc758 Pass@1 \ube44\uc728\uc744 \ubcf4\uc5ec\uc8fc\uc5b4, \ubaa8\ub378\uc774 \uc815\ub2f5\uc744 \uccab \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \uc81c\uc2dc\ud588\ub294\uc9c0 \uc5ec\ubd80\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ubaa8\ub378\uc740 \uae30\ubcf8 \ubaa8\ub378\uacfc \ucd94\uac00\uc801\uc778 \ubbf8\uc138\uc870\uc815 \uc5ec\ubd80\uc5d0 \ub530\ub77c \ub098\ub258\uc5b4 \ube44\uad50\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \ucf54\ub4dc \uc0dd\uc131 \ub2a5\ub825\uacfc \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ube44\uad50\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.2 \ud568\uc218 \uc218\uc900 \uc0dd\uc131"}, {"content": "| Model | Base | BigCodeBench-Full Complete | BigCodeBench-Full Instruct | BigCodeBench-Hard Complete | BigCodeBench-Hard Instruct | Avg |\n|---|---|---|---|---|---|---|\n| **Closed-source Model** |\n| GPT-4o (May 2024) | - | 61.1 | 51.1 | 29.1 | 25.0 | 41.6 |\n| DeepSeek-V2-Chat (June 2024) | - | 59.4 | 48.9 | 32.4 | 25.0 | 41.4 |\n| Claude-3.5-Sonnet (June 2024) | - | 58.6 | 46.8 | 33.1 | 25.7 | 41.1 |\n| **7B+ Scale** |\n| Qwen2.5-Coder-32B-Instruct | - | 58.0 | 49.0 | 33.8 | 27.7 | 42.1 |\n| DeepSeek-Coder-V2-Instruct | - | 59.7 | 48.2 | 29.7 | 24.3 | 40.5 |\n| Llama-3.3-70B-Instruct | - | 57.5 | 46.9 | 28.4 | 28.4 | 40.3 |\n| Codestral-22B-v0.1 | - | 52.5 | 41.8 | 24.3 | 16.9 | 33.9 |\n| DeepSeek-Coder-33B-Instruct | - | 51.1 | 42.0 | 20.9 | 17.6 | 32.9 |\n| OpenCoder-8B-Instruct | - | 50.9 | 43.2 | 18.9 | 18.2 | 32.8 |\n| **\u223c 7B Scale** |\n| ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) DSCoder-6.7B-Base | - | 41.8 | - | 13.5 | - | - |\n| DeepSeekCoder-6.7b-Instruct | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 43.8 | 35.5 | 15.5 | 10.1 | 26.2 |\n| Magicoder-S-DS | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 47.6 | 36.2 | 12.8 | 13.5 | 27.5 |\n| WaveCoder-Ultra-6.7B | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 43.7 | 33.9 | 16.9 | 12.8 | 26.8 |\n| OpenCodeInterpreter-DS-6.7B | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 44.6 | 37.1 | 16.9 | 13.5 | 28.0 |\n| **EpiCoder-DS-6.7B** | ![https://arxiv.org/html/2501.04694/figure/deepseek.png](https://arxiv.org/html/2501.04694/figure/deepseek.png) | 50.6 | 37.9 | 19.6 | 12.8 | 30.2 |\n|  |  |  |  |  |  |  |\n| ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) Qwen2.5-Coder-7B-Base | - | 45.8 | - | 16.2 | - | - |\n| Qwen2.5-Coder-7B-Instruct | ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) | 48.8 | 40.4 | 20.3 | 20.9 | 32.6 |\n| **EpiCoder-Qwen-7B** | ![https://arxiv.org/html/2501.04694/figure/qwen2.png](https://arxiv.org/html/2501.04694/figure/qwen2.png) | 51.9 | 43.8 | 27.7 | 22.3 | 36.4 |", "caption": "Table 2: Pass@1 (%) results of different LLMs on BigCodeBench computed with greedy decoding. We conducted the evaluation on the Full and Hard subsets of this benchmark, including the Complete and Instruct tasks. Except for the results underlined, which are sourced from their respective papers, all other results are obtained from the BigCodeBench-Leaderboard666https://huggingface.co/spaces/bigcode/bigcodebench-leaderboard.", "description": "\uc774 \ud45c\ub294 BigCodeBench \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c LLMs\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  greedy decoding\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ub418\uc5c8\uc73c\uba70,  Full \ubc0f Hard \ud558\uc704 \ubca4\uce58\ub9c8\ud06c(Complete \ubc0f Instruct \uc791\uc5c5 \ud3ec\ud568)\uc5d0\uc11c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubc11\uc904 \uce5c \uacb0\uacfc\ub294 \ud574\ub2f9 \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc628 \uac83\uc774\uace0, \ub098\uba38\uc9c0\ub294 BigCodeBench \ub9ac\ub354\ubcf4\ub4dc\uc5d0\uc11c \uac00\uc838\uc628 \uac83\uc785\ub2c8\ub2e4.  BigCodeBench\ub294 \ub2e4\uc591\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc640 \ucef4\ud4e8\ud130 \uacfc\ud559 \ub3c4\uba54\uc778\uc744 \ud3ec\ud568\ud558\ub294 \uad11\ubc94\uc704\ud55c \ubca4\uce58\ub9c8\ud06c\ub85c, \ucf54\ub4dc LLMs\uc758 \uae30\ub2a5\uc744 \uc885\ud569\uc801\uc73c\ub85c \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "3.2 Function-level Generation"}, {"content": "| Model | Difficult | Creative | Subtle | Combine | Tool Use | Avg |\n|---|---|---|---|---|---|---|\n| **Closed-source Model** |  |  |  |  |  |  |\n| GPT-4-Turbo | 50.0 | 61.0 | 82.0 | 45.0 | 69.0 | 61.4 |\n| GPT-4 | 52.0 | 66.0 | 76.0 | 53.0 | 68.0 | 63.0 |\n| Claude-3 | 50.0 | 53.0 | 81.0 | 42.0 | 69.0 | 59.0 |\n| ChatGPT | 33.0 | 42.0 | 70.0 | 33.0 | 64.0 | 48.4 |\n| Claude-3-haiku | 40.0 | 47.0 | 65.0 | 17.0 | 56.0 | 45.0 |\n| **7B+ Scale** |  |  |  |  |  |  |\n| DeepSeekCoder-33b-Instruct | 47.0 | 47.0 | 67.0 | 31.0 | 66.0 | 51.6 |\n| WizardCoder-33b-1.1 | 48.0 | 48.0 | 66.0 | 20.0 | 64.0 | 49.2 |\n| CodeLlama-70b-Instruct | 31.0 | 41.0 | 65.0 | 18.0 | 65.0 | 44.0 |\n| OpenCoder-8B-Instruct | 45.0 | 50.0 | 73.0 | 28.0 | 50.0 | 49.2 |\n| ~ **7B Scale** |  |  |  |  |  |  |\n| DeepSeek-Coder-6.7B-base | 21.0 | 24.0 | 47.0 | 5.0 | 55.0 | 30.4 |\n| DeepSeekCoder-6.7b-Instruct | 40.0 | 37.0 | 61.0 | 18.0 | 51.0 | 41.4 |\n| Magicoder-S-DS-6.7B | 40.0 | 34.0 | 67.0 | 21.0 | 61.0 | 44.6 |\n| WaveCoder-Ultra-6.7B | 38.0 | 42.0 | 71.0 | 24.0 | 35.0 | 42.0 |\n| OpenCodeInterpreter-DS-6.7B | 43.0 | 37.0 | 65.0 | 25.0 | 51.0 | 44.2 |\n| **EpiCoder-DS-6.7B** | 40.0 | 45.0 | 70.0 | 30.0 | 65.0 | 50.0 |\n| Qwen2.5-Coder-7B-Base | 35.0 | 20.0 | 55.0 | 27.0 | 41.0 | 35.6 |\n| Qwen2.5-Coder-7B-Instruct | 48.0 | 49.0 | 77.0 | 37.0 | 65.0 | 55.2 |\n| **EpiCoder-Qwen-7B** | 53.0 | 48.0 | 78.0 | 47.0 | 68.0 | 58.8 |", "caption": "Table 3: Pass@1 (%) results of different LLMs on EvoEval computed with greedy decoding.", "description": "\ubcf8 \ud45c\ub294 EvoEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ub2e4\uc591\ud55c LLMs\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. EvoEval\uc740 HumanEval\uc744 \uc5ec\ub7ec \ud558\uc704 \ub3c4\uba54\uc778(Difficult, Creative, Subtle, Combine, Tool Use)\uc73c\ub85c \ud655\uc7a5\ud55c \ubca4\uce58\ub9c8\ud06c\uc774\uba70, \uac01 \ub3c4\uba54\uc778\ubcc4 \ubb38\uc81c \ud574\uacb0 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 Pass@1 (greedy decoding \uc0ac\uc6a9) \uacb0\uacfc\uac00 \ub3c4\uba54\uc778\ubcc4, \uadf8\ub9ac\uace0 \ud3c9\uade0 \uc810\uc218\ub85c \ub098\ud0c0\ub098 \uc788\uc2b5\ub2c8\ub2e4. Pass@1\uc740 \ubaa8\ub378\uc774 \uccab \ubc88\uc9f8 \uc608\uce21\uc73c\ub85c \uc815\ub2f5\uc744 \ub9de\ud78c \ube44\uc728\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "3.2 Function-level Generation"}, {"content": "| Model | BP | AP | SE | DP | MA | DW | ML | SC | DB | MM | OS | Others | Overall |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Close-Sourced API Model |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| OpenAI o1-preview | 55.56 | 78.61 | 64.29 | 76.80 | 79.14 | 18.75 | 51.28 | 61.76 | 40.00 | 47.37 | 100.00 | 74.47 | 66.47 |\n| OpenAI o1-mini | 72.22 | 75.62 | 50.00 | 76.00 | 80.58 | 28.75 | 56.41 | 56.62 | 40.00 | 57.89 | 100.00 | 72.34 | 66.23 |\n| Claude-35-Sonnet | 50.00 | 75.62 | 71.43 | 76.00 | 76.26 | 13.75 | 51.28 | 61.76 | 50.00 | 63.16 | 100.00 | 78.72 | 65.52 |\n| GPT 4o-0806 | 72.22 | 72.14 | 53.57 | 78.40 | 76.98 | 21.25 | 66.67 | 55.15 | 40.00 | 68.42 | 100.00 | 72.34 | 65.05 |\n| Doubao-Coder-Preview | 55.56 | 69.65 | 50.00 | 77.60 | 75.54 | 27.50 | 51.28 | 60.29 | 20.00 | 63.16 | 50.00 | 55.32 | 62.91 |\n| DeepSeek-v2.5 | 55.56 | 68.16 | 50.00 | 76.00 | 76.26 | 20.00 | 48.72 | 56.62 | 40.00 | 63.16 | 50.00 | 65.96 | 61.85 |\n| Qwen-Max | 50.00 | 70.15 | 39.29 | 77.60 | 72.66 | 13.75 | 56.41 | 57.35 | 30.00 | 47.37 | 50.00 | 63.83 | 60.78 |\n| GLM-4-Plus | 55.56 | 65.67 | 39.29 | 76.80 | 74.82 | 13.75 | 58.97 | 50.00 | 40.00 | 52.63 | 100.00 | 53.19 | 58.77 |\n| 20B+ Instruction Tuned Coder |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| DeepSeekCoder-v2-Instruct | 55.56 | 68.66 | 35.71 | 81.60 | 79.14 | 16.25 | 48.72 | 53.68 | 40.00 | 52.63 | 50.00 | 57.45 | 61.26 |\n| Qwen2.5-Coder-32B-Instruct | 50.00 | 70.15 | 50.00 | 77.60 | 66.19 | 17.50 | 61.54 | 43.38 | 30.00 | 47.37 | 100.00 | 61.70 | 58.41 |\n| DeepSeekCoder-33B-Instruct | 50.00 | 59.70 | 21.43 | 71.20 | 48.92 | 18.75 | 48.72 | 40.44 | 30.00 | 42.11 | 50.00 | 44.68 | 49.05 |\n| CodeLlama-34B-Instruct | 5.56 | 22.89 | 14.29 | 40.00 | 17.27 | 16.25 | 15.38 | 18.38 | 30.00 | 26.32 | 0.00 | 23.40 | 22.27 |\n| 13B+ Instruction Tuned Coder |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Qwen2.5-Coder-14B-Instruct | 55.56 | 62.69 | 32.14 | 76.00 | 70.50 | 18.75 | 53.85 | 38.97 | 30.00 | 57.89 | 100.00 | 55.32 | 55.57 |\n| DeepSeekCoder-v2-Lite-Instruct | 50.00 | 64.68 | 32.14 | 64.00 | 56.12 | 26.25 | 43.59 | 33.82 | 60.00 | 21.05 | 50.00 | 53.19 | 50.47 |\n| StarCoder2-15B-Instruct-v0.1 | 61.11 | 44.28 | 32.14 | 63.20 | 36.69 | 31.25 | 53.85 | 28.68 | 60.00 | 36.84 | 50.00 | 53.19 | 43.01 |\n| CodeLlama-13B-Instruct | 11.11 | 22.39 | 25.00 | 24.00 | 20.86 | 30.00 | 20.51 | 13.97 | 40.00 | 10.53 | 50.00 | 23.40 | 21.56 |\n| 6B+ Instruction Tuned Coder |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| Qwen2.5-Coder-7B-Instruct | 33.33 | 58.21 | 39.29 | 66.40 | 48.92 | 18.75 | 38.46 | 32.35 | 40.00 | 47.37 | 50.00 | 59.57 | 47.51 |\n| Yi-Coder-9B-Chat | 61.11 | 50.25 | 32.14 | 66.40 | 46.76 | 26.25 | 43.59 | 36.76 | 50.00 | 36.84 | 50.00 | 48.94 | 46.56 |\n| DeepSeek-Coder-7B-Instruct-v1.5 | 50.00 | 51.74 | 25.00 | 64.80 | 37.41 | 25.00 | 30.77 | 34.56 | 20.00 | 52.63 | 50.00 | 48.94 | 43.60 |\n| OpenCoder-8B-Instruct | 44.44 | 53.73 | 28.57 | 57.60 | 35.97 | 26.25 | 28.21 | 28.68 | 0.00 | 47.37 | 0.00 | 44.68 | 41.11 |\n| DeepSeek-Coder-6.7B-Instruct | 61.11 | 49.75 | 28.57 | 65.60 | 38.13 | 18.75 | 38.46 | 22.79 | 30.00 | 31.58 | 50.00 | 42.55 | 40.88 |\n| CodeQwen1.5-7B-Chat | 38.89 | 45.77 | 50.00 | 58.40 | 31.65 | 15.00 | 33.33 | 22.79 | 20.00 | 31.58 | 0.00 | 42.55 | 37.20 |\n| CodeLlama-7B-Instruct | 27.78 | 23.88 | 25.00 | 28.00 | 20.86 | 23.75 | 10.26 | 11.76 | 50.00 | 10.53 | 0.00 | 21.28 | 21.33 |\n| **EpiCoder-DS-6.7B** | **61.11** | **47.26** | **25.00** | **61.60** | **41.01** | **40.00** | **41.03** | **27.21** | **50.00** | **36.84** | **50.00** | **42.55** | **43.25** |\n| **EpiCoder-Qwen-7B** | **44.44** | **61.19** | **17.86** | **72.80** | **61.15** | **28.75** | **51.28** | **27.94** | **20.00** | **47.37** | **50.00** | **40.43** | **50.24** |", "caption": "Table 4: Model performance across domains of Python in the English Subset of FullStackBench.", "description": "\ud45c 4\ub294 FullStackBench\uc758 \uc601\uc5b4 \ud558\uc704 \uc9d1\ud569 \ub0b4 \ud30c\uc774\uc36c \ub3c4\uba54\uc778 \uc804\ubc18\uc5d0 \uac78\uce5c \uc5ec\ub7ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\uc640 \ucef4\ud4e8\ud130 \uacfc\ud559 \ub3c4\uba54\uc778\uc744 \ud3ec\uad04\ud558\ub294 FullStackBench\uc758 \ud3ec\uad04\uc801\uc778 \ud2b9\uc131\uc744 \uac10\uc548\ud560 \ub54c, \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc2e4\uc81c \uc0c1\ud669\uc758 \ucf54\ub529 \ubb38\uc81c\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ub2e4\uc591\ud55c \ud558\uc704 \ub3c4\uba54\uc778(\uc608: \ubc31\uc5d4\ub4dc, API, \ub370\uc774\ud130 \uacfc\ud559 \ub4f1)\uc5d0\uc11c \ud3c9\uac00\ub418\uba70, \ubaa8\ub378\uc758 \uc804\ubc18\uc801\uc778 \ucf54\ub529 \ub2a5\ub825\uc744 \ud3ec\uad04\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "3.2 Function-level Generation"}, {"content": "| Dataset | Unique Operators | Unique Operands | Total Operators | Total Operands |\n|---|---|---|---|---|\n| Code Alpaca [Chaudhary (2023)] | 4.83 | 8.22 | 10.66 | 15.89 |\n| Evol CodeAlpaca [Luo et al. (2023)] | 7.94 | 18.97 | 29.91 | 46.70 |\n| CodeFeedBack [Zheng et al. (2024b)] | 8.11 | 20.42 | 30.98 | 50.05 |\n| OSS Instruct [Wei et al. (2024b)] | 7.44 | 20.99 | 28.05 | 47.55 |\n| Ours (func-level) | 10.66 | 44.32 | 56.98 | 100.36 |\n| Ours (file-level) | 11.64 | 72.87 | 100.24 | 179.98 |", "caption": "Table 5: Comparison of Halstead complexity between ours and existing codebase.", "description": "\ubcf8 \ud45c\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\ub41c \ucf54\ub4dc\uc640 \uae30\uc874 \ucf54\ub4dc\ubca0\uc774\uc2a4 \uac04\uc758 Halstead \ubcf5\uc7a1\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Halstead \ubcf5\uc7a1\ub3c4\ub294 \uc18c\ud504\ud2b8\uc6e8\uc5b4\uc758 \ubcf5\uc7a1\ub3c4\ub97c \uce21\uc815\ud558\ub294 \uc9c0\ud45c \uc911 \ud558\ub098\ub85c, \uc720\uc77c\ud55c \uc5f0\uc0b0\uc790 \uc218, \uc720\uc77c\ud55c \ud53c\uc5f0\uc0b0\uc790 \uc218, \ucd1d \uc5f0\uc0b0\uc790 \uc218, \ucd1d \ud53c\uc5f0\uc0b0\uc790 \uc218 \ub4f1\uc744 \uace0\ub824\ud558\uc5ec \uacc4\uc0b0\ub429\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uc81c\uc548\ub41c \ubc29\ubc95(\ud568\uc218 \uc218\uc900 \ubc0f \ud30c\uc77c \uc218\uc900)\uacfc \uae30\uc874 \ucf54\ub4dc\ubca0\uc774\uc2a4(Code Alpaca, Evol Code Alpaca, CodeFeedBack, OSS Instruct)\uc758 \uc720\uc77c\ud55c \uc5f0\uc0b0\uc790 \uc218, \uc720\uc77c\ud55c \ud53c\uc5f0\uc0b0\uc790 \uc218, \ucd1d \uc5f0\uc0b0\uc790 \uc218, \ucd1d \ud53c\uc5f0\uc0b0\uc790 \uc218\ub97c \ube44\uad50\ud558\uc5ec \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ubcf5\uc7a1\ub3c4 \ud2b9\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1 \ubcf5\uc7a1\ub3c4 \ud3c9\uac00"}, {"content": "| Dataset | Mean | Median | Std |\n|---|---|---|---| \n| Code Alpaca | 0.18 | 0.00 | 0.52 |\n| Evol CodeAlpaca | 0.82 | 0.00 | 1.63 |\n| CodeFeedBack | 0.97 | 0.00 | 2.09 |\n| OSS Instruct | 1.50 | 1.00 | 2.19 |\n| Ours (func-level) | 4.95 | 4.00 | 3.77 |\n| Ours (file-level) | 5.41 | 4.00 | 3.85 |", "caption": "Table 6: Comparison of Strictness complexity (left) and Cyclomatic complexity (right).", "description": "\ud45c 6\uc740 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uacf5\ud559 \uad00\uc810\uc5d0\uc11c \ubcf8 \ucf54\ub4dc \ubcf5\uc7a1\ub3c4 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc740 \uc5c4\uaca9\uc131 \ubcf5\uc7a1\ub3c4(Strictness Complexity), \uc624\ub978\ucabd\uc740 \uc21c\ud658 \ubcf5\uc7a1\ub3c4(Cyclomatic Complexity)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \uc9c0\ud45c\ub294 \ub370\uc774\ud130\uc14b\ubcc4 \ud3c9\uade0, \uc911\uac04\uac12, \ud45c\uc900\ud3b8\ucc28\ub97c \uc81c\uc2dc\ud558\uc5ec \ucf54\ub4dc\uc758 \uad6c\uc870\uc801 \ubcf5\uc7a1\uc131\uacfc \uc81c\uc5b4 \ud750\ub984 \ubcf5\uc7a1\uc131\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 EpiCoder \ub370\uc774\ud130\uc14b\uc758 \ubcf5\uc7a1\uc131\uc774 \uae30\uc874 \ub370\uc774\ud130\uc14b\ubcf4\ub2e4 \ud6e8\uc52c \ub192\uc74c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 \ubcf5\uc7a1\ub3c4 \ud3c9\uac00"}, {"content": "| Dataset | Mean | Median | Std |\n|---|---|---|---| \n| Code Alpaca | 2.10 | 1.00 | 1.66 |\n| Evol CodeAlpaca | 3.76 | 3.00 | 3.48 |\n| CodeFeedBack | 3.96 | 3.00 | 3.33 |\n| OSS Instruct | 3.45 | 3.00 | 2.98 |\n| Ours (func-level) | 5.14 | 5.00 | 3.01 |\n| Ours (file-level) | 14.93 | 14.00 | 6.73 |", "caption": "Table 7: Comparison of code complexity across four dimensions using GPT-4o.", "description": "GPT-4o\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucf54\ub4dc \ubcf5\uc7a1\uc131\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4. \uc624\ub958 \ucc98\ub9ac, \ubaa8\ub4c8\uc131, \ub370\uc774\ud130 \uad6c\uc870 \ubcf5\uc7a1\uc131, \ud0c0\uc0ac \uc885\uc18d\uc131\uc758 \ub124 \uac00\uc9c0 \uce21\uba74\uc5d0\uc11c \ucf54\ub4dc \ubcf5\uc7a1\uc131\uc744 \ud3c9\uac00\ud558\uace0 \uac01 \ucc28\uc6d0\uc5d0 \ub300\ud55c \uc810\uc218\ub97c \ubd80\uc5ec\ud558\uc5ec \ucf54\ub4dc\uc758 \uc804\ubc18\uc801\uc778 \ubcf5\uc7a1\uc131\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \ud568\uc218 \uc218\uc900\uacfc \ud30c\uc77c \uc218\uc900\uc758 \ucf54\ub4dc\uc5d0 \ub300\ud55c \ud3c9\uac00 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \uac01 \uc218\uc900\uc5d0\uc11c\uc758 \ubcf5\uc7a1\uc131\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4.1 \ubcf5\uc7a1\ub3c4 \ud3c9\uac00"}, {"content": "| Dataset | Error Handling | Modularity | Dependency | Data Structure | Avg. |\n|---|---|---|---|---|---| \n| Code Alpaca | 2.04 | 2.10 | 2.09 | 2.38 | 2.15 |\n| Evol CodeAlpaca | 2.53 | 3.32 | 2.66 | 3.58 | 3.02 |\n| CodeFeedBack | 2.71 | 3.47 | 2.23 | 3.75 | 3.04 |\n| OSS Instruct | 2.74 | 3.79 | 2.78 | 3.92 | 3.31 |\n| Ours (func-level) | 4.11 | 4.71 | 3.83 | 4.90 | 4.39 |\n| Ours (file-level) | 4.23 | 5.94 | 4.62 | 5.41 | 5.05 |", "caption": "Table 8: Distribution of unique features.", "description": "\ud45c 8\uc740 \ub2e4\uc591\ud55c \ucf54\ub4dc \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd94\ucd9c\ub41c \uace0\uc720\ud55c \ud2b9\uc9d5\ub4e4\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b(Alpaca, CodeFeedback, Evol-Alpaca, OSS-Instruct, \uadf8\ub9ac\uace0 \ubcf8 \ub17c\ubb38\uc758 \ud568\uc218 \ub808\ubca8 \ubc0f \ud30c\uc77c \ub808\ubca8 \ub370\uc774\ud130)\uc5d0 \ub300\ud574 \uac01 \ud2b9\uc9d5 \uc720\ud615(\uc6cc\ud06c\ud50c\ub85c\uc6b0, \uad6c\ud604 \uc2a4\ud0c0\uc77c, \uae30\ub2a5, \uc790\uc6d0 \uc0ac\uc6a9, \uc5f0\uc0b0, \ubcf4\uc548, \uc0ac\uc6a9\uc790 \uc0c1\ud638\uc791\uc6a9, \ub370\uc774\ud130 \ucc98\ub9ac, \ud30c\uc77c \uc870\uc791, \uc624\ub958 \ucc98\ub9ac, \ub85c\uae45, \uc885\uc18d\uc131 \uad00\uacc4, \uc54c\uace0\ub9ac\uc998, \ub370\uc774\ud130 \uad6c\uc870, \uad6c\ud604 \ub85c\uc9c1, \uace0\uae09 \uae30\ubc95)\ubcc4 \uace0\uc720 \ud2b9\uc9d5\uc758 \uac1c\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5 \ub2e4\uc591\uc131\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uace0, \ubcf8 \ub17c\ubb38\uc758 \ub370\uc774\ud130\uc14b\uc774 \ub2e4\ub978 \ub370\uc774\ud130\uc14b\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ub2e4\uc591\ud55c \ud2b9\uc9d5\uc744 \ud3ec\ud568\ud558\uace0 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \ub2e4\uc591\uc131 \ud3c9\uac00"}, {"content": "| Datasets | Workflow | Implementation | Style | Functionality | Resource | Usage | Computation | Operation | Security | User | Interaction | Data | Processing | Avg. |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Alpaca | 994 | 6 | 393 | 7 | 282 | 8 | 82 | 221 |  | 11 | 54 | 1 | 43 | 2.48 |\n| CodeFeedback | 2079 | 6 | 535 | 18 | 689 | 48 | 143 | 895 |  | 39 | 229 | 10 | 121 | 5.45 |\n| Evol-Alpaca | 2163 | 11 | 591 | 21 | 783 | 60 | 134 | 1401 |  | 55 | 212 | 15 | 226 | 6.38 |\n| OSS-Instruct | 2254 | 5 | 669 | 39 | 413 | 49 | 192 | 903 |  | 102 | 211 | 62 | 238 | 5.54 |\n| Ours (func-level) | 2422 | 6 | 657 | 37 | 819 | 156 | 363 | 2533 |  | 203 | 357 | 96 | 305 | 8.53 |\n| Ours (file-level) | 2475 | 11 | 812 | 43 | 536 | 103 | 800 | 2196 |  | 387 | 311 | 218 | 447 | 8.95 |", "caption": "Table 9: Comparison of Test Functions and Test Cases before and after augmentation for 930 data samples.", "description": "\ud45c 9\ub294 930\uac1c\uc758 \ub370\uc774\ud130 \uc0d8\ud50c\uc5d0 \ub300\ud574 \ud14c\uc2a4\ud2b8 \ud568\uc218\uc640 \ud14c\uc2a4\ud2b8 \ucf00\uc774\uc2a4\ub97c \uc99d\uac15\ud558\uae30 \uc804\uacfc \ud6c4\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc99d\uac15 \uc804\uc5d0\ub294 \uc0d8\ud50c\ub2f9 \ud3c9\uade0 4.13\uac1c\uc758 \ud14c\uc2a4\ud2b8 \ud568\uc218\uc640 6.46\uac1c\uc758 \ud14c\uc2a4\ud2b8 \ucf00\uc774\uc2a4\uac00 \uc788\uc5c8\uc9c0\ub9cc, \uc99d\uac15 \ud6c4\uc5d0\ub294 \uac01\uac01 8.53\uac1c\uc640 15.38\uac1c\ub85c \uc99d\uac00\ud588\uc2b5\ub2c8\ub2e4.  \ud14c\uc2a4\ud2b8 \ud568\uc218\uc758 \ucd5c\ub300 \uac1c\uc218\ub294 12\uc5d0\uc11c 23\uc73c\ub85c, \ud14c\uc2a4\ud2b8 \ucf00\uc774\uc2a4\uc758 \ucd5c\ub300 \uac1c\uc218\ub294 20\uc5d0\uc11c 44\ub85c \uc99d\uac00\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ud14c\uc2a4\ud2b8 \ubc94\uc704\ub97c \ud06c\uac8c \ud655\uc7a5\ud558\uc5ec \ucf54\ub4dc\uc758 \uacac\uace0\uc131\uacfc \uc2e0\ub8b0\uc131\uc744 \ud5a5\uc0c1\uc2dc\ucf30\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "B.1 Cross-File Dependency Benchmark"}, {"content": "| Implementation | Style |\n|---|---|", "caption": "Table 10: The index of the data samples presented in the case study.", "description": "\ud45c 10\uc740 \ubcf8 \uc5f0\uad6c\uc758 \uc0ac\ub840 \uc5f0\uad6c\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub370\uc774\ud130 \uc0d8\ud50c\uc758 \uc778\ub371\uc2a4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. HumanEval \ub370\uc774\ud130\uc14b\uacfc evol-codealpaca-v1 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc720\uc0ac\ub3c4 \uc810\uc218\uac00 99%, 95%, 90%, 85%\uc778 \ub370\uc774\ud130 \uc0d8\ud50c\uc758 \uc778\ub371\uc2a4\ub97c \uac01\uac01 \uc81c\uc2dc\ud558\uc5ec \ub370\uc774\ud130 \uc720\ucd9c \uac00\ub2a5\uc131 \uc5ec\ubd80\ub97c \ubd84\uc11d\ud558\uae30 \uc704\ud55c \uc790\ub8cc\ub85c \ud65c\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uac01 \uc720\uc0ac\ub3c4 \uc218\uc900\uc5d0 \ub530\ub77c HumanEval \ub370\uc774\ud130\uc14b\uacfc evol-codealpaca-v1 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub9e4\uce6d\ub418\ub294 \uc0d8\ud50c\uc758 \uc778\ub371\uc2a4\uac00 \ub2e4\ub974\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "C.1 Leakage Threshold Setting"}, {"content": "| Resource | Usage |\n|---|---|", "caption": "Table 11: Derived Halstead metrics. These metrics are derived from unique operators (n1subscript\ud835\udc5b1n_{1}italic_n start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), unique operands (n2subscript\ud835\udc5b2n_{2}italic_n start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), total operators (N1subscript\ud835\udc411N_{1}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT), and total operands (N2subscript\ud835\udc412N_{2}italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT).", "description": "\ud45c 11\uc740 Halstead \uba54\ud2b8\ub9ad\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uace0\uc720 \uc5f0\uc0b0\uc790(n\u2081), \uace0\uc720 \ud53c\uc5f0\uc0b0\uc790(n\u2082), \ucd1d \uc5f0\uc0b0\uc790(N\u2081), \ucd1d \ud53c\uc5f0\uc0b0\uc790(N\u2082)\ub97c \uae30\ubc18\uc73c\ub85c \uc720\ub3c4\ub41c \uba54\ud2b8\ub9ad\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ud504\ub85c\uadf8\ub7a8 \uae38\uc774, \uc5b4\ud718 \ud06c\uae30, \ubcfc\ub968, \ub09c\uc774\ub3c4, \ud504\ub85c\uadf8\ub798\ubc0d \ub178\ub825, \uc608\uc0c1 \uc2dc\uac04, \uc608\uce21 \ubc84\uadf8 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uba54\ud2b8\ub9ad\uc744 \ud1b5\ud574 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ubcf5\uc7a1\ub3c4\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1.1 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 \uad00\uc810\uc5d0\uc11c\uc758 \ud3c9\uac00"}, {"content": "| Computation | Operation |\n|---|---|", "caption": "Table 12: Comparison of different control flow and logical operation frequencies.", "description": "\ud45c 12\ub294 \ub2e4\uc591\ud55c \uc81c\uc5b4 \ud750\ub984 \ubc0f \ub17c\ub9ac \uc5f0\uc0b0\uc758 \ube48\ub3c4\ub97c \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  while, for, \uc608\uc678 \ucc98\ub9ac, return \ub4f1\uc758 \uc81c\uc5b4 \uad6c\uc870\uc640 \ub17c\ub9ac \uc5f0\uc0b0\uc790(bool_op) \uc0ac\uc6a9 \ube48\ub3c4\ub97c \ub370\uc774\ud130\uc14b\ubcc4\ub85c \ube44\uad50\ud558\uc5ec, \uac01 \ub370\uc774\ud130\uc14b\uc758 \ucf54\ub4dc \ubcf5\uc7a1\ub3c4\uc640 \ud2b9\uc9d5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub192\uc740 \ube48\ub3c4\uc758 if, for, except, return \ubb38\uc740 \ub354\uc6b1 \ubcf5\uc7a1\ud558\uace0 \ub2e4\uc591\ud55c \uc608\uc678 \ucc98\ub9ac \uc2dc\ub098\ub9ac\uc624\ub97c \ucc98\ub9ac\ud558\ub294 \ud504\ub85c\uadf8\ub7a8\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.1.1 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 \uad00\uc810\uc5d0\uc11c\uc758 \ud3c9\uac00"}, {"content": "| User | Interaction |\n|---|---|", "caption": "Table 13: Detailed metrics of code strictness complexity", "description": "\ud45c 13\uc740 \ucf54\ub4dc \uc5c4\uaca9\uc131 \ubcf5\uc7a1\ub3c4\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc9c0\ud45c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucf54\ub4dc\uc758 \uc5c4\uaca9\uc131\uc740 \ucf54\ub4dc \uc2a4\ud0c0\uc77c, \uc608\uc678 \ucc98\ub9ac, \ub9ac\ud134 \uac12 \uc720\ud6a8\uc131 \uac80\uc0ac, \ud0c0\uc785 \ud78c\ud2b8 \ub4f1 \uc5ec\ub7ec \uce21\uba74\uc744 \uace0\ub824\ud558\uc5ec \ud3c9\uac00\ub429\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \ucf54\ub4dc \ub370\uc774\ud130\uc14b(Code Alpaca, Evol Code Alpaca, CodeFeedBack, OSS Instruct, \uadf8\ub9ac\uace0 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \ud568\uc218 \ubc0f \ud30c\uc77c \uc218\uc900 \ub370\uc774\ud130\uc14b)\uc5d0 \ub300\ud574 \uac01 \uc9c0\ud45c(Type Hints, Exception Handling, Doc Strings, Return Value Validation \ub4f1)\uc758 \ud3c9\uade0 \uac12\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ub370\uc774\ud130\uc14b\uc774 \ucf54\ub4dc \uc5c4\uaca9\uc131 \uce21\uba74\uc5d0\uc11c \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1.1 \uc18c\ud504\ud2b8\uc6e8\uc5b4 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 \uad00\uc810\uc5d0\uc11c\uc758 \ud3c9\uac00"}, {"content": "| Data | Processing |\n|---|---|", "caption": "Table 14: Distribution of total features across 1k samples.", "description": "\ud45c 14\ub294 1,000\uac1c\uc758 \ucf54\ub4dc \uc0d8\ud50c\uc5d0 \uac78\uccd0 \ucd94\ucd9c\ub41c \ucd1d \uae30\ub2a5\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc0d8\ud50c\uc5d0\uc11c GPT-40\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ubc94\uc8fc(\uc6cc\ud06c\ud50c\ub85c\uc6b0, \uad6c\ud604 \uc2a4\ud0c0\uc77c, \uae30\ub2a5\uc131, \ub9ac\uc18c\uc2a4 \uc0ac\uc6a9, \uacc4\uc0b0 \uc5f0\uc0b0, \ubcf4\uc548, \uc0ac\uc6a9\uc790 \uc0c1\ud638 \uc791\uc6a9, \ub370\uc774\ud130 \ucc98\ub9ac, \ud30c\uc77c \uc870\uc791, \uc624\ub958 \ucc98\ub9ac, \ub85c\uae45, \uc885\uc18d\uc131 \uad00\uacc4, \uc54c\uace0\ub9ac\uc998, \ub370\uc774\ud130 \uad6c\uc870, \uad6c\ud604 \ub17c\ub9ac, \uace0\uae09 \uae30\uc220 \ub4f1)\uc5d0 \uac78\uccd0 \uae30\ub2a5\uc744 \ucd94\ucd9c\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ubc94\uc8fc\ubcc4 \uae30\ub2a5\uc758 \uac1c\uc218\ub97c \ub098\ud0c0\ub0b4\uc5b4, \ub370\uc774\ud130\uc14b\uc758 \ub2e4\uc591\uc131\uacfc \ubcf5\uc7a1\uc131\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  \ud2b9\ud788,  \ub2e4\uc591\ud55c \uae30\ub2a5\ub4e4\uc758 \ubd84\ud3ec\ub97c \ud1b5\ud574 \uac01 \ub370\uc774\ud130\uc14b\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc608\ub97c \ub4e4\uc5b4, \ud2b9\uc815 \ubc94\uc8fc\uc5d0\uc11c \uae30\ub2a5\uc758 \uc218\uac00 \ub9ce\uc744\uc218\ub85d \ud574\ub2f9 \ub370\uc774\ud130\uc14b\uc774 \uadf8 \ubc94\uc8fc\uc5d0 \ud574\ub2f9\ud558\ub294 \uc9c0\uc2dd\uc744 \ub354 \ub9ce\uc774 \ud3ec\ud568\ud558\uace0 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 \ub2e4\uc591\uc131 \ud3c9\uac00"}]