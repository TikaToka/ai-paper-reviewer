[{"content": "| Model | Pass@1 | +Repair |\n|---|---|---|\n| Qwen-2.5-coder-7B-instruct | 0.25 | 0.30 |\n| Qwen-2.5-coder-14B-instruct | 0.50 | 0.55 |\n| Qwen-2.5-coder-32B-instruct | 0.48 | 0.58 |\n| Qwen-2-72B-instruct | 0.34 | 0.43 |\n| DeepSeek-Coder-V2-Lite-Instruct | 0.43 | 0.53 |\n| LLama-3.1-70B | 0.21 | 0.27 |\n| GPT-4o | 0.60 | 0.70 |\n| **Fine-tune Data Mixture** |  |  |\n| 54K F* Only | 0.42 | 0.47 |\n| + Evol | 0.52 | 0.56 |\n| 93K F* Only | 0.48 | 0.52 |\n| + DSP-V1 | 0.52 | 0.54 |\n| + DSP-V1 + Evol + CodeAlpaca + RBR | **0.58** | **0.62** |\n| - F* NL2Code | 0.48 (**-)** | 0.52(**-)** |", "caption": "Table 1: Performance comparison across different models and fine-tuning data mixtures. F* only: synthetic F* data, Evol: 80K (54K F*) / 50K (93K F*) Magicoder-Evol-Instruct data, DSP-V1: 20K Deepseek-Prover-V1 data, CodeAlpaca: 15K CodeAlpaca data, RBR: 15K RunBugRun data", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ubaa8\ub378\uacfc \ubbf8\uc138 \uc870\uc815 \ub370\uc774\ud130 \ud63c\ud569\uc5d0 \ub530\ub978 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'F* only'\ub294 \ud569\uc131 F* \ub370\uc774\ud130\ub97c, 'Evol'\uc740 80K(54K F*) / 50K(93K F*) Magicoder-Evol-Instruct \ub370\uc774\ud130\ub97c, 'DSP-V1'\uc740 20K Deepseek-Prover-V1 \ub370\uc774\ud130\ub97c, 'CodeAlpaca'\ub294 15K CodeAlpaca \ub370\uc774\ud130\ub97c, 'RBR'\uc740 15K RunBugRun \ub370\uc774\ud130\ub97c \uac01\uac01 \uc0ac\uc6a9\ud55c \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 Pass@1(\ud55c \ubc88 \uc2dc\ub3c4 \uc131\uacf5\ub960)\uacfc Pass@1+Repair(\uc218\uc815 \ud6c4 \uc131\uacf5\ub960)\uc744 \ube44\uad50\ud558\uc5ec \uc5b4\ub5a4 \ubaa8\ub378\uacfc \ub370\uc774\ud130 \ud63c\ud569 \ubc29\uc2dd\uc774 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5 Function-Level Experiments"}, {"content": "| Baseline Models | Generate@5 | Repair@5 | Gen+Rep (Total 10) | Generate@10 |\n|---|---|---|---|---|\n| Qwen2.5-Coder-32B-Instruct | 23.5 | 0.8 | 24.3 | 27.1 |\n| Deepseek-Coder-33B-Instruct | 22.3 | 4.6 | 26.9 | 28.8 |\n| GPT-4o | 22.2 | 1.7 | 23.9 | 23.8 |\n| Qwen2.5-72B-Instruct | 23.4 | 3.0 | 26.4 | 25.8 |\n| Llama-3.3-70B-Instruct-Turbo | 19.6 | 3.9 | 23.5 | 21.6 |\n| **Data Mixture** |  |  |  |  |\n| *Existing Repos* | 30.7 | 1.0 | 31.7 | 35.3 |\n| + Syn. Project Proof | 32.2 | 2.2 | 34.4 | 36.2 |\n| + Func + Syn. Project Proof | 32.8 | 2.7 | 35.5 | 37.8 |\n| + Syn. Project Proof + Syn. Repair | 32.7 | 0.7 | 33.4 | 37.5 |\n| + Syn. Project Proof + Model Repair | 33.1 | 4.2 | 37.3 | 37.2 |\n| + Syn. Project Proof + All Repair | **34.0** | 4.7 | 38.7 | 38.0 |\n| PoPilot | 33.0 | **6.4** | **39.4** | **38.5** |", "caption": "Table 2: Performance comparison of baseline models and fine-tuning data configurations. Existing Repos: 30K existing repository level definition + proofs from the seed dataset; Syn. Project Proof : 30K model generated new definitions + proofs as described in 4.1; Func: synthetic simple questions mixed with other datasets in 5.2; Syn. Repair: 30K synthetic repair data in 4.2.1, Model Repair: 30K model-generarted repair data in 4.2.2; All Repair: Syn. Repair + Model Repair; PoPilot: Existing Repos + Syn. Project Proof + All Repair + 180K mixed function-level coding data used to finetune the best performance in Table 1", "description": "\ud45c 2\ub294 \uae30\uc900 \ubaa8\ub378\uacfc \ubbf8\uc138 \uc870\uc815 \ub370\uc774\ud130 \uad6c\uc131\uc5d0 \ub300\ud55c \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 \uc800\uc7a5\uc18c(Existing Repos): \uc2dc\ub4dc \ub370\uc774\ud130\uc14b\uc758 \uae30\uc874 \uc800\uc7a5\uc18c \uc218\uc900 \uc815\uc758 \ubc0f \uc99d\uba85 30K\uac1c; \ud569\uc131 \ud504\ub85c\uc81d\ud2b8 \uc99d\uba85(Syn. Project Proof): 4.1\uc808\uc5d0 \uc124\uba85\ub41c \ub300\ub85c \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc0c8\ub85c\uc6b4 \uc815\uc758 \ubc0f \uc99d\uba85 30K\uac1c; \ud568\uc218(Func): 5.2\uc808\uc758 \ub2e4\ub978 \ub370\uc774\ud130\uc14b\uacfc \ud63c\ud569\ub41c \ud569\uc131 \uac04\ub2e8 \uc9c8\ubb38; \ud569\uc131 \ubcf5\uad6c(Syn. Repair): 4.2.1\uc808\uc758 \ud569\uc131 \ubcf5\uad6c \ub370\uc774\ud130 30K\uac1c; \ubaa8\ub378 \ubcf5\uad6c(Model Repair): 4.2.2\uc808\uc758 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ubcf5\uad6c \ub370\uc774\ud130 30K\uac1c; \ubaa8\ub4e0 \ubcf5\uad6c(All Repair): \ud569\uc131 \ubcf5\uad6c + \ubaa8\ub378 \ubcf5\uad6c; PoPilot: \ud45c 1\uc5d0\uc11c \ucd5c\uace0 \uc131\ub2a5\uc744 \ubbf8\uc138 \uc870\uc815\ud558\ub294 \ub370 \uc0ac\uc6a9\ub41c \uae30\uc874 \uc800\uc7a5\uc18c + \ud569\uc131 \ud504\ub85c\uc81d\ud2b8 \uc99d\uba85 + \ubaa8\ub4e0 \ubcf5\uad6c + 180K\uac1c\uc758 \ud63c\ud569 \ud568\uc218 \uc218\uc900 \ucf54\ub529 \ub370\uc774\ud130", "section": "6 Project-Level Proof Synthesis"}, {"content": "| Model | Gen@5 | sample1-on-5 | sample5-on-1 |\n|---|---|---|---| \n| Our Best Model | 34 | +1.7 | +4.7 |\n| Qwen2.5-Coder-32B | 23.5 | +0.8 | +7.8 |\n| DS-Coder-33B | 22.3 | +4.6 | +9.8 |", "caption": "Table 3: Comparison of repair sampling strategies: sample1-on-5 repairs each incorrect solution once, while sample5-on-1 repairs the same incorrect solution multiple times.", "description": "\ud45c 3\uc740 \uc798\ubabb\ub41c \uc194\ub8e8\uc158\uc744 \uc218\uc815\ud558\ub294 \ub450 \uac00\uc9c0 \uc804\ub7b5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. sample1-on-5\ub294 \uac01 \uc798\ubabb\ub41c \uc194\ub8e8\uc158\uc744 \ud55c \ubc88\ub9cc \uc218\uc815\ud558\uace0, sample5-on-1\uc740 \ub3d9\uc77c\ud55c \uc798\ubabb\ub41c \uc194\ub8e8\uc158\uc744 \uc5ec\ub7ec \ubc88 \uc218\uc815\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub3d9\uc77c\ud55c \uc798\ubabb\ub41c \uc194\ub8e8\uc158\uc5d0 \ub300\ud55c \uc5ec\ub7ec \ubc88\uc758 \uc218\uc815 \uc2dc\ub3c4\uac00 \uc131\uacf5\ub960\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6.4 \uacb0\uacfc"}, {"content": "| Baseline Models | Generate@5 | Repair@5 | Gen+Rep (Total 10) | Generate@10 |\n|---|---|---|---|---|\n| Qwen2.5-Coder-32B-Instruct | 23.5 | 0.8 | 24.3 | 27.1 |\n| Deepseek-Coder-33B-Instruct | 22.3 | 4.6 | 26.9 | 28.8 |\n| GPT-4o | 22.2 | 1.7 | 23.9 | 23.8 |\n| Qwen2.5-72B-Instruct | 23.4 | 3.0 | 26.4 | 25.8 |\n| Llama-3.3-70B-Instruct-Turbo | 19.6 | 3.9 | 23.5 | 21.6 |\n| **Fine-tuned model** |  |  |  |  |\n| PoPilot-small | 21.9 | 3.9 | 25.8 | 29.2 |\n| **PoPilot** | **33.0** | **6.4** | **39.4** | **38.5** |", "caption": "Table 4: Performance comparison of the small model", "description": "\ud45c 4\ub294 \ubcf4\ub2e4 \uc791\uc740 \ubaa8\ub378(Qwen2.5-Coder-7B\ub97c \uae30\ubc18\uc73c\ub85c \ud568)\uc5d0 \ub300\ud55c \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874\uc758 \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\ub4e4(Qwen2.5-Coder-32B-INSTRUCT, Deepseek-Coder-33B-INSTRUCT, GPT-40, Qwen2.5-72B-INSTRUCT, LLaMa-3.3-70B-INSTRUCT-TURBO)\uacfc \ube44\uad50\ud558\uc5ec,  \uc791\uc740 \ubaa8\ub378\uc744 fine-tuning\ud55c \uacb0\uacfc(POPILOT-SMALL)\uc640 \ub17c\ubb38\uc758 \uc8fc\uc694 \ubaa8\ub378\uc778 POPILOT\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Generate@5, Repair@5, Gen+Rep (Total 10), Generate@10 \uc9c0\ud45c\ub97c \ud1b5\ud574 \ucf54\ub4dc \uc0dd\uc131 \ubc0f \ubcf5\uad6c \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "5. Function-Level Experiments"}]