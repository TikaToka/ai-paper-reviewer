{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduced CLIP, a highly influential vision-language model that forms the foundation for ThinkDiff's multimodal capabilities."}, {"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduced Stable Diffusion, a key diffusion model architecture that ThinkDiff builds upon and enhances with multimodal reasoning."}, {"fullname_first_author": "Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper demonstrated the remarkable few-shot learning capabilities of large language models, which are leveraged by ThinkDiff's proxy training task."}, {"fullname_first_author": "Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-10-01", "reason": "This paper introduced ControlNet, a method that incorporates structural and image-level controls into diffusion models, providing context for ThinkDiff's approach."}, {"fullname_first_author": "Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This foundational paper on denoising diffusion models provides the theoretical framework for ThinkDiff's use of diffusion models for image generation."}]}