{"references": [{"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces the foundational Latent Diffusion Model (LDM) architecture, which is extensively used and improved upon in many of the models discussed and evaluated in this paper."}, {"fullname_first_author": "Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-00-00", "reason": "This paper introduces the DiT model, which is a key downstream generative model used for evaluating the impact of the proposed EQ-VAE method."}, {"fullname_first_author": "Ma", "paper_title": "SIT: Exploring flow and diffusion-based generative models with scalable interpolant transformers", "publication_date": "2024-00-00", "reason": "This paper introduces the SiT model, another significant downstream generative model used to benchmark the EQ-VAE method."}, {"fullname_first_author": "Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces VQGAN, a key autoencoder model used in several downstream methods evaluated in the paper, and is important for understanding discrete autoencoder approaches."}, {"fullname_first_author": "Yu", "paper_title": "Scaling autoregressive models for content-rich text-to-image generation", "publication_date": "2025-00-00", "reason": "This paper introduces the REPA model, a further significant downstream generative model used to benchmark and showcase the EQ-VAE's effectiveness."}]}