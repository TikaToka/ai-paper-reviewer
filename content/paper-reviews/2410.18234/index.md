---
title: "Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits"
summary: "Researchers boosted Large Language Model inference speed by using multiple draft models and a novel token selection scheme, improving block efficiency and token rates."
categories: ["AI Generated"]
tags: ["ðŸ”– 24-10-23", "ðŸ¤— 24-10-25"]
showSummary: true
date: 2024-10-23
draft: false
---

### TL;DR


{{< lead >}}

This research tackles the slow speed of Large Language Model (LLM) text generation by improving 'speculative decoding'.  Instead of generating text one word at a time, speculative decoding uses a faster 'draft model' to suggest multiple options, which a more powerful LLM then verifies. This paper introduces 'multi-draft speculative sampling', which uses multiple draft models simultaneously to further accelerate this process.  The researchers prove mathematically that the optimal approach is to use a two-step process: first, importance sampling is used to select a promising token from the various draft models and then, the chosen token is verified using speculative sampling. They demonstrate consistent improvements over existing methods in terms of block efficiency (more tokens generated per LLM usage) and token rate (overall speed) across several datasets and scenarios.  The work also includes a detailed mathematical analysis of the optimal sampling scheme for two identical draft models, providing sufficient conditions for a perfect acceptance rate and an analytical expression for the optimal acceptance probability.  This work contributes significantly towards making LLMs more efficient and practical for use in various applications, especially in resource-constrained environments.

{{< /lead >}}


{{< button href="https://arxiv.org/abs/2410.18234" target="_self" >}}
{{< icon "link" >}} &nbsp; read the paper on arXiv
{{< /button >}}

#### Why does it matter?
This paper significantly advances the efficiency of large language model (LLM) inference by proposing a novel multi-draft speculative sampling method. It offers both theoretical analysis and empirical improvements, thus opening avenues for optimizing LLM decoding and impacting various downstream applications.  It addresses a critical bottleneck in LLM deployment, making it relevant to a broad research community.
#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} A new multi-draft speculative sampling method significantly improves LLM decoding efficiency. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} The optimal token selection strategy can be decomposed into importance sampling and single-draft speculative sampling. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Theoretical analysis provides conditions for achieving perfect acceptance probability and an explicit expression for optimal probability with two drafts. {{< /typeit >}}
{{< /alert >}}

------
#### Visual Insights



![](figures/figures_4_0.png "ðŸ”¼ Figure 1: Optimal Approach for Multi-Draft Speculative Sampling")

> The figure illustrates the optimal two-step approach for multi-draft speculative sampling, which involves importance weighted sampling followed by speculative sampling.





![](charts/charts_6_0.png "ðŸ”¼ Figure 2: Numerical evaluation of Pr(accept) for the optimal scheme (Theorem 3) as well as two baseline schemes â€“ SpecTr (Sun et al., 2024b) and SpecInfer (Miao et al., 2024). For sake of illustration we select alphabet Î© = {1,2,3} and p = [1/3,1/3, 1/3]. The left plot sets q = [1/3, q2, 2/3-q2] while the right plot sets q = [1/6, q2, 5/6 - q2] where q2 is varied on the x-axis.")

> The chart numerically evaluates the acceptance probability for the optimal scheme and two baseline schemes (SpecTr and SpecInfer) by varying the target distribution parameter q2.





{{< table-caption caption="ðŸ”½ Table 3: Comparison of average acceptance probability across different tasks for K = 2, 4, 8 drafts." >}}
<table id='2' style='font-size:16px'><tr><td>Ashish Khisti * 12</td><td>M.Reza Ebrahimi ãƒ»1</td><td>Hassan Dbouk1</td></tr><tr><td>Arash Behboodi1</td><td>Roland Memisevic 1</td><td>Christos Louizos t 1</td></tr></table>{{< /table-caption >}}

> This table compares the average acceptance probability across different tasks (XSum, Dolly, WMT) for varying numbers of draft models (K=2, 4, 8) using different methods (Optimal, IS, SpecTr, SpecInfer).



### More visual insights

<details>
<summary>More on figures
</summary>


![](figures/figures_24_0.png "ðŸ”¼ Figure 1: Optimal Approach for Multi-Draft Speculative Sampling")

> The figure illustrates the optimal two-step scheme for multi-draft speculative sampling, showing importance weighted sampling followed by speculative sampling.


![](figures/figures_35_0.png "ðŸ”¼ Figure 2: Numerical evaluation of Pr(accept) for the optimal scheme (Theorem 3) as well as two baseline schemes â€“ SpecTr (Sun et al., 2024b) and SpecInfer (Miao et al., 2024). For sake of illustration we select alphabet Î© = {1,2,3} and p = [1/3,1/3, 1/3]. The left plot sets q = [1/3, q2, 2/3-q2] while the right plot sets q = [1/6, q2, 5/6 - q2] where q2 is varied on the x-axis.")

> The figure shows a numerical evaluation of the acceptance probability for the optimal scheme and two baseline schemes, SpecTr and SpecInfer, for different values of q2.


</details>



<details>
<summary>More on charts
</summary>


![](charts/charts_9_0.png "ðŸ”¼ Figure 3: Performance comparison of different multi-draft schemes, while we vary the temperature of the two draft models.")

> The chart compares the block efficiency and token rate improvement over single-draft speculative decoding for different multi-draft schemes (IS, SpecTr, SpecInfer) across three datasets (Dolly, XSum, WMT) while varying the temperature of the draft models.


![](charts/charts_10_0.png "ðŸ”¼ Figure 4: Performance comparison of different multi-draft schemes. The temperature of the first draft model is set to 1.2, while we vary the temperature of the other draft.")

> The chart compares the performance of different multi-draft schemes across three datasets (Dolly, XSum, WMT) while varying the temperature of one draft model while keeping the other constant.


![](charts/charts_34_0.png "ðŸ”¼ Figure 2: Numerical evaluation of Pr(accept) for the optimal scheme (Theorem 3) as well as two baseline schemes â€“ SpecTr (Sun et al., 2024b) and SpecInfer (Miao et al., 2024). For sake of illustration we select alphabet Î© = {1,2,3} and p = [1/3,1/3, 1/3]. The left plot sets q = [1/3, q2, 2/3-q2] while the right plot sets q = [1/6, q2, 5/6 - q2] where q2 is varied on the x-axis.")

> The chart numerically evaluates the acceptance probability for the optimal scheme and compares it with two baseline schemes, SpecTr and SpecInfer, by varying the parameter q2.


![](charts/charts_34_1.png "ðŸ”¼ Figure 2: Numerical evaluation of Pr(accept) for the optimal scheme (Theorem 3) as well as two baseline schemes â€“ SpecTr (Sun et al., 2024b) and SpecInfer (Miao et al., 2024). For sake of illustration we select alphabet Î© = {1,2,3} and p = [1/3,1/3, 1/3]. The left plot sets q = [1/3, q2, 2/3-q2] while the right plot sets q = [1/6, q2, 5/6 - q2] where q2 is varied on the x-axis.")

> The chart numerically evaluates the acceptance probability for the optimal scheme and two baseline schemes (SpecTr and SpecInfer) by varying the target distribution parameter q2.


</details>



<details>
<summary>More on tables
</summary>


{{< table-caption caption="ðŸ”½ Table 1: Block efficiency achieved in the Dolly task for different number of draft models." >}}
<br><table id='4' style='font-size:16px'><tr><td>Scheme</td><td>K = 2</td><td>K = 3</td><td>K = 4</td><td>K = 5</td><td>K = 6</td></tr><tr><td>IS</td><td>2.13 åœŸ 0.05</td><td>2.22 å£« 0.05</td><td>2.26 åœŸ 0.05</td><td>2.27 å£« 0.05</td><td>2.28 å£« 0.06</td></tr><tr><td>SpecInfer</td><td>1.76 å£« 0.04</td><td>1.86 å£« 0.05</td><td>1.95 åœŸ 0.05</td><td>2.00 å£« 0.04</td><td>2.04 å£« 0.05</td></tr><tr><td>SpecTr</td><td>1.77 åœŸ 0.04</td><td>1.89 åœŸ 0.05</td><td>1.96 åœŸ 0.05</td><td>2.03 å£« 0.06</td><td>2.08 åœŸ 0.04</td></tr></table>{{< /table-caption >}}

> Table 1 shows the block efficiency achieved by three different multi-draft speculative sampling methods using 2 to 6 draft models on the Dolly task.


{{< table-caption caption="ðŸ”½ Table 2: Effect of LP Truncation and Alphabet Truncation" >}}
<br><table id='4' style='font-size:18px'><tr><td></td><td></td><td>Block Efficiency</td><td>Token Rate (% improvement to SD)</td></tr><tr><td rowspan="4">Alphabet Truncation ( 2âŒ€ )</td><td>10</td><td>1.98 å£« 0.03</td><td>-0.57 å£« 3.38%</td></tr><tr><td>20</td><td>2.00 å£« 0.04</td><td>1.00 åœŸ 3.08%</td></tr><tr><td>40</td><td>2.05 å£« 0.04</td><td>6.63 åœŸ 3.18%</td></tr><tr><td>50</td><td>2.03 å£« 0.05</td><td>3.22 åœŸ 3.39%</td></tr><tr><td rowspan="3">LP-Truncation Threshold (s)</td><td>5</td><td>2.05 å£« 0.04</td><td>6.63 å£« 3.18%</td></tr><tr><td>10</td><td>2.04 åœŸ 0.05</td><td>1.52 åœŸ 3.47%</td></tr><tr><td>15</td><td>2.04 å£« 0.04</td><td>1.74 åœŸ 2.36%</td></tr></table>{{< /table-caption >}}

> Table 2 shows the effect of LP truncation and alphabet truncation on the block efficiency and token rate improvement over the single-draft baseline.


{{< table-caption caption="ðŸ”½ Table 3: Comparison of average acceptance probability across different tasks for K = 2, 4, 8 drafts." >}}
<br><table id='8' style='font-size:16px'><tr><td>Scheme</td><td colspan="3">XSum</td><td colspan="3">Dolly</td></tr><tr><td></td><td>K=2</td><td>K=4</td><td>K=8</td><td>K=2</td><td>K=4</td><td>K=8</td></tr><tr><td>Optimal</td><td>0.5009</td><td>0.5226</td><td>0.5419</td><td>0.6384</td><td>0.6731</td><td>0.6962</td></tr><tr><td>IS</td><td>0.4933</td><td>0.5145</td><td>0.5333</td><td>0.6348</td><td>0.6691</td><td>0.6919</td></tr><tr><td>SpecTr</td><td>0.4889</td><td>0.5083</td><td>0.5263</td><td>0.6246</td><td>0.6560</td><td>0.6800</td></tr><tr><td>SpecInfer</td><td>0.4875</td><td>0.5058</td><td>0.5227</td><td>0.6202</td><td>0.6489</td><td>0.6722</td></tr></table>{{< /table-caption >}}

> Table 3 compares the token-level acceptance probability across different methods for K=2, 4, and 8 drafts on three different tasks.


{{< table-caption caption="ðŸ”½ Table 4: Block Efficiency achieved in the Dolly Task with top-k sampling" >}}
<br><table id='12' style='font-size:18px'><tr><td rowspan="2">Sampling</td><td rowspan="2">Scheme</td><td colspan="2">K = 2 drafts</td><td colspan="2">K = 3 drafts</td></tr><tr><td>Block Efficiency</td><td>Loss</td><td>Block Efficiency</td><td>Loss</td></tr><tr><td rowspan="3">top-k (k = 10)</td><td>IS</td><td>2.48 åœŸ 0.01</td><td></td><td>2.59 å£« 0.02</td><td></td></tr><tr><td>SpecTr</td><td>2.43 åœŸ 0.01</td><td>98%</td><td>2.55 å£« 0.01</td><td>98%</td></tr><tr><td>SpecInfer</td><td>2.38 å£« 0.02</td><td>96%</td><td>2.49 å£« 0.02</td><td>96%</td></tr><tr><td rowspan="3">top-k (k = 5)</td><td>IS</td><td>2.52 å£« 0.02</td><td></td><td>2.63 å£« 0.03</td><td></td></tr><tr><td>SpecTr</td><td>2.48 åœŸ 0.02</td><td>98%</td><td>2.56 å£« 0.03</td><td>97%</td></tr><tr><td>SpecInfer</td><td>2.47 å£« 0.01</td><td>98%</td><td>2.55 å£« 0.04</td><td>97%</td></tr></table>{{< /table-caption >}}

> Table 4 compares the block efficiencies for different methods using K=2 and K=3 drafts, applying top-k sampling with k=10 and k=5, and using temperature of 1.0 for both models.


{{< table-caption caption="ðŸ”½ Table 5: ROUGE-L scores on the XSum task across various decoders and sampling temperatures." >}}
<br><table id='3' style='font-size:16px'><tr><td>Draft Temp.</td><td>1.2</td><td>1.4</td><td>1.6</td><td>2.0</td><td>2.4</td></tr><tr><td colspan="6">Decoder</td></tr><tr><td>IS</td><td>0.186 å£« 0.004</td><td>0.188 åœŸ 0.002</td><td>0.191 åœŸ 0.003</td><td>0.186 åœŸ 0.004</td><td>0.187 å£« 0.003</td></tr><tr><td>Signle-draft SD</td><td>0.190 å£« 0.006</td><td>0.185 å£« 0.005</td><td>0.190 å£« 0.004</td><td>0.186 å£« 0.003</td><td>0.186 å£« 0.004</td></tr><tr><td>SpecInfer</td><td>0.184 åœŸ 0.004</td><td>0.190 åœŸ 0.002</td><td>0.187 åœŸ 0.001</td><td>0.186 å£« 0.003</td><td>0.186 å£« 0.004</td></tr><tr><td>SpecTr</td><td>0.188 åœŸ 0.002</td><td>0.182 åœŸ 0.006</td><td>0.188 å£« 0.001</td><td>0.185 åœŸ 0.006</td><td>0.188 åœŸ 0.001</td></tr></table>{{< /table-caption >}}

> Table 5 presents ROUGE-L scores on the XSum task for different decoders (IS, single-draft, SpecInfer, SpecTr) and draft model temperatures.


{{< table-caption caption="ðŸ”½ Table 6: BLEU scores on the WMT dataset across various decoders and sampling temperatures." >}}
<br><table id='5' style='font-size:18px'><tr><td>Draft Temp.</td><td>1.2</td><td>1.4</td><td>1.6</td><td>2.0</td><td>2.4</td></tr><tr><td colspan="6">Decoder</td></tr><tr><td>IS</td><td>0.037 å£« 0.002</td><td>0.038 åœŸ 0.004</td><td>0.034 åœŸ 0.002</td><td>0.039 å£« 0.003</td><td>0.039 åœŸ 0.002</td></tr><tr><td>Signle-draft SD</td><td>0.036 åœŸ 0.000</td><td>0.037 åœŸ 0.003</td><td>0.038 åœŸ 0.004</td><td>0.037 å£« 0.003</td><td>0.038 åœŸ 0.002</td></tr><tr><td>SpecInfer</td><td>0.035 åœŸ 0.003</td><td>0.039 åœŸ 0.004</td><td>0.035 å£« 0.003</td><td>0.034 å£« 0.009</td><td>0.036 åœŸ 0.003</td></tr><tr><td>SpecTr</td><td>0.039 åœŸ 0.001</td><td>0.037 åœŸ 0.001</td><td>0.039 åœŸ 0.001</td><td>0.036 å£« 0.002</td><td>0.035 å£« 0.001</td></tr></table>{{< /table-caption >}}

> Table 6 presents BLEU scores on the WMT dataset for different decoding methods (IS, single-draft speculative decoding, SpecInfer, and SpecTr) across various draft and target model temperatures.


{{< table-caption caption="ðŸ”½ Table 7: ROUGE-L scores on the XSum task across various decoders and sampling temperatures." >}}
<table id='8' style='font-size:16px'><tr><td></td><td colspan="5">Temperature</td></tr><tr><td>Draft 1</td><td colspan="5">1.2</td></tr><tr><td>Draft 2</td><td>1.2</td><td>1.6</td><td>2.0</td><td>2.4</td><td>N/A</td></tr><tr><td>Decoder</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>IS</td><td>0.187 å£« 0.004</td><td>0.189 åœŸ 0.007</td><td>0.189 å£« 0.001</td><td>0.191 å£« 0.002</td><td>-</td></tr><tr><td>SpecInfer</td><td>0.184 å£« 0.004</td><td>0.190 åœŸ 0.003</td><td>0.185 åœŸ 0.006</td><td>0.189 åœŸ 0.006</td><td></td></tr><tr><td>Single-draft SD</td><td>-</td><td></td><td></td><td>-</td><td>0.190 åœŸ 0.006</td></tr></table>{{< /table-caption >}}

> Table 7 compares the ROUGE-L scores for different multi-draft schemes across various decoders and sampling temperatures on the XSum task.


{{< table-caption caption="ðŸ”½ Table 8: BLEU scores on the WMT dataset across various decoders and sampling temperatures." >}}
<table id='10' style='font-size:14px'><tr><td></td><td colspan="5">Temperature</td></tr><tr><td>Draft 1</td><td colspan="5">1.2</td></tr><tr><td>Draft 2</td><td>1.2</td><td>1.6</td><td>2.0</td><td>2.4</td><td>N/A</td></tr><tr><td>Decoder</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>IS</td><td>0.036 åœŸ 0.003</td><td>0.035 åœŸ 0.002</td><td>0.036 åœŸ 0.002</td><td>0.035 å£« 0.002</td><td>-</td></tr><tr><td>SpecInfer</td><td>0.035 å£« 0.003</td><td>0.038 åœŸ 0.005</td><td>0.041 åœŸ 0.002</td><td>0.040 åœŸ 0.002</td><td></td></tr><tr><td>Single-draft SD</td><td>-</td><td>-</td><td>-</td><td>-</td><td>0.036 å£« 0.000</td></tr></table>{{< /table-caption >}}

> Table 8 shows the BLEU scores on the WMT dataset for different multi-draft schemes while varying the temperature of the two draft models.


</details>


### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/21.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/22.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/23.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/24.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/25.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/26.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/27.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/28.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/29.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/30.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/31.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/32.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/33.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/34.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/35.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/36.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/37.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/38.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}