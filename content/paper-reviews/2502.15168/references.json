{"references": [{"fullname_first_author": "Eleftheria Briakou", "paper_title": "Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer", "publication_date": "2021-06-00", "reason": "This paper introduces XFORMAL, a benchmark dataset crucial for evaluating multilingual formality style transfer models, directly relevant to the current paper's multilingual style embedding task."}, {"fullname_first_author": "Alexis Conneau", "paper_title": "Unsupervised cross-lingual representation learning at scale", "publication_date": "2019-00-00", "reason": "This paper introduces the multilingual xlm-roberta model, which serves as the base model in the current study, thus its architecture and performance are fundamental to the current work."}, {"fullname_first_author": "Ajay Patel", "paper_title": "DataDreamer: A tool for synthetic data generation and reproducible LLM workflows", "publication_date": "2024-00-00", "reason": "This work introduces DataDreamer, a crucial tool used for the synthetic data generation methodology employed in the main study, hence it's critical for understanding the data creation process."}, {"fullname_first_author": "Ajay Patel", "paper_title": "Learning interpretable style embeddings via prompting LLMs", "publication_date": "2023-00-00", "reason": "This paper explores the use of LLMs for style embedding, a technique that directly informs the approach taken by the current study.  Its insights are essential to the design of the new model."}, {"fullname_first_author": "Ajay Patel", "paper_title": "Styledistance: Stronger content-independent style embeddings with synthetic parallel examples", "publication_date": "2024-00-00", "reason": "This paper introduces the STYLEDISTANCE model, which forms the basis for the multilingual model developed in this paper, making it foundational to the current research."}]}