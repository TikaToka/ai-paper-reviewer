[{"figure_path": "https://arxiv.org/html/2502.01637/x1.png", "caption": "Figure 1: (Top) Perplexity (lower is better) on the OLMo (Groeneveld et\u00a0al., 2024) evaluation mixture. Inference-time FLOPS refer to the forward pass computation cost for four model sizes (0.7B, 1B, 1.3B, and 1.9B). With 10M f-grams, the 1.3B model matches the 1.9B baseline, while with 1B f-grams, the 1B model surpasses it. (Bottom) End-to-end token generation speed on a single A100 using vLLM (Kwon et\u00a0al., 2023). Storing f-gram embeddings in main memory introduces negligible latency, while NVMe storage slows generation slightly but does not create a bottleneck.", "description": "\uadf8\ub9bc 1\uc740 SCONE \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub450 \uac1c\uc758 \uadf8\ub798\ud504\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc704\ucabd \uadf8\ub798\ud504\ub294 OLMo \ud3c9\uac00 \ud63c\ud569 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub124 \uac00\uc9c0 \ud06c\uae30(0.7B, 1B, 1.3B, 1.9B)\uc758 \ubaa8\ub378\uc5d0 \ub300\ud55c perplexity\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  SCONE\uc744 \uc0ac\uc6a9\ud558\uba74 10M\uac1c\uc758 f-gram\uc744 \uc0ac\uc6a9\ud558\ub294 1.3B \ubaa8\ub378\uc774 1.9B \uae30\uc900 \ubaa8\ub378\uacfc \ub3d9\uc77c\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uace0, 1B\uac1c\uc758 f-gram\uc744 \uc0ac\uc6a9\ud558\ub294 1B \ubaa8\ub378\uc740 \uae30\uc900 \ubaa8\ub378\uc744 \ub2a5\uac00\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798\ucabd \uadf8\ub798\ud504\ub294 \ub2e8\uc77c A100\uc5d0\uc11c vLLM\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc885\ub2e8 \uac04 \ud1a0\ud070 \uc0dd\uc131 \uc18d\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. f-gram \uc784\ubca0\ub529\uc744 \uba54\uc778 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ud558\uba74 \uc9c0\uc5f0 \uc2dc\uac04\uc774 \uac70\uc758 \ubc1c\uc0dd\ud558\uc9c0 \uc54a\uc9c0\ub9cc, NVMe \uc800\uc7a5\uc18c\ub97c \uc0ac\uc6a9\ud558\uba74 \uc0dd\uc131 \uc18d\ub3c4\uac00 \uc57d\uac04 \ub290\ub824\uc9c0\uc9c0\ub9cc \ubcd1\ubaa9 \ud604\uc0c1\uc740 \ubc1c\uc0dd\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "4. Experimental Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.01637/x2.png", "caption": "Figure 2: Illustration of Scone (with a maximum n\ud835\udc5bnitalic_n-gram length of 3333). The term f-grams refers to the set of frequent n\ud835\udc5bnitalic_n-grams (Section\u00a03).", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c SCONE \ubc29\ubc95\uc758 \uac1c\ub150\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucd5c\ub300 3-gram \uae38\uc774\ub97c \uc0ac\uc6a9\ud558\ub294 \uc608\uc2dc\uac00 \ub098\uc640 \uc788\uc73c\uba70, \uc790\uc8fc \ub4f1\uc7a5\ud558\ub294 n-gram(f-gram)\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc785\ub825 \ud1a0\ud070 \uc784\ubca0\ub529\uc744 \ud655\uc7a5\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc785\ub825 \ud14d\uc2a4\ud2b8\ub294 \ud1a0\ud070\ud654\ub418\uace0, f-gram \ubaa8\ub378\uc740 \uc790\uc8fc \ub4f1\uc7a5\ud558\ub294 n-gram\uc5d0 \ub300\ud55c \ubb38\ub9e5\ud654\ub41c \uc784\ubca0\ub529\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 \uc784\ubca0\ub529\uc740 \ucd94\ub860 \uc911\uc5d0 \uc624\ud504-\uc561\uc140\ub7ec\ub808\uc774\ud130 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ub418\ubbc0\ub85c \ucd94\ub860 \uc18d\ub3c4\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.  SCONE\uc740 \uae30\uc874\uc758 \ub2e8\uc5b4 \uc784\ubca0\ub529\uacfc f-gram \uc784\ubca0\ub529\uc744 \uacb0\ud569\ud558\uc5ec \uc785\ub825 \ud1a0\ud070\uc758 \ud48d\ubd80\ud55c \ud45c\ud604\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 SCONE\uc758 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\uc640 \ub370\uc774\ud130 \ud750\ub984\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3. SCONE \uc544\ud0a4\ud14d\ucc98"}, {"figure_path": "https://arxiv.org/html/2502.01637/x3.png", "caption": "Figure 3: Number of unique 2222- to 6666-grams that appear at least five times. We vary the size of the corpus by uniformly sampling sequences from the OLMo tokenized training corpus (Soldaini et\u00a0al., 2024).", "description": "\uc774 \uadf8\ub9bc\uc740 OLMo \ud1a0\ud070\ud654\ub41c \ud6c8\ub828 \ub9d0\ubb49\uce58(Soldaini et al., 2024)\uc5d0\uc11c \uc2dc\ud000\uc2a4\ub97c \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1\ud558\uc5ec \ub9d0\ubb49\uce58 \ud06c\uae30\ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\uacbd\ud558\uba74\uc11c \ucd5c\uc18c 5\ud68c \uc774\uc0c1 \ub098\ud0c0\ub098\ub294 \uace0\uc720\ud55c 2-\uadf8\ub7a8\uc5d0\uc11c 6-\uadf8\ub7a8\uc758 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ud6c8\ub828 \ud1a0\ud070 \uc218(\uc218\uc2ed\uc5b5 \ub2e8\uc704)\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \uace0\uc720\ud55c n-\uadf8\ub7a8 \uc218(\ubc31\ub9cc \ub2e8\uc704)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \uc120\uc740 2-\uadf8\ub7a8, 3-\uadf8\ub7a8, 4-\uadf8\ub7a8, 5-\uadf8\ub7a8, 6-\uadf8\ub7a8\uc5d0 \ud574\ub2f9\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ud6c8\ub828 \ub370\uc774\ud130 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ub2e4\uc591\ud55c \uae38\uc774\uc758 n-\uadf8\ub7a8\uc758 \uc218\uac00 \uc5b4\ub5bb\uac8c \uc99d\uac00\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \ud45c\ud604\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uc774\ub294  SCONE \ubaa8\ub378\uc5d0\uc11c \uc790\uc8fc \ub098\ud0c0\ub098\ub294 n-\uadf8\ub7a8(f-gram)\uc744 \uc120\ud0dd\ud558\ub294 \uacfc\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 BPE-Style Discovery of f-grams"}, {"figure_path": "https://arxiv.org/html/2502.01637/x4.png", "caption": "Figure 4: Amortized per-token query latency (ms), averaged over 100,000 batches. The latency spike from batch size 1 to 2 when reading from system memory is due to batch operator overhead, which is less pronounced for solid-state drives.", "description": "\uadf8\ub9bc 4\ub294 10\ub9cc \uac1c\uc758 \ubc30\uce58\uc5d0 \ub300\ud574 \ud3c9\uade0\ud654\ub41c \ud1a0\ud070\ub2f9 \ucffc\ub9ac \uc9c0\uc5f0 \uc2dc\uac04(\ubc00\ub9ac\ucd08)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2dc\uc2a4\ud15c \uba54\ubaa8\ub9ac\uc5d0\uc11c \uc77d\uc744 \ub54c \ubc30\uce58 \ud06c\uae30\uac00 1\uc5d0\uc11c 2\ub85c \uc99d\uac00\ud558\uba74 \uc9c0\uc5f0 \uc2dc\uac04\uc774 \uae09\uc99d\ud558\ub294\ub370, \uc774\ub294 \ubc30\uce58 \uc5f0\uc0b0 \uc624\ubc84\ud5e4\ub4dc \ub54c\ubb38\uc785\ub2c8\ub2e4. \ubc18\uba74, SSD\ub97c \uc0ac\uc6a9\ud558\uba74 \uc774\ub7ec\ud55c \ud604\uc0c1\uc774 \ub35c \ub450\ub4dc\ub7ec\uc9d1\ub2c8\ub2e4. \uc774\ub294 \uc2dc\uc2a4\ud15c \uba54\ubaa8\ub9ac\uc5d0 \ube44\ud574 SSD\uc758 \ub354 \ube60\ub978 \ub370\uc774\ud130 \uc811\uadfc \uc18d\ub3c4 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \uba54\ubaa8\ub9ac\uc640 SSD\uc758 \ub450 \uac00\uc9c0 \uc800\uc7a5 \ubc29\ubc95\uc5d0 \ub300\ud55c \ud1a0\ud070\ub2f9 \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ubc30\uce58 \ud06c\uae30\uc5d0 \ub530\ub77c \ube44\uad50 \ubd84\uc11d\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 Space Usage and Query Latency"}, {"figure_path": "https://arxiv.org/html/2502.01637/x5.png", "caption": "Figure 5: Effect of the maximum f-gram length n\ud835\udc5bnitalic_n in Vf\u2062-\u2062gramsubscript\ud835\udc49f-gramV_{\\mathrm{f\\text{-}gram}}italic_V start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT, on perplexity and matched length. The left y\ud835\udc66yitalic_y-axis shows perplexity (averaged over three seeds), where the leftmost star indicates baseline performance. The right y\ud835\udc66yitalic_y-axis shows the average length of matched f-grams. The perplexity decreases as we increase the maximum length from 2 to 4, but then plateaus with some fluctuation. Similarly, the average matched length initially rises but stabilizes after size 4.", "description": "\uadf8\ub9bc 5\ub294 SCONE \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \ucd5c\ub300 f-gram \uae38\uc774(n)\uac00 \ubaa8\ub378 \uc131\ub2a5\uacfc \ub9e4\uce6d\ub41c f-gram\uc758 \ud3c9\uade0 \uae38\uc774\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd y\ucd95\uc740 \uc138 \ubc88\uc758 \uc2dc\ub4dc\uc5d0 \ub300\ud55c \ud3c9\uade0 perplexity\ub97c \ub098\ud0c0\ub0b4\uba70, \uac00\uc7a5 \uc67c\ucabd \ubcc4\ud45c\ub294 \uae30\uc900 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc624\ub978\ucabd y\ucd95\uc740 \ub9e4\uce6d\ub41c f-gram\uc758 \ud3c9\uade0 \uae38\uc774\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucd5c\ub300 \uae38\uc774\uac00 2\uc5d0\uc11c 4\ub85c \uc99d\uac00\ud568\uc5d0 \ub530\ub77c perplexity\ub294 \uac10\uc18c\ud558\uc9c0\ub9cc, \uadf8 \uc774\ud6c4\uc5d0\ub294 \uc57d\uac04\uc758 \ubcc0\ub3d9\uc744 \ubcf4\uc774\uba70 \uc548\uc815\ud654\ub429\ub2c8\ub2e4. \ub9c8\ucc2c\uac00\uc9c0\ub85c, \ub9e4\uce6d\ub41c f-gram\uc758 \ud3c9\uade0 \uae38\uc774\ub3c4 \ucc98\uc74c\uc5d0\ub294 \uc99d\uac00\ud558\uc9c0\ub9cc, \ud06c\uae30\uac00 4\uac00 \ub41c \ud6c4\uc5d0\ub294 \uc548\uc815\ud654\ub429\ub2c8\ub2e4. \uc774\ub294 \ub354 \uae34 f-gram\uc774 \ub35c \uc790\uc8fc \ub098\ud0c0\ub098\uace0, \ud6c8\ub828 \ub370\uc774\ud130\uc5d0\uc11c \ub354 \uae34 f-gram\uc774 \ud3c9\uac00 \ub370\uc774\ud130\uc640 \uc77c\uce58\ud560 \uac00\ub2a5\uc131\uc774 \uc801\uae30 \ub54c\ubb38\uc77c \uac83\uc785\ub2c8\ub2e4.", "section": "3. SCONE Architecture"}, {"figure_path": "https://arxiv.org/html/2502.01637/x6.png", "caption": "Figure 6: Evaluation perplexity as a function of |Vf\u2062-\u2062gram|subscript\ud835\udc49f-gram|V_{\\mathrm{f\\text{-}gram}}|| italic_V start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT |. Model sizes in the legend correspond to the main model sizes, including the token embedding layer. The dashed lines and leftmost stars indicate baseline performance. Perplexity decreases overall with increasing sizes of Vf\u2062-\u2062gramsubscript\ud835\udc49f-gramV_{\\mathrm{f\\text{-}gram}}italic_V start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT.", "description": "\uadf8\ub9bc 6\uc740 \uc8fc\uc694 \ubaa8\ub378 \ud06c\uae30(\ud1a0\ud070 \uc784\ubca0\ub529 \uacc4\uce35 \ud3ec\ud568)\uc5d0 \ub300\ud574 |Vf-gram|\uc758 \ud568\uc218\ub85c \ud3c9\uac00\ub41c perplexity\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc810\uc120\uacfc \ub9e8 \uc67c\ucabd \ubcc4\ud45c\ub294 \uae30\uc900 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. |Vf-gram|\uc758 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c perplexity\uac00 \uc804\ubc18\uc801\uc73c\ub85c \uac10\uc18c\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc8fc\uc694 \ubaa8\ub378\uc5d0 \ub300\ud574, \uc790\uc8fc \ubc1c\uc0dd\ud558\ub294 n-gram\uc758 \uc784\ubca0\ub529 \uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc5b8\uc5b4 \ubaa8\ub378 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1.2 VARYING THE NUMBER OF F-GRAMS"}, {"figure_path": "https://arxiv.org/html/2502.01637/x7.png", "caption": "Figure 7: Evaluation perplexity on Wikitext-103 as a function of the size of \ud835\udc9cf\u2062-\u2062gramsubscript\ud835\udc9cf-gram\\mathcal{A}_{\\mathrm{f\\text{-}gram}}caligraphic_A start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT. Model sizes in the legend correspond to the main model sizes, including the token embedding layer. Dashed lines and stars on the left represent baseline performance. The perplexity improves as the size of \ud835\udc9cf\u2062-\u2062gramsubscript\ud835\udc9cf-gram\\mathcal{A}_{\\mathrm{f\\text{-}gram}}caligraphic_A start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT grows.", "description": "\uadf8\ub9bc 7\uc740 \uc8fc\uc694 \ubaa8\ub378 \ud06c\uae30(\ud1a0\ud070 \uc784\ubca0\ub529 \uacc4\uce35 \ud3ec\ud568)\uc5d0 \ub300\ud55c Wikitext-103\uc758 \ud3c9\uac00 \ud37c\ud50c\ub809\uc11c\ud2f0\ub97c Af-gram \ubaa8\ub378 \ud06c\uae30\uc758 \ud568\uc218\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc758 \uc810\uc120\uacfc \ubcc4\ud45c\ub294 \uae30\uc900 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. Af-gram \ubaa8\ub378 \ud06c\uae30\uac00 \ucee4\uc9d0\uc5d0 \ub530\ub77c \ud37c\ud50c\ub809\uc11c\ud2f0\uac00 \uac1c\uc120\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 Af-gram \ubaa8\ub378 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc5b8\uc5b4 \ubaa8\ub378 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.1.3. Varying the size of the Af-gram model"}, {"figure_path": "https://arxiv.org/html/2502.01637/x8.png", "caption": "Figure 8: BPC of three model sizes on the validation set (lower is better). For all three model sizes, BPC initially improves as vocabulary size increases but eventually deteriorates.", "description": " \uadf8\ub9bc 8\uc740 \uc138 \uac00\uc9c0 \ud06c\uae30\uc758 \ubaa8\ub378\uc5d0 \ub300\ud55c \uac80\uc99d \uc138\ud2b8\uc758 BPC(Bits Per Character)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. BPC\ub294 \ub0ae\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \ubaa8\ub378 \ud06c\uae30 \ubaa8\ub450\uc5d0\uc11c \uc5b4\ud718 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c BPC\uac00 \ucc98\uc74c\uc5d0\ub294 \ud5a5\uc0c1\ub418\uc9c0\ub9cc \uacb0\uad6d\uc5d0\ub294 \uc800\ud558\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub354 \ud070 \uc5b4\ud718 \ud06c\uae30\uac00 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \uae0d\uc815\uc801\uc774\uc9c0\ub9cc \uc5b4\ub290 \uc815\ub3c4\uae4c\uc9c0\ub9cc \uadf8\ub807\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc5b4\ud718 \ud06c\uae30\uac00 \ub108\ubb34 \ucee4\uc9c0\uba74 \uc131\ub2a5\uc774 \uc800\ud558\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "C. \uc5b4\ud718 \ud06c\uae30 \uc870\uc815\uc758 \uacfc\uc81c"}, {"figure_path": "https://arxiv.org/html/2502.01637/x9.png", "caption": "Figure 9: Percentages of tokens (y-axis) that receive more than a given number of updates (x-axis), measured over 100 million training tokens. As the vocabulary size increases, tokens receive increasingly sparse updates.", "description": "\uc774 \uadf8\ub9bc\uc740 1\uc5b5 \uac1c\uc758 \ud1a0\ud070\uc5d0 \ub300\ud55c \ud559\uc2b5 \ud6c4\uc5d0 \ud2b9\uc815 \ud69f\uc218 \uc774\uc0c1\uc758 \uc5c5\ub370\uc774\ud2b8\ub97c \ubc1b\uc740 \ud1a0\ud070\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. x\ucd95\uc740 \uc5c5\ub370\uc774\ud2b8 \ud69f\uc218 \uc784\uacc4\uac12\uc774\uace0, y\ucd95\uc740 \ud574\ub2f9 \uc784\uacc4\uac12\ubcf4\ub2e4 \ub9ce\uc740 \uc5c5\ub370\uc774\ud2b8\ub97c \ubc1b\uc740 \ud1a0\ud070\uc758 \ube44\uc728\uc785\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc5b4\ud718 \ud06c\uae30\uc5d0 \ub300\ud574 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uc5b4\ud718 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ud1a0\ud070 \uc5c5\ub370\uc774\ud2b8\uac00 \uc810\uc810 \ub4dc\ubb3c\uc5b4\uc9d0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \ud070 \uc5b4\ud718\ub97c \uc0ac\uc6a9\ud558\uba74 \ud76c\uadc0 \ud1a0\ud070\uc758 \uc784\ubca0\ub529\uc740 \uac70\uc758 \uc5c5\ub370\uc774\ud2b8\ub418\uc9c0 \uc54a\uc544 \uc131\ub2a5 \uc800\ud558\ub85c \uc774\uc5b4\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "C. Challenges of Scaling Vocabulary Size in Embedding Layers"}, {"figure_path": "https://arxiv.org/html/2502.01637/x10.png", "caption": "Figure 10: Number of embedding layer parameters on the GPU and corresponding GPU memory usage. Computational costs increase linearly with vocabulary size.", "description": "\uadf8\ub9bc 10\uc740 \uc5b4\ud718 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uacfc GPU\uc5d0 \uc800\uc7a5\ub41c \uc784\ubca0\ub529 \uacc4\uce35 \ub9e4\uac1c\ubcc0\uc218\uc758 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uacfc \ub9e4\uac1c\ubcc0\uc218 \uc218\ub294 \uc5b4\ud718 \ud06c\uae30\uc5d0 \ub530\ub77c \uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud569\ub2c8\ub2e4. \uc774\ub294 \ud070 \uc5b4\ud718\ub97c \uac16\ub294 \uc5b8\uc5b4 \ubaa8\ub378\uc5d0\uc11c \uacc4\uc0b0 \ube44\uc6a9\uc774 \uc5b4\ub5bb\uac8c \uc99d\uac00\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \ud45c\ud604\uc785\ub2c8\ub2e4.  \uc784\ubca0\ub529 \uacc4\uce35\uc758 \ud06c\uae30\uac00 \ucee4\uc9d0\uc5d0 \ub530\ub77c \ubaa8\ub378\uc758 \uba54\ubaa8\ub9ac \uc694\uad6c\uc0ac\ud56d\uc774 \uc5b4\ub5bb\uac8c \uc99d\uac00\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 \uadf8\uc5d0 \ub530\ub978 \uc131\ub2a5 \uc800\ud558 \uac00\ub2a5\uc131\uc744 \uc774\ud574\ud558\ub294\ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3.3 Space Usage and Query Latency"}, {"figure_path": "https://arxiv.org/html/2502.01637/x11.png", "caption": "Figure 11: Effect of the maximum f-gram length in Vf\u2062-\u2062gramsubscript\ud835\udc49f-gramV_{\\mathrm{f\\text{-}gram}}italic_V start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT, evaluated on the WebText validation split.", "description": "\uadf8\ub9bc 11\uc740 WebText \uac80\uc99d \ubd84\ud560\uc5d0 \ub300\ud574 \ud3c9\uac00\ub41c V<sub>f-gram</sub>\uc5d0\uc11c \ucd5c\ub300 f-gram \uae38\uc774\uac00 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ucd5c\ub300 f-gram \uae38\uc774(n)\uc774\uace0, y\ucd95\uc740 \ub450 \uac00\uc9c0 \uc9c0\ud45c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc67c\ucabd y\ucd95\uc740 \ud3c9\uade0 perplexity\ub97c, \uc624\ub978\ucabd y\ucd95\uc740 \uc77c\uce58\ud558\ub294 f-gram\uc758 \ud3c9\uade0 \uae38\uc774\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uadf8\ub798\ud504\ub294 \ucd5c\ub300 f-gram \uae38\uc774\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c perplexity\uac00 \uac10\uc18c\ud558\ub2e4\uac00 \uc5b4\ub290 \uc815\ub3c4\uc5d0\uc11c \uc548\uc815\ud654\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc77c\uce58\ud558\ub294 f-gram\uc758 \ud3c9\uade0 \uae38\uc774\ub294 \ucd5c\ub300 f-gram \uae38\uc774\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc99d\uac00\ud558\ub2e4\uac00 \ub9c8\ucc2c\uac00\uc9c0\ub85c \uc5b4\ub290 \uc2dc\uc810\uc5d0\uc11c \uc548\uc815\ud654\ub429\ub2c8\ub2e4. \uc774\ub294 \uc9e7\uc740 f-gram\uc774 \ub354 \ube48\ubc88\ud558\uac8c \ub098\ud0c0\ub098\uace0, \ub354 \uae34 f-gram\uc740 \ud6c8\ub828 \ub370\uc774\ud130\uc5d0 \ube44\ud574 \uac80\uc99d \ub370\uc774\ud130\uc5d0\uc11c \uc77c\uce58\ud560 \uac00\ub2a5\uc131\uc774 \uc801\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ucd5c\uc801\uc758 \ucd5c\ub300 f-gram \uae38\uc774\uac00 \uc874\uc7ac\ud558\uba70, \ub108\ubb34 \uc9e7\uac70\ub098 \ub108\ubb34 \uae38\uc5b4\ub3c4 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc81c\ud55c\uc774 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.1.1. VARYING THE MAXIMUM F-GRAM LENGTH"}, {"figure_path": "https://arxiv.org/html/2502.01637/x12.png", "caption": "Figure 12: Evaluation perplexity on WebText as a function of the size of \ud835\udc9cf\u2062-\u2062gramsubscript\ud835\udc9cf-gram\\mathcal{A}_{\\mathrm{f\\text{-}gram}}caligraphic_A start_POSTSUBSCRIPT roman_f - roman_gram end_POSTSUBSCRIPT.", "description": "\uadf8\ub9bc 12\ub294 WebText \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud6c8\ub828\ub41c \uc8fc\uc694 \ubaa8\ub378\uc758 \ud06c\uae30\uc5d0 \ub530\ub978(128M, 419M, 589M, 204M, 759M, 1099M)  f-gram \ubaa8\ub378 (\ud835\udc9cf-gramsubscript\ud835\udc9cf-gram\n\n\nmathcal{A}_{\n\n\nmathrm{f\n\n\n-\n\n\ngram}}\n\n\n)\uc758 \ud06c\uae30 \ubcc0\ud654\uc5d0 \ub530\ub978 \ud3c9\uac00 perplexity\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  f-gram \ubaa8\ub378\uc758 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c perplexity\uac00 \uac10\uc18c\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub300\ud574 \uc5ec\ub7ec \ud06c\uae30\uc758 f-gram \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\uc5ec \ube44\uad50 \ubd84\uc11d\ud558\uc600\uc2b5\ub2c8\ub2e4.", "section": "4.1.3. VARYING THE SIZE OF THE Af-gram MODEL"}, {"figure_path": "https://arxiv.org/html/2502.01637/x13.png", "caption": "Figure 13: Average perplexity on the OLMo evaluation mixture throughout training. Models with Scone enabled converge later, indicating stronger capacity, and achieve better perplexity.", "description": "\uadf8\ub9bc 13\uc740 OLMo \ud3c9\uac00 \ud63c\ud569\ubb3c\uc5d0 \ub300\ud55c \ud3c9\uade0 perplexity\ub97c \ud6c8\ub828 \uc804\uccb4\uc5d0 \uac78\uccd0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SCONE\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud6c8\ub828\ub41c \ubaa8\ub378\uc740 \ub354 \ub098\uc740 perplexity\uc5d0 \ub3c4\ub2ec\ud560 \ubfd0\ub9cc \uc544\ub2c8\ub77c, \uc218\ub834\uc5d0 \ub354 \ub9ce\uc740 \ud6c8\ub828 \ud1a0\ud070\uc744 \ud544\uc694\ub85c \ud569\ub2c8\ub2e4. \uc774\ub294 SCONE\uc774 \ubaa8\ub378\uc758 \uc6a9\ub7c9\uc744 \uc99d\uac00\uc2dc\ucf1c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.2 OLMo \ud1a0\ud070\ud654\ub41c \ud6c8\ub828 \ub9d0\ubb49\uce58"}]