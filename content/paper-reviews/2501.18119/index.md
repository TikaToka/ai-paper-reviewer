---
title: "Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models"
summary: "ë³¸ ì—°êµ¬ëŠ” ì§€ì‹ ê·¸ë˜í”„(KG)ì™€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì›í™œí•˜ê²Œ í†µí•©í•˜ëŠ” ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì–‘ìí™”ëœ í‘œí˜„ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ National University of Singapore",]
showSummary: true
date: 2025-01-30
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2501.18119 {{< /keyword >}}
{{< keyword icon="writer" >}} Qika Lin et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-03 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2501.18119" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2501.18119" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/self-supervised-quantized-representation-for" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ë³¸ ë…¼ë¬¸ì€ ì§€ì‹ ê·¸ë˜í”„(KG)ì™€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í†µí•©ì´ ì–´ë ¤ìš´ ì ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ KGì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì§€ ëª»í•˜ê³ , ë§ì€ í† í°ì„ í•„ìš”ë¡œ í•˜ì—¬ LLMì˜ ì²˜ë¦¬ ëŠ¥ë ¥ì— ì œì•½ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì–‘ìí™”ëœ í‘œí˜„(SSQR)** ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.



SSQRì€ KGì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ì •ë³´ë¥¼ ì´ì‚°ì ì¸ ì½”ë“œ(í† í°)ë¡œ ë³€í™˜í•˜ì—¬, LLMì´ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. **ì´ë¥¼ í†µí•´ KGì˜ ì •ë³´ë¥¼ LLMì— íš¨ìœ¨ì ìœ¼ë¡œ í†µí•©**í•˜ê³ , KG ë§í¬ ì˜ˆì¸¡ ë° íŠ¸ë¦¬í”Œ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” **LLMê³¼ KG í†µí•© ë¶„ì•¼ì— ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„**ì„ ì œì‹œí•˜ê³ , **ë‹¤ì–‘í•œ KG ì‘ìš© ë¶„ì•¼ì— ê´‘ë²”ìœ„í•œ ì˜í–¥**ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì–‘ìí™”ëœ í‘œí˜„(SSQR) ë°©ë²•ì„ í†µí•´ KGì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶• {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} í•™ìŠµëœ ì½”ë“œë¥¼ LLMì— ì§ì ‘ ì…ë ¥í•˜ì—¬ KGì™€ LLMì„ ì›í™œí•˜ê²Œ í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ ì œì‹œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} KG ë§í¬ ì˜ˆì¸¡ ë° íŠ¸ë¦¬í”Œ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì…ì¦ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ê³¼ **ì§€ì‹ ê·¸ë˜í”„(KG)**ì˜ ì›í™œí•œ í†µí•©ì´ë¼ëŠ” ì¤‘ìš”í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•˜ì—¬, **ì—°êµ¬ìë“¤ì—ê²Œ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œ**í•˜ê³  **ë‹¤ì–‘í•œ KG ì‘ìš© ë¶„ì•¼ì— ê´‘ë²”ìœ„í•œ ì˜í–¥**ì„ ë¯¸ì¹  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ì´ë©°, ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì€ **KGì™€ LLM í†µí•© ë¶„ì•¼ì˜ ì—°êµ¬ ë°œì „ì— í¬ê²Œ ê¸°ì—¬**í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/intro_f.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ì§€ì‹ ê·¸ë˜í”„(KG)ë¥¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ í†µí•©í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (a)ëŠ” ê¸°ì¡´ì˜ ì§ì ‘ì ì¸ ë°©ë²•ìœ¼ë¡œ, ìƒ˜í”Œë§ëœ ê·¸ë˜í”„ êµ¬ì¡°ì™€ ì˜ë¯¸ì  í…ìŠ¤íŠ¸ë¥¼ LLMì— ì§ì ‘ ì…ë ¥í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ KGì˜ ì „ì²´ êµ¬ì¡° ì •ë³´ë¥¼ í™œìš©í•˜ì§€ ëª»í•˜ê³ , ë§ì€ í† í°ì„ í•„ìš”ë¡œ í•˜ì—¬ ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (b)ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, KGì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ì§€ì‹ì„ ì´ì‚° ì½”ë“œ(ì¦‰, í† í°)ë¡œ ì••ì¶•í•˜ì—¬ LLMê³¼ì˜ ì›í™œí•œ í†µí•©ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì–¸ì–´ ë¬¸ì¥ì˜ í˜•ì‹ê³¼ ì¼ì¹˜í•˜ëŠ” ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ KG ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í‘œí˜„í•˜ê³  LLMì— ì…ë ¥í•©ë‹ˆë‹¤.  ì´ëŠ” KGì™€ LLMì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ëŠ” íš¨ê³¼ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Illustration of different strategies to integrate KGs with LLMs. (a) The direct method utilizes (sampled) graph structures and semantic text as inputs. (b) Our method for seamlessly integrating KGs with LLMs using learned quantized and discrete codes.
> </details>





{{< table-caption >}}
| Instruction | This is a knowledge graph completion task, which needs to predict the tail entity for an incomplete query triplet. | 
| Input | The query triplet is ( _h_, _r_, ?). The quantized representation of entity _h_ is: [Code(_h_)] The answer candidates and corresponding quantized representations are as follows: _entity 1_, [Code(_entity 1_)] â€¦ _entity 20_, [Code(_entity 20_)] Please generate quantized representations of the top-3 potential answers, ranked from highest to lowest: | 
| Output | 1. [Code(_candidate 1_)] 2. [Code(_candidate 2_)] 3. [Code(_candidate 3_)] |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ì§€ì‹ ê·¸ë˜í”„ì˜ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì„ ìœ„í•œ ì§€ì¹¨ í˜•ì‹ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í•™ìŠµëœ ì½”ë“œëŠ” ì—”í‹°í‹° íŠ¹ì§•ìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ ë­í‚¹ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œ, ë¶ˆì™„ì „í•œ ì¿¼ë¦¬ íŠ¸ë¦¬í”Œ (h, r, ?)ì´ ì£¼ì–´ì§€ë©´, í—¤ë“œ ì—”í‹°í‹° hì˜ ì •ëŸ‰í™”ëœ í‘œí˜„ì´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ê³ , ì ì¬ì ì¸ ë‹µë³€ í›„ë³´ì™€ ê·¸ì— í•´ë‹¹í•˜ëŠ” ì •ëŸ‰í™”ëœ í‘œí˜„ë“¤ì´ ì œê³µë©ë‹ˆë‹¤.  ëª¨ë¸ì€ ìƒìœ„ 3ê°œì˜ ì ì¬ì ì¸ ë‹µë³€ í›„ë³´ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ë“¤ì„ ìƒì„±í•˜ì—¬ ìˆœìœ„ë¥¼ ë§¤ê²¨ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Instruction format for link prediction, where learned codes serve as entity features to help ranking.
> </details>





### In-depth insights


#### Quantized KG Encoding
ì–‘ìí™”ëœ KG ì¸ì½”ë”©ì€ ì§€ì‹ ê·¸ë˜í”„(KG)ì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ì •ë³´ë¥¼ ì´ì‚° ì½”ë“œ(í† í°)ë¡œ ì••ì¶•í•˜ì—¬ **LLMê³¼ì˜ ì›í™œí•œ í†µí•©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ê¸°ìˆ **ì…ë‹ˆë‹¤.  **ìê¸°ì§€ë„í•™ìŠµ ë°©ì‹**ì„ í†µí•´ KGì˜ êµ¬ì¡°ì™€ ì˜ë¯¸ë¥¼ ëª¨ë‘ í¬ì°©í•˜ëŠ” ì–‘ìí™”ëœ í‘œí˜„ì„ í•™ìŠµí•˜ë©°, ê·¸ë˜í”„ í•©ì„±ê³± ì‹ ê²½ë§(GCN)ê³¼ ë²¡í„° ì–‘ìí™”(VQ)ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  **í•™ìŠµëœ ì½”ë“œëŠ” LLMì˜ í† í° í˜•ì‹ê³¼ ì¼ì¹˜**í•˜ë¯€ë¡œ, ë³„ë„ì˜ í”„ë ˆì„ì›Œí¬ ìˆ˜ì • ì—†ì´ LLMì— ì§ì ‘ ì…ë ¥ ê°€ëŠ¥í•˜ë©°, KG ì‘ì—…ì„ ìœ„í•œ íŠ¹ì • ëª…ë ¹ì–´ì™€ ê²°í•©í•˜ì—¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ì˜ ì—°ì† KG ì„ë² ë”© ë°©ì‹ê³¼ ë¹„êµí•˜ì—¬ **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë° LLMê³¼ì˜ í†µí•©ì„±ì„ í¬ê²Œ í–¥ìƒ**ì‹œí‚µë‹ˆë‹¤.  **ìê¸°ì§€ë„í•™ìŠµì„ í†µí•œ í•™ìŠµ**ì€ ì§€ë„í•™ìŠµ ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ë‹¤ì–‘í•œ KG ì‘ì—…ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.

#### LLM Integration
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **ì§€ì‹ ê·¸ë˜í”„(KG)ì™€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í†µí•©**ì´ë¼ëŠ” ì£¼ì œì— ëŒ€í•´ ì‹¬ë„ ìˆê²Œ ë…¼ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.  ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì€ KGì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ LLMì— íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì—ˆì§€ë§Œ, ë³¸ ì—°êµ¬ëŠ” **ì–‘ìí™”ëœ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ KGì™€ LLMì„ ì›í™œí•˜ê²Œ í†µí•©**í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ KGì˜ êµ¬ì¡°ì , ì˜ë¯¸ì  ì •ë³´ë¥¼ LLMì— íš¨ìœ¨ì ìœ¼ë¡œ ì „ë‹¬í•˜ê³ , ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ìê¸° ì§€ë„ í•™ìŠµ ë°©ì‹ì˜ ì–‘ìí™”ëœ í‘œí˜„ í•™ìŠµ(SSQR)**ì€ KGì˜ êµ¬ì¡°ì™€ ì˜ë¯¸ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì´ì‚°ì ì¸ ì½”ë“œ(í† í°)ë¡œ ë³€í™˜í•¨ìœ¼ë¡œì¨ LLMì´ ìì—°ì–´ ì²˜ë¦¬ì²˜ëŸ¼ KG ì •ë³´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.  ë˜í•œ, ë³¸ ì—°êµ¬ëŠ” **LLMì— KG ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„**ì„ ì œì‹œí•˜ì—¬ ë‹¤ì–‘í•œ KG ì‘ìš© ë¶„ì•¼ì— ì ìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  **ì‹¤í—˜ ê²°ê³¼ëŠ” ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ì˜ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì–‘ìí™” ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥**ì„ ë³´ì„ì„ ë³´ì—¬ì£¼ë©°, ì´ë¥¼ í†µí•´ KGì™€ LLMì˜ í†µí•©ì— ëŒ€í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

#### SSQR Experiments
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ SSQR(Self-Supervised Quantized Representation) ë°©ë²•ë¡ ì˜ ì‹¤í—˜ ê²°ê³¼ëŠ” **ì •ëŸ‰ì  ì„±ëŠ¥ í‰ê°€ì™€ ì •ì„±ì  ë¶„ì„** ë‘ ê°€ì§€ ì¸¡ë©´ì—ì„œ ì œì‹œë  ê²ƒì…ë‹ˆë‹¤. ì •ëŸ‰ì  í‰ê°€ëŠ” ì£¼ë¡œ ë§í¬ ì˜ˆì¸¡ ë° íŠ¸ë¦¬í”Œ ë¶„ë¥˜ ì‘ì—…ì—ì„œì˜ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-scoreì™€ ê°™ì€ ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ë‹¤ì–‘í•œ ê¸°ì¡´ ë°©ë²•ë“¤ê³¼ ë¹„êµí•˜ì—¬ SSQRì˜ ìš°ìˆ˜ì„±ì„ ë³´ì—¬ì£¼ëŠ” ê²°ê³¼ê°€ ì œì‹œë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. íŠ¹íˆ, **ì ì€ ìˆ˜ì˜ í† í°ë§Œì„ ì‚¬ìš©í•˜ë©´ì„œë„ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±**í•œ ì ì„ ê°•ì¡°í•˜ì—¬, ê¸°ì¡´ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ë°©ë²•ë¡ ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” íš¨ìœ¨ì„±ì„ ë¶€ê°í•  ê²ƒì…ë‹ˆë‹¤. ì •ì„±ì  ë¶„ì„ì€ **í•™ìŠµëœ ì½”ë“œì˜ ì°¨ë³„ì„± ë° êµ¬ì¡°ì  ì •ë³´ í‘œí˜„ ëŠ¥ë ¥**ì„ í‰ê°€í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, t-SNEì™€ ê°™ì€ ì°¨ì› ì¶•ì†Œ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ì½”ë“œì˜ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ê³ , ê° ì½”ë“œê°€ ì˜ë¯¸ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ì˜ êµ¬ë¶„ë˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, ê·¸ë˜í”„ ì¬êµ¬ì¶• ë“±ì˜ ì‘ì—…ì„ í†µí•´ í•™ìŠµëœ ì½”ë“œê°€ ì›ë˜ì˜ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë³µì›í•˜ëŠ”ì§€ ë¶„ì„í•˜ì—¬ SSQRì˜ **êµ¬ì¡°ì  ì •ë³´ í‘œí˜„ ëŠ¥ë ¥**ì„ ê²€ì¦í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì„¤ì •**ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ SSQRì˜ ì•ˆì •ì„±ê³¼ ê²¬ê³ ì„±ì„ í™•ì¸í•˜ê³ , ì¶”ê°€ì ìœ¼ë¡œ ablation studyë¥¼ í†µí•´ ê° ëª¨ë“ˆì˜ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë°©ë²•ë¡ ì˜ ì„¤ê³„ì˜ íƒ€ë‹¹ì„±ì„ ì…ì¦í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ, SSQRì´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ê³¼ì˜ í†µí•©ì— ìˆì–´ì„œ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì¸ì§€ì— ëŒ€í•œ ì¢…í•©ì ì¸ ê²°ë¡ ì„ ë„ì¶œí•  ê²ƒì…ë‹ˆë‹¤.

#### Future Directions
ë³¸ ë…¼ë¬¸ì€ ì§€ì‹ ê·¸ë˜í”„ì™€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ ì›í™œí•˜ê²Œ í†µí•©í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. **ë¯¸ë˜ ë°©í–¥**ìœ¼ë¡œëŠ”, ìš°ì„  **ë‹¤ì–‘í•œ ì§€ì‹ ê·¸ë˜í”„ ì‘ì—…ì— ì ìš© ê°€ëŠ¥í•œ í†µí•©ì ì¸ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ êµ¬ì¶•**í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” ì§€ì‹ ê·¸ë˜í”„ì˜ ë‹¤ì–‘í•œ íŠ¹ì§•ê³¼ êµ¬ì¡°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°˜ì˜í•˜ëŠ” ìƒˆë¡œìš´ ì–‘ìí™” ê¸°ë²•ì„ ê°œë°œí•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•œ ì§€ì¹¨ ë°ì´í„°ë¥¼ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ, **ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•œ íš¨ìœ¨ì ì¸ ìµœì í™” ê¸°ë²•**ì„ ì—°êµ¬í•´ì•¼ í•©ë‹ˆë‹¤. **ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒ**ì‹œí‚¤ê¸° ìœ„í•œ ì—°êµ¬ë„ í•„ìš”í•˜ë©°, ì´ë¥¼ ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ì§€ì‹ ê·¸ë˜í”„ì™€ ì‘ì—…ì— ëŒ€í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ í™•ë³´í•˜ê³ , ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **ê°œë°œëœ ë°©ë²•ì˜ ìœ¤ë¦¬ì  ë° ì‚¬íšŒì  ì˜í–¥**ì— ëŒ€í•œ ê³ ì°°ë„ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•œ ì—°êµ¬ëŠ” ì§€ì‹ ê·¸ë˜í”„ì™€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ í†µí•©ì„ ë”ìš± ë°œì „ì‹œí‚¤ê³ , ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œì˜ ì‘ìš©ì„ í™•ëŒ€í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒì…ë‹ˆë‹¤.

#### Method Limitations
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ë°©ë²•ì˜ í•œê³„ì ì„ ê¹Šì´ ìˆê²Œ ë…¼ì˜í•´ ë³´ê² ìŠµë‹ˆë‹¤. **ê°€ì¥ í° ì œì•½ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë§‰ëŒ€í•œ ê³„ì‚° ë¹„ìš©**ì…ë‹ˆë‹¤. LLMì€ íŠ¹ì • ì§€ì‹ ê·¸ë˜í”„(KG)ì™€ ì‘ì—…ì— ë¯¸ì„¸ ì¡°ì •ë˜ê¸° ë•Œë¬¸ì— ë‹¤ì–‘í•œ KG ì‘ì—…ì— ì ìš©í•˜ëŠ” ë° ì œí•œì´ ìˆìŠµë‹ˆë‹¤.  **ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë™ì¼í•œ ì´ì‚° ê³µê°„ ë‚´ì—ì„œ ì •ëŸ‰í™”ë¥¼ êµ¬í˜„í•˜ëŠ” í†µí•© LLMì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ í•„ìš”**í•©ë‹ˆë‹¤.  ë˜í•œ, **ë³¸ ì—°êµ¬ëŠ” ìê°€ ê°ë… ë°©ì‹ì˜ ì •ëŸ‰í™” í•™ìŠµì— ì´ˆì ì„ ë§ì¶”ì—ˆì§€ë§Œ, ë‹¤ë¥¸ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë²•ê³¼ ë¹„êµ ë¶„ì„ì´ ë¶€ì¡±**í•©ë‹ˆë‹¤.  í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ SSQRì˜ ê°•ì ê³¼ ì•½ì ì„ ë” ëª…í™•íˆ ê·œëª…í•´ì•¼ í•©ë‹ˆë‹¤.  **ë°ì´í„° ì…‹ì˜ íŠ¹ì„±ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„ë„ ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”**í•˜ë©°, íŠ¹íˆ KG êµ¬ì¡°ì™€ ì˜ë¯¸ ì •ë³´ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ ë‹¤ì–‘í•œ KG ë°ì´í„° ì…‹ì—ì„œ ë¶„ì„í•˜ëŠ” ì—°êµ¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, ì œì•ˆëœ ë°©ë²•ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³ , ë‹¤ì–‘í•œ KG ì‘ìš© ë¶„ì•¼ì— ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/fb_sta.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” FB15k-237 ë°ì´í„°ì…‹ì—ì„œ ê° ì—”í‹°í‹°ì— ëŒ€í•´ 2-hop ì´ì›ƒì„ ìƒ˜í”Œë§í–ˆì„ ë•Œ, LLaMA2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ í† í° ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ í†µê³„ ìë£Œì…ë‹ˆë‹¤.  20%ì™€ 30%ì˜ ì´ì›ƒì„ ê°ê° ìƒ˜í”Œë§í•œ ê²½ìš°ì— ëŒ€í•œ ì¤‘ê°„ê°’ê³¼ í‰ê· ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” ì§€ì‹ ê·¸ë˜í”„(KG) ì •ë³´ë¥¼ LLMì— ì§ì ‘ ì…ë ¥í•˜ëŠ” ë°©ì‹ì˜ ë‹¨ì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œë¡œ,  hop ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ëŠ” í† í° ìˆ˜ë¡œ ì¸í•´ ìì› ì†Œëª¨ê°€ ë§¤ìš° ì»¤ì§ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: The statistics of 2-hop sampled neighbors and needed tokens (by LLaMA2) for entities in FB15k-237.
> </details>



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/arc_f.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. (a)ëŠ” KGì— ëŒ€í•œ ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì–‘ìí™”ëœ í‘œí˜„ í•™ìŠµ(SSQR) ê³¼ì •ì„, (b)ëŠ” í•™ìŠµëœ ì–‘ìí™”ëœ í‘œí˜„ì„ íŠ¹ì§•ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ KG ì‘ì—…ì„ ìœ„í•œ ì§€ì‹œ ì¡°ì • ê³¼ì •ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œ ì‚¬ìš©ëœ ì•„ì´ì½˜ (â– )ê³¼ (â– )ì€ ê°ê° ëª¨ë“ˆì˜ í•™ìŠµ ê³¼ì • ì¤‘ ê³ ì •ë˜ì—ˆëŠ”ì§€ ë˜ëŠ” ì—…ë°ì´íŠ¸ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3:  The overall architecture of our study. (a) is for SSQR learning. (b) is for instruction tuning for KG tasks, where the learned quantized representations serve as features. Icons â€„and â€„represent the status of the module during training, indicating if it is frozen or being updated, respectively.
> </details>



![](https://arxiv.org/html/2501.18119/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 4(a)ëŠ” WN18RR ë°ì´í„°ì…‹ì˜ 8ê°œ ì—”í‹°í‹°ì— ëŒ€í•œ ì›ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì—”í‹°í‹°ì— ëŒ€í•´ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ì‚¬ìš©í•˜ì—¬ ì–»ì€ ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì›ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©ì´ ì—”í‹°í‹° ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë°˜ì˜í•˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë‹¤ë¥¸ ê·¸ë¦¼ë“¤ê³¼ ë¹„êµí•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©ì˜ íŠ¹ì§•ê³¼ SSQR ê¸°ë²•ì˜ íš¨ê³¼ë¥¼ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Original text embedding.
> </details>



![](https://arxiv.org/html/2501.18119/x2.png)

> ğŸ”¼ ê·¸ë¦¼ (b)ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì–‘ìí™”ëœ í‘œí˜„ í•™ìŠµ ë°©ë²•ì¸ SSQR(Self-supervised Quantized Representation)ì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. SSQRì€ ì§€ì‹ ê·¸ë˜í”„(KG)ì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ë¡ ì  ì •ë³´ë¥¼ ì´ì‚° ì½”ë“œ(í† í°)ë¡œ ì••ì¶•í•˜ì—¬, LLMs(Large Language Models)ê³¼ì˜ ì›í™œí•œ í†µí•©ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œ, ê·¸ë˜í”„ í•©ì„±ê³± ì‹ ê²½ë§(GCN)ì„ ì´ìš©í•˜ì—¬ KGì˜ êµ¬ì¡° ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ê³ , ë²¡í„° ì–‘ìí™”(VQ)ë¥¼ í†µí•´ ì´ì‚° ì½”ë“œë¶ì„ ìƒì„±í•©ë‹ˆë‹¤.  ì´ë ‡ê²Œ ìƒì„±ëœ ì½”ë“œëŠ” LLMsì˜ ì…ë ¥ í˜•ì‹ê³¼ í˜¸í™˜ë˜ë„ë¡ ì„¤ê³„ë˜ì–´, LLMsì˜ ì–´íœ˜ ì‚¬ì „ í™•ì¥ë§Œìœ¼ë¡œ KG ì •ë³´ë¥¼ LLMsì— í†µí•©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ SSQR í•™ìŠµ ê³¼ì •ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë“¤ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì–´, KG ì •ë³´ì˜ ì–‘ìí™”ëœ í‘œí˜„ í•™ìŠµ ë° LLMsì™€ì˜ í†µí•© ê³¼ì •ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) SSQR.
> </details>



![](https://arxiv.org/html/2501.18119/x3.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì§€ì‹ ê·¸ë˜í”„ì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê·¸ë˜í”„ í•©ì„±ê³± ì‹ ê²½ë§(GCN)ì„ ì œê±°í–ˆì„ ë•Œì˜ SSQR(Self-supervised Quantized Representation)ì˜ ì •ëŸ‰í™”ëœ í‘œí˜„ì— ëŒ€í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  GCNì„ ì œì™¸í•˜ë©´, ì •ëŸ‰í™”ëœ ë²¡í„°ë“¤ì´ ì„œë¡œ ë§¤ìš° ìœ ì‚¬í•´ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” GCNì´ ì§€ì‹ ê·¸ë˜í”„ì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (c) SSQR w/o GCN.
> </details>



![](https://arxiv.org/html/2501.18119/x4.png)

> ğŸ”¼ ê·¸ë¦¼ì€ WN18RR ë°ì´í„°ì…‹ì˜ 8ê°œ ê°œì²´ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  (d)ëŠ” ì˜ë¯¸ ì •ë³´ ì—†ì´ SSQRì„ ì ìš©í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¦‰, ì§€ì‹ ê·¸ë˜í”„ì˜ êµ¬ì¡°ì  ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°œì²´ë¥¼ ì •ëŸ‰í™”ëœ ì½”ë“œë¡œ í‘œí˜„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.  ì˜ë¯¸ ì •ë³´ë¥¼ í™œìš©í•˜ì§€ ì•ŠìŒìœ¼ë¡œì¨, ê°œì²´ í‘œí˜„ì˜ ë‹¤ì–‘ì„±ì´ ê°ì†Œí•˜ê³  êµ¬ì¡°ì  ìœ ì‚¬ì„±ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ì˜ë¯¸ ì •ë³´ê°€ ê°œì²´ë¥¼ ë³´ë‹¤ ì˜ êµ¬ë¶„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (d) SSQR w/o semantics.
> </details>



![](https://arxiv.org/html/2501.18119/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” WN18RR ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œë§ëœ 8ê°œ ê°œì²´ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê·¸ë˜í”„ëŠ” ë‹¤ë¥¸ ì •ëŸ‰í™” ë°©ë²•(ì›ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©, SSQR, GCN ì—†ì´ SSQR, ì˜ë¯¸ ì •ë³´ ì—†ì´ SSQR)ìœ¼ë¡œ ìƒì„±ëœ 8ê°œ ê°œì²´ì˜ ì •ëŸ‰í™”ëœ í‘œí˜„ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° í–‰ë ¬ì˜ ê°’ì€ ë‘ ê°œì²´ì˜ ì •ëŸ‰í™”ëœ í‘œí˜„ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê°’ì´ ë†’ì„ìˆ˜ë¡ ë‘ ê°œì²´ì˜ ìœ ì‚¬ë„ê°€ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì„ í†µí•´ ê° ì •ëŸ‰í™” ë°©ë²•ì´ ê°œì²´ ê°„ì˜ ìœ ì‚¬ì„±ì„ ì–¼ë§ˆë‚˜ ì˜ í¬ì°©í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ê° ë°©ë²•ì˜ ê°•ì ê³¼ ì•½ì ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: The cosine similarity of quantized representations on the WN18RR dataset (sampled 8 entities).
> </details>



![](https://arxiv.org/html/2501.18119/x6.png)

> ğŸ”¼ ê·¸ë¦¼ 5(a)ëŠ” WN18RR ë°ì´í„°ì…‹ì—ì„œ ì—”í‹°í‹°ë‹¹ ì½”ë“œë¶ ê¸¸ì´(M)ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´(N)ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ Mê³¼ N ê°’ì— ëŒ€í•œ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì˜ MRR(Mean Reciprocal Rank), Hits@1, Hits@3, Hits@10 ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” 3ì°¨ì› ë§‰ëŒ€ ê·¸ë˜í”„ì…ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ Mê³¼ Nì˜ í¬ê¸°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°ì ìœ¼ë¡œ íŒŒì•…í•˜ê³  ìµœì ì˜ Mê³¼ N ê°’ì„ ê²°ì •í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Mê³¼ N ê°’ì´ í´ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ë§Œ, íŠ¹ì • ì§€ì ì„ ë„˜ì–´ì„œë©´ ì„±ëŠ¥ í–¥ìƒí­ì´ ê°ì†Œí•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) WN18RR dataset.
> </details>



![](https://arxiv.org/html/2501.18119/x7.png)

> ğŸ”¼ ê·¸ë¦¼ 5(b)ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ìê¸° ì§€ë„ í•™ìŠµ ë°©ì‹ì˜ ì–‘ìí™”ëœ í‘œí˜„ ë°©ë²•(SSQR)ì´ FB15k-237 ë°ì´í„°ì…‹ì— ì ìš©ë˜ì—ˆì„ ë•Œì˜ ì½”ë“œë¶ ê¸¸ì´(M)ì™€ ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì‹œí€€ìŠ¤ ê¸¸ì´(N)ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  Mê³¼ Nì˜ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ” ê·¸ë˜í”„ì…ë‹ˆë‹¤.  WN18RR ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ FB15k-237 ë°ì´í„°ì…‹ì—ì„œ Nì˜ ì˜í–¥ì´ ë” í¬ë‹¤ëŠ” ì ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) FB15k-237 dataset.
> </details>



![](https://arxiv.org/html/2501.18119/x8.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì½”ë“œë¶ ê¸¸ì´(M)ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´(N)ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‘ ê°€ì§€ í•˜ì´í¼íŒŒë¼ë¯¸í„° Mê³¼ Nì´ WN18RRê³¼ FB15k-237 ë°ì´í„°ì…‹ì—ì„œì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ MRR(í‰ê·  ìƒí˜¸ ìˆœìœ„), Hits@1, Hits@3, Hits@10 ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ ìµœì ì˜ ì½”ë“œë¶ í¬ê¸°(M)ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´(N)ë¥¼ ì„ íƒí•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: The effects of codebook length (Mğ‘€Mitalic_M) and sequence length (Nğ‘Nitalic_N) for each entity.
> </details>



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/llm_bar2.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ì½”ë“œë¶ ê¸¸ì´(M)ê³¼ ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì‹œí€€ìŠ¤ ê¸¸ì´(N)ì˜ ì˜í–¥ì„ WN18RR ë° FB15k-237 ë°ì´í„°ì…‹ì—ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Mê³¼ Nì´ í´ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤. ì™œëƒí•˜ë©´ Mê³¼ Nì´ í´ìˆ˜ë¡ SSQRì˜ ëª¨ë¸ë§ ëŠ¥ë ¥ì´ í–¥ìƒë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. WN18RR ë°ì´í„°ì…‹ì—ì„œëŠ” Nì´ Më³´ë‹¤ ë” í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ë°, ì´ëŠ” WN18RRì˜ êµ¬ì¡°ê°€ ë” í¬ì†Œí•˜ê³  ì—”í‹°í‹°ê°€ ë” ë§ê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) WN18RR dataset.
> </details>



![](https://arxiv.org/html/2501.18119/x9.png)

> ğŸ”¼ ê·¸ë¦¼ì€ ë³¸ ë…¼ë¬¸ì˜ SSQR(Self-supervised Quantized Representation) ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.  FB15k-237 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ì‹¤í—˜ ê²°ê³¼ë¡œ,  M(codebook length)ê³¼ N(sequence length)ì˜ ë³€í™”ì— ë”°ë¥¸ MRR(Mean Reciprocal Rank) ë° Hits@k ì§€í‘œ ê°’ì„ 3ì°¨ì› ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì…ë‹ˆë‹¤.  ê° ì¶•ì€ M, N, ê·¸ë¦¬ê³  ì„±ëŠ¥ ì§€í‘œë¥¼ ë‚˜íƒ€ë‚´ë©°,  Mê³¼ Nì˜ ê°’ì„ ì¡°ì ˆí•¨ì— ë”°ë¼ ì„±ëŠ¥ ì§€í‘œ ê°’ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” SSQR ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) FB15k-237 dataset.
> </details>



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/wn_sta.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ íŠ¹ì • ì—”í‹°í‹°ì™€ í•´ë‹¹ ì—”í‹°í‹°ì™€ ê°€ì¥ ê°€ê¹Œìš´ kê°œì˜ ì´ì›ƒ ì—”í‹°í‹°ë“¤ ê°„ì˜ ì½”ë“œì— ëŒ€í•œ í‰ê·  Jaccard ê±°ë¦¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  Jaccard ê±°ë¦¬ëŠ” ë‘ ì§‘í•©ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œë¡œ, ë‘ ì—”í‹°í‹°ì˜ ì½”ë“œ ë²¡í„°ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. kê°’ì´ ì¦ê°€í•¨ì— ë”°ë¼ ê±°ë¦¬ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ì–´,  ì—”í‹°í‹° ì½”ë“œì˜ ìœ ì‚¬ì„± ë° ë¶„í¬ë¥¼ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.  ì¦‰,  ì„œë¡œ ë¹„ìŠ·í•œ ì—”í‹°í‹°ì¼ìˆ˜ë¡ Jaccard ê±°ë¦¬ê°€ ë‚®ê³ , ì„œë¡œ ë‹¤ë¥¸ ì—”í‹°í‹°ì¼ìˆ˜ë¡ Jaccard ê±°ë¦¬ê°€ ë†’ìŒì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: The mean Jaccard distance between codes of a specific entity and its kğ‘˜kitalic_k nearest ones.
> </details>



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/train_zhexian.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ FB15k-237 ë°ì´í„°ì…‹ì—ì„œ LLMì„ ì‚¬ìš©í•œ KG ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ì½”ë“œë¶ ê¸¸ì´(M)ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´(N) ì„¤ì •ì—ì„œ MRR(í‰ê·  ìƒí˜¸ ìˆœìœ„), Hits@1, Hits@3, Hits@10 ì§€í‘œë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬,  ìµœì ì˜ ì½”ë“œ ê¸¸ì´ì™€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì°¾ê³   LLM ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°ì ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´  ìµœì ì˜ ì •ëŸ‰í™”ëœ í‘œí˜„ ì„¤ì •ì„ ë„ì¶œí•˜ê³  LLM ê¸°ë°˜ KG ë§í¬ ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: The impacts of quantized representation for KG link prediction task using LLMs on FB15k-237.
> </details>



![](https://arxiv.org/html/2501.18119/extracted/6164369/fig/llm_bar1.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ WN18RR ë°ì´í„°ì…‹ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ë‚´ì˜ í† í° ì„ë² ë”© ì‹œê°í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ ì ì€ ì‹¤ì œ ë‹¨ì–´ í† í°ì„, íŒŒë€ìƒ‰ ì ì€ ì½”ë“œ í† í°ì„ ê°ê° ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‘ ê°€ì§€ ìœ í˜•ì˜ í† í°ì´ LLM ë‚´ì—ì„œ ì–´ë–»ê²Œ ë‹¤ë¥¸ ì˜ì—­ì— ë¶„í¬í•˜ëŠ”ì§€ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ê²ƒìœ¼ë¡œ,  LLMì´ ë‘ ê°€ì§€ ìœ í˜•ì˜ í† í°ì„ êµ¬ë¶„í•˜ì—¬ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì´ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” SSQR ê¸°ë²•ì´ LLMì— KG ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ ì¦ê±°ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Token embedding virtualization in LLMs (WN18RR dataset), where red and blue dots are real word tokens and code tokens, respectively.
> </details>



![](https://arxiv.org/html/2501.18119/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 9ëŠ” WN18RR ë°ì´í„°ì…‹ì—ì„œ ê°œì²´ë‹¹ 2-hop ì´ì›ƒ ë…¸ë“œ ìˆ˜ì™€ LLaMA2ë¥¼ ì‚¬ìš©í•˜ì—¬ í•„ìš”í•œ í† í° ìˆ˜ì˜ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  50%ì™€ 100% ë‘ ê°€ì§€ ì´ì›ƒ ìƒ˜í”Œë§ ë¹„ìœ¨ì— ë”°ë¥¸ ì´ì›ƒ ìˆ˜ì™€ í† í° ìˆ˜ì˜ ì¤‘ê°„ê°’ê³¼ í‰ê· ê°’ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ëŠ” ê° ê°œì²´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë° SSQRì´ 16ê°œì˜ í† í°ë§Œ í•„ìš”í•œ ë°˜ë©´, 50%ì™€ 100% ìƒ˜í”Œë§ ëª¨ë‘ ìƒë‹¹íˆ ë§ì€ ìˆ˜ì˜ í† í°ì„ í•„ìš”ë¡œ í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: The statistics of 2-hop sampled neighbors and needed tokens (by LLaMA2) for entities in WN18RR.
> </details>



![](https://arxiv.org/html/2501.18119/x11.png)

> ğŸ”¼ ê·¸ë¦¼ 10ì€ ì œì•ˆëœ ìê¸°ì§€ë„í•™ìŠµ ê¸°ë°˜ ì •ëŸ‰í™”ëœ í‘œí˜„ í•™ìŠµ ë°©ë²•(SSQR)ì˜ í•™ìŠµ ê³¼ì •ì„ Hits@1 ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. Hits@1ì€ ìƒìœ„ 1ê°œì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì‹¤ì œ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚´ëŠ” í‰ê°€ ì§€í‘œì…ë‹ˆë‹¤.  ê·¸ë˜í”„ëŠ” SSQR ëª¨ë¸ì˜ í•™ìŠµ ì§„í–‰ì— ë”°ë¥¸ Hits@1 ê°’ì˜ ë³€í™”ë¥¼ ë³´ì—¬ì£¼ë©°,  GCN(Graph Convolutional Network) ë° ì˜ë¯¸ ì •ë³´ ì¦ë¥˜(semantic distilling)ì˜ ìœ ë¬´ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ SSQR ëª¨ë¸ì˜ í•™ìŠµ ì•ˆì •ì„± ë° ì„±ëŠ¥ í–¥ìƒì— GCNê³¼ ì˜ë¯¸ ì •ë³´ ì¦ë¥˜ê°€ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: The training process of SSQR, where the Hits@1 metric is used to show the model performance.
> </details>



![](https://arxiv.org/html/2501.18119/x12.png)

> ğŸ”¼ ê·¸ë¦¼ 11ì€ WN18RR ë°ì´í„°ì…‹ì—ì„œ LLMsë¥¼ ì‚¬ìš©í•œ KG ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì„ ìœ„í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ ê·¸ë˜í”„ëŠ” ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì„¤ì •(Mê³¼ Nì˜ í¬ê¸°) í•˜ì—ì„œ í‰ê°€ ì§€í‘œ(MRR, Hits@1, Hits@3, Hits@10)ì˜ ë³€í™”ë¥¼ ë³´ì—¬ì£¼ì–´,  ìµœì ì˜ ì„±ëŠ¥ì„ ì–»ê¸° ìœ„í•œ ì •ëŸ‰í™”ëœ ë²¡í„°ì˜ ì°¨ì› ë° ê¸¸ì´ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì¤‘ìš”í•œ ê³ ë ¤ ì‚¬í•­ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: The impacts of quantized representation for KG link prediction task using LLMs on WN18RR.
> </details>



![](https://arxiv.org/html/2501.18119/x13.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” WN18RR ë°ì´í„°ì…‹ì—ì„œ 8ê°œì˜ ì—”í‹°í‹°ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (a)ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„, (b)ëŠ” ì œì•ˆëœ SSQR ë°©ë²•ì„, (c)ëŠ” GCN ì—†ì´ SSQRì„, (d)ëŠ” ì˜ë¯¸ë¡ ì  ì •ë³´ ì—†ì´ SSQRì„ ê°ê° ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ SSQRì´ ì—”í‹°í‹° í‘œí˜„ì„ ë³´ë‹¤ êµ¬ë³„ë˜ê²Œ ë§Œë“¤ê³  KGì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ë¡ ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ë° ë„ì›€ì´ ë¨ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Original text embedding.
> </details>



![](https://arxiv.org/html/2501.18119/x14.png)

> ğŸ”¼ ê·¸ë¦¼ (b)ëŠ” ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì–‘ìí™”ëœ í‘œí˜„ í•™ìŠµ ë°©ë²•ì¸ SSQR(Self-supervised Quantized Representation)ì˜ ê°œë…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  KG(Knowledge Graph)ì˜ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ì •ë³´ë¥¼ ì´ì‚°í™”ëœ ì½”ë“œ(í† í°)ë¡œ ì••ì¶•í•˜ì—¬, LLMs(Large Language Models)ì´ ìì—°ì–´ ë¬¸ì¥ì²˜ëŸ¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê³¼ì •ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì¦‰, KGì˜ ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì–‘ìí™”ëœ ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ LLMì— ì§ì ‘ ì…ë ¥í•¨ìœ¼ë¡œì¨ KGì™€ LLMì˜ ì›í™œí•œ í†µí•©ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) SSQR.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | WN18RR MRR | WN18RR Hits@10 | FB15k-237 MRR | FB15k-237 Hits@10 |
|---|---|---|---|---|
| NodePiece | 0.403 | 0.515 | 0.256 | 0.420 |
| +RandomEQ | 0.425 | 0.522 | 0.263 | 0.425 |
| EARL | 0.440 | 0.527 | 0.310 | 0.501 |
| +RandomEQ | 0.442 | 0.536 | 0.308 | 0.502 |
| SSQR | **0.483** | **0.578** | **0.361** | **0.545** |
| Î” (â†‘)â€  | 9.28% | 7.84% | 16.45% | 8.57% |
| w/o GCN | 0.479 | 0.577 | 0.309 | 0.482 |
| Î” (â†“)â€¡ | 0.83% | 0.17% | 14.40% | 11.56% |
| w/o sem | 0.447 | 0.521 | 0.347 | 0.528 |
| Î” (â†“)â€¡ | 7.45% | 9.86% | 3.88% | 3.12 %|{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ SSQR ë°©ë²•ì˜ ì„±ëŠ¥ì„ ê¸°ì¡´ì˜ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ ë°©ë²•ë“¤(NodePiece, EARL, RandomEQ)ê³¼ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  â€ ëŠ” ê° ì§€í‘œì—ì„œ SSQRì´ ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ë³´ë‹¤ ì–¼ë§ˆë‚˜ í–¥ìƒë˜ì—ˆëŠ”ì§€ë¥¼ ë°±ë¶„ìœ¨(%)ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ê³ , â€¡ëŠ” SSQRì˜ ì„±ëŠ¥ì„ ablation studyë¥¼ í†µí•´ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, SSQRì—ì„œ íŠ¹ì • ëª¨ë“ˆ(GCN ë˜ëŠ” semantic distilling)ì„ ì œê±°í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.  WN18RRê³¼ FB15k-237 ë‘ ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²°ê³¼ê°€ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, MRR(Mean Reciprocal Rank)ê³¼ Hits@10(Top-10 ì •í™•ë„) ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: The results of baselines are fromÂ Li etÂ al. (2023). â€ â€ \daggerâ€  means the improvement of SSQR compared to the best performance in each metric. â€¡â€¡\ddaggerâ€¡ means the ablation results compared to the results of SSQR.
> </details>

{{< table-caption >}}
| Model | WN18RR MRR | WN18RR Hits@1 | WN18RR Hits@3 | WN18RR Hits@10 | FB15k237 MRR | FB15k237 Hits@1 | FB15k237 Hits@3 | FB15k237 Hits@10 |
|---|---|---|---|---|---|---|---|---|
| **General Embedding Methods** |  |  |  |  |  |  |  |  |
| TransE [Bordes et al. (2013)] | 0.223 | 0.014 | 0.401 | 0.529 | 0.330 | 0.231 | 0.369 | 0.528 |
| CompGCN [Vashishth et al. (2020)] | 0.479 | 0.443 | 0.494 | 0.546 | 0.355 | 0.264 | 0.390 | 0.535 |
| AdaProp [Zhang et al. (2023)] | 0.562 | 0.499 | â€“ | 0.671 | 0.417 | 0.331 | â€“ | 0.585 |
| MA-GNN [Xu et al. (2023)] | 0.565 | 0.507 | 0.592 | 0.679 | 0.379 | 0.282 | 0.415 | 0.569 |
| TCRA [Guo et al. (2024a)] | 0.496 | 0.457 | 0.511 | 0.574 | 0.367 | 0.275 | 0.403 | 0.554 |
| DiffusionE [Cao et al. (2024)] | 0.557 | 0.504 | â€“ | 0.658 | 0.376 | 0.294 | â€“ | 0.539 |
| **LLM-based Methods** |  |  |  |  |  |  |  |  |
| KICGPT [Wei et al. (2023)] | 0.549 | 0.474 | 0.585 | 0.641 | 0.412 | 0.327 | 0.448 | 0.554 |
| CSProm-KG-CD [Li et al. (2024)] | 0.559 | 0.508 | 0.578 | 0.660 | â€“ | â€“ | â€“ | â€“ |
| ARR [Chen et al. (2024)] | 0.521 | â€“ | 0.607 | â€“ | 0.398 | â€“ | 0.436 | â€“ |
| KG-FIT [Jiang et al. (2024)] | 0.553 | 0.488 | 0.595 | 0.695 | 0.362 | 0.275 | 0.485 | 0.572 |
| MKGL [Guo et al. (2024b)] | 0.552 | 0.500 | 0.577 | 0.656 | 0.415 | 0.325 | 0.454 | 0.591 |
| SSQR-LLaMA2 | 0.591 | 0.548 | 0.618 | 0.673 | 0.449 | 0.374 | 0.491 | 0.597 |
| SSQR-LLaMA3.1 | 0.598 | 0.559 | 0.618 | 0.675 | 0.459 | 0.393 | 0.491 | 0.597 |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ì§€ì‹ ê·¸ë˜í”„ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì—ì„œ ì¼ë°˜ì ì¸ ì„ë² ë”© ë°©ë²•ê³¼ LLM ê¸°ë°˜ ë°©ë²•ì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  WN18RRê³¼ FB15k-237 ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ MRR(í‰ê·  ì—­ìˆœìœ„), Hits@1, Hits@3, Hits@10 ì§€í‘œë¥¼ ë¹„êµí•˜ì—¬ ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì„ë² ë”© ë°©ë²•ê³¼ LLM ê¸°ë°˜ ë°©ë²• ê°„ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¶„ì„í•˜ê³ , ì œì‹œëœ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: The experiment results of general embedding methods and LLM-based methods for KG link prediction.
> </details>

{{< table-caption >}}
| Model | Acc | P | R | F1 |
|---|---|---|---|---|
| TransE [Bordes et al. (2013)] | 0.697 | 0.708 | 0.671 | 0.689 |
| DistMult [Yang et al. (2015)] | 0.587 | 0.590 | 0.568 | 0.579 |
| RotatE [Sun et al. (2019)] | 0.684 | 0.692 | 0.664 | 0.678 |
| Alpaca$_{zero-shot}$ | 0.561 | 0.533 | 0.974 | 0.689 |
| GPT-3.5$_{zero-shot}$ | 0.602 | 0.866 | 0.240 | 0.376 |
| KG-LLaMA [Yao et al. (2023)] | 0.748 | 0.674 | 0.962 | 0.793 |
| KG-Alpaca [Yao et al. (2023)] | 0.699 | 0.627 | 0.983 | 0.766 |
| KoPA [Zhang et al. (2024b)] | 0.777 | 0.708 | 0.941 | 0.808 |
| SSQR-LLaMA2 | 0.794 | 0.757 | 0.867 | 0.808 |
|  w/o SSQR | 0.754 | 0.699 | 0.891 | 0.783 |
| Î” | -5.13% | -7.71% | +2.85% | -3.07% |
| SSQR-LLaMA3.1 | 0.798 | 0.759 | 0.872 | 0.811 |
|  w/o SSQR | 0.767 | 0.711 | 0.901 | 0.795 |
| Î” | -3.77% | -6.34% | +3.41% | -2.03% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ FB15k-237N ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í–‰ëœ ì‚¼ì¤‘í•­ ë¶„ë¥˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í‘œì—ëŠ” ì œì•ˆëœ ë°©ë²•(SSQR-LLaMA2, SSQR-LLaMA3.1)ì˜ ì„±ëŠ¥ê³¼ ë¹„êµë¥¼ ìœ„í•´ ì‚¬ìš©ëœ ì—¬ëŸ¬ ê¸°ì¡´ ë°©ë²•ë“¤ì˜ ì„±ëŠ¥(ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-ì ìˆ˜)ì´ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ê¸°ì¡´ ë°©ë²•ë“¤ì˜ ê²°ê³¼ëŠ” Zhang et al.(2024b) ë…¼ë¬¸ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì´ í‘œë¥¼ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ ì„±ëŠ¥ ìš°ìˆ˜ì„±ê³¼ ê¸°ì¡´ ë°©ë²•ë“¤ê³¼ì˜ ì°¨ì´ì ì„ ëª…í™•í•˜ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: The experiment results of the triple classification on FB15k-237N dataset. The results of baselines are taken fromÂ Zhang etÂ al. (2024b).
> </details>

{{< table-caption >}}
| Model | MRR | Hits@1 | Hits@3 | Hits@10 |
|---|---|---|---|---|
| **WN18RR** |  |  |  |  |
| SSQR-LLaMA2 | 0.591 | 0.548 | 0.618 | 0.673 |
| w/o SSQR | 0.541 | 0.495 | 0.603 | 0.668 |
| Î” (â†“) | 8.46% | 9.67% | 2.43% | 0.74% |
| **FB15k-237** |  |  |  |  |
| SSQR-LLaMA2 | 0.449 | 0.374 | 0.491 | 0.597 |
| w/o SSQR | 0.401 | 0.322 | 0.441 | 0.589 |
| Î” (â†“) | 10.69% | 13.90% | 10.18% | 1.34% |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ablation ì—°êµ¬ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  SSQR ëª¨ë¸ì—ì„œ ê° ëª¨ë“ˆ(GCN, ì˜ë¯¸ë¡ ì  ì¦ë¥˜)ì„ ì œê±°í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì—¬ ê° ëª¨ë“ˆì˜ ì¤‘ìš”ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. WN18RR ë° FB15k-237 ë°ì´í„°ì…‹ì— ëŒ€í•œ MRR, Hits@1, Hits@3, Hits@10 ì§€í‘œê°€ ì œì‹œë©ë‹ˆë‹¤.  SSQR ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê¸°ì¤€ìœ¼ë¡œ ê° ablation ì‹¤í—˜ì˜ ì„±ëŠ¥ ì €í•˜ ì •ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œí•˜ì—¬, ëª¨ë¸ì˜ ì„±ëŠ¥ì— ê° ëª¨ë“ˆì´ ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: The ablation results for the link prediction task.
> </details>

{{< table-caption >}}
| Dataset | Ent | Rel | Train | Valid | Test |
|---|---|---|---|---|---| 
| WN18RR | 40943 | 11 | 86835 | 3034 | 3134 |
| FB15k-237 | 14541 | 237 | 272115 | 17535 | 20466 |
| FB15k-237N | 13104 | 93 | 87282 | 7041/7041 | 8226/8226 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ì„¸ ê°€ì§€ ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„°ì…‹(WN18RR, FB15k-237, FB15k-237N)ì˜ í†µê³„ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. WN18RRê³¼ FB15k-237 ë°ì´í„°ì…‹ì€ ë§í¬ ì˜ˆì¸¡ ì‹¤í—˜ì— ì‚¬ìš©ë˜ì—ˆìœ¼ë©°, FB15k-237N ë°ì´í„°ì…‹ì€ íŠ¸ë¦¬í”Œ ë¶„ë¥˜ ì‹¤í—˜ì— ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. FB15k-237N ë°ì´í„°ì…‹ì˜ ê²½ìš°, â€˜/â€™ ê¸°í˜¸ëŠ” ì–‘ì„± ìƒ˜í”Œê³¼ ìŒì„± ìƒ˜í”Œì„ êµ¬ë¶„í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ì—”í‹°í‹°(entity), ë¦´ë ˆì´ì…˜(relation), í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°, ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°ê°€ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: The statistics of WN18RR, FB15k-237, and FB15k-237N datasets. The former two are for link prediction. FB15k-237N dataset is for triple classification, where â€˜/â€™ splits the positive and negative samples.
> </details>

{{< table-caption >}}
| Instruction | Input | Output |
|---|---|---|
| Given a triple in the knowledge graph, you need to predict its validity based on the triple itself and entitiesâ€™ quantized representations. | The triple is: ( _h_, _r_, _t_)<br>The quantized representation of entity _h_ is: [Code(_h_)]<br>The quantized representation of entity _t_ is: [Code(_t_)]<br>Please determine the validity of the triple and respond True or False. | True/False |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ì§€ì‹ ê·¸ë˜í”„ì˜ ì„¸ ê°œì˜ ìš”ì†Œ(ì£¼ì–´, ê´€ê³„, ëª©ì ì–´)ë¡œ ì´ë£¨ì–´ì§„ ì‚¼ì¤‘í•­ì˜ ìœ íš¨ì„±ì„ LLMs(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì— ëŒ€í•œ ì§€ì‹œ ì‚¬í•­ì˜ í˜•ì‹ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì‚¼ì¤‘í•­ì˜ ì£¼ì–´ì™€ ëª©ì ì–´ì— ëŒ€í•œ ì–‘ìí™”ëœ í‘œí˜„(ì½”ë“œ)ì´ ì…ë ¥ìœ¼ë¡œ ì œê³µë˜ê³ , LLMsëŠ” ì‚¼ì¤‘í•­ì´ ìœ íš¨í•œì§€ ì—¬ë¶€ë¥¼ True ë˜ëŠ” Falseë¡œ ì‘ë‹µí•©ë‹ˆë‹¤. ì´ëŠ” LLMsì´ KG(ì§€ì‹ ê·¸ë˜í”„) ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³   ì‚¼ì¤‘í•­ì˜ ìœ íš¨ì„±ì„ íŒë‹¨í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Instruction format for triple classification.
> </details>

{{< table-caption >}}
| Input | This is a knowledge graph completion task, which needs to predict the tail entity for an incomplete query triplet. The query triplet is (radiotherapy, hypernym, ?). The quantized representation of entity radiotherapy is: [2006] [588] [350] [1486] [214] [929] [328] [1424] [1792] [919] [944] [740] [438] [843] [147] [628] The answer candidates and corresponding quantized representations are as follows: disease, [156] [1880] [1777] [185] [121] [720] [783] [1713] [945] [1077] [180] [1576] [1574] [1433] [216] [1280] tomography, [182] [597] [657] [1486] [404] [468] [732] [564] [833] [1470] [1756] [626] [1674] [843] [1928] [513] medical care, [422] [68] [1329] [1517] [1251] [431] [1479] [1445] [1666] [407] [952] [406] [1337] [388] [1982] [685] status, [1721] [1906] [1773] [1811] [12] [892] [1625] [1476] [1561] [176] [534] [1463] [1657] [368] [70] [1618] physiological state, [1721] [718] [267] [394] [120] [1105] [885] [1823] [1496] [23] [952] [406] [1559] [1198] [1149] [1800] medical science, [565] [413] [842] [1517] [350] [873] [575] [595] [721] [935] [1554] [175] [708] [1643] [1820] [1775] infection, [565] [1594] [990] [1066] [974] [40] [434] [874] [1401] [371] [1700] [1118] [1709] [52] [71] [1408] picturing, [788] [168] [641] [1797] [927] [711] [1608] [123] [1163] [1460] [952] [406] [1752] [1464] [553] [1158] medicine, [1879] [1216] [691] [296] [1743] [892] [1851] [595] [2039] [1428] [426] [740] [399] [579] [433] [1987] unhealthiness, [1389] [644] [570] [258] [635] [647] [732] [1139] [1660] [407] [464] [1020] [1574] [1905] [926] [1971] grounds, [1268] [1053] [803] [780] [1194] [285] [328] [289] [1163] [915] [1921] [1020] [524] [1774] [430] [1572] defense reaction, [1881] [1821] [1620] [1703] [435] [995] [908] [1308] [1596] [1598] [401] [2008] [903] [817] [92] [1158] radiology, [1478] [588] [1340] [1797] [1436] [1914] [1894] [1424] [634] [1460] [1756] [740] [673] [843] [108] [1088] radioscopy, [1005] [1002] [1441] [137] [1436] [1378] [1479] [1649] [1544] [1470] [534] [626] [902] [272] [904] [1874] treat, [396] [2007] [1935] [1305] [1993] [1030] [1690] [1445] [1203] [1417] [1554] [495] [1752] [1001] [1236] [98] specialize, [1005] [1933] [1976] [780] [927] [1728] [575] [105] [1791] [1598] [616] [1118] [1752] [425] [437] [1847] therapy, [396] [816] [81] [488] [336] [1164] [1690] [1288] [900] [915] [1554] [175] [666] [1622] [765] [685] specialism, [384] [816] [599] [394] [435] [789] [1479] [105] [664] [407] [1554] [103] [1752] [1708] [697] [1130] symptom, [1721] [1913] [772] [858] [120] [1150] [1374] [289] [1666] [1417] [944] [2008] [1454] [958] [1169] [1800] medicine, [156] [350] [1599] [1955] [1368] [508] [1527] [1445] [1561] [1460] [426] [1142] [940] [653] [793] [471] Please generate quantized representations of the top-3 potential answer entities, ranked from highest to lowest: LLM Output: 1, [396] [816] [81] [488] [336] [1164] [1690] [1288] [900] [915] [1554] [175] [666] [1622] [765] [685] 2, [156] [1880] [1777] [185] [121] [720] [783] [1713] [945] [1077] [180] [1576] [1574] [1433] [216] [1280] 3, [182] [597] [657] [1486] [404] [468] [732] [564] [833] [1470] [1756] [626] [1674] [843] [1928] [513] Ground Truth: [396] [816] [81] [488] [336] [1164] [1690] [1288] [900] [915] [1554] [175] [666] [1622] [765] [685] |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” LLaMA2ë¥¼ ì‚¬ìš©í•˜ì—¬ WN18RR ë°ì´í„°ì…‹ì—ì„œ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. 'radiotherapy' (ë°©ì‚¬ì„  ì¹˜ë£Œ) ì—”í‹°í‹°ì— ëŒ€í•œ ì§ˆì˜ê°€ ì£¼ì–´ì§€ê³ , 'hypernym' (ìƒìœ„ ê°œë…) ê´€ê³„ì— ëŒ€í•œ ì •ë‹µ í›„ë³´ë“¤ì´ ì œì‹œë©ë‹ˆë‹¤.  LLaMA2 ëª¨ë¸ì€ ì •ë‹µìœ¼ë¡œ 'therapy' (ì¹˜ë£Œ)ë¥¼ ì˜ˆì¸¡í–ˆìœ¼ë©°, í•´ë‹¹ ì½”ë“œëŠ” 17ë²ˆì§¸ ìˆœìœ„ì—ì„œ 1ìœ„ë¡œ ì˜¬ë¼ì™”ìŠµë‹ˆë‹¤. ì´ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì´ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì—ì„œ íš¨ê³¼ì ì„ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Case study on WN18RR for link prediction using LLaMA2. The code of ground truth therapy is ranked to the first position from 17-th.
> </details>

{{< table-caption >}}
| Input | LLM Output | Ground Truth |
|---|---|---|
| ![Input](https://arxiv.org/html/2501.18119/A5.T9.1.1.1.pic1.png) | 1, [497] [1875] [1849] [377] [1694] [61] [1471] [1445] [392] [1672] [1500] [300] [711] [1839] [331] [136]<br>2, [1532] [258] [1837] [357] [923] [1994] [638] [555] [771] [1003] [1736] [1473] [1495] [1436] [1313] [20]<br>3, [661] [1243] [542] [1741] [1907] [1799] [858] [1794] [1916] [458] [1844] [909] [438] [1737] [686] [963] | [497] [1875] [1849] [377] [1694] [61] [1471] [1445] [392] [1672] [1500] [300] [711] [1839] [331] [136] |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” LLaMA2ë¥¼ ì‚¬ìš©í•˜ì—¬ FB15k-237 ë°ì´í„°ì…‹ì—ì„œ ë§í¬ ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ í‘œëŠ” ì§ˆì˜ íŠ¸ë¦¬í”Œì— ëŒ€í•œ ìƒìœ„ 3ê°œì˜ ì˜ˆì¸¡ëœ ê¼¬ë¦¬ ì—”í‹°í‹°ì™€ ê° ì—”í‹°í‹°ì— ëŒ€í•œ ì •ëŸ‰í™”ëœ í‘œí˜„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹¤ì œ ì •ë‹µì¸ IndianaëŠ” 16ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ 1ìœ„ë¡œ ì˜¬ë¼ì™”ìŠµë‹ˆë‹¤.  ì´ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ë¡ ì´ KGì˜ êµ¬ì¡°ì™€ ì˜ë¯¸ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ LLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ì¢‹ì€ ì˜ˆì‹œì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Case study on FB15k-237 for link prediction using LLaMA2. The code of ground truth Indiana is ranked to the first position from 16-th.
> </details>

{{< table-caption >}}
| Input | LLM Output | Ground Truth |
|---|---|---|
| Given a triple in the knowledge graph, you need to predict its validity based on the triple itself and entitiesâ€™ quantized representations. The triple is: (Carl Foreman, /people/person/place_of_birth, Chicago) The quantized representation of entity â€œCarl Foremanâ€ is: [72] [114] [150] [336] [519] [494] [155] [482] [594] [934] [1012] [677] [473] [450] [827] [455] The quantized representation of entity â€œChicagoâ€ is: [603] [413] [385] [937] [731] [735] [836] [92] [400] [372] [563] [225] [82] [526] [81] [229] Please determine the validity of the triple and respond True or False. | True | True |
| Given a triple in the knowledge graph, you need to predict its validity based on the triple itself and entitiesâ€™ quantized representations. The triple is: (Jessica Lange, /people/person/profession, Lawyer) The quantized representation of entity â€œJessica Langeâ€ is: [23] [712] [484] [202] [289] [211] [772] [667] [870] [903] [213] [693] [360] [59] [868] [722] The quantized representation of entity â€œLawyerâ€ is: [760] [84] [976] [802] [430] [735] [912] [480] [966] [411] [284] [113] [727] [744] [333] [56] Please determine the validity of the triple and respond True or False. | False | False |{{< /table-caption >}}
> ğŸ”¼ í‘œ 10ì€ LLaMA2ë¥¼ ì‚¬ìš©í•˜ì—¬ FB15k-237N ë°ì´í„°ì…‹ì—ì„œ ìˆ˜í–‰í•œ ì‚¼ì¤‘í•­ ë¶„ë¥˜ ì‘ì—…ì˜ ë‘ ê°€ì§€ ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì‚¬ë¡€ëŠ” ì§ˆë¬¸(ì‚¼ì¤‘í•­)ê³¼ ê·¸ì— ëŒ€í•œ LLaMA2ì˜ ì‘ë‹µì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ ì„±ëŠ¥ê³¼ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Two cases on FB15k-237N dataset for triple classification using LLaMA2.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}