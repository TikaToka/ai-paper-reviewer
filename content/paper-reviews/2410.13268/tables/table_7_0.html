<table id='1' style='font-size:14px'><tr><td rowspan="2">Level</td><td rowspan="2">Task</td><td rowspan="2">Human Baseline</td><td colspan="5">Models</td></tr><tr><td>GPT-4o</td><td>MuLLaMA</td><td>GAMA</td><td>SALMONN</td><td>Qwen2-Audio</td></tr><tr><td rowspan="6">L1</td><td>Language Identification</td><td>x</td><td>88.50%</td><td>8.48%</td><td>x</td><td>35.17%</td><td>96.44%</td></tr><tr><td>Auto-Speech Recognition</td><td>15.49*</td><td>10.24*</td><td>x</td><td>x</td><td>5.45*</td><td>4.63*</td></tr><tr><td>ASR for Legal Terms</td><td>98.50%</td><td>26.47%</td><td>x</td><td>x</td><td>x</td><td>81.04%</td></tr><tr><td>ASR for Medical Terms</td><td>97.50%</td><td>41.87%</td><td>x</td><td>x</td><td>x</td><td>53.86%</td></tr><tr><td>Auto-Lyrics Transcription</td><td>26.88*</td><td>x</td><td>x</td><td>x</td><td>77.12*</td><td>32.48*</td></tr><tr><td>- Hallucination Rate</td><td>3.00%</td><td>x</td><td>x</td><td>x</td><td>29.26%</td><td>38.21%</td></tr><tr><td rowspan="3">L2</td><td>Volume Perception</td><td>100.00%</td><td>x</td><td>50.00%</td><td>11.98%</td><td>53.22%</td><td>48.96%</td></tr><tr><td>Pitch Perception</td><td>96.25%</td><td>29.33%</td><td>33.78%</td><td>41.50%</td><td>50.00%</td><td>50.00%</td></tr><tr><td>Binaural Effect Perception</td><td>100.00%</td><td>41.38%</td><td>x</td><td>x</td><td>49.88%</td><td>x</td></tr><tr><td rowspan="9">L3</td><td>Ambient Noise Detection</td><td>91.88%</td><td>45.27%</td><td>50.00%</td><td>60.17%</td><td>49.88%</td><td>50.00%</td></tr><tr><td>Acoustic Scene Classification</td><td>90.28%</td><td>16.36%</td><td>5.07%</td><td>12.05%</td><td>20.74%</td><td>27.67%</td></tr><tr><td>Speaker's Age Prediction</td><td>52.59%</td><td>13.43%</td><td>33.60%</td><td>x</td><td>36.87%</td><td>38.55%</td></tr><tr><td>Speaker's Gender Recognition</td><td>97.50%</td><td>x</td><td>50.00%</td><td>x</td><td>48.12%</td><td>79.60%</td></tr><tr><td>Speech Emotion Recognition</td><td>50.71%</td><td>16.77%</td><td>9.20%</td><td>3.68%</td><td>10.93%</td><td>79.51%</td></tr><tr><td>Cappella Emotion Recognition</td><td>62.25%</td><td>21.50%</td><td>12.42%</td><td>7.08%</td><td>14.62%</td><td>62.38%</td></tr><tr><td>Emotion Intensity Perception</td><td>97.50%</td><td>72.67%</td><td>50.00%</td><td>50.00%</td><td>49.29%</td><td>50.00%</td></tr><tr><td>Emotion Translation t</td><td>3.68</td><td>0.32</td><td>x</td><td>x</td><td>0.27</td><td>0.31</td></tr><tr><td>Singing Detection</td><td>99.38%</td><td>53.11%</td><td>50.00%</td><td>64.82%</td><td>56.47%</td><td>50.22%</td></tr><tr><td rowspan="4">L4</td><td>COVID-19 Risk Detection</td><td>60.63%</td><td>x</td><td>x</td><td>x</td><td>50.00%</td><td>14.17%</td></tr><tr><td>Cough Type Classification</td><td>52.50%</td><td>40.33%</td><td>50.16%</td><td>44.17%</td><td>49.17%</td><td>43.39%</td></tr><tr><td>Cough Origin Diagnosis</td><td>32.19%</td><td>x</td><td>x</td><td>x</td><td>4.01%</td><td>25.65%</td></tr><tr><td>Cough Severity Assessment</td><td>45.42%</td><td>24.12%</td><td>30.85%</td><td>28.50%</td><td>38.24%</td><td>33.86%</td></tr><tr><td rowspan="2">L5</td><td>Spoken English Coach +</td><td>1.39</td><td>0.15</td><td>1.29</td><td>0.44</td><td>0.48</td><td>0.54</td></tr><tr><td>Voice Detectiveâ€ </td><td>1.20</td><td>x</td><td>0.84</td><td>0.83</td><td>0.86</td><td>1.24</td></tr></table>