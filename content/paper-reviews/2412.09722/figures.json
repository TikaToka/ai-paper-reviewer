[{"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/overview_greater.png", "caption": "Figure 1: Comparison of textual feedback-based prompt optimization and GReaTer. Left: textual feedback relies entirely on a larger language model\u2019s judgments. Right: GReaTer avoids external large, proprietary models, using token suggestions from a small model and guiding prompt token selection with loss gradients. GReaTer incorporates model reasoning by first generating reasoning, then applying an extraction prompt to obtain answer logits for computing loss gradients. This \u201cgradient over reasoning\u201d approach optimizes using direct signals rather than relying on language model feedback.", "description": "\uc774 \uadf8\ub9bc\uc740 \ud14d\uc2a4\ud2b8 \ud53c\ub4dc\ubc31 \uae30\ubc18 \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654\uc640 GREATER\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8 \ud53c\ub4dc\ubc31 \uae30\ubc18 \ubc29\ubc95\uc740 \uac70\ub300 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \ud310\ub2e8\uc5d0 \uc804\uc801\uc73c\ub85c \uc758\uc874\ud558\uc5ec \ud504\ub86c\ud504\ud2b8\ub97c \uac1c\uc120\ud569\ub2c8\ub2e4. \ubc18\uba74 GREATER\ub294 \uc791\uc740 \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ub41c \ud1a0\ud070 \ud6c4\ubcf4\ub97c \uc0ac\uc6a9\ud558\uace0 \uc190\uc2e4 \uae30\uc6b8\uae30\ub97c \uae30\ubc18\uc73c\ub85c \ucd5c\uc801\uc758 \ud1a0\ud070\uc744 \uc120\ud0dd\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc791\ub3d9\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uac70\ub300 LLM \uc5c6\uc774\ub3c4 \ud504\ub86c\ud504\ud2b8\ub97c \ucd5c\uc801\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. GREATER\ub294 \ucd94\ub860 \uacfc\uc815\uc744 \uba3c\uc800 \uc0dd\uc131\ud558\uace0, \ucd94\ucd9c \ud504\ub86c\ud504\ud2b8\ub97c \uc801\uc6a9\ud558\uc5ec \uc815\ub2f5 \ub85c\uc9d3\uc744 \uc5bb\uace0, \uc774\ub97c \ud1b5\ud574 \uc190\uc2e4 \uae30\uc6b8\uae30\ub97c \uacc4\uc0b0\ud558\ub294 \"\ucd94\ub860 \uae30\ubc18 \uae30\uc6b8\uae30\" \uc811\uadfc \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub294 \uc5b8\uc5b4 \ubaa8\ub378 \ud53c\ub4dc\ubc31 \ub300\uc2e0 \uc9c1\uc811\uc801\uc778 \uc2e0\ud638\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc801\ud654\ub97c \uc218\ud589\ud568\uc73c\ub85c\uc368 \ub354 \ud6a8\uc728\uc801\uc778 \ud504\ub86c\ud504\ud2b8 \uac1c\uc120\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "Introduction"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/greatprompt_methodology_v2.png", "caption": "Figure 2: Overall workflow of GReaTer. (i) The language model fLLMsubscript\ud835\udc53LLMf_{\\text{LLM}}italic_f start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT generates token candidates by conditioning on input samples. (ii) fLLMsubscript\ud835\udc53LLMf_{\\text{LLM}}italic_f start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT uses task input and current prompt to generate reasoning and extract final answer logits. (iii) The logits are used to calculate loss and compute gradient over generated reasoning with respect to the candidate tokens. These gradients determine the selection of candidate token to update the current position of the current prompt.", "description": "GReaTer\ub294 \uc138 \ub2e8\uacc4\ub85c \uc791\ub3d9\ud569\ub2c8\ub2e4. (i) \uc5b8\uc5b4 \ubaa8\ub378(fLLM)\uc774 \uc785\ub825 \uc0d8\ud50c\uc744 \uae30\ubc18\uc73c\ub85c \ud6c4\ubcf4 \ud1a0\ud070\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. (ii) fLLM\uc740 \uc791\uc5c5 \uc785\ub825\uacfc \ud604\uc7ac \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd94\ub860\uc744 \uc0dd\uc131\ud558\uace0 \ucd5c\uc885 \ub2f5\ubcc0 \ub85c\uc9d3\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4. (iii) \ub85c\uc9d3\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0 \uc0dd\uc131\ub41c \ucd94\ub860\uc5d0 \ub300\ud55c \uae30\uc6b8\uae30\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uae30\uc6b8\uae30\ub294 \ud604\uc7ac \ud504\ub86c\ud504\ud2b8\uc758 \ud604\uc7ac \uc704\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud558\uae30 \uc704\ud55c \ud6c4\ubcf4 \ud1a0\ud070 \uc120\ud0dd\uc744 \uacb0\uc815\ud569\ub2c8\ub2e4.", "section": "4. OUR METHOD"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/impact_gradient_reasoning.png", "caption": "Figure 3: Ablation study on \u201cGradient Over Reasoning\u201d in GReaTer. Gradient calculation without reasoning causes notable performance drops, showing the importance of reasoning for gradients.", "description": "\uc774 \uadf8\ub9bc\uc740 \ucd94\ub860 \uacfc\uc815 \uc5c6\uc774 \uae30\uc6b8\uae30 \uacc4\uc0b0\uc744 \uc218\ud589\ud588\uc744 \ub54c \uc791\uc5c5 \uc131\ub2a5\uc774 \ud06c\uac8c \uc800\ud558\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, GREATER\uc5d0\uc11c \"\ucd94\ub860\uc5d0 \ub300\ud55c \uae30\uc6b8\uae30\"\ub97c \uc81c\uac70\ud558\uba74 movie_recommendation \ubc0f tracking_shuffled_objects_five_objects \uc791\uc5c5 \ubaa8\ub450\uc5d0\uc11c Llama-3-8B \ubc0f Gemma-2-9B \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc800\ud558\ub429\ub2c8\ub2e4. \uc774\ub294 \ucd94\ub860 \uacfc\uc815\uc774 \uae30\uc6b8\uae30 \uacc4\uc0b0 \ubc0f \ucd5c\uc801\ud654\uc5d0 \ud544\uc218\uc801\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "5.4 ABLATION OF GRADIENT OVER REASONING"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/five_vs_zero_shot.png", "caption": "Figure 4: Efficacy of GReaTer in zero-shot setting compared to five-shot inference with Llama-3-8B-Instruct.", "description": "\uc774 \uadf8\ub9bc\uc740 Llama-3-8B-Instruct \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec 5-shot In-Context Learning\uacfc GREATER \uae30\ubc95\uc744 \uc0ac\uc6a9\ud55c Zero-shot \ucd94\ub860\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uac00\uc9c0 \uc791\uc5c5(\uc601\ud654 \ucd94\ucc9c \ubc0f 5\uac1c\uc758 \ubb3c\uccb4 \ucd94\uc801)\uc5d0\uc11c GREATER\ub97c \uc0ac\uc6a9\ud55c Zero-shot \ucd94\ub860\uc774 5-shot In-Context Learning\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub418\uc5c8\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 GREATER\uac00 \ud6a8\uc728\uc801\uc778 \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654\ub97c \ud1b5\ud574 \uc801\uc740 \uc218\uc758 \uc608\uc2dc \uc5c6\uc774\ub3c4 In-Context Learning\uc5d0 \ube44\ud574 \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "5.4 ABLATION OF GRADIENT OVER REASONING"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/llama_wdl.png", "caption": "Figure 5: Win/Draw/Loss Comparison of GReaTer and SOTA prompt optimization techniques APO, TextGrad, APE, and PE2 in optimization with Llama-3-8B-Instruct. GReaTer maintains a significant winning margin over these methods, highlighting its effectiveness in optimization.", "description": "GReaTer\uac00 Llama-3-8B-Instruct \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ucd5c\uc801\ud654\uc5d0\uc11c APO, TextGrad, APE, PE2\uc640 \uac19\uc740 \ucd5c\ucca8\ub2e8 \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654 \uae30\ubc95\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. GReaTer\ub294 \ub300\ubd80\ubd84\uc758 \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc2b9\ub960\uc774 \ub192\uc73c\uba70, \uc774\ub294 \ucd5c\uc801\ud654\uc5d0\uc11c GReaTer\uc758 \ud6a8\uc728\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "5.2 OVERALL RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/llama_all_res.png", "caption": "Figure 6: Full performance breakdown across 21 BBH tasks of GReaTer and SOTA prompt optimization techniques APO, TextGrad, APE, and PE2 in optimization with Llama-3-8B.", "description": "Llama-3-8B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ucd5c\uc801\ud654\uc5d0\uc11c GReaTer\uc640 SOTA \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654 \uae30\ubc95(APO, TextGrad, APE, PE2)\uc758 21\uac00\uc9c0 BBH \uc791\uc5c5\uc5d0 \ub300\ud55c \uc804\uccb4 \uc131\ub2a5 \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4. GReaTer\uac00 \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "H.2 BIG BENCH HARD (BBH): OPTIMIED PROMPTS AND DETAILED RESULTS"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/gemma_wdl.png", "caption": "Figure 7: Win/Draw/Loss Comparison of GReaTer and SOTA prompt optimization techniques APO, TextGrad, APE, and PE2 in optimization with Gemma-2-9B-it. GReaTer maintains winning margin over these methods, highlighting its effectiveness in optimization.", "description": "GReaTer\ub294 Gemma-2-9B-it \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ucd5c\uc801\ud654\uc5d0\uc11c APO, TextGrad, APE, PE2\uc640 \uac19\uc740 SOTA \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654 \uae30\ubc95\uacfc \ube44\uad50\ud558\uc5ec Win/Draw/Loss\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. GReaTer\ub294 \ub300\ubd80\ubd84\uc758 \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098 \ucd5c\uc801\ud654\uc758 \ud6a8\uc728\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "5. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.09722/extracted/5991147/figures/gemma_allres.png", "caption": "Figure 8: Full performance breakdown across 21 BBH tasks of GReaTer and SOTA prompt optimization techniques APO, TextGrad, APE, and PE2 in optimization with Gemma-2-9B.", "description": "\uc774 \uadf8\ub9bc\uc740 Gemma-2-9B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec 21\uac1c\uc758 Big Bench Hard (BBH) \ucd94\ub860 \uc791\uc5c5\uc5d0\uc11c GReaTer\uc640 \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654 \uae30\ubc95(APO, TextGrad, APE, PE2)\uc758 \uc131\ub2a5\uc744 \uc790\uc138\ud788 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc740 \ub9c9\ub300 \uadf8\ub798\ud504\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, GReaTer\uc640 \uae30\uc900 \uc131\ub2a5 \uac04\uc758 \ucc28\uc774\ub97c \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. GReaTer\uac00 \ub300\ubd80\ubd84\uc758 \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "I.2 Big Bench Hard (BBH): OPTIMIZED PROMPTS AND DETAILED RESULTS"}]