[{"figure_path": "https://arxiv.org/html/2502.02358/x1.png", "caption": "Figure 1. Demonstration of our MotionLab\u2019s versatility, performance and efficiency. Previous SOTA refer to multiple expert models, including MotionLCM (Dai et\u00a0al., 2025), OmniControl (Xie et\u00a0al., 2023), MotionFix (Athanasiou et\u00a0al., 2024), CondMDI (Cohan et\u00a0al., 2024) and MCM-LDM (Song et\u00a0al., 2024). All motions are represented using SMPL (Loper et\u00a0al., 2023), where transparent motion indicates the source motion or condition, and the other represents the target motion. More qualitative results are available in the website and appendix.", "description": "\uadf8\ub9bc 1\uc740 MotionLab\uc758 \ub2e4\uc591\uc131, \uc131\ub2a5 \ubc0f \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ud14d\uc2a4\ud2b8 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131, \uada4\uc801 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131, \ubaa8\uc158 \ubcf4\uac04 \ubc0f \uc2a4\ud0c0\uc77c \ubcc0\ud658\uacfc \uac19\uc740 \uc5ec\ub7ec \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub294 MotionLab\uc758 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud22c\uba85\ud55c \ubaa8\uc158\uc740 \uc18c\uc2a4 \ubaa8\uc158 \ub610\ub294 \uc870\uac74\uc744 \ub098\ud0c0\ub0b4\uace0, \ub2e4\ub978 \ubaa8\uc158\uc740 \ubaa9\ud45c \ubaa8\uc158\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ube44\uad50\ub97c \uc704\ud574 MotionLCM, OmniControl, MotionFix, CondMDI \ubc0f MCM-LDM\uacfc \uac19\uc740 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\uc758 \uacb0\uacfc\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 MotionLab\uc758 \uc6b0\uc218\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. SMPL\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub4e0 \ubaa8\uc158\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc6f9\uc0ac\uc774\ud2b8\uc640 \ubd80\ub85d\uc5d0\uc11c \ub354 \uc790\uc138\ud55c \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1 INTRODUCTION"}, {"figure_path": "https://arxiv.org/html/2502.02358/x2.png", "caption": "Figure 2. Demonstration of the difference trajectory between diffusion models and rectified flows. This difference lies in that the trajectory of diffusion models is based on xt=(1\u2212\u03b1t\u00af)\u2062x0+\u03b1t\u00af\u2062\u03f5subscript\ud835\udc65\ud835\udc611\u00afsubscript\ud835\udefc\ud835\udc61subscript\ud835\udc650\u00afsubscript\ud835\udefc\ud835\udc61italic-\u03f5x_{t}=\\sqrt{(1-\\overline{\\alpha_{t}})}x_{0}+\\sqrt{\\overline{\\alpha_{t}}}\\epsilonitalic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG ( 1 - over\u00af start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ) end_ARG italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + square-root start_ARG over\u00af start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_\u03f5, while the trajectory of rectified flows is based on xt=(1\u2212t)\u2062x0+t\u2062x1subscript\ud835\udc65\ud835\udc611\ud835\udc61subscript\ud835\udc650\ud835\udc61subscript\ud835\udc651x_{t}=(1-t)x_{0}+tx_{1}italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( 1 - italic_t ) italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_t italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. This distinction leads to more robust learning by maintaining a constant velocity, contributing to model\u2019s efficiency (Zhao et\u00a0al., 2024).", "description": "\uadf8\ub9bc 2\ub294 \ud655\uc0b0 \ubaa8\ub378\uacfc \uc815\ub958 \ud750\ub984(Rectified Flows)\uc758 \uacbd\ub85c \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud655\uc0b0 \ubaa8\ub378\uc740  x\u209c = \u221a(1-\u03b1t)x\u2080 + \u221a\u03b1t\u03f5 \uc640 \uac19\uc740 \uacbd\ub85c\ub97c \ub530\ub974\ub294 \ubc18\uba74, \uc815\ub958 \ud750\ub984\uc740 x\u209c = (1-t)x\u2080 + tx\u2081 \uc640 \uac19\uc740 \uacbd\ub85c\ub97c \ub530\ub985\ub2c8\ub2e4. \uc5ec\uae30\uc11c \u03b1t\ub294 \uc2dc\uac04\uc5d0 \ub530\ub978 \ud655\uc0b0 \uacc4\uc218, x\u2080\ub294 \ucd08\uae30 \ub178\uc774\uc988, \u03f5\ub294 \ub178\uc774\uc988 \ubca1\ud130, x\u2081\uc740 \ubaa9\ud45c \ub370\uc774\ud130\uc785\ub2c8\ub2e4.  \uc815\ub958 \ud750\ub984\uc740 \uc77c\uc815\ud55c \uc18d\ub3c4\ub97c \uc720\uc9c0\ud558\uc5ec \ubcf4\ub2e4 \uac15\uac74\ud55c \ud559\uc2b5\uc744 \uac00\ub2a5\ud558\uac8c \ud558\uba70, \ubaa8\ub378 \ud6a8\uc728\uc131\uc744 \ub192\uc785\ub2c8\ub2e4 (Zhao et al., 2024).", "section": "3 PRELIMINARY: RECTIFIED FLOWS"}, {"figure_path": "https://arxiv.org/html/2502.02358/x3.png", "caption": "Figure 3. Illustration of our MotionLab and the detail of its MotionFlow Transformer (MFT).", "description": "\uadf8\ub9bc 3\uc740 \uc81c\uc548\ub41c MotionLab \ud504\ub808\uc784\uc6cc\ud06c\uc758 \uc804\uccb4 \uc544\ud0a4\ud14d\ucc98\uc640 MotionFlow Transformer (MFT) \ube14\ub85d\uc758 \uc138\ubd80 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MotionLab\uc740 Motion-Condition-Motion \ud328\ub7ec\ub2e4\uc784\uc744 \uae30\ubc18\uc73c\ub85c \ud558\uba70, \uc18c\uc2a4 \ubaa8\uc158, \uc870\uac74, \uadf8\ub9ac\uace0 \ud0c0\uac9f \ubaa8\uc158\uc758 \uc138 \uac00\uc9c0 \uac1c\ub150\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ud734\uba3c \ubaa8\uc158 \uc0dd\uc131 \ubc0f \ud3b8\uc9d1 \uc791\uc5c5\uc744 \ud1b5\ud569\ud569\ub2c8\ub2e4. MFT\ub294 \uc18c\uc2a4 \ubaa8\uc158\uc744 \uc870\uac74\uc5d0 \ub530\ub77c \ud0c0\uac9f \ubaa8\uc158\uc73c\ub85c \ub9e4\ud551\ud558\uae30 \uc704\ud574 \uc815\ub958 \ud750\ub984\uc744 \ud65c\uc6a9\ud569\ub2c8\ub2e4. \ub610\ud55c, \ub2e4\uc591\ud55c \ubaa8\ub4dc(\uc18c\uc2a4 \ubaa8\uc158, \ud0c0\uac9f \ubaa8\uc158, \ud14d\uc2a4\ud2b8, \uada4\uc801, \uc2a4\ud0c0\uc77c \ub4f1)\ub97c \ud1b5\ud569\ud558\uace0 \uc870\uac74\ubd80 \uc0dd\uc131 \ubc0f \ud3b8\uc9d1 \uae30\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \uacf5\ub3d9 \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uacfc \uc870\uac74 \uacbd\ub85c\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc815\ub82c\ub41c \ud68c\uc804 \uc704\uce58 \uc778\ucf54\ub529(Aligned ROPE)\uc744 \ud1b5\ud574 \uc18c\uc2a4 \ubaa8\uc158\uacfc \ud0c0\uac9f \ubaa8\uc158 \uac04\uc758 \uc2dc\uac04 \ub3d9\uae30\ud654\ub97c \ubcf4\uc7a5\ud569\ub2c8\ub2e4. \uc791\uc5c5 \uc9c0\uc2dc \ubcc0\uc870(Task Instruction Modulation)\ub294 \uac01 \uc791\uc5c5\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uc784\ubca0\ub529\uc744 \ub3c4\uc785\ud558\uc5ec \ub2e4\uc591\ud55c \uc791\uc5c5\uc744 \uc6d0\ud65c\ud558\uac8c \ud1b5\ud569\ud569\ub2c8\ub2e4. \uadf8\ub9bc (b)\ub294 MFT \ube14\ub85d\uc758 \ub0b4\ubd80 \uad6c\uc870\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uacf5\ub3d9 \uc5b4\ud150\uc158, \uc870\uac74 \uacbd\ub85c, \uc815\ub82c\ub41c ROPE\uc758 \uac01 \uad6c\uc131 \uc694\uc18c\uac00 \uc5b4\ub5bb\uac8c \uc0c1\ud638 \uc791\uc6a9\ud558\uace0 \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5 MOTIONLAB"}, {"figure_path": "https://arxiv.org/html/2502.02358/x4.png", "caption": "Figure 4. Qualitative results of MotionLab on the text-based motion generation. For clarity, as time progresses, motion sequences transit from light to dark colors.", "description": "\uadf8\ub9bc 4\ub294 MotionLab\uc744 \uc0ac\uc6a9\ud55c \ud14d\uc2a4\ud2b8 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud55c \uc0dd\uc131\ub41c \ubaa8\uc158 \uc2dc\ud000\uc2a4\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uc2dc\uac04\uc774 \uc9c0\ub0a8\uc5d0 \ub530\ub77c \ubaa8\uc158 \uc2dc\ud000\uc2a4\uac00 \ubc1d\uc740 \uc0c9\uc5d0\uc11c \uc5b4\ub450\uc6b4 \uc0c9\uc73c\ub85c \ubcc0\ud654\ud558\uc5ec \uc2dc\uac04 \uacbd\uacfc\uc5d0 \ub530\ub978 \ubaa8\uc158\uc758 \ubcc0\ud654\ub97c \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc774\ubbf8\uc9c0\ub294 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub530\ub77c \uc0dd\uc131\ub41c 3D \uce90\ub9ad\ud130\uc758 \ub3d9\uc791\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uba70, MotionLab\uc758 \ubaa8\uc158 \uc0dd\uc131 \ub2a5\ub825\uc744 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "6 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.02358/x5.png", "caption": "Figure 5. Qualitative results of MotionLab on the text-based motion editing. The transparent motion is the source motion, and the other is the generated motion.", "description": "\uadf8\ub9bc 5\ub294 MotionLab\uc744 \uc0ac\uc6a9\ud55c \ud14d\uc2a4\ud2b8 \uae30\ubc18 \ubaa8\uc158 \ud3b8\uc9d1\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud22c\uba85\ud55c \ubaa8\uc158\uc740 \uc18c\uc2a4 \ubaa8\uc158\uc774\uace0, \ub098\uba38\uc9c0 \ubaa8\uc158\uc740 \uc0dd\uc131\ub41c \ubaa8\uc158\uc785\ub2c8\ub2e4.  \uc989, \uc0ac\uc6a9\uc790\uac00 \ud14d\uc2a4\ud2b8\ub97c \uc785\ub825\ud558\uc5ec \uae30\uc874 \ubaa8\uc158\uc744 \uc218\uc815\ud558\ub294 \uc791\uc5c5\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc774\ubbf8\uc9c0\ub4e4\uc785\ub2c8\ub2e4. \uac01 \uc774\ubbf8\uc9c0\ub294 \uc18c\uc2a4 \ubaa8\uc158\uacfc \uc218\uc815\ub41c \ubaa8\uc158\uc744 \ube44\uad50\ud558\uc5ec \ud14d\uc2a4\ud2b8 \uc785\ub825\uc5d0 \ub530\ub978 \ubaa8\uc158 \ubcc0\ud654\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 MotionLab\uc774 \ud14d\uc2a4\ud2b8 \uba85\ub839\uc744 \uc815\ud655\ud558\uac8c \uc774\ud574\ud558\uace0 \ubaa8\uc158\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc218\uc815\ud558\ub294 \ub2a5\ub825\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5 MOTIONLAB"}, {"figure_path": "https://arxiv.org/html/2502.02358/x6.png", "caption": "Figure 6. Qualitative results of MotionLab on the trajectory-based motion generation. The red balls are the trajectory of the pelvis, right hand and right foot.", "description": "\uadf8\ub9bc 6\uc740 MotionLab\uc774 \uada4\uc801 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131 \uc791\uc5c5\uc5d0\uc11c \ubcf4\uc5ec\uc8fc\ub294 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube68\uac04\uc0c9 \uacf5\uc740 \uace8\ubc18, \uc624\ub978\uc190, \uc624\ub978\ubc1c\uc758 \uada4\uc801\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 MotionLab\uc774 \uc8fc\uc5b4\uc9c4 \uada4\uc801\uc744 \ub530\ub77c \uc0ac\ub78c\uc758 \uc6c0\uc9c1\uc784\uc744 \uc0dd\uc131\ud558\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc6c0\uc9c1\uc784\uc740 \uada4\uc801\uc758 \uc815\ud655\uc131\uacfc \uc790\uc5f0\uc2a4\ub7ec\uc6c0\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \ub2e4\uc591\ud55c \uc790\uc138\uc640 \ub3d9\uc791\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \uc2dc\uac01\uc801 \uc608\uc2dc\ub294 MotionLab\uc758 \uc131\ub2a5\uacfc \uada4\uc801 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131 \uc791\uc5c5\uc758 \ud6a8\uc728\uc131\uc744 \ub354 \uc798 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "6 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.02358/x7.png", "caption": "Figure 7. Comparison of the motion in-between with CondMDI (Cohan et\u00a0al., 2024) on HumanML3D (Guo et\u00a0al., 2022a), which shows that our model outperforms CondMDI.", "description": "\uadf8\ub9bc 7\uc740 \uc81c\uc548\ub41c \ubaa8\ub378\uacfc CondMDI \ubaa8\ub378\uc758 HumanML3D \ub370\uc774\ud130\uc14b \uae30\ubc18 \ubaa8\uc158 \uc911\uac04 \uc0dd\uc131 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CondMDI\ub294 \uae30\uc874\uc758 \ubaa8\uc158 \uc911\uac04 \uc0dd\uc131 \ubaa8\ub378\uc774\uba70, \ubcf8 \ub17c\ubb38\uc758 \ubaa8\ub378\uc740 \uc0c8\ub86d\uac8c \uc81c\uc548\ub41c \ubaa8\ub378\uc785\ub2c8\ub2e4.  \uadf8\ub9bc\uc740 FID(Fr\u00e9chet Inception Distance), \ud3c9\uade0 \uc624\ucc28, R-precision, \ub2e4\uc591\uc131, \ubc1c \uc2a4\ucf00\uc774\ud305 \ube44\uc728 \ub4f1 \ub2e4\uc591\ud55c \uc9c0\ud45c\ub97c \ud1b5\ud574 \ub450 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c, \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ub41c \ubaa8\ub378\uc774 CondMDI\ubcf4\ub2e4 \ubaa8\ub4e0 \uc9c0\ud45c\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub294 \uc81c\uc548\ub41c \ubaa8\ub378\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uc2e4\ud5d8 \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "6 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2502.02358/extracted/6183938/Figure/style.png", "caption": "Figure 8. Comparison of the motion style transfer with MCM-LDM (Song et\u00a0al., 2024) on a subset of HumanML3D (Guo et\u00a0al., 2022a). This shows that our model has a stronger ability to preserve the semantics of source motion and a stronger ability to learn the style of style motion.", "description": "\uadf8\ub9bc 8\uc740 HumanML3D \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80\ubd84\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc81c\uc548\ub41c MotionLab \ubaa8\ub378\uacfc MCM-LDM \ubaa8\ub378\uc758 \ubaa8\uc158 \uc2a4\ud0c0\uc77c \uc804\uc774 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub450 \ubaa8\ub378 \ubaa8\ub450 \uc18c\uc2a4 \ubaa8\uc158\uc758 \uc758\ubbf8\ub97c \uc720\uc9c0\ud558\uba74\uc11c \uc2a4\ud0c0\uc77c\uc744 \ubcc0\ud658\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uacb0\uacfc\ub294 MotionLab \ubaa8\ub378\uc774 \uc18c\uc2a4 \ubaa8\uc158\uc758 \uc758\ubbf8\ub97c \ub354 \uc798 \ubcf4\uc874\ud558\uba74\uc11c \ub3d9\uc2dc\uc5d0 \uc2a4\ud0c0\uc77c \ubaa8\uc158\uc758 \uc2a4\ud0c0\uc77c\uc744 \ub354 \ud6a8\uacfc\uc801\uc73c\ub85c \ud559\uc2b5\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, MotionLab\uc740 \uc6d0\ubcf8 \ub3d9\uc791\uc758 \ud2b9\uc9d5\uc744 \ub354 \uc798 \uc720\uc9c0\ud558\uba74\uc11c \uc2a4\ud0c0\uc77c\uc744 \uc804\uc774\ud558\ub294 \uc131\ub2a5\uc774 \ub354 \uc6b0\uc218\ud568\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "6.3 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2502.02358/x8.png", "caption": "Figure 9. Ablation results of MotionLab on the motion in-between. Beige motion is use 1D-learnable position encoding, purple motion use Aligned ROPE, and gray motions are the poses provided in keyframes, demonstrating the importance of Aligned ROPE.", "description": "\uadf8\ub9bc 9\ub294 MotionLab\uc758 \ubaa8\uc158 \uc911\uac04\uc0bd\uc785 \uc791\uc5c5\uc5d0 \ub300\ud55c ablation \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubca0\uc774\uc9c0\uc0c9 \ubaa8\uc158\uc740 1D \ud559\uc2b5 \uac00\ub2a5\ud55c \uc704\uce58 \uc778\ucf54\ub529\uc744 \uc0ac\uc6a9\ud558\uace0, \ubcf4\ub77c\uc0c9 \ubaa8\uc158\uc740 \uc815\ub82c\ub41c ROPE(Rotational Position Encoding)\uc744 \uc0ac\uc6a9\ud558\uba70, \ud68c\uc0c9 \ubaa8\uc158\uc740 \ud0a4\ud504\ub808\uc784\uc5d0\uc11c \uc81c\uacf5\ub41c \ud3ec\uc988\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc815\ub82c\ub41c ROPE\uc758 \uc911\uc694\uc131\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uc815\ub82c\ub41c ROPE\ub97c \uc0ac\uc6a9\ud55c \ubcf4\ub77c\uc0c9 \ubaa8\uc158\uc774 \ub2e4\ub978 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub354 \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc815\ud655\ud55c \uc911\uac04 \ubaa8\uc158\uc744 \uc0dd\uc131\ud568\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  1D \ud559\uc2b5 \uac00\ub2a5\ud55c \uc704\uce58 \uc778\ucf54\ub529\uc740 \uc2dc\uac04\uc801 \uc815\ub82c\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \ubc18\uba74, \uc815\ub82c\ub41c ROPE\ub294 \uc18c\uc2a4 \ubaa8\uc158\uacfc \ud0c0\uac9f \ubaa8\uc158 \uac04\uc758 \uc2dc\uac04\uc801 \ub3d9\uae30\ud654\ub97c \ub354 \uc798 \uc720\uc9c0\ud558\uc5ec \ub354\uc6b1 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uc911\uac04 \ubaa8\uc158\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "6.3 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2502.02358/extracted/6183938/Figure/timesteps.png", "caption": "Figure 10. Comparison of the inference time on text-based motion generation. We calculate AITS on the test set of HumanML3D (Guo et\u00a0al., 2022a) without model or data loading parts. All tests are performed on the same RTX 4090D. The closer the model\u2019s points are to the lower left corner, the stronger the model is.", "description": "\uadf8\ub9bc 10\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ub41c MotionLab \ubaa8\ub378\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec \ud14d\uc2a4\ud2b8 \uae30\ubc18 \ubaa8\uc158 \uc0dd\uc131 \ubaa8\ub378\ub4e4\uc758 \ucd94\ub860 \uc2dc\uac04\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  HumanML3D \ub370\uc774\ud130\uc14b\uc758 \ud14c\uc2a4\ud2b8\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378 \ubc0f \ub370\uc774\ud130 \ub85c\ub529 \uc2dc\uac04\uc744 \uc81c\uc678\ud558\uace0, \ub3d9\uc77c\ud55c RTX 4090D GPU\uc5d0\uc11c \ubaa8\ub4e0 \ubaa8\ub378\uc758 \ucd94\ub860 \uc2dc\uac04(AITS)\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub798\ud504\uc5d0\uc11c \uac01 \uc810\uc740 FID(Fr\u00e9chet Inception Distance, \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud3c9\uac00 \uc9c0\ud45c) \uac12\uacfc AITS \uac12\uc744 \ub098\ud0c0\ub0b4\uba70, \uc810\uc774 \uc67c\ucabd \uc544\ub798 \ubaa8\uc11c\ub9ac\uc5d0 \uac00\uae4c\uc6b8\uc218\ub85d FID \uac12\uc774 \ub0ae\uace0 AITS \uac12\uc774 \uc9e7\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc989, \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc6b0\uc218\ud558\uace0 \ucd94\ub860 \uc18d\ub3c4\uac00 \ube60\ub974\ub2e4\ub294 \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ub41c MotionLab \ubaa8\ub378\uc740 \ub0ae\uc740 FID \uac12\uacfc \ube60\ub978 AITS \uac12\uc744 \ub3d9\uc2dc\uc5d0 \ub2ec\uc131\ud558\uc5ec \uc6b0\uc218\ud55c \uc131\ub2a5\uacfc \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6 EXPERIMENTS"}]