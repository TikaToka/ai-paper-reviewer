{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is foundational for the Motion-Condition-Motion paradigm, providing inspiration from the next-token prediction paradigm that revolutionized NLP."}, {"fullname_first_author": "Nikos Athanasiou", "paper_title": "MotionFix: Text-Driven 3D Human Motion Editing", "publication_date": "2024-08-00", "reason": "This paper introduces text-based motion editing, which is extended in the current work to include trajectory-based editing, highlighting a key related concept."}, {"fullname_first_author": "Wenxun Dai", "paper_title": "MotionLCM: Real-time controllable motion generation via latent consistency model", "publication_date": "2025-00-00", "reason": "This paper proposes a state-of-the-art method for motion generation that is used as a baseline and compared against in the current research."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces diffusion models, a core technology used in the MotionLab framework for efficient and robust learning."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "This paper introduces rectified flow transformers, a key component of MotionLab that enables efficient and scalable mapping between source and target motion."}]}