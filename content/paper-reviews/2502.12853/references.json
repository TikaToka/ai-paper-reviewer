{"references": [{"fullname_first_author": "Aman Madaan", "paper_title": "Self-refine: Iterative refinement with self-feedback", "publication_date": "2024-XX-XX", "reason": "This paper introduces the concept of iterative refinement with self-feedback, which is directly related to the core idea of self-verification and self-correction in the target paper."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-XX-XX", "reason": "This is a foundational paper in reinforcement learning for language models, which is the core methodology used in the target paper for improving the reasoning capabilities of LLMs."}, {"fullname_first_author": "Xinyu Guan", "paper_title": "rstar-math: Small LLMs can master math reasoning with self-evolved deep thinking", "publication_date": "2025-01-04", "reason": "This paper is highly relevant as it explores enhancing the mathematical reasoning capabilities of smaller LLMs, which is directly comparable and competitive to the approach of the target paper."}, {"fullname_first_author": "Charlie Snell", "paper_title": "Scaling LLM test-time compute optimally can be more effective than scaling model parameters", "publication_date": "2024-08-03", "reason": "This paper discusses test-time scaling in LLMs, which is directly related to the efficiency goal of the target paper in improving LLM reasoning without extensive training."}, {"fullname_first_author": "Daya Guo", "paper_title": "DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning", "publication_date": "2025-01-12", "reason": "This paper is highly relevant as it also employs reinforcement learning to enhance LLM reasoning capabilities, offering a comparative approach and results to the target paper."}]}