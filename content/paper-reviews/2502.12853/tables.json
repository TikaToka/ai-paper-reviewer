[{"content": "| Base Model | Source | # Training Data |\n|---|---|---|\n| *Stage 1: Behavior Initialization* |  |  |\n| Llama-3.1-8B-Instruct | MATH | 4614 |\n| Qwen2-7B-Instruct | MATH | 4366 |\n| Qwen2.5-Math-7B | MATH | 3111 |\n| *Stage 2: Reinforcement Learning* |  |  |\n| Llama-3.1-8B-Instruct | MATH+GSM8K | 9601 |\n| Qwen2-7B-Instruct | MATH+GSM8K | 9601 |\n| Qwen2.5-Math-7B | MATH+OpenMath2.0 | 10000 |", "caption": "Table 1: Training data statistics.", "description": "\ubcf8 \ub17c\ubb38\uc758 \ud45c 1\uc740 \uc138 \uac00\uc9c0 \uae30\ubcf8 \ubaa8\ub378(Llama-3.1-8B-Instruct, Qwen2-7B-Instruct, Qwen2.5-Math-7B)\uc5d0 \ub300\ud55c \ud6c8\ub828 \ub370\uc774\ud130 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574, \ub370\uc774\ud130 \ucd9c\ucc98(MATH)\uc640 \ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30(# Training Data)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  S2R(Self-verification and Self-correction via Reinforcement Learning) \ud504\ub808\uc784\uc6cc\ud06c\uc758 1\ub2e8\uacc4(Behavior Initialization)\uc640 2\ub2e8\uacc4(Reinforcement Learning)\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud6c8\ub828 \ub370\uc774\ud130\ub97c \uad6c\ubd84\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3.1 Experiment Setup"}, {"content": "| Model | MATH | AIME | AMC | College Math | Olympiad Bench | GSM8K | GaokaoEn 2023 | Average |\n|---|---|---|---|---|---|---|---|---|\n| **Datasets** |  |  |  |  |  |  |  |  |\n| **Frontier LLMs** |  |  |  |  |  |  |  |  |\n| GPT-4o<sup>\u22c6</sup> | 76.6 | 9.3 | 47.5 | 48.5 | 43.3 | 92.9 | 67.5 | 55.1 |\n| Claude3.5-Sonnet<sup>\u22c6</sup> | 78.3 | 16.0 | - | - | - | 96.4 | - | - |\n| GPT-o1-preview<sup>\u22c6</sup> | 85.5 | 44.6 | 90.0 | - | - | - | - | - |\n| GPT-o1-mini<sup>\u22c6</sup> | 90.0 | 56.7 | 95.0 | 57.8 | 65.3 | 94.8 | 78.4 | 76.9 |\n| **Top-tier Open-source Reasoning LLMs** |  |  |  |  |  |  |  |  |\n| Mathstral-7B-v0.1<sup>\u22c6</sup> | 57.8 | 0.0 | 37.5 | 33.7 | 21.5 | 84.9 | 46.0 | 40.2 |\n| NuminaMath-72B-CoT<sup>\u22c6</sup> | 64.0 | 3.3 | 70.0 | 39.7 | 32.6 | 90.8 | 58.4 | 51.3 |\n| LLaMA3.1-70B-Instruct<sup>\u22c6</sup> | 65.4 | 23.3 | 50.0 | 42.5 | 27.7 | 94.1 | 54.0 | 51.0 |\n| Qwen2.5-Math-72B-Instruct<sup>\u22c6</sup> | 85.6 | 30.0 | 70.0 | 49.5 | 49.0 | 95.9 | 71.9 | 64.6 |\n| **General Model: Llama-3.1-8B-Instruct** |  |  |  |  |  |  |  |  |\n| Llama-3.1-8B-Instruct | 48.0 | 6.7 | 30.0 | 30.8 | 15.6 | 84.4 | 41.0 | 36.6 |\n| Llama-3.1-8B-Instruct + Original Solution SFT | 31.0 | 3.3 | 7.5 | 22.0 | 8.0 | 58.7 | 28.3 | 22.7 |\n| Llama-3.1-8B-Instruct + Long CoT SFT | 51.4 | 6.7 | 27.5 | 36.3 | 19.0 | 87.0 | 48.3 | 39.5 |\n| **Llama-3.1-8B-S<sup>2</sup>r-BI (ours)** | 49.6 | 10.0 | 20.0 | 33.3 | 17.6 | 85.3 | 41.0 | 36.7 |\n| **Llama-3.1-8B-S<sup>2</sup>r-PRL (ours)** | 53.6 | 6.7 | 25.0 | 33.7 | 18.5 | 86.7 | 43.1 | 38.2 |\n| **Llama-3.1-8B-S<sup>2</sup>r-ORL (ours)** | 55.0 | 6.7 | 32.5 | 34.7 | 20.7 | 87.3 | 45.2 | 40.3 |\n| **General Model: Qwen2-7B-Instruct** |  |  |  |  |  |  |  |  |\n| Qwen2-7B-Instruct | 51.2 | 3.3 | 30.0 | 18.2 | 19.1 | 86.4 | 39.0 | 35.3 |\n| Qwen2-7B-Instruct + Original Solution SFT | 41.2 | 0.0 | 25.0 | 30.1 | 10.2 | 74.5 | 34.8 | 30.8 |\n| Qwen2-7B-Instruct + Long CoT SFT | 60.4 | 6.7 | 32.5 | 36.3 | 23.4 | 81.2 | 53.5 | 42.0 |\n| **Qwen2-7B-S<sup>2</sup>r-BI (ours)** | 61.2 | 3.3 | 27.5 | 41.1 | 27.1 | 87.4 | 49.1 | 42.4 |\n| **Qwen2-7B-S<sup>2</sup>r-PRL (ours)** | 65.4 | 6.7 | 35.0 | 36.7 | 27.0 | 89.0 | 49.9 | 44.2 |\n| **Qwen2-7B-S<sup>2</sup>r-ORL (ours)** | 64.8 | 3.3 | 42.5 | 34.7 | 26.2 | 86.4 | 50.9 | 44.1 |\n| **Math-Specialized Model: Qwen2.5-Math-7B** |  |  |  |  |  |  |  |  |\n| Qwen2.5-Math-7B | 51.0 | 16.7 | 45.0 | 21.5 | 16.7 | 58.3 | 39.7 | 35.6 |\n| Qwen2.5-Math-7B-Instruct | 83.2 | 13.3 | 72.5 | 47.0 | 40.4 | 95.6 | 67.5 | 59.9 |\n| Eurus-2-7B-PRIME<sup>\u22c6</sup> | 79.2 | 26.7 | 57.8 | 45.0 | 42.1 | 88.0 | 57.1 | 56.6 |\n| rStar-Math-7B<sup>\u22c6</sup> | 78.4 | 26.7 | 47.5 | 52.5 | 47.1 | 89.7 | 65.7 | 58.2 |\n| Qwen2.5-Math-7B + Original Solution SFT | 58.0 | 6.7 | 42.5 | 35.8 | 20.0 | 79.5 | 51.9 | 42.1 |\n| Qwen2.5-Math-7B + Long CoT SFT | 80.2 | 16.7 | 60.0 | 49.6 | 42.1 | 91.4 | 69.1 | 58.4 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-BI (ours)** | 81.6 | 23.3 | 60.0 | 43.9 | 44.4 | 91.9 | 70.1 | 59.3 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-PRL (ours)** | 83.4 | 26.7 | 70.0 | 43.8 | 46.4 | 93.2 | 70.4 | 62.0 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-ORL (ours)** | 84.4 | 23.3 | 77.5 | 43.8 | 44.9 | 92.9 | 70.1 | 62.4 |", "caption": "Table 2: The performance of S2r and other strong baselines on the most challenging math benchmarks is presented. BI refers to the behavior-initialized models through supervised fine-tuning, ORL denotes models trained with outcome-level RL, and PRL refers to models trained with process-level RL. The highest results are highlighted in bold and the second-best results are marked with underline. For some baselines, we use the results from their original reports or from Guan et\u00a0al. (2025), denoted by \u2217.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \uc218\ud559 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c S2R \ubc0f \uae30\ud0c0 \uac15\ub825\ud55c \uae30\uc900 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  BI\ub294 \uc9c0\ub3c4 \ud559\uc2b5 \ubbf8\uc138 \uc870\uc815\uc744 \ud1b5\ud574 \ub3d9\uc791\uc744 \ucd08\uae30\ud654\ud55c \ubaa8\ub378\uc744 \ub098\ud0c0\ub0b4\uace0, ORL\uc740 \uacb0\uacfc \uc218\uc900 \uac15\ud654 \ud559\uc2b5\uc73c\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc744, PRL\uc740 \uacfc\uc815 \uc218\uc900 \uac15\ud654 \ud559\uc2b5\uc73c\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac00\uc7a5 \ub192\uc740 \uacb0\uacfc\ub294 \uad75\uac8c \ud45c\uc2dc\ud558\uace0, \ub450 \ubc88\uc9f8\ub85c \ub192\uc740 \uacb0\uacfc\ub294 \ubc11\uc904\uc774 \uadf8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. \uc77c\ubd80 \uae30\uc900 \ubaa8\ub378\uc758 \uacbd\uc6b0 Guan et al.(2025)\uc758 \uc6d0\ub798 \ubcf4\uace0\uc11c\uc758 \uacb0\uacfc\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc218\ud559\uc801 \ucd94\ub860 \ub2a5\ub825\uc744 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ud3c9\uac00\ud558\uc5ec S2R\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Model | FOLIO | CRUX-Eval | Strategy-QA | MMLUPro-STEM |\n|---|---|---|---|---|\n| Qwen2.5-Math-72B-Instruct | 69.5 | 68.6 | 94.3 | 66.0 |\n| Llama-3.1-70B-Instruct<sup>\u2217</sup> | 65.0 | 59.6 | 88.8 | 61.7 |\n| OpenMath2-Llama3.1-70B<sup>\u2217</sup> | 68.5 | 35.1 | 95.6 | 55.0 |\n| QwQ-32B-Preview<sup>\u2217</sup> | 84.2 | 65.2 | 88.2 | 71.9 |\n| Eurus-2-7B-PRIME | 56.7 | 50.0 | 79.0 | 53.7 |\n| Qwen2.5-Math-7B-Instruct | 61.6 | 28.0 | 81.2 | 44.7 |\n| Qwen2.5-Math-7B | 37.9 | 40.8 | 61.1 | 46.0 |\n| Qwen2.5-Math-7B-S<sup>2</sup>r-BI (ours) | 58.1 | 48.0 | 88.7 | 49.8 |\n| Qwen2.5-Math-7B-S<sup>2</sup>r-ORL (ours) | 61.6 | 50.9 | 90.8 | 50.0 |", "caption": "Table 3: Performance of the proposed method and the baseline methods on 4 cross-domain tasks. The results with \u2217 are reported by Shen et\u00a0al. (2025).", "description": "\ud45c 3\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \uae30\uc900 \ubc29\ubc95\uc758 4\uac00\uc9c0 \uad50\ucc28 \ub3c4\uba54\uc778 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc81c\uc548\ub41c S2R \ubc29\ubc95\uc740 \ub2e4\uc591\ud55c \uae30\uc900 \ubaa8\ub378\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, Qwen2.5-Math-7B \ubaa8\ub378\uc5d0\uc11c\ub294 MATH500\uacfc GSM8K\uc5d0\uc11c \uae30\uc900 \ubaa8\ub378\uc744 \uac01\uac01 32.2%\uc640 34.3% \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \ub610\ud55c, S2R\uc740 \ub3d9\uc77c\ud55c \uae30\uc900 \ubaa8\ub378\uc5d0\uc11c \ud30c\uc0dd\ub41c \uae30\uc900 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub300\ubd80\ubd84\uc758 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ud765\ubbf8\ub86d\uac8c\ub3c4, S2R\uc740 \ucd5c\uadfc \uc81c\uc548\ub41c \uacbd\uc7c1\ub825 \uc788\ub294 \uae30\uc900 \ubc29\ubc95\ub4e4(Eurus-2-7B-PRIME, rStar-Math-7B, Qwen2.5-7B-SimpleRL)\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 S2R\uc774 \ub370\uc774\ud130 \uad6c\uc131\uacfc \ubcf4\uc0c1 \ubaa8\ub378\ub9c1\uc5d0 \ub300\ud55c \ub178\ub825\uc744 \uc904\uc774\uace0 \ud6a8\uc728\uc131\uc744 \ub192\uc778\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \ub3d9\uc77c\ud55c \uaddc\ubaa8\uc758 SFT \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec S2R\uc740 QwQ-32B-Preview\uc5d0\uc11c \ucd94\ucd9c\ub41c \uc7a5\uae30 CoT \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294\ub370, \uc774\ub294 \uc791\uc740 LLMs\uc5d0\uc11c \uc790\uccb4 \uac80\uc99d \ubc0f \uc790\uccb4 \uc218\uc815\uc744 \ubc30\uc6b0\ub294 \uac83\uc774 \uc7a5\uae30 CoT\uc758 \ud6a8\uacfc\uc801\uc778 \ub300\uc548\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0 \uc81c\uc2dc\ub41c \uacb0\uacfc\ub294 Shen et al.(2025)\uc5d0 \ubcf4\uace0\ub41c \uacb0\uacfc\ub97c \ud3ec\ud568\ud558\uc5ec \uc5ec\ub7ec \ucd9c\ucc98\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4.", "section": "3.3 \uad50\ucc28 \ub3c4\uba54\uc778 \uc791\uc5c5 \uc77c\ubc18\ud654"}, {"content": "| Base Model | Methods | Overall Verification Acc. | Initial Verification Acc. |\n|---|---|---|---| \n| **<br>Llama3.1-8B-Instruct** | Problem-solving | 80.10 | 87.28 |\n|  | Confirmative | 65.67 | 77.27 |\n| **<br>Qwen2-7B-Instruct** | Problem-solving | 73.28 | 90.24 |\n|  | Confirmative | 58.31 | 76.16 |\n| **<br>Qwen2.5-Math-7B** | Problem-solving | 77.25 | 91.21 |\n|  | Confirmative | 61.58 | 82.80 |", "caption": "Table 4: Comparison of problem-solving and confirmative verification.", "description": "\ubcf8 \ud45c\ub294 \ubb38\uc81c \ud574\uacb0 \ubc29\uc2dd\uacfc \ud655\uc778 \ubc29\uc2dd\uc758 \ub450 \uac00\uc9c0 \uac80\uc99d \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubb38\uc81c \ud574\uacb0 \ubc29\uc2dd\uc740 \ubb38\uc81c\ub97c \ub2e4\uc2dc \ud480\uc5b4\uc11c \ub2f5\uc744 \ud655\uc778\ud558\ub294 \ubc29\uc2dd\uc774\uace0, \ud655\uc778 \ubc29\uc2dd\uc740 \uae30\uc874 \ub2f5\uc758 \uc815\ud655\uc131\uc744 \ub2e4\ub978 \uad00\uc810\uc5d0\uc11c \ud3c9\uac00\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubc29\uc2dd\uc758 \uc804\uccb4 \uac80\uc99d \uc815\ud655\ub3c4\uc640 \ucd08\uae30 \ub2f5\uc774 \ub9de\uc558\uc744 \ub54c\uc640 \ud2c0\ub838\uc744 \ub54c\uc758 \ucd08\uae30 \uac80\uc99d \uc815\ud655\ub3c4\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \uae30\ubcf8 \ubaa8\ub378(Llama-3.1-8B-Instruct, Qwen2-7B-Instruct, Qwen2.5-Math-7B)\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.4.1 Problem-solving v.s. Confirmative Verification"}, {"content": "| Model | MATH 500 | AIME 2024 | AMC 2023 | College Math | Olympiad Bench | GSM8K | GaokaoEn 2023 |\n|---|---|---|---|---|---|---|---| \n| **Datasets** |  |  |  |  |  |  |  |\n| **General Model: Qwen2-7B-Instruct** |  |  |  |  |  |  |  |\n| Qwen2-7B-Instruct | 51.2 | 3.3 | 30.0 | 18.2 | 19.1 | 86.4 | 39.0 | 35.3 |\n| **Qwen2-7B-S<sup>2</sup>r-BI (ours)** | 61.2 | 3.3 | 27.5 | **41.1** | **27.1** | 87.4 | 49.1 | 42.4 |\n| **Qwen2-7B-S<sup>2</sup>r-PRL (ours)** | **65.4** | <ins>6.7</ins> | 35.0 | 36.7 | <ins>27.0</ins> | **89.0** | <ins>49.9</ins> | <ins>44.2</ins> |\n| **Qwen2-7B-S<sup>2</sup>r-ORL (ours)** | <ins>64.8</ins> | 3.3 | **42.5** | 34.7 | 26.2 | 86.4 | **50.9** | 44.1 |\n| **Qwen2-7B\u2013Instruct-S<sup>2</sup>r-PRL-offline (ours)** | 61.6 | **10.0** | 32.5 | 40.2 | 26.5 | <ins>87.6</ins> | 50.4 | 44.1 |\n| **Qwen2-7B-Instruct-S<sup>2</sup>r-ORL-offline (ours)** | 61.0 | <ins>6.7</ins> | <ins>37.5</ins> | <ins>40.5</ins> | 27.3 | 87.4 | 49.6 | **44.3** |\n| **Math-Specialized Model: Qwen2.5-Math-7B** |  |  |  |  |  |  |  |  |\n| Qwen2.5-Math-7B | 51.0 | 16.7 | 45.0 | 21.5 | 16.7 | 58.3 | 39.7 | 35.6 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-BI (ours)** | 81.6 | <ins>23.3</ins> | 60.0 | 43.9 | 44.4 | 91.9 | 70.1 | 59.3 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-PRL (ours)** | <ins>83.4</ins> | **26.7** | <ins>70.0</ins> | 43.8 | <ins>46.4</ins> | **93.2** | <ins>70.4</ins> | <ins>62.0</ins> |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-ORL (ours)** | **84.4** | 23.3 | **77.5** | 43.8 | 44.9 | <ins>92.9</ins> | 70.1 | **62.4** |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-PRL-offline (ours)** | <ins>83.4</ins> | <ins>23.3</ins> | 62.5 | **50.0** | **46.7** | <ins>92.9</ins> | **72.2** | 61.6 |\n| **Qwen2.5-Math-7B-S<sup>2</sup>r-ORL-offline (ours)** | 82.0 | 20.0 | 67.5 | <ins>49.8</ins> | 45.8 | 92.6 | <ins>70.4</ins> | 61.2 |", "caption": "Table 5: Comparison of S2r using online and offline RL training.", "description": "\ud45c 5\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 S2R \uae30\ubc95\uc5d0 \ub300\ud574 \uc628\ub77c\uc778 \uac15\ud654 \ud559\uc2b5\uacfc \uc624\ud504\ub77c\uc778 \uac15\ud654 \ud559\uc2b5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc628\ub77c\uc778 \ud559\uc2b5\uacfc \uc624\ud504\ub77c\uc778 \ud559\uc2b5 \ubaa8\ub450\uc5d0\uc11c S2R\uc758 \ud6a8\uacfc\ub97c \ud655\uc778\ud558\uace0,  \ub450 \ud559\uc2b5 \ubc29\uc2dd \uac04\uc758 \ucc28\uc774\uc810\uacfc \uc7a5\ub2e8\uc810\uc744 \ubd84\uc11d\ud558\uc5ec \uc624\ud504\ub77c\uc778 \ud559\uc2b5\uc758 \ud6a8\uc728\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4\uc640 \ud3c9\uade0 \uc2dc\ud589 \ud69f\uc218\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uc624\ud504\ub77c\uc778 \uac15\ud654\ud559\uc2b5\uc758 \uc2e4\uc6a9\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.5 \uc624\ud504\ub77c\uc778 RL \ud0d0\uc0c9"}, {"content": "| Without Asking for Confirmative Verification | Asking for Confirmative Verification |\n|---|---|---|\n| Model | Confirmative out of 100 | Confirmative out of 100 |\n| GPT-4o | 26 | 44 |\n| GPT-4-Preview-1106 | 32 | 61 |\n| QwQ-32B-preview | 37 | 58 |\n| Llama-3.1-70B-Instruct | 28 | 50 |", "caption": "Table 6:", "description": "\ud45c 6\uc740 \ubaa8\ub378\uc774 \uc790\uccb4\uc801\uc73c\ub85c \uac80\uc99d\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 '\ubb38\uc81c \ud574\uacb0' \ubc29\uc2dd\uacfc '\ud655\uc778' \ubc29\uc2dd \ub450 \uac00\uc9c0 \uac80\uc99d \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\uc2dd\uc5d0 \ub300\ud55c \uc804\ubc18\uc801\uc778 \uc815\ud655\ub3c4\uc640 \ucd08\uae30 \uc751\ub2f5\uc774 \uc815\ub2f5\uc77c \ub54c\uc640 \uc624\ub2f5\uc77c \ub54c\uc758 \ucd08\uae30 \uac80\uc99d \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uac01 \ubc29\uc2dd\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574, \ubaa8\ub378\uc758 \uc790\uccb4 \uac80\uc99d \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud55c \ucd5c\uc801\uc758 \uc811\uadfc \ubc29\uc2dd\uc744 \uc120\ud0dd\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.4.1 \ubb38\uc81c \ud574\uacb0 \ubc29\uc2dd\uacfc \ud655\uc778 \ubc29\uc2dd \uac80\uc99d \ube44\uad50"}, {"content": "| Model | Learning Rate | Batch Size | KL Coefficient | Max Length | Training Epochs |\n|---|---|---|---|---|---| \n| Llama-3.1-8B-Instruct | 5e-6 | 32 | 0.1 | 8000 | 3 |\n| Qwen2-7B-Instruct | 5e-6 | 32 | 0.1 | 6000 | 3 |\n| Qwen2.5-Math-7B | 5e-6 | 32 | 0.01 | 8000 | 3 |", "caption": "Table 7: Model Training Hyperparameter Settings (SFT)", "description": "\ubcf8 \ud45c\ub294 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uc124\uc815 \ubd80\ubd84\uc5d0 \uc788\ub294 \ud45c 7\uc774\uba70, \uc9c0\ub3c4 \ud559\uc2b5 \ubc29\uc2dd(Supervised Fine-tuning)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0ac \ub54c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uac12\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \uae30\ubcf8 \ubaa8\ub378(Llama-3.1-8B-Instruct, Qwen2-7B-Instruct, Qwen2.5-Math-7B)\uc5d0 \ub300\ud574 \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30, KL \uacc4\uc218, \ucd5c\ub300 \uae38\uc774, \ud559\uc2b5 \uc5d0\ud3ed \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uc124\uc815\uac12\ub4e4\uc740 \uac01 \ubaa8\ub378\uc758 \ud2b9\uc131\uacfc \ud559\uc2b5 \ubaa9\ud45c\uc5d0 \ub9de\ucdb0 \uc870\uc815\ub418\uc5c8\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.1 Experiment Setup"}, {"content": "| Model | Learning Rate | Training Batch Size | Forward Batch Size | KL Coefficient | Max Length | Sampling Temperature | Clip Range | Training Steps |\n|---|---|---|---|---|---|---|---|---|\n| Llama-3.1 | 5e-7 | 64 | 256 | 0.05 | 8000 | 0.7 | 0.2 | 500 |\n| Qwen2-7B-Instruct | 5e-7 | 64 | 256 | 0.05 | 6000 | 0.7 | 0.2 | 500 |\n| Qwen2.5-Math-7B | 5e-7 | 64 | 256 | 0.01 | 8000 | 0.7 | 0.2 | 500 |", "caption": "Table 8: Model Training Hyperparameter Settings (RL)", "description": "\ubcf8 \ud45c\ub294 \uac15\ud654 \ud559\uc2b5(Reinforcement Learning)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0ac \ub54c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378 \ud559\uc2b5 \uc124\uc815\uc5d0\uc11c \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30, KL \uacc4\uc218, \ucd5c\ub300 \uae38\uc774, \uc0d8\ud50c\ub9c1 \uc628\ub3c4, \ud074\ub9bd \ubc94\uc704, \ud6c8\ub828 \ub2e8\uacc4 \ub4f1 \ub2e4\uc591\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uae30\ubcf8 \ubaa8\ub378\uc5d0 \ub300\ud55c \uac15\ud654 \ud559\uc2b5 \ud6c8\ub828\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "The below is the Markdown format of the given HTML table.\n\n| Variable | Description |\n|---|---| \n| \u03c0 | The policy |\n| x | Problem instance |\n| y | Series of predefined actions:  y={a<sub>1</sub>,a<sub>2</sub>,\u2026,a<sub>n</sub>} |\n| a<sub>i</sub> | The i-th action in the response y, and let |\n|  | Type(a<sub>i</sub>)\u2208{verify,solve,&lt;end&gt;} |\n| s<sub>j</sub> | j<sup>th</sup> attempt to solve the problem |\n| v<sub>j</sub> | j<sup>th</sup> self-verification for the j<sup>th</sup> attempt |\n|  | The text parser to get the self-verification result |\n|  | indicating the correctness of action s<sub>j</sub> |\n| V<sub>golden</sub>(\u22c5) |  V<sub>golden</sub>(a<sub>i</sub>)\u2208{correct,incorrect} |\n| R(\u22c5) | The rule based reward function |\n|  | R(\u22c5)\u2208{-1,1} |\n|  | R(s<sub>j</sub>) = { 1, & V<sub>golden</sub>(s<sub>j</sub>)=correct<br> -1, otherwise } |\n|  | R(v<sub>j</sub>) = { 1, & Parser(v<sub>j</sub>)=V<sub>golden</sub>(s<sub>j</sub>)<br> -1, otherwise } |\n| <end> | End of action series |\n| \ud835\udd40(\u22c5) | The indicator function, \ud835\udd40(\u22c5)\u2208{0,1}.<br> \ud835\udd40(\u22c5)=1 if the condition inside holds true, and \ud835\udd40(\u22c5)=0 otherwise. |", "caption": "Table 9: Variable Lookup Table", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \ubc29\ubc95\ub860 \uc139\uc158\uc5d0 \uc788\ub294 \ud45c 9\ub85c, \uac15\ud654 \ud559\uc2b5\uc744 \ud1b5\ud574 LLMs\uc758 \uc790\uae30 \uac80\uc99d \ubc0f \uc790\uae30 \uc218\uc815 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 S2R \ud504\ub808\uc784\uc6cc\ud06c\uc5d0 \ub300\ud55c \uc124\uba85\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ubcc0\uc218\ub4e4\uc744 \uc815\uc758\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ubcc0\uc218\uc758 \uc774\ub984, \uc124\uba85, \uadf8\ub9ac\uace0 \ub370\uc774\ud130 \ud0c0\uc785\uc774 \uba85\uc2dc\ub418\uc5b4 \uc788\uc5b4, \uc774\ud6c4\uc758 \ubd84\uc11d \ubc0f \uacb0\uacfc \ud574\uc11d\uc5d0 \ud544\uc694\ud55c \uae30\ubcf8\uc801\uc778 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "2 Methodology"}, {"content": "| Accuracy Range | Retained Questions | MATH500 | AIME2024 | AMC2023 | College Math | Olympiad Bench | GSM8K | GaokaoEn2023 | Average |\n|---|---|---|---|---|---|---|---|---|---| \n| [0.1-0.7] | 1805 | 83.4 | 23.3 | 62.5 | 50.0 | 46.7 | 92.9 | 72.2 | 61.6 |\n| [0.2-0.8] | 2516 | 82.6 | 23.3 | 70.0 | 49.8 | 45.3 | 92.4 | 70.1 | 61.9 |\n| [0.3-0.9] | 4448 | 81.6 | 23.3 | 70.0 | 49.4 | 44.7 | 92.0 | 68.1 | 61.3 |\n| [0-1] | Full | 80.6 | 26.7 | 67.5 | 50.0 | 43.0 | 91.4 | 67.0 | 60.9 |", "caption": "Table 10: Comparison of question filtering accuracy selection.", "description": "\ud45c 10\uc740 \uc9c8\ubb38 \ud544\ud130\ub9c1 \uc815\ud655\ub3c4 \uc120\ud0dd\uc5d0 \ub300\ud55c \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc815\ud655\ub3c4 \ubc94\uc704\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc9c8\ubb38\uc744 \ud544\ud130\ub9c1\ud588\uc744 \ub54c MATH500, AIME2024, AMC2023, College Math, Olympiad Bench, GSM8K, GaokaoEn2023 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. \uac01 \ubc94\uc704\ubcc4\ub85c \uc720\uc9c0\ub41c \uc9c8\ubb38\uc758 \uc218\uc640 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \uc81c\uc2dc\ud558\uc5ec \uc5b4\ub5a4 \uc815\ud655\ub3c4 \ubc94\uc704\uac00 \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  [0.1-0.7] \ubc94\uc704\uac00 \uac00\uc7a5 \uc548\uc815\uc801\uc778 \uacb0\uacfc\ub97c \ubcf4\uc774\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.5 Offline RL \ud0d0\uc0c9"}, {"content": "| Baseline Method | MATH500 | AIME2024 | AMC2023 | College Math | Olympiad Bench | GSM8K | GaokaoEn2023 | Average |\n|---|---|---|---|---|---|---|---|---|\n| **Based on reward context** | 82.4 | 26.7 | 65.0 | 50.1 | 46.1 | 92.9 | 71.2 | 62.1 |\n| **Based on accuracy group with position** | 83.4 | 23.3 | 62.5 | 50.0 | 46.7 | 92.9 | 72.2 | 61.6 |\n| **Based on accuracy group with reward context** | 82.4 | 23.3 | 67.5 | 49.3 | 45.8 | 93.3 | 71.2 | 61.8 |", "caption": "Table 11: The performance of different baselines", "description": "\ud45c 11\uc740 \ub2e4\uc591\ud55c \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ub2e4\ub978 \uae30\uc900 \ubaa8\ub378(Reward Context \uae30\ubc18, \uc704\uce58 \uae30\ubc18 \uc815\ud655\ub3c4 \uadf8\ub8f9, \ubcf4\uc0c1 \ucee8\ud14d\uc2a4\ud2b8 \uae30\ubc18 \uc815\ud655\ub3c4 \uadf8\ub8f9)\uc758 MATH500, AIME2024, AMC2023, \ub300\ud559 \uc218\ud559, \uc218\ud559 \uc62c\ub9bc\ud53c\uc544\ub4dc \ubca4\uce58\ub9c8\ud06c, GSM8K, GaokaoEn2023 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uac01 \uae30\uc900 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\uace0, \uc5b4\ub5a4 \ubc29\uc2dd\uc774 \ud2b9\uc815 \ub370\uc774\ud130\uc14b\uc5d0 \ub354 \ud6a8\uacfc\uc801\uc778\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ud6a8\uc728\uc801\uc778 \uac15\ud654 \ud559\uc2b5 \uc804\ub7b5\uc744 \uc120\ud0dd\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3.5 \uc624\ud504\ub77c\uc778 \uac15\ud654 \ud559\uc2b5 \ud0d0\uc0c9"}]