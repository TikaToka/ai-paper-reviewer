[{"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p1.png", "caption": "Figure 1: Accuracy-Length Relationship at Instance level. The relationship between length and accuracy varies significantly across problems, with peak accuracy occurring at short, medium, or long intervals. Notably, high accuracy often persists in shorter intervals.", "description": "\uadf8\ub9bc 1\uc740 \uac01 \ubb38\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4-\uae38\uc774 \uad00\uacc4\ub97c \uc778\uc2a4\ud134\uc2a4 \uc218\uc900\uc5d0\uc11c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc815\ud655\ub3c4\uc640 \uae38\uc774 \uac04\uc758 \uad00\uacc4\ub294 \ubb38\uc81c\ub9c8\ub2e4 \ud06c\uac8c \ub2ec\ub77c\uc9c0\uba70, \ucd5c\uace0 \uc815\ud655\ub3c4\ub294 \uc9e7\uc740, \uc911\uac04 \ub610\ub294 \uae34 \uac04\uaca9\uc5d0\uc11c \ub098\ud0c0\ub0a9\ub2c8\ub2e4. \ud2b9\ud788 \uc9e7\uc740 \uac04\uaca9\uc5d0\uc11c\ub3c4 \ub192\uc740 \uc815\ud655\ub3c4\uac00 \uc720\uc9c0\ub418\ub294 \uacbd\uc6b0\uac00 \ub9ce\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \uae34 \ucd94\ub860 \uacfc\uc815\uc744 \uac70\uce58\ub294 \ubaa8\ub378\uc774 \ud56d\uc0c1 \ub354 \ub098\uc740 \uc815\ud655\ub3c4\ub97c \uc81c\uacf5\ud558\ub294 \uac83\uc740 \uc544\ub2c8\uba70, \uc624\ud788\ub824 \uc9e7\uc740 \ucd94\ub860 \uacfc\uc815\uc5d0\uc11c\ub3c4 \ub192\uc740 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3. \uae34 \ucd94\ub860\uc5d0\uc11c\uc758 \uae38\uc774 \ubd88\uc77c\uce58"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p4.png", "caption": "Figure 2: Length-Harmonizing Fine-Tuning. During the training phase, for each problem, we sample multiple times from the reference model. Subsequently, we sample from the model to be optimized and compute the reward based on the reference samples, followed by a RL-style fine-tuning. During the inference phase, the model optimized through O1-Pruner demonstrates a significant improvement in inference speed, along with a noticeable enhancement in accuracy.", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c 01-Pruner \ubc29\ubc95\uc758 \ud559\uc2b5 \ubc0f \ucd94\ub860 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud559\uc2b5 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uac01 \ubb38\uc81c\uc5d0 \ub300\ud574 \uae30\uc900 \ubaa8\ub378(reference model)\uc5d0\uc11c \uc5ec\ub7ec \ubc88 \uc0d8\ud50c\ub9c1\ud558\uc5ec \ub2e4\uc591\ud55c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ucd5c\uc801\ud654\ud560 \ubaa8\ub378\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ud558\uc5ec \uae30\uc900 \ubaa8\ub378\uc758 \uc0d8\ud50c\ub4e4\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc0c1(reward)\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uac15\ud654 \ud559\uc2b5 \ubc29\uc2dd(RL-style fine-tuning)\uc744 \ud1b5\ud574 \ubaa8\ub378\uc774 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654\ud558\ub3c4\ub85d \ud559\uc2b5\ud569\ub2c8\ub2e4. \ucd94\ub860 \ub2e8\uacc4\uc5d0\uc11c\ub294 01-Pruner\ub97c \ud1b5\ud574 \ud559\uc2b5\ub41c \ubaa8\ub378\uc774 \ucd94\ub860 \uc18d\ub3c4\uac00 \ud6e8\uc52c \ube68\ub77c\uc9c0\uace0 \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/marco/p5.png", "caption": "Figure 3: Comparison of inference time-cost on MATH among different models and methods. O1-Pruner achieves the shortest inference times (slightly over 1 minute for Marco-o1-7B and \u00a04 minutes for QwQ-32B-Preview), demonstrating its effectiveness in accelerating long-thought model inference for both small and large long thought models.", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \ubaa8\ub378\uacfc \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec MATH \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd94\ub860 \uc2dc\uac04 \ube44\uc6a9\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. O1-Pruner\ub294 Marco-01-7B \ubaa8\ub378\uc758 \uacbd\uc6b0 1\ubd84 \uc57d\uac04 \ucd08\uacfc, QwQ-32B-Preview \ubaa8\ub378\uc758 \uacbd\uc6b0 4\ubd84\uc73c\ub85c \uac00\uc7a5 \uc9e7\uc740 \ucd94\ub860 \uc2dc\uac04\uc744 \ub2ec\uc131\ud558\uc5ec, \uc18c\ud615 \ubc0f \ub300\ud615 \uc7a5\uae30 \ucd94\ub860 \ubaa8\ub378 \ubaa8\ub450\uc5d0\uc11c \uc7a5\uae30 \ucd94\ub860 \ubaa8\ub378 \ucd94\ub860 \uc18d\ub3c4 \ud5a5\uc0c1\uc5d0 \ub300\ud55c \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub9c9\ub300 \uadf8\ub798\ud504\ub294 \uac01 \ubaa8\ub378\uacfc \ubc29\ubc95\uc5d0 \ub300\ud55c \ucd94\ub860 \uc2dc\uac04\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub9c9\ub300\uc758 \uae38\uc774\ub294 \ucd94\ub860 \uc2dc\uac04\uc5d0 \ube44\ub840\ud558\uba70, O1-Pruner\uac00 \ub2e4\ub978 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ud6e8\uc52c \uc9e7\uc740 \ucd94\ub860 \uc2dc\uac04\uc744 \uac00\uc9d0\uc744 \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.12570/extracted/6145807/rethink_figures/qwq/p0.png", "caption": "Figure 4:  Performance on MATH Test-set When Trained on Problems of Different Difficulty Levels. Models trained on more challenging datasets tend to generate longer solutions, while learning to solve harder problems enhances model accuracy. In contrast, for less challenging datasets, shorter solutions are produced without a corresponding accuracy improvement.", "description": "\uadf8\ub9bc 4\ub294 \ub2e4\uc591\ud55c \ub09c\uc774\ub3c4\uc758 \ubb38\uc81c\ub4e4\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\ub4e4\uc758 MATH \ud14c\uc2a4\ud2b8\uc14b \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub354 \uc5b4\ub824\uc6b4 \ubb38\uc81c\ub4e4\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc77c\uc218\ub85d \ub354 \uae34 \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc9c0\ub9cc, \uc5b4\ub824\uc6b4 \ubb38\uc81c\ub4e4\uc744 \ud478\ub294 \ub2a5\ub825\uc774 \ud5a5\uc0c1\ub418\uc5b4 \uc815\ud655\ub3c4 \ub610\ud55c \ub192\uc544\uc9d1\ub2c8\ub2e4. \ubc18\ub300\ub85c, \uc26c\uc6b4 \ubb38\uc81c\ub4e4\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\ub4e4\uc740 \ub2f5\ubcc0 \uae38\uc774\uac00 \uc9e7\uc544\uc9c0\uc9c0\ub9cc, \uc815\ud655\ub3c4 \ud5a5\uc0c1\uc740 \uc5c6\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc758 \ud559\uc2b5 \ub370\uc774\ud130 \ub09c\uc774\ub3c4\uc5d0 \ub530\ub77c \ub2f5\ubcc0 \uae38\uc774\uc640 \uc815\ud655\ub3c4 \uac04\uc758 \uc0c1\uad00\uad00\uacc4\uac00 \ub2e4\ub974\uac8c \ub098\ud0c0\ub0a8\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "6.2. \ub2e4\uc591\ud55c \ub09c\uc774\ub3c4\uc758 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc131\ub2a5"}]