{"references": [{"fullname_first_author": "OpenAI", "paper_title": "Learning to reason with LLMs", "publication_date": "2024-09-19", "reason": "This paper introduces the foundational long-thought reasoning model, O1, which is the focus of the current research."}, {"fullname_first_author": "Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2023-01-01", "reason": "This paper introduces the chain of thought prompting method, a crucial technique enabling enhanced reasoning capabilities in LLMs, which is directly relevant to the current work."}, {"fullname_first_author": "Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2024-05-01", "reason": "This paper introduces the DPO method, a competing method for LLM optimization, which is used as a comparison in the current paper."}, {"fullname_first_author": "Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "publication_date": "2023-05-01", "reason": "This paper explores advanced reasoning methods extending chain-of-thought, providing context for the current research's focus on improving reasoning efficiency."}, {"fullname_first_author": "Hendrycks", "paper_title": "Measuring mathematical problem solving with the MATH dataset", "publication_date": "2021-03-01", "reason": "This paper introduces the MATH dataset, a benchmark used in the current work for evaluating the performance of different reasoning models."}]}