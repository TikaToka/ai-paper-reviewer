{"references": [{"fullname_first_author": "Ankner, Z.", "paper_title": "Critique-out-loud reward models", "publication_date": "2024-08-11", "reason": "This paper is cited because it introduces a method for creating reward models for reinforcement learning, a technique relevant to test-time scaling."}, {"fullname_first_author": "Brown, B.", "paper_title": "Large language monkeys: Scaling inference compute with repeated sampling", "publication_date": "2024-07-21", "reason": "This paper is highly relevant due to its focus on scaling inference compute, a central theme of test-time scaling."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "DeepSeek-r1: Incentivizing reasoning capability in LLMs via reinforcement learning", "publication_date": "2025-01-12", "reason": "This work is among the most important because it successfully replicates OpenAI's results on test-time scaling and because it is a direct competitor to the current work."}, {"fullname_first_author": "Gao, L.", "paper_title": "Lessons from the trenches on reproducible evaluation of language models", "publication_date": "2024-00-00", "reason": "This paper offers important guidance on evaluating language models, which is vital for establishing the effectiveness of test-time scaling approaches."}, {"fullname_first_author": "OpenAI", "paper_title": "Learning to reason with LLMs", "publication_date": "2024-09-00", "reason": "This is one of the most important references because it is the seminal paper introducing test-time scaling as a new paradigm for language model improvement."}]}