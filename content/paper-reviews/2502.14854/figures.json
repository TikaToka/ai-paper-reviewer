[{"figure_path": "https://arxiv.org/html/2502.14854/x1.png", "caption": "Figure 1: Results on CLIPPER\u2019s test set and NoCha for baselines, small closed models, and CLIPPER\u00a0models. Fine-tuning on our synthetic data significantly improves narrative claim verification.", "description": "\uadf8\ub9bc 1\uc740 CLIPPER\uc758 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc640 NoCha \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uae30\uc900 \ubaa8\ub378, \uc18c\uaddc\ubaa8 \ud3d0\uc1c4\ud615 \ubaa8\ub378 \ubc0f CLIPPER \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac00\ub85c\ucd95\uc740 \uc815\ud655\ub3c4(%)\uc774\uace0 \uc138\ub85c\ucd95\uc740 \ubaa8\ub378 \uc774\ub984\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 CLIPPER \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc640 NoCha \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c\uc758 \uc131\ub2a5\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4.  CLIPPER \ubaa8\ub378\uc740 \ud569\uc131 \ub370\uc774\ud130\ub85c \ubbf8\uc138 \uc870\uc815\ub418\uc5c8\uc73c\uba70, \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \uc11c\uc220\uc801 \uc8fc\uc7a5 \uac80\uc99d \uc791\uc5c5\uc5d0\uc11c \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, CLIPPER\ub97c \uc0ac\uc6a9\ud55c \ubbf8\uc138 \uc870\uc815\uc740 \ubaa8\ub378\uc758 \uc11c\uc220\uc801 \uc8fc\uc7a5 \uac80\uc99d \ub2a5\ub825\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 Supervised finetuning for LLMs on CLIPPER data"}, {"figure_path": "https://arxiv.org/html/2502.14854/x2.png", "caption": "Figure 2: Overview of the CLIPPER\u00a0pipeline. (1) Compression: We generate chapter outlines and book summaries using an LLM. Our books average 90,437 tokens, our outlines average 8,745 tokens, and our summaries average 618 tokens. (2) Synthetic claim generation: We ask LLMs to generate true and false claims based on the outlines and summaries. Each generated claim comes with a chain-of-thought. The book texts, generated claims, and corresponding chains-of-thoughts are then used for supervised finetuning.", "description": "CLIPPER \ud30c\uc774\ud504\ub77c\uc778\uc740 \ud06c\uac8c \ub450 \ub2e8\uacc4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uba3c\uc800, \uc785\ub825\uc73c\ub85c \uc8fc\uc5b4\uc9c4 \ucc45\uc758 \ud14d\uc2a4\ud2b8\ub97c LLM\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc694\uc57d\uacfc \uac01 \uc7a5\uc758 \uac1c\uc694\ub85c \uc555\ucd95\ud569\ub2c8\ub2e4. \ucc45\uc758 \ud3c9\uade0 \ud1a0\ud070 \uc218\ub294 90,437\uac1c, \uc694\uc57d\uc758 \ud3c9\uade0 \ud1a0\ud070 \uc218\ub294 618\uac1c, \uac01 \uc7a5\uc758 \uac1c\uc694\uc758 \ud3c9\uade0 \ud1a0\ud070 \uc218\ub294 8,745\uac1c\uc785\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc694\uc57d\uacfc \uac01 \uc7a5\uc758 \uac1c\uc694\ub97c \uae30\ubc18\uc73c\ub85c LLM\uc5d0\uac8c \ucc38 \ub610\ub294 \uac70\uc9d3 \uc8fc\uc7a5\uc744 \uc0dd\uc131\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc0dd\uc131\ub41c \uac01 \uc8fc\uc7a5\uc5d0\ub294 \ucd94\ub860 \uacfc\uc815(chain-of-thought)\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4.  \ucd5c\uc885\uc801\uc73c\ub85c, \ucc45\uc758 \ud14d\uc2a4\ud2b8, \uc0dd\uc131\ub41c \uc8fc\uc7a5, \uadf8\ub9ac\uace0 \ud574\ub2f9 \ucd94\ub860 \uacfc\uc815\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac10\ub3c5 \ud559\uc2b5 \ubc29\uc2dd\uc73c\ub85c \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud569\ub2c8\ub2e4.", "section": "2 CLIPPER: generating high-quality synthetic data via compression"}]