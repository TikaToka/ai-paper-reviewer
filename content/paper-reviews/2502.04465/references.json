{"references": [{"fullname_first_author": "A. Baevski", "paper_title": "wav2vec 2.0: A framework for self-supervised learning of speech representations", "publication_date": "2020-12-01", "reason": "This paper introduces wav2vec 2.0, a foundational self-supervised learning model for speech that significantly impacts the field and is directly leveraged by FocalCodec."}, {"fullname_first_author": "A. Defossez", "paper_title": "High fidelity neural audio compression", "publication_date": "2023-01-01", "reason": "This paper introduces a state-of-the-art acoustic codec, EnCodec, which is a strong baseline for comparison and provides insights into the limitations of current approaches."}, {"fullname_first_author": "J. Kong", "paper_title": "HiFi-GAN: generative adversarial networks for efficient and high fidelity speech synthesis", "publication_date": "2020-12-01", "reason": "This paper introduces HiFi-GAN, a high-fidelity vocoder used in FocalCodec for speech reconstruction, significantly impacting the audio synthesis community and being instrumental in the current work."}, {"fullname_first_author": "J. Parker", "paper_title": "Scaling transformers for low-bitrate high-quality speech coding", "publication_date": "2024-11-01", "reason": "This paper introduces StableCodec, a strong baseline for low-bitrate speech coding which serves as a key comparison point to understand the performance of FocalCodec."}, {"fullname_first_author": "H. Zen", "paper_title": "LibriTTS: A corpus derived from LibriSpeech for text-to-speech", "publication_date": "2019-12-01", "reason": "This paper introduces LibriTTS, a major speech dataset used for training FocalCodec, directly impacting the quality and generalizability of the model."}]}