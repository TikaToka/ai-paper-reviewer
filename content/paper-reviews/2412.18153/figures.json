[{"figure_path": "https://arxiv.org/html/2412.18153/x2.png", "caption": "Figure 1: DepthLab\u00a0 for diverse downstream tasks. Many tasks naturally contain partial depth information, such as (1) 3D Gaussian inpainting, (2) LiDAR depth completion, (3) sparse-view reconstruction with Dust3R, and (4) text-to-scene generation.\nOur model leverages this known information to achieve improved depth estimation, enhancing performance in downstream tasks. We hope to motivate more related tasks to adopt DepthLab.", "description": "\uadf8\ub9bc 1\uc740 DepthLab\uc774 \ub2e4\uc591\ud55c \ud558\uc704 \uc791\uc5c5\uc5d0 \uc801\uc6a9\ub420 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 3D Gaussian inpainting, LiDAR depth completion, Dust3R\uc744 \uc774\uc6a9\ud55c sparse-view reconstruction, text-to-scene generation \ub4f1 \ub9ce\uc740 \uc791\uc5c5\uc5d0\ub294 \ubd80\ubd84\uc801\uc778 \uae4a\uc774 \uc815\ubcf4\uac00 \uc790\uc5f0\uc2a4\ub7fd\uac8c \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. DepthLab \ubaa8\ub378\uc740 \uc774\ub7ec\ud55c \uae30\uc874 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \uae4a\uc774 \ucd94\uc815\uc744 \uac1c\uc120\ud558\uace0 \ud558\uc704 \uc791\uc5c5\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 DepthLab\uc744 \ub354 \ub9ce\uc740 \uad00\ub828 \uc791\uc5c5\uc5d0 \uc801\uc6a9\ud558\ub294 \uac83\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.18153/x3.png", "caption": "Figure 2: The training process of DepthLab. First, we apply random masking to the ground truth depth to create the masked depth, followed by interpolation. Both the interpolated masked depth and the original depth undergo random scale normalization before being fed into the encoder. The Reference U-Net extracts RGB features, while the Estimation U-Net takes the noisy depth, masked depth, and encoded mask as input. Layer-by-layer feature fusion allows for finer-grained visual guidance, achieving high-quality depth predictions even in large or complex masked regions.", "description": "\uadf8\ub9bc 2\ub294 DepthLab\uc758 \ud559\uc2b5 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800, \uc815\ub2f5 \uc2ec\ub3c4 \ub9f5\uc5d0 \uc784\uc758\uc758 \ub9c8\uc2a4\ud06c\ub97c \uc801\uc6a9\ud558\uc5ec \ub9c8\uc2a4\ud06c\ub41c \uc2ec\ub3c4 \ub9f5\uc744 \uc0dd\uc131\ud558\uace0, \uc774\ub97c \ubcf4\uac04\ud569\ub2c8\ub2e4. \ubcf4\uac04\ub41c \ub9c8\uc2a4\ud06c \uc2ec\ub3c4 \ub9f5\uacfc \uc6d0\ubcf8 \uc2ec\ub3c4 \ub9f5 \ubaa8\ub450 \uc784\uc758\uc758 \uc2a4\ucf00\uc77c \uc815\uaddc\ud654\ub97c \uac70\uce5c \ud6c4 \uc778\ucf54\ub354\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4. Reference U-Net\uc740 RGB \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud558\uace0, Estimation U-Net\uc740 \uc7a1\uc74c\uc774 \ucd94\uac00\ub41c \uc2ec\ub3c4 \ub9f5, \ub9c8\uc2a4\ud06c \uc2ec\ub3c4 \ub9f5, \uadf8\ub9ac\uace0 \uc778\ucf54\ub529\ub41c \ub9c8\uc2a4\ud06c\ub97c \uc785\ub825\ubc1b\uc2b5\ub2c8\ub2e4. \uacc4\uce35\ubcc4 \ud2b9\uc9d5 \uc735\ud569\uc744 \ud1b5\ud574 \ubcf4\ub2e4 \uc138\ubc00\ud55c \uc2dc\uac01\uc801 \uc548\ub0b4\ub97c \uc81c\uacf5\ud558\uc5ec \ud06c\uac70\ub098 \ubcf5\uc7a1\ud55c \ub9c8\uc2a4\ud06c \uc601\uc5ed\uc5d0\uc11c\ub3c4 \uace0\ud488\uc9c8\uc758 \uc2ec\ub3c4 \uc608\uce21\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.18153/x4.png", "caption": "Figure 3: Qualitative comparison of various methods on different datasets. In the second column, black represents the known regions, while white indicates the predicted areas.\nNotably, to emphasize the contrast, we reattach the known ground truth depth to the corresponding positions in the right-side visualizations of the depth maps. Other methods exhibit significant geometric inconsistency.", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc744 \uc5ec\ub7ec \ub370\uc774\ud130\uc14b\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \uc5f4\uc5d0\uc11c \uac80\uc740\uc0c9\uc740 \uc54c\ub824\uc9c4 \uc601\uc5ed(known regions), \ud770\uc0c9\uc740 \uc608\uce21\ub41c \uc601\uc5ed(predicted areas)\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc624\ub978\ucabd \uc5f4\uc758 \uae4a\uc774 \ub9f5 \uc2dc\uac01\ud654\uc5d0\uc11c\ub294 \ub300\uc870\ub97c \uac15\uc870\ud558\uae30 \uc704\ud574 \uc54c\ub824\uc9c4 \uc815\ub2f5 \uae4a\uc774(ground truth depth)\ub97c \ud574\ub2f9 \uc704\uce58\uc5d0 \ub2e4\uc2dc \ubd99\uc600\uc2b5\ub2c8\ub2e4. \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc740 \uc0c1\ub2f9\ud55c \uae30\ud558\ud559\uc801 \ubd88\uc77c\uce58(geometric inconsistency)\ub97c \ubcf4\uc774\ub294 \ubc18\uba74, \uc81c\uc2dc\ub41c \ubc29\ubc95\uc740 \uc77c\uad00\ub41c \uae4a\uc774 \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.18153/x5.png", "caption": "Figure 4: Visualization of gaussian inpainting. By projecting depth directly into three-dimensional space as initial points, natural 3D consistency is maintained, enabling texture editing and object addition. Please zoom in to view more details.", "description": "\uadf8\ub9bc 4\ub294 Gaussian Inpainting\uc758 \uc2dc\uac01\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae4a\uc774 \uc815\ubcf4\ub97c 3\ucc28\uc6d0 \uacf5\uac04\uc5d0 \uc9c1\uc811 \ud22c\uc601\ud558\uc5ec \ucd08\uae30 \uc810\uc73c\ub85c \uc0ac\uc6a9\ud568\uc73c\ub85c\uc368 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 3\ucc28\uc6d0 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uace0, \uc774\ub97c \ud1b5\ud574 \uc9c8\uac10 \ud3b8\uc9d1 \ubc0f \uac1c\uccb4 \ucd94\uac00\uac00 \uac00\ub2a5\ud569\ub2c8\ub2e4. \ubcf4\ub2e4 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ud655\ub300\ud558\uc5ec \ud655\uc778\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ubd80\ubd84\uc801\uc778 \uae4a\uc774 \uc815\ubcf4\ub9cc \uc8fc\uc5b4\uc84c\uc744 \ub54c, \ubaa8\ub378\uc774 \uc8fc\ubcc0 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec 3\ucc28\uc6d0 \uacf5\uac04\uc5d0\uc11c \uc790\uc5f0\uc2a4\ub7fd\uac8c \uae4a\uc774\ub97c \uc644\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc77c\uad00\uc131 \uc788\ub294 \uae4a\uc774 \uc815\ubcf4\ub97c \uc0dd\uc131\ud558\uc5ec 3\ucc28\uc6d0 \ubaa8\ub378\uc758 \uc9c8\uac10 \uc218\uc815\uc774\ub098 \ubb3c\uccb4 \ucd94\uac00 \uc791\uc5c5\uc774 \uac00\ub2a5\ud574\uc9d0\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.18153/x6.png", "caption": "Figure 5: Visualization of 3d scene generation. Left: Depth comparison. \u201dAlign\u201d represents the least-square method and shows clear geometric inconsistencies at boundaries. While LucidDreamer reduces these inconsistencies, it compromises the accuracy of the newly estimated depth.\nIn contrast, our model produces consistent and accurate depth. Right: The improved depth estimation from our model leads to superior 3D scene generation results.", "description": "\uadf8\ub9bc 5\ub294 3D \uc7a5\uba74 \uc0dd\uc131\uc5d0 \ub300\ud55c DepthLab\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc740 \uae4a\uc774 \ube44\uad50\ub97c \ub098\ud0c0\ub0b4\ub294\ub370, '\uc815\ub82c'\uc740 \ucd5c\uc18c \uc81c\uacf1\ubc95\uc744 \uc0ac\uc6a9\ud55c \uacb0\uacfc\uc774\uba70 \uacbd\uacc4\uc5d0\uc11c \uba85\ud655\ud55c \uae30\ud558\ud559\uc801 \ubd88\uc77c\uce58\uac00 \ubc1c\uc0dd\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LucidDreamer\ub294 \uc774\ub7ec\ud55c \ubd88\uc77c\uce58\ub97c \uc904\uc774\uc9c0\ub9cc \uc0c8\ub85c \ucd94\uc815\ub41c \uae4a\uc774\uc758 \uc815\ud655\ub3c4\ub97c \ub5a8\uc5b4\ub728\ub9bd\ub2c8\ub2e4. \ubc18\uba74\uc5d0 DepthLab \ubaa8\ub378\uc740 \uc77c\uad00\ub418\uace0 \uc815\ud655\ud55c \uae4a\uc774\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc624\ub978\ucabd\uc740 DepthLab \ubaa8\ub378\uc758 \ud5a5\uc0c1\ub41c \uae4a\uc774 \ucd94\uc815\uc73c\ub85c \uc778\ud574 \uc6b0\uc218\ud55c 3D \uc7a5\uba74 \uc0dd\uc131 \uacb0\uacfc\uac00 \uc0dd\uc131\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Applications"}]