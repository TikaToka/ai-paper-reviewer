[{"figure_path": "https://arxiv.org/html/2502.13142/x1.png", "caption": "Figure 1: Overview of ARM4R. We introduce an Auto-regressive Robotic Model that leverages low-level 4D Representations (3D point tracks across time) learned from human videos to yield a better pre-trained robotic model.", "description": "\uadf8\ub9bc 1\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 ARM4R \ubaa8\ub378\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ARM4R\uc740 \uc790\ub3d9 \ud68c\uadc0 \ub85c\ubd07 \ubaa8\ub378\ub85c, \uc778\uac04\uc758 \ube44\ub514\uc624 \ub370\uc774\ud130\uc5d0\uc11c \ud559\uc2b5\ub41c \uc800\uc218\uc900 4D \ud45c\ud604(\uc2dc\uac04\uc5d0 \ub530\ub978 3D \uc810 \ucd94\uc801)\uc744 \ud65c\uc6a9\ud558\uc5ec \ub354 \ub098\uc740 \uc0ac\uc804 \ud6c8\ub828\ub41c \ub85c\ubd07 \ubaa8\ub378\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e8\uc548 \ube44\ub514\uc624\uc5d0\uc11c 3D \uc810 \ucd94\uc801\uc744 \uc608\uce21\ud558\uace0, \uc774\ub97c \ub85c\ubd07 \uc81c\uc5b4\uc5d0 \uc0ac\uc6a9\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc778\uac04\uc758 \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud558\uc5ec \ub85c\ubd07 \uc870\uc791 \uc791\uc5c5\uc5d0 \ud6a8\uacfc\uc801\uc73c\ub85c \uc804\uc774 \ud559\uc2b5\uc744 \uc218\ud589\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc124\uba85\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.13142/x2.png", "caption": "Figure 2:  ARM4R is trained in three stages. Top Grey Box: The first two stages focus on learning a scene-wide 4D representation by predicting 3D points across time, where Stage 1 pre-trains on a large egocentric human dataset (Epic-Kitchens100), and Stage 2 fine-tunes on a smaller dataset (1-2K demonstrations) of robotic scenes, adapting the point tracking to robotic scene and camera. Bottom Grey Box: Finally, the model is fine-tuned to predict robot proprioceptive states rather than 3D points to enable robotic control.", "description": "\uadf8\ub9bc 2\ub294 ARM4R \ubaa8\ub378\uc758 \uc138 \uac00\uc9c0 \ud6c8\ub828 \ub2e8\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc704\ucabd \ud68c\uc0c9 \uc0c1\uc790\ub294 3D \uc810\uc744 \uc2dc\uac04\uc5d0 \ub530\ub77c \uc608\uce21\ud558\uc5ec \uc804\uccb4 \uc7a5\uba74\uc5d0 \ub300\ud55c 4D \ud45c\ud604\uc744 \ud559\uc2b5\ud558\ub294 \uccab \ub450 \ub2e8\uacc4\uc5d0 \ucd08\uc810\uc744 \ub9de\ucda5\ub2c8\ub2e4. 1\ub2e8\uacc4\uc5d0\uc11c\ub294 \ub300\uaddc\ubaa8 \uc790\uae30\uc911\uc2ec\uc801 \uc778\uac04 \ub370\uc774\ud130\uc14b(Epic-Kitchens100)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804 \ud6c8\ub828\ud558\uace0, 2\ub2e8\uacc4\uc5d0\uc11c\ub294 \ub85c\ubd07 \uc7a5\uba74\uc758 \ub354 \uc791\uc740 \ub370\uc774\ud130\uc14b(1~2K \ub370\ubaa8)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ud558\uc5ec \ub85c\ubd07 \uc7a5\uba74\uacfc \uce74\uba54\ub77c\uc5d0 \ub9de\uac8c \uc810 \ucd94\uc801\uc744 \uc870\uc815\ud569\ub2c8\ub2e4. \uc544\ub798\ucabd \ud68c\uc0c9 \uc0c1\uc790\ub294 \ucd5c\uc885\uc801\uc73c\ub85c 3D \uc810\uc774 \uc544\ub2cc \ub85c\ubd07 \uace0\uc720\uc218\uc6a9\uc131 \uc0c1\ud0dc\ub97c \uc608\uce21\ud558\ub3c4\ub85d \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\uc5ec \ub85c\ubd07 \uc81c\uc5b4\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "3. Auto-regressive Robotic Models"}, {"figure_path": "https://arxiv.org/html/2502.13142/x3.png", "caption": "Figure 3: Ablation Study for Stages 1 and 2. We train ARM4R on three real tasks in the Kinova setting, ablating Stages 1 and 2. The results indicate that while both stages improve performance, Stage 1 has a more significant impact.", "description": "\uadf8\ub9bc 3\uc740 ARM4R \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\uc81c Kinova \ub85c\ubd07 \ud658\uacbd\uc5d0\uc11c \uc138 \uac00\uc9c0 \uc791\uc5c5(Pick, Destack, Stack)\uc744 \uc218\ud589\ud558\uba70, \ubaa8\ub378 \ud559\uc2b5 \ub2e8\uacc4(Stage) \uc911 Stage 1(\uc778\uac04 \ube44\ub514\uc624 \uc0ac\uc804 \ud559\uc2b5)\uacfc Stage 2(\ub85c\ubd07 \ube44\ub514\uc624 \ubbf8\uc138 \uc870\uc815)\uc744 \uc81c\uc678\ud55c \uacbd\uc6b0\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uacb0\uacfc\ub294 Stage 1\uacfc Stage 2 \ubaa8\ub450 \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud558\uc9c0\ub9cc, Stage 1\uc758 \uc601\ud5a5\uc774 Stage 2\ubcf4\ub2e4 \ud6e8\uc52c \ud06c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \uc778\uac04 \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud55c \uc0ac\uc804 \ud559\uc2b5\uc774 \ub85c\ubd07 \uc81c\uc5b4 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.4. Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/supp_human.png", "caption": "Figure 4: Visualization of ARM4R\u2019s 3D Point Track results on randomly chosen Epic-Kitchens (in-domain) and Ego-4D (out-of-domain) human videos.", "description": "\uadf8\ub9bc 4\ub294 ARM4R \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c 3D \ud3ec\uc778\ud2b8 \ucd94\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Epic-Kitchens \ub370\uc774\ud130\uc14b(\ub3c4\uba54\uc778 \ub0b4)\uacfc Ego-4D \ub370\uc774\ud130\uc14b(\ub3c4\uba54\uc778 \uc678)\uc758 \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ub41c \uc601\uc0c1\ub4e4\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 ARM4R \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc778\uac04 \ud65c\ub3d9 \uc601\uc0c1\uc5d0\uc11c 3D \ud3ec\uc778\ud2b8\ub4e4\uc744 \uc815\ud655\ud558\uac8c \ucd94\uc801\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788 \ub3c4\uba54\uc778 \ub0b4 \uc601\uc0c1\uacfc \ub3c4\uba54\uc778 \uc678 \uc601\uc0c1 \ubaa8\ub450\uc5d0\uc11c \uc77c\uad00\ub41c \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uc810\uc5d0 \uc8fc\ubaa9\ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub294 ARM4R \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \ub2a5\ub825\uc774 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc99d\uac70\uc785\ub2c8\ub2e4.", "section": "3. Auto-regressive Robotic Models"}, {"figure_path": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/supp_robot.png", "caption": "Figure 5: Visualization of ARM4R\u2019s 3D Point Track results on randomly chosen Kinova (in-domain) and Open X-Embodiment (out-of-domain) robot videos.", "description": "\uadf8\ub9bc 5\ub294 ARM4R \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c 3D \ud3ec\uc778\ud2b8 \ud2b8\ub799 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Kinova \ub85c\ubd07 \ube44\ub514\uc624(\ub3c4\uba54\uc778 \ub0b4)\uc640 Open X-Embodiment \ub85c\ubd07 \ube44\ub514\uc624(\ub3c4\uba54\uc778 \uc678)\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ub41c \ube44\ub514\uc624\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 ARM4R \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub85c\ubd07 \ud658\uacbd\uacfc \uad6c\uc131\uc5d0\uc11c 3D \ud3ec\uc778\ud2b8\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ucd94\uc801\ud558\uace0, \ub3c4\uba54\uc778 \ub0b4\uc678 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ub85c\ubd07 \ube44\ub514\uc624\uc758 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc9e7\uc740 \uc124\uba85\uacfc \ud568\uaed8 \uc2dc\uac01\ud654\ub41c 3D \ud3ec\uc778\ud2b8 \ud2b8\ub799\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Auto-regressive Robotic Models"}, {"figure_path": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/kinova_setup.jpg", "caption": "Figure 6: The real-world experiment setup of Kinova robot.", "description": "\uadf8\ub9bc 6\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c Kinova \ub85c\ubd07\uc758 \uc2e4\uc81c \uc2e4\ud5d8 \ud658\uacbd \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc2e4\uc81c \ub85c\ubd07 \ud314\uacfc \uce74\uba54\ub77c\uc758 \ubc30\uce58, \uadf8\ub9ac\uace0 \uc791\uc5c5 \uacf5\uac04\uc744 \uc0c1\uc138\ud558\uac8c \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\uc9c4\uc785\ub2c8\ub2e4. \ub85c\ubd07 \ud314\uc758 \uad00\uc808\uacfc \uadf8\ub9ac\ud37c, \uadf8\ub9ac\uace0 \uc791\uc5c5 \uacf5\uac04\uc5d0 \ubc30\uce58\ub41c \ubb3c\uccb4\ub4e4\uc774 \ubcf4\uc774\uba70,  \uc2e4\ud5d8 \ud658\uacbd\uc5d0 \ub300\ud55c \uc804\ubc18\uc801\uc778 \uc774\ud574\ub97c \ub3d5\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \ub85c\ubd07 \ud314\uc758 \uc704\uce58\uc640 \uce74\uba54\ub77c\uc758 \uac01\ub3c4\ub294 \ub85c\ubd07\uc758 \uc2dc\uac01\uc801 \uc785\ub825\uacfc \uc81c\uc5b4\uc5d0 \uc911\uc694\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\ubbc0\ub85c, \uc774 \uadf8\ub9bc\uc740 \uc774\ub7ec\ud55c \uce21\uba74\uc744 \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3. \uc2e4\uc81c \ub85c\ubd07 \ud3c9\uac00"}, {"figure_path": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/kinova_tasks.jpg", "caption": "Figure 7: Task building of real-world Kinova setup.", "description": "\uadf8\ub9bc 7\uc740 \uc2e4\uc81c \ud0a4\ub178\ubc14 \ub85c\ubd07 \uc124\uc815\uc5d0\uc11c \uc218\ud589\ub41c \uc791\uc5c5\uc5d0 \ub300\ud55c \uc124\uba85\uc785\ub2c8\ub2e4.  \uac01 \uc791\uc5c5\uc740 \ub85c\ubd07 \uc554\uc758 \ucd08\uae30 \uc704\uce58, \ubb3c\uccb4\uc758 \uc704\uce58, \ubaa9\ud45c \uc704\uce58, \uadf8\ub9ac\uace0 \uc791\uc5c5 \uc218\ud589 \uc21c\uc11c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ud0a4\ub178\ubc14 \ub85c\ubd07\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8\uc758 \uc138\ubd80\uc0ac\ud56d\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.  \uac01 \uc791\uc5c5(\ud050\ube0c \uc90d\uae30, \ud050\ube0c \uc313\uae30, \ud050\ube0c \ub0b4\ub9ac\uae30, \ubc84\ud2bc \ub204\ub974\uae30, \uc7a5\ub09c\uac10/\ub18d\uad6c\uacf5 \uc90d\uace0 \ub193\uae30)\uc758 \ub2e8\uacc4\ubcc4 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uc5b4 \uc2e4\ud5d8 \uc124\uc815\uc744 \uc790\uc138\ud788 \uc124\uba85\ud569\ub2c8\ub2e4.", "section": "4.3. \uc2e4\uc81c \ub85c\ubd07 \ud3c9\uac00"}, {"figure_path": "https://arxiv.org/html/2502.13142/extracted/6193432/Figures/franka_setup.jpg", "caption": "Figure 8: The real-world experiment setup of Franka robot.", "description": "\uadf8\ub9bc 8\uc740 \uc2e4\uc81c \ud504\ub791\uce74 \ub85c\ubd07 \uc2e4\ud5d8 \ud658\uacbd\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud504\ub791\uce74 \ub85c\ubd07 \uc591\ucabd\uc5d0 \uc124\uce58\ub41c \ub450 \ub300\uc758 \ub85c\uc9c0\ud14d BRIO 4K \uce74\uba54\ub77c\uac00 \ub85c\ubd07\uc758 \uc870\uc791 \ub3d9\uc791\uc744 \ucd2c\uc601\ud569\ub2c8\ub2e4. \uae4a\uc774 \uc815\ubcf4 \uc5c6\uc774 RGB \uc601\uc0c1\ub9cc \uc81c\uacf5\ud558\uba70, \uc790\ub3d9 \ucd08\uc810 \uae30\ub2a5\uc740 \uaebc\uc838 \uc788\uace0 640x480 \ud574\uc0c1\ub3c4\ub85c \ub370\uc774\ud130\ub97c \uc218\uc9d1\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ub85c\ubd07 \uc2e4\ud5d8\uc758 \ud558\ub4dc\uc6e8\uc5b4 \uc124\uc815\uc744 \uac04\ub7b5\ud558\uac8c \ubcf4\uc5ec\uc8fc\ub294 \uc774\ubbf8\uc9c0\uc785\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \ubc0f \uacb0\uacfc"}]