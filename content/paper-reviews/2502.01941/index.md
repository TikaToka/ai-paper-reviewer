---
title: "Can LLMs Maintain Fundamental Abilities under KV Cache Compression?"
summary: "대규모 언어 모델의 KV 캐시 압축이 핵심 기능에 미치는 영향을 심층 분석한 결과, 산술 추론 작업에서 성능 저하가 특히 심하며, ShotKV라는 새로운 압축 방법이 장문 생성 작업의 성능을 개선함을 밝혔습니다."
categories: ["AI Generated", "🤗 Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "🏢 Hong Kong University of Science and Technology",]
showSummary: true
date: 2025-02-04
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.01941 {{< /keyword >}}
{{< keyword icon="writer" >}} Xiang Liu et el. {{< /keyword >}}
 
{{< keyword >}} 🤗 2025-02-05 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.01941" target="_self" >}}
↗ arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.01941" target="_self" >}}
↗ Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/can-llms-maintain-fundamental-abilities-under" target="_self" >}}
↗ Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

대규모 언어 모델(LLM)의 효율적인 구축을 위해 **KV 캐시 압축**이 중요해지고 있습니다.  하지만 기존 방법들은 장문 맥락 처리 성능에 대한 평가에 치우쳐져, **LLM의 기본 기능 유지**에 대한 이해가 부족했습니다. 본 연구는 이 문제를 해결하기 위해 다양한 작업에 걸쳐 주요 KV 캐시 압축 방법들을 평가했습니다.

본 연구는 **산술 추론 작업이 압축에 특히 취약**하다는 것을 발견했습니다.  반면 **DeepSeek R1 Distill 모델**은 다른 모델보다 압축에 강인했습니다.  연구진은 이러한 관찰 결과를 바탕으로, **ShotKV**라는 새로운 압축 방법을 제안했습니다.  ShotKV는 사전 채우기 단계와 디코딩 단계를 구분하여 처리하여, **장문 맥락 생성 작업에서 성능을 9~18% 향상**시켰습니다. 이는 **LLM의 효율적인 배포 및 최적화**에 중요한 기여를 할 것으로 기대됩니다.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} KV 캐시 압축은 작업에 따라 성능 저하가 다르게 나타남 {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} 산술 추론 작업은 압축에 매우 민감함 {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ShotKV는 장문 맥락 생성 작업에서 성능을 개선함 {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
본 논문은 **대규모 언어 모델의 효율적인 배포를 위한 KV 캐시 압축 기술**에 대한 중요한 통찰력을 제공하며, **특정 작업에 대한 성능 저하**를 밝히고, 이를 완화하기 위한 새로운 방법인 **ShotKV**를 제시합니다. 이는 **모델 개발 및 배포 전략**에 상당한 영향을 미칠 수 있으며, 특히 **장문 맥락 처리**가 중요한 응용 분야에서 그 중요성이 더욱 커질 것입니다. 또한, 향후 **작업 특이적 압축 전략** 및 **압축에 강인한 모델 설계**에 대한 추가 연구를 위한 새로운 방향을 제시합니다.

------
#### Visual Insights



![](https://arxiv.org/html/2502.01941/x1.png)

> 🔼 그림 (a)는 다양한 KV 캐시 압축 방법이 장문 벤치마크와 산술 벤치마크에서의 성능에 미치는 영향을 보여줍니다. 장문 벤치마크는 긴 맥락을 처리하는 모델의 능력을 평가하는 데 사용되는 반면, 산술 벤치마크는 수학적 추론 능력을 평가하는 데 사용됩니다. 이 그림은 다양한 압축 비율에서 각 벤치마크의 정확도를 나타내는 그래프를 보여주어, 압축 방법이 벤치마크 유형에 따라 성능에 미치는 영향이 다르다는 것을 시각적으로 보여줍니다. 특히 산술 벤치마크는 장문 벤치마크보다 압축에 더 민감하게 반응하는 것을 알 수 있습니다.
> <details>
> <summary>read the caption</summary>
> (a) KV cache compression methods on long-context and arithmetic benchmarks.
> </details>





{{< table-caption >}}
| Benchmark | Zero-shot ↑ | Few-shot ↑ | Delta Δ |
|---|---|---|---|
| GSM8K | 0.2904 | 0.7945 | +0.5041 |
| MMLU | 0.6262 | 0.6882 | +0.0620 |{{< /table-caption >}}

> 🔼 표 1은 제로샷(zero-shot) 학습과 퓨샷(few-shot) 학습을 사용했을 때의 성능 차이를 보여줍니다. 제로샷은 사전 학습된 모델을 바로 사용하는 반면, 퓨샷은 모델에 추가적인 예제를 제공하여 특정 작업에 대한 성능을 높입니다. 이 표는 다양한 벤치마크에서 제로샷과 퓨샷 성능의 차이를 계산하여, 퓨샷 학습을 통해 얻을 수 있는 성능 향상 정도를 보여줍니다.  특히 GSM8K(산술 추론) 작업에서는 퓨샷 학습을 통해 상당한 성능 향상이 있음을 확인할 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Table 1: Zero-shot vs Few-shot Performance Comparison
> </details>





### In-depth insights


#### LLM Abilities Under Compression
본 논문은 압축 하에서의 대규모 언어 모델(LLM)의 기본 능력에 대한 심층적인 분석을 제공합니다. **KV 캐시 압축 기법이 LLM의 성능에 미치는 영향**을 다양한 벤치마크를 통해 평가하고 있습니다. 특히 **산술 추론 과제에 대한 민감도**와 **장문 컨텍스트 작업에 대한 강건성**이라는 두 가지 주요 관찰 결과가 제시됩니다.  **과제 특이적인 성능 저하** 현상이 나타나며, 특정 과제(예: 산술 추론)에서는 압축률에 따라 성능 저하가 심각하게 나타날 수 있습니다.  **ShotKV**와 같은 새로운 압축 기법이 제안되며, 이는 **전처리 및 디코딩 단계를 구별**하여 장문 컨텍스트 생성 작업에서 성능 향상을 보여줍니다.  결론적으로, 본 연구는 LLM의 효율적인 배포를 위해 **과제 특이성과 압축률 간의 상호작용**을 고려한 섬세한 접근 방식이 필요함을 시사합니다.

#### Task-Specific Sensitivity
본 논문에서 다룬 "Task-Specific Sensitivity"는 특정 작업에 대한 KV 캐시 압축의 영향이 작업의 종류에 따라 크게 다르다는 것을 보여줍니다. **특히, 산술 추론 작업은 압축에 매우 민감하여 성능 저하가 두드러지게 나타났습니다.** 반면, 장문맥락 이해와 생성 작업은 압축에 대한 내성이 더 강했습니다. 이러한 **작업 특이적 민감도는 모델의 어텐션 패턴과 밀접한 관련이 있습니다.** 산술 추론 작업에서는 어텐션이 특정 토큰에 집중되는 반면, 장문맥락 작업에서는 어텐션 분포가 더 고르게 나타났습니다.  **이는 압축 방법이 작업의 특성에 맞게 조정되어야 함을 시사합니다.**  단순히 압축률만을 고려하는 것이 아니라, **각 작업의 특성과 모델의 어텐션 패턴을 고려하여 최적의 압축 전략을 선택해야 합니다.**  **ShotKV와 같이 작업 단계별로 다른 압축 전략을 적용하는 방법**이 효과적일 수 있습니다.  **향후 연구는 다양한 작업과 모델에 대한 광범위한 실험을 통해 작업 특이적 민감도를 더욱 심층적으로 분석하고, 각 작업에 최적화된 압축 기술을 개발하는 데 집중해야 합니다.**

#### ShotKV: A Novel Approach
본 논문에서 제시된 ShotKV는 기존의 KV 캐시 압축 방식의 한계를 극복하기 위한 새로운 시도로, **전처리 단계와 디코딩 단계를 명확히 구분하여 각 단계에 최적화된 압축 전략을 적용**합니다. 특히, **전처리 단계에서는 중요한 샷(예시)들을 보존**하여 의미적 일관성을 유지하고, **디코딩 단계에서는 토큰의 중요도에 따라 선택적으로 토큰을 유지**하는 방식을 채택합니다. 이는 기존 방식들이 긴 문맥 생성 작업에서 성능 저하를 보이는 문제점을 해결하기 위한 핵심적인 전략입니다. ShotKV는 **긴 문맥의 산술적 추론 및 생성 작업에서 성능 향상**을 보였으며, **과도한 압축 비율에서도 견고한 성능**을 유지하는 것으로 나타났습니다. 이는 **작업의 특성에 따른 적응적인 압축**이 가능함을 시사합니다.  **샷 단위의 의미적 일관성 유지**라는 혁신적인 아이디어를 통해  LLM의 기본적인 능력을 유지하면서 효율적인 KV 캐시 압축을 달성하는데 기여할 것으로 기대됩니다.

#### Compression Robustness
본 논문은 대규모 언어 모델(LLM)의 기본 능력에 대한 KV 캐시 압축 방법의 영향을 종합적으로 평가합니다. **수치 추론 작업은 공격적인 압축에 특히 민감하며, 여러 방법에서 성능 저하가 17.4%~43.3%에 달합니다.**  흥미롭게도, **DeepSeek R1 Distill 모델은 지침 미세 조정 모델에 비해 압축 허용 오차가 더 크며, 성능 저하가 9.67%~25.53%에 불과합니다.**  이는 다단계 추론 LLM이 압축에 대해 더 강건함을 시사합니다.  **주의할 점은 압축 민감도는 작업에 따라 크게 다르며, 짧은 프롬프트는 압축에 더 취약하다는 점입니다.**  본 연구는 모델 훈련 역학, 프롬프트 길이 특성, 작업별 요구 사항, 장문 맥락 추론 및 생성 능력을 포함한 여러 요인이 압축 민감도에 영향을 미침을 밝힙니다.  **ShotKV는 이러한 과제를 해결하기 위한 새로운 압축 방식을 제시하며, 공격적인 압축 비율에서도 장문 맥락 생성 작업의 성능을 9%~18% 향상시킵니다.** 이는 단순히 압축률만을 고려하는 기존 방식과는 대조적입니다. 따라서 **모델의 기본 능력을 유지하면서 효율적인 LLM 배포를 달성하려면 작업별 압축 민감도를 고려한 적응형 압축 전략이 필수적입니다.**

#### Future Research Directions
본 논문은 KV 캐시 압축이 LLM의 기본 성능에 미치는 영향을 종합적으로 분석하였습니다.  **향후 연구 방향은 다음과 같이 제시될 수 있습니다.** 첫째, **다양한 LLM 아키텍처와 압축 기법에 대한 광범위한 실험**을 통해 일반화된 성능 저하 패턴을 규명하고, **특정 작업 유형에 대한 최적의 압축 전략**을 개발하는 연구가 필요합니다. 둘째, **모델 훈련 과정에 압축 내성을 고려한 새로운 훈련 방법론**을 개발하여 압축으로 인한 성능 저하를 최소화할 수 있는 모델을 설계하는 연구가 중요합니다. 셋째, 본 논문에서 제안된 ShotKV 기법을 더욱 발전시켜 **프리필 및 디코딩 단계의 압축 전략을 더욱 정교화**하고, 다양한 작업 유형에 대한 적응성을 높이는 연구가 필요합니다. 마지막으로, **압축된 KV 캐시의 메모리 사용량과 성능 간의 상호작용을 정량적으로 분석**하고, 이를 바탕으로 보다 효율적인 메모리 관리 기법을 개발하는 연구가 중요합니다. 이러한 연구들을 통해 LLM의 효율성과 성능을 동시에 향상시킬 수 있는 혁신적인 압축 기술을 개발할 수 있을 것입니다.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.01941/x2.png)

> 🔼 그림 (b)는 긴 문맥과 산술 연산 벤치마크에서 어텐션 히트맵을 보여줍니다.  긴 문맥 벤치마크의 경우 어텐션 분포가 보다 넓게 분산되어 있고, 산술 연산 벤치마크의 경우 어텐션이 특정 토큰에 집중되어 있음을 보여줍니다. 이는 긴 문맥 작업은 광범위한 문맥 정보를 활용하는 반면, 산술 연산 작업은 문제 해결을 위해 특정 부분에 집중하는 경향이 있음을 시사합니다.  두 벤치마크 간 어텐션 패턴의 차이는 KV 캐시 압축이 작업 성능에 미치는 영향에 대한 이해에 중요한 단서를 제공합니다.
> <details>
> <summary>read the caption</summary>
> (b) Attention heatmap on long-context and arithmetic benchmarks.
> </details>



![](https://arxiv.org/html/2502.01941/x3.png)

> 🔼 그림 1은 장문 벤치마크와 산술 벤치마크에서 KV 캐시 압축 방법의 성능을 보여줍니다. (a)는 산술 벤치마크가 장문 벤치마크보다 성능 저하가 더 크다는 것을 보여주고, (b)는 장문 벤치마크의 어텐션 히트맵이 더욱 희소하다는 것을 보여줍니다.  즉, 숫자 계산 문제는 압축에 더 민감하게 반응하며, 장문 텍스트 처리 시에는 어텐션 메커니즘이 특정 단어에 집중하기보다는 텍스트 전체를 고르게 고려한다는 것을 시각적으로 나타냅니다. 이는 KV 캐시 압축이 모델의 기본적인 능력에 미치는 영향이 작업의 종류에 따라 다르게 나타날 수 있음을 시사합니다.
> <details>
> <summary>read the caption</summary>
> Figure 1: KV cache compression methods on long-context and arithmetic benchmarks. (a) Arithmetic benchmark shows more performance degradation than long-context benchmark. (b) Long-Context benchmark shows more sparsity in attention heatmap.
> </details>



![](https://arxiv.org/html/2502.01941/x4.png)

> 🔼 그림 2는 다양한 작업에 대한 어텐션 히트맵을 보여줍니다.  LLaMA-3.1-8B-Instruct 모델의 15번째 레이어, 10번째 어텐션 헤드의 어텐션 점수를 사용하여 생성되었습니다. 각 히트맵은 시스템 프롬프트, 샷 예제, 질문을 나타내는 색상으로 구분된 영역을 보여줍니다. 이를 통해 각 작업에서 문맥이 어떻게 활용되는지에 대한 통찰력을 제공합니다.  세부적으로는, 세계 지식 및 상식 추론 작업은 균일한 어텐션 분포를 보이는 반면, 산술 추론 및 안전 작업은 더욱 전문화된 패턴을 보여줍니다.  산술 추론 작업은 개별 프롬프트 예제에 대한 집중적인 어텐션을 나타내는 어텐션의 희소성이 증가하는 반면, 안전 작업은 시스템 프롬프트에 집중된 어텐션을 보입니다. 세계 지식 및 상식 추론 작업은 프롬프트 전체에 걸쳐 더욱 균일한 어텐션 분포를 보입니다.  이러한 다양한 어텐션 패턴은 모델 크기, 프롬프트 길이, 작업 유형을 포함한 여러 요인에 대한 압축의 영향을 이해하는 데 중요한 통찰력을 제공합니다.
> <details>
> <summary>read the caption</summary>
> Figure 2: Attention heatmap on different tasks. The heatmap is generated by the attention scores of the 15-th layer of the LLaMA-3.1-8B-Instruct attention head 10.
> </details>



![](https://arxiv.org/html/2502.01941/x5.png)

> 🔼 그림 3은 다양한 벤치마크 범주에서 KV 캐시 압축에 대한 민감도 분석을 보여줍니다.  (a) 그래프는 다양한 벤치마크(MMLU, GSM8K, CSQA, JailBreakV, HumanEval)에 대해 압축 비율을 변화시키면서 정확도 변화를 보여줍니다.  각 벤치마크는 압축 비율에 따라 다르게 영향을 받는 것을 보여주며, 특히 Arithmetic reasoning task인 GSM8K가 압축에 가장 민감하게 반응하는 것을 확인할 수 있습니다. 즉, 높은 압축률에서는 성능 저하가 크게 나타납니다. 이는 다른 작업 유형보다 Arithmetic Reasoning 작업이 KV 캐시 압축에 더 민감하게 반응함을 시사합니다.  (b) 그래프는 기준선과 비교한 성능 변화율을 보여주는 추가 분석입니다.
> <details>
> <summary>read the caption</summary>
> (a) Sensitivity Analysis of Different Benchmark Categories to KV Cache Compression
> </details>



![](https://arxiv.org/html/2502.01941/x6.png)

> 🔼 그림 (b)는 다양한 벤치마크에서 기준 성능 대비 성능 변화를 보여줍니다.  x축은 압축 비율을 나타내고 y축은 성능 변화(퍼센트)를 나타냅니다. 각 선은 다른 벤치마크(MMLU, GSM8K, CSQA, JailBreakV, HumanEval)에 대한 성능 변화를 나타냅니다. 이 그래프를 통해 각 벤치마크별 KV 캐시 압축에 대한 민감도를 비교 분석할 수 있습니다. 예를 들어, 산술 추론 벤치마크(GSM8K)는 압축에 대한 민감도가 높은 반면, 세계 지식 벤치마크(MMLU)는 압축에 대한 민감도가 상대적으로 낮음을 보여줍니다.
> <details>
> <summary>read the caption</summary>
> (b) Performance Delta Lines with Baseline
> </details>



![](https://arxiv.org/html/2502.01941/x7.png)

> 🔼 그림 3은 다양한 벤치마크 범주에 대한 KV 캐시 압축의 민감도 분석을 보여줍니다.  x축은 압축 비율을, y축은 정확도 변화를 나타냅니다.  각 선은 특정 벤치마크(MMLU, GSM8K, CSQA, JailBreakV, HumanEval)에서의 성능 변화를 압축 비율에 따라 보여줍니다.  수식 (1)을 사용하여 계산된 성능 변화율(퍼센트)을 보여줍니다.  이 그래프는  KV 캐시 압축이 벤치마크 유형에 따라 서로 다른 영향을 미친다는 것을 시각적으로 보여줍니다. 특히, 산술 추론 작업은 압축에 매우 민감한 반면, 장문맥스트 벤치마크는 상대적으로 영향을 덜 받는다는 것을 알 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Figure 3: Sensitivity Analysis of Different Benchmark Categories to KV Cache Compression. The performance delta lines are calculated by Equation 1.
> </details>



![](https://arxiv.org/html/2502.01941/x8.png)

> 🔼 그림 4는 다양한 작업에 걸쳐 KV 캐시 압축 방법의 성능을 비교한 것입니다. 각 그래프는 특정 작업(MMLU, CSQA, JailBreakV, GSM8K, HumanEval)에 대한 압축 비율에 따른 정확도 변화를 보여줍니다.  y축 눈금은 작업마다 다르게 설정되어 있으므로, 그래프 간의 직접적인 비교는 어렵습니다.  (e)번 그래프의 R1-GSM8K 결과는 DeepSeek-R1-Distill-Llama-8B 모델을 사용하여 얻은 것입니다. 이 그림은  KV 캐시 압축이 작업 성능에 미치는 영향이 작업의 종류에 따라 상당히 다를 수 있음을 시각적으로 보여줍니다. 특히, 산술 추론 작업(GSM8K)의 경우 압축에 대한 민감도가 높은 것을 알 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Figure 4: Performance Comparison of KV Cache Compression Methods Across Tasks. Note: The y-axis scales vary across different tasks. Results for R1-GSM8K (e) were obtained using the DeepSeek-R1-Distill-Llama-8B model.
> </details>



![](https://arxiv.org/html/2502.01941/x9.png)

> 🔼 그림 5는 GSM8K 벤치마크에서 다양한 학습 방식(Instruction Tuning, R1 증류, 기본 모델)을 사용한 여러 KV 캐시 압축 방법의 성능을 비교 분석한 결과를 보여줍니다.  각 학습 방식에 따른 세 가지 모델의 성능을 압축 비율에 따라 보여주는 그래프입니다.  압축 비율이 높아질수록 정확도가 감소하는 경향이 나타나지만, 특히 Instruction Tuning된 모델이 압축에 더 민감하게 반응하는 것을 확인할 수 있습니다. 반면 R1 증류 모델은 압축에 대한 강건성이 높은 것을 보여줍니다. 이는 R1 증류 방식이 모델의 압축에 대한 강인성을 향상시켰음을 시사합니다.
> <details>
> <summary>read the caption</summary>
> Figure 5: Performance Comparison of KV Cache Compression Methods on different training dynamics on GSM8K
> </details>



![](https://arxiv.org/html/2502.01941/x10.png)

> 🔼 그림 6은 다양한 샷 수에 따른 평균 성능을 보여줍니다. 즉, 언어 모델에 제시되는 예시의 개수에 따라 KV 캐시 압축의 영향이 어떻게 달라지는지를 보여주는 그래프입니다. 샷 수가 증가할수록 (예시 개수가 많아질수록) KV 캐시 압축에 대한 모델의 강건성이 향상되는 것을 보여줍니다. 즉, 압축률이 높아져도 성능 저하가 적다는 것을 의미합니다. 반대로, 샷 수가 적을수록 (예시 개수가 적을수록) 압축률에 민감하게 반응하여 성능 저하가 크게 나타납니다. 이는 적은 수의 예시만으로는 모델이 충분한 정보를 얻지 못해 압축으로 인한 정보 손실에 취약하기 때문입니다. 그림은 다양한 압축률에서 여러 샷 수에 대한 성능을 비교하여, 적절한 샷 수를 선택하는 것이 KV 캐시 압축 전략을 수립하는 데 중요함을 시사합니다.
> <details>
> <summary>read the caption</summary>
> Figure 6: Average Performance Across Different Shot Numbers
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Method | 100% | 40% | 35% | 30% | 25% |
|---|---|---|---|---|---| 
| **FullKV** | 46.00 | - | - | - | - |
| StreamingLLM | - | 39.50 | 28.67 | 14.83 | 6.33 |
| H2O | - | 32.66 | 25.17 | 19.83 | 14.83 |
| PyramidInfer | - | 38.33 | 27.67 | 20.50 | 16.67 |
| **ShotKV(Ours)** | - | **47.33** | **41.33** | **38.33** | **26.83** |{{< /table-caption >}}
> 🔼 이 표는 LongGenBench-GSM8K 벤치마크에서 다양한 KV 캐시 압축 방법의 성능을 보여줍니다. LongGenBench-GSM8K는 긴 컨텍스트 생성 작업에 대한 성능을 평가하는 벤치마크입니다. 이 표는 전체 KV 캐시(FullKV)를 사용한 결과와 여러 압축 방법(StreamingLLM, H2O, PyramidInfer, ShotKV)을 적용한 결과를 비교하여 압축 비율에 따른 성능 변화를 보여줍니다.  각 압축 방법은 100%, 40%, 35%, 30%, 25%의 다섯 가지 압축 비율로 평가되었으며, 성능은 정확도(%)로 측정되었습니다.
> <details>
> <summary>read the caption</summary>
> Table 2: KV cache compression methods’ performance on LongGenBench-GSM8K
> </details>

{{< table-caption >}}
| Method | 100% | 40% | 30% | 20% | 10% |
|---|---|---|---|---|---| 
| FullKV | 0.8235 | - | - | - | - |
| StreamingLLM | - | 0.8037 | 0.7835 | 0.7537 | 0.7432 |
| H2O | - | 0.7832 | 0.7932 | 0.7428 | 0.5127 |
| PyramidKV | - | 0.7834 | 0.7934 | 0.7832 | 0.7037 |
| SnapKV | - | 0.7935 | 0.8038 | 0.7934 | 0.6827 |
| ChunkKV | - | 0.7832 | 0.7932 | 0.7835 | 0.7932 |
| ShotKV(Ours) | - | **0.8107** | **0.8082** | **0.8057** | **0.8037** |{{< /table-caption >}}
> 🔼 본 논문의 표 3은 다양한 KV 캐시 압축 방법을 사용하여 Many-shot GSM8K 벤치마크에서의 성능을 보여줍니다.  Many-shot GSM8K는 장문의 맥락을 이해하는 능력을 평가하는 벤치마크이며, 여러 개의 예시를 포함하고 있습니다. 표에서는 여러 가지 압축 비율(10%, 20%, 30%, 40%, 50%, 70%, 80%, 90%)에 따른 다양한 압축 기법(StreamingLLM, H2O, SnapKV, PyramidKV, ChunkKV)의 정확도를 보여줍니다.  FullKV는 압축을 적용하지 않은 기준 성능을 나타냅니다. 이 표를 통해 연구자들은 다양한 압축 방법의 효율성과 성능 저하 정도를 압축률에 따라 비교 분석할 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Table 3: KV cache compression methods’ performance on Many-shot GSM8K
> </details>

{{< table-caption >}}
| Benchmarks | Obs 1 | Obs 2 | Obs 3 | Obs 4 | Obs 5 | Obs 6 | Obs 6 |
|---|---|---|---|---|---|---|---| 
| MMLU [Hendrycks et al., 2020] | 5 | 5 | - | - | 0,5 | - | - |
| CommonsenseQA [Talmor et al., 2019] | 4 | 4 | - | - | - | - | - |
| GSM8K [Cobbe et al., 2021] | 8 | 8 | 1-8 | 50 | 0,8 | - | - |
| HumanEval [Chen et al., 2021] | 8 | 8 | - | - | - | - | - |
| JailBreakV [Luo et al., 2024] | 8 | 8 | - | - | - | - | - |
| LongGenBench-GSM8K [Liu et al., 2024d] | - | - | - | - | - | 35 | 20 |{{< /table-caption >}}
> 🔼 표 4는 논문의 실험 설계 부분에서 다양한 관찰(observations)에 대해 사용된 하이퍼파라미터들을 보여줍니다. 각 관찰은 서로 다른 벤치마크 작업에 대한 실험 결과를 나타내며, 각 관찰에 따라 샷(shot)의 수, 온도(temperature), 그리고 K와 T 값과 같은 하이퍼파라미터들이 다르게 설정되었음을 보여줍니다. 이 표는 실험의 재현성을 확보하고, 각 관찰에서 사용된 설정의 차이를 명확히 이해하는 데 도움을 줍니다.
> <details>
> <summary>read the caption</summary>
> Table 4: Hyperparameters for Different Observations
> </details>

{{< table-caption >}}
Benchmark | Ratio | StreamingLLM | H2O | SnapKV | PyramidKV | ChunkKV | Average ↑
---|---|---|---|---|---|---
R1-GSM8K | Baseline | R1-Distill-Llama-8B FullKV: 0.6938 |  |  |  |  | 
R1-GSM8K | 90% | 0.7167_(+3.30%) | 0.6900_(-0.55%) | 0.6933_(-0.07%) | 0.7100_(+2.34%) | 0.6867_(-1.02%) | 0.6993_(+0.79%)
R1-GSM8K | 80% | 0.6867_(-1.02%) | 0.6933_(-0.07%) | 0.7100_(+2.34%) | 0.6867_(-1.02%) | 0.6993_(+0.79%) | 
R1-GSM8K | 70% | 0.6933_(-0.07%) | 0.6633_(-4.40%) | 0.7100_(+2.34%) | 0.7100_(+2.34%) | 0.7000_(+0.89%) | 0.6953_(+0.22%)
R1-GSM8K | 60% | 0.6833_(-1.51%) | 0.6900_(-0.55%) | 0.6900_(-0.55%) | 0.7133_(+2.81%) | 0.7067_(+1.86%) | 0.6967_(+0.42%)
R1-GSM8K | 50% | 0.6700_(-3.43%) | 0.6967_(+0.42%) | 0.7067_(+1.86%) | 0.7000_(+0.89%) | 0.6867_(-1.02%) | 0.6920_(-0.26%)
R1-GSM8K | 40% | 0.6767_(-2.47%) | 0.6800_(-1.99%) | 0.5967_(-13.99%) | 0.6967_(+0.42%) | 0.7133_(+2.81%) | 0.6727_(-3.04%)
R1-GSM8K | 30% | 0.6600_(-4.87%) | 0.5900_(-14.96%) | 0.5833_(-15.93%) | 0.6700_(-3.43%) | 0.7000_(+0.89%) | 0.6407_(-7.66%)
R1-GSM8K | 20% | 0.6200_(-10.64%) | 0.4933_(-28.90%) | 0.5633_(-18.81%) | 0.6833_(-1.51%) | 0.6533_(-5.84%) | 0.6026_(-13.14%)
R1-GSM8K | 10% | 0.5167_(-25.53%) | 0.5567_(-19.76%) | 0.5767_(-16.88%) | 0.6267_(-9.67%) | 0.6433_(-7.28%) | 0.5840_(-15.82%)
GSM8K | Baseline | LLaMA-3.1-8B-Instruct FullKV: 0.7945 |  |  |  |  | 
GSM8K | 90% | 0.7695_(-3.10%) | 0.7923_(-0.30%) | 0.7839_(-1.30%) | 0.7854_(-1.10%) | 0.7824_(-1.50%) | 0.7827_(-1.50%)
GSM8K | 80% | 0.7642_(-3.80%) | 0.7938_(-0.10%) | 0.7824_(-1.50%) | 0.7900_(-0.60%) | 0.7824_(-1.50%) | 0.7826_(-1.50%)
GSM8K | 70% | 0.7642_(-3.80%) | 0.7900_(-0.60%) | 0.7923_(-0.30%) | 0.7983_(+0.50%) | 0.7809_(-1.70%) | 0.7851_(-1.20%)
GSM8K | 60% | 0.7650_(-3.70%) | 0.7809_(-1.70%) | 0.7885_(-0.80%) | 0.7923_(-0.30%) | 0.7885_(-0.80%) | 0.7830_(-1.50%)
GSM8K | 50% | 0.7657_(-3.60%) | 0.7854_(-1.10%) | 0.7847_(-1.20%) | 0.7854_(-1.10%) | 0.7824_(-1.50%) | 0.7807_(-1.70%)
GSM8K | 40% | 0.7491_(-5.70%) | 0.7688_(-3.20%) | 0.7756_(-2.40%) | 0.7839_(-1.30%) | 0.7763_(-2.30%) | 0.7707_(-3.00%)
GSM8K | 30% | 0.7051_(-11.20%) | 0.7225_(-9.10%) | 0.7619_(-4.10%) | 0.7718_(-2.90%) | 0.7733_(-2.70%) | 0.7469_(-6.00%)
GSM8K | 20% | 0.6384_(-19.70%) | 0.6406_(-19.40%) | 0.6884_(-13.40%) | 0.7142_(-10.10%) | 0.7763_(-2.30%) | 0.6916_(-13.00%)
GSM8K | 10% | 0.4784_(-39.80%) | 0.4503_(-43.30%) | 0.5034_(-36.60%) | 0.4829_(-39.20%) | 0.6566_(-17.40%) | 0.5143_(-35.30%){{< /table-caption >}}
> 🔼 표 5는 instruction-tuning 모델과 multi-step reasoning 모델에서 다양한 KV 캐시 압축 방법의 성능을 비교한 것입니다.  instruction-tuning 모델과 multi-step reasoning 모델 모두에서 다양한 압축 비율(90%, 80%, ..., 10%)에 따른 여러 벤치마크(MMLU, GSM8K 등)에서의 성능 변화를 보여줍니다. 특히,  다양한 압축 방법(StreamingLLM, H2O, SnapKV, PyramidKV, ChunkKV)의 성능을 비교하여 각 방법의 강점과 약점, 그리고 압축률에 따른 성능 저하 정도를 보여줍니다. 이를 통해 어떤 모델이 어떤 압축 방법에 더 강인한지, 어떤 벤치마크에서 압축에 더 민감한지 등을 파악할 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Table 5: Performance Comparison of Different KV Cache Compression Methods on Instruction-Tuning Model and Multi-Step Reasoning Model
> </details>

{{< table-caption >}}
Benchmark | Ratio | StreamingLLM | H2O | SnapKV | PyramidKV | ChunkKV | Average ↑
---|---|---|---|---|---|---
MMLU | Baseline | FullKV: 0.6882 |  |  |  |  | 
 | 90% | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%)
 | 80% | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%)
 | 70% | 0.6881_(-0.01%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%)
 | 60% | 0.6881_(-0.01%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%)
 | 50% | 0.6881_(-0.01%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%)
 | 40% | 0.6879_(-0.04%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6881_(-0.01%)
 | 30% |  |  |  |  |  | 
 | 20% | 0.6859_(-0.33%) | 0.6878_(-0.06%) | 0.6880_(-0.03%) | 0.6882_(+0.00%) | 0.6882_(+0.00%) | 0.6876_(-0.08%)
 | 10% | 0.6787_(-1.38%) | 0.6852_(-0.44%) | 0.6831_(-0.74%) | 0.6882_(0.00%) | 0.6842_(-0.58%) | 0.6839_(-0.63%)
GSM8K | Baseline | FullKV: 0.7945 |  |  |  |  | 
 | 90% | 0.7695_(-3.10%) | 0.7923_(-0.30%) | 0.7839_(-1.30%) | 0.7854_(-1.10%) | 0.7824_(-1.50%) | 0.7827_(-1.50%)
 | 80% | 0.7642_(-3.80%) | 0.7938_(-0.10%) | 0.7824_(-1.50%) | 0.7900_(-0.60%) | 0.7824_(-1.50%) | 0.7826_(-1.50%)
 | 70% |  |  |  |  |  | 
 | 60% | 0.7650_(-3.70%) | 0.7809_(-1.70%) | 0.7900_(-0.60%) | 0.7885_(-0.80%) | 0.7824_(-1.50%) | 0.7830_(-1.50%)
 | 50% |  |  |  |  |  | 
 | 40% | 0.7491_(-5.70%) | 0.7688_(-3.20%) | 0.7756_(-2.40%) | 0.7839_(-1.30%) | 0.7763_(-2.30%) | 0.7707_(-3.00%)
 | 30% |  |  |  |  |  | 
 | 20% |  |  |  |  |  | 
 | 10% |  |  |  |  |  | 
CSQA | Baseline | FullKV: 0.7748 |  |  |  |  | 
 | 90% | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%)
 | 80% | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%)
 | 70% |  |  |  |  |  | 
 | 60% | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%)
 | 50% |  |  |  |  |  | 
 | 40% | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7740_(-0.10%) | 0.7748_(+0.00%) | 0.7748_(+0.00%)
 | 30% |  |  |  |  |  | 
 | 20% | 0.7174_(-7.40%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7748_(+0.00%) | 0.7723_(-0.30%) | 0.7622_(-1.60%)
 | 10% | 0.6806_(-12.20%) | 0.7510_(-3.10%) | 0.7191_(-7.20%) | 0.7002_(-9.60%) | 0.7246_(-6.50%) |  
JailBreakV | Baseline | FullKV: 0.8895 |  |  |  |  | 
 | 90% | 0.8893_(-0.00%) | 0.8890_(-0.10%) | 0.8894_(-0.00%) | 0.8893_(-0.00%) | 0.8896_(+0.00%) | 0.8893_(-0.00%)
 | 80% | 0.8878_(-0.20%) | 0.8885_(-0.10%) | 0.8895_(+0.00%) | 0.8891_(-0.00%) | 0.8894_(-0.00%) | 0.8889_(-0.10%)
 | 70% | 0.8872_(-0.30%) | 0.8879_(-0.20%) | 0.8896_(+0.00%) | 0.8886_(-0.10%) | 0.8895_(+0.00%) | 0.8886_(-0.10%)
 | 60% | 0.8845_(-0.60%) | 0.8848_(-0.50%) | 0.8892_(-0.00%) | 0.8887_(-0.10%) | 0.8899_(+0.00%) | 0.8874_(-0.20%)
 | 50% | 0.8849_(-0.50%) | 0.8749_(-1.60%) | 0.8886_(-0.10%) | 0.8884_(-0.10%) | 0.8894_(-0.00%) | 0.8852_(-0.50%)
 | 40% | 0.8734_(-1.80%) | 0.8557_(-3.80%) | 0.8880_(-0.20%) | 0.8877_(-0.20%) | 0.8900_(+0.10%) | 0.8790_(-1.20%)
 | 30% | 0.8329_(-6.40%) | 0.8015_(-9.90%) | 0.8858_(-0.40%) | 0.8899_(+0.00%) | 0.8846_(-0.60%) | 0.8589_(-3.50%)
 | 20% | 0.6501_(-26.90%) | 0.7178_(-19.30%) | 0.8806_(-1.00%) | 0.8751_(-1.60%) | 0.8902_(+0.10%) | 0.8028_(-9.70%)
 | 10% | 0.5314_(-40.30%) | 0.6544_(-26.40%) | 0.8434_(-5.20%) | 0.8556_(-3.80%) | 0.8799_(-1.10%) | 0.7529_(-15.40%)
HumanEval | Baseline | FullKV: 0.5122 |  |  |  |  | 
 | 90% | 0.5061_(-1.20%) | 0.5183_(+1.20%) | 0.5122_(+0.00%) | 0.5122_(+0.00%) | 0.5122_(+0.00%) | 0.5122_(+0.00%)
 | 80% | 0.5061_(-1.20%) | 0.5366_(+4.80%) | 0.5122_(+0.00%) | 0.5183_(+1.20%) | 0.5122_(+0.00%) | 0.5134_(+0.20%)
 | 70% | 0.5000_(-2.40%) | 0.5244_(+2.40%) | 0.5122_(+0.00%) | 0.5366_(+4.80%) | 0.5122_(+0.00%) | 0.5159_(+0.70%)
 | 60% | 0.4939_(-3.60%) | 0.5427_(+6.00%) | 0.5122_(+0.00%) | 0.5061_(-1.20%) | 0.5000_(-2.40%) | 0.5049_(-1.40%)
 | 50% |  |  |  |  |  | 
 | 40% | 0.4817_(-6.00%) | 0.5305_(+3.60%) | 0.5061_(-1.20%) | 0.4939_(-3.60%) | 0.4878_(-4.80%) | 0.4841_(-5.50%)
 | 30% |  |  |  |  |  | 
 | 20% |  |  |  |  |  | 
 | 10% |  |  |  |  |  | {{< /table-caption >}}
> 🔼 표 6은 다양한 벤치마크에서 여러 가지 KV 캐시 압축 방법의 성능을 비교한 표입니다.  세부적으로는, World Knowledge(MMLU), Common Sense Reasoning(CommonsenseQA), Arithmetic Reasoning(GSM8K), Code Generation(HumanEval), Safety(JailBreakV) 등 다섯 가지 벤치마크에서 각 압축 방법의 성능 변화를 정량적으로 보여줍니다.  각 벤치마크마다 전체 KV 캐시를 사용한 기준 성능(FullKV)과 비교하여 상대적 성능 변화를 백분율로 나타냅니다. 이를 통해 다양한 작업에서 KV 캐시 압축 방법의 성능 저하 정도와 특징을 파악할 수 있습니다.
> <details>
> <summary>read the caption</summary>
> Table 6: Performance Comparison of Different KV Cache Compression Methods on Multiple Benchmarks
> </details>

{{< table-caption >}}
Setting|Ratio|StreamingLLM|H2O|SnapKV|PyramidKV|ChunkKV|Average ↑
---|---|---|---|---|---|---|---
w/ Instruct Tuning|Baseline|FullKV: 0.7945||||||
|90%|0.7695<sub>(-3.10%)</sub>|0.7923<sub>(-0.30%)</sub>|0.7839<sub>(-1.30%)</sub>|0.7854<sub>(-1.10%)</sub>|0.7824<sub>(-1.50%)</sub>|0.7827<sub>(-1.50%)</sub>
|80%|0.7642<sub>(-3.80%)</sub>|0.7938<sub>(-0.10%)</sub>|0.7824<sub>(-1.50%)</sub>|0.7900<sub>(-0.60%)</sub>|0.7824<sub>(-1.50%)</sub>|0.7826<sub>(-1.50%)</sub>
|70%|0.7642<sub>(-3.80%)</sub>|0.7900<sub>(-0.60%)</sub>|0.7923<sub>(-0.30%)</sub>|0.7983<sub>(+0.50%)</sub>|0.7809<sub>(-1.70%)</sub>|0.7851<sub>(-1.20%)</sub>
|60%|0.7650<sub>(-3.70%)</sub>|0.7809<sub>(-1.70%)</sub>|0.7923<sub>(-0.30%)</sub>|0.7885<sub>(-0.80%)</sub>|0.7885<sub>(-0.80%)</sub>|0.7830<sub>(-1.50%)</sub>
|50%|0.7657<sub>(-3.60%)</sub>|0.7854<sub>(-1.10%)</sub>|0.7847<sub>(-1.20%)</sub>|0.7854<sub>(-1.10%)</sub>|0.7824<sub>(-1.50%)</sub>|0.7807<sub>(-1.70%)</sub>
|40%|0.7491<sub>(-5.70%)</sub>|0.7688<sub>(-3.20%)</sub>|0.7756<sub>(-2.40%)</sub>|0.7839<sub>(-1.30%)</sub>|0.7763<sub>(-2.30%)</sub>|0.7707<sub>(-3.00%)</sub>
|30%|0.7051<sub>(-11.20%)</sub>|0.7225<sub>(-9.10%)</sub>|0.7619<sub>(-4.10%)</sub>|0.7718<sub>(-2.90%)</sub>|0.7733<sub>(-2.70%)</sub>|0.7469<sub>(-6.00%)</sub>
|20%|0.6384<sub>(-19.70%)</sub>|0.6406<sub>(-19.40%)</sub>|0.6884<sub>(-13.40%)</sub>|0.7142<sub>(-10.10%)</sub>|0.7763<sub>(-2.30%)</sub>|0.6916<sub>(-13.00%)</sub>
w/ R1 Distill|Baseline|R1-Distill-Llama-8B FullKV: 0.6938||||||
|90%|0.7167<sub>(+3.30%)</sub>|0.6900<sub>(-0.55%)</sub>|0.6933<sub>(-0.07%)</sub>|0.7100<sub>(+2.34%)</sub>|0.6867<sub>(-1.02%)</sub>|0.6993<sub>(+0.79%)</sub>
|80%|0.6867<sub>(-1.02%)</sub>|0.6933<sub>(-0.07%)</sub>|0.6933<sub>(-0.07%)</sub>|0.7067<sub>(+1.86%)</sub>|0.6767<sub>(-2.47%)</sub>|0.6913<sub>(-0.36%)</sub>
|70%|0.6833<sub>(-1.51%)</sub>|0.6900<sub>(-0.55%)</sub>|0.6633<sub>(-4.40%)</sub>|0.7100<sub>(+2.34%)</sub>|0.7067<sub>(+1.86%)</sub>|0.6953<sub>(+0.22%)</sub>
|60%|0.6700<sub>(-3.43%)</sub>|0.6967<sub>(+0.42%)</sub>|0.6900<sub>(-0.55%)</sub>|0.7133<sub>(+2.81%)</sub>|0.7067<sub>(+1.86%)</sub>|0.6920<sub>(-0.26%)</sub>
|50%|0.6767<sub>(-2.47%)</sub>|0.6800<sub>(-1.99%)</sub>|0.5967<sub>(-13.99%)</sub>|0.6967<sub>(+0.42%)</sub>|0.7000<sub>(+0.89%)</sub>|0.6727<sub>(-3.04%)</sub>
|40%|0.6600<sub>(-4.87%)</sub>|0.5900<sub>(-14.96%)</sub>|0.6767<sub>(-2.47%)</sub>|0.5833<sub>(-15.93%)</sub>|0.6700<sub>(-3.43%)</sub>|0.6407<sub>(-7.66%)</sub>
|30%|0.6200<sub>(-10.64%)</sub>|0.4933<sub>(-28.90%)</sub>|0.5567<sub>(-19.76%)</sub>|0.5767<sub>(-16.88%)</sub>|0.6267<sub>(-9.67%)</sub>|0.6433<sub>(-7.28%)</sub>
|20%|0.5167<sub>(-25.53%)</sub>|0.5567<sub>(-19.76%)</sub>|0.4634<sub>(-9.50%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5767<sub>(-16.88%)</sub>|0.5840<sub>(-15.82%)</sub>
w/o Instruct Tuning|Baseline|FullKV: 0.5122||||||
|90%|0.5061<sub>(-1.20%)</sub>|0.5183<sub>(+1.20%)</sub>|0.5122<sub>(+0.00%)</sub>|0.5122<sub>(+0.00%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5122<sub>(+0.00%)</sub>
|80%|0.5000<sub>(-2.40%)</sub>|0.5244<sub>(+2.40%)</sub>|0.5122<sub>(+0.00%)</sub>|0.5183<sub>(+1.20%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5134<sub>(+0.20%)</sub>
|70%|0.4817<sub>(-6.00%)</sub>|0.5427<sub>(+6.00%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5366<sub>(+4.80%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5085<sub>(-0.70%)</sub>
|60%|0.4634<sub>(-9.50%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5305<sub>(+3.60%)</sub>|0.5366<sub>(+4.80%)</sub>|0.5244<sub>(+2.40%)</sub>|0.4976<sub>(-2.90%)</sub>
|50%|0.4634<sub>(-9.50%)</sub>|0.5305<sub>(+3.60%)</sub>|0.5061<sub>(-1.20%)</sub>|0.4939<sub>(-3.60%)</sub>|0.5000<sub>(-2.40%)</sub>|0.5085<sub>(-0.70%)</sub>
|40%|0.4268<sub>(-16.70%)</sub>|0.5122<sub>(+0.00%)</sub>|0.4939<sub>(-3.60%)</sub>|0.5000<sub>(-2.40%)</sub>|0.4878<sub>(-4.80%)</sub>|0.4841<sub>(-5.50%)</sub>
|30%|0.3659<sub>(-28.60%)</sub>|0.4634<sub>(-9.50%)</sub>|0.5061<sub>(-1.20%)</sub>|0.5427<sub>(+6.00%)</sub>|0.4878<sub>(-4.80%)</sub>|0.4976<sub>(-2.90%)</sub>
|20%|0.4634<sub>(-9.50%)</sub>|0.5061<sub>(-1.20%)</sub>|0.4268<sub>(-16.70%)</sub>|0.5000<sub>(-2.40%)</sub>|0.4451<sub>(-13.10%)</sub>|0.4244<sub>(-17.20%)</sub>{{< /table-caption >}}
> 🔼 표 7은 GSM8K 벤치마크에서 다양한 지시 조정 설정을 사용한 KV 캐시 압축 성능 비교를 보여줍니다.  표는 지시 조정(Instruction Tuning)이 적용된 모델과 적용되지 않은 모델 모두에 대해 다양한 압축 비율(90%, 80%, 70%, 60%, 50%, 40%, 30%, 20%, 10%)에서의 성능 변화를 보여줍니다. 각 압축 비율에 대한 StreamingLLM, H2O, SnapKV, PyramidKV, ChunkKV 등 다양한 KV 압축 방법의 정확도를 비교하여, 지시 조정의 유무에 따른 압축에 대한 모델의 강건성을 분석합니다.  각 방법의 성능 변화는 기준(FullKV)과 비교하여 백분율로 표시됩니다.  이를 통해 지시 조정 여부에 따른 KV 캐시 압축에 대한 모델의 취약성 차이를 명확히 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Table 7: KV Cache Compression Performance Comparison on GSM8K with Different Instruction TuningSettings
> </details>

{{< table-caption >}}
 | Shot | Ratio | StreamingLLM | H2O | SnapKV | PyramidKV | ChunkKV | Average ↑ |
|---|---|---|---|---|---|---|---| 
| 1-shot | Baseline | FullKV: 0.7149 |  |  |  |  |  |
|  | 90% | 0.7013<sub>(-1.90%)</sub> | 0.7172<sub>(+0.30%)</sub> | 0.7142<sub>(-0.10%)</sub> | 0.7020<sub>(-1.80%)</sub> | 0.7172<sub>(+0.30%)</sub> | 0.7104<sub>(-0.60%)</sub> |  |
|  | 80% | 0.6892<sub>(-3.60%)</sub> | 0.7089<sub>(-0.80%)</sub> | 0.7066<sub>(-1.20%)</sub> | 0.6952<sub>(-2.80%)</sub> | 0.7081<sub>(-1.00%)</sub> | 0.7016<sub>(-1.90%)</sub> |  |
|  | 70% | 0.6816<sub>(-4.70%)</sub> | 0.6914<sub>(-3.30%)</sub> | 0.6945<sub>(-2.90%)</sub> | 0.6884<sub>(-3.70%)</sub> | 0.7127<sub>(-0.30%)</sub> | 0.6937<sub>(-3.00%)</sub> |  |
|  | 60% | 0.6884<sub>(-3.70%)</sub> | 0.6831<sub>(-4.40%)</sub> | 0.6914<sub>(-3.30%)</sub> | 0.6816<sub>(-4.70%)</sub> | 0.6990<sub>(-2.20%)</sub> | 0.6887<sub>(-3.70%)</sub> |  |
|  | 50% | 0.6952<sub>(-2.80%)</sub> | 0.6596<sub>(-7.70%)</sub> | 0.6611<sub>(-7.50%)</sub> | 0.6717<sub>(-6.00%)</sub> | 0.6732<sub>(-5.80%)</sub> | 0.6722<sub>(-6.00%)</sub> |  |
|  | 40% | 0.6657<sub>(-6.90%)</sub> | 0.6202<sub>(-13.20%)</sub> | 0.6065<sub>(-15.20%)</sub> | 0.6475<sub>(-9.40%)</sub> | 0.6050<sub>(-15.40%)</sub> | 0.6290<sub>(-12.00%)</sub> |  |
|  | 30% | 0.5118<sub>(-28.40%)</sub> | 0.5004<sub>(-30.00%)</sub> | 0.5042<sub>(-29.50%)</sub> | 0.5898<sub>(-17.50%)</sub> | 0.4011<sub>(-43.90%)</sub> | 0.5015<sub>(-29.90%)</sub> |  |
|  | 20% | 0.2320<sub>(-67.50%)</sub> | 0.2714<sub>(-62.00%)</sub> | 0.2654<sub>(-62.90%)</sub> | 0.3973<sub>(-44.40%)</sub> | 0.1319<sub>(-81.60%)</sub> | 0.2596<sub>(-63.70%)</sub> |  |
|  | 10% | 0.0296<sub>(-95.90%)</sub> | 0.0243<sub>(-96.60%)</sub> | 0.0296<sub>(-95.90%)</sub> | 0.1236<sub>(-82.70%)</sub> | 0.0190<sub>(-97.30%)</sub> | 0.0452<sub>(-93.70%)</sub> |  |
| 2-shot | Baseline | FullKV: 0.7574 |  |  |  |  |  |
|  | 90% | 0.7544<sub>(-0.40%)</sub> | 0.7604<sub>(+0.40%)</sub> | 0.7574<sub>(+0.00%)</sub> | 0.7612<sub>(+0.50%)</sub> | 0.7627<sub>(+0.70%)</sub> | 0.7592<sub>(+0.20%)</sub> |  |
|  | 80% | 0.7551<sub>(-0.30%)</sub> | 0.7521<sub>(-0.70%)</sub> | 0.7559<sub>(-0.20%)</sub> | 0.7559<sub>(-0.20%)</sub> | 0.7589<sub>(+0.20%)</sub> | 0.7556<sub>(-0.20%)</sub> |  |
|  | 70% | 0.7521<sub>(-0.70%)</sub> | 0.7453<sub>(-1.60%)</sub> | 0.7566<sub>(-0.10%)</sub> | 0.7574<sub>(+0.00%)</sub> | 0.7642<sub>(+0.90%)</sub> | 0.7551<sub>(-0.30%)</sub> |  |
|  | 60% | 0.7475<sub>(-1.30%)</sub> | 0.7506<sub>(-0.90%)</sub> | 0.7521<sub>(-0.70%)</sub> | 0.7589<sub>(+0.20%)</sub> | 0.7695<sub>(+1.60%)</sub> | 0.7557<sub>(-0.20%)</sub> |  |
|  | 50% | 0.7460<sub>(-1.50%)</sub> | 0.7437<sub>(-1.80%)</sub> | 0.7437<sub>(-1.80%)</sub> | 0.7604<sub>(+0.40%)</sub> | 0.7619<sub>(+0.60%)</sub> | 0.7511<sub>(-0.80%)</sub> |  |
|  | 40% | 0.7445<sub>(-1.70%)</sub> | 0.7081<sub>(-6.50%)</sub> | 0.7202<sub>(-4.90%)</sub> | 0.7309<sub>(-3.50%)</sub> | 0.7650<sub>(+1.00%)</sub> | 0.7337<sub>(-3.10%)</sub> |  |
|  | 30% | 0.7506<sub>(-0.90%)</sub> | 0.6133<sub>(-19.00%)</sub> | 0.6657<sub>(-12.10%)</sub> | 0.7036<sub>(-7.10%)</sub> | 0.7445<sub>(-1.70%)</sub> | 0.6955<sub>(-8.20%)</sub> |  |
|  | 20% | 0.6217<sub>(-17.90%)</sub> | 0.4412<sub>(-41.70%)</sub> | 0.4936<sub>(-34.80%)</sub> | 0.5534<sub>(-26.90%)</sub> | 0.5368<sub>(-29.10%)</sub> | 0.5293<sub>(-30.10%)</sub> |  |
|  | 10% | 0.1516<sub>(-80.00%)</sub> | 0.1759<sub>(-76.80%)</sub> | 0.1622<sub>(-78.60%)</sub> | 0.2244<sub>(-70.40%)</sub> | 0.0735<sub>(-90.30%)</sub> | 0.1575<sub>(-79.20%)</sub> |  |
| 4-shot | Baseline | FullKV: 0.7597 |  |  |  |  |  |
|  | 90% | 0.7597<sub>(+0.00%)</sub> | 0.7604<sub>(+0.10%)</sub> | 0.7650<sub>(+0.70%)</sub> | 0.7642<sub>(+0.60%)</sub> | 0.7657<sub>(+0.80%)</sub> | 0.7630<sub>(+0.40%)</sub> |  |
|  | 80% | 0.7559<sub>(-0.50%)</sub> | 0.7688<sub>(+1.20%)</sub> | 0.7695<sub>(+1.30%)</sub> | 0.7680<sub>(+1.10%)</sub> | 0.7642<sub>(+0.60%)</sub> | 0.7653<sub>(+0.70%)</sub> |  |
|  | 70% | 0.7597<sub>(+0.00%)</sub> | 0.7695<sub>(+1.30%)</sub> | 0.7688<sub>(+1.20%)</sub> | 0.7680<sub>(+1.10%)</sub> | 0.7710<sub>(+1.50%)</sub> | 0.7682<sub>(+1.10%)</sub> |  |
|  | 60% | 0.7369<sub>(-3.00%)</sub> | 0.7726<sub>(+1.70%)</sub> | 0.7688<sub>(+1.20%)</sub> | 0.7680<sub>(+1.10%)</sub> | 0.7718<sub>(+1.60%)</sub> | 0.7627<sub>(+0.40%)</sub> |  |
|  | 50% | 0.7475<sub>(-1.60%)</sub> | 0.7612<sub>(+0.20%)</sub> | 0.7619<sub>(+0.30%)</sub> | 0.7665<sub>(+0.90%)</sub> | 0.7635<sub>(+0.50%)</sub> | 0.7601<sub>(+0.10%)</sub> |  |
|  | 40% | 0.7165<sub>(-5.70%)</sub> | 0.7339<sub>(-3.40%)</sub> | 0.7377<sub>(-2.90%)</sub> | 0.7483<sub>(-1.50%)</sub> | 0.7612<sub>(+0.20%)</sub> | 0.7395<sub>(-2.70%)</sub> |  |
|  | 30% | 0.6558<sub>(-13.70%)</sub> | 0.6603<sub>(-13.10%)</sub> | 0.7111<sub>(-6.40%)</sub> | 0.7202<sub>(-4.90%)</sub> | 0.7309<sub>(-3.50%)</sub> | 0.7026<sub>(-7.50%)</sub> |  |
|  | 20% | 0.6224<sub>(-18.10%)</sub> | 0.5625<sub>(-26.00%)</sub> | 0.6065<sub>(-20.20%)</sub> | 0.6543<sub>(-13.90%)</sub> | 0.4936<sub>(-34.80%)</sub> | 0.5293<sub>(-30.10%)</sub> |  |
|  | 10% | 0.4708<sub>(-38.00%)</sub> | 0.3980<sub>(-47.60%)</sub> | 0.3995<sub>(-47.40%)</sub> | 0.4321<sub>(-43.10%)</sub> | 0.3434<sub>(-54.80%)</sub> | 0.4088<sub>(-46.20%)</sub> |  |
| 6-shot | Baseline | FullKV: 0.7680 |  |  |  |  |  |
|  | 90% | 0.7551<sub>(-1.70%)</sub> | 0.7748<sub>(+0.90%)</sub> | 0.7839<sub>(+2.10%)</sub> | 0.7794<sub>(+1.50%)</sub> | 0.7642<sub>(+0.60%)</sub> | 0.7706<sub>(+0.30%)</sub> |  |
|  | 80% | 0.7642<sub>(-0.50%)</sub> | 0.7771<sub>(+1.20%)</sub> | 0.7809<sub>(+1.70%)</sub> | 0.7771<sub>(+1.20%)</sub> | 0.7786<sub>(+1.40%)</sub> | 0.7747<sub>(+0.90%)</sub> |  |
|  | 70% | 0.7468<sub>(-2.80%)</sub> | 0.7748<sub>(+0.90%)</sub> | 0.7809<sub>(+1.70%)</sub> | 0.7733<sub>(+0.70%)</sub> | 0.7786<sub>(+1.40%)</sub> | 0.7730<sub>(+0.70%)</sub> |  |
|  | 60% | 0.7407<sub>(-3.60%)</sub> | 0.7718<sub>(+0.50%)</sub> | 0.7733<sub>(+0.70%)</sub> | 0.7666<sub>(-0.20%)</sub> | 0.7763<sub>(+1.10%)</sub> | 0.7639<sub>(-0.50%)</sub> |  |
|  | 50% | 0.7377<sub>(-3.90%)</sub> | 0.7506<sub>(-2.30%)</sub> | 0.7771<sub>(+1.20%)</sub> | 0.7718<sub>(+0.50%)</sub> | 0.7763<sub>(+1.10%)</sub> | 0.7707<sub>(-3.00%)</sub> |  |
|  | 40% | 0.7058<sub>(-8.10%)</sub> | 0.7255<sub>(-5.50%)</sub> | 0.7392<sub>(-3.70%)</sub> | 0.7491<sub>(-2.50%)</sub> | 0.7612<sub>(+0.20%)</sub> | 0.7392<sub>(-3.70%)</sub> |  |
|  | 30% | 0.6224<sub>(-18.10%)</sub> | 0.6406<sub>(-19.40%)</sub> | 0.6884<sub>(-13.40%)</sub> | 0.7142<sub>(-10.10%)</sub> | 0.7468<sub>(-1.70%)</sub> | 0.7730<sub>(+0.70%)</sub> |  |
|  | 20% | 0.5921<sub>(-22.90%)</sub> | 0.6232<sub>(-18.80%)</sub> | 0.6732<sub>(-12.30%)</sub> | 0.6960<sub>(-9.40%)</sub> | 0.7468<sub>(-1.70%)</sub> | 0.6702<sub>(-12.70%)</sub> |  |
|  | 10% | 0.4572<sub>(-40.50%)</sub> | 0.4481<sub>(-41.60%)</sub> | 0.4958<sub>(-35.40%)</sub> | 0.4458<sub>(-41.90%)</sub> | 0.5565<sub>(-27.50%)</sub> | 0.4807<sub>(-37.40%)</sub> |  |{{< /table-caption >}}
> 🔼 표 8은 GSM8K 벤치마크에서 다양한 샷(shot) 개수에 따른 성능 비교 결과를 보여줍니다.  다양한 압축률에서 1-shot, 2-shot, 4-shot, 6-shot, 8-shot 시나리오를 비교 분석하여, 샷의 개수가 KV 캐시 압축에 대한 모델의 민감도에 어떻게 영향을 미치는지 보여줍니다.  특히, 짧은 프롬프트(샷 수가 적은 경우)가 압축에 더 민감하게 반응하는 것을 보여주는 결과가 포함되어 있습니다.  각 샷 시나리오마다 여러 가지 KV 압축 방법의 성능이 제시됩니다.
> <details>
> <summary>read the caption</summary>
> Table 8: Performance Comparison of Different Shot Numbers on GSM8K
> </details>

{{< table-caption >}}
Benchmark|Ratio|StreamingLLM|H2O|SnapKV|PyramidKV|ChunkKV|Average ↑
---|---|---|---|---|---|---|---
Many-shot GSM8K|Baseline|LLaMA-3.1-8B-Instruct FullKV: 0.8235|||||
|90%|0.7728<sub>(-6.16%)</sub>|0.8142<sub>(-1.13%)</sub>|0.8137<sub>(-1.19%)</sub>|0.7932<sub>(-3.68%)</sub>|0.8233<sub>(-0.02%)</sub>|0.8034<sub>(-2.44%)</sub>
|80%|0.7935<sub>(-3.64%)</sub>|0.8334<sub>(+1.20%)</sub>|0.8138<sub>(-1.18%)</sub>|0.8037<sub>(-2.40%)</sub>|0.7932<sub>(-3.68%)</sub>|0.8075<sub>(-1.94%)</sub>
|70%|0.8038<sub>(-2.39%)</sub>|0.8136<sub>(-1.20%)</sub>|0.7832<sub>(-4.89%)</sub>|0.7932<sub>(-3.68%)</sub>|0.8037<sub>(-2.40%)</sub>|0.7995<sub>(-2.91%)</sub>
|60%|0.7932<sub>(-3.68%)</sub>|0.8142<sub>(-1.13%)</sub>|0.8037<sub>(-2.40%)</sub>|0.7935<sub>(-3.64%)</sub>|0.8038<sub>(-2.39%)</sub>|0.8017<sub>(-2.65%)</sub>
|50%|0.7934<sub>(-3.65%)</sub>|0.8137<sub>(-1.19%)</sub>|0.7932<sub>(-3.68%)</sub>|0.7835<sub>(-4.86%)</sub>|0.7954<sub>(-3.41%)</sub>|
|40%|0.8037<sub>(-2.40%)</sub>|0.7832<sub>(-4.89%)</sub>|0.7935<sub>(-3.64%)</sub>|0.7834<sub>(-4.87%)</sub>|0.7832<sub>(-4.89%)</sub>|0.7894<sub>(-4.14%)</sub>
|30%|0.7835<sub>(-4.86%)</sub>|0.7932<sub>(-3.68%)</sub>|0.8038<sub>(-2.39%)</sub>|0.7934<sub>(-3.65%)</sub>|0.7932<sub>(-3.68%)</sub>|0.7934<sub>(-3.65%)</sub>
|20%|0.7537<sub>(-8.47%)</sub>|0.7428<sub>(-9.80%)</sub>|0.7934<sub>(-3.65%)</sub>|0.7832<sub>(-4.89%)</sub>|0.7835<sub>(-4.86%)</sub>|0.7713<sub>(-6.34%)</sub>
|10%|0.7432<sub>(-9.75%)</sub>|0.5127<sub>(-37.74%)</sub>|0.6827<sub>(-17.10%)</sub>|0.7037<sub>(-14.55%)</sub>|0.7932<sub>(-3.68%)</sub>|0.6871<sub>(-16.56%)</sub>
Many-shot GSM8K|Baseline|R1-Distill-Llama-8B FullKV: 0.7123|||||
|90%|0.7123<sub>(+1.42%)</sub>|0.6612<sub>(-5.85%)</sub>|0.6534<sub>(-6.96%)</sub>|0.6912<sub>(-1.58%)</sub>|0.6923<sub>(-1.42%)</sub>|0.6821<sub>(-2.88%)</sub>
|80%|0.7234<sub>(+3.00%)</sub>|0.6534<sub>(-6.96%)</sub>|0.7123<sub>(+1.42%)</sub>|0.6423<sub>(-8.54%)</sub>|0.7123<sub>(+1.42%)</sub>|0.6887<sub>(-1.94%)</sub>
|70%|0.7412<sub>(+5.54%)</sub>|0.6523<sub>(-7.12%)</sub>|0.7234<sub>(+3.00%)</sub>|0.6923<sub>(-1.42%)</sub>|0.7234<sub>(+3.00%)</sub>|0.7065<sub>(+0.60%)</sub>
|60%|0.7423<sub>(+5.69%)</sub>|0.6912<sub>(-1.58%)</sub>|0.6912<sub>(-1.58%)</sub>|0.6823<sub>(-2.85%)</sub>|0.6634<sub>(-5.54%)</sub>|0.6941<sub>(-1.17%)</sub>
|50%|0.7234<sub>(+3.00%)</sub>|0.7134<sub>(+1.58%)</sub>|0.7312<sub>(+4.12%)</sub>|0.7123<sub>(+1.42%)</sub>|0.7123<sub>(+1.42%)</sub>|0.7185<sub>(+2.31%)</sub>
|40%|0.7123<sub>(+1.42%)</sub>|0.6923<sub>(-1.42%)</sub>|0.6923<sub>(-1.42%)</sub>|0.7023<sub>(+0.00%)</sub>|0.7234<sub>(+3.00%)</sub>|0.7045<sub>(+0.31%)</sub>
|30%|0.6523<sub>(-7.12%)</sub>|0.7312<sub>(+4.12%)</sub>|0.6634<sub>(-5.54%)</sub>|0.7423<sub>(+5.69%)</sub>|0.6912<sub>(-1.58%)</sub>|0.6961<sub>(-0.88%)</sub>
|20%|0.6912<sub>(-1.58%)</sub>|0.5834<sub>(-16.93%)</sub>|0.5123<sub>(-27.05%)</sub>|0.6823<sub>(-2.85%)</sub>|0.6634<sub>(-5.54%)</sub>|0.6265<sub>(-10.79%)</sub>
|10%|0.6323<sub>(-9.97%)</sub>|0.5423<sub>(-22.78%)</sub>|0.5412<sub>(-22.94%)</sub>|0.5923<sub>(-15.66%)</sub>|0.6823<sub>(-2.85%)</sub>|0.5981<sub>(-14.84%)</sub>{{< /table-caption >}}
> 🔼 표 9는 다양한 KV 캐시 압축 방법을 사용하여 many-shot GSM8K 벤치마크에서의 성능을 비교한 결과를 보여줍니다.  many-shot 설정에서 다양한 압축 비율(90%, 80%, ..., 10%) 하에서 여러 압축 기법 (StreamingLLM, H2O, SnapKV, PyramidKV, ChunkKV)의 성능을 측정하고,  기준 성능(FullKV)과 비교하여 상대적 성능 변화를 보여줍니다.  LLaMA-3.1-8B-Instruct 및 DeepSeek R1-Distill 두 모델에 대한 결과를 각각 제시하여,  모델의 구조와 압축에 대한 민감도의 상관관계를 분석합니다. 표는 각 압축 기법의 정확도를 수치로 제시하며, 압축률이 높아짐에 따라 성능 저하 정도를 비교 분석하는 데 유용합니다.
> <details>
> <summary>read the caption</summary>
> Table 9: Performance Comparison of Different KV Cache Compression Methods on Many-shot GSM8K
> </details>

{{< table-caption >}}
| Dataset | Task Type | # Test | Metric | Evaluation Method |
|---|---|---|---|---|
| MMLU (Hendrycks et al., 2020) | World Knowledge | 14,079 | Accuracy | Generation-Based |
| GSM8K (Cobbe et al., 2021) | Arithmetic | 1,319 | Exact match | Generation-Based |
| CSQA* (Talmor et al., 2019) | Commonsense | 1,221 | Accuracy | Generation-Based |
| HumanEval (Chen et al., 2021) | Code Generation | 164 | Pass@1 rate | Generation-Based |
| JailBreakV (Luo et al., 2024) | Safety | 28,000 | Attack success rate | Generation-Based |{{< /table-caption >}}
> 🔼 이 표는 논문에서 사용된 데이터셋들의 통계량을 보여줍니다.  각 데이터셋의 이름, 과업 유형(예: 세계 지식, 상식 추론, 산술 추론, 코드 생성, 안전), 테스트 데이터 수, 평가 지표(예: 정확도, 정답률, 통과율, 공격 성공률), 그리고 평가 방법(예: 생성 기반) 등이 포함되어 있습니다.  #Train은 학습 데이터 수, #Test는 테스트 데이터 수를 나타냅니다.
> <details>
> <summary>read the caption</summary>
> Table 10: The statistics of the datasets used in this paper. # Test denote the number of training data and test data, respectively.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}