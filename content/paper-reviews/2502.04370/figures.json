[{"figure_path": "https://arxiv.org/html/2502.04370/x1.png", "caption": "Figure 1: Overview of our method.\nDreamDPO first constructs pairwise examples, then compares their alignment with human preferences using reward or large multimodal models, and lastly optimizes the 3D presentation with a preference-driven loss function. The loss function pulls the win example \ud835\udc31twinsuperscriptsubscript\ud835\udc31\ud835\udc61win\\mathbf{x}_{t}^{\\text{win}}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT win end_POSTSUPERSCRIPT closer and pushes the lose example \ud835\udc31tlosesuperscriptsubscript\ud835\udc31\ud835\udc61lose\\mathbf{x}_{t}^{\\text{lose}}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT lose end_POSTSUPERSCRIPT away.\nAs a piecewise objective, it selectively pushes \ud835\udc31tlosesuperscriptsubscript\ud835\udc31\ud835\udc61lose\\mathbf{x}_{t}^{\\text{lose}}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT lose end_POSTSUPERSCRIPT only when the preference score gap sgapsubscript\ud835\udc60gaps_{\\text{gap}}italic_s start_POSTSUBSCRIPT gap end_POSTSUBSCRIPT exceeds a threshold \u03c4\ud835\udf0f\\tauitalic_\u03c4, preventing chaotic gradients from overly similar \ud835\udc31tlosesuperscriptsubscript\ud835\udc31\ud835\udc61lose\\mathbf{x}_{t}^{\\text{lose}}bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT lose end_POSTSUPERSCRIPT.", "description": "\uadf8\ub9bc 1\uc740 DreamDPO \ubc29\ubc95\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. DreamDPO\ub294 \uba3c\uc800 \uc30d\uc73c\ub85c \ub41c \uc608\uc2dc\ub4e4\uc744 \ub9cc\ub4e4\uace0, \ubcf4\uc0c1 \ubaa8\ub378\uc774\ub098 \ub300\uaddc\ubaa8 \ub2e4\uc911 \ubaa8\ub4dc \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0ac\ub78c\uc758 \uc120\ud638\ub3c4\uc640\uc758 \uc815\ub82c\uc744 \ube44\uad50\ud55c \ub2e4\uc74c, \uc120\ud638\ub3c4 \uae30\ubc18 \uc190\uc2e4 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec 3D \ud45c\ud604\uc744 \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4. \uc190\uc2e4 \ud568\uc218\ub294 '\uc774\uae30\ub294' \uc608\uc2dc(xwin)\uc744 \ub354 \uac00\uae5d\uac8c \ub04c\uc5b4\ub2f9\uae30\uace0, '\uc9c0\ub294' \uc608\uc2dc(xlose)\ub97c \uba40\ub9ac \ubc00\uc5b4\ub0c5\ub2c8\ub2e4. \uc870\uac01\ubcc4 \ubaa9\uc801 \ud568\uc218\ub85c\uc11c, \uc120\ud638\ub3c4 \uc810\uc218 \ucc28\uc774(sgap)\uac00 \uc784\uacc4\uac12(\u03c4)\uc744 \ucd08\uacfc\ud560 \ub54c\uc5d0\ub9cc xlose\ub97c \uc120\ud0dd\uc801\uc73c\ub85c \ubc00\uc5b4\ub0b4\uc5b4, \ub108\ubb34 \uc720\uc0ac\ud55c xlose\ub85c \uc778\ud55c \ud63c\ub780\uc2a4\ub7ec\uc6b4 \uae30\uc6b8\uae30\ub97c \ubc29\uc9c0\ud569\ub2c8\ub2e4.", "section": "3 Method"}, {"figure_path": "https://arxiv.org/html/2502.04370/x2.png", "caption": "Figure 2: \nQualitative comparisons on the benchmark of GPTEval3D\u00a0[25].\nExisting methods struggle with text matching, as marked in red.\nDreamDPO improves text matching, which provides better human preference results.\n(Zoom in to see the details.)", "description": "\uadf8\ub9bc 2\ub294 GPTEval3D \ubca4\uce58\ub9c8\ud06c [25]\uc5d0 \ub300\ud55c \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \uae30\uc874 \ubc29\ubc95\ub4e4\uc740 \uc81c\uc2dc\ub41c \ud14d\uc2a4\ud2b8\uc640 \uc77c\uce58\ud558\ub294 3D \ubaa8\ub378 \uc0dd\uc131\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \ubc18\uba74, DreamDPO\ub294 \ud14d\uc2a4\ud2b8 \ub9e4\uce6d\uc744 \uac1c\uc120\ud558\uc5ec \uc0ac\ub78c\uc758 \uc120\ud638\ub3c4\uc5d0 \ub354 \ubd80\ud569\ud558\ub294 \uace0\ud488\uc9c8\uc758 3D \ubaa8\ub378\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ud655\ub300\ud558\uc5ec \ud655\uc778\ud558\uc2ed\uc2dc\uc624.", "section": "4.2 \uae30\uc874 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2502.04370/x3.png", "caption": "Figure 3: \nQualitative comparisons with MVDream\u00a0[7].\nDreamDPO performs well across short to long prompts, offering better human preference results, marked in red.\u00a0(Zoom in to see the details.)", "description": "\uc774 \uadf8\ub9bc\uc740 DreamDPO\uc640 MVDream [7]\uc758 \uc131\ub2a5\uc744 \uc9e7\uc740 \ud504\ub86c\ud504\ud2b8\uc640 \uae34 \ud504\ub86c\ud504\ud2b8 \ubaa8\ub450\uc5d0\uc11c \ube44\uad50\ud55c \uc815\uc131\uc801 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \ubd80\ubd84\uc740 DreamDPO\uac00 MVDream\ubcf4\ub2e4 \uc0ac\ub78c\uc758 \uc120\ud638\ub3c4\ub97c \ub354 \uc798 \ubc18\uc601\ud558\ub294 \uacb0\uacfc\ub97c \uc0dd\uc131\ud588\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. DreamDPO\ub294 \uc9e7\uace0 \uae34 \ud504\ub86c\ud504\ud2b8 \ubaa8\ub450\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uba70, \ud14d\uc2a4\ud2b8 \uc77c\uce58\ub3c4\uac00 \ud5a5\uc0c1\ub418\uace0, \ub354 \ub192\uc740 \ud488\uc9c8\uc758 \uc9c8\uac10\uacfc \uae30\ud558\ud559\uc801 \ub514\ud14c\uc77c\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc758 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ud655\ub300\ud558\uc5ec \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 \ube44\uad50\ubd84\uc11d: \uae30\uc874 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2502.04370/x4.png", "caption": "Figure 4: The analysis of backbone.\nWe present the results of DreamDPO using Stable Diffusion v2.1 (SD2.1)\u00a0[17].\nDreamDPO demonstrates effective performance with SD2.1, highlighting its potential to leverage more advanced backbone diffusion models for further improvements.", "description": "\uadf8\ub9bc 4\ub294 DreamDPO \ubaa8\ub378\uc758 \ubc31\ubcf8(backbone)\uc73c\ub85c Stable Diffusion v2.1 [17]\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \uc2e4\ud5d8\uc740 DreamDPO\uac00 SD2.1\uacfc \uac19\uc740 \uace0\uae09 \ubc31\ubcf8 \ud655\uc0b0 \ubaa8\ub378\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uc5ec \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud55c \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70,  DreamDPO\uac00 SD2.1\uc744 \ubc31\ubcf8\uc73c\ub85c \uc0ac\uc6a9\ud588\uc744 \ub54c\uc5d0\ub3c4 \uace0\ud488\uc9c8\uc758 3D \ubaa8\ub378\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc99d\uba85\ud569\ub2c8\ub2e4. \ud5a5\ud6c4 \ub354\uc6b1 \ubc1c\uc804\ub41c \ubc31\ubcf8 \ud655\uc0b0 \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uba74 DreamDPO\uc758 \uc131\ub2a5\uc774 \ub354\uc6b1 \ud5a5\uc0c1\ub420 \uac00\ub2a5\uc131\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 \ub354 \uc790\uc138\ud55c \ubd84\uc11d \ubc0f \uc815\ub2f9\ud654"}, {"figure_path": "https://arxiv.org/html/2502.04370/x5.png", "caption": "Figure 5: The analysis of reward models.\nWe present the results of DreamDPO using ImageReward\u00a0[26].\nDreamDPO demonstrates effective performance with ImageReward, highlighting its potential to leverage stronger reward models to further enhance generation quality.", "description": "\uc774 \uadf8\ub9bc\uc740 DreamDPO \ubaa8\ub378\uc774 ImageReward \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ImageReward\ub294 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc0ac\ub78c\uc758 \uc120\ud638\ub3c4\ub97c \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ub294 \ubcf4\uc0c1 \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 DreamDPO\uac00 ImageReward\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud6a8\uacfc\uc801\uc778 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uace0, \ub354\uc6b1 \uac15\ub825\ud55c \ubcf4\uc0c1 \ubaa8\ub378\uc744 \ud65c\uc6a9\ud558\uba74 \uc0dd\uc131 \ud488\uc9c8\uc744 \ub354\uc6b1 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 More Analyses and Justifications"}, {"figure_path": "https://arxiv.org/html/2502.04370/x6.png", "caption": "Figure 6: \nThe analysis of the score gap threshold \u03c4\ud835\udf0f\\tauitalic_\u03c4.\nWe conduct 2D toy experiments with \u03c4\ud835\udf0f\\tauitalic_\u03c4 ranging from 0.010.010.010.01 to 00.\nThe results indicate that a small but non-zero \u03c4\ud835\udf0f\\tauitalic_\u03c4 effectively filters out overly similar lose examples, leading to more detailed outputs.", "description": "\uadf8\ub9bc 6\uc740 \uc810\uc218 \ucc28\uc774 \uc784\uacc4\uac12 \u03c4(tau)\uc5d0 \ub300\ud55c \ubd84\uc11d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5f0\uad6c\uc9c4\uc740 \u03c4 \uac12\uc744 0.01\uc5d0\uc11c 0\uae4c\uc9c0 \ubcc0\ud654\uc2dc\ud0a4\uba74\uc11c 2\ucc28\uc6d0 \ud1a0\uc774 \uc2e4\ud5d8\uc744 \uc218\ud589\ud588\uc2b5\ub2c8\ub2e4. \uadf8 \uacb0\uacfc, \uc791\uc9c0\ub9cc 0\uc774 \uc544\ub2cc \u03c4 \uac12\uc740 \uc720\uc0ac\ud55c 'lose' \uc608\uc2dc\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uac78\ub7ec\ub0b4\uc5b4 \ub354\uc6b1 \uc0c1\uc138\ud55c \uacb0\uacfc\ubb3c\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uae30\uc5ec\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989,  \u03c4 \uac12\uc774 \ub108\ubb34 \uc791\uc73c\uba74 \ube44\uc2b7\ud55c \uacb0\uacfc\ubb3c\ub4e4\uc744 \uad6c\ubd84\ud558\uc9c0 \ubabb\ud558\uace0, \ub108\ubb34 \ud06c\uba74 \uc88b\uc740 \uacb0\uacfc\ubb3c\ub4e4\uc744 \uc81c\uc678\ud560 \uc218 \uc788\uc73c\ubbc0\ub85c \uc801\uc808\ud55c \u03c4 \uac12\uc744 \uc124\uc815\ud558\ub294 \uac83\uc774 \uc911\uc694\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 More Analyses and Justifications"}, {"figure_path": "https://arxiv.org/html/2502.04370/x7.png", "caption": "Figure 7: \nQualitative comparisons with DreamReward\u00a0[12].\nDreamDPO improves both text matching (marked in red) and geometric/texture details.", "description": "\uadf8\ub9bc 7\uc740 DreamReward [12]\uc640 \ube44\uad50\ud558\uc5ec \uc81c\uc548\ub41c DreamDPO \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \ubd80\ubd84\ucc98\ub7fc DreamDPO\ub294 \ud14d\uc2a4\ud2b8 \ub9e4\uce6d\uc744 \uac1c\uc120\ud558\uace0 \uae30\ud558\ud559\uc801 \ubc0f \uc9c8\uac10 \uc138\ubd80 \uc815\ubcf4\ub97c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. DreamReward\ub294 \uc591\ud638\ud55c \ud654\uc9c8\uc758 3D \uc790\uc0b0\uc744 \uc0dd\uc131\ud558\uc9c0\ub9cc, \ud14d\uc2a4\ud2b8\uc640 \uc77c\uce58\ud558\uc9c0 \uc54a\ub294 \uacbd\uc6b0\uac00 \ub9ce\uace0(\uc608: \uc790\uc804\uac70\uc5d0 \uaf43\uc78e\uc774 \uc788\ub294 \uacbd\uc6b0), \uc138\ubd80 \uc0ac\ud56d\uc774 \ubd80\uc871\ud55c \ubc18\uba74 DreamDPO\ub294 \ud14d\uc2a4\ud2b8\uc640\uc758 \uc815\ud569\uc131\uc744 \uac1c\uc120\ud558\uace0 \uc9c8\uac10 \ubc0f \uae30\ud558\ud559\uc801 \ub514\ud14c\uc77c\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \ube44\uad50\ubd84\uc11d: \uae30\uc874 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2502.04370/x8.png", "caption": "Figure 8: \nThe generation results of DreamDPO with large multi-modal models (LMMs).\nWe explore the potential of our method to leverage LMMs, such as QwenVL\u00a0[41] for explicit guidance in correcting the number and attribute of 3D assets. The left corner shows the details of pairwise comparisons using the LMM, including the question and win/lose criteria.\nBy carefully designing the question, DreamDPO can leverage both win and lose examples to guide optimization. (Zoom in to see the details.)", "description": "\uadf8\ub9bc 8\uc740 DreamDPO\uac00 \ub300\uaddc\ubaa8 \ub2e4\uc911 \ubaa8\ub2ec \ubaa8\ub378(LMM)\uc744 \uc0ac\uc6a9\ud558\uc5ec 3D \uc790\uc0b0 \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. QwenVL [41]\uacfc \uac19\uc740 LMM\uc744 \ud65c\uc6a9\ud558\uc5ec 3D \uc790\uc0b0\uc758 \uac1c\uc218\uc640 \uc18d\uc131\uc744 \uc218\uc815\ud558\ub294 \uba85\uc2dc\uc801 \uc9c0\uce68\uc744 \uc81c\uacf5\ud558\ub294 \ubc29\ubc95\uc758 \uc7a0\uc7ac\ub825\uc744 \ud0d0\uad6c\ud569\ub2c8\ub2e4. \uadf8\ub9bc \uc67c\ucabd \uc0c1\ub2e8\uc5d0\ub294 LMM\uc744 \uc0ac\uc6a9\ud55c \uc30d \ube44\uad50\uc758 \uc138\ubd80 \uc815\ubcf4\uac00 \ub098\uc640 \uc788\uc73c\uba70, \uc5ec\uae30\uc5d0\ub294 \uc9c8\ubb38\uacfc \uc2b9/\ud328 \uae30\uc900\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc9c8\ubb38\uc744 \uc2e0\uc911\ud558\uac8c \uc124\uacc4\ud568\uc73c\ub85c\uc368 DreamDPO\ub294 \ucd5c\uc801\ud654\ub97c \uc548\ub0b4\ud558\ub294 \ub370 \uc2b9/\ud328 \uc608\uc81c\ub97c \ubaa8\ub450 \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 More Analyses and Justifications"}, {"figure_path": "https://arxiv.org/html/2502.04370/x9.png", "caption": "Figure 9: The analysis of pairwise example construction.\nWe compare (1) different noises: adding different Gaussian noises with the same timesteps, and (2) difference timesteps: adding the same Gaussian noise with different timesteps.", "description": " \uadf8\ub9bc 9\ub294 \uc30d\uc73c\ub85c \uc774\ub8e8\uc5b4\uc9c4 \uc608\uc2dc \uc0dd\uc131 \uacfc\uc815\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc77c\ud55c \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \uc11c\ub85c \ub2e4\ub978 \uac00\uc6b0\uc2dc\uc548 \ub178\uc774\uc988\ub97c \ucd94\uac00\ud558\ub294 \ubc29\ubc95(1)\uacfc, \uc11c\ub85c \ub2e4\ub978 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub3d9\uc77c\ud55c \uac00\uc6b0\uc2dc\uc548 \ub178\uc774\uc988\ub97c \ucd94\uac00\ud558\ub294 \ubc29\ubc95(2)\uc758 \ub450 \uac00\uc9c0 \ubc29\ubc95\uc744 \ube44\uad50\ud558\uc5ec \uc5b4\ub5a4 \ubc29\ubc95\uc774 \ub354 \ud6a8\uacfc\uc801\uc778\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0 \uc30d\uc758 \ud488\uc9c8\uacfc \ub2e4\uc591\uc131\uc5d0 \uc5b4\ub5a4 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \ube44\uad50\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574, DreamDPO \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud558\uae30 \uc704\ud55c \ucd5c\uc801\uc758 \uc608\uc2dc \uc0dd\uc131 \uc804\ub7b5\uc744 \uacb0\uc815\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4.3 More Analyses and Justifications"}, {"figure_path": "https://arxiv.org/html/2502.04370/x10.png", "caption": "Figure 10: The further application of DreamDPO.\nWe conduct toy experiments on text-to-avatar generation by combining DreamDPO with Gaussian-based avatar generation framework\u00a0[48]. More details can be checked in Appendix\u00a0B.3.", "description": "\uadf8\ub9bc 10\uc740 DreamDPO\uc758 \ucd94\uac00\uc801\uc778 \ud65c\uc6a9 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Gaussian \uae30\ubc18 \uc544\ubc14\ud0c0 \uc0dd\uc131 \ud504\ub808\uc784\uc6cc\ud06c[48]\uc640 DreamDPO\ub97c \uacb0\ud569\ud558\uc5ec \uac04\ub2e8\ud55c \uc2e4\ud5d8\uc744 \ud1b5\ud574 text-to-avatar \uc0dd\uc131\uc744 \uc218\ud589\ud588\uc2b5\ub2c8\ub2e4.  DreamDPO\uac00 \uae30\uc874\uc758 Gaussian \uae30\ubc18 \uc544\ubc14\ud0c0 \uc0dd\uc131 \ubc29\uc2dd\uc744 \uac1c\uc120\ud558\uc5ec \ub354\uc6b1 \ud5a5\uc0c1\ub41c \uc544\ubc14\ud0c0\ub97c \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\uc785\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ubd80\ub85d B.3\uc808\uc744 \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4.3 More Analyses and Justifications"}, {"figure_path": "https://arxiv.org/html/2502.04370/x11.png", "caption": "Figure 11: More qualitative results using DreamDPO.", "description": "\uc774 \uadf8\ub9bc\uc740 DreamDPO\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ucd94\uac00\uc801\uc778 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  MVDream \ubaa8\ub378\uc758 \uacb0\uacfc\uc640 \ube44\uad50\ud558\uc5ec DreamDPO\uac00 \ud14d\uc2a4\ud2b8\uc640 \ub354 \uc798 \uc77c\uce58\ud558\uace0 \uae30\ud558\ud559\uc801 \ubc0f \uc9c8\uac10 \uc138\ubd80 \uc0ac\ud56d\uc774 \ud5a5\uc0c1\ub41c \uace0\ud488\uc9c8 3D \uc790\uc0b0\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud589\uc740 \ud2b9\uc815 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud55c \ub450 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uba70,  DreamDPO\uc758 \uacb0\uacfc\uac00 \ud504\ub86c\ud504\ud2b8\ub97c \ub354 \uc815\ud655\ud558\uac8c \ubc18\uc601\ud558\uace0 \ub354\uc6b1 \uc138\ubc00\ud558\uace0 \ud604\uc2e4\uac10 \uc788\ub294 3D \ubaa8\ub378\uc744 \uc0dd\uc131\ud568\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \uc815\uc131\uc801 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2502.04370/x12.png", "caption": "Figure 12: More qualitative results using DreamDPO.", "description": "\uadf8\ub9bc 12\ub294 DreamDPO\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ud55c \ucd94\uac00\uc801\uc778 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  DreamDPO\uac00 \ub2e4\uc591\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud574 \uace0\ud488\uc9c8\uc758 3D \uc790\uc0b0\uc744 \uc0dd\uc131\ud558\uace0, \ud14d\uc2a4\ud2b8\uc640\uc758 \uc815\ub82c \ubc0f \uae30\ud558\ud559\uc801/\uc9c8\uac10 \uc138\ubd80 \uc0ac\ud56d\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uc608\uc2dc \uc774\ubbf8\uc9c0\ub4e4\uc744 \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ubbf8\uc9c0\ub294 \ub2e4\uc591\ud55c \uac1d\uccb4\uc640 \uc7a5\uba74\uc744 \ud3ec\ucc29\ud558\uc5ec DreamDPO\uc758 \uc720\uc5f0\uc131\uacfc \uc801\uc751\ub825\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "4.2.1 \uc815\uc131\uc801 \ube44\uad50"}]