{"references": [{"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2022-09-14", "reason": "This paper introduces DreamFusion, a pioneering work in text-to-3D generation that directly leverages 2D diffusion models, significantly influencing subsequent research in this field."}, {"fullname_first_author": "Zhengyi Wang", "paper_title": "Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation", "publication_date": "2023-05-16", "reason": "ProlificDreamer enhances text-to-3D generation by incorporating variational score distillation, leading to higher-fidelity and more diverse outputs, setting a new standard for quality and diversity."}, {"fullname_first_author": "Yichun Shi", "paper_title": "Mvdream: Multi-view diffusion for 3d generation", "publication_date": "2023-08-16", "reason": "MVDream introduces a novel multi-view diffusion approach for 3D generation, which tackles the challenge of multi-view consistency in generated 3D models, improving the overall realism and coherence."}, {"fullname_first_author": "Junliang Ye", "paper_title": "Dreamreward: Text-to-3d generation with human preference", "publication_date": "2025-00-00", "reason": "DreamReward directly integrates human preferences into the text-to-3D generation pipeline through reward modeling, enhancing the alignment between generated outputs and human expectations."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces significant advancements in high-resolution image synthesis using latent diffusion models, providing a foundation for subsequent improvements in text-to-3D generation, where high-quality images are essential for effective 3D reconstruction."}]}