[{"figure_path": "https://arxiv.org/html/2502.06155/x1.png", "caption": "Figure 1: We observe the\u00a0Attention Tile\u00a0pattern in 3D DiTs. (a) the attention map can be broken down into smaller repetitive blocks. (b) These blocks can be classified into two types, where attention weights on the diagonal blocks are noticeably larger than on off-diagonal ones. (c) These blocks exhibit locality, where the attention score differences between the first frame and later frames gradually increases. (d) The block structure is stable across different data points, but varies across layers. We randomly select 2 prompts (one landscape and one portrait) and record the important positions in the attention map that accounted for 90% (95%, 99%) of the total. We printed the proportion of stable overlap of important positions across layers.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 3D \ud655\uc0b0 \ud2b8\ub79c\uc2a4\ud3ec\uba38(DiT)\uc5d0\uc11c \uad00\ucc30\ub418\ub294 \uc8fc\ubaa9 \ud328\ud134\uc778 \uc5b4\ud150\uc158 \ud0c0\uc77c(Attention Tile)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc5b4\ud150\uc158 \ub9f5\uc774 \uc791\uace0 \ubc18\ubcf5\uc801\uc778 \ube14\ub85d\ub4e4\ub85c \ub098\ub260 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 \uc774\ub7ec\ud55c \ube14\ub85d\ub4e4\uc744 \ub300\uac01\uc120 \ube14\ub85d\uacfc \ub300\uac01\uc120\uc774 \uc544\ub2cc \ube14\ub85d\uc758 \ub450 \uac00\uc9c0 \uc720\ud615\uc73c\ub85c \ubd84\ub958\ud560 \uc218 \uc788\uc73c\uba70, \ub300\uac01\uc120 \ube14\ub85d\uc758 \uc5b4\ud150\uc158 \uac00\uc911\uce58\uac00 \ub300\uac01\uc120\uc774 \uc544\ub2cc \ube14\ub85d\ubcf4\ub2e4 \ud604\uc800\ud788 \ud06c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (c)\ub294 \uc774\ub7ec\ud55c \ube14\ub85d\ub4e4\uc774 \uc9c0\uc5ed\uc131(locality)\uc744 \ub098\ud0c0\ub0b4\uba70, \uccab \ubc88\uc9f8 \ud504\ub808\uc784\uacfc \ub098\uc911 \ud504\ub808\uc784 \uac04\uc758 \uc5b4\ud150\uc158 \uc810\uc218 \ucc28\uc774\uac00 \uc810\uc9c4\uc801\uc73c\ub85c \uc99d\uac00\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (d)\ub294 \ube14\ub85d \uad6c\uc870\uac00 \uc11c\ub85c \ub2e4\ub978 \ub370\uc774\ud130 \ud3ec\uc778\ud2b8\uc5d0\uc11c \uc548\uc815\uc801\uc774\uc9c0\ub9cc \ub808\uc774\uc5b4 \uac04\uc5d0\ub294 \ub2e4\ub984\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c, \uc784\uc758\ub85c \uc120\ud0dd\ub41c \ub450 \uac1c\uc758 \ud504\ub86c\ud504\ud2b8(\ud48d\uacbd \ubc0f \uc778\ubb3c \uc0ac\uc9c4)\uc5d0 \ub300\ud574 \uc5b4\ud150\uc158 \ub9f5\uc5d0\uc11c \uc804\uccb4\uc758 90%, 95%, 99%\ub97c \ucc28\uc9c0\ud558\ub294 \uc911\uc694\ud55c \uc704\uce58\ub4e4\uc744 \uae30\ub85d\ud558\uace0, \ub808\uc774\uc5b4 \uac04 \uc911\uc694\ud55c \uc704\uce58\ub4e4\uc758 \uc548\uc815\uc801\uc778 \uc911\ubcf5 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. EFFICIENT-VDIT"}, {"figure_path": "https://arxiv.org/html/2502.06155/x2.png", "caption": "Figure 2: \u00a0Efficient-vDiT\u00a0takes in a pre-trained 3D Full Attention video diffusion transformer(DiT), with slow inference speed and high fidelity. It then operates on three stages to greatly accelerate the inference while maintaining the fidelity. In Stage 1, we modify the multi-step consistency distillation framework from\u00a0(Heek et\u00a0al., 2024) to the video domain, which turned a DiT model to a CM model with stable training. In Stage 2,\u00a0Efficient-vDiT\u00a0performs a searching algorithm to find the best sparse attention pattern for each layer. In stage 3,\u00a0Efficient-vDiT\u00a0performs a knowledge distillation procedure to optimize the fidelity of the sparse DiT. At the end,\u00a0Efficient-vDiT\u00a0outputs a DiT with linear attention, high fidelity and fastest inference speed.", "description": "\uadf8\ub9bc 2\ub294 Efficient-VDIT\uc758 \uc138 \ub2e8\uacc4 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uba3c\uc800, \uae30\uc874\uc758 3D \uc804 \uc8fc\uc758(Full Attention) \ube44\ub514\uc624 \ud655\uc0b0 \ud2b8\ub79c\uc2a4\ud3ec\uba38(DiT) \ubaa8\ub378\uc744 \uc785\ub825\ubc1b\uc2b5\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc740 \ub192\uc740 \ucda9\uc2e4\ub3c4\ub97c \uac00\uc9c0\uc9c0\ub9cc \ucd94\ub860 \uc18d\ub3c4\uac00 \ub290\ub9bd\ub2c8\ub2e4. 1\ub2e8\uacc4\uc5d0\uc11c\ub294 Heek et al.(2024)\uc758 \ub2e4\ub2e8\uacc4 \uc77c\uad00\uc131 \uc99d\ub958(Multi-step Consistency Distillation) \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ube44\ub514\uc624 \uc601\uc5ed\uc5d0 \ub9de\ucdb0 \uc218\uc815\ud558\uc5ec DiT \ubaa8\ub378\uc744 \uc548\uc815\uc801\uc778 \ud6c8\ub828\uc774 \uac00\ub2a5\ud55c CM \ubaa8\ub378\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4. 2\ub2e8\uacc4\uc5d0\uc11c\ub294 \uac01 \ub808\uc774\uc5b4\uc5d0 \ub300\ud574 \ucd5c\uc801\uc758 \ud76c\uc18c \uc8fc\uc758 \ud328\ud134\uc744 \ucc3e\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \uc2e4\ud589\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 3\ub2e8\uacc4\uc5d0\uc11c\ub294 \uc9c0\uc2dd \uc99d\ub958(Knowledge Distillation)\ub97c \ud1b5\ud574 \ud76c\uc18c DiT\uc758 \ucda9\uc2e4\ub3c4\ub97c \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4. \ucd5c\uc885\uc801\uc73c\ub85c Efficient-VDIT\ub294 \uc120\ud615 \ubcf5\uc7a1\ub3c4\uc758 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998\uc744 \uac00\uc9c0\uba74\uc11c \ub192\uc740 \ucda9\uc2e4\ub3c4\uc640 \ube60\ub978 \ucd94\ub860 \uc18d\ub3c4\ub97c \uac00\uc9c4 DiT \ubaa8\ub378\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4.", "section": "3. EFFICIENT-VDIT"}, {"figure_path": "https://arxiv.org/html/2502.06155/x3.png", "caption": "Figure 3: Exemplar attention mask (2:6:262:62 : 6). It maintains the attention in the main diagonals and against 2 global reference latent frames. Tile blocks in white are not computed.", "description": "\uadf8\ub9bc 3\uc740 2:6 \ud06c\uae30\uc758 \uc608\uc2dc\uc801\uc778 \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ub9c8\uc2a4\ud06c\ub294 \uc8fc\ub300\uac01\uc120\uc758 \uc5b4\ud150\uc158\uacfc 2\uac1c\uc758 \uae00\ub85c\ubc8c \ucc38\uc870\uc7a0\uc7ac \ud504\ub808\uc784\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4. \ud770\uc0c9 \ud0c0\uc77c \ube14\ub85d\uc740 \uacc4\uc0b0\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.  \ub354 \uc790\uc138\ud788 \uc124\uba85\ud558\uc790\uba74, \uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ud76c\uc18c \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\ub514\uc624 \ub370\uc774\ud130\uc758 3\ucc28\uc6d0 \uc5b4\ud150\uc158 \ub9f5\uc5d0\uc11c \ubc18\ubcf5\uc801\uc778 \ud328\ud134(Attention Tile)\uc744 \ubc1c\uacac\ud558\uace0, \uc774\ub97c \ud65c\uc6a9\ud558\uc5ec \uacc4\uc0b0\ub7c9\uc744 \uc904\uc774\ub294 \ud76c\uc18c \uc5b4\ud150\uc158 \ub9c8\uc2a4\ud06c\ub97c \uc124\uacc4\ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774, \ub9c8\uc2a4\ud06c\ub294 \uc8fc\ub300\uac01\uc120 \uc694\uc18c\uc640 \uc77c\ubd80 \ud2b9\uc815 \ud504\ub808\uc784\ub4e4\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158\ub9cc\uc744 \uc720\uc9c0\ud558\uace0, \ub098\uba38\uc9c0 \uc694\uc18c\ub4e4\uc740 0\uc73c\ub85c \uc124\uc815\ub418\uc5b4 \uacc4\uc0b0\uc744 \uc0dd\ub7b5\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\ub97c \ub0ae\ucd94\uba74\uc11c\ub3c4 \ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5\uc744 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  2:6\uc740 \uac01 \ud504\ub808\uc784\uc774 2\uac1c\uc758 \ub2e4\ub978 \ud504\ub808\uc784\uacfc\ub9cc \uc5b4\ud150\uc158\uc744 \uacc4\uc0b0\ud55c\ub2e4\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4. 262:62 \ub4f1\uc740 \ub2e4\ub978 \ub9e4\uac1c\ubcc0\uc218\ub85c \uc0dd\uc131\ud55c \ub9c8\uc2a4\ud06c\uc758 \uc608\uc2dc\uc785\ub2c8\ub2e4.  2\uac1c\uc758 \uae00\ub85c\ubc8c \ucc38\uc870 \ud504\ub808\uc784\uc744 \uc0ac\uc6a9\ud558\uc5ec  \ube44\ub514\uc624 \uc2dc\ud000\uc2a4 \ub0b4\uc758 \uc7a5\uae30\uc801\uc778 \uc758\uc874\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. EFFICIENT-VDIT"}, {"figure_path": "https://arxiv.org/html/2502.06155/x4.png", "caption": "Figure 4: Search results for Open-Sora-Plan v1.2 model (29 frames). We verify that different layers have different sparsity in 3D video DiTs.", "description": "\uadf8\ub9bc 4\ub294 Open-Sora-Plan v1.2 \ubaa8\ub378(29\ud504\ub808\uc784)\uc5d0 \ub300\ud55c \ud0d0\uc0c9 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  3D \ube44\ub514\uc624 DiT\uc5d0\uc11c \uac01 \ub808\uc774\uc5b4\ub9c8\ub2e4 \uc2a4\ud30c\uc2a4(sparse) \uc815\ub3c4\uac00 \ub2e4\ub974\ub2e4\ub294 \uac83\uc744 \ud655\uc778\ud558\uae30 \uc704\ud574 \uc2e4\ud5d8\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.  \uc989, \ubaa8\ub4e0 \ub808\uc774\uc5b4\uac00 \ub3d9\uc77c\ud55c \uc218\uc900\uc758 \uc2a4\ud30c\uc2a4\uc131\uc744 \uac16\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, \ub808\uc774\uc5b4\uc5d0 \ub530\ub77c \uc2a4\ud30c\uc2a4 \ud328\ud134\uc774 \ub2e4\ub974\uac8c \ub098\ud0c0\ub0a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ud6a8\uc728\uc801\uc778 \ube44\ub514\uc624 \uc0dd\uc131\uc744 \uc704\ud574 \ub808\uc774\uc5b4\ubcc4\ub85c \ucd5c\uc801\uc758 \uc2a4\ud30c\uc2a4\uc131\uc744 \ucc3e\ub294 \uac83\uc774 \uc911\uc694\ud558\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3. EFFICIENT-VDIT"}, {"figure_path": "https://arxiv.org/html/2502.06155/extracted/6191047/figures/prompt_sample/ablation.jpg", "caption": "Figure 5: Qualitative samples of our models. We compare the generation quality between the base model, MLCD model, and after knowledge distillation. Frames shown are equally spaced samples from the generated video. Efficient-vDiT\u00a0is shortened as \u2018E-vdit\u2019 for simplicity. More samples can be found in Appendix F.", "description": "\uadf8\ub9bc 5\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \uc138 \uac00\uc9c0 \ubaa8\ub378(\uae30\ubcf8 \ubaa8\ub378, MLCD \ubaa8\ub378, \uc9c0\uc2dd \uc99d\ub958 \ud6c4 \ubaa8\ub378)\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \ud488\uc9c8\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uade0\ub4f1\ud558\uac8c \ubd84\ud3ec\ub41c \ud504\ub808\uc784\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc73c\uba70, \ud6a8\uc728\uc801\uc778 VDIT \ubaa8\ub378\uc740 \uac04\ub2e8\ud788 \"E-vdit\"\ub85c \ud45c\uae30\ud588\uc2b5\ub2c8\ub2e4. \ubcf4\ub2e4 \ub9ce\uc740 \uc0dd\uc131 \uacb0\uacfc\ub294 \ubd80\ub85d F\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc8fc\uc5b4, \uc81c\uc548\ub41c \ubaa8\ub378\uc758 \ud6a8\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4.4 \uc9c8\uc801 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2502.06155/extracted/6191047/figures/prompt_sample/cogvideo_batch.jpg", "caption": "Figure 6: Qualitative samples of ablation of distillation order. sampled from VBench prompts. We show that both MLCD and\u00a0Efficient-vDiT\u00a0model can simliar quality on these samples. In two consecutive videos, the top shows results from MLCD + CD model followed by KD + MLCD model.", "description": "\uadf8\ub9bc 6\uc740 \uc99d\ub958 \uc21c\uc11c\uc758 ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc815\uc131\uc801 \uc0d8\ud50c\ub4e4\uc785\ub2c8\ub2e4. VBench \ud504\ub86c\ud504\ud2b8\uc5d0\uc11c \uc0d8\ud50c\ub4e4\uc774 \ucd94\ucd9c\ub418\uc5c8\uc2b5\ub2c8\ub2e4. MLCD \ubaa8\ub378\uacfc Efficient-VDIT \ubaa8\ub378 \ubaa8\ub450 \uc720\uc0ac\ud55c \ud654\uc9c8\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uac1c\uc758 \uc5f0\uc18d\uc801\uc778 \ube44\ub514\uc624\uc5d0\uc11c, \uc0c1\ub2e8\uc740 MLCD + CD \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c, \ud558\ub2e8\uc740 KD + MLCD \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 Video Quality benchmark"}, {"figure_path": "https://arxiv.org/html/2502.06155/extracted/6191047/figures/prompt_sample/output_batch_1.jpg", "caption": "Figure 7: Qualitative samples of CogvideoX-5B (Yang et\u00a0al., 2024b) distillation from its sample prompts. We show that our attention distill is capable of MM-DiT model architecture. In two consecutive videos, the top shows results from the base model, followed by the distillation model.", "description": "\uadf8\ub9bc 7\uc740 CogVideoX-5B \ubaa8\ub378\uc5d0 \uc801\uc6a9\ub41c \uc5b4\ud150\uc158 \uc99d\ub958\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CogVideoX-5B \ubaa8\ub378\uc740 MM-DiT \uc544\ud0a4\ud14d\ucc98\ub97c \uae30\ubc18\uc73c\ub85c \ud558\uba70,  \ubcf8 \ub17c\ubb38\uc758 \uc5b4\ud150\uc158 \uc99d\ub958 \uae30\ubc95\uc774 MM-DiT \uc544\ud0a4\ud14d\ucc98\uc5d0\ub3c4 \uc801\uc6a9 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uac1c\uc758 \uc5f0\uc18d\uc801\uc778 \ube44\ub514\uc624\uc5d0\uc11c \uc704\ucabd\uc740 \uae30\ubcf8 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c, \uc544\ub798\ucabd\uc740 \uc99d\ub958 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc608\uc2dc\ub97c \ud1b5\ud574 \uae30\ubcf8 \ubaa8\ub378\uacfc \uc99d\ub958 \ubaa8\ub378\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \ud488\uc9c8\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \uc5b4\ud150\uc158 \uc99d\ub958\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4. Qualitative result"}, {"figure_path": "https://arxiv.org/html/2502.06155/extracted/6191047/figures/prompt_sample/output_batch_3.jpg", "caption": "Figure 8: Based on Open-Sora\u2019s examples (Zheng et\u00a0al., 2024) , we selected dynamic prompts featuring centralized explosions and radiating energy, demonstrating dramatic transitions from focal points to expansive environmental transformations, emphasizing large-scale motion.", "description": "\uadf8\ub9bc 8\uc740 Open-Sora\uc758 \uc608\uc2dc(Zheng et al., 2024)\ub97c \ubc14\ud0d5\uc73c\ub85c \uc81c\uc791\ub418\uc5c8\uc73c\uba70, \uc911\uc559\uc5d0\uc11c \ud3ed\ubc1c\uc774 \uc77c\uc5b4\ub098\uace0 \uc5d0\ub108\uc9c0\uac00 \ubc29\uc0ac\ud615\uc73c\ub85c \ud37c\uc838\ub098\uac00\ub294 \uc5ed\ub3d9\uc801\uc778 \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \uc120\ubcc4\ud558\uc5ec \uc2dc\uac01\ud654\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ucd08\uc810 \uc601\uc5ed\uc5d0\uc11c \ub113\uc740 \ud658\uacbd\uc73c\ub85c\uc758 \uadf9\uc801\uc778 \ubcc0\ud654\uc640 \ub300\uaddc\ubaa8 \uc6c0\uc9c1\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud3ed\ubc1c\uc774\ub098 \uc5d0\ub108\uc9c0 \ubc29\ucd9c\uacfc \uac19\uc740 \uc5ed\ub3d9\uc801\uc778 \ud604\uc0c1\uc774 \uc810 \ub610\ub294 \ucd08\uc810\uc5d0\uc11c \uc2dc\uc791\ud558\uc5ec \uc8fc\ubcc0 \ud658\uacbd\uc73c\ub85c \ub113\uac8c \ud37c\uc838\ub098\uac00\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc5ec  \ub300\uaddc\ubaa8 \uc6b4\ub3d9 \ud6a8\uacfc\ub97c \uac15\uc870\ud588\uc2b5\ub2c8\ub2e4.", "section": "4.4. \uc9c8\uc801 \uacb0\uacfc"}]