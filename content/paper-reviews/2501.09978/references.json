{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduces NeRF, a foundational model for novel view synthesis that heavily influences the field of 3D scene representation and is directly relevant to the current work on Gaussian head avatar editing."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian splatting, a key technique used in the current work, providing real-time performance and high-quality rendering for 3D scenes."}, {"fullname_first_author": "Ayaan Haque", "paper_title": "Instruct-nerf2nerf: Editing 3d scenes with instructions", "publication_date": "2023-00-00", "reason": "This paper presents Instruct-NeRF2NeRF, a method for text-driven 3D scene editing, providing a framework for incorporating text-based control and editing in 3D scenes, a core concept adapted in the current research."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Instructpix2pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "This paper introduces InstructPix2Pix, a 2D image editing method based on diffusion models, which is utilized in the current work as a key component for text-driven editing of the rendered images."}, {"fullname_first_author": "Shenhan Qian", "paper_title": "Gaussianavatars: Photorealistic head avatars with rigged 3d gaussians", "publication_date": "2023-00-00", "reason": "This paper introduces GaussianAvatars, providing the foundation for creating animatable Gaussian head avatars, which serves as a direct base and starting point for the current research."}]}