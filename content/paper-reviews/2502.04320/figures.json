[{"figure_path": "https://arxiv.org/html/2502.04320/extracted/6176595/figures/CrownJewelDragon.png", "caption": "Figure 1: ConceptAttention produces saliency maps that precisely localize the presence of textual concepts in images. We compare Flux raw cross attention, DAAM (Tang et\u00a0al., 2022) with SDXL, and TextSpan (Gandelsman et\u00a0al., 2024) for CLIP.", "description": "\uadf8\ub9bc 1\uc740 ConceptAttention\uc774 \uc774\ubbf8\uc9c0 \ub0b4 \ud14d\uc2a4\ud2b8 \uac1c\ub150\uc758 \uc874\uc7ac \uc704\uce58\ub97c \uc815\ud655\ud558\uac8c \ucc3e\uc544\ub0b4\ub294 \uc815\ud655\ub3c4 \ub192\uc740 \uc140\ub7f0\uc2dc \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Flux\uc758 \uc6d0\uc2dc \uad50\ucc28 \uc5b4\ud150\uc158, SDXL\uc744 \uc0ac\uc6a9\ud55c DAAM(Tang et al., 2022), \uadf8\ub9ac\uace0 CLIP\uc744 \uc704\ud55c TextSpan(Gandelsman et al., 2024)\uacfc\uc758 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 \"A dragon on a hill\" \uc774\ub77c\ub294 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud55c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc140\ub7f0\uc2dc \ub9f5\uc744 \uc0dd\uc131\ud558\uba70,  ConceptAttention\uc740 \ub2e4\ub978 \ubc29\ubc95\ub4e4\uc5d0 \ube44\ud574 \uac1c\ub150(dragon, rock, sun, clouds)\uc744 \ub354\uc6b1 \uc815\ud655\ud558\uac8c \uc774\ubbf8\uc9c0 \uc601\uc5ed\uc5d0 \ub9e4\ud551\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 ConceptAttention\uc774 diffusion transformer\uc758 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub97c \ud65c\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \ub0b4 \uac1c\ub150\uc758 \uc704\uce58\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud30c\uc545\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.04320/x1.png", "caption": "Figure 2: ConceptAttention augments multi-modal DiTs with a sequence of concept embeddings that can be used to produce saliency maps. (Left) An unmodified multi-modal attention (MMAttn) layer processes both prompt and image tokens. (Right) ConceptAttention augments these layers without impacting the image appearance to create a set of contextualized concept tokens.", "description": "\uadf8\ub9bc 2\ub294 ConceptAttention\uc774 \uc5b4\ub5bb\uac8c \ub2e4\uc911 \ubaa8\ub4dc \ud655\uc0b0 \ud2b8\ub79c\uc2a4\ud3ec\uba38(DiT)\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ud328\ub110\uc740 \uc218\uc815\ub418\uc9c0 \uc54a\uc740 \ub2e4\uc911 \ubaa8\ub4dc \uc5b4\ud150\uc158(MMAttn) \ub808\uc774\uc5b4\uac00 \ud504\ub86c\ud504\ud2b8 \ud1a0\ud070\uacfc \uc774\ubbf8\uc9c0 \ud1a0\ud070\uc744 \ucc98\ub9ac\ud558\ub294 \uacfc\uc815\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc624\ub978\ucabd \ud328\ub110\uc5d0\uc11c\ub294 ConceptAttention\uc774 \uc774\ubbf8\uc9c0\uc758 \uc678\uad00\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0 \uc54a\uc73c\uba74\uc11c \uc774\ub7ec\ud55c \ub808\uc774\uc5b4\ub97c \uc99d\uac15\ud558\uc5ec \ubb38\ub9e5\ud654\ub41c \uac1c\ub150 \ud1a0\ud070 \uc9d1\ud569\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uac1c\ub150 \ud1a0\ud070\ub4e4\uc740 \uc140\ub9ac\uc5b8\uc2dc \ub9f5\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4. \uc81c\uc548\ub41c \ubc29\ubc95: ConceptAttention"}, {"figure_path": "https://arxiv.org/html/2502.04320/x2.png", "caption": "Figure 3: ConceptAttention can generate high-quality saliency maps for multiple concepts simultaneously.  Additionally, our approach is not restricted to concepts in the prompt vocabulary.", "description": "\uadf8\ub9bc 3\uc740 ConceptAttention\uc774 \uc5ec\ub7ec \uac1c\ub150\uc5d0 \ub300\ud55c \uace0\ud488\uc9c8\uc758 \uc911\uc694\ub3c4 \uc9c0\ub3c4\ub97c \ub3d9\uc2dc\uc5d0 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \uc774 \ubc29\ubc95\uc740 \ud504\ub86c\ud504\ud2b8 \uc5b4\ud718\uc5d0 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc740 \uac1c\ub150\uc5d0\ub3c4 \uc801\uc6a9\ub420 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.  \uc5ec\ub7ec \uac1c\ub150(\uaf43, \uc815\uc7a5, \ud558\ub298, \uc5bc\uad74, \ub098\ubb34, \ud480, \ud48d\uc120, \ud0dc\uc591, \uc0b0, \uad6c\ub984, \ubb3c, \uc575\ubb34\uc0c8, \ub208, \ub098\ubb34, \uc9d1 \ub4f1)\uc774 \uc774\ubbf8\uc9c0 \ub0b4\uc5d0\uc11c \uc815\ud655\ud558\uac8c \uc704\uce58\ub97c \ud30c\uc545\ud558\uc5ec \ud45c\uc2dc\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 ConceptAttention\uc758 \uac15\ub825\ud55c \uac1c\ub150 \uad6d\uc7ac\ud654 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ubaa8\ub378\uc774 \ud504\ub86c\ud504\ud2b8\uc5d0 \uba85\uc2dc\uc801\uc73c\ub85c \ud3ec\ud568\ub418\uc9c0 \uc54a\uc740 \uac1c\ub150\ub3c4 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc2dd\ubcc4\ud558\uace0 \uc2dc\uac01\ud654\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "2. \uad00\ub828 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2502.04320/x3.png", "caption": "Figure 4: (a) MMAttn combines cross and self attention operations between the prompt and image tokens. (b) Our ConceptAttention allows the concept tokens to incorporate information from other concept tokens and the image tokens, but not the other way around.", "description": "\uadf8\ub9bc 4\ub294 \ub2e4\uc911 \ubaa8\ub4dc \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc758 \uc791\ub3d9 \ubc29\uc2dd\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uae30\uc874\uc758 MMAttn (\ub2e4\uc911 \ubaa8\ub4dc \uc5b4\ud150\uc158)\uc774 \ud504\ub86c\ud504\ud2b8 \ud1a0\ud070\uacfc \uc774\ubbf8\uc9c0 \ud1a0\ud070 \uac04\uc758 \uc0c1\ud638 \uc791\uc6a9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158\uacfc \uc140\ud504 \uc5b4\ud150\uc158\uc744 \ud1b5\ud574 \ud504\ub86c\ud504\ud2b8\uc640 \uc774\ubbf8\uc9c0 \uc815\ubcf4\uac00 \uc11c\ub85c \uc601\ud5a5\uc744 \uc8fc\uace0\ubc1b\uc2b5\ub2c8\ub2e4. \ubc18\uba74 (b)\uc758 ConceptAttention\uc740 \uac1c\ub150 \ud1a0\ud070\uc774 \ub2e4\ub978 \uac1c\ub150 \ud1a0\ud070\uacfc \uc774\ubbf8\uc9c0 \ud1a0\ud070\uc73c\ub85c\ubd80\ud130 \uc815\ubcf4\ub97c \ubc1b\uc9c0\ub9cc, \uadf8 \ubc18\ub300\ub294 \ub418\uc9c0 \uc54a\ub294\ub2e4\ub294 \uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \uac1c\ub150 \ud1a0\ud070\uc774 \uc774\ubbf8\uc9c0\uc758 \ud2b9\uc9d5\uc744 \uc124\uba85\ud558\ub294 \ub370 \uc9d1\uc911\ud558\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc989, \uc774\ubbf8\uc9c0\uc640 \ud504\ub86c\ud504\ud2b8\uac00 \uac1c\ub150 \ud1a0\ud070\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uc9c0\ub9cc, \uac1c\ub150 \ud1a0\ud070\uc740 \uc774\ubbf8\uc9c0\uc640 \ud504\ub86c\ud504\ud2b8\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "4. Proposed Method: CONCEPTATTENTION"}, {"figure_path": "https://arxiv.org/html/2502.04320/x4.png", "caption": "Figure 5: ConceptAttention produces higher fidelity raw scores and saliency maps than alternative methods, sometimes surpassing in quality even the ground truth saliency map provided by the ImageNet-Segmentation task. Top row shows the soft predictions of each method and the bottom shows the binarized predictions.", "description": "\uadf8\ub9bc 5\ub294 \uc81c\uc548\ub41c ConceptAttention \ubc29\ubc95\uacfc \ub2e4\ub978 \uc5ec\ub7ec \ud574\uc11d \uac00\ub2a5\uc131 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 ImageNet-Segmentation \ub370\uc774\ud130\uc14b\uc744 \uae30\ubc18\uc73c\ub85c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ConceptAttention\uc740 \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub354 \uc815\ud655\ud558\uace0 \uc138\ubc00\ud55c \uc140\ub7f0\uc2dc \ub9f5(saliency map)\uc744 \uc0dd\uc131\ud558\uba70, \uacbd\uc6b0\uc5d0 \ub530\ub77c ImageNet-Segmentation \uc791\uc5c5\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uc815\ub2f5 \uc140\ub7f0\uc2dc \ub9f5\ubcf4\ub2e4 \ub354 \ub098\uc740 \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc \uc0c1\ub2e8 \ud589\uc740 \uac01 \ubc29\ubc95\uc758 \uc18c\ud504\ud2b8 \uc608\uce21(soft prediction) \uacb0\uacfc\ub97c, \ud558\ub2e8 \ud589\uc740 \uc774\uc9c4\ud654\ub41c \uc608\uce21(binarized prediction) \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989,  \uc5b4\ub5a4 \uc601\uc5ed\uc774 \ud2b9\uc815 \uac1c\ub150\uc5d0 \uc5bc\ub9c8\ub098 \uc18d\ud558\ub294\uc9c0\ub97c \ud655\ub960\uc801\uc73c\ub85c \ub098\ud0c0\ub0b4\ub294 \uac83\uacfc, \ud574\ub2f9 \uc601\uc5ed\uc774 \ud2b9\uc815 \uac1c\ub150\uc5d0 \uc18d\ud558\ub294\uc9c0 \uc544\ub2cc\uc9c0\ub97c \uc774\uc9c4\uc801\uc73c\ub85c \ud310\ub2e8\ud558\ub294 \uac83\uc744 \uac01\uac01 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/x5.png", "caption": "Figure 6: Later MMAttn layers encode richer features for zero-shot segmentation.  We investigated the impact of using features from various MMAttn layers and found that deeper layers lead to better performance on segmentation metrics like pixelwise accuracy, mIoU, and mAP. We also found that combining the information from all layers further improves performance.", "description": "\uadf8\ub9bc 6\uc740 \uc81c\ub85c\uc0f7 \ubd84\ud560\uc5d0\uc11c \ub354 \uae4a\uc740 \uacc4\uce35\uc774 \ub354 \ud48d\ubd80\ud55c \ud2b9\uc9d5\uc744 \uc778\ucf54\ub529\ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc591\ud55c MMAttn \uacc4\uce35\uc758 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc758 \uc601\ud5a5\uc744 \uc870\uc0ac\ud55c \uacb0\uacfc, \ub354 \uae4a\uc740 \uacc4\uce35\uc744 \uc0ac\uc6a9\ud560\uc218\ub85d \ud53d\uc140 \uc815\ud655\ub3c4, mIoU \ubc0f mAP\uc640 \uac19\uc740 \ubd84\ud560 \uc9c0\ud45c\uc758 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \ubc1c\uacac\ud588\uc2b5\ub2c8\ub2e4. \ub610\ud55c \ubaa8\ub4e0 \uacc4\uce35\uc758 \uc815\ubcf4\ub97c \uacb0\ud569\ud558\uba74 \uc131\ub2a5\uc774 \ub354\uc6b1 \ud5a5\uc0c1\ub428\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4.", "section": "5.1 \uc81c\ub85c\uc0f7 \uc774\ubbf8\uc9c0 \ubd84\ud560"}, {"figure_path": "https://arxiv.org/html/2502.04320/x6.png", "caption": "Figure 7: Optimal segmentation performance requires some noise to be present in the image.  We evaluated the performance of ConceptAttention by encoding samples from a variety of timesteps (determines the amount of noise). Interestingly, we found that the optimal amount of noise was not zero, but in the middle to later stages of the noise schedule.", "description": "\uc774 \uadf8\ub9bc\uc740 ConceptAttention\uc758 \uc131\ub2a5\uc774 \uc774\ubbf8\uc9c0\uc5d0 \uc5b4\ub290 \uc815\ub3c4\uc758 \ub178\uc774\uc988\uac00 \uc874\uc7ac\ud560 \ub54c \ucd5c\uc801\ud654\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc591\ud55c timestep(\ub178\uc774\uc988 \uc591\uc744 \uacb0\uc815)\uc5d0\uc11c \uc0d8\ud50c\uc744 \uc778\ucf54\ub529\ud558\uc5ec ConceptAttention\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4. \ud765\ubbf8\ub86d\uac8c\ub3c4, \ub178\uc774\uc988\uac00 \uc804\ud600 \uc5c6\ub294 \uac83\ubcf4\ub2e4 \uc911\uac04 \ub610\ub294 \ud6c4\ubc18 \ub2e8\uacc4\uc758 \ub178\uc774\uc988 \uc2a4\ucf00\uc904\uc5d0\uc11c \ucd5c\uc801\uc758 \ub178\uc774\uc988 \uc591\uc744 \ubc1c\uacac\ud588\uc2b5\ub2c8\ub2e4.  \uc989, \ub178\uc774\uc988\uac00 \uc644\uc804\ud788 \uc81c\uac70\ub41c \uc774\ubbf8\uc9c0\ubcf4\ub2e4 \uc801\uc808\ud55c \uc218\uc900\uc758 \ub178\uc774\uc988\uac00 \uc788\ub294 \uc774\ubbf8\uc9c0\uc5d0\uc11c ConceptAttention\uc758 \uc131\ub2a5\uc774 \ub354 \uc6b0\uc218\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "5.2 Ablation Studies"}, {"figure_path": "https://arxiv.org/html/2502.04320/x7.png", "caption": "Figure 8: Pseudo-code depicting the (a) multi-modal attention operation used by Flux DiTs and (b) our ConceptAttention operation. We leverage the parameters of a multi-modal attention layer to construct a set of contextualized concept embeddings. The concepts query the image tokens (cross-attention) and other concept tokens (self-attention) in an attention operation. The updated concept embeddings are returned in addition to the image and text embeddings.", "description": " \uadf8\ub9bc 8\uc740 Flux DiT\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 (a) \ub2e4\uc911 \ubaa8\ub4dc \uc5b4\ud150\uc158 \uc5f0\uc0b0\uacfc (b) ConceptAttention \uc5f0\uc0b0\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc758\uc0ac \ucf54\ub4dc\uc785\ub2c8\ub2e4. \ub2e4\uc911 \ubaa8\ub4dc \uc5b4\ud150\uc158 \uacc4\uce35\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ud65c\uc6a9\ud558\uc5ec \ubb38\ub9e5\ud654\ub41c \uac1c\ub150 \uc784\ubca0\ub529 \uc9d1\ud569\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4. \uac1c\ub150\ub4e4\uc740 \uc5b4\ud150\uc158 \uc5f0\uc0b0\uc5d0\uc11c \uc774\ubbf8\uc9c0 \ud1a0\ud070(\uad50\ucc28 \uc5b4\ud150\uc158)\uacfc \ub2e4\ub978 \uac1c\ub150 \ud1a0\ud070(\uc790\uae30 \uc5b4\ud150\uc158)\uc744 \uc9c8\uc758\ud569\ub2c8\ub2e4. \uc5c5\ub370\uc774\ud2b8\ub41c \uac1c\ub150 \uc784\ubca0\ub529\uc740 \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529 \uc678\uc5d0\ub3c4 \ubc18\ud658\ub429\ub2c8\ub2e4.", "section": "4. Proposed Method: CONCEPTATTENTION"}, {"figure_path": "https://arxiv.org/html/2502.04320/extracted/6176595/figures/supplemental_imagenet_segmentations/QualitativeComparisonFigure.png", "caption": "Figure 9: A qualitative comparison between our method and several others.", "description": "\uadf8\ub9bc 9\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \ub2e4\ub978 \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc744 \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc740 \uc774\ubbf8\uc9c0 \ub0b4 \uac1c\ub150(\uac1c, \uacf5, \ub098\ubb34, \uc794\ub514, \ud558\ub298, \ubc30\uacbd)\uc758 \uc704\uce58\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud45c\ud604\ud558\ub294 \uc0d0\ub9ac\uc5b8\uc2dc \ub9f5(saliency map)\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uac01 \ubc29\ubc95\uc758 \uac1c\ub150 \uc2dd\ubcc4 \ubc0f \uc704\uce58 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc131\ub2a5 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \uc81c\uc548\ub41c \ubc29\ubc95\uc740 \uac1c\ub150\uc744 \ub354\uc6b1 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\uace0 \uc704\uce58\ub97c \uc9c0\uc815\ud558\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/x8.png", "caption": "Figure 10: A qualitative comparison between our method and several others.", "description": "\uadf8\ub9bc 10\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \ub2e4\ub978 \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \ub2e4\uc591\ud55c \uac1c\uccb4\uc640 \ubc30\uacbd\uc774 \ud3ec\ud568\ub41c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574, CONCEPTATTENTION(\uc81c\uc548\ub41c \ubc29\ubc95), Flux\uc758 Cross Attention, SDXL\uc758 DAAM, \uadf8\ub9ac\uace0 CLIP\uc758 TextSpan \ubc29\ubc95\uc774 \uc0dd\uc131\ud55c \uc140\ub7f0\uc2dc \ub9f5(saliency map)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc774 \uc774\ubbf8\uc9c0 \ub0b4\uc758 \uac1c\uccb4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \ucc3e\uc544\ub0b4\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ub354\uc6b1 \uba85\ud655\ud558\uac8c \uc774\ud574\ud560 \uc218 \uc788\ub3c4\ub85d \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/x9.png", "caption": "Figure 11: A qualitative comparison between our method and several others.", "description": "\uadf8\ub9bc 11\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \ub2e4\ub978 \uc5ec\ub7ec \ubc29\ubc95\ub4e4 \uac04\uc758 \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uac1c\uccb4\uc640 \ubc30\uacbd\uc744 \ud3ec\ud568\ud55c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574,  CONCEPTATTENTION (\uc81c\uc548\ub41c \ubc29\ubc95), Flux\uc758 cross attention, SDXL\uc758 DAAM, CLIP\uc758 TextSpan \ub4f1 \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc758 \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \uac01 \ubc29\ubc95\uc774 \uc774\ubbf8\uc9c0 \ub0b4\uc758 \uac1c\uccb4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\uace0 \uc704\uce58\ub97c \ud2b9\uc815\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5 \ucc28\uc774\uc640 \uac15\uc810, \uc57d\uc810\uc744 \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/extracted/6176595/figures/supplemental_imagenet_segmentations/supplemental_6.png", "caption": "Figure 12: A qualitative comparison between numerous baselines on ImageNet Segmentation Images. The top row shows the soft predictions of each method and the bottom shows the binarized segmentation predictions.", "description": "\uadf8\ub9bc 12\ub294 ImageNet Segmentation \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \uc815\uc131\uc801\uc73c\ub85c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc704\ucabd \ud589\uc740 \uac01 \ubaa8\ub378\uc758 \uc18c\ud504\ud2b8 \uc608\uce21 \uacb0\uacfc\ub97c, \uc544\ub798\ucabd \ud589\uc740 \uc774\uc9c4\ud654\ub41c \ubd84\ud560 \uc608\uce21 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc758 \ubd84\ud560 \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\uace0, CONCEPTATTENTION \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uacfc \uc0c1\ub300\uc801\uc73c\ub85c \ud3c9\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/extracted/6176595/figures/supplemental_imagenet_segmentations/supplemental_3.png", "caption": "Figure 13: A qualitative comparison between numerous baselines on ImageNet Segmentation Images. The top row shows the soft predictions of each method and the bottom shows the binarized segmentation predictions.", "description": "\uadf8\ub9bc 13\uc740 ImageNet Segmentation \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uc815\uc131\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc704\ucabd \ud589\uc740 \uac01 \ubc29\ubc95\uc758 \uc18c\ud504\ud2b8 \uc608\uce21 \uacb0\uacfc\ub97c, \uc544\ub798\ucabd \ud589\uc740 \uc774\uc9c4\ud654\ub41c \ubd84\ud560 \uc608\uce21 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \uac01 \ubc29\ubc95\uc774 \uc774\ubbf8\uc9c0\uc758 \uac1d\uccb4\ub97c \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\uace0 \ubd84\ud560\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 CONCEPTATTENTION\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2502.04320/extracted/6176595/figures/supplemental_imagenet_segmentations/supplemental_4.png", "caption": "Figure 14: A qualitative comparison between numerous baselines on ImageNet Segmentation Images. The top row shows the soft predictions of each method and the bottom shows the binarized segmentation predictions.", "description": "\uadf8\ub9bc 14\ub294 ImageNet Segmentation \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \uae30\uc900 \ubc29\ubc95\ub4e4\uc758 \uc815\uc131\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc704\ucabd \ud589\uc740 \uac01 \ubc29\ubc95\uc758 \uc18c\ud504\ud2b8 \uc608\uce21 \uacb0\uacfc\ub97c, \uc544\ub798\ucabd \ud589\uc740 \uc774\uc9c4\ud654\ub41c \ubd84\ud560 \uc608\uce21 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \uac01 \ubc29\ubc95\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ud2b9\ud788, CONCEPTATTENTION \ubc29\ubc95\uc758 \uc815\ud655\ub3c4\uc640 \uc815\ubc00\ub3c4\ub97c \ub2e4\ub978 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud558\uc5ec, \uadf8 \uc131\ub2a5 \uc6b0\uc218\uc131\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}]