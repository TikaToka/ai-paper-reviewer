{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-02-01", "reason": "This paper introduces CLIP, a foundational model used extensively for comparing CONCEPTATTENTION against other zero-shot image interpretability methods."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-04-01", "reason": "This paper introduces Stable Diffusion, a widely used diffusion model whose architecture is similar to the multi-modal DiT models analyzed in CONCEPTATTENTION."}, {"fullname_first_author": "Alexander R. Richards", "paper_title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "publication_date": "2024-03-01", "reason": "This paper introduces SDXL, a state-of-the-art diffusion model architecture used as a comparison against CONCEPTATTENTION's ability to generate saliency maps."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "publication_date": "2024-03-01", "reason": "This paper introduces SDXL, a state-of-the-art diffusion model architecture used as a comparison against CONCEPTATTENTION's ability to generate saliency maps."}, {"fullname_first_author": "Boyuan Feng", "paper_title": "What the DAAM: Interpreting Stable Diffusion Using Cross Attention", "publication_date": "2022-12-01", "reason": "This paper introduces DAAM, a method for interpreting Stable Diffusion's cross-attention maps, which is directly compared to CONCEPTATTENTION's performance on zero-shot image segmentation."}]}