{"references": [{"fullname_first_author": "Zhang", "paper_title": "Multimodal chain-of-thought reasoning in language models", "publication_date": "2023-02-00", "reason": "This paper is highly relevant to the topic of multimodal chain-of-thought reasoning and is directly cited in the introduction as a key work in this area."}, {"fullname_first_author": "Lu", "paper_title": "MathVista: Evaluating mathematical reasoning of foundation models in visual contexts", "publication_date": "2023-10-00", "reason": "MathVista is used as a benchmark in the paper's experimental evaluation, indicating its importance in the field of multimodal mathematical reasoning."}, {"fullname_first_author": "Peng", "paper_title": "Multimath: Bridging visual and mathematical reasoning for large language models", "publication_date": "2024-09-00", "reason": "The Multimath dataset is a major source of training data used in this paper, highlighting its significance in the creation of the MMathCoT-1M dataset."}, {"fullname_first_author": "Zou", "paper_title": "Dynamath: A dynamic visual benchmark for evaluating mathematical reasoning robustness of vision language models", "publication_date": "2024-11-00", "reason": "Dynamath is another important benchmark dataset used in the paper's experimental evaluation, showcasing its role in assessing the robustness of the proposed model."}, {"fullname_first_author": "Wang", "paper_title": "Math-shepherd: Verify and reinforce LLMs step-by-step without human annotations", "publication_date": "2024-09-00", "reason": "This paper is cited in relation to the dual-view process supervision strategy, which is a core methodology of the paper, making it highly relevant to the core contribution."}]}