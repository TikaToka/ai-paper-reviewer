[{"content": "| Methods | Rank | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Baseline |  |  |  |  |  |  |  |  |  |  |\n| Chance Level (Random) | - | - | - | - | - | - | 25.0 | 36.1 | 28.3 | 25.0 |\n| Chance Level (Frequency) | - | 34.0 | 62.1 | 32.0 | 29.9 | 33.1 | 25.1 | 47.9 | 28.4 | 25.2 |\n| VSI-Bench (tiny) Perf. |  |  |  |  |  |  |  |  |  |  |\n| Human Level<sup>\u2020</sup> | - | 79.2 | 94.3 | 47.0 | 60.4 | 45.9 | 94.7 | 95.8 | 95.8 | 100.0 |\n| Gemini-1.5 Flash<sup>\u2020</sup> | - | 45.7 | 50.8 | 33.6 | 56.5 | 45.2 | 48.0 | 39.8 | 32.7 | 59.2 |\n| Gemini-1.5 Pro<sup>\u2020</sup> | - | 48.8 | 49.6 | 28.8 | 58.6 | 49.4 | 46.0 | 48.1 | 42.0 | 68.0 |\n| Gemini-2.0 Flash<sup>\u2020</sup> | - | 45.4 | 52.4 | 30.6 | 66.7 | 31.8 | 56.0 | 46.3 | 24.5 | 55.1 |\n| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |  |\n| GPT-4o | 3 | 34.0 | 46.2 | 5.3 | 43.8 | 38.2 | 37.0 | 41.3 | 31.5 | 28.5 |\n| Gemini-1.5 Flash | 2 | 42.1 | 49.8 | 30.8 | 53.5 | 54.4 | 37.7 | 41.0 | 31.5 | 37.8 |\n| Gemini-1.5 Pro | 1 | 45.4 | 56.2 | 30.9 | 64.1 | 43.6 | 51.3 | 46.3 | 36.0 | 34.6 |\n| Open-source Models |  |  |  |  |  |  |  |  |  |  |\n| InternVL2-2B | 11 | 27.4 | 21.8 | 24.9 | 22.0 | 35.0 | 33.8 | 44.2 | 30.5 | 7.1 |\n| InternVL2-8B | 5 | 34.6 | 23.1 | 28.7 | 48.2 | 39.8 | 36.7 | 30.7 | 29.9 | 39.6 |\n| InternVL2-40B | 3 | 36.0 | 34.9 | 26.9 | 46.5 | 31.8 | 42.1 | 32.2 | 34.0 | 39.6 |\n| LongVILA-8B | 12 | 21.6 | 29.1 | 9.1 | 16.7 | 0.0 | 29.6 | 30.7 | 32.5 | 25.5 |\n| VILA-1.5-8B | 9 | 28.9 | 17.4 | 21.8 | 50.3 | 18.8 | 32.1 | 34.8 | 31.0 | 24.8 |\n| VILA-1.5-40B | 7 | 31.2 | 22.4 | 24.8 | 48.7 | 22.7 | 40.5 | 25.7 | 31.5 | 32.9 |\n| LongVA-7B | 8 | 29.2 | 38.0 | 16.6 | 38.9 | 22.2 | 33.1 | 43.3 | 25.4 | 15.7 |\n| LLaVA-NeXT-Video-7B | 4 | 35.6 | 48.5 | 14.0 | 47.8 | 24.2 | 43.5 | 42.4 | 34.0 | 30.6 |\n| LLaVA-NeXT-Video-72B | 1 | 40.9 | 48.9 | 22.8 | 57.4 | 35.3 | 42.4 | 36.7 | 35.0 | 48.6 |\n| LLaVA-OneVision-0.5B | 10 | 28.0 | 46.1 | 28.4 | 15.4 | 28.3 | 28.9 | 36.9 | 34.5 | 5.8 |\n| LLaVA-OneVision-7B | 6 | 32.4 | 47.7 | 20.2 | 47.4 | 12.3 | 42.5 | 35.2 | 29.4 | 24.4 |\n| LLaVA-OneVision-72B | 2 | 40.2 | 43.5 | 23.9 | 57.6 | 37.5 | 42.5 | 39.9 | 32.5 | 44.6 |", "caption": "Table 1: Gemini-1.5 Pro CoT performance on a 500-questions subset in VideoMME.", "description": "\ud45c 2\ub294 VideoMME\ub77c\ub294 \ube44\ub514\uc624 \uc774\ud574 \ubca4\uce58\ub9c8\ud06c\uc758 500\uac1c \uc9c8\ubb38 \ud558\uc704 \uc9d1\ud569\uc5d0 \ub300\ud55c Gemini-1.5 Pro \ubaa8\ub378\uc758 Chain-of-Thought(CoT) \ud504\ub86c\ud504\ud305 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  CoT \ud504\ub86c\ud504\ud305\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc640 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, CoT \ud504\ub86c\ud504\ud305\uc774 VideoMME \uc791\uc5c5\uc5d0\uc11c Gemini-1.5 Pro \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5.2 Limits of CoT Methods in Visuospatial Tasks"}, {"content": "| Case | Performance |\n|---|---| \n| Gemini-1.5 Pro (w/o CoT) | 77.2 |\n| Gemini-1.5 Pro (w/ CoT) | 79.8 |", "caption": "(a) Cognitive map prompting.", "description": "\ud45c (a)\ub294 \uc778\uc9c0 \uc9c0\ub3c4 \ud504\ub86c\ud504\ud305\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'Cog. Map Src'\ub294 \uc778\uc9c0 \uc9c0\ub3c4 \uc0dd\uc131\uc5d0 \uc0ac\uc6a9\ub41c \uc18c\uc2a4(MLLM \ub610\ub294 GT)\ub97c \ub098\ud0c0\ub0b4\uace0, 'Size'\ub294 \uc778\uc9c0 \uc9c0\ub3c4\uc758 \ud06c\uae30\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. 'Rel. Dist Acc'\ub294 \uc0c1\ub300 \uac70\ub9ac \uc815\ud655\ub3c4\ub97c \uc758\ubbf8\ud558\uba70, \uc778\uc9c0 \uc9c0\ub3c4\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c\uc640 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c\uc758 \uc0c1\ub300 \uac70\ub9ac \uc9c8\ubb38\uc5d0 \ub300\ud55c MLLM\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud569\ub2c8\ub2e4.  \uacb0\uacfc\ub294 \uc778\uc9c0 \uc9c0\ub3c4\ub97c \uc0ac\uc6a9\ud558\uba74 MLLM\uc758 \uc0c1\ub300 \uac70\ub9ac \ucd94\ub860 \ub2a5\ub825\uc774 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6.2 How MLLMs Think in Space Visually"}, {"content": "| Case | Rel. Dist Acc. |\n|---|---| \n| w/o Cog. map | 46.0 |\n| w/ Cog. map | 56.0 |\n| w/ Cog. map (GT) | 66.0 |", "caption": "(b) Cognitive map canvas size.", "description": "\ud45c (b)\ub294 MLLM\uc774 \uacf5\uac04\uc744 \uae30\uc5b5\ud558\ub294 \ubc29\uc2dd\uc744 \uc870\uc0ac\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \uc778\uc9c0 \uc9c0\ub3c4\uc758 \ud06c\uae30\uac00 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  10x10 \ud06c\uae30\uc758 \uaca9\uc790\uc640 20x20 \ud06c\uae30\uc758 \uaca9\uc790\ub97c \ube44\uad50\ud558\uc5ec, MLLM\uc758 \uc0c1\ub300\uc801 \uac70\ub9ac \ucd94\ub860 \uc815\ud655\ub3c4\uc5d0 \ub300\ud55c \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uc989, MLLM\uc774 \uacf5\uac04\uc744 \ud45c\ud604\ud558\ub294 \ub370 \uc0ac\uc6a9\ud558\ub294 \uaca9\uc790 \ud06c\uae30\uac00 \ub2e4\ub97c \ub54c \uc0c1\ub300\uc801 \uac70\ub9ac \uc778\uc2dd \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "6.2 How MLLMs Think in Space Visually"}, {"content": "| Cog. Map Src. | Size | Rel. Dist Acc. |\n|---|---|---|\n| MLLM | 10 \u00d7 10 | 56.0 |\n| MLLM | 20 \u00d7 20 | 54.0 |\n| GT | 10 \u00d7 10 | 66.0 |\n| GT | 20 \u00d7 20 | 78.0 |", "caption": "Table 2: Relative distance task with cognitive map.", "description": "\ud45c 2\ub294 \ubaa8\ub378\uc774 \uacf5\uac04\uc801 \uc815\ubcf4\ub97c \uae30\uc5b5\ud558\ub294 \ubc29\uc2dd\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c '\uc778\uc9c0 \uc9c0\ub3c4' \uc811\uadfc\ubc95\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \uc778\uc9c0 \uc9c0\ub3c4\ub97c \ud65c\uc6a9\ud588\uc744 \ub54c \uc0c1\ub300\uc801 \uac70\ub9ac \ucd94\ub860 \uacfc\uc81c\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1 \uc5ec\ubd80\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  '\uc778\uc9c0 \uc9c0\ub3c4 \uc0dd\uc131' \ud06c\uae30(10x10 \ub610\ub294 20x20)\ub97c \ub2ec\ub9ac\ud558\uc5ec \uc2e4\ud5d8\ud55c \uacb0\uacfc\ub3c4 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uae30\uc900 \ubaa8\ub378(MLLM)\uacfc \uc778\uc9c0 \uc9c0\ub3c4\ub97c \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uc778\uc9c0 \uc9c0\ub3c4\uc758 \ud6a8\uacfc\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "6. How MLLMs Think in Space Visually"}, {"content": "| Task | Question Template |\n|---|---| \n| Object Counting | How many {category}(s) are in this room? |\n| Relative Distance | Measuring from the closest point of each object, which of these objects ({choice a}, {choice b}, {choice c}, {choice d}) is the closest to the {category}? |\n| Relative Direction | To create a comprehensive test of relative direction, three difficulty levels were created:\n* **Easy:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to the left or the right of the {orienting object}? \n* **Medium:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to my left, right, or back? An object is to my back if I would have to turn at least 135 degrees in order to face it. \n* **Hard:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to my front-left, front-right, back-left, or back-right? Directions refer to the quadrants of a Cartesian plane (assuming I am at the origin and facing the positive y-axis). |\n| Appearance Order | What will be the first-time appearance order of the following categories in the video: {choice a}, {choice b}, {choice c}, {choice d}? |\n| Object Size | What is the length of the longest dimension (length, width, or height) of the {category}, measured in centimeters? |\n| Absolute Distance | Measuring from the closest point of each object, what is the direct distance between the {object 1} and the {object 2} (in meters)? |\n| Room Size | What is the size of this room (in square meters)? If multiple rooms are shown, estimate the size of the combined space. |\n| Route Plan | You are a robot beginning at {the bed facing the tv}. You want to navigate to {the toilet}. You will perform the following actions (Note: for each [please fill in], choose either \u2018turn back,\u2019 \u2018turn left,\u2019 or \u2018turn right.\u2019): {1. Go forward until the TV 2. [please fill in] 3. Go forward until the shower 4. [please fill in] 5. Go forward until the toilet.}. You have reached the final destination.|", "caption": "Table 3: Question Templates for tasks in VSI-Bench. We replace the highlighted part in the question template from scene to scene to construct our benchmark. Note that a complete example question is provided for Route Plan.", "description": "\uc774 \ud45c\ub294 VSI-Bench(Video-based Spatial Intelligence Benchmark)\uc758 \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc9c8\ubb38 \ud15c\ud50c\ub9bf\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VSI-Bench\ub294 \ub2e4\uc591\ud55c \uc2e4\ub0b4 \ud658\uacbd\uc758 \ube44\ub514\uc624\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc911 \ubaa8\ub2ec \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uc758 \uc2dc\uac01-\uacf5\uac04 \uc9c0\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac1c\uccb4 \uacc4\uc218, \uc0c1\ub300 \uac70\ub9ac, \uc0c1\ub300 \ubc29\ud5a5, \uacbd\ub85c \uacc4\ud68d, \uc678\ud615 \uc21c\uc11c, \uac1c\uccb4 \ud06c\uae30, \uc808\ub300 \uac70\ub9ac, \ubc29 \ud06c\uae30 \ub4f1 8\uac00\uc9c0 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc9c8\ubb38 \ud15c\ud50c\ub9bf\uc774 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ud15c\ud50c\ub9bf\uc5d0\ub294 \ud2b9\uc815 \uc694\uc18c(\uc608: \uac1c\uccb4 \ubc94\uc8fc, \uc120\ud0dd\uc9c0)\ub97c \ud574\ub2f9 \uc7a5\uba74\uc5d0 \ub9de\uac8c \ubc14\uafd4\uc11c \uc0ac\uc6a9\ud558\ub3c4\ub85d \ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uacbd\ub85c \uacc4\ud68d \uacfc\uc81c\uc758 \uacbd\uc6b0 \uc644\ubcbd\ud55c \uc608\uc2dc \uc9c8\ubb38\uc774 \uc81c\uacf5\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 VSI-Bench \ub370\uc774\ud130\uc14b\uc744 \uad6c\uc131\ud558\ub294 \ubc29\ubc95\uacfc MLLM \ud3c9\uac00 \ubc29\uc2dd\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub3d5\uc2b5\ub2c8\ub2e4.", "section": "3 VSI-Bench"}, {"content": "| Order | Avg. |\n|---|---| \n| Video first | **48.8** |\n| Question first | 46.3 |", "caption": "(a) Input Sequence", "description": "\ud45c 5\ub294 \ube44\ub514\uc624 \uc785\ub825 \uc21c\uc11c\uc640 \ubc18\ubcf5\uc5d0 \ub530\ub978 \ube44\uad50 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a) \ube44\ub514\uc624 \uc785\ub825 \uc21c\uc11c\ub294 \ube44\ub514\uc624\ub97c \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\uacfc \uc9c8\ubb38\uc744 \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. (b) \ube44\ub514\uc624 \ubc18\ubcf5 \ud69f\uc218\ub294 \ube44\ub514\uc624\ub97c \ud55c \ubc88 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uacfc \ub450 \ubc88 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. \uc2e4\ud5d8 \uacb0\uacfc, \ube44\ub514\uc624\ub97c \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\uc774 \uc9c8\ubb38\uc744 \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\ubcf4\ub2e4 \ud3c9\uade0 \uc815\ud655\ub3c4\uac00 \uc57d 2.5% \ub192\uc558\uace0, \ube44\ub514\uc624\ub97c \ub450 \ubc88 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\uc774 \ud55c \ubc88 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd\ubcf4\ub2e4 \ud3c9\uade0 \uc815\ud655\ub3c4\uac00 \uc57d 2.1% \ub192\uc558\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc0ac\ub78c\uc774 \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \uc5ec\ub7ec \ubc88 \uac80\ud1a0\ud558\uc5ec \ubb38\uc81c \ud574\uacb0 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uacfc \uc720\uc0ac\ud569\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \uacb0\uacfc\ub294 MLLM\uc774 \ube44\ub514\uc624 \uc774\ud574\uc5d0 \uc788\uc5b4 \ub2e8\uc21c\ud788 \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \ucc98\ub9ac\ud558\ub294 \uac83\uc744 \ub118\uc5b4,  \ubc18\ubcf5\uc801\uc778 \uac80\ud1a0\ub97c \ud1b5\ud574  \ucd94\ub860 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. \ud3c9\uac00 \uacb0\uacfc"}, {"content": "| # Times | Avg. |\n|---|---| \n| 1 | 48.8 |\n| 2 | **50.9** |", "caption": "(b) Video Repetition Times", "description": "\ud45c 5(b)\ub294 \ube44\ub514\uc624 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\ub514\uc624\ub97c \ud55c \ubc88\ub9cc \ubcf4\uc5ec\uc8fc\uc5c8\uc744 \ub54c\uc640 \ub450 \ubc88 \ubcf4\uc5ec\uc8fc\uc5c8\uc744 \ub54c\uc758 Gemini-1.5 Pro \ubaa8\ub378 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec, \ube44\ub514\uc624\ub97c \ubc18\ubcf5\ud574\uc11c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc774 \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294, \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec \ube44\ub514\uc624 \ubc18\ubcf5\uc774 \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc5b4\ub5a4 \uc601\ud5a5\uc744 \uc8fc\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4. \ub2e8\uc21c\ud788 \ube44\ub514\uc624\ub97c \uc5ec\ub7ec \ubc88 \ubcf4\uc5ec\uc8fc\ub294 \uac83\ub9cc\uc73c\ub85c\ub3c4 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub420 \uc218 \uc788\ub294\uc9c0,  \uadf8\ub9ac\uace0 \uadf8 \uc815\ub3c4\ub294 \uc5b4\ub290 \uc815\ub3c4\uc778\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "4. \ud3c9\uac00 \uacb0\uacfc"}, {"content": "| Methods | # of Frames |\n|---|---| \n| _Proprietary Models (API)_ |  |\n| GPT-4o | 16 |\n| Gemini-1.5 Flash | - |\n| Gemini-1.5 Pro | - |\n| _Open-source Models_ |  |\n| InternVL2-2B | 8 |\n| InternVL2-8B | 8 |\n| InternVL2-40B | 8 |\n| LongVILA-8B | 32 |\n| VILA-1.5-8B | 32 |\n| VILA-1.5-40B | 32 |\n| LongVA-7B | 32 |\n| LLaVA-NeXT-Video-7B | 32 |\n| LLaVA-NeXT-Video-72B | 32 |\n| LLaVA-OneVision-0.5B | 32 |\n| LLaVA-OneVision-7B | 32 |\n| LLaVA-OneVision-72B | 32 |", "caption": "Table 4: Ablations on the video input sequence and repetition.", "description": "\ud45c 5\ub294 \ube44\ub514\uc624 \uc785\ub825 \uc21c\uc11c \ubc0f \ubc18\ubcf5\uc5d0 \ub300\ud55c \ucd94\uac00 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uba3c\uc800, \ube44\ub514\uc624\ub97c \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd(Video first)\uacfc \uc9c8\ubb38\uc744 \uba3c\uc800 \ubcf4\uc5ec\uc8fc\ub294 \ubc29\uc2dd(Question first)\uc744 \ube44\uad50\ud55c \uacb0\uacfc, \ube44\ub514\uc624 \uba3c\uc800 \ubc29\uc2dd\uc774 \ud3c9\uade0 2.5% \ub354 \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc2dc\uac01\uc801 \uc815\ubcf4\ub97c \uba3c\uc800 \uc81c\uacf5\ud558\ub294 \uac83\uc774 \ubaa8\ub378\uc758 \uc774\ud574\ub3c4 \ud5a5\uc0c1\uc5d0 \ub3c4\uc6c0\uc774 \ub41c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ub2e4\uc74c\uc73c\ub85c, \ube44\ub514\uc624 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubd84\uc11d\ud55c \uacb0\uacfc, \ube44\ub514\uc624\ub97c \ub450 \ubc88 \ubc18\ubcf5\ud574\uc11c \ubcf4\uc5ec\uc900 \uacbd\uc6b0 \ud3c9\uade0 2.1% \ub354 \ub192\uc740 \uc131\ub2a5\uc744 \uae30\ub85d\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \ube44\ub514\uc624\ub97c \uc5ec\ub7ec \ubc88 \ubd84\uc11d\ud560 \uc218 \uc788\ub294 \uae30\ud68c\ub97c \uc81c\uacf5\ud558\uba74 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub0bc \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uacb0\uacfc\uc785\ub2c8\ub2e4. \uc989,  \uc2dc\uac01 \uc815\ubcf4\uc758 \uc21c\uc11c\uc640 \ubc18\ubcf5 \ud69f\uc218\uac00 \ubaa8\ub378\uc758  \uc2dc\uac01\uc801 \ucd94\ub860 \ub2a5\ub825\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce68\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8\uc785\ub2c8\ub2e4.", "section": "4.2 \uc8fc\uc694 \uacb0\uacfc"}, {"content": "| Models | QA. Type | Prompt |\n|---|---|---|\n| Pre-Prompt | - | _These are frames of a video._ |\n| Post-Prompt | Open-source Models | NA | _Please answer the question using a single word or phrase._ |\n|  |  | MCA | _Answer with the option\u2019s letter from the given choices directly._ |\n| Post-Prompt | Proprietary Models | NA | _Do not respond with anything other than a single number!_ |\n|  |  | MCA | _Answer with the option\u2019s letter from the given choices directly._ |", "caption": "Table 5: Number of frames used in evaluation.", "description": "\ud45c 6\uc740 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ube44\ub514\uc624 \ud504\ub808\uc784 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \ube44\ub514\uc624\uc758 \uc804\uccb4 \ud504\ub808\uc784 \uc218\uac00 \uc544\ub2c8\ub77c,  \uc2e4\uc81c \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ud504\ub808\uc784\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ube44\ub514\uc624 \ub370\uc774\ud130\uc758 \uc591\uc801 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc815\ubcf4\uc785\ub2c8\ub2e4.  \ud2b9\ud788,  \uc77c\ubd80 \ubaa8\ub378\uc758 \uacbd\uc6b0 \ube44\ub514\uc624 \uc804\uccb4\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0 \uc77c\ubd80\ub9cc \uc0ac\uc6a9\ud588\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ube44\ub514\uc624 \ud504\ub808\uc784\uc758 \uc218\ub294 \ubaa8\ub378\uc758 \uc720\ud615\uacfc \ub9e4\uac1c\ubcc0\uc218 \ud06c\uae30 \ub4f1\uc5d0 \ub530\ub77c \ub2e4\ub985\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubaa8\ub378\ubcc4\ub85c \uc0ac\uc6a9\ub41c \ube44\ub514\uc624 \ub370\uc774\ud130 \uc591\uc758 \ucc28\uc774\ub97c \uace0\ub824\ud574\uc57c \ud560 \ud544\uc694\uac00 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. VSI-Bench \ud3c9\uac00"}, {"content": "| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |\n|---|---|---|---|---|---|---|---|---|---| \n| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |\n| GPT-4o | 35.6 | 36.2 | 4.6 | 47.2 | 40.4 | 40.0 | 46.2 | 32.0 | 38.0 |\n| Gemini-1.5 Flash | 45.7 | 50.8 | 33.6 | 56.5 | 45.2 | 48.0 | 39.8 | 32.7 | 59.2 |\n| Gemini-1.5 Pro | 48.8 | 49.6 | 28.8 | 58.6 | 49.4 | 46.0 | 48.1 | 42.0 | 68.0 |\n| Gemini-2.0 Flash | 45.4 | 52.4 | 30.6 | 66.7 | 31.8 | 56.0 | 46.3 | 24.5 | 55.1 |\n| Open-source Models |  |  |  |  |  |  |  |  |  |\n| InternVL2-2B | 25.5 | 30.6 | 20.4 | 26.0 | 29.6 | 28.0 | 39.2 | 28.0 | 2.0 |\n| InternVL2-8B | 32.9 | 26.4 | 25.4 | 43.8 | 41.6 | 30.0 | 32.2 | 20.0 | 44.0 |\n| InternVL2-40B | 37.6 | 40.8 | 23.8 | 48.0 | 26.0 | 46.0 | 30.1 | 42.0 | 44.0 |\n| LongVILA-8B | 19.1 | 23.4 | 10.8 | 11.4 | 0.0 | 20.0 | 33.1 | 28.0 | 26.0 |\n| VILA-1.5-8B | 31.4 | 12.2 | 23.4 | 51.4 | 18.6 | 36.0 | 41.5 | 42.0 | 26.0 |\n| VILA-1.5-40B | 32.3 | 14.6 | 21.0 | 48.0 | 20.6 | 42.0 | 22.0 | 40.0 | 50.0 |\n| LongVA-7B | 31.8 | 41.2 | 17.4 | 39.6 | 25.4 | 30.0 | 52.8 | 34.0 | 14.0 |\n| LLaVA-NeXT-Video-7B | 35.7 | 49.0 | 12.8 | 48.6 | 21.4 | 40.0 | 43.5 | 34.0 | 36.0 |\n| LLaVA-NeXT-Video-72B | 39.3 | 41.4 | 26.6 | 55.6 | 31.6 | 36.0 | 25.6 | 42.0 | 56.0 |\n| LLaVA-OneVision-0.5B | 27.7 | 44.0 | 23.0 | 18.8 | 28.4 | 30.0 | 33.4 | 36.0 | 8.0 |\n| LLaVA-OneVision-7B | 33.8 | 48.2 | 22.0 | 44.4 | 14.0 | 44.0 | 31.9 | 34.0 | 32.0 |\n| LLaVA-OneVision-72B | 41.6 | 38.0 | 31.6 | 54.4 | 35.2 | 44.0 | 39.7 | 32.0 | 58.0 |", "caption": "Table 6: Prompts used in evaluation. NA and MAC indicates questions with Numerical Answer and Multiple Choice Answer respectively.", "description": "\ud45c 7\uc740 \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378(\uc624\ud508\uc18c\uc2a4 \ubaa8\ub378\uacfc \ub3c5\uc810 \ubaa8\ub378)\uacfc \uc9c8\ubb38 \uc720\ud615(\uc218\uce58\ud615 \ub2f5\ubcc0, \ub2e4\uc911 \uc120\ud0dd\ud615 \ub2f5\ubcc0)\uc5d0 \ub530\ub77c \ub2e4\ub978 \ud504\ub86c\ud504\ud2b8\uac00 \uc0ac\uc6a9\ub418\uc5c8\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc218\uce58\ud615 \ub2f5\ubcc0\uc758 \uacbd\uc6b0 \uc22b\uc790\ub9cc\uc73c\ub85c \ub2f5\ubcc0\ud558\ub3c4\ub85d \uc9c0\uc2dc\ud558\uace0, \ub2e4\uc911 \uc120\ud0dd\ud615 \ub2f5\ubcc0\uc758 \uacbd\uc6b0 \uc81c\uc2dc\ub41c \uc120\ud0dd\uc9c0 \uc911 \ud558\ub098\uc758 \ubb38\uc790\ub97c \ub2f5\uc73c\ub85c \uc81c\ucd9c\ud558\ub3c4\ub85d \uc9c0\uc2dc\ud569\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc758 \uc751\ub2f5 \ud615\uc2dd\uc744 \uc77c\uad00\uc131 \uc788\uac8c \uc720\uc9c0\ud558\uace0, \uacb0\uacfc \ubd84\uc11d\uc758 \uc815\ud655\uc131\uc744 \ub192\uc774\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4. VSI-Bench \ud3c9\uac00"}, {"content": "| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |\n|---|---|---|---|---|---|---|---|---|---| \n| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |\n| GPT-4o | 14.5 | 0.1 | 5.2 | 36.7 | 0.0 | 10.8 | 23.2 | 26.9 | 13.1 |\n| Gemini-1.5 Flash | 19.9 | 25.0 | 30.3 | 52.5 | 0.0 | 0.0 | 21.2 | 29.9 | 0.2 |\n| Gemini-1.5 Pro | 32.3 | 30.6 | 11.5 | 51.5 | 33.1 | 33.8 | 44.6 | 33.5 | 20.2 |\n| Open-source Models |  |  |  |  |  |  |  |  |  |\n| InternVL2-2B | 17.8 | 5.4 | 23.7 | 9.2 | 0.0 | 26.9 | 41.2 | 27.9 | 7.9 |\n| InternVL2-8B | 27.6 | 31.9 | 26.8 | 38.3 | 0.7 | 27.1 | 39.2 | 33.0 | 23.6 |\n| InternVL2-40B | 24.4 | 5.4 | 29.1 | 39.2 | 0.7 | 30.3 | 37.7 | 27.9 | 24.7 |\n| LongVILA-8B | 20.2 | 47.4 | 12.6 | 8.7 | 0.6 | 24.3 | 27.0 | 27.4 | 13.9 |\n| VILA-1.5-8B | 21.5 | 7.4 | 7.6 | 45.7 | 0.0 | 25.4 | 39.1 | 29.4 | 17.6 |\n| VILA-1.5-40B | 25.5 | 5.3 | 27.6 | 46.5 | 0.7 | 30.2 | 37.1 | 31.5 | 25.0 |\n| LongVA-7B | 21.9 | 5.1 | 18.1 | 27.4 | 26.1 | 23.4 | 39.8 | 26.9 | 8.7 |\n| LLaVA-NeXT-Video-7B | 25.2 | 14.8 | 14.6 | 32.5 | 26.1 | 26.8 | 45.0 | 33.0 | 8.5 |\n| LLaVA-NeXT-Video-72B | 29.1 | 19.0 | 25.4 | 46.3 | 26.1 | 29.0 | 38.8 | 33.0 | 15.5 |\n| LLaVA-OneVision-0.5B | 28.6 | 38.4 | 30.1 | 32.0 | 24.3 | 22.0 | 41.8 | 34.5 | 5.4 |\n| LLaVA-OneVision-7B | 25.3 | 13.8 | 8.5 | 45.5 | 26.1 | 28.6 | 41.2 | 27.9 | 11.1 |\n| LLaVA-OneVision-72B | 28.9 | 8.2 | 23.8 | 54.1 | 26.1 | 30.4 | 38.1 | 33.0 | 17.1 |", "caption": "Table 7: Complete VSI-Bench (tiny) evaluation results.", "description": "\ud45c 7\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c VSI-Bench (tiny) \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c 15\uac00\uc9c0 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc9c0\uc6d0 \ub2e4\uc911 \ubaa8\ub2ec \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uc758 \uc131\ub2a5 \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\uc640 \ud568\uaed8, \uac1c\uccb4 \uc218 \uc138\uae30, \uc0c1\ub300 \uac70\ub9ac, \uac1c\uccb4 \ud06c\uae30, \ubc29 \ud06c\uae30, \uc0c1\ub300 \ubc29\ud5a5, \uacbd\ub85c \uacc4\ud68d, \uc678\uad00 \uc21c\uc11c \ub4f1 8\uac00\uc9c0 \uc2dc\uac01\uc801 \uacf5\uac04 \uc9c0\ub2a5 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc138\ubd80 \uc815\ud655\ub3c4 \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c MLLM\uc758 \uc2dc\uac01\uc801 \uacf5\uac04 \ucd94\ub860 \ub2a5\ub825\uc744 \ube44\uad50\ud558\uace0, \uac15\uc810\uacfc \uc57d\uc810\uc744 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. VSI-Bench\uc5d0 \ub300\ud55c \ud3c9\uac00"}, {"content": "| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |\n|---|---|---|---|---|---|---|---|---|---| \n| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |\n| GPT-4o | 19.5 | 46.1 | 0.1 | 7.1 | 38.2 | 26.2 | 18.0 | 4.6 | 15.4 |\n| Gemini-1.5 Flash | 22.2 | 24.9 | 0.5 | 1.0 | 54.4 | 37.7 | 19.9 | 1.5 | 37.7 |\n| Gemini-1.5 Pro | 13.0 | 25.5 | 19.5 | 12.6 | 10.6 | 17.5 | 1.7 | 2.5 | 14.4 |\n| Open-source Models |  |  |  |  |  |  |  |  |  |\n| InternVL2-2B | 9.6 | 16.4 | 1.2 | 12.8 | 35.0 | 6.9 | 3.0 | 2.5 | -0.8 |\n| InternVL2-8B | 7.0 | -8.8 | 1.9 | 9.9 | 39.1 | 9.7 | -8.5 | -3.0 | 16.0 |\n| InternVL2-40B | 11.6 | 29.6 | -2.2 | 7.3 | 31.1 | 11.8 | -5.5 | 6.1 | 14.9 |\n| LongVILA-8B | 1.4 | -18.2 | -3.5 | 7.9 | -0.6 | 5.3 | 3.7 | 5.1 | 11.5 |\n| VILA-1.5-8B | 7.3 | 10.0 | 14.2 | 4.6 | 18.8 | 6.7 | -4.4 | 1.5 | 7.2 |\n| VILA-1.5-40B | 5.7 | 17.1 | -2.8 | 2.2 | 22.0 | 10.4 | -11.4 | 0.0 | 7.9 |\n| LongVA-7B | 7.2 | 32.9 | -1.5 | 11.5 | -3.9 | 9.7 | 3.5 | -1.5 | 7.1 |\n| LLaVA-NeXT-Video-7B | 10.5 | 33.8 | -0.6 | 15.2 | -1.9 | 16.7 | -2.7 | 1.0 | 22.1 |\n| LLaVA-NeXT-Video-72B | 11.7 | 29.9 | -2.6 | 11.1 | 9.2 | 13.3 | -2.0 | 2.0 | 33.0 |\n| LLaVA-OneVision-0.5B | -0.5 | 7.8 | -1.7 | -16.6 | 4.0 | 6.9 | -5.0 | 0.0 | 0.3 |\n| LLaVA-OneVision-7B | 7.0 | 33.9 | 11.7 | 1.9 | -13.9 | 13.9 | -6.0 | 1.5 | 13.3 |\n| LLaVA-OneVision-72B | 11.4 | 35.4 | 0.1 | 3.5 | 11.4 | 12.1 | 1.8 | -0.5 | 27.4 |", "caption": "Table 8: Complete blind evaluation results.", "description": "\ud45c 8\uc740 \ube44\uc804 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0(\uc989, \ube44\uc804\uc774 \ube44\ud65c\uc131\ud654\ub41c \uc0c1\ud0dc\uc5d0\uc11c) \ub2e4\uc591\ud55c \ubaa8\ub378\uc774 VSI-Bench(tiny) \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2ec\uc131\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \ud3c9\uade0 \uc815\ud655\ub3c4\uc640 \uac01 \uc791\uc5c5(\uac1c\uccb4 \uc218 \uc138\uae30, \uc808\ub300 \uac70\ub9ac, \uac1c\uccb4 \ud06c\uae30, \ubc29 \ud06c\uae30, \uc0c1\ub300 \uac70\ub9ac, \uc0c1\ub300 \ubc29\ud5a5, \uacbd\ub85c \uacc4\ud68d, \uc678\uad00 \uc21c\uc11c)\uc5d0 \ub300\ud55c \uc138\ubd80 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \ubaa8\ub378\uc758 \uc2dc\uac01\uc801 \uacf5\uac04 \uc9c0\ub2a5 \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788, \ub2e4\uc591\ud55c \ubaa8\ub378 \uc720\ud615\uacfc \ud06c\uae30(\ub9e4\uac1c\ubcc0\uc218 \uc218) \uac04\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ud30c\uc545\ud558\uace0, \uac1c\ubc29\ud615 \ubaa8\ub378\uacfc \ub3c5\uc810 \ubaa8\ub378 \uac04\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. VSI-Bench \ud3c9\uac00"}]