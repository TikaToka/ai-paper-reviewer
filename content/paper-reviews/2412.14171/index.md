---
title: "Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces"
summary: "MLLMì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ëŠ” ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ VSI-Bench ë°œí‘œ!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Computer Vision", "Visual Question Answering", "ğŸ¢ Stanford University",]
showSummary: true
date: 2024-12-18
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2412.14171 {{< /keyword >}}
{{< keyword icon="writer" >}} Jihan Yang et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2024-12-19 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2412.14171" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2412.14171" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/thinking-in-space-how-multimodal-large" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ìµœê·¼ **ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)**ì´ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ê´„ëª©í•  ë§Œí•œ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆì§€ë§Œ, ì‹œê°-ê³µê°„ ì§€ëŠ¥ì€ ì•„ì§ ë¯¸ê°œì²™ ë¶„ì•¼ë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.  ê¸°ì¡´ì˜ ì—°êµ¬ë“¤ì€ ì£¼ë¡œ ì •ì§€ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°-ê³µê°„ ì§€ëŠ¥ì„ í‰ê°€í–ˆì§€ë§Œ, ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ë¥¼ í¬ì°©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ë™ì˜ìƒ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹œê°-ê³µê°„ ì§€ëŠ¥ í‰ê°€ì˜ í•„ìš”ì„±ì´ ëŒ€ë‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.

ë³¸ ì—°êµ¬ì—ì„œëŠ” **MLLMì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ì¸ VSI-Bench**ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. VSI-BenchëŠ” ë‹¤ì–‘í•œ ì‹¤ë‚´ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ 5,000ê°œ ì´ìƒì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ í¬í•¨í•˜ë©°, **ê°ì²´ ê³„ìˆ˜, ìƒëŒ€ ê±°ë¦¬, ë°©í–¥, í¬ê¸°, ê²½ë¡œ ê³„íš** ë“± ë‹¤ì–‘í•œ ì‹œê°-ê³µê°„ ì§€ëŠ¥ ê³¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ VSI-Benchë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ MLLM ëª¨ë¸ì„ í‰ê°€í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ MLLMì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ì˜ ê°•ì ê³¼ ì•½ì ì„ ë°í˜”ìŠµë‹ˆë‹¤. íŠ¹íˆ, ê¸°ì¡´ì˜ ì–¸ì–´ì  ì¶”ë¡  ê¸°ë²•ì€ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ì§€ ì•Šì§€ë§Œ, **ì¸ì§€ ì§€ë„ ìƒì„±**ì„ í†µí•´ ê³µê°„ì  ê±°ë¦¬ ì¶”ë¡  ëŠ¥ë ¥ì´ í–¥ìƒë¨ì„ ë°œê²¬í•˜ì˜€ìŠµë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ VSI-Benchë¥¼ í†µí•´ ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} MLLMì´ ê³µê°„ì  ì¶”ë¡ ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ë°íˆê³ , ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²• ì œì‹œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} MLLMì˜ ê³µê°„ ì§€ê° ëŠ¥ë ¥ì€ **êµ­ì§€ì  ëª¨ë¸**ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, **ê¸€ë¡œë²Œ ëª¨ë¸** êµ¬ì¶•ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ì‚¬ì‹¤ ë°œê²¬ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)**ì˜ ê³µê°„ ì§€ê° ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ **VSI-Bench**ë¥¼ ì œì‹œí•˜ê³ , MLLMì´ ê³µê°„ì„ ì–´ë–»ê²Œ ì´í•´í•˜ê³  ê¸°ì–µí•˜ëŠ”ì§€ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” **ë¡œë´‡ ê³µí•™, ììœ¨ ì£¼í–‰, ì¦ê°• í˜„ì‹¤/ê°€ìƒ í˜„ì‹¤** ë¶„ì•¼ì—ì„œì˜ ì ì¬ì  ì‘ìš©ê³¼ ë”ë¶ˆì–´ **ì‹œê°-ê³µê°„ ì§€ëŠ¥** ì—°êµ¬ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë˜í•œ, ì œì‹œëœ ë²¤ì¹˜ë§ˆí¬ì™€ ë¶„ì„ ë°©ë²•ì€ í–¥í›„ ì—°êµ¬ìë“¤ì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ ì—°êµ¬ì— ê·€ì¤‘í•œ ìë£Œê°€ ë  ê²ƒì…ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2412.14171/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ì˜ í•µì‹¬ ìš”ì†Œì¸ ê³µê°„ ì¸ì§€, ê³µê°„ ë°°ì¹˜ ê¸°ì–µ, ê·¸ë¦¬ê³  ìš”êµ¬ì‹œ ê³µê°„ ì •ë³´ë¥¼ ë– ì˜¬ë ¤ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœê·¼ ë‹¤ì¤‘ ëª¨ë“œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(Multimodal LLMs)ì€ ì¼ë°˜ì ì¸ ë¹„ë””ì˜¤ë¥¼ ì´í•´í•  ìˆ˜ ìˆì§€ë§Œ, í™˜ê²½ì˜ ë¹„ë””ì˜¤ ë…¹í™”ë¥¼ ë³´ì—¬ì£¼ë©´ 'ê³µê°„ì ìœ¼ë¡œ ìƒê°'í•  ìˆ˜ ìˆì„ê¹Œìš”? ëª¨ë¸ì´ ê³µê°„ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆë„ë¡ ì •í™•í•˜ê³  ì•”ë¬µì ì¸ 'ì¸ì§€ ì§€ë„(cognitive map)'ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œìš”? ê·¸ë¦¬ê³  ê³µê°„ ì§€ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì¤‘ ëª¨ë“œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì˜ ê°•ì ê³¼ í•œê³„ëŠ” ë¬´ì—‡ì¼ê¹Œìš”? ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ì¤‘ ëª¨ë“œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì´ ì‹œì²­í•  ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì„¤ì •í•˜ê³ , ëª¨ë¸ì˜ ê¸°ì–µì„ í™•ì¸í•˜ê¸° ìœ„í•œ VQA ë²¤ì¹˜ë§ˆí¬ë¥¼ êµ¬ì¶•í•˜ê³ , ë‹¤ì¤‘ ëª¨ë“œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì´ ì‹¤ì œë¡œ ë¬´ì—‡ì„ ê¸°ì–µí•˜ê³  ì´í•´í•˜ëŠ”ì§€ ì¡°ì‚¬í•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ì§ˆë¬¸ë“¤ì„ íƒêµ¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Whether at home, in the workplace, or elsewhere, the ability to perceive a space, remember its layout, and retrieve this spatial information to answer questions on demand is a key aspect of visual-spatial intelligence. Recent Multimodal LLMs can understand general videos, but can they â€œthink spatiallyâ€ when presented with a video recording of an environment? Can they build an accurate, implicit â€œcognitive mapâ€ that allows them to answer questions about a space? What are the strengths and limitations of using MLLMs to enhance spatial intelligence? We dig into these questions by setting up video data for MLLMs to watch, building a VQA benchmark to check their recall, and examining what the MLLMs actually remember and understand.
> </details>





{{< table-caption >}}
| Methods | Rank | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |
|---|---|---|---|---|---|---|---|---|---|---|
| Baseline |  |  |  |  |  |  |  |  |  |  |
| Chance Level (Random) | - | - | - | - | - | - | 25.0 | 36.1 | 28.3 | 25.0 |
| Chance Level (Frequency) | - | 34.0 | 62.1 | 32.0 | 29.9 | 33.1 | 25.1 | 47.9 | 28.4 | 25.2 |
| VSI-Bench (tiny) Perf. |  |  |  |  |  |  |  |  |  |  |
| Human Level<sup>â€ </sup> | - | 79.2 | 94.3 | 47.0 | 60.4 | 45.9 | 94.7 | 95.8 | 95.8 | 100.0 |
| Gemini-1.5 Flash<sup>â€ </sup> | - | 45.7 | 50.8 | 33.6 | 56.5 | 45.2 | 48.0 | 39.8 | 32.7 | 59.2 |
| Gemini-1.5 Pro<sup>â€ </sup> | - | 48.8 | 49.6 | 28.8 | 58.6 | 49.4 | 46.0 | 48.1 | 42.0 | 68.0 |
| Gemini-2.0 Flash<sup>â€ </sup> | - | 45.4 | 52.4 | 30.6 | 66.7 | 31.8 | 56.0 | 46.3 | 24.5 | 55.1 |
| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |  |
| GPT-4o | 3 | 34.0 | 46.2 | 5.3 | 43.8 | 38.2 | 37.0 | 41.3 | 31.5 | 28.5 |
| Gemini-1.5 Flash | 2 | 42.1 | 49.8 | 30.8 | 53.5 | 54.4 | 37.7 | 41.0 | 31.5 | 37.8 |
| Gemini-1.5 Pro | 1 | 45.4 | 56.2 | 30.9 | 64.1 | 43.6 | 51.3 | 46.3 | 36.0 | 34.6 |
| Open-source Models |  |  |  |  |  |  |  |  |  |  |
| InternVL2-2B | 11 | 27.4 | 21.8 | 24.9 | 22.0 | 35.0 | 33.8 | 44.2 | 30.5 | 7.1 |
| InternVL2-8B | 5 | 34.6 | 23.1 | 28.7 | 48.2 | 39.8 | 36.7 | 30.7 | 29.9 | 39.6 |
| InternVL2-40B | 3 | 36.0 | 34.9 | 26.9 | 46.5 | 31.8 | 42.1 | 32.2 | 34.0 | 39.6 |
| LongVILA-8B | 12 | 21.6 | 29.1 | 9.1 | 16.7 | 0.0 | 29.6 | 30.7 | 32.5 | 25.5 |
| VILA-1.5-8B | 9 | 28.9 | 17.4 | 21.8 | 50.3 | 18.8 | 32.1 | 34.8 | 31.0 | 24.8 |
| VILA-1.5-40B | 7 | 31.2 | 22.4 | 24.8 | 48.7 | 22.7 | 40.5 | 25.7 | 31.5 | 32.9 |
| LongVA-7B | 8 | 29.2 | 38.0 | 16.6 | 38.9 | 22.2 | 33.1 | 43.3 | 25.4 | 15.7 |
| LLaVA-NeXT-Video-7B | 4 | 35.6 | 48.5 | 14.0 | 47.8 | 24.2 | 43.5 | 42.4 | 34.0 | 30.6 |
| LLaVA-NeXT-Video-72B | 1 | 40.9 | 48.9 | 22.8 | 57.4 | 35.3 | 42.4 | 36.7 | 35.0 | 48.6 |
| LLaVA-OneVision-0.5B | 10 | 28.0 | 46.1 | 28.4 | 15.4 | 28.3 | 28.9 | 36.9 | 34.5 | 5.8 |
| LLaVA-OneVision-7B | 6 | 32.4 | 47.7 | 20.2 | 47.4 | 12.3 | 42.5 | 35.2 | 29.4 | 24.4 |
| LLaVA-OneVision-72B | 2 | 40.2 | 43.5 | 23.9 | 57.6 | 37.5 | 42.5 | 39.9 | 32.5 | 44.6 |{{< /table-caption >}}

> ğŸ”¼ í‘œ 2ëŠ” VideoMMEë¼ëŠ” ë¹„ë””ì˜¤ ì´í•´ ë²¤ì¹˜ë§ˆí¬ì˜ 500ê°œ ì§ˆë¬¸ í•˜ìœ„ ì§‘í•©ì— ëŒ€í•œ Gemini-1.5 Pro ëª¨ë¸ì˜ Chain-of-Thought(CoT) í”„ë¡¬í”„íŒ… ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  CoT í”„ë¡¬í”„íŒ…ì„ ì‚¬ìš©í–ˆì„ ë•Œì™€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ì–´, CoT í”„ë¡¬í”„íŒ…ì´ VideoMME ì‘ì—…ì—ì„œ Gemini-1.5 Pro ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Gemini-1.5 Pro CoT performance on a 500-questions subset in VideoMME.
> </details>





### In-depth insights


#### Spatial Intelligence
ë³¸ ë…¼ë¬¸ì—ì„œ ë…¼ì˜ëœ ê³µê°„ ì§€ëŠ¥ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ìƒê°ì€ **ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°(ì‹œê°, ì–¸ì–´)ë¥¼ í†µí•©í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ê³µê°„ì  ì‚¬ê³  ëŠ¥ë ¥**ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  ì¸ê°„ì˜ ê³µê°„ ì§€ëŠ¥ì€ ë‹¨ìˆœíˆ ê³µê°„ì  ì •ë³´ë¥¼ ì¸ì§€í•˜ëŠ” ê²ƒì„ ë„˜ì–´, **ê³µê°„ì  ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì¡°ì‘í•˜ëŠ” ëŠ¥ë ¥**ì„ í¬í•¨í•©ë‹ˆë‹¤.  MLLMì€ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í†µí•´ ê³µê°„ì„ í•™ìŠµí•˜ì§€ë§Œ,  **ì¸ê°„ ìˆ˜ì¤€ì˜ ê³µê°„ ì§€ëŠ¥ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í•˜ë©°, íŠ¹íˆ ê³µê°„ì  ì¶”ë¡ ê³¼ ë°°ì¹˜(allocentric) ë° ìê¸°ì¤‘ì‹¬ì (egocentric) ê´€ì  ì „í™˜ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²ƒ**ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.  í¥ë¯¸ë¡­ê²Œë„, ì–¸ì–´ì  ì¶”ë¡  ê¸°ë²•ì€ ê³µê°„ ì§€ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ì§€ ì•Šì§€ë§Œ, **ì¸ì§€ì  ì§€ë„ ìƒì„±ì€ MLLMì˜ ê³µê°„ ê±°ë¦¬ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.  ì´ëŠ” **MLLMì´ ê³µê°„ì„ êµ­ì†Œì  ëª¨ë¸ë¡œ í‘œìƒí•˜ê³ , ì „ì—­ì  ëª¨ë¸ ìƒì„±ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ì **ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ê²°ë¡ ì ìœ¼ë¡œ, MLLMì˜ ê³µê°„ ì§€ëŠ¥ì€ ì—¬ì „íˆ ë°œì „ì˜ ì—¬ì§€ê°€ í¬ë©°, í–¥í›„ ì—°êµ¬ëŠ” **êµ­ì†Œì  ëª¨ë¸ì„ ì „ì—­ì  ëª¨ë¸ë¡œ í†µí•©í•˜ëŠ” ë°©ë²•ë¡ **ì— ì´ˆì ì„ ë§ì¶°ì•¼ í•  ê²ƒì…ë‹ˆë‹¤.

#### VSI-Bench
VSI-BenchëŠ” **ë¹„ë””ì˜¤ ê¸°ë°˜ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ë²¤ì¹˜ë§ˆí¬**ë¡œ, ë‹¤ì–‘í•œ í™˜ê²½ì˜ ì‹¤ë‚´ ê³µê°„ì„ ë¬˜ì‚¬í•˜ëŠ” 288ê°œì˜ ì‹¤ì œ ì˜ìƒê³¼ 5,000ê°œ ì´ìƒì˜ ì§ˆì˜ì‘ë‹µ ìŒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. **ì‹¤ì œ í™˜ê²½ ë°ì´í„°**ë¥¼ ì‚¬ìš©í•˜ì—¬ **ë‹¤ì–‘í•œ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ê³¼ì œ**ë¥¼ í‰ê°€í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ í•µì‹¬ì…ë‹ˆë‹¤.  ì´ëŠ” ì •ì  ì´ë¯¸ì§€ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ë”ìš± í’ë¶€í•œ ê³µê°„ ì´í•´ì™€ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸** (ê°ì²´ ê°œìˆ˜ ì„¸ê¸°, ìƒëŒ€ì  ê±°ë¦¬, ë°©í–¥, ê²½ë¡œ ê³„íš ë“±)ì„ í¬í•¨í•˜ë©°, ëª¨ë¸ì˜ ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í¬ê´„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.  **ì •ëŸ‰ì  ì„±ëŠ¥ í‰ê°€**ë¥¼ ìœ„í•œ ëª…í™•í•œ ì§€í‘œë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨, ë‹¤ì–‘í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ìˆ˜ì¤€ì„ ë¹„êµ ë¶„ì„í•˜ê³ , í–¥í›„ ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  íŠ¹íˆ, **ì¸ê°„ì˜ ì„±ëŠ¥ê³¼ì˜ ë¹„êµ**ë¥¼ í†µí•´ ëª¨ë¸ì˜ ê°•ì ê³¼ í•œê³„ë¥¼ ëª…í™•íˆ ë“œëŸ¬ë‚´ì–´, **ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ í–¥ìƒ**ì„ ìœ„í•œ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

#### MLLM Reasoning
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **MLLM(ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)**ì˜ ì¶”ë¡  ëŠ¥ë ¥ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ ì œì‹œí•©ë‹ˆë‹¤.  íŠ¹íˆ, ì‹œê³µê°„ì  ì§€ëŠ¥(visual-spatial intelligence) ì¸¡ë©´ì—ì„œ MLLMì´ ê³µê°„ì„ ì–´ë–»ê²Œ ì¸ì§€í•˜ê³ , ê¸°ì–µí•˜ê³ , ìƒê¸°í•˜ëŠ”ì§€ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  **ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ VSI-Bench ë²¤ì¹˜ë§ˆí¬**ë¥¼ í†µí•´ MLLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , **ì¸ê°„ ìˆ˜ì¤€ì˜ ì‹œê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ê³¼ì˜ ì°¨ì´ì ì„ ë¶„ì„**í•©ë‹ˆë‹¤.  í¥ë¯¸ë¡­ê²Œë„, **ì–¸ì–´ì  ì¶”ë¡  ê¸°ë²•(CoT, self-consistency, ToT)ì€ MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì— í° íš¨ê³¼ê°€ ì—†ë‹¤ëŠ” ì **ì„ ë°œê²¬í•˜ì˜€ìŠµë‹ˆë‹¤. ë°˜ë©´, **ì¸ì§€ ì§€ë„(cognitive maps) ìƒì„±ì„ í†µí•´ MLLMì˜ ê³µê°„ ê±°ë¦¬ ì¶”ì • ëŠ¥ë ¥ì´ í–¥ìƒ**ë˜ì—ˆìŒì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” **MLLMì´ êµ­ì§€ì ì¸ ê³µê°„ ëª¨ë¸ì€ ì˜ êµ¬ì¶•í•˜ì§€ë§Œ, ì „ë°˜ì ì¸ ê³µê°„ ëª¨ë¸ êµ¬ì¶•ì—ëŠ” ì–´ë ¤ì›€**ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, **MLLMì˜ ì‹œê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•´ì„œëŠ” êµ­ì§€ì  ëª¨ë¸ì—ì„œ ì „ë°˜ì ì¸ ê³µê°„ ëª¨ë¸ë¡œì˜ í™•ì¥ì´ ì¤‘ìš”**í•œ ê³¼ì œì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

#### Cognitive Maps
ë³¸ ë…¼ë¬¸ì—ì„œ ì¸ìš©ëœ 'ì¸ì§€ ì§€ë„(Cognitive Maps)'ëŠ” **ë‹¤ì¤‘ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)**ì´ ê³µê°„ì  ì •ë³´ë¥¼ ì–´ë–»ê²Œ í‘œìƒí•˜ê³  ê¸°ì–µí•˜ëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•œ ê°œë…ì…ë‹ˆë‹¤.  ì—°êµ¬ëŠ” MLLMì´ **ë‹¨í¸ì ì¸ ë¹„ë””ì˜¤ í”„ë ˆì„**ì—ì„œ **ì „ì²´ì ì¸ ê³µê°„ ì§€ë„**ë¥¼ ìƒì„±í•˜ê¸°ë³´ë‹¤ëŠ” **êµ­ì†Œì ì¸ ê³µê°„ ëª¨ë¸**ì„ ë§Œë“¤ì–´ ì—°ì†ì ì¸ ê³µê°„ ê²½í—˜ì„ ì¬êµ¬ì„±í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ êµ­ì†Œì  ëª¨ë¸ì€ ì¸ì ‘í•œ ì‚¬ë¬¼ë“¤ì˜ ìœ„ì¹˜ ê´€ê³„ëŠ” ì •í™•í•˜ê²Œ íŒŒì•…í•˜ì§€ë§Œ, ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡ ì •í™•ë„ê°€ ë–¨ì–´ì§‘ë‹ˆë‹¤.  **ì¸ì§€ ì§€ë„ ìƒì„±**ì€ MLLMì˜ **ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥**ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. íŠ¹íˆ, ê±°ë¦¬ ì¶”ì •ê³¼ ê°™ì€ ê³¼ì œì—ì„œ **ì¸ì§€ ì§€ë„ í™œìš©**ì€ ì„±ëŠ¥ ê°œì„ ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ì´ëŠ” MLLMì´ ê³µê°„ì  ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì— ëŒ€í•œ ì¤‘ìš”í•œ í†µì°°ë ¥ì„ ì œê³µí•˜ë©°, **ë³´ë‹¤ ì •êµí•œ ê³µê°„ì  ì´í•´ ëŠ¥ë ¥**ì„ ê°–ì¶˜ ëª¨ë¸ ê°œë°œì„ ìœ„í•œ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

#### Future Work
ë³¸ ë…¼ë¬¸ì˜ "ë¯¸ë˜ ì—°êµ¬" ë¶€ë¶„ì€ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ í–¥ìƒì„ ìœ„í•œ **ë‹¤ì–‘í•œ ë°©í–¥**ì„ ì œì‹œí•©ë‹ˆë‹¤.  **MLLMì˜ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ**ì„ ìœ„í•´ íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ íŒŒì¸íŠœë‹, ìê¸° ì§€ë„ í•™ìŠµ ê¸°ë²• ë„ì…, ê·¸ë¦¬ê³  ì‹œê°ì  ê³µê°„ ì¶”ë¡ ì— ë§ì¶¤í™”ëœ í”„ë¡¬í”„íŒ… ê¸°ë²• ê°œë°œ ë“±ì„ ì œì•ˆí•©ë‹ˆë‹¤.  ë˜í•œ, **ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í™œìš©í•œ MLLMì˜ ê³µê°„ ì´í•´ ëŠ¥ë ¥**ì— ëŒ€í•œ ì‹¬ì¸µ ì—°êµ¬ë¥¼ í†µí•´, **ì§€ë„ í•™ìŠµê³¼ ë¹„ì§€ë„ í•™ìŠµì˜ ê°•ì ì„ ê²°í•©**í•œ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµì„ ëª¨ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.  **ê³µê°„ì  ì¶”ë¡  ê³¼ì •ì˜ íˆ¬ëª…ì„±ì„ ë†’ì´ëŠ” ë°©ë²•**ë„ ì¤‘ìš”í•œ ì—°êµ¬ ê³¼ì œì…ë‹ˆë‹¤.  **ì‹¤ì œ ë¡œë´‡ê³¼ì˜ ìƒí˜¸ ì‘ìš©**ì„ í†µí•´ MLLMì˜ ê³µê°„ ì§€ëŠ¥ì„ í‰ê°€í•˜ê³  ë°œì „ì‹œí‚¤ëŠ” ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.  ê¶ê·¹ì ìœ¼ë¡œ, **ì¸ê°„ ìˆ˜ì¤€ì˜ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ì„ ê°€ì§„ MLLM**ì„ ê°œë°œí•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ ì§€ì†ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2412.14171/x6.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” ì‹œê°-ê³µê°„ ì§€ëŠ¥ ëŠ¥ë ¥ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹œê°ì  ì§€ê°, ê³µê°„ ì¶”ë¡ , ì‹œê°„ì  ì²˜ë¦¬, ì–¸ì–´ì  ì§€ëŠ¥ì˜ ë„¤ ê°€ì§€ ì£¼ìš” ì˜ì—­ì´ ìˆìŠµë‹ˆë‹¤.  ê³µê°„ ì¶”ë¡ ì€ ê´€ê³„ì  ì¶”ë¡ ê³¼ ìê¸°ì¤‘ì‹¬-íƒ€ì¤‘ì‹¬ ë³€í™˜ì´ë¼ëŠ” ë‘ ê°€ì§€ ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ê´€ê³„ì  ì¶”ë¡ ì€ ê±°ë¦¬ì™€ ë°©í–¥ì„ í†µí•´ ê°ì²´ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë˜í•œ, í¬ê¸°, ê±°ë¦¬ ë“±ì˜ ì‹œê°ì  ìƒì‹ì— ê¸°ë°˜í•˜ì—¬ ê°ì²´ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ì¶”ë¡ í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ìê¸°ì¤‘ì‹¬-íƒ€ì¤‘ì‹¬ ë³€í™˜ì€ ìê¸°ì¤‘ì‹¬ì  ê´€ì (ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ê´€ì )ê³¼ íƒ€ì¤‘ì‹¬ì  ê´€ì (í™˜ê²½ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ê´€ì )ì„ ì „í™˜í•˜ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤.  ì´ëŸ¬í•œ ì „í™˜ì€ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê³µê°„ì„ ì´í•´í•˜ê³  ìƒˆë¡œìš´ ê´€ì ì„ ì‹œê°í™”í•˜ê³ , ê²½ë¡œ ê³„íšê³¼ ê°™ì€ ì‘ì—…ì— í•„ìˆ˜ì ì¸ ê³µê°„ì  ì •ì‹  ì§€ë„ë¥¼ ë§Œë“œëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.  ì‹œê°ì  ì‘ì—… ê¸°ì–µì€ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë‚˜íƒ€ë‚´ë©°, ì›ê·¼ ì‹œê°í™”ëŠ” ê°ì²´ì˜ ìœ„ì¹˜ì™€ ë°©í–¥ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë˜í•œ, ì‹œê°-ê³µê°„ ì§€ëŠ¥ì€ ê±°ë¦¬, ë°©í–¥, ì‹œê°ì  ê³µê°„ ìƒì‹ê³¼ ê°™ì€ ì‹œê°ì  ê³µê°„ ìƒì‹ì— ëŒ€í•œ ì´í•´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: A taxonomy of visual-spatial intelligence capabilities.
> </details>



![](https://arxiv.org/html/2412.14171/x7.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ VSI-Benchì˜ 8ê°€ì§€ ê³¼ì œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ê³¼ì œëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‹œê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, 'ë¬¼ì²´ ê°œìˆ˜ ì„¸ê¸°'ëŠ” ê³µê°„ ë‚´ ë¬¼ì²´ì˜ ìˆ˜ë¥¼ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì„, 'ìƒëŒ€ ê±°ë¦¬ ì¸¡ì •'ì€ ë¬¼ì²´ ê°„ì˜ ìƒëŒ€ì  ê±°ë¦¬ë¥¼ ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥ì„, 'ìƒëŒ€ ë°©í–¥ íŒŒì•…'ì€ ë¬¼ì²´ì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì„, 'ì™¸ê´€ ìˆœì„œ'ëŠ” ì‹œê°„ì  ìˆœì„œì— ë”°ë¥¸ ë¬¼ì²´ì˜ ì¶œí˜„ ìˆœì„œë¥¼ ê¸°ì–µí•˜ëŠ” ëŠ¥ë ¥ì„, 'ìƒëŒ€ì  ë°©í–¥'ì€ ì£¼ì–´ì§„ ìœ„ì¹˜ì—ì„œ ë‹¤ë¥¸ ë¬¼ì²´ì˜ ë°©í–¥ì„ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì„, 'ì ˆëŒ€ ê±°ë¦¬ ì¸¡ì •'ì€ ë¬¼ì²´ ê°„ì˜ ì ˆëŒ€ì  ê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ëŠ” ëŠ¥ë ¥ì„, 'ë°© í¬ê¸°'ëŠ” ë°©ì˜ í¬ê¸°ë¥¼ ì¶”ì •í•˜ëŠ” ëŠ¥ë ¥ì„, 'ê²½ë¡œ ê³„íš'ì€ ì£¼ì–´ì§„ í™˜ê²½ì—ì„œ ëª©í‘œ ìœ„ì¹˜ê¹Œì§€ì˜ ê²½ë¡œë¥¼ ê³„íší•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.  ê° ê³¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì€ ëª…í™•ì„±ê³¼ ê°„ê²°ì„±ì„ ìœ„í•´ ì•½ê°„ ê°„ëµí™”ë˜ì—ˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Tasks demonstration of VSI-Bench. Note: the questions above are simplified slightly for clarity and brevity.
> </details>



![](https://arxiv.org/html/2412.14171/x8.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” VSI-Bench ë°ì´í„°ì…‹ ì œì‘ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ë“¤ì„ í‘œì¤€í™”ëœ í˜•ì‹ê³¼ ì˜ë¯¸ ê³µê°„ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì¼ê´€ëœ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.  QA ìŒì€ ì‚¬ëŒì˜ ì£¼ì„ê³¼ ì§ˆë¬¸ í…œí”Œë¦¿ì„ í†µí•´ ìƒì„±ë©ë‹ˆë‹¤. í’ˆì§ˆì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì €í’ˆì§ˆ ë¹„ë””ì˜¤, ì£¼ì„ ë° ëª¨í˜¸í•œ QA ìŒì„ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•´ ëª¨ë“  ë‹¨ê³„ì—ì„œ ì‚¬ëŒì˜ ê²€ì¦ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Benchmark curation pipeline. The pipeline first unifies diverse datasets into a standardized format and semantic space for consistent processing. QA pairs are then generated through both human annotation and question templates. To ensure quality, human verification is implemented at all key stages for filtering low-quality videos, annotations, and ambiguous QA pairs.
> </details>



![](https://arxiv.org/html/2412.14171/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” VSI-Bench ë°ì´í„°ì…‹ì˜ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ìœ„ìª½ ê·¸ë˜í”„ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ë²”ì£¼(êµ¬ì„±, ì¸¡ì •, ì‹œê³µê°„)ì— ê±¸ì³ ì‘ì—…ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ëŠ” ë§‰ëŒ€ ê·¸ë˜í”„ì…ë‹ˆë‹¤. ê° ë²”ì£¼ ë‚´ì—ëŠ” ì—¬ëŸ¬ í•˜ìœ„ ì‘ì—…ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ê° í•˜ìœ„ ì‘ì—…ì˜ ë°ì´í„°ì…‹ ë‚´ ë¹„ìœ¨ì´ í‘œì‹œë©ë‹ˆë‹¤. ì•„ë˜ìª½ ê·¸ë˜í”„ëŠ” ê° ë°ì´í„°ì…‹(ScanNet, ScanNet++, ARKitScenes)ì— ë”°ë¥¸ ë¹„ë””ì˜¤ ê¸¸ì´ ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” íˆìŠ¤í† ê·¸ë¨ì…ë‹ˆë‹¤. ì´ íˆìŠ¤í† ê·¸ë¨ì„ í†µí•´ ê° ë°ì´í„°ì…‹ì˜ ë¹„ë””ì˜¤ ê¸¸ì´ ë¶„í¬ íŠ¹ì§•ì„ íŒŒì•…í•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„°ì…‹ì˜ ë‹¤ì–‘ì„±ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Benchmark Statistics. Top: The distribution of tasks across three main categories. Bottom: The video length statistic.
> </details>



![](https://arxiv.org/html/2412.14171/x11.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ VSI-Benchì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì™¼ìª½ ê·¸ë˜í”„ëŠ” ëª¨ë“  ëª¨ë¸ ì¤‘ ìµœê³  ì„±ëŠ¥ì„ ì–´ë‘ìš´ íšŒìƒ‰ìœ¼ë¡œ, ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì¤‘ ìµœê³  ì„±ëŠ¥ì„ ë°ì€ íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. â€ ëŠ” ì¶•ì†Œëœ VSI-Bench(tiny) ë°ì´í„°ì…‹ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ëŠ” ìƒìœ„ 3ê°œì˜ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì„ í¬í•¨í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê³¼ì œì— ëŒ€í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•˜ì—¬ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ì˜ ê°•ì ê³¼ ì•½ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Evaluation on VSI-Bench. Left: Dark gray indicates the best result among all models and light gray indicates the best result among open-source models. â€  indicates results on VSI-Bench (tiny) set. Right: Results including the top-3 open-source models.
> </details>



![](https://arxiv.org/html/2412.14171/x12.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ ë¹„ì „ í™œì„±í™”(ë¹„ë””ì˜¤ í¬í•¨), ë¹„ì „ ë¹„í™œì„±í™”(ë¹„ë””ì˜¤ ì—†ìŒ), ê·¸ë¦¬ê³  ìš°ì—° ìˆ˜ì¤€(ë¹ˆë„) ê°„ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. í™œì„±í™”-ë¹„í™œì„±í™”ëŠ” ë¹„ì „ í™œì„±í™”ì™€ ë¹„ì „ ë¹„í™œì„±í™” ê°„ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ê³ , ë¹„í™œì„±í™”-ìš°ì—°ì€ ë¹„ì „ ë¹„í™œì„±í™”ì™€ ìš°ì—° ìˆ˜ì¤€(ë¹ˆë„) ê°„ì˜ ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê³¼ì œëŠ” í™œì„±í™”-ë¹„í™œì„±í™”ì— ë”°ë¼ ì •ë ¬ë˜ì–´ ì´í•´ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ê³¼ì œì—ì„œ ë¹„ë””ì˜¤ ë°ì´í„°ì˜ ì¤‘ìš”ì„±ê³¼ ëª¨ë¸ì˜ í•œê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Performance comparisons between Vision Enabled (w/ video), Vision Disabled (w/o video) and Chance Level (Freq.). Enabledâˆ’--Disabled indicates the gap between Vision Enabled and Vision Disabled, and Disabledâˆ’--Chance betokens the gap between Vision Disabled and Chance Level (Freq.). Tasks are sorted by Enableâˆ’--Disable for better understanding.
> </details>



![](https://arxiv.org/html/2412.14171/x13.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì´ ìì²´ ì„¤ëª…ì—ì„œ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. MLLMì€ ë¹„ë””ì˜¤ ì´í•´ ë° ì–¸ì–´ì  ì¶”ë¡  ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ì§€ë§Œ, ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ì€ ì•„ì§ ê°œë°œ ì¤‘ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¦‰, ê·¸ë¦¼ì€ MLLMì´ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì‚¬ê³  ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ìì²´ ì„¤ëª…ì˜ ì˜ˆì‹œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.  ê° ì˜ˆì‹œëŠ” ì‹œê°ì  ì •ë³´(ë¹„ë””ì˜¤)ì™€ ì–¸ì–´ì  ì •ë³´(ì§ˆë¬¸, ë‹µë³€, ì¶”ë¡  ê³¼ì •)ë¥¼ í•¨ê»˜ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ MLLMì˜ ì‚¬ê³  ê³¼ì •ì„ ìì„¸íˆ ë¶„ì„í•˜ê³ , ê°•ì ê³¼ ì•½ì ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. íŠ¹íˆ, MLLMì˜ ì‹œê°ì  ì •ë³´ ì²˜ë¦¬ ëŠ¥ë ¥ê³¼ ì–¸ì–´ì  ì¶”ë¡  ëŠ¥ë ¥ì€ ë›°ì–´ë‚˜ì§€ë§Œ, ê³µê°„ì ì¸ ê´€ê³„ë‚˜ ìœ„ì¹˜ë¥¼ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ì¶”ë¡ í•˜ëŠ” ë°ëŠ” ì–´ë ¤ì›€ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Examples of how a MLLM thinks as seen in self-explanations. While a MLLM exhibits strong video understanding and linguistic reasoning capabilities, its spatial reasoning capabilities are still developing.
> </details>



![](https://arxiv.org/html/2412.14171/x14.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‹¤ìˆ˜ì— ëŒ€í•œ ì¸ê°„ì´ ìˆ˜í–‰í•œ ë¶„ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê³¼ì œ ìœ í˜•ë³„ë¡œ ëª¨ë¸ì´ ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜¤ë¥˜ë¥¼ ë²”í–ˆëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë§‰ëŒ€ ê·¸ë˜í”„ì™€ ì› ê·¸ë˜í”„ê°€ í•¨ê»˜ ì œì‹œë©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ì— ë”°ë¥´ë©´, 70%ê°€ ë„˜ëŠ” ì˜¤ë¥˜ê°€ ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì˜ ê²°í•¨ì—ì„œ ë¹„ë¡¯ëœë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ëŠ” ëª¨ë¸ì´ ê³µê°„ì  ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì´ëŠ” ë‹¨ìˆœíˆ ê°œì²´ë¥¼ ì¸ì‹í•˜ëŠ” ê²ƒ ì´ìƒìœ¼ë¡œ ê³µê°„ì  ì‚¬ê³  ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: Human-conducted analysis of errors by type. Over 70% of errors stem from faulty spatial reasoning capabilities.
> </details>



![](https://arxiv.org/html/2412.14171/x15.png)

> ğŸ”¼ ê·¸ë¦¼ 10ì€ ì œì‹œëœ ë²¤ì¹˜ë§ˆí¬(VSI-Bench)ì—ì„œ ì„¸ ê°€ì§€ ì£¼ìš” ì–¸ì–´ì  í”„ë¡¬í”„íŒ… ê¸°ë²•(ì œë¡œìƒ· ì²´ì¸ ì˜¤ë¸Œ ìŠ¤ë ˆë“œ, ìê¸° ì¼ê´€ì„±, íŠ¸ë¦¬ ì˜¤ë¸Œ ìŠ¤ë ˆë“œ)ì˜ ì„±ëŠ¥ í–¥ìƒ ì •ë„ë¥¼ ê¸°ì¤€ ì„±ëŠ¥ê³¼ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ ê°€ì§€ ë°©ë²• ëª¨ë‘ í‰ê· ì ìœ¼ë¡œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì‹¤íŒ¨í–ˆìœ¼ë©°, ê²½ìš°ì— ë”°ë¼ ì ìš© í›„ ì‘ì—… ì„±ëŠ¥ì´ í›¨ì”¬ ì €í•˜ë˜ëŠ” ê²½ìš°ë„ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” VSI-Benchê°€ ë‹¨ìˆœíˆ ì–¸ì–´ì  ëŠ¥ë ¥ë§Œ í–¥ìƒì‹œì¼œì„œëŠ” í•´ê²°í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì¦‰, ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ì€ ì–¸ì–´ì  ì¶”ë¡ ë§Œìœ¼ë¡œëŠ” í•´ê²°ë  ìˆ˜ ì—†ìœ¼ë©°, ì‹œê°ì  ì •ë³´ ì²˜ë¦¬ ë° ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ì˜ í–¥ìƒ ë˜í•œ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: Relative improvements of CoT, self-consistency and Tree-of-Thought compared to the baseline. All three prevailing prompting techniques fail on average on our benchmark, and, in some cases, task performance becomes much worse after applying them. This implies that VSI-Bench cannot be solved by solely improving linguistic capabilities.
> </details>



![](https://arxiv.org/html/2412.14171/x16.png)

> ğŸ”¼ ê·¸ë¦¼ 11ì€ ë‹¤ì–‘í•œ ì‹¤ë‚´ í™˜ê²½ì— ëŒ€í•œ MLLM(ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ê³¼ GT(Ground Truth)ì˜ ì¸ì§€ ì§€ë„ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤.  ê° ì§€ë„ëŠ” ë°© ì•ˆì˜ ë¬¼ì²´ë“¤ì˜ ìœ„ì¹˜ë¥¼ 10x10 ê²©ì ì¢Œí‘œë¡œ í‘œí˜„í•˜ì—¬, MLLMì´ ì‹¤ì œ ê³µê°„ì„ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì´í•´í•˜ê³  ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  MLLMì˜ ì˜ˆì¸¡ ê²°ê³¼ëŠ” GTì™€ ë¹„êµí•˜ì—¬, MLLMì´ ê³µê°„ì  ê´€ê³„ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íŒŒì•…í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ì˜¤ì°¨ê°€ ë°œìƒí•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  íŠ¹íˆ, ê°€ê¹Œìš´ ë¬¼ì²´ë“¤ì˜ ìœ„ì¹˜ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, ë¨¼ ë¬¼ì²´ì¼ìˆ˜ë¡ ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” ê²½í–¥ì´ ê·¸ë¦¼ì—ì„œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: Visualization of cognitive maps from MLLM and GT.
> </details>



![](https://arxiv.org/html/2412.14171/x17.png)

> ğŸ”¼ ë³¸ ê·¸ë¦¼ì€ MLLMì´ ì˜ˆì¸¡í•œ ì¸ì§€ ì§€ë„ì—ì„œ ê±°ë¦¬ ì •í™•ë„ê°€ ê°ì²´ ê°„ì˜ ê±°ë¦¬ê°€ ì¦ê°€í•¨ì— ë”°ë¼ í¬ê²Œ ê°ì†Œí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, MLLMì€ ê°€ê¹Œìš´ ê°ì²´ë“¤ì˜ ìœ„ì¹˜ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ì§€ë§Œ, ë©€ë¦¬ ë–¨ì–´ì§„ ê°ì²´ë“¤ì˜ ìœ„ì¹˜ëŠ” ì •í™•ë„ê°€ ê¸‰ê²©íˆ ë–¨ì–´ì§ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” MLLMì´ ê³µê°„ì„ í‘œí˜„í•  ë•Œ, ì „ì²´ ê³µê°„ì— ëŒ€í•œ í•˜ë‚˜ì˜ í†µí•©ëœ ì§€ë„ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, êµ­ë¶€ì ì¸ ì˜ì—­ì— ëŒ€í•œ ì—¬ëŸ¬ ê°œì˜ ë¶€ë¶„ì ì¸ ì§€ë„ë¥¼ í˜•ì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 12: Locality of the MLLMâ€™s predicted cognitive maps. The MLLMâ€™s map-distance accuracy decreases dramatically with increasing object distance.
> </details>



![](https://arxiv.org/html/2412.14171/x18.png)

> ğŸ”¼ ê·¸ë¦¼ 13ì€ VSI-Benchì˜ ì§ˆë¬¸ ìœ í˜• ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ (ë¬¼ì²´ ê°œìˆ˜ ì„¸ê¸°, ìƒëŒ€ì  ê±°ë¦¬, ë°©í–¥, ì™¸í˜• ìˆœì„œ, í¬ê¸°, ì ˆëŒ€ì  ê±°ë¦¬, ë°© í¬ê¸°, ê²½ë¡œ ê³„íš) ì´ ì œì‹œë˜ë©° ê° ì§ˆë¬¸ ìœ í˜•ì— ëŒ€í•œ ì—¬ëŸ¬ê°€ì§€ ì˜ˆì‹œ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ê³µê°„ì  ì§€ê°, ê¸°ì–µ, ìƒê¸° ëŠ¥ë ¥ì„ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°ê°ì˜ ì˜ˆì‹œëŠ” ë‹¤ì–‘í•œ ì‹¤ë‚´ ê³µê°„ì„ ë³´ì—¬ì£¼ëŠ” ë¹„ë””ì˜¤ í´ë¦½ê³¼ ì—°ê´€ë˜ì–´ ìˆì–´, ëª¨ë¸ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 13: VSI-Bench Examples (Part 1).
> </details>



![](https://arxiv.org/html/2412.14171/x19.png)

> ğŸ”¼ ê·¸ë¦¼ 14ëŠ” VSI-Benchì˜ ì§ˆë¬¸ ìœ í˜• ì˜ˆì‹œ ì¤‘ ì¼ë¶€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì§ˆë¬¸ ìœ í˜•(ê°œì²´ ìˆ˜ ì„¸ê¸°, ìƒëŒ€ ê±°ë¦¬, ê°œì²´ í¬ê¸°, ë°© í¬ê¸°, ìƒëŒ€ ë°©í–¥, ê²½ë¡œ ê³„íš, ì™¸ê´€ ìˆœì„œ)ì— ëŒ€í•´ 2ê°œì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ë‹¤ì–‘í•œ ì‹œê°ì  ê³µê°„ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì˜ˆì‹œëŠ” ì§ˆë¬¸ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€, ì •ë‹µì„ í¬í•¨í•©ë‹ˆë‹¤.  ì´ ê·¸ë¦¼ì€ ë…¼ë¬¸ì˜ 3ì¥, VSI-Bench ë²¤ì¹˜ë§ˆí¬ ì†Œê°œ ë¶€ë¶„ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 14: VSI-Bench Examples (Part 2).
> </details>



![](https://arxiv.org/html/2412.14171/x20.png)

> ğŸ”¼ ê·¸ë¦¼ 15ëŠ” ëª¨ë¸ì˜ ì˜¤ë¥˜ ë¶„ì„ ì‚¬ë¡€ë“¤ì„ ì¶”ê°€ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹œê°ì  ì¸ì‹ ì˜¤ë¥˜, ì–¸ì–´ì  ì§€ëŠ¥ ì˜¤ë¥˜, ê´€ê³„ì  ì¶”ë¡  ì˜¤ë¥˜, ê·¸ë¦¬ê³  ìê¸° ì¤‘ì‹¬ì -íƒ€ì¤‘ì‹¬ì  ë³€í™˜ ì˜¤ë¥˜ ë“± ë„¤ ê°€ì§€ ì£¼ìš” ì˜¤ë¥˜ ìœ í˜•ì„ ë³´ì—¬ì£¼ëŠ” ë‹¤ì–‘í•œ ì§ˆë¬¸ê³¼ ë‹µë³€ ì˜ˆì‹œë“¤ì´ ì œì‹œë©ë‹ˆë‹¤. ê° ì˜¤ë¥˜ ìœ í˜•ì— ëŒ€í•œ ì„¤ëª…ê³¼ í•¨ê»˜, ëª¨ë¸ì´ ì–´ë–¤ ë¶€ë¶„ì—ì„œ ì˜¤ë¥˜ë¥¼ ë²”í–ˆëŠ”ì§€ì— ëŒ€í•œ ìì„¸í•œ ë¶„ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  íŠ¹íˆ, ëª¨ë¸ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ì‹œê°ì  ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  í•´ì„í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ìœ í˜•ì˜ ì¶”ë¡  ê³¼ì •ì„ ê±°ì¹˜ëŠ”ì§€ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 15: Additional Error Analysis Examples.
> </details>



![](https://arxiv.org/html/2412.14171/x21.png)

> ğŸ”¼ ê·¸ë¦¼ 16ì€ ì œë¡œìƒ· ì²´ì¸ ì˜¤ë¸Œ ìŠ¤ë ˆë“œ(Zero-Shot Chain of Thought) ê¸°ë²•ì„ ì‚¬ìš©í•œ ì§ˆì˜ì‘ë‹µ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ ê°€ì§€ ë‹¤ë¥¸ ìœ í˜•ì˜ ì§ˆë¬¸(ê°œì²´ ìˆ˜ ì„¸ê¸°, ê°œì²´ í¬ê¸°, ë°© í¬ê¸°)ì— ëŒ€í•œ ëª¨ë¸ì˜ ì‘ë‹µê³¼ ì¶”ë¡  ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì§ˆë¬¸ ìœ í˜•ì— ëŒ€í•´ ëª¨ë¸ì´ ì–´ë–»ê²Œ ì§ˆë¬¸ì„ ì´í•´í•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ìµœì¢… ë‹µë³€ì— ë„ë‹¬í•˜ëŠ”ì§€ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ í•œê³„ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 16: Zero-Shot CoT Examples.
> </details>



![](https://arxiv.org/html/2412.14171/x22.png)

> ğŸ”¼ ê·¸ë¦¼ 17ì€ 'Self-Consistency with Chain-of-Thought' í”„ë¡¬í”„íŒ… ê¸°ë²•ì„ ì‚¬ìš©í•œ ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ ê°€ì§€ ê³¼ì œ(ê°œì²´ ìˆ˜ ì„¸ê¸°, ê°œì²´ í¬ê¸° ì¶”ì •, ë°© í¬ê¸° ì¶”ì •)ì— ëŒ€í•´, ëª¨ë¸ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ë„ì¶œí•˜ëŠ” ë‹¤ì„¯ ê°€ì§€ ë‹¤ë¥¸ ì‹œë„ì˜ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì‹œë„ëŠ” ì¤‘ê°„ ë‹¨ê³„ì˜ ì¶”ë¡  ê³¼ì •ê³¼ ìµœì¢… ë‹µë³€ì„ í¬í•¨í•˜ë©°, ê° ê³¼ì œì— ëŒ€í•´ ë‹¤ìˆ˜ê²° íˆ¬í‘œë¡œ ìµœì¢… ë‹µë³€ì„ ê²°ì •í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì£¼ì–´ì§„ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´ë–»ê²Œ ì¶”ë¡ í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  Self-Consistency ê¸°ë²•ì´ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì ì¸ ì„¤ëª…ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 17: Self-Consistency w/ CoT Examples.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Case | Performance |
|---|---| 
| Gemini-1.5 Pro (w/o CoT) | 77.2 |
| Gemini-1.5 Pro (w/ CoT) | 79.8 |{{< /table-caption >}}
> ğŸ”¼ í‘œ (a)ëŠ” ì¸ì§€ ì§€ë„ í”„ë¡¬í”„íŒ…ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'Cog. Map Src'ëŠ” ì¸ì§€ ì§€ë„ ìƒì„±ì— ì‚¬ìš©ëœ ì†ŒìŠ¤(MLLM ë˜ëŠ” GT)ë¥¼ ë‚˜íƒ€ë‚´ê³ , 'Size'ëŠ” ì¸ì§€ ì§€ë„ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 'Rel. Dist Acc'ëŠ” ìƒëŒ€ ê±°ë¦¬ ì •í™•ë„ë¥¼ ì˜ë¯¸í•˜ë©°, ì¸ì§€ ì§€ë„ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì™€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ìƒëŒ€ ê±°ë¦¬ ì§ˆë¬¸ì— ëŒ€í•œ MLLMì˜ ì •í™•ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.  ê²°ê³¼ëŠ” ì¸ì§€ ì§€ë„ë¥¼ ì‚¬ìš©í•˜ë©´ MLLMì˜ ìƒëŒ€ ê±°ë¦¬ ì¶”ë¡  ëŠ¥ë ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Cognitive map prompting.
> </details>

{{< table-caption >}}
| Case | Rel. Dist Acc. |
|---|---| 
| w/o Cog. map | 46.0 |
| w/ Cog. map | 56.0 |
| w/ Cog. map (GT) | 66.0 |{{< /table-caption >}}
> ğŸ”¼ í‘œ (b)ëŠ” MLLMì´ ê³µê°„ì„ ê¸°ì–µí•˜ëŠ” ë°©ì‹ì„ ì¡°ì‚¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ ì¸ì§€ ì§€ë„ì˜ í¬ê¸°ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  10x10 í¬ê¸°ì˜ ê²©ìì™€ 20x20 í¬ê¸°ì˜ ê²©ìë¥¼ ë¹„êµí•˜ì—¬, MLLMì˜ ìƒëŒ€ì  ê±°ë¦¬ ì¶”ë¡  ì •í™•ë„ì— ëŒ€í•œ ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.  ì¦‰, MLLMì´ ê³µê°„ì„ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” ê²©ì í¬ê¸°ê°€ ë‹¤ë¥¼ ë•Œ ìƒëŒ€ì  ê±°ë¦¬ ì¸ì‹ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Cognitive map canvas size.
> </details>

{{< table-caption >}}
| Cog. Map Src. | Size | Rel. Dist Acc. |
|---|---|---|
| MLLM | 10 Ã— 10 | 56.0 |
| MLLM | 20 Ã— 20 | 54.0 |
| GT | 10 Ã— 10 | 66.0 |
| GT | 20 Ã— 20 | 78.0 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ëª¨ë¸ì´ ê³µê°„ì  ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” ë°©ì‹ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ 'ì¸ì§€ ì§€ë„' ì ‘ê·¼ë²•ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  íŠ¹íˆ, ì¸ì§€ ì§€ë„ë¥¼ í™œìš©í–ˆì„ ë•Œ ìƒëŒ€ì  ê±°ë¦¬ ì¶”ë¡  ê³¼ì œì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒ ì—¬ë¶€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'ì¸ì§€ ì§€ë„ ìƒì„±' í¬ê¸°(10x10 ë˜ëŠ” 20x20)ë¥¼ ë‹¬ë¦¬í•˜ì—¬ ì‹¤í—˜í•œ ê²°ê³¼ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ê¸°ì¤€ ëª¨ë¸(MLLM)ê³¼ ì¸ì§€ ì§€ë„ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ì¸ì§€ ì§€ë„ì˜ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Relative distance task with cognitive map.
> </details>

{{< table-caption >}}
| Task | Question Template |
|---|---| 
| Object Counting | How many {category}(s) are in this room? |
| Relative Distance | Measuring from the closest point of each object, which of these objects ({choice a}, {choice b}, {choice c}, {choice d}) is the closest to the {category}? |
| Relative Direction | To create a comprehensive test of relative direction, three difficulty levels were created:
* **Easy:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to the left or the right of the {orienting object}? 
* **Medium:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to my left, right, or back? An object is to my back if I would have to turn at least 135 degrees in order to face it. 
* **Hard:** If I am standing by the {positioning object} and facing the {orienting object}, is the {querying object} to my front-left, front-right, back-left, or back-right? Directions refer to the quadrants of a Cartesian plane (assuming I am at the origin and facing the positive y-axis). |
| Appearance Order | What will be the first-time appearance order of the following categories in the video: {choice a}, {choice b}, {choice c}, {choice d}? |
| Object Size | What is the length of the longest dimension (length, width, or height) of the {category}, measured in centimeters? |
| Absolute Distance | Measuring from the closest point of each object, what is the direct distance between the {object 1} and the {object 2} (in meters)? |
| Room Size | What is the size of this room (in square meters)? If multiple rooms are shown, estimate the size of the combined space. |
| Route Plan | You are a robot beginning at {the bed facing the tv}. You want to navigate to {the toilet}. You will perform the following actions (Note: for each [please fill in], choose either â€˜turn back,â€™ â€˜turn left,â€™ or â€˜turn right.â€™): {1. Go forward until the TV 2. [please fill in] 3. Go forward until the shower 4. [please fill in] 5. Go forward until the toilet.}. You have reached the final destination.|{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” VSI-Bench(Video-based Spatial Intelligence Benchmark)ì˜ ê° ê³¼ì œì— ëŒ€í•œ ì§ˆë¬¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  VSI-BenchëŠ” ë‹¤ì–‘í•œ ì‹¤ë‚´ í™˜ê²½ì˜ ë¹„ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. í‘œì—ëŠ” ê°œì²´ ê³„ìˆ˜, ìƒëŒ€ ê±°ë¦¬, ìƒëŒ€ ë°©í–¥, ê²½ë¡œ ê³„íš, ì™¸í˜• ìˆœì„œ, ê°œì²´ í¬ê¸°, ì ˆëŒ€ ê±°ë¦¬, ë°© í¬ê¸° ë“± 8ê°€ì§€ ê³¼ì œì— ëŒ€í•œ ì§ˆë¬¸ í…œí”Œë¦¿ì´ ë‚˜ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° í…œí”Œë¦¿ì—ëŠ” íŠ¹ì • ìš”ì†Œ(ì˜ˆ: ê°œì²´ ë²”ì£¼, ì„ íƒì§€)ë¥¼ í•´ë‹¹ ì¥ë©´ì— ë§ê²Œ ë°”ê¿”ì„œ ì‚¬ìš©í•˜ë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²½ë¡œ ê³„íš ê³¼ì œì˜ ê²½ìš° ì™„ë²½í•œ ì˜ˆì‹œ ì§ˆë¬¸ì´ ì œê³µë©ë‹ˆë‹¤. ì´ í‘œëŠ” VSI-Bench ë°ì´í„°ì…‹ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ê³¼ MLLM í‰ê°€ ë°©ì‹ì— ëŒ€í•œ ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Question Templates for tasks in VSI-Bench. We replace the highlighted part in the question template from scene to scene to construct our benchmark. Note that a complete example question is provided for Route Plan.
> </details>

{{< table-caption >}}
| Order | Avg. |
|---|---| 
| Video first | **48.8** |
| Question first | 46.3 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë¹„ë””ì˜¤ ì…ë ¥ ìˆœì„œì™€ ë°˜ë³µì— ë”°ë¥¸ ë¹„êµ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. (a) ë¹„ë””ì˜¤ ì…ë ¥ ìˆœì„œëŠ” ë¹„ë””ì˜¤ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹ê³¼ ì§ˆë¬¸ì„ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹ì„ ë¹„êµí•©ë‹ˆë‹¤. (b) ë¹„ë””ì˜¤ ë°˜ë³µ íšŸìˆ˜ëŠ” ë¹„ë””ì˜¤ë¥¼ í•œ ë²ˆ ë³´ì—¬ì£¼ëŠ” ê²ƒê³¼ ë‘ ë²ˆ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ë¹„êµí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ë¹„ë””ì˜¤ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹ì´ ì§ˆë¬¸ì„ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹ë³´ë‹¤ í‰ê·  ì •í™•ë„ê°€ ì•½ 2.5% ë†’ì•˜ê³ , ë¹„ë””ì˜¤ë¥¼ ë‘ ë²ˆ ë³´ì—¬ì£¼ëŠ” ë°©ì‹ì´ í•œ ë²ˆ ë³´ì—¬ì£¼ëŠ” ë°©ì‹ë³´ë‹¤ í‰ê·  ì •í™•ë„ê°€ ì•½ 2.1% ë†’ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ëŒì´ ì‹œê°ì  ì •ë³´ë¥¼ ì—¬ëŸ¬ ë²ˆ ê²€í† í•˜ì—¬ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ê²°ê³¼ëŠ” MLLMì´ ë¹„ë””ì˜¤ ì´í•´ì— ìˆì–´ ë‹¨ìˆœíˆ ì‹œê°ì  ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê²ƒì„ ë„˜ì–´,  ë°˜ë³µì ì¸ ê²€í† ë¥¼ í†µí•´  ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Input Sequence
> </details>

{{< table-caption >}}
| # Times | Avg. |
|---|---| 
| 1 | 48.8 |
| 2 | **50.9** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5(b)ëŠ” ë¹„ë””ì˜¤ ë°˜ë³µ íšŸìˆ˜ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë¹„ë””ì˜¤ë¥¼ í•œ ë²ˆë§Œ ë³´ì—¬ì£¼ì—ˆì„ ë•Œì™€ ë‘ ë²ˆ ë³´ì—¬ì£¼ì—ˆì„ ë•Œì˜ Gemini-1.5 Pro ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬, ë¹„ë””ì˜¤ë¥¼ ë°˜ë³µí•´ì„œ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œëŠ”, í‰ê·  ì •í™•ë„ë¥¼ ë¹„êµí•˜ì—¬ ë¹„ë””ì˜¤ ë°˜ë³µì´ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ë¹„ë””ì˜¤ë¥¼ ì—¬ëŸ¬ ë²ˆ ë³´ì—¬ì£¼ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ìˆëŠ”ì§€,  ê·¸ë¦¬ê³  ê·¸ ì •ë„ëŠ” ì–´ëŠ ì •ë„ì¸ì§€ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Video Repetition Times
> </details>

{{< table-caption >}}
| Methods | # of Frames |
|---|---| 
| _Proprietary Models (API)_ |  |
| GPT-4o | 16 |
| Gemini-1.5 Flash | - |
| Gemini-1.5 Pro | - |
| _Open-source Models_ |  |
| InternVL2-2B | 8 |
| InternVL2-8B | 8 |
| InternVL2-40B | 8 |
| LongVILA-8B | 32 |
| VILA-1.5-8B | 32 |
| VILA-1.5-40B | 32 |
| LongVA-7B | 32 |
| LLaVA-NeXT-Video-7B | 32 |
| LLaVA-NeXT-Video-72B | 32 |
| LLaVA-OneVision-0.5B | 32 |
| LLaVA-OneVision-7B | 32 |
| LLaVA-OneVision-72B | 32 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ë¹„ë””ì˜¤ ì…ë ¥ ìˆœì„œ ë° ë°˜ë³µì— ëŒ€í•œ ì¶”ê°€ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë¨¼ì €, ë¹„ë””ì˜¤ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹(Video first)ê³¼ ì§ˆë¬¸ì„ ë¨¼ì € ë³´ì—¬ì£¼ëŠ” ë°©ì‹(Question first)ì„ ë¹„êµí•œ ê²°ê³¼, ë¹„ë””ì˜¤ ë¨¼ì € ë°©ì‹ì´ í‰ê·  2.5% ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì‹œê°ì  ì •ë³´ë¥¼ ë¨¼ì € ì œê³µí•˜ëŠ” ê²ƒì´ ëª¨ë¸ì˜ ì´í•´ë„ í–¥ìƒì— ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ë¹„ë””ì˜¤ ë°˜ë³µ íšŸìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ë¹„ë””ì˜¤ë¥¼ ë‘ ë²ˆ ë°˜ë³µí•´ì„œ ë³´ì—¬ì¤€ ê²½ìš° í‰ê·  2.1% ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë¹„ë””ì˜¤ë¥¼ ì—¬ëŸ¬ ë²ˆ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•˜ë©´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ê²°ê³¼ì…ë‹ˆë‹¤. ì¦‰,  ì‹œê° ì •ë³´ì˜ ìˆœì„œì™€ ë°˜ë³µ íšŸìˆ˜ê°€ ëª¨ë¸ì˜  ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì— ì˜í–¥ì„ ë¯¸ì¹¨ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Ablations on the video input sequence and repetition.
> </details>

{{< table-caption >}}
| Models | QA. Type | Prompt |
|---|---|---|
| Pre-Prompt | - | _These are frames of a video._ |
| Post-Prompt | Open-source Models | NA | _Please answer the question using a single word or phrase._ |
|  |  | MCA | _Answer with the optionâ€™s letter from the given choices directly._ |
| Post-Prompt | Proprietary Models | NA | _Do not respond with anything other than a single number!_ |
|  |  | MCA | _Answer with the optionâ€™s letter from the given choices directly._ |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ í‰ê°€ì— ì‚¬ìš©ëœ ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ëª¨ë¸ì— ëŒ€í•´ ë¹„ë””ì˜¤ì˜ ì „ì²´ í”„ë ˆì„ ìˆ˜ê°€ ì•„ë‹ˆë¼,  ì‹¤ì œ í‰ê°€ì— ì‚¬ìš©ëœ í”„ë ˆì„ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ì— ì‚¬ìš©ëœ ë¹„ë””ì˜¤ ë°ì´í„°ì˜ ì–‘ì  ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ëŠ” ì •ë³´ì…ë‹ˆë‹¤.  íŠ¹íˆ,  ì¼ë¶€ ëª¨ë¸ì˜ ê²½ìš° ë¹„ë””ì˜¤ ì „ì²´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¼ë¶€ë§Œ ì‚¬ìš©í–ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¹„ë””ì˜¤ í”„ë ˆì„ì˜ ìˆ˜ëŠ” ëª¨ë¸ì˜ ìœ í˜•ê³¼ ë§¤ê°œë³€ìˆ˜ í¬ê¸° ë“±ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.  ì´ í‘œëŠ” ëª¨ë¸ë³„ë¡œ ì‚¬ìš©ëœ ë¹„ë””ì˜¤ ë°ì´í„° ì–‘ì˜ ì°¨ì´ë¥¼ ê³ ë ¤í•´ì•¼ í•  í•„ìš”ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Number of frames used in evaluation.
> </details>

{{< table-caption >}}
| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |
|---|---|---|---|---|---|---|---|---|---| 
| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |
| GPT-4o | 35.6 | 36.2 | 4.6 | 47.2 | 40.4 | 40.0 | 46.2 | 32.0 | 38.0 |
| Gemini-1.5 Flash | 45.7 | 50.8 | 33.6 | 56.5 | 45.2 | 48.0 | 39.8 | 32.7 | 59.2 |
| Gemini-1.5 Pro | 48.8 | 49.6 | 28.8 | 58.6 | 49.4 | 46.0 | 48.1 | 42.0 | 68.0 |
| Gemini-2.0 Flash | 45.4 | 52.4 | 30.6 | 66.7 | 31.8 | 56.0 | 46.3 | 24.5 | 55.1 |
| Open-source Models |  |  |  |  |  |  |  |  |  |
| InternVL2-2B | 25.5 | 30.6 | 20.4 | 26.0 | 29.6 | 28.0 | 39.2 | 28.0 | 2.0 |
| InternVL2-8B | 32.9 | 26.4 | 25.4 | 43.8 | 41.6 | 30.0 | 32.2 | 20.0 | 44.0 |
| InternVL2-40B | 37.6 | 40.8 | 23.8 | 48.0 | 26.0 | 46.0 | 30.1 | 42.0 | 44.0 |
| LongVILA-8B | 19.1 | 23.4 | 10.8 | 11.4 | 0.0 | 20.0 | 33.1 | 28.0 | 26.0 |
| VILA-1.5-8B | 31.4 | 12.2 | 23.4 | 51.4 | 18.6 | 36.0 | 41.5 | 42.0 | 26.0 |
| VILA-1.5-40B | 32.3 | 14.6 | 21.0 | 48.0 | 20.6 | 42.0 | 22.0 | 40.0 | 50.0 |
| LongVA-7B | 31.8 | 41.2 | 17.4 | 39.6 | 25.4 | 30.0 | 52.8 | 34.0 | 14.0 |
| LLaVA-NeXT-Video-7B | 35.7 | 49.0 | 12.8 | 48.6 | 21.4 | 40.0 | 43.5 | 34.0 | 36.0 |
| LLaVA-NeXT-Video-72B | 39.3 | 41.4 | 26.6 | 55.6 | 31.6 | 36.0 | 25.6 | 42.0 | 56.0 |
| LLaVA-OneVision-0.5B | 27.7 | 44.0 | 23.0 | 18.8 | 28.4 | 30.0 | 33.4 | 36.0 | 8.0 |
| LLaVA-OneVision-7B | 33.8 | 48.2 | 22.0 | 44.4 | 14.0 | 44.0 | 31.9 | 34.0 | 32.0 |
| LLaVA-OneVision-72B | 41.6 | 38.0 | 31.6 | 54.4 | 35.2 | 44.0 | 39.7 | 32.0 | 58.0 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ì—ì„œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ëª¨ë¸(ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ê³¼ ë…ì  ëª¨ë¸)ê³¼ ì§ˆë¬¸ ìœ í˜•(ìˆ˜ì¹˜í˜• ë‹µë³€, ë‹¤ì¤‘ ì„ íƒí˜• ë‹µë³€)ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ê°€ ì‚¬ìš©ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì¹˜í˜• ë‹µë³€ì˜ ê²½ìš° ìˆ«ìë§Œìœ¼ë¡œ ë‹µë³€í•˜ë„ë¡ ì§€ì‹œí•˜ê³ , ë‹¤ì¤‘ ì„ íƒí˜• ë‹µë³€ì˜ ê²½ìš° ì œì‹œëœ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ì˜ ë¬¸ìë¥¼ ë‹µìœ¼ë¡œ ì œì¶œí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ì‘ë‹µ í˜•ì‹ì„ ì¼ê´€ì„± ìˆê²Œ ìœ ì§€í•˜ê³ , ê²°ê³¼ ë¶„ì„ì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Prompts used in evaluation. NA and MAC indicates questions with Numerical Answer and Multiple Choice Answer respectively.
> </details>

{{< table-caption >}}
| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |
|---|---|---|---|---|---|---|---|---|---| 
| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |
| GPT-4o | 14.5 | 0.1 | 5.2 | 36.7 | 0.0 | 10.8 | 23.2 | 26.9 | 13.1 |
| Gemini-1.5 Flash | 19.9 | 25.0 | 30.3 | 52.5 | 0.0 | 0.0 | 21.2 | 29.9 | 0.2 |
| Gemini-1.5 Pro | 32.3 | 30.6 | 11.5 | 51.5 | 33.1 | 33.8 | 44.6 | 33.5 | 20.2 |
| Open-source Models |  |  |  |  |  |  |  |  |  |
| InternVL2-2B | 17.8 | 5.4 | 23.7 | 9.2 | 0.0 | 26.9 | 41.2 | 27.9 | 7.9 |
| InternVL2-8B | 27.6 | 31.9 | 26.8 | 38.3 | 0.7 | 27.1 | 39.2 | 33.0 | 23.6 |
| InternVL2-40B | 24.4 | 5.4 | 29.1 | 39.2 | 0.7 | 30.3 | 37.7 | 27.9 | 24.7 |
| LongVILA-8B | 20.2 | 47.4 | 12.6 | 8.7 | 0.6 | 24.3 | 27.0 | 27.4 | 13.9 |
| VILA-1.5-8B | 21.5 | 7.4 | 7.6 | 45.7 | 0.0 | 25.4 | 39.1 | 29.4 | 17.6 |
| VILA-1.5-40B | 25.5 | 5.3 | 27.6 | 46.5 | 0.7 | 30.2 | 37.1 | 31.5 | 25.0 |
| LongVA-7B | 21.9 | 5.1 | 18.1 | 27.4 | 26.1 | 23.4 | 39.8 | 26.9 | 8.7 |
| LLaVA-NeXT-Video-7B | 25.2 | 14.8 | 14.6 | 32.5 | 26.1 | 26.8 | 45.0 | 33.0 | 8.5 |
| LLaVA-NeXT-Video-72B | 29.1 | 19.0 | 25.4 | 46.3 | 26.1 | 29.0 | 38.8 | 33.0 | 15.5 |
| LLaVA-OneVision-0.5B | 28.6 | 38.4 | 30.1 | 32.0 | 24.3 | 22.0 | 41.8 | 34.5 | 5.4 |
| LLaVA-OneVision-7B | 25.3 | 13.8 | 8.5 | 45.5 | 26.1 | 28.6 | 41.2 | 27.9 | 11.1 |
| LLaVA-OneVision-72B | 28.9 | 8.2 | 23.8 | 54.1 | 26.1 | 30.4 | 38.1 | 33.0 | 17.1 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ VSI-Bench (tiny) ë°ì´í„°ì…‹ì— ëŒ€í•œ 15ê°€ì§€ ë‹¤ì–‘í•œ ë¹„ë””ì˜¤ ì§€ì› ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í‘œì—ëŠ” ê° ëª¨ë¸ì˜ í‰ê·  ì •í™•ë„ì™€ í•¨ê»˜, ê°œì²´ ìˆ˜ ì„¸ê¸°, ìƒëŒ€ ê±°ë¦¬, ê°œì²´ í¬ê¸°, ë°© í¬ê¸°, ìƒëŒ€ ë°©í–¥, ê²½ë¡œ ê³„íš, ì™¸ê´€ ìˆœì„œ ë“± 8ê°€ì§€ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ì‘ì—…ì— ëŒ€í•œ ì„¸ë¶€ ì •í™•ë„ ì ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ í‘œëŠ” ë‹¤ì–‘í•œ MLLMì˜ ì‹œê°ì  ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ ë¹„êµí•˜ê³ , ê°•ì ê³¼ ì•½ì ì„ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Complete VSI-Bench (tiny) evaluation results.
> </details>

{{< table-caption >}}
| Methods | Avg. | Obj. Count | Abs. Dist. | Obj. Size | Room Size | Rel. Dist. | Rel. Dir. | Route Plan | Appr. Order |
|---|---|---|---|---|---|---|---|---|---| 
| Proprietary Models (API) |  |  |  |  |  |  |  |  |  |
| GPT-4o | 19.5 | 46.1 | 0.1 | 7.1 | 38.2 | 26.2 | 18.0 | 4.6 | 15.4 |
| Gemini-1.5 Flash | 22.2 | 24.9 | 0.5 | 1.0 | 54.4 | 37.7 | 19.9 | 1.5 | 37.7 |
| Gemini-1.5 Pro | 13.0 | 25.5 | 19.5 | 12.6 | 10.6 | 17.5 | 1.7 | 2.5 | 14.4 |
| Open-source Models |  |  |  |  |  |  |  |  |  |
| InternVL2-2B | 9.6 | 16.4 | 1.2 | 12.8 | 35.0 | 6.9 | 3.0 | 2.5 | -0.8 |
| InternVL2-8B | 7.0 | -8.8 | 1.9 | 9.9 | 39.1 | 9.7 | -8.5 | -3.0 | 16.0 |
| InternVL2-40B | 11.6 | 29.6 | -2.2 | 7.3 | 31.1 | 11.8 | -5.5 | 6.1 | 14.9 |
| LongVILA-8B | 1.4 | -18.2 | -3.5 | 7.9 | -0.6 | 5.3 | 3.7 | 5.1 | 11.5 |
| VILA-1.5-8B | 7.3 | 10.0 | 14.2 | 4.6 | 18.8 | 6.7 | -4.4 | 1.5 | 7.2 |
| VILA-1.5-40B | 5.7 | 17.1 | -2.8 | 2.2 | 22.0 | 10.4 | -11.4 | 0.0 | 7.9 |
| LongVA-7B | 7.2 | 32.9 | -1.5 | 11.5 | -3.9 | 9.7 | 3.5 | -1.5 | 7.1 |
| LLaVA-NeXT-Video-7B | 10.5 | 33.8 | -0.6 | 15.2 | -1.9 | 16.7 | -2.7 | 1.0 | 22.1 |
| LLaVA-NeXT-Video-72B | 11.7 | 29.9 | -2.6 | 11.1 | 9.2 | 13.3 | -2.0 | 2.0 | 33.0 |
| LLaVA-OneVision-0.5B | -0.5 | 7.8 | -1.7 | -16.6 | 4.0 | 6.9 | -5.0 | 0.0 | 0.3 |
| LLaVA-OneVision-7B | 7.0 | 33.9 | 11.7 | 1.9 | -13.9 | 13.9 | -6.0 | 1.5 | 13.3 |
| LLaVA-OneVision-72B | 11.4 | 35.4 | 0.1 | 3.5 | 11.4 | 12.1 | 1.8 | -0.5 | 27.4 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ ë¹„ì „ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ (ì¦‰, ë¹„ì „ì´ ë¹„í™œì„±í™”ëœ ìƒíƒœì—ì„œ) ë‹¤ì–‘í•œ ëª¨ë¸ì´ VSI-Bench(tiny) ë°ì´í„°ì…‹ì—ì„œ ë‹¬ì„±í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ëª¨ë¸ì˜ í‰ê·  ì •í™•ë„ì™€ ê° ì‘ì—…(ê°œì²´ ìˆ˜ ì„¸ê¸°, ì ˆëŒ€ ê±°ë¦¬, ê°œì²´ í¬ê¸°, ë°© í¬ê¸°, ìƒëŒ€ ê±°ë¦¬, ìƒëŒ€ ë°©í–¥, ê²½ë¡œ ê³„íš, ì™¸ê´€ ìˆœì„œ)ì— ëŒ€í•œ ì„¸ë¶€ ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ì–´ ëª¨ë¸ì˜ ì‹œê°ì  ê³µê°„ ì§€ëŠ¥ ëŠ¥ë ¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  íŠ¹íˆ, ë‹¤ì–‘í•œ ëª¨ë¸ ìœ í˜•ê³¼ í¬ê¸°(ë§¤ê°œë³€ìˆ˜ ìˆ˜) ê°„ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ íŒŒì•…í•˜ê³ , ê°œë°©í˜• ëª¨ë¸ê³¼ ë…ì  ëª¨ë¸ ê°„ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Complete blind evaluation results.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}