[{"figure_path": "https://arxiv.org/html/2501.05707/x1.png", "caption": "Figure 1: Multiagent finetuning improves reasoning performance over multiple rounds of finetuning.\nOur multiagent finetuning procedure enables models to improve across multiple iterations of finetuing. Results reported on the MATH dataset.", "description": "\uadf8\ub9bc 1\uc740 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\uc774 \uc5ec\ub7ec \ubc88\uc758 \ubbf8\uc138 \uc870\uc815\uc744 \uac70\uce58\uba74\uc11c \ucd94\ub860 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815 \uc808\ucc28\ub294 \uc5ec\ub7ec \ubc88\uc758 \ubbf8\uc138 \uc870\uc815 \uacfc\uc815\uc5d0\uc11c\ub3c4 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 MATH \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8\ub294 \uc11c\ub85c \ub2e4\ub978 \ucd94\ub860 \uacbd\ub85c\ub97c \ud1b5\ud574 \uc0c1\ud638 \uc791\uc6a9\ud558\uc5ec \ubaa8\ub378\uc758 \uc804\ubc18\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uacfc \ub2e4\uc591\ud55c \ucd94\ub860 \ub2a5\ub825\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uac01 \uc5d0\uc774\uc804\ud2b8\ub294 \ub3c5\ub9bd\uc801\uc73c\ub85c \ub370\uc774\ud130\ub97c \uc5c5\ub370\uc774\ud2b8\ud558\uace0, \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378 \uac04\uc758 \uc804\ubb38\ud654 \ubc0f \ub2e4\uc591\uc131\uc774 \ud5a5\uc0c1\ub418\uc5b4, \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\ubcf4\ub2e4 \ub354 \ub9ce\uc740 \ubbf8\uc138 \uc870\uc815 \ub77c\uc6b4\ub4dc\ub97c \uac70\uccd0\ub3c4 \uc9c0\uc18d\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc774\ub8f0 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05707/x2.png", "caption": "Figure 2: Overview of Multiagent Finetuning.We first use multiagent debate and majority voting to create the finetuning datasets (left). These datasets are then used to finetune the generation and critic agents (right). When finetuning generation models, we use the majority voted result (\u201dcorrect\u201d output) to select first-round responses from each agent. We then finetune critic models using responses from the final round based on whether responses match the majority voted result (mix of \u201dcorrect and incorrect\u201d outputs). The finetuned models are combined through multiagent debate to generate more accurate answers. In this figure, we illustrate a single finetuning iteration. Applying multiple rounds of finetuning iterations can significantly boost performance.", "description": "\uadf8\ub9bc 2\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ud1a0\ub860\uacfc \ub2e4\uc218\uacb0 \ud22c\ud45c\ub97c \ud1b5\ud574 \ubbf8\uc138 \uc870\uc815 \ub370\uc774\ud130 \uc138\ud2b8\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4 (\uc67c\ucabd). \uc0dd\uc131\ub41c \ub370\uc774\ud130 \uc138\ud2b8\ub294 \uc0dd\uc131 \uc5d0\uc774\uc804\ud2b8\uc640 \ube44\ud3c9 \uc5d0\uc774\uc804\ud2b8\ub97c \ubbf8\uc138 \uc870\uc815\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4 (\uc624\ub978\ucabd). \uc0dd\uc131 \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud560 \ub54c\ub294 \ub2e4\uc218\uacb0 \uacb0\uacfc(\uc815\ub2f5 \ucd9c\ub825)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac01 \uc5d0\uc774\uc804\ud2b8\uc758 \uccab \ubc88\uc9f8 \ub77c\uc6b4\ub4dc \uc751\ub2f5\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ucd5c\uc885 \ub77c\uc6b4\ub4dc\uc758 \uc751\ub2f5\uc774 \ub2e4\uc218\uacb0 \uacb0\uacfc\uc640 \uc77c\uce58\ud558\ub294\uc9c0 \uc5ec\ubd80\ub97c \uae30\ubc18\uc73c\ub85c \ucd5c\uc885 \ub77c\uc6b4\ub4dc\uc758 \uc751\ub2f5\uc744 \uc0ac\uc6a9\ud558\uc5ec \ube44\ud3c9 \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud569\ub2c8\ub2e4 (\uc815\ub2f5\uacfc \uc624\ub2f5 \ud63c\ud569). \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc740 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ud1a0\ub860\uc744 \ud1b5\ud574 \uacb0\ud569\ub418\uc5b4 \ub354 \uc815\ud655\ud55c \ub2f5\ubcc0\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc5d0\uc11c\ub294 \ub2e8\uc77c \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\ub7ec \ub77c\uc6b4\ub4dc\uc758 \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5\uc744 \uc801\uc6a9\ud558\uba74 \uc131\ub2a5\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 MULTIAGENT FINETUNING OF LANGUAGE MODELS"}, {"figure_path": "https://arxiv.org/html/2501.05707/x3.png", "caption": "Figure 3: Diversity is preserved and can improve across iterations of finetuning. We measure the response diversity of our method and the single-agent finetuning method on the MATH dataset using two diversity measures. The diversity of our method remains consistent over finetuning iterations for one metric and improves for another metric, whereas the diversity of the single-agent method drops significantly.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub2e4\uc591\uc131 \uce21\uc815 \uc9c0\ud45c \ub450 \uac00\uc9c0(Likelihood, Embedding Dissimilarity)\ub97c \uc0ac\uc6a9\ud558\uc5ec MATH \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ud30c\uc778\ud29c\ub2dd \ubc29\ubc95\uc758 \uc751\ub2f5 \ub2e4\uc591\uc131\uc744 \uce21\uc815\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc81c\uc548\ub41c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ud30c\uc778\ud29c\ub2dd \ubc29\ubc95\uc758 \uacbd\uc6b0, \ud30c\uc778\ud29c\ub2dd \ubc18\ubcf5 \ud69f\uc218\uac00 \uc99d\uac00\ud574\ub3c4 \ud55c \uac00\uc9c0 \uc9c0\ud45c\uc5d0\uc11c\ub294 \ub2e4\uc591\uc131\uc774 \uc77c\uc815\ud558\uac8c \uc720\uc9c0\ub418\uace0 \ub2e4\ub978 \uc9c0\ud45c\uc5d0\uc11c\ub294 \ub2e4\uc591\uc131\uc774 \ud5a5\uc0c1\ub418\ub294 \ubc18\uba74, \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubc29\ubc95\uc740 \ub2e4\uc591\uc131\uc774 \ud06c\uac8c \uac10\uc18c\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ud30c\uc778\ud29c\ub2dd\uc774 \ubaa8\ub378\uc758 \ub2e4\uc591\uc131\uc744 \uc720\uc9c0\ud558\uace0 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05707/x4.png", "caption": "Figure 4: Relationship between accuracy and diversity. We visualize the relationship between embedding dissimilarity and MATH accuracy across rounds of finetuning. Our multiagent finetuning preserves diversity across rounds of finetuning while improving accuracy.", "description": "\uadf8\ub9bc 4\ub294 \uc815\ud655\ub3c4\uc640 \ub2e4\uc591\uc131 \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \uba40\ud2f0\uc5d0\uc774\uc804\ud2b8 \ud30c\uc778\ud29c\ub2dd\uc744 \ud1b5\ud574 \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub3d9\uc2dc\uc5d0 \ub2e4\uc591\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc784\ubca0\ub529 \uc720\uc0ac\uc131(embedding dissimilarity)\uacfc MATH \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4 \uac04\uc758 \uad00\uacc4\ub97c \uc5ec\ub7ec \ubc88\uc758 \ud30c\uc778\ud29c\ub2dd \ub77c\uc6b4\ub4dc\uc5d0 \uac78\uccd0 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba40\ud2f0\uc5d0\uc774\uc804\ud2b8 \ud30c\uc778\ud29c\ub2dd\uc744 \uc0ac\uc6a9\ud558\uba74 \ud30c\uc778\ud29c\ub2dd \ub77c\uc6b4\ub4dc\uac00 \ubc18\ubcf5\ub418\uc5b4\ub3c4 \ub2e4\uc591\uc131\uc774 \uc720\uc9c0\ub418\uba74\uc11c \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc989, \ub2e4\uc591\ud55c \ucd94\ub860 \uacfc\uc815\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ubaa8\ub378 \uc131\ub2a5\uc774 \uc9c0\uc18d\uc801\uc73c\ub85c \uac1c\uc120\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.05707/x5.png", "caption": "Figure 5: Zero-shot generalization of the proposed method. Our method demonstrates zero-shot generalization capabilities. When trained on the MATH dataset, it can effectively generalize to the GSM dataset. It outperforms all the baselines that are trained on the GSM dataset.", "description": "\uadf8\ub9bc 5\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc81c\ub85c\uc0f7 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MATH \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc774 GSM \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub3c4 \ud6a8\uacfc\uc801\uc73c\ub85c \uc77c\ubc18\ud654\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 GSM \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub4e0 \uae30\uc900 \ubaa8\ub378\ub4e4\uc744 \uc131\ub2a5\uba74\uc5d0\uc11c \ub2a5\uac00\ud568\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \ubcf4\ub2e4 \uc790\uc138\ud788 \uc124\uba85\ud558\uba74, \uc81c\uc548\ub41c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \uae30\ubc95\uc744 \ud1b5\ud574 \ud559\uc2b5\ub41c \ubaa8\ub378\uc774,  \uae30\uc874\uc758 \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubc29\uc2dd\uc73c\ub85c GSM \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \ud559\uc2b5\ub41c \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub294 \uc81c\uc548\ub41c \ubaa8\ub378\uc774 \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \uc0ac\uc804 \ud559\uc2b5 \uc5c6\uc774\ub3c4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubc1c\ud718\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05707/x6.png", "caption": "Figure 6: Consensus: Response diversity across finetuning iterations. We measure the response diversity based on agent consensus of our method and the single-agent finetuning method on the MATH dataset. The diversity of our method remains consistent over finetuning iterations, whereas the diversity of the single-agent method drops significantly.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uacfc \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc744 MATH \ub370\uc774\ud130\uc14b\uc5d0 \uc801\uc6a9\ud558\uc5ec \uac01 \ubc18\ubcf5 \ud559\uc2b5 \uc2dc\ub3c4\ubcc4 \uc751\ub2f5\uc758 \ub2e4\uc591\uc131\uc744 \uce21\uc815\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc758 \uacbd\uc6b0, \ud559\uc2b5 \ubc18\ubcf5 \ud69f\uc218\uac00 \uc99d\uac00\ud574\ub3c4 \uc751\ub2f5\uc758 \ub2e4\uc591\uc131\uc774 \uc77c\uc815\ud558\uac8c \uc720\uc9c0\ub418\ub294 \ubc18\uba74, \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc740 \uc751\ub2f5\uc758 \ub2e4\uc591\uc131\uc774 \ud06c\uac8c \uac10\uc18c\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc774 \ubaa8\ub378\uc758 \uacfc\uc801\ud569\uc744 \ubc29\uc9c0\ud558\uace0 \ub2e4\uc591\ud55c \ucd94\ub860 \uacfc\uc815\uc744 \uc720\uc9c0\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3.4 \ub2e4\uc911 \ubc18\ubcf5 \ubbf8\uc138\uc870\uc815"}, {"figure_path": "https://arxiv.org/html/2501.05707/x7.png", "caption": "Figure 7: KL-Divergence: Response diversity across finetuning iterations. We measure diversity based on the KL-divergence between the probabilities of the output tokens between agents. Similar to our likelihood measurement, we find that diversity is preserved across rounds of finetuning.", "description": "\uadf8\ub9bc 7\uc740 \uc5ec\ub7ec \ubc88\uc758 \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5\uc744 \uac70\uce58\uba74\uc11c \ubaa8\ub378\uc758 \uc751\ub2f5 \ub2e4\uc591\uc131\uc744 KL \ub2e4\uc774\ubc84\uc804\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uce21\uc815\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc73c\ub85c, \uac01 \uc5d0\uc774\uc804\ud2b8\uc758 \ucd9c\ub825 \ud1a0\ud070 \ud655\ub960 \ubd84\ud3ec \uac04\uc758 KL \ub2e4\uc774\ubc84\uc804\uc2a4\ub97c \uacc4\uc0b0\ud558\uc5ec \ub2e4\uc591\uc131\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \uc774\uc804\uc5d0 \uc0ac\uc6a9\ud588\ub358 \uac00\ub2a5\ub3c4 \uce21\uc815\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c, \uc5ec\ub7ec \ubc88\uc758 \ubbf8\uc138 \uc870\uc815 \ud6c4\uc5d0\ub3c4 \ub2e4\uc591\uc131\uc774 \uc720\uc9c0\ub428\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4. \uc989, \ubbf8\uc138 \uc870\uc815 \uacfc\uc815\uc5d0\uc11c \ubaa8\ub378\uc774 \ud2b9\uc815 \uc720\ud615\uc758 \uc751\ub2f5\uc5d0 \uce58\uc6b0\uce58\uc9c0 \uc54a\uace0 \ub2e4\uc591\ud55c \uc751\ub2f5\uc744 \uc0dd\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "3. \ub2e4\uc591\uc131 \uce21\uc815"}, {"figure_path": "https://arxiv.org/html/2501.05707/x8.png", "caption": "Figure 8: KL Diversity between finetuned and unfinetuned LLM. We measure the KL-divergence between likelihoods of responses from finetuned agents and base LLM agents for single-agent finetuning and generation/critic agents from multiagent finetuning. Likelihoods are calculated using Gemma-2 (2B). We find that our method diverges from the base LLM probabilities and furthermore, critic agents have better divergence in responses and our method has better diversity metrics than single-agent FT.", "description": "\uadf8\ub9bc 8\uc740 \ubbf8\uc138 \uc870\uc815\ub41c \uc5b8\uc5b4 \ubaa8\ub378\uacfc \ubbf8\uc138 \uc870\uc815\ub418\uc9c0 \uc54a\uc740 \uae30\ubcf8 \uc5b8\uc5b4 \ubaa8\ub378 \uac04\uc758 KL \ub2e4\uc774\ubc84\uc804\uc2a4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\uacfc \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\uc758 \uc0dd\uc131/\ube44\ud3c9 \uc5d0\uc774\uc804\ud2b8 \ubaa8\ub450\uc5d0 \ub300\ud574 \ubbf8\uc138 \uc870\uc815\ub41c \uc5d0\uc774\uc804\ud2b8\uc640 \uae30\ubcf8 LLM \uc5d0\uc774\uc804\ud2b8\uc758 \uc751\ub2f5\uc5d0 \ub300\ud55c \uc6b0\ub3c4 \uac04\uc758 KL \ub2e4\uc774\ubc84\uc804\uc2a4\ub97c \uce21\uc815\ud569\ub2c8\ub2e4. Gemma-2(2B)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc6b0\ub3c4\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\uc740 \uae30\ubcf8 LLM \ud655\ub960\uacfc \ub2e4\ub974\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc73c\uba70, \ube44\ud3c9 \uc5d0\uc774\uc804\ud2b8\ub294 \uc751\ub2f5\uc758 \ub2e4\uc774\ubc84\uc804\uc2a4\uac00 \ub354 \ud06c\uace0, \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\uc740 \ub2e8\uc77c \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\ubcf4\ub2e4 \ub2e4\uc591\uc131 \uce21\uc815\uac12\uc774 \ub354 \uc88b\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.4 \ub2e4\uc911 \ubc18\ubcf5 \ubbf8\uc138 \uc870\uc815"}, {"figure_path": "https://arxiv.org/html/2501.05707/x9.png", "caption": "Figure 9: Embedding Dissimilarity: Response diversity across finetuning iterations. We measure the response diversity based on the embedding dissimilarity between the responses of different agents, where embeddings are computed using the T5-3B encoder. We notice that similar to likelihood measurement, we find that diversity is preserved across rounds of finetuning.", "description": "\uadf8\ub9bc 9\ub294 \ub2e4\uc591\ud55c \uc5d0\uc774\uc804\ud2b8\uc758 \uc751\ub2f5 \uac04\uc758 \uc784\ubca0\ub529 \uc720\uc0ac\ub3c4 \ucc28\uc774\ub97c \uae30\ubc18\uc73c\ub85c \uce21\uc815\ud55c \uc751\ub2f5 \ub2e4\uc591\uc131\uc744 \uc5ec\ub7ec\ubc88\uc758 \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5\uc5d0 \uac78\uccd0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. T5-3B \uc778\ucf54\ub354\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc784\ubca0\ub529\uc744 \uacc4\uc0b0\ud588\uc2b5\ub2c8\ub2e4. \uacb0\uacfc\ub294 \uac00\ub2a5\ub3c4 \uce21\uc815\uacfc \uc720\uc0ac\ud558\uac8c \ubbf8\uc138 \uc870\uc815 \ub77c\uc6b4\ub4dc\uc5d0 \uac78\uccd0 \ub2e4\uc591\uc131\uc774 \uc720\uc9c0\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \uc5ec\ub7ec \uc5d0\uc774\uc804\ud2b8\uc758 \uc751\ub2f5\uc774 \uc11c\ub85c \uc720\uc0ac\ud558\uc9c0 \uc54a\uace0 \ub2e4\uc591\ud558\uac8c \uc720\uc9c0\ub418\uba74\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub428\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \uc5d0\uc774\uc804\ud2b8 \uc751\ub2f5 \ub2e4\uc591\uc131"}, {"figure_path": "https://arxiv.org/html/2501.05707/x10.png", "caption": "Figure 10: Inducing diversity through increasing temperature. We introduce an additional baseline where we apply the Single-Agent FT baselin with a temperature of 2. By increasing the sampling temperature, we allow the model to generate more diverse responses. We observe that our method out-performs higher temperature settings, which demonstrates that temperature does not increase diversity in a way that is useful for accuracy.", "description": "\uadf8\ub9bc 10\uc740 \uc628\ub3c4\ub97c \ub192\uc5ec \ub2e4\uc591\uc131\uc744 \uc720\ub3c4\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 Single-Agent FT(Fine-tuning) \ubc29\ubc95\uc5d0 \uc628\ub3c4 2\ub97c \uc801\uc6a9\ud55c \ucd94\uac00\uc801\uc778 \uae30\uc900\uc120\uc744 \uc124\uc815\ud558\uc5ec \ubaa8\ub378\uc774 \ub354 \ub2e4\uc591\ud55c \uc751\ub2f5\uc744 \uc0dd\uc131\ud558\ub3c4\ub85d \ud588\uc2b5\ub2c8\ub2e4. \uc2e4\ud5d8 \uacb0\uacfc, \uc81c\uc548\ub41c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc774 \ub192\uc740 \uc628\ub3c4 \uc124\uc815\uc744 \uc0ac\uc6a9\ud55c Single-Agent FT\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ub2e8\uc21c\ud788 \uc628\ub3c4\ub97c \ub192\uc774\ub294 \uac83\ub9cc\uc73c\ub85c\ub294 \uc815\ud655\ub3c4\uc5d0 \ub3c4\uc6c0\uc774 \ub418\ub294 \ubc29\uc2dd\uc73c\ub85c \ub2e4\uc591\uc131\uc744 \uc99d\uac00\uc2dc\ud0ac \uc218 \uc5c6\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \ubc29\ubc95\uc740 \ub2e4\uc591\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c \uc815\ud655\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub354 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.4 \ub2e4\uc911 \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5"}, {"figure_path": "https://arxiv.org/html/2501.05707/x11.png", "caption": "Figure 11: Multiple iterations of finetuning over all levels of MATH. We apply multiple iterations of finetuning over 500 examples of MATH sampled from all levels. Even over a more difficult domain, we see significant improvements from multiagent finetuning that continue to self-improve.", "description": "\uadf8\ub9bc 11\uc740 \ub2e4\uc591\ud55c \ub09c\uc774\ub3c4\uc758 MATH \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\uc758 \ubc18\ubcf5\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 500\uac1c\uc758 MATH \ubb38\uc81c \uc0d8\ud50c\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \ubc88\uc758 \ubbf8\uc138 \uc870\uc815\uc744 \uc218\ud589\ud588\uc73c\uba70, \ub354 \uc5b4\ub824\uc6b4 \ub3c4\uba54\uc778\uc5d0\uc11c\ub3c4 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815\uc744 \ud1b5\ud574 \uc9c0\uc18d\uc801\uc778 \uc790\uac00 \uac1c\uc120\uc774 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05707/x12.png", "caption": "Figure 12: Testing zero-shot generalization across 1000 GSM problems We test the zero-shot capabilities of our method using models trained on the MATH dataset. We find that over 1000 problems of GSM, our method performs better than all baselines.", "description": "\uc774 \uadf8\ub9bc\uc740 MATH \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec GSM \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc81c\ub85c\uc0f7 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ud14c\uc2a4\ud2b8\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  1000\uac1c\uc758 GSM \ubb38\uc81c\uc5d0 \ub300\ud55c \ud14c\uc2a4\ud2b8 \uacb0\uacfc, \uc81c\uc548\ub41c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \uae30\ubc95\uc774 \ubaa8\ub4e0 \uae30\uc900 \ubaa8\ub378\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uadf8\ub9bc\uc740 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138\uc870\uc815 \uae30\ubc95\uc758 \uc81c\ub85c\uc0f7 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.05707/x13.png", "caption": "Figure 13: Zero-shot generalization after arithmetic finetuning. We evaluate the ability of our method to generalize after finetuning Mistral on the arithmetic task and evaluating on GSM. We find that this aids in GSM performance, even more than finetuning with MATH.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0b0\uc220 \uc5f0\uc0b0 \ubb38\uc81c\ub97c \uc0ac\uc6a9\ud558\uc5ec Mistral \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud55c \ud6c4 GSM(Grade School Math) \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \uc81c\ub85c\uc0f7 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uadf8\ub9bc\uc740 \uc0b0\uc220 \ubb38\uc81c\ub85c \ubbf8\uc138 \uc870\uc815\ud588\uc744 \ub54c  MATH \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubbf8\uc138 \uc870\uc815\ud588\uc744 \ub54c\ubcf4\ub2e4 GSM \uc131\ub2a5\uc774 \ub354 \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \uc81c\uc548\ub41c \ub2e4 \uc5d0\uc774\uc804\ud2b8 \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}]