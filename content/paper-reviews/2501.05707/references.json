{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of large language models (LLMs), introducing the concept of few-shot learning, which significantly impacted the development of self-improvement techniques for LLMs."}, {"fullname_first_author": "Jiaxin Huang", "paper_title": "Large language models can self-improve", "publication_date": "2022-10-26", "reason": "This paper is among the earliest to explore the concept of LLM self-improvement and directly inspired the current work's exploration of self-improvement through multi-agent interaction."}, {"fullname_first_author": "Yilun Du", "paper_title": "Improving factuality and reasoning in language models through multiagent debate", "publication_date": "2023-05-15", "reason": "This paper introduces the multiagent debate method, which forms the core methodology of the proposed multiagent finetuning approach."}, {"fullname_first_author": "Eric Zelikman", "paper_title": "STAR: Self-taught reasoner bootstrapping reasoning with reasoning", "publication_date": "2022-12-01", "reason": "This paper proposes an iterative self-improvement method using self-generated rationales and is directly compared to the proposed approach, highlighting its limitations and motivating the alternative strategy."}, {"fullname_first_author": "Yuntao Bai", "paper_title": "Constitutional AI: Harmlessness from AI feedback", "publication_date": "2022-12-01", "reason": "This paper presents a prominent approach to improving the safety and harmlessness of LLMs through iterative feedback and finetuning, which is closely related to the concept of self-improvement explored in the current study."}]}