{"references": [{"fullname_first_author": "Jimenez", "paper_title": "SWE-Bench: Can language models resolve real-world GitHub issues?", "publication_date": "2024-05-07", "reason": "This paper introduces SWE-Bench, a benchmark dataset for evaluating software engineering agents, which is frequently referenced and compared to in the current paper."}, {"fullname_first_author": "Wang", "paper_title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents", "publication_date": "2024-07-01", "reason": "This paper introduces OpenHands, an agent scaffold used in the current paper's experiments, and is crucial for understanding the baseline performance and methodology."}, {"fullname_first_author": "Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-26", "reason": "This paper introduces the concept of training outcome-supervised reward models (ORMs), which are used as verifiers in the current work for inference-time scaling."}, {"fullname_first_author": "Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This paper is highly influential in introducing Reinforcement Learning from Human Feedback (RLHF), a technique relevant to the training methods used for language models in the current research."}, {"fullname_first_author": "Yao", "paper_title": "React: Synergizing reasoning and acting in language models", "publication_date": "2023-05-01", "reason": "This paper introduces the ReAct framework, a prompting approach used in the OpenHands agent scaffold, which is a key component of the current paper's experimental setup."}]}