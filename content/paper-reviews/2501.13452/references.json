{"references": [{"fullname_first_author": "Mengyue Yang", "paper_title": "Causalvae: Structured causal disentanglement in variational autoencoder", "publication_date": "2020-04-00", "reason": "This paper is foundational for understanding causal disentanglement in variational autoencoders, a crucial concept for generating high-quality, controllable videos."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-00-00", "reason": "This work is highly relevant due to its introduction of scalable diffusion models using transformers, which are the basis for many recent advancements in video generation."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-00-00", "reason": "This paper is important because it details the addition of conditional control to text-to-image diffusion models, which is essential for controlling identity and attributes in video generation."}, {"fullname_first_author": "Wangbo Yu", "paper_title": "Evagaussians: Event stream assisted gaussian splatting from blurry images", "publication_date": "2024-05-00", "reason": "This paper introduces a novel approach to generating high-quality images from blurry inputs, which is highly relevant to the task of identity-preserving video generation."}, {"fullname_first_author": "Zhenyu Tang", "paper_title": "Cycle3d: High-quality and consistent image-to-3d generation via generation-reconstruction cycle", "publication_date": "2024-07-00", "reason": "This paper presents a method for generating high-quality and consistent 3D content from images, which is a related and relevant task to video generation."}]}