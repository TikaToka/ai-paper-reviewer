---
title: "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models"
summary: "HippoRAG 2ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¥ê¸° ê¸°ì–µëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë¹„ëª¨ìˆ˜ì  ì§€ì† í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¡œ, ê¸°ì¡´ RAG ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ì¸ê°„ì˜ ê¸°ì–µ ëŠ¥ë ¥ì— í•œì¸µ ë” ê°€ê¹Œì›Œì¡ŒìŠµë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Ohio State University",]
showSummary: true
date: 2025-02-20
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.14802 {{< /keyword >}}
{{< keyword icon="writer" >}} Bernal JimÃ©nez GutiÃ©rrez et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-21 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.14802" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.14802" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/from-rag-to-memory-non-parametric-continual" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¸ê°„ì²˜ëŸ¼ ì§€ì†ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì§€ì‹ì„ ìŠµë“í•˜ê³  í™œìš©í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) ë°©ì‹ì€ ë²¡í„° ê²€ìƒ‰ì— ì˜ì¡´í•˜ì—¬ ì¸ê°„ì˜ ë™ì ì¸ ì¥ê¸° ê¸°ì–µì„ ëª¨ë°©í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.  ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì—¬ëŸ¬ ì—°êµ¬ì—ì„œ ì§€ì‹ ê·¸ë˜í”„ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ë²¡í„° ì„ë² ë”©ì— ì¶”ê°€í•˜ëŠ” ë“±ì˜ ê°œì„  ì‹œë„ê°€ ìˆì—ˆì§€ë§Œ, ê¸°ë³¸ì ì¸ ì‚¬ì‹¤ ê¸°ì–µ ê³¼ì œì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ë¬¸ì œì ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” HippoRAG 2ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ì—¬, ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. HippoRAG 2ëŠ” ê°œì„ ëœ PPR ì•Œê³ ë¦¬ì¦˜, ì‹¬ì¸µì ì¸ ë¬¸ë§¥ í†µí•©, íš¨ìœ¨ì ì¸ LLM í™œìš©ì„ í†µí•´ ê¸°ì¡´ RAG ë°©ì‹ë³´ë‹¤ ì‚¬ì‹¤ ê¸°ì–µ, ì˜ë¯¸ ì´í•´, ì—°ê´€ì„± íŒŒì•… ë“± ë‹¤ì–‘í•œ ê¸°ì–µ ê³¼ì œì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, ì—°ê´€ì„± ê¸°ì–µ ê³¼ì œì—ì„œ ìµœì²¨ë‹¨ ì„ë² ë”© ëª¨ë¸ ëŒ€ë¹„ 7% í–¥ìƒëœ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.  ì´ ì—°êµ¬ëŠ” LLMì„ ìœ„í•œ ë¹„ëª¨ìˆ˜ì  ì§€ì† í•™ìŠµì˜ ìƒˆë¡œìš´ ê¸¸ì„ ì œì‹œí•˜ëŠ” ì¤‘ìš”í•œ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} HippoRAG 2ëŠ” ê¸°ì¡´ RAG ë°©ì‹ë³´ë‹¤ **ë‹¨ìˆœ ì‚¬ì‹¤ ê¸°ì–µ, ì˜ë¯¸ ì´í•´, ì—°ê´€ì„± íŒŒì•… ë“±ì˜ ë‹¤ì–‘í•œ ê¸°ì–µ ê³¼ì œì—ì„œ ì„±ëŠ¥ì´ ë›°ì–´ë‚¨**ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} **ë¹„ëª¨ìˆ˜ì  ë°©ì‹**ì„ í†µí•´ ê¸°ì¡´ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì§€ì† í•™ìŠµ ëª¨ë¸ì˜ **íŒŒê´´ì  ë§ê° ë¬¸ì œë¥¼ í•´ê²°**í–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} **ì¸ê°„ì˜ ê¸°ì–µ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ ì˜ê°**ì„ ì–»ì–´ ì„¤ê³„ëœ HippoRAG 2ëŠ” **ë”ìš± ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ì§€ì† í•™ìŠµ ì‹œìŠ¤í…œ**ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ì´ ë…¼ë¬¸ì€ **ì§€ì†ì ì¸ í•™ìŠµì„ ìœ„í•œ ë¹„ëª¨ìˆ˜ì  ë°©ë²•ë¡ **ì„ ì œì‹œí•˜ì—¬, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¥ê¸° ê¸°ì–µ ëŠ¥ë ¥ í–¥ìƒì— í¬ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ê¸°ì¡´ì˜ RAG ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µ**í•˜ê³  ì¸ê°„ì˜ ê¸°ì–µê³¼ ìœ ì‚¬í•œ ê¸°ëŠ¥ì„ êµ¬í˜„í•œ HippoRAG 2ëŠ” **ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì—°êµ¬ìë“¤ì—ê²Œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±**ì„ ì—´ì–´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ì—°êµ¬ íŠ¸ë Œë“œì¸ ì§€ì†ì ì¸ í•™ìŠµê³¼ ì¥ê¸° ê¸°ì–µ ëª¨ë¸ë§ ë¶„ì•¼**ì— í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, **í–¥í›„ ì—°êµ¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°©í–¥**ì„ ì œì‹œí•©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.14802/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ì§€ì†ì ì¸ í•™ìŠµ ëŠ¥ë ¥ì„ ì„¸ ê°€ì§€ ì£¼ìš” ì¸¡ë©´(ì‚¬ì‹¤ì  ê¸°ì–µ, ì˜ë¯¸ íŒŒì•…, ì—°ê´€ì„±)ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì‚¬ì‹¤ì  ê¸°ì–µì€ NaturalQuestionsì™€ PopQA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ì—ˆê³ , ì˜ë¯¸ íŒŒì•…ì€ NarrativeQA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ì—°ê´€ì„±ì€ MuSiQue, 2Wiki, HotpotQA, LV-Eval ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. HippoRAG 2ëŠ” ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ë²”ì£¼ì—ì„œ ë‹¤ë¥¸ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ë©°, ì§„ì •í•œ ì¥ê¸° ê¸°ì–µ ì‹œìŠ¤í…œì— í•œ ê±¸ìŒ ë” ê°€ê¹Œì´ ë‹¤ê°€ê°”ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1:  Evaluation of continual learning capabilities across three key dimensions: factual memory (NaturalQuestions, PopQA), sense-making (NarrativeQA), and associativity (MuSiQue, 2Wiki, HotpotQA, and LV-Eval). HippoRAG 2 surpasses other methods across all benchmark categories, bringing it one step closer to a true long-term memory system.
> </details>





{{< table-caption >}}
|               | NQ      | PopQA    | MuSiQue  | 2Wiki    | HotpotQA | LV-Eval  | NarrativeQA |
| :------------ | :------- | :-------- | :-------- | :-------- | :-------- | :-------- | :------------ |
| Num of queries | 1,000    | 1,000     | 1,000     | 1,000     | 124      | 293      |               |
| Num of passages | 9,633    | 8,676     | 11,656    | 6,119     | 9,811     | 22,849    | 4,111        |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì˜ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ ì§ˆë¬¸, ê·¸ë¦¬ê³  ê´€ë ¨ êµ¬ì ˆì˜ ìˆ˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ì„¸ë¶€ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ê° ë°ì´í„°ì…‹ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ê±¸ì³ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ë•Œ ì¤‘ìš”í•œ ì •ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Dataset statistics
> </details>





### In-depth insights


#### HippoRAG: Intro
HippoRAG ì†Œê°œëŠ” ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì™€ ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ëŠ” ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.  **ê¸°ì¡´ RAG(Retrieval Augmented Generation) ë°©ì‹ì˜ í•œê³„ì **ì¸ ë‹¨ìˆœ ë²¡í„° ê²€ìƒ‰ì— ëŒ€í•œ ì˜ì¡´ìœ¼ë¡œ ì¸í•œ ì˜ë¯¸ íŒŒì•… ë° ì—°ê´€ì„± ë¶€ì¡±ì„ ì§€ì í•˜ê³ , **HippoRAGê°€ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì œì‹œí•˜ëŠ” í•´ê²°ì±…**ì„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.  HippoRAGëŠ” ê°œì¸í™”ëœ í˜ì´ì§€ë­í¬ ì•Œê³ ë¦¬ì¦˜ê³¼ LLM(Large Language Model)ì„ í™œìš©í•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ê³ , ë‹¤ì¤‘ í˜¸í”„ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•¨ìœ¼ë¡œì¨ **ì¸ê°„ì˜ ì¥ê¸° ê¸°ì–µì— ê°€ê¹Œìš´ ì„±ëŠ¥**ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  ì†Œê°œ ë¶€ë¶„ì—ì„œëŠ” ì´ëŸ¬í•œ í•µì‹¬ ê¸°ëŠ¥ë“¤ì„ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•˜ì—¬ ë…ìì˜ ì´í•´ë¥¼ ë•ê³ , ë…¼ë¬¸ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì— ëŒ€í•œ ê¸°ëŒ€ê°ì„ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.  íŠ¹íˆ, **ê°œì¸í™”ëœ í˜ì´ì§€ë­í¬ ì•Œê³ ë¦¬ì¦˜ì˜ í™œìš©**, **LLMì˜ íš¨ê³¼ì ì¸ í†µí•©**, ê·¸ë¦¬ê³  **ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•ì„ í†µí•œ ì˜ë¯¸ íŒŒì•… ë° ì—°ê´€ì„± ê°œì„ ** ë“±ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°•ì¡°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  ë˜í•œ, HippoRAGì˜ ì„±ëŠ¥ í‰ê°€ì— ì‚¬ìš©ë  ê¸°ì¤€ ë° ë°ì´í„°ì…‹ì— ëŒ€í•œ ì–¸ê¸‰ë„ í¬í•¨ë˜ì–´ì•¼ ë…ìì—ê²Œ ì „ì²´ì ì¸ ê·¸ë¦¼ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Memory Systems
ë³¸ ë…¼ë¬¸ì—ì„œ 'ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ'ì´ë¼ëŠ” ê°œë…ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ ì§€ì†ì ì¸ í•™ìŠµ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í•µì‹¬ ìš”ì†Œë¡œ ì œì‹œë©ë‹ˆë‹¤.  ê¸°ì¡´ì˜ LLMì€ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ìŠµë“í•˜ë©´ ì´ì „ ì •ë³´ë¥¼ ë§ê°í•˜ëŠ” **íŒŒêµ­ì  ë§ê°(catastrophic forgetting)** ë¬¸ì œë¥¼ ê²ªìŠµë‹ˆë‹¤.  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë…¼ë¬¸ì€ **ë¹„ëª¨ìˆ˜ì  ì§€ì† í•™ìŠµ(non-parametric continual learning)** ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.  **RAG(Retrieval-Augmented Generation)**ëŠ” ìƒˆë¡œìš´ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ í™œìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì˜ ì—­í• ì„ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ë‹¨ìˆœ ë²¡í„° ê²€ìƒ‰ì— ì˜ì¡´í•˜ëŠ” ê¸°ì¡´ RAGëŠ” ì¸ê°„ì˜ ë™ì ì¸ ê¸°ì–µ ì²´ê³„ì™€ ì—°ê²°ì„±ì„ ì¶©ë¶„íˆ ëª¨ë°©í•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.  ë³¸ ë…¼ë¬¸ì€ **HippoRAG 2**ì™€ ê°™ì€ ê°œì„ ëœ RAG êµ¬ì¡°ë¥¼ í†µí•´,  **êµ¬ì¡°í™”ëœ ì§€ì‹(structured knowledge)**ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ì‹¤ì  ê¸°ì–µ, ì˜ë¯¸ íŒŒì•…, ì—°ê´€ì„± í•™ìŠµ ë“± ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ê³¼ì œì—ì„œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë”°ë¼ì„œ, **ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì€ LLMì˜ ì§€ì†ì ì¸ í•™ìŠµ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í•µì‹¬ ìš”ì†Œì´ë©°,  ì¸ê°„ì˜ ê¸°ì–µê³¼ ìœ ì‚¬í•œ ì—­ë™ì ì´ê³  ì—°ê²°ëœ êµ¬ì¡°ë¥¼ ê°€ì§„ ë¹„ëª¨ìˆ˜ì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ì´ ì¤‘ìš”í•¨**ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

#### Experimental Setup
ë³¸ ë…¼ë¬¸ì˜ "ì‹¤í—˜ ì„¤ì •" ë¶€ë¶„ì€ **ë‹¤ì–‘í•œ ê¸°ì¤€ì  ëª¨ë¸ë“¤ê³¼ ë°ì´í„°ì…‹ ì„ íƒ**ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë…¼ì˜ë¥¼ ì œì‹œí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œ, **ê¸°ì¡´ì˜ ì •ë³´ ê²€ìƒ‰ ë°©ë²•ë¡ (BM25, Contriever, GTR)ê³¼ ëŒ€ê·œëª¨ ì„ë² ë”© ëª¨ë¸(GTE-Qwen2-7B-Instruct, GritLM-7B, NV-Embed-v2)ì„ ê¸°ì¤€ì **ìœ¼ë¡œ ì‚¼ì•„ ì œì•ˆëœ ë°©ë²•ë¡ ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ì‹¤í—˜ ì„¤ê³„ê°€ í¬í•¨ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ë˜í•œ, **ë‹¨ìˆœ ì‚¬ì‹¤ ê¸°ì–µ, ì˜ë¯¸ íŒŒì•…, ì—°ê´€ì„± íŒŒì•… ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë©”ëª¨ë¦¬ ê³¼ì œë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ (Natural Questions, PopQA, MuSiQue, 2Wiki, HotpotQA, LV-Eval, NarrativeQA)**ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ê°ì ì¸ ì¸¡ë©´ì—ì„œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ì‹¤í—˜ í™˜ê²½ì„ êµ¬ì„±í–ˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ì‹¤í—˜ ì„¤ê³„ëŠ” ì œì•ˆëœ ë°©ë²•ë¡ ì´ ê¸°ì¡´ ë°©ë²•ë¡ ì— ë¹„í•´ ì–¼ë§ˆë‚˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ìœ í˜•ì˜ ë©”ëª¨ë¦¬ ê³¼ì œì— íŠ¹íˆ ê°•ì ì„ ë³´ì´ëŠ”ì§€ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒì…ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ê¸°ì¤€ì ê³¼ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, ì œì•ˆëœ ë°©ë²•ë¡ ì˜ ì¼ë°˜í™” ì„±ëŠ¥ê³¼ ì‹¤ìš©ì„±ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€**í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ,  **ì‹¤í—˜ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ í†µê³„ì  ë¶„ì„ ë°©ë²•**ì— ëŒ€í•œ ëª…ì‹œì ì¸ ì–¸ê¸‰ì´ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Ablation Study
ë³¸ ë…¼ë¬¸ì˜ "ì ˆì œ ì—°êµ¬(Ablation Study)"ëŠ” **ëª¨ë¸ì˜ ì„±ëŠ¥ì— ê¸°ì—¬í•˜ëŠ” ê° êµ¬ì„±ìš”ì†Œì˜ ì¤‘ìš”ë„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€**í•˜ê¸° ìœ„í•´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œ, ì €ìë“¤ì€ ì œì•ˆëœ ë°©ë²•(HippoRAG 2)ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì œê±°í•˜ê³ , ê° êµ¬ì„±ìš”ì†Œ ì œê±° í›„ ëª¨ë¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ **ê° êµ¬ì„±ìš”ì†Œì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ì™€ ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ ê¸°ì—¬ë„**ë¥¼ ëª…í™•íˆ íŒŒì•…í•˜ê³ ì í•˜ì˜€ìŠµë‹ˆë‹¤.  **íŠ¹íˆ, ì¿¼ë¦¬ì™€ KG(Knowledge Graph)ì˜ ì—°ê²° ë°©ì‹, KG êµ¬ì„± ë°©ë²•, ê·¸ë¦¬ê³  ì¸ì‹ ê¸°ì–µ(Recognition Memory) ëª¨ë“ˆì˜ ì˜í–¥**ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ í†µí•´, ê° ìš”ì†Œê°€ ìµœì¢… ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë©´ë°€íˆ ê²€í† í–ˆìŠµë‹ˆë‹¤.  **ì‹¤í—˜ ê²°ê³¼ëŠ” ê° êµ¬ì„±ìš”ì†Œê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ìƒí˜¸ì‘ìš©ê³¼ ì¤‘ìš”ë„**ë¥¼ ë³´ì—¬ì£¼ëŠ” ì¦ê±°ë¥¼ ì œì‹œí•˜ë©°, **HippoRAG 2 ëª¨ë¸ì˜ ì„¤ê³„ ë° ê°œì„  ë°©í–¥**ì— ëŒ€í•œ ê·€ì¤‘í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.  **ê°œë³„ êµ¬ì„±ìš”ì†Œì˜ ê¸°ì—¬ë„ ë¶„ì„ì„ í†µí•´ í–¥í›„ ëª¨ë¸ ê°œì„  ë° ìµœì í™”**ì— í•„ìš”í•œ ë°©í–¥ì„ ì œì‹œí•¨ìœ¼ë¡œì¨, ë³¸ ì—°êµ¬ì˜ ì‹¤ìš©ì  ê°€ì¹˜ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.

#### Future Work
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ HippoRAG 2ëŠ” ì¥ê¸° ê¸°ì–µê³¼ ì—°ê´€ëœ LLMì˜ ì—­ë™ì ì´ê³  ìƒí˜¸ ì—°ê²°ëœ íŠ¹ì„±ì„ ëª¨ë°©í•˜ëŠ” ë° ìˆì–´ ìƒë‹¹í•œ ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, **í–¥í›„ ì—°êµ¬ ë°©í–¥**ì€ ì—¬ì „íˆ ë§ìŠµë‹ˆë‹¤.  **ê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ ë©”ì»¤ë‹ˆì¦˜**ì˜ ê°œì„ ì„ í†µí•´ ë”ìš± ì •êµí•œ ë‹¤ë‹¨ê³„ ì¶”ë¡ ê³¼ ë³µì¡í•œ ì§ˆì˜ì— ëŒ€í•œ ê°•ë ¥í•œ ëŒ€ì‘ ëŠ¥ë ¥ì„ í™•ë³´í•´ì•¼ í•©ë‹ˆë‹¤.  **ì¸ì‹ ê¸°ì–µ(Recognition Memory)**ì˜ ì •í™•ì„± í–¥ìƒì„ ìœ„í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•˜ë©°, ì´ë¥¼ í†µí•´ ë¶ˆí•„ìš”í•œ ì •ë³´ í•„í„°ë§ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ë‹¤ì–‘í•œ í¬ê¸°ì™€ ìœ í˜•ì˜ LLM**ì„ í™œìš©í•œ ì‹¤í—˜ì„ í†µí•´ HippoRAG 2ì˜ ì¼ë°˜ì„±ê³¼ ê²¬ê³ ì„±ì„ í‰ê°€í•˜ê³ , **ë”ìš± ê´‘ë²”ìœ„í•œ ë°ì´í„°ì…‹**ì„ ì´ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **ì¥ê¸°ì ì¸ ëŒ€í™” ë§¥ë½**ì—ì„œì˜ ì—í”¼ì†Œë“œ ê¸°ì–µ ê¸°ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì—°êµ¬ë¥¼ í†µí•´ LLMì˜ ì§€ëŠ¥ ìˆ˜ì¤€ì„ í•œì¸µ ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë…¸ë ¥ì„ í†µí•´ HippoRAG 2ëŠ” ì¸ê°„ì˜ ì¥ê¸° ê¸°ì–µ ì‹œìŠ¤í…œì— ë”ìš± ê·¼ì ‘í•˜ê³ ,  ì§„ì •í•œ ì¸ê°„ ìˆ˜ì¤€ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ê°œë°œì— í•œ ê±¸ìŒ ë” ë‹¤ê°€ì„¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.14802/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” HippoRAG 2ì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ ë™ì‘ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜¤í”„ë¼ì¸ ìƒ‰ì¸ ë‹¨ê³„ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ë³¸ë¬¸ì—ì„œ ì§€ì‹ ê·¸ë˜í”„(KG)ì˜ 3ì¤‘í•­(triple)ì„ ì¶”ì¶œí•˜ê³ , êµ¬ì ˆ ë…¸ë“œ(phrase node)ì— ë™ì˜ì–´ íƒì§€ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì¶”ì¶œëœ êµ¬ì ˆê³¼ ë³¸ë¬¸ì€ í†µí•©ë˜ì–´ í•˜ë‚˜ì˜ KGë¥¼ í˜•ì„±í•©ë‹ˆë‹¤. ì˜¨ë¼ì¸ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œëŠ” ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë³¸ë¬¸ê³¼ 3ì¤‘í•­ì„ í‰ê°€í•˜ì—¬ PPR ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í•œ ì‹œë“œ ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.  ì¸ì‹ ë©”ëª¨ë¦¬(Recognition memory)ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒìœ„ 3ì¤‘í•­ì„ í•„í„°ë§í•©ë‹ˆë‹¤. PPR ì•Œê³ ë¦¬ì¦˜ì€ KGì—ì„œ ë¬¸ë§¥ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì¢… ì§ˆì˜ì‘ë‹µ(QA) ì‘ì—…ì— ê°€ì¥ ì í•©í•œ ë³¸ë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤. KG ë…¸ë“œì˜ ìƒ‰ìƒì€ PPR í”„ë¡œì„¸ìŠ¤ì— ì˜í•´ ìœ ë„ëœ í™•ë¥  ì§ˆëŸ‰ì„ ë°˜ì˜í•˜ë©°, ë” ì–´ë‘ìš´ ìƒ‰ìƒì€ ë” ë†’ì€ í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: HippoRAG 2 methodology. For offline indexing, we use an LLM to extract open KG triples from passages, with synonym detection applied to phrase nodes. Together, these phrases and passages form the open KG. For online retrieval, an embedding model scores both the passages and triples to identify the seed nodes of both types for the Personalized PageRank (PPR) algorithm. Recognition memory filters the top triples using an LLM. The PPR algorithm then performs context-based retrieval on the KG to provide the most relevant passages for the final QA task. The different colors shown in the KG nodes above reflect their probability mass; darker shades indicate higher probabilities induced by the PPR process.
> </details>



![](https://arxiv.org/html/2502.14802/x3.png)

> ğŸ”¼  ê·¸ë¦¼ 3ì€ ë³¸ ë…¼ë¬¸ì˜ ì¸ì‹ ê¸°ì–µ(recognition memory)ì— ê´€í•œ ë‚´ìš©ì„ ì„¤ëª…í•˜ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤.  LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ ì´ìš©í•´ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì„¸ ê°€ì§€ ì‚¬ì‹¤(triple)ì„ ê±¸ëŸ¬ë‚´ëŠ” ê³¼ì •(triple filtering)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ë¦¼ì€ ì§€ì¹¨(instruction), ëª‡ ê°€ì§€ ì˜ˆì‹œ(few-shot demonstrations), ê·¸ë¦¬ê³  ì…ë ¥ í˜•ì‹(input format)ì„ í¬í•¨í•œ LLM í”„ë¡¬í”„íŠ¸ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  LLMì€ ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë„ì¶œí•˜ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë§Œì„ ì„ íƒí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ì‹œìŠ¤í…œì€ ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì œê±°í•˜ê³  ì •í™•í•œ ë‹µë³€ ë„ì¶œì— í•„ìš”í•œ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: LLM prompts for triple filtering (recognition memory).
> </details>



![](https://arxiv.org/html/2502.14802/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” HippoRAG 2 íŒŒì´í”„ë¼ì¸ì˜ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¿¼ë¦¬(â€œErik Hortì˜ ì¶œìƒì§€ëŠ” ì–´ëŠ ì¹´ìš´í‹°ì¸ê°€ìš”?â€)ê°€ ì£¼ì–´ì§€ë©´, ë¨¼ì € ì¿¼ë¦¬-íˆ¬-íŠ¸ë¦¬í”Œ ë‹¨ê³„ì—ì„œ ê´€ë ¨ íŠ¸ë¦¬í”Œ í›„ë³´ë“¤ì´ ì¶”ì¶œë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì¸ì‹ ê¸°ì–µ ë‹¨ê³„ì—ì„œ LLMì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ì„±ì´ ë‚®ì€ íŠ¸ë¦¬í”Œì„ í•„í„°ë§í•©ë‹ˆë‹¤. í•„í„°ë§ëœ íŠ¸ë¦¬í”Œì€ PPR(Personalized PageRank) ê·¸ë˜í”„ ê²€ìƒ‰ì˜ ì‹œë“œ ë…¸ë“œë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì‹œë“œ ë…¸ë“œì—ëŠ” êµ¬ë¬¸ ë…¸ë“œì™€ ë‹¨ë½ ë…¸ë“œê°€ í¬í•¨ë©ë‹ˆë‹¤. PPR ê·¸ë˜í”„ ê²€ìƒ‰ì„ í†µí•´ ìƒìœ„ ë‹¨ë½ë“¤ì´ ì„ ë³„ë˜ê³ , ìµœì¢…ì ìœ¼ë¡œ QA(Question Answering) ë‹¨ê³„ì—ì„œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œëŠ” ê° ë‹¨ê³„ì—ì„œì˜ ì¤‘ê°„ ê²°ê³¼ì™€ ìµœì¢… ìƒìœ„ ë‹¨ë½ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœì¢… ë‹µë³€ì€ â€œMontebelloâ€ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: An example of HippoRAG 2 pipeline.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
Simple QA

|               | NQ    | PopQA  | Multi-Hop QA                     |                |                |                |                | Avg   |
| :------------ | :---- | :----- | :-------------------------------- | :------------- | :------------- | :------------- | :------------- | :---- |
| **Retrieval** |       |        |                                 |                |                |                |                |       |
| None          | 54.9  | 32.5   | 26.1                              | 42.8           | 47.3           | 6.0            | 12.9           | 38.4  |
| Contriever (Izacard et al., 2022) | 58.9  | 53.1   | 31.3                              | 41.9           | 62.3           | 8.1            | 19.7           | 46.9  |
| BM25 (Robertson & Walker, 1994) | 59.0  | 49.9   | 28.8                              | 51.2           | 63.4           | 5.9            | 18.3           | 47.7  |
| GTR (T5-base) (Ni et al., 2022)   | 59.9  | 56.2   | 34.6                              | 52.8           | 62.8           | 7.1            | 19.9           | 50.4  |
Large Embedding Models
| GTE-Qwen2-7B-Instruct (Li et al., 2023) | 62.0  | 56.3   | 40.9                              | 60.0           | 71.0           | 7.1            | 21.3           | 54.9  |
| GritLM-7B (Muennighoff et al., 2024)   | 61.3  | 55.8   | 44.8                              | 60.6           | 73.3           | 9.8            | 23.9           | 56.1  |
| NV-Embed-v2 (7B) (Lee et al., 2025)  | 61.9  | 55.7   | 45.7                              | 61.5           | 75.3           | 9.8            | 25.7           | 57.0  |
Structure-Augmented RAG
| RAPTOR (Sarthi et al., 2024)       | 50.7  | 56.2   | 28.9                              | 52.1           | 69.5           | 5.0            | 21.4           | 48.8  |
| GraphRAG (Edge et al., 2024)       | 46.9  | 48.1   | 38.5                              | 58.6           | 68.6           | 11.2           | 23.0           | 49.6  |
| LightRAG (Guo et al., 2024)        | 16.6  | 2.4    | 1.6                               | 11.6           | 2.4            | 1.0            | 3.7            | 6.6   |
| HippoRAG (GutiÃ©rrez et al., 2024)   | 55.3  | 55.9   | 35.1                              | 71.8           | 63.5           | 8.4            | 16.3           | 53.1  |
| HippoRAG 2                            | 63.3  | 56.2   | 48.6                              | 71.0           | 75.5           | 12.9           | 25.9           | 59.8  |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” Llama-3.3-70B-Instruct ëª¨ë¸ì„ ì§ˆì˜ì‘ë‹µ(QA) íŒë…ê¸°ë¡œ ì‚¬ìš©í•˜ì—¬ RAG ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µ ì„±ëŠ¥(F1 ì ìˆ˜)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  'No retrieval'ì€ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜í™”ëœ ì§€ì‹ì„ í‰ê°€í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. HippoRAG ë° HippoRAG 2ëŠ” ì¶”ì¶œê¸°(ë° 3ì¤‘ í•„í„°)ë¡œ Llama-3.3-70B-Instructë¥¼, ê²€ìƒ‰ê¸°ë¡œ NV-Embed-v2ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í‘œì™€ ê·¸ ì´í›„ì˜ í‘œì—ì„œëŠ” ìµœê³  ë° ì°¨ê³  ì„±ëŠ¥ ê²°ê³¼ë¥¼ ê°•ì¡° í‘œì‹œí•©ë‹ˆë‹¤.  í‘œëŠ” ë‹¨ìˆœ QA, ë‹¤ì¤‘ í™‰ QA, ë‹´í™” ì´í•´ë¼ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ì¸¡ë©´ì—ì„œ ë‹¤ì–‘í•œ ê¸°ì¤€(NQ, PopQA, MuSiQue, 2Wiki, HotpotQA, LV-Eval, NarrativeQA)ì— ëŒ€í•œ F1 ì ìˆ˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.  ê° ê¸°ì¤€ë³„ë¡œ 'No Retrieval',  ê¸°ë³¸ ê²€ìƒ‰ ë°©ë²•(Contriever, BM25, GTR), ëŒ€ê·œëª¨ ì„ë² ë”© ëª¨ë¸(GTE-Qwen2-7B-Instruct, GritLM-7B, NV-Embed-v2), êµ¬ì¡° ê¸°ë°˜ RAG ë°©ë²•(RAPTOR, GraphRAG, LightRAG, HippoRAG) ë“± ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ HippoRAG 2ì˜ ìš°ìˆ˜ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: QA performance (F1 scores) on RAG benchmarks using Llama-3.3-70B-Instruct as the QA reader. No retrieval means evaluating the parametric knowledge of the readers. HippoRAG (and HippoRAG 2) uses Llama-3.3-70B-Instruct as the extractor (and the triple filter) and NV-Embed-v2 as the retriever. This table, along with the following ones, highlight the best and second-best results.
> </details>

{{< table-caption >}}
|           | Simple QA                     |           | Multi-Hop QA                       |           |           |           |
| :--------- | :------------------------------ | :--------- | :--------------------------------- | :--------- | :--------- | :--------- |
| Retrieval | NQ                             | PopQA      | MuSiQue                             | 2Wiki      | HotpotQA   | Avg        |
|           | **Simple Baselines**             |           | **Simple Baselines**                 |           |           |           |
| BM25 (Robertson & Walker, 1994) | 56.1                          | 35.7       | 43.5                               | 65.3       | 74.8       | 55.1       |
| Contriever (Izacard et al., 2022) | 54.6                          | 43.2       | 46.6                               | 57.5       | 75.3       | 55.4       |
| GTR (T5-base) (Ni et al., 2022)   | 63.4                          | 49.4       | 49.1                               | 67.9       | 73.9       | 60.7       |
|           | **Large Embedding Models**       |           | **Large Embedding Models**           |           |           |           |
| GTE-Qwen2-7B-Instruct (Li et al., 2023) | 74.3                          | 50.6       | 63.6                               | 74.8       | 89.1       | 70.5       |
| GritLM-7B (Muennighoff et al., 2024) | 76.6                          | 50.1       | 65.9                               | 76.0       | 92.4       | 72.2       |
| NV-Embed-v2 (7B) (Lee et al., 2025) | 75.4                          | 51.0       | 69.7                               | 76.5       | 94.5       | 73.4       |
|           | **Structure-Augmented RAG**      |           | **Structure-Augmented RAG**          |           |           |           |
| RAPTOR (Sarthi et al., 2024)      | 68.3                          | 48.7       | 57.8                               | 66.2       | 86.9       | 65.6       |
| HippoRAG* (GutiÃ©rrez et al., 2024) | -                             | -         | 51.9                               | 89.1       | 77.7       | -         |
| HippoRAG (reproduced)            | 44.4                          | 53.8       | 53.2                               | 90.4       | 77.3       | 63.8       |
| HippoRAG 2                       | 78.0                          | 51.7       | 74.7                               | 90.4       | 96.3       | 78.2       |{{< /table-caption >}}
> ğŸ”¼ í‘œ 3ì€ ë‹¤ì–‘í•œ RAG ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê²€ìƒ‰ ì„±ëŠ¥(passage recall@5)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì› ë…¼ë¬¸ì˜ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ëŠ” ë° * í‘œì‹œë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´, ë¹„êµ ëŒ€ìƒ êµ¬ì¡° ê¸°ë°˜ RAG ë°©ë²•ë“¤ì€ ë³¸ ë…¼ë¬¸ê³¼ ë™ì¼í•œ LLM ë° ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. GraphRAGì™€ LightRAGëŠ” íŒ¨ì‹œì§€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì œê³µí•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í‘œì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  ì¦‰, ì´ í‘œëŠ” ì—¬ëŸ¬ ê°€ì§€ RAG ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ê´€ë ¨ëœ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•´ë‚´ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€í‘œë¥¼ ì œì‹œí•˜ë©°, íŠ¹íˆ ê¸°ì¡´ ë°©ì‹ê³¼ ìƒˆë¡œìš´ êµ¬ì¡° ê¸°ë°˜ ë°©ì‹ë“¤ì„ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•˜ê²Œ í™œìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Retrieval performance (passage recall@5) on RAG benchmarks. * denotes the report from the original paper. The compared structure-augmented RAG methods are reproduced with the same LLM and retriever as ours for a fair comparison. GraphRAG and LightRAG are not presented because they do not directly produce passage retrieval results.
> </details>

{{< table-caption >}}
|       | MuSiQue | 2Wiki | HotpotQA | Avg |
| :---: | :---: | :---: | :---: | :---: |
| HippoRAG 2 | **74.7** | 90.4 | **96.3** | **87.1** |
| w/ NER to node | 53.8 | **91.2** | 78.8 | 74.6 |
| w/ Query to node | 44.9 | 65.5 | 68.3 | 59.6 |
| w/o Passage Node | 63.7 | 90.3 | 88.9 | 81.0 |
| w/o Filter | 73.0 | 90.7 | 95.4 | 86.4 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ë‹¤ì–‘í•œ ì„¤ì •ì—ì„œì˜ ë©€í‹°í™‰ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ íŒ¨ì‹œì§€ ì¬í˜„ìœ¨@5ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  HippoRAG 2ì˜ ì„±ëŠ¥ì— ëŒ€í•œ ablation study ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤.  ì—¬ëŸ¬ ê°€ì§€ êµ¬ì„± ìš”ì†Œ (NER to Node, Query to Node, Query to Triple, Passage Node, Triple Filter)ë¥¼ ì œê±°í•˜ê±°ë‚˜ ì¶”ê°€í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤Œìœ¼ë¡œì¨, ê° êµ¬ì„±ìš”ì†Œì˜ ì¤‘ìš”ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ HippoRAG 2ì˜ ê°•ê±´ì„±ê³¼ ê°œì„  ì‚¬í•­ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Ablations: passage recall@5 on multi-hop benchmarks.
> </details>

{{< table-caption >}}
| Weight | 0.01 | 0.05 | 0.1 | 0.3 | 0.5 |
|---|---|---|---|---|---| 
| MuSiQue | 79.9 | **80.5** | 79.8 | 78.4 | 77.9 |
| NQ | 75.6 | **76.9** | 76.9 | 76.7 | 76.4 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” MuSiQue ê°œë°œ ë°ì´í„° ì„¸íŠ¸ì™€ Natural Questions (NQ) ê°œë°œ ë°ì´í„° ì„¸íŠ¸ì—ì„œ íŒ¨ì‹œì§€ ë…¸ë“œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê³„ìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ ì ìš©í–ˆì„ ë•Œì˜ íŒ¨ì‹œì§€ ì¬í˜„ìœ¨@5ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë°ì´í„° ì„¸íŠ¸ì—ëŠ” 1,000ê°œì˜ ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒ¨ì‹œì§€ ë…¸ë“œì˜ ì¤‘ìš”ë„ë¥¼ ì¡°ì ˆí–ˆì„ ë•Œ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì£¼ì–´, ìµœì ì˜ ê°€ì¤‘ì¹˜ ê³„ìˆ˜ë¥¼ ì°¾ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Passage recall@5 with different weight factors for passage nodes on our MuSiQue dev set and NaturalQuestions (NQ) dev set, where each set has 1,00010001,0001 , 000 queries.
> </details>

{{< table-caption >}}
| Retriever | Dense Retrieval | HippoRAG 2 |
|---|---|---|
| GTE-Qwen2-7B-Instruct | 63.6 | **68.8** |
| GritLM-7B | 66.0 | **71.6** |
| NV-Embed-v2 (7B) | 69.7 | **74.7** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ MuSiQue í•˜ìœ„ ë°ì´í„°ì…‹ì—ì„œì˜ íŒ¨ì‹œì§€ ì¬í˜„ìœ¨@5ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. HippoRAG 2ëŠ” ë‹¤ì–‘í•œ ê³ ë°€ë„ ê²€ìƒ‰ê¸°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ê³ ë°€ë„ ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ HippoRAG 2ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬, HippoRAG 2ì˜ ê°•ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  HippoRAG 2ëŠ” ë‹¤ì–‘í•œ ê³ ë°€ë„ ê²€ìƒ‰ê¸°ì— ëŒ€í•´ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©°,  íŠ¹ì • ê³ ë°€ë„ ê²€ìƒ‰ê¸°ì— ì˜ì¡´í•˜ì§€ ì•Šê³ ë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Passage recall@5 on MuSiQue subset. HippoRAG 2 supports different dense retrievers.
> </details>

{{< table-caption >}}
| Question | NV-Embed-v2 Results | HippoRAG 2 Filtered Triples | HippoRAG 2 Results |
|---|---|---|---| 
| **Simple QA** | In what city was I.P. Paul born? | 1. I. P. Paul <br> 2. Yinka Ayefele - Early life <br> 3. Paul Parker (singer) | (**I. P. Paul**, from, **Thrissur**) <br> (**I. P. Paul**, was mayor of, Thrissur municipal corporation) | 1. I. P. Paul <br> 2. **Thrissur** <br> 3. Yinka Ayefele |
| **Multi-Hop QA** | What county is Erik Hortâ€™s birthplace a part of? | 1. Erik Hort <br> 2. Horton Park (Saint Paul, Minnesota) <br> 3. Hertfordshire | (**Erik Hort**, born in, **Montebello**) <br> (**Erik Hort**, born in, New York) | 1. Erik Hort <br> 2. Horton Park (Saint Paul, Minnesota) <br> 3. **Monstebello, New York** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ HippoRAG 2ì™€ NV-Embed-v2 ëª¨ë¸ì´ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì–´ë–»ê²Œ íŒ¨ì‹œì§€ë¥¼ ê²€ìƒ‰í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ëŒ€í‘œì ì¸ ì˜ˆì‹œë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ì§ˆë¬¸ ìœ í˜•(ë‹¨ìˆœ ì§ˆë¬¸, ë‹¤ì¤‘ í™‰ ì§ˆë¬¸)ì— ëŒ€í•´ ë‘ ëª¨ë¸ì´ ìƒìœ„ ìˆœìœ„ë¡œ ì œì‹œí•œ íŒ¨ì‹œì§€ ì œëª©ë“¤ì„ ë‚˜ì—´í•˜ê³  ìˆìŠµë‹ˆë‹¤.  íŠ¹íˆ, ì‹¤ì œ ë‹µë³€ì„ ì°¾ëŠ” ë° ê¸°ì—¬í•œ íŒ¨ì‹œì§€ ì œëª©ë“¤ì€ êµµì€ ê¸€ì”¨ì²´ë¡œ í‘œì‹œí•˜ì—¬, ê° ëª¨ë¸ì˜ ê²€ìƒ‰ ì„±ëŠ¥ê³¼ ë‹µë³€ ë„ì¶œ ê³¼ì •ì„ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ëª¨ë¸ì˜ ì¥ë‹¨ì  ë° ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ê²€ìƒ‰ ì „ëµì˜ ì°¨ì´ë¥¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: We show exemplary retrieval results (the title of passages) from HippoRAG 2 and NV-Embed-v2 on different types of questions. Bolded items denote the titles of supporting passages.
> </details>

{{< table-caption >}}
Simple QA

|       | NQ       | PopQA     | Multi-Hop QA             |                                         |  |
| :---- | :-------- | :-------- | :------------------------- | :-------------------------------------- | :- | 
| Retrieval | 40.2 / 54.9 | 28.2 / 32.5 | 17.6 / 26.1 | 36.5 / 42.8 | 37.0 / 47.3 | 4.0 / 6.0 | 3.4 / 12.9 | 29.7 / 38.4 |
| Llama-3.3-70B-Instruct |  |  |  |  |  |  |  |  |
| None | 40.2 / 54.9 | 28.2 / 32.5 | 17.6 / 26.1 | 36.5 / 42.8 | 37.0 / 47.3 | 4.0 / 6.0 | 3.4 / 12.9 | 29.7 / 38.4 |
| Contriever (Izacard et al., 2022) | 45.0 / 58.9 | 41.6 / 53.1 | 24.0 / 31.3 | 38.1 / 41.9 | 51.3 / 62.3 | 5.7 / 8.1 | 6.5 / 19.7 | 37.4 / 46.9 |
| BM25 (Robertson & Walker, 1994) | 44.7 / 59.0 | 39.1 / 49.9 | 20.3 / 28.8 | 47.9 / 51.2 | 52.0 / 63.4 | 4.0 / 5.9 | 4.4 / 18.3 | 38.0 / 47.7 |
| GTR (T5-base) (Ni et al., 2022) | 45.5 / 59.9 | 43.2 / 56.2 | 25.8 / 34.6 | 49.2 / 52.8 | 50.6 / 62.8 | 4.8 / 7.1 | 6.8 / 19.9 | 40.0 / 50.4 |
| GTE-Qwen2-7B-Instruct (Li et al., 2023) | 46.6 / 62.0 | 43.5 / 56.3 | 30.6 / 40.9 | 55.1 / 60.0 | 58.6 / 71.0 | 5.7 / 7.1 | 7.9 / 21.3 | 43.8 / 54.9 |
| GritLM-7B (Muennighoff et al., 2024) | 46.8 / 61.3 | 42.8 / 55.8 | 33.6 / 44.8 | 55.8 / 60.6 | 60.7 / 73.3 | 7.3 / 9.8 | 8.2 / 23.9 | 44.9 / 56.1 |
| NV-Embed-v2 (7B) (Lee et al., 2025) | 47.3 / 61.9 | 42.9 / 55.7 | 34.7 / 45.7 | 57.5 / 61.5 | 62.8 / 75.3 | 7.3 / 9.8 | 8.9 / 25.7 | 45.9 / 57.0 |
| RAPTOR (Sarthi et al., 2024) | 36.9 / 50.7 | 43.1 / 56.2 | 20.7 / 28.9 | 47.3 / 52.1 | 56.8 / 69.5 | 2.4 / 5.0 | 5.1 / 21.4 | 38.1 / 48.8 |
| GraphRAG (Edge et al., 2024) | 30.8 / 46.9 | 31.4 / 48.1 | 27.3 / 38.5 | 51.4 / 58.6 | 55.2 / 68.6 | 4.8 / 11.2 | 6.8 / 23.0 | 36.7 / 49.6 |
| LightRAG (Guo et al., 2024) | 8.6 / 16.6 | 2.1 / 2.4 | 0.5 / 1.6 | 9.4 / 11.6 | 2.0 / 2.4 | 0.8 / 1.0 | 1.0 / 3.7 | 4.2 / 6.6 |
| HippoRAG (GutiÃ©rrez et al., 2024) | 43.0 / 55.3 | 42.7 / 55.9 | 26.2 / 35.1 | 65.0 / 71.8 | 52.6 / 63.5 | 6.5 / 8.4 | 4.4 / 16.3 | 42.8 / 53.1 |
| HippoRAG 2 | 48.6 / 63.3 | 42.9 / 56.2 | 37.2 / 48.6 | 65.0 / 71.0 | 62.7 / 75.5 | 9.7 / 12.9 | 8.9 / 25.9 | 48.0 / 59.8 |
GPT-4o-mini
|       | NQ       | PopQA     | Multi-Hop QA             |                                         |  |
| :---- | :-------- | :-------- | :------------------------- | :-------------------------------------- | :- | 
| None | 35.2 / 52.7 | 16.1 / 22.7 | 11.2 / 22.0 | 30.2 / 36.3 | 28.6 / 41.0 | 3.2 / 5.0 | 2.7 / 14.1 | 22.6 / 33.1 |
| NV-Embed-v2 (7B) (Lee et al., 2025) | 43.5 / 59.9 | 41.7 / 55.8 | 32.8 / 46.0 | 54.4 / 60.8 | 57.3 / 71.0 | 7.3 / 10.0 | 5.1 / 24.2 | 42.9 / 55.7 |
| RAPTOR (Sarthi et al., 2024) | 37.8 / 54.5 | 41.9 / 55.1 | 27.7 / 39.2 | 39.7 / 48.4 | 50.6 / 64.7 | 5.6 / 9.2 | 5.4 / 20.9 | 36.0 / 52.6 |
| GraphRAG (Edge et al., 2024) | 38.0 / 55.5 | 30.7 / 51.3 | 27.0 / 42.0 | 45.7 / 61.0 | 51.4 / 67.6 | 4.9 / 11.0 | 5.4 / 20.9 | 36.0 / 52.6 |
| LightRAG (Guo et al., 2024) | 2.8 / 15.4 | 1.9 / 14.8 | 2.0 / 9.3 | 2.5 / 12.1 | 9.9 / 20.2 | 0.9 / 5.0 | 1.0 / 9.0 | 3.6 / 13.9 |
| HippoRAG (GutiÃ©rrez et al., 2024) | 37.2 / 52.2 | 42.5 / 56.2 | 24.0 / 35.9 | 59.4 / 67.3 | 46.3 / 60.0 | 4.8 / 7.6 | 2.1 / 16.1 | 38.9 / 51.2 |
| HippoRAG 2 | 43.4 / 60.0 | 41.7 / 55.7 | 35.0 / 49.3 | 60.5 / 69.7 | 56.3 / 71.1 | 10.5 / 14.0 | 5.8 / 25.2 | 44.3 / 58.1 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 8ì€ ë‹¤ì–‘í•œ RAG ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µ ì„±ëŠ¥(EM/F1 ì ìˆ˜)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  'No retrieval'ì€ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ê¸°ë°˜ ì§€ì‹ë§Œ í‰ê°€í•œ ê²°ê³¼ì…ë‹ˆë‹¤. HippoRAGì™€ HippoRAG 2ëŠ” OpenIE(3ì¤‘ í•„í„°ë§) ë° ì§ˆì˜ì‘ë‹µì— ì§€ì •ëœ LLMì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  í‘œëŠ” ê° ë²¤ì¹˜ë§ˆí¬(ë‹¨ìˆœ QA, ë‹¤ì¤‘ í™‰ QA, ë‹´í™” ì´í•´)ì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²•(ê¸°ë³¸ ê²€ìƒ‰, ëŒ€ê·œëª¨ ì„ë² ë”© ëª¨ë¸, êµ¬ì¡° ê¸°ë°˜ RAG)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ HippoRAG 2ì˜ ìš°ìˆ˜ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: QA performance (EM / F1 scores) on RAG benchmarks. No retrieval means evaluating the parametric knowledge of the readers. HippoRAG (and HippoRAG 2) uses the denoted LLM for OpenIE (triple filtering) and QA reading.
> </details>

{{< table-caption >}}
|       | Simple       |             | Multi-hop        |             |             |             |       |
| :---- | :-----------: | :----------: | :-------------: | :----------: | :----------: | :----------: | :---- |
|       | NQ           | PopQA        | MuSiQue         | 2Wiki        | HotpotQA     | Avg          |       |
| Simple Baselines |              |              |              |              |              |              |       |
| Contriever (Izacard et al., 2022) | 29.1 / 54.6 | 27.0 / 43.2 | 34.8 / 46.6 | 46.6 / 57.5 | 58.4 / 75.3 | 39.2 / 55.4 |       |
| BM25 (Robertson & Walker, 1994) | 28.2 / 56.1 | 24.0 / 35.7 | 32.4 / 43.5 | 55.3 / 65.3 | 57.3 / 74.8 | 39.4 / 55.1 |       |
| GTR (T5-base) (Ni et al., 2022) | 35.0 / 63.4 | 40.1 / 49.4 | 37.4 / 49.1 | 60.2 / 67.9 | 59.3 / 73.9 | 46.4 / 60.7 |       |
| Large Embedding Models |              |              |              |              |              |              |       |
| GTE-Qwen2-7B-Instruct (Li et al., 2023) | 44.7 / 74.3 | 47.7 / 50.6 | 48.1 / 63.6 | 66.7 / 74.8 | 75.8 / 89.1 | 56.6 / 70.5 |       |
| GritLM-7B (Muennighoff et al., 2024) | 46.2 / 76.6 | 44.0 / 50.1 | 49.7 / 65.9 | 67.3 / 76.0 | 79.2 / 92.4 | 57.3 / 72.2 |       |
| NV-Embed-v2 (7B) (Lee et al., 2025) | 45.3 / 75.4 | 45.3 / 51.0 | 52.7 / 69.7 | 67.1 / 76.5 | 84.1 / 94.5 | 58.9 / 73.4 |       |
| Structure-augmented RAG |              |              |              |              |              |              |       |
| RAPTOR (GPT-4o-mini) | 40.5 / 69.4 | 37.2 / 48.1 | 49.1 / 61.0 | 58.4 / 66.0 | 78.6 / 90.2 | 52.8 / 67.0 |       |
| RAPTOR (Llama-3.3-70B-Instruct) | 40.3 / 68.3 | 40.2 / 48.7 | 47.0 / 57.8 | 58.3 / 66.2 | 76.8 / 86.9 | 52.5 / 65.6 |       |
| HippoRAG* (GutiÃ©rrez et al., 2024) | -           | -           | 40.9 / 51.9 | 70.7 / 89.1 | -           | -           |       |
| HippoRAG (GPT-4o-mini) | 21.6 / 45.1 | 36.5 / 52.2 | 41.8 / 52.4 | 68.4 / 87.0 | 60.1 / 78.5 | 45.7 / 63.0 |       |
| HippoRAG (Llama-3.3-70B-Instruct) | 21.3 / 44.4 | 40.0 / 53.8 | 41.2 / 53.2 | 71.9 / 90.4 | 60.4 / 77.3 | 47.0 / 63.8 |       |
| HippoRAG 2 (GPT-4o-mini) | 44.4 / 76.4 | 43.5 / 52.2 | 53.5 / 74.2 | 74.6 / 90.2 | 80.5 / 95.7 | 59.3 / 77.7 |       |
| HippoRAG 2 (Llama-3.3-70B-Instruct) | 45.6 / 78.0 | 43.9 / 51.7 | 56.1 / 74.7 | 76.2 / 90.4 | 83.5 / 96.3 | 61.1 / 78.2 |       |{{< /table-caption >}}
> ğŸ”¼ í‘œ 9ëŠ” ë‹¤ì–‘í•œ RAG ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ íŒ¨ì‹œì§€ ì¬í˜„ìœ¨(@2 ë° @5)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì› ë…¼ë¬¸ì˜ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ë„ë¡ LLM ë° ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ HippoRAG ê²°ê³¼ë¥¼ ì¬í˜„í–ˆìŠµë‹ˆë‹¤. í‘œëŠ” ë‹¨ìˆœ QA, ë‹¤ì¤‘ í™‰ QA ë° ë‹´í™” ì´í•´ ì‘ì—…ì— ëŒ€í•œ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. ë‹¨ìˆœ QAëŠ” ê°œë³„ ì—”í‹°í‹°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ëŠ” ì§ˆë¬¸ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´, ë‹¤ì¤‘ í™‰ QAëŠ” ë‹µì„ ì–»ê¸° ìœ„í•´ ì—¬ëŸ¬ ì •ë³´ ì¡°ê°ì„ ì—°ê²°í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ë‹´í™” ì´í•´ëŠ” ê¸´ ì„œìˆ ì„ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ê¸°ì¤€ ë°©ë²•(BM25, Contriever, GTR ë“±), ëŒ€ê·œëª¨ ì„ë² ë”© ëª¨ë¸, ê·¸ë¦¬ê³  êµ¬ì¡°ë¥¼ ê°•í™”í•œ ë‹¤ë¥¸ RAG ë°©ë²•(RAPTOR, GraphRAG, LightRAG ë“±)ê³¼ HippoRAGì™€ HippoRAG 2ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.  HippoRAG 2ëŠ” ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì „ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ í–¥ìƒëœ ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Passage recall@2 / @5 on RAG benchmarks. * denotes the report from the original paper while we reproduce the HippoRAG results with aligned LLM and retriever.
> </details>

{{< table-caption >}}
## Table 1: Statistics of the knowledge graphs constructed from different datasets

|   | NQ | PopQA | MuSiQue | 2Wiki | HotpotQA | LV-Eval | NarrativeQA |
|---|---|---|---|---|---|---|---| 
| **Llama-3.3-70B-Instruct** |  |  |  |  |  |  |  |
| # of phrase nodes | 68,375 | 76,539 | 85,288 | 44,004 | 81,200 | 175,195 | 9,224 |
| # of passage nodes | 9,633 | 8,676 | 11,656 | 6,119 | 9,811 | 22,849 | 4,111 |
| # of total nodes | 78,008 | 85,215 | 96,944 | 50,123 | 91,011 | 198,044 | 13,335 |
| # of extracted edges | 125,777 | 124,579 | 140,830 | 68,881 | 130,058 | 314,324 | 26,208 |
| # of synonym edges | 899,031 | 845,014 | 1,125,951 | 593,298 | 994,187 | 2,674,833 | 72,494 |
| # of context edges | 126,757 | 118,909 | 132,586 | 64,132 | 122,437 | 375,424 | 33,395 |
| # of total edges | 1,151,565 | 1,088,502 | 1,399,367 | 726,311 | 1,246,682 | 3,364,581 | 132,097 |
| **GPT-4o-mini** |  |  |  |  |  |  |  |
| # of phrase nodes | 86,904 | 85,744 | 101,641 | 49,544 | 95,105 | 217,085 | 15,365 |
| # of passage nodes | 9,633 | 8,676 | 11,656 | 6,119 | 9,811 | 22,849 | 4,111 |
| # of total nodes | 96,537 | 94,420 | 113,297 | 55,663 | 104,916 | 239,934 | 19,476 |
| # of extracted edges | 114,900 | 108,989 | 125,903 | 62,626 | 119,630 | 303,491 | 24,373 |
| # of synonym edges | 1,094,651 | 901,528 | 1,304,605 | 715,763 | 1,126,501 | 3,268,084 | 14,075 |
| # of context edges | 142,419 | 127,568 | 146,293 | 68,348 | 133,220 | 404,210 | 38,632 |
| # of total edges | 1,351,970 | 1,144,082 | 1,576,801 | 846,737 | 1,379,351 | 3,975,785 | 77,080 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 10ì€ OpenIE(Open Information Extraction)ì— ì‚¬ìš©ëœ ë‘ ê°€ì§€ ë‹¤ë¥¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì§€ì‹ ê·¸ë˜í”„ì˜ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  OpenIEëŠ” ë¹„ì •í˜• í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°(ì¦‰, íŠ¸ë¦¬í”Œ)ë¥¼ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ í‘œëŠ” ê° LLM(Llama-3.3-70B-Instruct ë° GPT-40-mini)ì— ëŒ€í•´ ê³ ìœ í•œ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ëœ ë‹¤ì–‘í•œ ì§€ì‹ ê·¸ë˜í”„ ìš”ì†Œì˜ ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ê° LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ êµ¬ë¬¸ ë…¸ë“œ, êµ¬ì ˆ ë…¸ë“œ, ì´ ë…¸ë“œ ìˆ˜, ì¶”ì¶œëœ ì—ì§€, ë™ì˜ì–´ ì—ì§€, ë¬¸ë§¥ ì—ì§€ ë° ì´ ì—ì§€ ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë‘ ê°€ì§€ ë‹¤ë¥¸ LLMì´ ì–´ë–»ê²Œ ë‹¤ë¥¸ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ê° ê·¸ë˜í”„ì˜ í¬ê¸°ì™€ ë³µì¡ì„±ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(NQ, PopQA, MuSiQue, 2Wiki, HotpotQA, LV-Eval ë° NarrativeQA)ì— ëŒ€í•œ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Knowledge graph statistics using different LLMs for OpenIE. The nodes and triples are counted based on unique values.
> </details>

{{< table-caption >}}
| Query | Answer | Supporting Passages (Title) | Retrieved Passages (Title) | Query to Triple (Top-5) | Filtered Triple |
|---|---|---|---|---|---| 
| "Where is the district that the person who wanted to reform and address Bernhard Lichtenbergâ€™s religion preached a sermon on Marian devotion before his death located?" | Saxony-Anhalt | 1. Mary, mother of Jesus 2. Reformation 3. Wittenberg (district) 4. Bernhard Lichtenberg | 1. Bernhard Lichtenberg 2. Mary, mother of Jesus 3. Ambroise-Marie CarrÃ© 4. Reformation 5. Henry Scott Holland (Recall@5 is 0.75) | ("Bernhard Lichtenberg", "was", "Roman Catholic Priest")<br>("Bernhard Lichtenberg", "beatified by", "Catholic Church")<br>("Bernhard Lichtenberg", "died on", "5 November 1943")<br>("Catholic Church", "beatified", "Bernhard Lichtenberg")<br>("Bernhard Lichtenberg", "was", "Theologian")<br>All above subjects and objects appear in supporting passages | Empty |
| "Who is the grandmother of Philippe, Duke of OrlÃ©ans?" | Marie deâ€™ Medici | 1. Philippe I, Duke of OrlÃ©ans 2. Leonora Dori | 1. Philippe I, Duke of OrlÃ©ans 2. Louise Ã‰lisabeth dâ€™OrlÃ©ans 3. Philip III of Spain 4. Anna of Lorraine 5. Louis Philippe I (Recall@5 is 0.5) | ("Bank of America", "purchased", "Fleetboston Financial")<br>("Fleetboston Financial", "was acquired by", "Bank of America")<br>("Bank of America", "acquired", "Fleetboston Financial")<br>("Bank of America", "announced purchase of", "Fleetboston Financial")<br>("Bank of America", "merged with", "Fleetboston Financial")<br>All above subjects and objects appear in supporting passages | ("Bank of America", "purchased", "Fleetboston Financial")<br>("Fleetboston Financial", "was acquired by", "Bank of America")<br>All above subjects and objects appear in supporting passages |{{< /table-caption >}}
> ğŸ”¼ í‘œ 11ì€ MuSiQue ë°ì´í„°ì…‹ì—ì„œ passage recall@5ê°€ 1.0 ë¯¸ë§Œì¸ ë‘ ê°€ì§€ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. passage recall@5ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” ìƒìœ„ 5ê°œì˜ íŒ¨ì‹œì§€ ì¤‘ ì‹¤ì œë¡œ ë‹µë³€ì„ í¬í•¨í•˜ëŠ” íŒ¨ì‹œì§€ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ í‘œëŠ” HippoRAG 2 ëª¨ë¸ì´ ì–´ë–¤ ì§ˆë¬¸ ìœ í˜•ì—ì„œëŠ” ìƒìœ„ 5ê°œ íŒ¨ì‹œì§€ì— ì •ë‹µì„ í¬í•¨í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œì´ë©°, ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•œ ë¶„ì„ì— í™œìš©ë©ë‹ˆë‹¤. ê° ì˜ˆì‹œëŠ” ì§ˆë¬¸, ì •ë‹µ, ê´€ë ¨ íŒ¨ì‹œì§€ ì œëª©, ìƒìœ„ 5ê°œ íŒ¨ì‹œì§€ ì¤‘ ì •ë‹µì„ í¬í•¨í•˜ëŠ” íŒ¨ì‹œì§€ì˜ ê°œìˆ˜, í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì˜¤ë¥˜ ì›ì¸ ë¶„ì„ ë° ì„±ëŠ¥ í–¥ìƒ ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: Two examples from MuSiQue where passage recall@5 is less than 1.0.
> </details>

{{< table-caption >}}
|---|---|---|---|---|
| **Input Tokens** | <span class="ltx_text ltx_font_bold" style="font-size:90%;">HippoRAG 2</span> 9.2M (100.0%) | <span class="ltx_text ltx_font_bold" style="font-size:90%;">RAPTOR</span> 1.7M (18.5%) | <span class="ltx_text ltx_font_bold" style="font-size:90%;">LightRAG</span> 68.5M (744.6%) | <span class="ltx_text ltx_font_bold" style="font-size:90%;">GraphRAG</span> 115.5M (1255.4%) |
| **Output Tokens** | 3.0M (100.0%) | 0.2M (6.7%) | 18.3M (610.0%) | 36.1M (1203.3%) |{{< /table-caption >}}
> ğŸ”¼ í‘œ 12ëŠ” ë‹¤ì–‘í•œ êµ¬ì¡°ì  ì¦ê°• RAG ê¸°ë²•ë“¤ì„ ì‚¬ìš©í•˜ì—¬ MuSiQue ë§ë­‰ì¹˜(11,656ê°œ ë¬¸ë‹¨)ë¥¼ ìƒ‰ì¸í•˜ëŠ” ë° ì‚¬ìš©ëœ í† í° ìˆ˜ì™€ ìƒëŒ€ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  HippoRAG 2, RAPTOR, LightRAG, GraphRAG ë„¤ ê°€ì§€ ë°©ë²•ì˜ ì…ë ¥ í† í° ìˆ˜ì™€ ì¶œë ¥ í† í° ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ ê° ë°©ë²•ì˜ í† í° íš¨ìœ¨ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ê° ëª¨ë¸ì˜ ìƒ‰ì¸ ê³¼ì •ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì˜ ì°¨ì´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: Token usage of different structure-augmented RAG methods for indexing the MuSiQue corpus (11,6561165611,65611 , 656 passages) and their relative proportions.
> </details>

{{< table-caption >}}
| Hyperparameter | Value |
|---|---| 
| Synonym Threshold | 0.8 |
| Damping Factor of PPR | 0.5 |
| Temperature | 0.0 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 13ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” HippoRAG 2 ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ì„¤ì •ê°’ë“¤ë¡œ,  ì´ í‘œì—ì„œëŠ” Synonym Threshold (ë™ì˜ì–´ ì„ê³„ê°’), PPRì˜ Damping Factor (ê°ì‡  ê³„ìˆ˜), ê·¸ë¦¬ê³  Temperature (ì˜¨ë„) ê°’ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ê° í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ê°’ì€ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ë‚´ë„ë¡ ì‹¤í—˜ì ìœ¼ë¡œ ê²°ì •ëœ ê°’ì´ë©°, ë³¸ ë…¼ë¬¸ì˜ ì‹¤í—˜ ê²°ê³¼ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.  ì´ëŸ¬í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ë“¤ì„ í†µí•´ HippoRAG 2 ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ê³¼ì •ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Hyperparameters set on HippoRAG 2
> </details>

{{< table-caption >}}
| Hyperparameters | LightRAG | GraphRAG |
|---|---|---|
| Mode | Local | Local |
| Response Type | Short phrase | Short phrase |
| Top-k Phrases for QA | 60 | 60 |
| Chunk Token Size | 1,200 | 1,200 |
| Chunk Overlap Token Size | 100 | 100 |
| Community Report Max Length | 2,000 | - |
| Max Input Length | 8,000 | - |
| Max Cluster Size | 10 | - |
| Entity Summary Max Tokens | - | 500 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 14ëŠ” ë…¼ë¬¸ì—ì„œ LightRAGì™€ GraphRAG ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜(ëª¨ë“œ, ì‘ë‹µ ìœ í˜•, QAë¥¼ ìœ„í•œ ìƒìœ„ k êµ¬ì ˆ, ì²­í¬ í† í° í¬ê¸°, ì²­í¬ ê²¹ì¹¨ í† í° í¬ê¸°, ì»¤ë®¤ë‹ˆí‹° ë³´ê³ ì„œ ìµœëŒ€ ê¸¸ì´, ìµœëŒ€ ì…ë ¥ ê¸¸ì´, ìµœëŒ€ í´ëŸ¬ìŠ¤í„° í¬ê¸°, ì—”í‹°í‹° ìš”ì•½ ìµœëŒ€ í† í° ìˆ˜)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.  ì´ í‘œëŠ” LightRAGì™€ GraphRAGì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë¹„êµí•˜ì—¬ ë‘ ëª¨ë¸ì˜ ì°¨ì´ì ê³¼ ìœ ì‚¬ì ì„ ë³´ì—¬ì£¼ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ê° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ì¡°ì •ë˜ì—ˆìœ¼ë©°, í•´ë‹¹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì—°êµ¬ìë‚˜ ê°œë°œìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Hyperparameters set on LightRAG and GraphRAG
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}