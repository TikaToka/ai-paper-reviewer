---
title: "Smaller Language Models Are Better Instruction Evolvers"
summary: "ì†Œí˜• ì–¸ì–´ ëª¨ë¸ì´ ë” ë‚˜ì€ ëª…ë ¹ ìƒì„±ì!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Beijing University of Posts and Telecommunications",]
showSummary: true
date: 2024-12-15
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2412.11231 {{< /keyword >}}
{{< keyword icon="writer" >}} Tingfeng Hui et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2024-12-17 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2412.11231" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2412.11231" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/smaller-language-models-are-better" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

**ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹¤ì–‘í•œ ì‘ì—…ì— íš¨ê³¼ì ì´ì§€ë§Œ, ê³ í’ˆì§ˆ ëª…ë ¹ íŠœë‹ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.** ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì„ ìƒì„±í•˜ëŠ” ê²ƒì€ ì–´ë µê³  ì‹œê°„ì´ ë§ì´ ê±¸ë¦½ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” LLMì´ ë” ë‚˜ì€ ëª…ë ¹ ìƒì„± ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •í–ˆì§€ë§Œ, ì´ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ê°€ì •ì— ì˜ë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ëŠ” **ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì´ LLMë³´ë‹¤ ë” íš¨ê³¼ì ì¸ ëª…ë ¹ ìƒì„±ì**ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ ê°€ì§€ ëª…ë ¹ ìƒì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ SLMì€ **ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì„ ìƒì„±**í–ˆìŠµë‹ˆë‹¤. SLMì€ **ë” ë„“ì€ ì¶œë ¥ ê³µê°„ì„ ê°€ì§€ë¯€ë¡œ ê³¼ì‹ ë¢°ë„ê°€ ë‚®ê³  ë” ë‹¤ì–‘í•œ ëª…ë ¹ì„ ìƒì„±**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë³¸ ì—°êµ¬ì—ì„œëŠ” ëª…ë ¹ì˜ ë³µì¡ì„±ì„ ê³ ë ¤í•˜ëŠ” ìƒˆë¡œìš´ í‰ê°€ ì§€í‘œì¸ **IC-IFD(Instruction Complex-Aware IFD)**ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. IC-IFDëŠ” ëª…ë ¹ ë°ì´í„°ì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë° ìˆì–´ **ê¸°ì¡´ ì§€í‘œë³´ë‹¤ ì •í™•**í•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} SLMì€ LLMë³´ë‹¤ ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} SLMì€ LLMë³´ë‹¤ ë” ë„“ì€ ì¶œë ¥ ê³µê°„ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ê³¼ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} IC-IFDëŠ” ëª…ë ¹ ë°ì´í„°ì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ ì§€í‘œë³´ë‹¤ ë” ì •í™•í•©ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
**ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì´ ë³µì¡í•œ ëª…ë ¹ ìƒì„±ì— ìˆì–´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ ë” íš¨ê³¼ì ì¼ ìˆ˜ ìˆë‹¤ëŠ” ì **ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” SLMì´ **ë” ë„“ì€ ì¶œë ¥ ê³µê°„ê³¼ ë‚®ì€ ê³¼ì‹ ë¢°ë„**ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë˜í•œ ëª…ë ¹ì˜ ë³µì¡ì„±ì„ ê³ ë ¤í•˜ëŠ” ìƒˆë¡œìš´ í‰ê°€ ì§€í‘œì¸ **IC-IFD**ë¥¼ ì œì‹œí•˜ì—¬ ëª…ë ¹ ë°ì´í„°ì˜ íš¨ê³¼ë¥¼ ë³´ë‹¤ ì •í™•í•˜ê²Œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” **ëª…ë ¹ ë°ì´í„° ìƒì„± ë° í‰ê°€ì— ëŒ€í•œ ìƒˆë¡œìš´ ê´€ì **ì„ ì œì‹œí•˜ë©°, **LLMì˜ íš¨ìœ¨ì ì¸ í™œìš© ë° ì„±ëŠ¥ í–¥ìƒ**ì„ ìœ„í•œ  **SLM ì—°êµ¬ì˜ ì¤‘ìš”ì„±**ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2412.11231/x1.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instruct(SLM)ì™€ Llama-3.1-70B-Instruct(LLM)ë¥¼ ê° ë¼ìš´ë“œì˜ ê°ë… ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬ Llama-3-8Bì— ëŒ€í•´ ì„¸ ë²ˆì˜ ëª…ë ¹ì–´ ë°œì „ ë°˜ë³µ ë™ì•ˆì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. 4ê°€ì§€ ë²¤ì¹˜ë§ˆí¬(IFEval Pr.(S), IFEval In.(S), IFEval Pr.(L), IFEval In.(L), GSM8K, MATH, HumanEval, MBPP)ì—ì„œ SLMê³¼ LLMìœ¼ë¡œ ìƒì„±ëœ ëª…ë ¹ì–´ ë°ì´í„°ë¡œ í›ˆë ¨ëœ Llama-3-8Bì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. xì¶•ì€ ë°˜ë³µ íšŸìˆ˜(0~3)ë¥¼ ë‚˜íƒ€ë‚´ê³ , yì¶•ì€ ê° ë²¤ì¹˜ë§ˆí¬ì˜ ì„±ëŠ¥ ì ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê° ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•´ SLM ê¸°ë°˜ ëª…ë ¹ì–´ ë°ì´í„°(íŒŒë€ìƒ‰ ì‹¤ì„ )ì™€ LLM ê¸°ë°˜ ëª…ë ¹ì–´ ë°ì´í„°(ì£¼í™©ìƒ‰ ì‹¤ì„ )ì˜ ì„±ëŠ¥ ê³¡ì„ ì´ í‘œì‹œë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Comparison of performance on Llama-3-8B during three iterations of instruction evolution, using Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models for each round under Evol-Instruct scenario.
> </details>





{{< table-caption >}}
| Model | Instruction Following (IFEval) | | Math Reasoning | | Code Generation | 
|---|---|---|---|---|---|---|---|---|---| 
| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | |
| Mistral-7B-v0.3 | 19.59 | 31.77 | 22.74 | 34.65 | | 33.89 | **3.16** | | 24.39 | 6.00 |
| DeepSeek-7B | 36.23 | **48.20** | 41.04 | 52.52 | | **48.07** | 2.96 | | 28.66 | 33.00 |
| Llama-3.2-3B | 40.11 | 50.84 | 43.81 | 54.43 | | 53.75 | 6.60 | | 35.98 | **36.00** |
| Llama-3-8B | 33.83 | 46.28 | 36.41 | 49.28 | | 63.00 | 7.62 | | 43.90 | 36.20 |
| Llama-3.1-8B | 34.57 | 46.04 | 38.81 | 50.48 | | 64.22 | 11.32 | | **51.22** | 40.60 |
| InternLM-2-7B | 40.85 | 53.48 | 44.54 | 56.95 | | **68.31** | 19.50 | | 56.10 | 40.40 |
| Supervised Model: Llama-3.1-8B-Instruct||||| | | | | |
| Mistral-7B-v0.3 | **24.40** | **35.01** | **26.25** | **37.53** | | **40.18** | 2.84 | | **29.27** | **19.60** |
| DeepSeek-7B | **36.60** | 48.08 | **41.77** | **53.12** | | 47.92 | **3.56** | | **34.76** | **33.80** |
| Llama-3.2-3B | **41.59** | **53.48** | **45.66** | **57.07** | | **55.12** | **7.32** | | **39.02** | 32.80 |
| Llama-3-8B | **35.49** | **47.00** | **39.56** | **50.72** | | **63.38** | **11.44** | | **48.17** | **37.60** |
| Llama-3.1-8B | **38.45** | **50.96** | **43.81** | **55.28** | | **67.10** | **13.12** | | 48.78 | **41.60** |
| InternLM-2-7B | **43.07** | **54.80** | **47.32** | **58.39** | | 68.08 | **20.32** | | **57.93** | **40.80** |{{< /table-caption >}}

> ğŸ”¼ Llama-3.1-8B-Instruct ë° Llama-3.1-70B-Instructë¥¼ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê°ê° êµì‚¬ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì§€ì‹œ ì§„í™” ì„±ëŠ¥ì„ ì—¬ëŸ¬ ëª¨ë¸ì— ëŒ€í•´ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤. ì§€ì‹œ ë”°ë¥´ê¸°(IFEval), ìˆ˜í•™ì  ì¶”ë¡ (GSM8K, MATH), ì½”ë“œ ìƒì„±(HumanEval, MBPP)ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. í‘œì—ì„œ Pr.(S)ëŠ” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ ì ìˆ˜ë¥¼, In.(S)ëŠ” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì§€ì‹œ ì ìˆ˜ë¥¼, Pr.(L)ëŠ” í° ëª¨ë¸ì„ ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ ì ìˆ˜ë¥¼, In.(L)ëŠ” í° ëª¨ë¸ì„ ì‚¬ìš©í•œ ì§€ì‹œ ì ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under Evol-Instruct scenario.
> </details>





### In-depth insights


#### SLM Instruction Evolution
**SLM ëª…ë ¹ì–´ ì§„í™”**ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ ì‘ì€ ì–¸ì–´ ëª¨ë¸(SLM)ì´ ëª…ë ¹ì–´ ë°ì´í„°ë¥¼ ì§„í™”ì‹œí‚¤ëŠ” ë° **ë” íš¨ê³¼ì **ì´ë¼ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SLMì€ **ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì–´**ë¥¼ ìƒì„±í•˜ì—¬ í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. SLMì˜ **ë” ë„“ì€ ì¶œë ¥ ê³µê°„**ì€ LLMë³´ë‹¤ **ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ë‚®ê³  ë” ë‹¤ì–‘í•œ í† í°**ì„ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë˜í•œ **IC-IFD**ëŠ” ëª…ë ¹ì–´ ë°ì´í„°ì˜ ë³µì¡ì„±ì„ ê³ ë ¤í•˜ì—¬ **ëª…ë ¹ì–´ íŠœë‹ ì—†ì´ë„** ëª…ë ¹ì–´ ë°ì´í„°ì˜ íš¨ê³¼ë¥¼ **ë” ì •í™•í•˜ê²Œ í‰ê°€**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” SLMì´ ëª…ë ¹ì–´ ì§„í™”ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ë©°, íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ì¸ ëª…ë ¹ì–´ ë°ì´í„° ìƒì„±ì— ëŒ€í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

#### Output Space Comparison
**ì¶œë ¥ ê³µê°„ ë¹„êµ**ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì°½ì˜ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ë” í° ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ë” ë„“ì€ ì¶œë ¥ ê³µê°„ì— ì ‘ê·¼í•  ìˆ˜ ìˆì§€ë§Œ ì¶œë ¥ì´ ë” ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê³  ëœ ë‹¤ì–‘í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì‘ì€ ëª¨ë¸ì€ ì œí•œëœ ê³µê°„ì—ì„œ ì‘ë™í•˜ì§€ë§Œ ì˜ˆìƒì¹˜ ëª»í•œ ë…ì°½ì ì¸ ì¶œë ¥ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **í† í° í™•ë¥  ë¶„í¬ ë¹„êµ ë° MND(ìµœì†Œ ì´ì›ƒ ê±°ë¦¬)ì™€ ê°™ì€ ë©”íŠ¸ë¦­**ì€ ì´ëŸ¬í•œ ì°¨ì´ì ì„ ì •ëŸ‰í™”í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ì¶œë ¥ ê³µê°„ì˜ í­ê³¼ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ë‹¤ì–‘ì„± ê°„ì˜ ê· í˜•ì„ ì´í•´í•˜ëŠ” ê²ƒ**ì´ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.

#### Instruction Complexity
**ëª…ë ¹ì–´ ë³µì¡ì„±**ì€ LLM ì„±ëŠ¥ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ë³µì¡í•œ ëª…ë ¹ì–´ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ ë°œíœ˜í•˜ëŠ” ë° ë„ì›€ì´ ë˜ì§€ë§Œ ë„ˆë¬´ ë³µì¡í•œ ëª…ë ¹ì–´ëŠ” ì—­íš¨ê³¼ë¥¼ ë‚³ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” **ì‘ì€ ì–¸ì–´ ëª¨ë¸(SLM)ì´ í° ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì–´ë¥¼ ìƒì„±í•˜ëŠ” ë° ë” íš¨ê³¼ì **ì´ë¼ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. SLMì€ **ë” ë„“ì€ ì¶œë ¥ ê³µê°„**ì„ ê°€ì§€ê³  ìˆì–´ **ê³¼ì‹ í•˜ëŠ” ê²½í–¥ì´ ì ê³ ** ë‹¤ì–‘í•œ í† í°ì„ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ë˜í•œ ëª…ë ¹ì–´ì˜ ë³µì¡ì„±ì„ ê³ ë ¤í•˜ëŠ” ìƒˆë¡œìš´ ì§€í‘œì¸ **IC-IFD**ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. IC-IFDëŠ” ëª…ë ¹ì–´ íŠœë‹ ì—†ì´ ëª…ë ¹ì–´ ë°ì´í„°ì˜ íš¨ê³¼ë¥¼ ë” ì •í™•í•˜ê²Œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ LLM í›ˆë ¨ì„ ìœ„í•œ ê³ í’ˆì§ˆ ëª…ë ¹ì–´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì— ëŒ€í•œ ì‹œì‚¬ì ì„ ì œê³µí•©ë‹ˆë‹¤.

#### IC-IFD Metric
**IC-IFD(ëª…ë ¹ì–´ ë³µì¡ë„ ì¸ì‹ IFD)**ëŠ” ê¸°ì¡´ IFD ì ìˆ˜ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì œì•ˆëœ ìƒˆë¡œìš´ ì§€í‘œì…ë‹ˆë‹¤. ê¸°ì¡´ IFDëŠ” ëª…ë ¹ì–´ì˜ ì˜í–¥ë ¥ì„ ì¸¡ì •í•˜ì§€ë§Œ ëª…ë ¹ì–´ ìì²´ì˜ ë³µì¡ë„ëŠ” ê³ ë ¤í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë³µì¡í•œ ëª…ë ¹ì–´ê°€ ë†’ì€ IFD ì ìˆ˜ë¥¼ ë°›ë”ë¼ë„ ì‹¤ì œ ì„±ëŠ¥ì€ ê¸°ëŒ€ì— ëª» ë¯¸ì¹˜ëŠ” ê²½ìš°ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. IC-IFDëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ëª…ë ¹ì–´ì˜ ë‚œì´ë„ë¥¼ í˜ë„í‹° í•­ìœ¼ë¡œ ì¶”ê°€**í•©ë‹ˆë‹¤. ì¦‰, ëª…ë ¹ì–´ê°€ ë³µì¡í• ìˆ˜ë¡ IC-IFD ì ìˆ˜ëŠ” ë‚®ì•„ì§‘ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ **ëª…ë ¹ì–´ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë”ìš± ì •í™•í•˜ê²Œ í‰ê°€**í•˜ê³ , **ëª…ë ¹ì–´ íŠœë‹ ì—†ì´ë„ íš¨ê³¼ì ì¸ ëª…ë ¹ì–´ ë°ì´í„°ë¥¼ íŒë³„**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, IC-IFDëŠ” ë‹¤ì–‘í•œ ì„¤ì •ì—ì„œ ê¸°ì¡´ IFDë³´ë‹¤ ì„±ëŠ¥ ì €í•˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì™„í™”í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” IC-IFDê°€ **ë³µì¡í•œ ëª…ë ¹ì–´ì˜ ì˜í–¥ì„ ì ì ˆíˆ ë°˜ì˜**í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. IC-IFDëŠ” í–¥í›„ ëª…ë ¹ì–´ ë°ì´í„° í•©ì„± ì—°êµ¬ì— **ìƒˆë¡œìš´ ê¸°ì¤€**ì„ ì œì‹œí•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

#### SLM Potential & Limits
**ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)**ì€ **íš¨ìœ¨ì ì¸ ëª…ë ¹ì–´ ìƒì„±**ê³¼ **ë‹¤ì–‘í•œ ì¶œë ¥**ì—ì„œ ê°•ì ì„ ë³´ì…ë‹ˆë‹¤. **ë” ì ì€ ì»´í“¨íŒ… íŒŒì›Œ**ì™€ **ë‚®ì€ ì¶”ë¡  ëŠ¥ë ¥**ì—ë„ ë¶ˆêµ¬í•˜ê³ , **ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì–´ ìƒì„±**ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì´ëŠ” SLMì´ **ë” ë„“ì€ ì¶œë ¥ ê³µê°„**ì„ ê°€ì§€ê³ , **ê³¼ì í•©**ë  ê°€ëŠ¥ì„±ì´ ì ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ SLMì€ **ë§¤ìš° ì–´ë ¤ìš´ ëª…ë ¹ì–´**ë¥¼ ìƒì„±í•  ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìœ¼ë©°, **ë‹¤ì–‘í•œ ì‘ì—…**ì— ëŒ€í•œ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ, **ëª…ë ¹ì–´ ë°ì´í„°ì˜ íš¨ìœ¨ì„± í‰ê°€**ë¥¼ ìœ„í•œ **ìƒˆë¡œìš´ ì§€í‘œ** ê°œë°œì´ ì¤‘ìš”í•©ë‹ˆë‹¤. í–¥í›„ ì—°êµ¬ì—ì„œëŠ” **ë‹¤ì–‘í•œ ë„ë©”ì¸**ì—ì„œì˜ SLM ì„±ëŠ¥ê³¼ **ì „ì²´ ëª…ë ¹ì–´ ë°ì´í„° í•©ì„± ê³¼ì •**ì—ì„œì˜ ì—­í• ì„ íƒêµ¬í•´ì•¼ í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2412.11231/x2.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instruct(SLM)ì™€ Llama-3.1-70B-Instruct(LLM)ë¥¼ ê°ë… ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì„¸ ë²ˆì˜ ë°˜ë³µ ë™ì•ˆ ì§„í™”ëœ ëª…ë ¹ì–´ì˜ ë‚œì´ë„ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë¼ìš´ë“œë§ˆë‹¤ SLMì—ì„œ ìƒì„±ëœ ëª…ë ¹ì–´ ë°ì´í„°ëŠ” ë§¤ìš° ì‰¬ì›€, ì‰¬ì›€, ì¤‘ê°„, ì–´ë ¤ì›€, ë§¤ìš° ì–´ë ¤ì›€ì˜ ë‹¤ì„¯ ê°€ì§€ ë‚œì´ë„ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ê° ë§‰ëŒ€ëŠ” íŠ¹ì • ë‚œì´ë„ ë²”ì£¼ì— ì†í•˜ëŠ” ëª…ë ¹ì–´ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ SLMì´ LLMë³´ë‹¤ ë” ë³µì¡í•˜ê³  ì–´ë ¤ìš´ ëª…ë ¹ì–´ë¥¼ ìƒì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ ì„¸ ë²ˆì§¸ ë°˜ë³µì—ì„œ SLMì— ì˜í•´ ìƒì„±ëœ ëª…ë ¹ì–´ì˜ ëŒ€ë¶€ë¶„ì€ 'ë§¤ìš° ì–´ë ¤ì›€'ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ë°˜ë©´ LLMì—ì„œ ìƒì„±ëœ ëª…ë ¹ì–´ëŠ” ë‚œì´ë„ê°€ ë‚®ì€ ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Distribution of difficulty levels for instructions evolved during three iterations, using Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models for each round under Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x3.png)

> ğŸ”¼ Qwen-2.5 ì‹œë¦¬ì¦ˆ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì£¼ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë‹¤ì–‘í•œ í¬ê¸°ì˜ Qwen-2.5 ëª¨ë¸ (0.5Bì—ì„œ 72Bê¹Œì§€)ì— ëŒ€í•´ SLM-INSTì™€ LLM-INSTì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ SLMì´ ë”ìš± ë³µì¡í•˜ê³  ì–´ë ¤ìš´ ëª…ë ¹ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìì„¸í•œ ê²°ê³¼ëŠ” í‘œ 11ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Comparison of performance among Qwen-2.5 series models. Detailed results can be found in TableÂ 11.
> </details>



![](https://arxiv.org/html/2412.11231/x4.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ AutoIF ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instructì™€ Llama-3.1-70B-Instructê°€ ìƒì„±í•œ ëª…ë ¹ì–´ì— ëŒ€í•œ ìµœì†Œ ì´ì›ƒ ê±°ë¦¬ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœì†Œ ì´ì›ƒ ê±°ë¦¬ëŠ” ì„ë² ë”© ê³µê°„ì—ì„œ ëª…ë ¹ì–´ë“¤ ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•œ ê²ƒìœ¼ë¡œ, ê°’ì´ í´ìˆ˜ë¡ ë‹¤ì–‘ì„±ì´ ë†’ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œ SLM(Llama-3.1-8B-Instruct)ì´ ìƒì„±í•œ ëª…ë ¹ì–´ë“¤ì´ LLM(Llama-3.1-70B-Instruct)ë³´ë‹¤ ë” ë„“ê²Œ ë¶„í¬ë˜ì–´ ìˆì–´, SLMì´ ë” ë‹¤ì–‘í•œ ëª…ë ¹ì–´ë¥¼ ìƒì„±í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Distribution of Minimum Neighbor Distance for instructions generated by Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct in the AutoIF scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x5.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ SLM(ì‘ì€ ì–¸ì–´ ëª¨ë¸)ê³¼ LLM(í° ì–¸ì–´ ëª¨ë¸)ì´ ì¶œë ¥ í† í° í™•ë¥  ë¶„í¬ë¥¼ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. SLMì€ LLMì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ ëª…ë ¹ì–´ ì¤€ìˆ˜ ëŠ¥ë ¥ìœ¼ë¡œ ì¸í•´ ì¶œë ¥ ê³µê°„ì´ ë” ë„“ê³  ë‹¤ì–‘í•œ í† í°ì„ ìƒì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë”°ë¼ì„œ SLMì€ LLMì— ë¹„í•´ ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ëª…ë ¹ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. xì¶•ì€ í™•ë¥ ì„ ë‚˜íƒ€ë‚´ê³ , yì¶•ì€ ë°€ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Comparison of output token probability distributions in the Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x6.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì„¸ ê°€ì§€ ë°ì´í„° ì„ íƒ ë¹„ìœ¨(5%, 10%, 15%)ì—ì„œ IC-IFDì™€ IFDë¥¼ ì‚¬ìš©í•˜ì—¬ Alpaca ë°ì´í„°ì…‹ì˜ ìƒìœ„ ë¶€ë¶„ì„ ìœ ì§€í–ˆì„ ë•Œ Llama-3-8B ë° Llama-3.2-3B ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë¹„ìœ¨ì— ëŒ€í•´ IC-IFDê°€ IFDë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, IC-IFDë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ë©´ IFDë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Performance comparison of three data selection ratios on Alpaca dataset between IC-IFD and IFD.
> </details>



![](https://arxiv.org/html/2412.11231/x7.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì„¸ ê°€ì§€ ë°ì´í„° ì„ íƒ ë¹„ìœ¨(5%, 10%, 15%)ì— ëŒ€í•´ IC-IFDë¡œ í•„í„°ë§ëœ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ê³¼ ì „ì²´ Alpaca ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.2-3Bì™€ Llama-3-8B ë‘ ëª¨ë¸ì— ëŒ€í•´, IC-IFDë¡œ í•„í„°ë§ëœ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” IC-IFDê°€ íš¨ê³¼ì ìœ¼ë¡œ ê³ í’ˆì§ˆì˜ ëª…ë ¹ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Performance comparison of three data selection ratios on Alpaca dataset between IC-IFD and full dataset.
> </details>



![](https://arxiv.org/html/2412.11231/x8.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ 'ì œì•½ ì¡°ê±´ ì¶”ê°€' ì „ëµì„ ì ìš©í–ˆì„ ë•Œ LLMê³¼ SLMì´ ìƒì„±í•œ ì§€ì‹œë¬¸ì˜ ì°¨ì´ì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. LLMì€ ì£¼ì–´ì§„ 'ê±´ê°• ìœ ì§€ ìš”ë ¹ 3ê°€ì§€ ì œì‹œ' ì§€ì‹œë¬¸ì— 'ì ë‹¹í•œ ìƒí™œ ë°©ì‹ì„ ê³ ë ¤í•˜ì—¬ ê±´ê°•ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ 3ê°€ì§€ ìš”ë ¹ì„ ì œì‹œí•˜ê³ , ì´ë¥¼ ì¼ìƒì— ì–´ë–»ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•˜ë¼'ëŠ” ì¡°ê±´ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ë°˜ë©´, SLMì€ 'ìš´ë™ ì‹œê°„ì´ ì œí•œë˜ê³  ì‹ë‹¨ ì œì•½ì´ ìˆëŠ” ë°”ìœ ì¼ì •ì„ ê°€ì§„ ì‚¬ëŒì´ ì „ë°˜ì ì¸ ê±´ê°•ê³¼ ì›°ë¹™ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ê·¼ê±° ê¸°ë°˜ ìš”ë ¹ 3ê°€ì§€ë¥¼ ì œê³µí•˜ë¼'ëŠ” ë”ìš± ê¹Œë‹¤ë¡œìš´ ì¡°ê±´ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. SLMì€ ê°™ì€ ì§„í™” ì „ëµ í•˜ì—ì„œ LLMë³´ë‹¤ ë” ë³µì¡í•˜ê³  ì–´ë ¤ìš´ ì§€ì‹œë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Comparison of cases between LLMs and SLMs under adding constraints strategy.
> </details>



![](https://arxiv.org/html/2412.11231/x9.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ 'ì‹¬í™”' ì „ëµì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° LLMê³¼ SLMì´ ìƒì„±í•œ ì§€ì‹œì‚¬í•­ì˜ ì°¨ì´ì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. LLMì´ ìƒì„±í•œ ì§€ì‹œì‚¬í•­ì€ ë‹¨ìˆœíˆ ì‹œê°„ë‹¹ ìš”ê¸ˆê³¼ ì¶”ê°€ ê·¼ë¬´ ì‹œê°„ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì¶”ê°€í•˜ëŠ” ë°˜ë©´, SLMì€ í‰ì¼ê³¼ ì£¼ë§ì˜ ê°€ë³€ ì‹œê¸‰, ì¶”ê°€ ë³´ë„ˆìŠ¤, ì‹œê°„ ì œí•œ ë“± ë” ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ì¡°ê±´ì„ í¬í•¨í•˜ëŠ” ì§€ì‹œì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤. ì¦‰, SLMì€ ë™ì¼í•œ ì „ëµì—ì„œ LLMë³´ë‹¤ ë” ë³µì¡í•˜ê³  ì‹¬ì¸µì ì¸ ì§€ì‹œì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: Comparison of cases between LLMs and SLMs under deepening strategy.
> </details>



![](https://arxiv.org/html/2412.11231/x10.png)

> ğŸ”¼ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì‹¬ì¸µ ì§„í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë³µì¡í•œ ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ì—¬ ChatGPT ë° GPT-4ì™€ ê°™ì€ ìœ ëª… AI ì‹œìŠ¤í…œì´ ì²˜ë¦¬í•˜ê¸° ë” ì–´ë µê²Œ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” í•©ë¦¬ì ì´ì–´ì•¼ í•˜ê³ , ì¸ê°„ì´ ì´í•´í•˜ê³  ì‘ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì¡í•˜ê²Œ ë§Œë“œëŠ” ë°©ë²•(METHOD)ì´ ì œê³µë˜ë©°, ë‹¤ì‹œ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ê°„ê²°í•´ì•¼ í•˜ê³  ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— 10~20ë‹¨ì–´ë§Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶œë ¥ì—ëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì™€ ë‹¤ì‹œ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ ì—†ì´ ìƒˆ í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: In-depth evolution prompt template utilized in Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x11.png)

> ğŸ”¼ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë„¤ ê°€ì§€ ì‹¬ì¸µ ì§„í™” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì—ëŠ” ì œì•½ ì¡°ê±´ ì¶”ê°€, ì§ˆë¬¸ ì‹¬í™”, êµ¬ì²´í™”, ì¶”ë¡  ë‹¨ê³„ ì¶”ê°€ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì œì•½ ì¡°ê±´ ì¶”ê°€ëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ì œì•½/ìš”êµ¬ ì‚¬í•­ì„ í•˜ë‚˜ ë” ì¶”ê°€í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì‹¬í™”ëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— íŠ¹ì • ë¬¸ì œì— ëŒ€í•œ ì§ˆë¬¸ì´ í¬í•¨ëœ ê²½ìš° ì§ˆë¬¸ì˜ ê¹Šì´ì™€ í­ì„ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. êµ¬ì²´í™”ëŠ” ì¼ë°˜ì ì¸ ê°œë…ì„ ë” êµ¬ì²´ì ì¸ ê°œë…ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì¶”ë¡  ë‹¨ê³„ ì¶”ê°€ëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ëª‡ ê°€ì§€ ê°„ë‹¨í•œ ì‚¬ê³  ê³¼ì •ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê²½ìš° ëª…ì‹œì ìœ¼ë¡œ ì—¬ëŸ¬ ë‹¨ê³„ ì¶”ë¡ ì„ ìš”ì²­í•˜ë„ë¡ ë‹¤ì‹œ ì‘ì„±í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: Four in-depth methods utilized in Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x12.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë„ˆë¹„ ìš°ì„  ì§„í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì—ì„œ ì˜ê°ì„ ì–»ì–´ ì™„ì „íˆ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ëŠ” ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì™€ ê°™ì€ ë„ë©”ì¸ì— ì†í•´ì•¼ í•˜ì§€ë§Œ ë” í¬ê·€í•´ì•¼ í•©ë‹ˆë‹¤. ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ì˜ ê¸¸ì´ì™€ ë³µì¡ì„±ì€ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤. ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” í•©ë¦¬ì ì´ì–´ì•¼ í•˜ê³  ì¸ê°„ì´ë‚˜ ìµœì‹  AI ì±—ë´‡ì´ ì´í•´í•˜ê³  ì‘ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ ì—†ì´ ìƒˆ í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 12: In-breadth evolution prompt template utilized in Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x13.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ AutoIF ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Self-Instruct Seed Instructionsì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. AutoIFëŠ” ì†Œê·œëª¨ ì‹œë“œ ëª…ë ¹ì–´ ì„¸íŠ¸ì—ì„œ ì‹œì‘í•˜ì—¬ ëª¨ë¸ì˜ ëª…ë ¹ì–´ ì¤€ìˆ˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ëŒ€ê·œëª¨ì˜ ì•ˆì •ì ì¸ ëª…ë ¹ì–´ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì— í‘œì‹œëœ í”„ë¡¬í”„íŠ¸ëŠ” AutoIFì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. í…œí”Œë¦¿ì€ ëª¨ë¸ì— 50ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ëª…ë ¹ì–´ë¥¼ ì œê³µí•˜ë„ë¡ ìš”ì²­í•˜ê³  ìˆìœ¼ë©°, ê° ëª…ë ¹ì–´ëŠ” ì‘ë‹µ í˜•ì‹ì— ê´€í•œ ê²ƒì´ì–´ì•¼ í•˜ê³  Python í•¨ìˆ˜ë¡œ ì‰½ê²Œ í‰ê°€í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ëª‡ ê°€ì§€ ì‹œë“œ ëª…ë ¹ì–´ ì˜ˆì‹œì™€ ì›í•˜ì§€ ì•ŠëŠ” ëª…ë ¹ì–´ ìœ í˜• ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‘ë‹µì—ì„œ ê° ëª…ë ¹ì–´ëŠ” í•œ ì¤„ì— í•˜ë‚˜ì”© ìƒì„±ë˜ì–´ì•¼ í•˜ë©° '-'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ì‹œë“œ ëª…ë ¹ì–´ë¥¼ ë°˜ë³µí•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 13: Prompt template of Self-Instruct Seed Instructions in AutoIF scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x14.png)

> ğŸ”¼ AutoIFëŠ” ì£¼ì–´ì§„ ëª…ë ¹ì— ë”°ë¼ ì‘ë‹µì´ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ Pythonì—ì„œ í‰ê°€ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ ì—­í• ì„ í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤. ëª…ë ¹ì–´ê°€ ì£¼ì–´ì§€ë©´, ì…ë ¥ ë¬¸ìì—´ 'response'ê°€ í•´ë‹¹ ëª…ë ¹ì–´ë¥¼ ë”°ë¥´ëŠ”ì§€ í‰ê°€í•˜ëŠ” 'evaluate'ë¼ëŠ” Python í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¥´ëŠ” ê²½ìš° Trueë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‘ë‹µì€ 'func' í‚¤ì— í‰ê°€ í•¨ìˆ˜ê°€ í¬í•¨ëœ ë‹¨ì¼ JSONê³¼ 'cases' í‚¤ì— ì„¸ ê°€ì§€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ëª©ë¡ì´ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ëŠ” 'input' í‚¤ì— ì…ë ¥ê³¼ 'output' í‚¤ì— ì˜ˆìƒ ì¶œë ¥(true ë˜ëŠ” false)ì„ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 14: Prompt template of Verification Funcs and Cases Generation in AutoIF scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x15.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ Auto Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼ì–´ì§„ ëª…ë ¹ì„ ë” ë³µì¡í•œ ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ëŠ” ëª…ë ¹ ë‹¤ì‹œ ì‘ì„±ì ì—­í• ì„ LLMsì—ê²Œ ìš”ì²­í•©ë‹ˆë‹¤. 4ë‹¨ê³„ì˜ ê³„íšì„ ì„¸ìš°ê³  ì‹¤í–‰í•˜ì—¬ ì£¼ì–´ì§„ ëª…ë ¹ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“¤ê³  ìµœì¢…ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±ëœ ëª…ë ¹ì„ ì œê³µí•©ë‹ˆë‹¤. ëª…ë ¹ì˜ ì–¸ì–´ë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ì€ ì œê³µí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 15: Prompt template of Auto Evol-Instruct scenario.
> </details>



![](https://arxiv.org/html/2412.11231/x16.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì…ë ¥ì´ ì œê³µë˜ëŠ” ê²½ìš°, ì£¼ì–´ì§„ ëª…ë ¹ê³¼ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ í¬ê´„ì ì´ê³  ì •í™•í•œ ì‘ë‹µì„ ì œê³µí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ì…ë ¥ì´ ì œê³µë˜ì§€ ì•ŠëŠ” ê²½ìš°, ì£¼ì–´ì§„ ëª…ë ¹ì„ ë°”íƒ•ìœ¼ë¡œ í¬ê´„ì ì´ê³  ì •í™•í•œ ì‘ë‹µì„ ì œê³µí•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 16: Prompt template of response generation.
> </details>



![](https://arxiv.org/html/2412.11231/x17.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì£¼ì–´ì§„ ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì˜ë„ë¥¼ ì‹ë³„í•˜ê³  ì¿¼ë¦¬ì˜ ë‚œì´ë„ë¥¼ í‰ê°€í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ì‚¬ìš©ì ì¿¼ë¦¬, ì¶œë ¥ í˜•ì‹(ì‚¬ìš©ì ì˜ë„, í’€ì´ì— í•„ìš”í•œ ì§€ì‹, 'ë§¤ìš° ì‰¬ì›€', 'ì‰¬ì›€', 'ì¤‘ê°„', 'ì–´ë ¤ì›€', 'ë§¤ìš° ì–´ë ¤ì›€' ì¤‘ í•˜ë‚˜ì¸ ë‚œì´ë„), ê·¸ë¦¬ê³  ì¶œë ¥ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 17: Prompt template of evaluating the difficulty levels.
> </details>



![](https://arxiv.org/html/2412.11231/x18.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì§„í™” ê¶¤ì ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§€ì‹œ ì§„í™” ê¶¤ì ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³  í•µì‹¬ ê°œë…ì´ë‚˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ê¶¤ì ì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì§§ê³  ê°„ë‹¨í•œ êµ¬ë¬¸ì„ ë§Œë“­ë‹ˆë‹¤. ìš”ì•½ì€ ê°„ê²°í•´ì•¼ í•˜ê³  ì§„í™” ê³¼ì •ì˜ ë³¸ì§ˆì— ì´ˆì ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤. êµ¬ë¬¸ì— ë¶ˆí•„ìš”í•œ ê¸°í˜¸, êµ¬ë‘ì  ë˜ëŠ” ì„œì‹ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. ê°„ëµí•˜ê³  ëª…í™•í•œ ë©”ì„œë“œ ì„¤ëª…ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë©”ì„œë“œ ì‹œì‘ ë¶€ë¶„ì— ìˆëŠ” ìˆ«ì ë ˆì´ë¸”ì´ë‚˜ íŠ¹ìˆ˜ ì‹ë³„ìëŠ” ë¬´ì‹œí•˜ì‹­ì‹œì˜¤. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ì •ë³´ ì—†ì´ ìš”ì•½ êµ¬ë¬¸ë§Œ ì œê³µí•©ë‹ˆë‹¤. ì§€ì‹œ ì§„í™” ê¶¤ì : {TRAJECTORY}
> <details>
> <summary>read the caption</summary>
> Figure 18: Prompt template of extracting the keywords from evolution trajectories.
> </details>



![](https://arxiv.org/html/2412.11231/x19.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ë‚œì´ë„ ì ìˆ˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì—ê²Œ ì£¼ì–´ì§„ ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ì˜ë„ë¥¼ ë¨¼ì € ì‹ë³„í•œ ë‹¤ìŒ, ì¿¼ë¦¬ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 0ì—ì„œ 100ê¹Œì§€ì˜ ë‚œì´ë„ ì ìˆ˜ë¥¼ ë§¤ê¸°ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ì¶œë ¥ì€ ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ê¸°í˜¸ ì—†ì´ ë‚œì´ë„ ì ìˆ˜ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 19: Prompt template of evaluating the difficulty scores.
> </details>



![](https://arxiv.org/html/2412.11231/x20.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‘ AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì„ ë¹„êµí•˜ì—¬ ìŠ¹íŒ¨ë¥¼ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‘ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ì‘ë‹µì´ ì£¼ì–´ì§€ë©´, í‰ê°€ìëŠ” ì‘ë‹µì´ ì‚¬ìš©ìì˜ ìš”êµ¬ì— ì–¼ë§ˆë‚˜ ì˜ ë¶€í•©í•˜ëŠ”ì§€, ê°„ê²°í•˜ê³  ì •í™•í•œì§€, ë¶ˆí•„ìš”í•œ ì •ë³´ ì—†ì´ í¬ê´„ì ì¸ì§€, ë…¼ë¦¬ì ì¸ íë¦„ì„ ë”°ë¥´ëŠ”ì§€, ì •í™•í•œ ê¸°ìˆ  ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€, ì‚¬ì‹¤ì ìœ¼ë¡œ ì •í™•í•˜ê³  ê°ê´€ì ì¸ì§€ ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ ì¤„ì—ëŠ” ì–´ë–¤ ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ë” ë‚˜ì€ì§€, í˜¹ì€ ë™ë“±í•œì§€ ë‹¨ì¼ ë ˆì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 20: Prompt template of evaluating the win-tie-lose rates.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |
|---|---|---|---|---|---|---|---|
|       | Pr.(S) | In.(S) | Pr.(L) | In.(L) |   | GSM8K | MATH |   | HumanEval | MBPP |
|---|---|---|---|---|---|---|---|---|---|---| 
| **Supervised Model: Qwen-2-72B-Instruct** | | | | | | | | | |
| Mistral-7B-v0.3 | 20.15 | 30.94 | 23.84 | 34.41 |   | 46.93 | **3.26** |   | 32.32 | 1.80 |
| DeepSeek-7B | 35.67 | 47.12 | **39.56** | 50.84 |   | 44.81 | 2.76 |   | **36.59** | **34.00** |
| Llama-3.2-3B | 39.74 | 51.44 | 43.99 | 55.40 |   | 53.83 | **7.40** |   | 38.41 | 31.00 |
| Llama-3-8B | 34.75 | 45.80 | 37.71 | 48.92 |   | 63.76 | **10.06** |   | 43.90 | 35.40 |
| Llama-3.1-8B | **36.41** | **47.60** | 39.00 | 50.60 |   | 65.43 | 10.84 |   | **48.17** | 38.40 |
| InternLM-2-7B | 41.96 | 53.60 | 43.99 | 55.64 |   | 65.28 | 17.96 |   | 56.71 | 40.60 |
| **Supervised Model: Qwen-2-7B-Instruct** | | | | | | | | | |
| Mistral-7B-v0.3 | **25.32** | **37.17** | **29.76** | **41.01** |   | **47.31** | 2.20 |   | **32.93** | **12.00** |
| DeepSeek-7B | **36.41** | **48.56** | 39.37 | **51.32** |   | **48.07** | **3.82** |   | 35.37 | 33.20 |
| Llama-3.2-3B | **43.81** | **55.16** | **47.87** | **58.27** |   | **56.56** | 7.18 |   | **39.63** | **31.40** |
| Llama-3-8B | **38.92** | **48.33** | **43.81** | **52.19** |   | **63.91** | 8.66 |   | **45.73** | **38.40** |
| Llama-3.1-8B | 34.75 | 45.80 | **39.93** | **51.08** |   | **68.76** | **14.02** |   | 46.34 | **38.60** |
| InternLM-2-7B | **44.12** | **55.16** | **48.62** | **58.73** |   | **66.87** | **19.60** |   | **58.54** | **41.40** |{{< /table-caption >}}
> ğŸ”¼ Qwen-2-7B-Instruct(SLM)ì™€ Qwen-2-72B-Instruct(LLM)ë¥¼ Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì§€ë„ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤.  IFEval, FollowBench, GSM8K, MATH, HumanEval, MBPP ë“± ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„±ëŠ¥ì„ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤.  Pr.(S)ì™€ In.(S)ëŠ” ê°ê° ì‘ì€ ëª¨ë¸ë¡œ ìƒì„±í•œ ëª…ë ¹ê³¼ ì§€ì‹œì— ëŒ€í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ë©°, Pr.(L)ê³¼ In.(L)ëŠ” í° ëª¨ë¸ì— ëŒ€í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Comparison of performance with Qwen-2-7B-Instruct and Qwen-2-72B-Instruct as supervised models under Evol-Instruct scenario.
> </details>

{{< table-caption >}}
| Model | IFEval | | | | FollowBench (HSR) | | | | | Common Abilities | |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---| 
| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | Level 1 | Level 2 | Level 3 | Level 4 | Level 5 | Avg. | | C-Eval | MMLU | HumanEval | GSM8K |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---| 
| *Supervision Model: Llama-3.1-70B-Instruct* | | | | | | | | | | | | | | | |
| Llama-3.2-3B | 40.85 | 51.92 | 42.33 | 53.84 | | **61.17** | 57.59 | **50.55** | 33.09 | 26.74 | 45.83 | | **41.37** | **52.65** | **29.88** | 27.07 |
| Llama-3-8B | 37.71 | 50.00 | 39.19 | 52.04 | | 49.64 | 46.60 | 41.56 | 27.05 | 22.37 | 37.44 | | 41.87 | 51.14 | 26.83 | 37.76 |
| Llama-3.1-8B | 41.96 | 53.36 | 42.70 | 54.20 | | 51.77 | 45.60 | 45.04 | 34.85 | 26.61 | 40.78 | | **44.50** | 56.39 | 31.10 | 38.21 |
| Qwen-2-7B | 41.96 | 53.60 | 43.62 | 55.64 | | 72.18 | 62.45 | **56.43** | 41.31 | 35.42 | 53.56 | | **81.08** | 55.71 | 57.32 | **79.68** |
| Qwen-2.5-7B | 49.17 | **60.31** | 50.46 | 61.51 | | **78.88** | **73.78** | **61.50** | 51.99 | 45.42 | **62.31** | | **80.46** | 58.39 | 67.68 | **85.90** |
| InternLM-2-7B | 46.21 | 56.71 | 48.06 | 58.63 | | 68.89 | 62.23 | 54.17 | 44.27 | 42.06 | 54.33 | | 60.11 | 60.59 | 65.35 | 50.00 |
| *Supervision Model: Llama-3.1-8B-Instruct* | | | | | | | | | | | | | | | |
| Llama-3.2-3B | **43.62** | **54.20** | **46.95** | **57.07** | | 56.95 | **61.46** | 50.20 | **37.65** | **34.16** | **48.08** | | 40.56 | 49.08 | 25.00 | **29.87** |
| Llama-3-8B | **41.04** | **51.32** | **42.88** | **53.11** | | **62.99** | **54.38** | **49.29** | **32.21** | **32.21** | **46.21** | | **43.49** | **55.63** | **37.20** | **45.26** |
| Llama-3.1-8B | **42.51** | **54.92** | **44.73** | **56.71** | | **63.99** | **58.15** | **53.29** | **39.49** | **36.02** | **50.19** | | 43.77 | **58.32** | **32.32** | **47.92** |
| Qwen-2-7B | **44.92** | **55.76** | **47.50** | **58.39** | | **78.75** | **63.30** | 52.31 | **50.28** | **43.08** | **57.54** | | 80.11 | **56.84** | **65.24** | 79.53 |
| Qwen-2.5-7B | **50.09** | 59.59 | **52.50** | **61.75** | | 77.86 | 70.22 | 59.86 | **53.35** | **47.18** | 61.69 | | 79.74 | **60.17** | **72.56** | 84.69 |
| InternLM-2-7B | **47.50** | **57.67** | **50.83** | **61.15** | | **74.73** | **66.16** | **61.94** | **54.10** | **46.28** | **60.64** | | **63.03** | **63.16** | **70.96** | **54.27** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” AutoIF ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instructì™€ Llama-3.1-70B-Instructë¥¼ ì§€ë„ ëª¨ë¸ë¡œ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. AutoIFëŠ” ì†Œìˆ˜ì˜ ì´ˆê¸° ì§€ì¹¨ì—ì„œ ëŒ€ê·œëª¨ì˜ ì•ˆì •ì ì¸ ì§€ì¹¨ì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. í‘œì—ì„œ Pr.(S) ë° In.(S)ëŠ” ê°ê° ì‘ì€ ëª¨ë¸(Llama-3.1-8B-Instruct)ë¡œ ì§€ë„ í•™ìŠµëœ ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ ë° ì§€ì¹¨ ìˆ˜ì¤€ì—ì„œì˜ IFEval ì •í™•ë„ë¥¼ ë‚˜íƒ€ë‚´ê³ , Pr.(L) ë° In.(L)ì€ í° ëª¨ë¸(Llama-3.1-70B-Instruct)ë¡œ ì§€ë„ í•™ìŠµëœ ëª¨ë¸ì˜ IFEval ì •í™•ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. FollowBench(HSR) ì—´ì€ ë‹¤ì„¯ ê°€ì§€ ë‚œì´ë„ ìˆ˜ì¤€(1-5)ê³¼ í‰ê·  HSR(Hard Satisfaction Rate)ì„ ë³´ì—¬ì£¼ë©°, Common Abilities ì—´ì€ C-Eval, MMLU, HumanEval, GSM8Kì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ SLMê³¼ LLMì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under AutoIF scenario.
> </details>

{{< table-caption >}}
| Model | Instruction Following (IFEval) | | | | | Math Reasoning | | | Code Generation | |
|---|---|---|---|---|---|---|---|---|---|---| 
| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP | 
|---|---|---|---|---|---|---|---|---|---|---| 
| Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | | 
| Llama-3.2-3B | 36.60 | 48.68 | 39.00 | 51.08 | | 53.60 | 7.56 | | 35.37 | 33.00 | 
| Llama-3-8B | 35.86 | 47.60 | 38.63 | 50.24 | | 63.91 | 9.18 | | 38.41 | 32.40 | 
| Llama-3.1-8B | 36.97 | 47.60 | 40.30 | 51.08 | | 66.11 | 11.68 | | 40.85 | **40.40** | 
| Supervised Model: Llama-3.1-8B-Instruct | | | | | | | | | | | 
| Llama-3.2-3B | **45.47** | **57.43** | **50.28** | **61.27** | | **56.48** | **8.42** | | **38.41** | **34.40** | 
| Llama-3-8B | **37.34** | **49.64** | **39.74** | **51.56** | | **67.40** | **12.26** | | **43.90** | **34.80** | 
| Llama-3.1-8B | **38.08** | **49.76** | **40.48** | **52.40** | | **69.52** | **15.62** | | **51.22** | 38.80 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Auto Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instructì™€ Llama-3.1-70B-Instructë¥¼ ì§€ë„ ëª¨ë¸ë¡œ ì‚¬ìš©í•œ ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Auto Evol-InstructëŠ” ì£¼ì–´ì§„ ëª…ë ¹ì„ ë” ë³µì¡í•œ ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ëŠ” ëª…ë ¹ ì¬ì‘ì„±ê¸°ì…ë‹ˆë‹¤. í‘œì—ì„œ SLM(Llama-3.1-8B-Instruct)ì€ LLM(Llama-3.1-70B-Instruct)ë³´ë‹¤ ë” íš¨ê³¼ì ì¸ ëª…ë ¹ì„ ìë™ìœ¼ë¡œ ì§„í™”ì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under Auto Evol-Instruct scenario.
> </details>

{{< table-caption >}}
| Metrics | IFEval | | | |
|---|---|---|---|---| 
| | Pr.(S) | In.(S) | Pr.(L) | In.(L) |
| Original | 33.09 | 44.72 | 36.41 | 48.32 |
| Instruction Len. | 29.94 | 39.69 | 33.83 | 43.53 |
| Instruction PPL | 27.91 | 39.69 | 32.35 | 44.36 |
| IFD | 30.87 | 43.53 | 36.04 | 47.60 |
| IC-IFD | **34.01** | **46.16** | **38.82** | **50.72** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Llama-3-8B ëª¨ë¸ì—ì„œ SLMìœ¼ë¡œ ìƒì„±ëœ Alpaca-iter3 ë°ì´í„°ì˜ 25%ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ë¹„êµí•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ëª…ë ¹ ê¸¸ì´, ëª…ë ¹ PPL, IFD ë° IC-IFDì™€ ê°™ì€ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  Llama-3-8Bì—ì„œ IFEval ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ IC-IFDê°€ ëª…ë ¹ ë³µì¡ë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë‹¤ë¥¸ ë©”íŠ¸ë¦­ë³´ë‹¤ ë” ì •í™•í•œ ë°ì´í„° í’ˆì§ˆ í‰ê°€ë¥¼ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Comparison of different metrics under 25% of Alpaca-iter3 evolved by SLMs on Llama-3-8B.
> </details>

{{< table-caption >}}
| Hyperparameter | Value |
|---|---| 
| Learning Rate | 2 Ã— 10â»âµ |
| Number of Epochs | 3 |
| Number of Devices | 8 |
| Per-device Batch Size | 1 |
| Gradient Accumulation Steps | 8 |
| Learning Rate Scheduler | cosine |
| Warmup Ratio | 0.03 |
| Max Sequence Length | 2048 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct, AutoIF, Auto Evol-Instruct ì„¸ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¼ë°˜ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œëŠ” epoch ìˆ˜, ë””ë°”ì´ìŠ¤ ìˆ˜, ë°°ì¹˜ í¬ê¸°, ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ë‹¨ê³„, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, ì›œì—… ë¹„ìœ¨, ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ìˆìŠµë‹ˆë‹¤. LoRA í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œëŠ” LoRA Rank, LoRA Alpha, LoRA Target, LoRA Dropoutì´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Hyperparameters utilized in Evol-Instruct, AutoIF and Auto Evol-Instruct scenarios.
> </details>

{{< table-caption >}}
| Hyperparameter | Value |
|---|---| 
| **General Hyperparameters** | |
| Number of Epochs | 2 |
| Number of Devices | 8 |
| Per-device Batch Size | 1 |
| Gradient Accumulation Steps | 8 |
| Learning Rate Scheduler | cosine |
| Warmup Ratio | 0.03 |
| Max Sequence Length | 2048 |
| **LoRA Hyperparameters** |  |
| LoRA Rank | 8 |
| LoRA Alpha | 8 |
| LoRA Target | all module |
| LoRA Dropout | 0.0 |
| **Qwen-2.5-0.5B and 1.5B** | |
| Learning Rate | 1e-5 |
| **Qwen-2.5-3B and 7B** | |
| Learning Rate | 7e-6 |
| **Qwen-2.5-14B, 32B and 72B** | |
| Learning Rate | 5e-5 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Qwen-2.5 ì‹œë¦¬ì¦ˆ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ í•™ìŠµë¥ ê³¼ LoRA ì ìš© ì—¬ë¶€ê°€ ë‹¤ë¦…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Hyperparameters utilized for fine-tuning Qwen-2.5 series models.
> </details>

{{< table-caption >}}
| | Seed Data | | 
| --- | ---: | ---: |
|  | **Dataset** | **Datasize** |
| Instruction Following | Alpaca | 51,983 |
| Mathematical Reasoning | GSM8K Train | 7,473 |
| Code Generation | Code Alpaca | 20,022 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct ë° Auto-Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì— ì‚¬ìš©ëœ ì‹œë“œ ëª…ë ¹ ë°ì´í„°ì˜ í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ë°ì´í„° ì„¸íŠ¸ì˜ ì´ë¦„ê³¼ í•´ë‹¹í•˜ëŠ” ë°ì´í„° í¬ê¸°ê°€ ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Statistics of seed instruction data used in the Evol-Instruct and Auto-Evol-Instruct scenarios.
> </details>

{{< table-caption >}}
| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |
|---|---|---|---|---|---|---|---|
|       | Pr.(S) | In.(S) | Pr.(L) | In.(L) |   | GSM8K | MATH |   | HumanEval | MBPP |
|---|---|---|---|---|---|---|---|---|---|
|       |       |       |       |       |       |       |       |       |       |       |
| Mistral-7B-v0.3 | 17.01 | 26.86 | 19.04 | 29.14 |   | 27.07 | 0.12 |   | 10.20 | 8.80 |
| DeepSeek-7B | 22.00 | 34.05 | 23.48 | 35.73 |   | 44.05 | 0.56 |   | 25.61 | 33.80 |
| Llama-3.2-3B | 22.55 | 34.17 | 25.88 | 37.65 |   | 46.40 | 0.56 |   | 28.05 | 32.20 |
| Llama-3-8B | 23.11 | 32.97 | 24.77 | 35.13 |   | 53.68 | 0.22 |   | 25.00 | 28.60 |
| Llama-3.1-8B | 27.54 | 38.13 | 28.65 | 39.21 |   | 56.41 | 7.56 |   | 29.88 | 31.80 |
| InternLM-2-7B | 32.72 | 45.08 | 35.30 | 48.08 |   | 61.87 | 10.28 |   | 42.07 | 40.00 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct ë° Auto Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì‹œë“œ ëª…ë ¹ ë°ì´í„°ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.2-3B, Llama-3-8B, Llama-3.1-8B, DeepSeek-7B, Mistral-7B-v0.3, InternLM-2-7B ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì— ëŒ€í•œ IFEval(ëª…ë ¹ì–´ ìˆ˜í–‰), ìˆ˜í•™ì  ì¶”ë¡ (GSM8K, MATH), ì½”ë“œ ìƒì„±(HumanEval, MBPP) ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í‘œì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì´ëŸ¬í•œ ì‹œë“œ ë°ì´í„°ë¡œ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ìµœì ì´ ì•„ë‹™ë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ ìµœì‹  ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸°ì—ëŠ” ì´ëŸ¬í•œ ì‹œë“œ ë°ì´í„°ì˜ í’ˆì§ˆì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Results of seed instruction data.
> </details>

{{< table-caption >}}
| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |
|---|---|---|---|---|---|---| 
|  | Pr.(S) | In.(S) | Pr.(L) | In.(L) | GSM8K | MATH | HumanEval | MBPP |
|---|---|---|---|---|---|---|---|---| 
| *Supervised Model: Llama-3.1-70B-Instruct* |  |  |  |  |  |  |  |  |
| Iteration 1 | 33.83 | 46.28 | 36.41 | 49.28 | 63.00 | 7.62 | 43.90 | 36.20 |
| Iteration 2 | 32.53 | 43.76 | 34.20 | 46.16 | 64.59 | 10.04 | 42.07 | 36.60 |
| Iteration 3 | 35.12 | 47.36 | 36.97 | 49.28 | 64.75 | 11.82 | 43.29 | 37.20 |
| *Supervised Model: Llama-3.1-8B-Instruct* |  |  |  |  |  |  |  |  |
| Iteration 1 | 35.49 | 47.00 | 39.56 | 50.72 | 63.38 | 11.44 | 48.17 | 37.60 |
| Iteration 2 | 36.78 | 48.20 | 40.30 | 50.84 | 64.82 | 11.48 | 48.78 | 39.40 |
| Iteration 3 | 33.09 | 44.72 | 36.41 | 48.32 | 65.88 | 14.12 | 44.51 | 40.80 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3-8B ëª¨ë¸ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ì§„í™” ë°˜ë³µ(Iteration 1, 2, 3)ì„ ì ìš©í•œ í›„ì˜ ì„±ëŠ¥ì„ ìì„¸íˆ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.1-70B-Instructì™€ Llama-3.1-8B-Instructë¥¼ ê°ê° ì§€ë„ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤. ì„±ëŠ¥ ì§€í‘œëŠ” IFEval(Instruction Following), GSM8K, MATH(Math Reasoning), HumanEval, MBPP(Code Generation)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: Detailed performance of different evolved iterations on Llama-3-8B refer to FigureÂ 1.
> </details>

{{< table-caption >}}
| Model | Instruction Following (IFEval) | | | | | Math Reasoning | | | Code Generation | |
|---|---|---|---|---|---|---|---|---|---|---|
| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP |
|---|---|---|---|---|---|---|---|---|---|---|
| Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | |
| Qwen-2.5-0.5B | 18.48 | 32.73 | 22.00 | 35.85 | | 40.26 | 16.32 | | 30.49 | 27.60 |
| Qwen-2.5-1.5B | 28.84 | 42.67 | 31.98 | 46.04 | | 62.32 | 24.06 | | 50.00 | 43.20 |
| Qwen-2.5-3B | 37.89 | 48.56 | 42.70 | 53.60 | | 76.12 | 26.44 | | 63.41 | 55.40 |
| Qwen-2.5-7B | 46.21 | 56.83 | 50.64 | 60.79 | | 76.12 | 38.14 | | 70.73 | 61.60 |
| Qwen-2.5-14B (LoRA) | 40.11 | 54.43 | 48.24 | 61.99 | | 87.79 | 49.94 | | 75.00 | 67.20 |
| Qwen-2.5-32B (LoRA) | 42.88 | 57.31 | 51.20 | 64.15 | | 87.79 | 55.02 | | 80.49 | 71.20 |
| Qwen-2.5-72B (LoRA) | 50.63 | 68.43 | 57.12 | 70.98 | | 91.05 | 58.83 | | 82.93 | 76.00 |
| Supervised Model: Llama-3.1-8B-Instruct | | | | | | | | | | |
| Qwen-2.5-0.5B | 17.38 | 29.38 | 19.78 | 32.01 | | 40.71 | 16.26 | | 34.76 | 28.00 |
| Qwen-2.5-1.5B | 28.47 | 41.73 | 31.98 | 44.96 | | 65.35 | 27.84 | | 52.44 | 49.94 |
| Qwen-2.5-3B | 38.82 | 49.76 | 42.51 | 53.96 | | 76.57 | 30.92 | | 64.02 | 55.80 |
| Qwen-2.5-7B | 47.32 | 58.39 | 51.39 | 62.35 | | 82.03 | 43.78 | | 71.95 | 61.80 |
| Qwen-2.5-14B (LoRA) | 42.51 | 55.16 | 51.02 | 62.47 | | 88.17 | 52.22 | | 75.61 | 67.20 |
| Qwen-2.5-32B (LoRA) | 45.84 | 58.75 | 54.71 | 66.31 | | 89.61 | 55.28 | | 81.71 | 73.20 |
| Qwen-2.5-72B (LoRA) | 52.79 | 72.56 | 61.25 | 73.27 | | 91.36 | 60.75 | | 84.67 | 76.80 |{{< /table-caption >}}
> ğŸ”¼ Qwen-2.5 ì‹œë¦¬ì¦ˆ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµë¥¼ ìì„¸íˆ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤. Figure 3ì—ì„œ ì–¸ê¸‰ëœ ëª¨ë¸ í¬ê¸° ì¡°ì • ì‹¤í—˜ì˜ ê²°ê³¼ë¥¼ ìì„¸íˆ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.1-70B-Instruct ë° Llama-3.1-8B-Instructë¥¼ ê°ë… ëª¨ë¸ë¡œ ì‚¬ìš©í•œ ë‘ ê°€ì§€ ì„¤ì •ì—ì„œ Qwen-2.5-0.5B, Qwen-2.5-1.5B, Qwen-2.5-3B, Qwen-2.5-7B, Qwen-2.5-14B (LORA), Qwen-2.5-32B (LORA), Qwen-2.5-72B (LORA) ëª¨ë¸ì˜ ì„±ëŠ¥ì„ IFEval (Pr.(S), In.(S), Pr.(L), In.(L)), GSM8K, MATH, HumanEval, MBPP ë“±ì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: Detailed performance among Qwen-2.5 series models refer to FigureÂ 3.
> </details>

{{< table-caption >}}
| Temperature | HumanEval | MBPP | HumanEval | MBPP |
|---|---|---|---|---| 
| | *Supervised Model: Llama-3.1-70B-Instruct* | | *Supervised Model: Llama-3.1-8B-Instruct* | |
| greedy | 37.20 | 33.40 | **39.63** | **36.40** |
| 0.1 | 36.59 | 36.40 | **37.80** | **37.60** |
| 0.3 | 38.41 | 35.20 | **39.63** | **37.80** |
| 0.5 | 35.98 | 33.40 | **37.80** | **35.80** |
| 0.7 | 35.98 | **36.00** | **39.02** | 32.80 |
| 0.9 | 34.76 | 33.00 | **40.24** | **35.80** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì½”ë“œ ìƒì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë‹¤ì–‘í•œ ì˜¨ë„ ì„¤ì •ì— ë”°ë¥¸ Llama-3.2-3B ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, greedy decoding (ì˜¨ë„ 0)ê³¼ 0.1ì—ì„œ 0.9ê¹Œì§€ ë‹¤ì„¯ ê°€ì§€ ì˜¨ë„ ì„¤ì •ì—ì„œ Code Alpaca ë°ì´í„°ì— ëŒ€í•œ ì§„í™” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ëª¨ë“  ì‘ë‹µ ìƒì„±ì—ëŠ” Qwen-2.5-72B-Instructë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í‘œëŠ” HumanEval ë° MBPP ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ pass@1 ì§€í‘œë¥¼ ë³´ì—¬ì£¼ë©°, Llama-3.1-70B-Instruct ë° Llama-3.1-8B-Instructë¼ëŠ” ë‘ ê°€ì§€ supervised modelì„ ì‚¬ìš©í•˜ì—¬ fine-tuningí•œ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: Performance among different temperatures on Llama-3.2-3B under code generation scenario.
> </details>

{{< table-caption >}}
|                       | Alpaca | GSM8K Train | Code Alpaca |
| :-------------------- | :----: | :---------: | :--------: |
| Seed Instruction     | 27.63 |    34.05    |   26.01    |
| LLM-Inst Iter1      | 52.89 |    39.88    |   46.75    |
| **SLM-Inst Iter1** | **66.35** |  **48.85**  |  **58.86**  |
| LLM-Inst Iter2      | 68.16 |    47.14    |   65.02    |
| **SLM-Inst Iter2** | **77.62** |  **63.48**  |  **73.37**  |
| LLM-Inst Iter3      | 75.73 |    54.00    |   72.85    |
| **SLM-Inst Iter3** | **82.44** |  **72.12**  |  **79.19**  |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ Llama-3.1-8B-Instruct(SLM)ì™€ Llama-3.1-70B-Instruct(LLM)ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ë²ˆì˜ ë°˜ë³µ ë™ì•ˆ ì§„í™”ëœ ëª…ë ¹ì–´ì˜ ë‚œì´ë„ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ë°˜ë³µì—ì„œ SLMê³¼ LLMìœ¼ë¡œ ìƒì„±ëœ ëª…ë ¹ì–´ ë°ì´í„°ì…‹(SLM-INST, LLM-INST)ì— ëŒ€í•´ Alpaca, GSM8K Train, Code Alpaca ë°ì´í„°ì…‹ì˜ ë‚œì´ë„ ì ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ë‚œì´ë„ ì ìˆ˜ëŠ” Qwen-2.5-72B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Scores of difficulty levels for instructions evolved during three iterations, using Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models for each round under Evol-Instruct scenario.
> </details>

{{< table-caption >}}
| Iteration | Average Reward | Average Reward | Average Reward |
|---|---|---|---| 
| | Alpaca | GSM8K | Code Alpaca |
|---|---|---|---| 
| *Supervised Model: Llama-3.1-70B-Instruct* | | | | 
| Iteration 1 | 1.54 | 0.74 | 1.10 |
| Iteration 2 | **1.68** | 0.73 | **1.19** |
| Iteration 3 | **1.56** | 0.69 | **1.14** |
| *Supervised Model: Llama-3.1-8B-Instruct* | | | |
| Iteration 1 | **1.59** | **1.01** | **1.23** |
| Iteration 2 | 1.54 | **0.79** | 0.96 |
| Iteration 3 | 1.42 | **0.97** | 1.03 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Evol-Instruct ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë°˜ë³µ ì§„í–‰ í›„ ì§„í™”ëœ ëª…ë ¹ ë°ì´í„°ì˜ í‰ê·  ë³´ìƒì„ ë¹„êµí•˜ì—¬ SLMê³¼ LLM ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ë‚˜ì€ ëª…ë ¹ì„ ìƒì„±í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.1-70B-Instructì™€ Llama-3.1-8B-Instructë¥¼ ê°ë… ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê³ , ì„¸ ê°€ì§€ ë°ì´í„°ì…‹(Alpaca, GSM8K, Code Alpaca)ì— ëŒ€í•´ ë°˜ë³µ 1, 2, 3ì˜ í‰ê·  ë³´ìƒ ì ìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Comparison of average rewards among different iteration evolution instruction data.
> </details>

{{< table-caption >}}
| Datasets | IFD (%) | IC-IFD (%) | Performance |
|---|---|---|---| 
| SLMs (Alpaca iter 3) | **83.04** | 35.89 | 40.64 |
| LLMs (Alpaca iter 3) | 82.03 | **37.05** | **42.18** |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì„¸ ë²ˆì§¸ ì§„í™” ê³¼ì •ì„ ê±°ì¹œ Alpaca ë°ì´í„°ì…‹ì—ì„œ SLMê³¼ LLMìœ¼ë¡œ ìƒì„±ëœ ì§€ì‹œë¬¸ì˜ IFD ë° IC-IFD ì ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ì§€ì‹œë¬¸ì˜ ë‚œì´ë„ê°€ ë§¤ìš° ë†’ì€ ê²½ìš°, IFD ì ìˆ˜ê°€ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆì§€ë§Œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ê¸°ëŒ€ì— ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ì™€ ë°˜ëŒ€ë¡œ, IC-IFD ì ìˆ˜ëŠ” ì§€ì‹œë¬¸ ë³µì¡ì„±ì˜ ì˜í–¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•œ ë°ì´í„° í’ˆì§ˆ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Llama-3-8B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ë°ì´í„°ì…‹ì— ëŒ€í•œ IFEvalì˜ í‰ê·  ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 15: Comparison of IFD and IC-IFD on third-round evolved Alpaca datasets from SLMs and LLMs.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}