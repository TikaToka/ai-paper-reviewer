{"references": [{"fullname_first_author": "Yuntao Bai", "paper_title": "Constitutional AI: Harmlessness from AI feedback", "publication_date": "2022-12-08", "reason": "This paper introduces the concept of Constitutional AI, a framework for aligning AI models with human values, which is directly relevant to the image safety problem addressed in the main paper."}, {"fullname_first_author": "Stefano Calzavara", "paper_title": "Content security problems? Evaluating the effectiveness of content security policy in the wild", "publication_date": "2016-10-26", "reason": "This paper provides insights into the challenges of content moderation on online platforms, highlighting the growing concerns about image content safety."}, {"fullname_first_author": "Jianfa Chen", "paper_title": "Class-RAG: Content moderation with retrieval augmented generation", "publication_date": "2024-10-24", "reason": "This paper is highly relevant due to its focus on content moderation using large language models, which is the core methodology of the main paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial component of the main paper's method for assessing the relevance of safety rules to images."}, {"fullname_first_author": "Patrick Schramowski", "paper_title": "Can machines help us answering question 16 in datasheets, and in turn reflecting on inappropriate content?", "publication_date": "2022-06-01", "reason": "This paper explores the use of machine learning models for safety assessments, which is directly related to the main paper's approach to image content safety judgment."}]}