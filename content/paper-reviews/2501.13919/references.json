{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper is a foundational technical report for GPT-4, a large language model (LLM) that is referenced extensively in the current study's methodology for video understanding."}, {"fullname_first_author": "Chaoyou Fu", "paper_title": "Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-Modal LLMs in Video Analysis", "publication_date": "2024-05-21", "reason": "This paper introduces Video-MME, a benchmark dataset crucial for evaluating the performance of the proposed temporal preference optimization (TPO) method in the context of long-form video understanding."}, {"fullname_first_author": "Peiyuan Zhang", "paper_title": "Long Context Transfer from Language to Vision", "publication_date": "2024-06-16", "reason": "This paper introduces LongVA, a model used as a baseline in the current study, which is essential for evaluating the effectiveness of the proposed TPO."}, {"fullname_first_author": "Yuanhan Zhang", "paper_title": "LLaVA-Next: A Strong Zero-Shot Video Understanding Model", "publication_date": "2024-00-00", "reason": "This paper introduces LLaVA-Video, another baseline model in this study, which is vital for contrasting the performance improvement achieved by applying the proposed TPO."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "publication_date": "2024-00-00", "reason": "This paper introduces the Direct Preference Optimization (DPO) method, which is adopted in the current work, and forms a core component of the proposed TPO framework for improving video-LLM performance."}]}