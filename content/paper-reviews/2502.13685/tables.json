[{"content": "Method|Memory Update Rule\n---|---|---\nLA|\\bm{M}_{t}=\\bm{M}_{t-1}+\\bm{k}_{t}^{T}\\bm{v}_{t}\nLightning|\\bm{M}_{t}=\\gamma\\bm{M}_{t-1}+\\bm{k}_{t}^{T}\\bm{v}_{t}\nRetNet|\\bm{M}_{t}=\\gamma\\bm{M}_{t-1}+\\bm{k}_{t}^{T}\\bm{v}_{t}\nHGRN2|\\bm{M}_{t}=(\\bm{a}_{t}^{T}\\bm{1})\\bm{M}_{t-1}+(1-\\bm{a}_{t})^{T}\\bm{v}_{t}\nGLA|\\bm{M}_{t}=(\\bm{a}_{t}^{T}\\bm{1})\\bm{M}_{t-1}+\\bm{k}_{t}^{T}\\bm{v}_{t}\nMamba2|\\bm{M}_{t}=\\alpha_{t}\\bm{M}_{t-1}+\\beta_{t}\\bm{k}_{t}^{T}\\bm{v}_{t}\nDeltaNet|\\bm{M}_{t}=(\\bm{I}-\\bm{k}_{t}^{T}\\bm{k}_{t})\\bm{M}_{t-1}+\\beta_{t}\\bm{k}_{t}^{T}\\bm{v}_{t}\nG-DeltaNet|\\bm{M}_{t}=\\alpha_{t}(\\bm{I}-\\bm{k}_{t}^{T}\\bm{k}_{t})\\bm{M}_{t-1}+\\beta_{t}\\bm{k}_{t}^{T}\\bm{v}_{t}\nTTT|\\bm{M}_{t}=\\bm{M}_{t-1}+\\beta_{t}\\nabla l(\\bm{M}_{t-1};\\bm{k}_{t},\\bm{v}_{t})\nTitan|\\bm{M}_{t}=\\alpha_{t}\\bm{M}_{t-1}+\\beta_{t}\\nabla l(\\bm{M}_{t-1};\\bm{k}_{t},\\bm{v}_{t})", "caption": "Table 1: Memory Update Rules. We demonstrate that several current linear sequence models can be viewed as recurrent models in terms of memory updates, where \u03b1t,\u03b2t\u2208(0,1)subscript\ud835\udefc\ud835\udc61subscript\ud835\udefd\ud835\udc6101\\alpha_{t},\\beta_{t}\\in(0,1)italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2208 ( 0 , 1 ) are data-dependent scaler, \ud835\udc82tsubscript\ud835\udc82\ud835\udc61\\bm{a}_{t}bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is data-dependent vector, and \u03b3\ud835\udefe\\gammaitalic_\u03b3 is a data-independent constant.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \uc120\ud615 \uc21c\ucc28 \ubaa8\ub378\uc758 \uba54\ubaa8\ub9ac \uc5c5\ub370\uc774\ud2b8 \uaddc\uce59\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc120\ud615 \uc21c\ucc28 \ubaa8\ub378\uc744 \uc21c\ud658 \uc2e0\uacbd\ub9dd(RNN)\uc73c\ub85c \ud574\uc11d\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uba54\ubaa8\ub9ac \uc5c5\ub370\uc774\ud2b8 \uacfc\uc815\uc744 \uc218\uc2dd\uc73c\ub85c \uc81c\uc2dc\ud558\uace0 \uc788\uc73c\uba70, \u03b1t \uc640 \u03b2t\ub294 \ub370\uc774\ud130\uc5d0 \ub530\ub77c \ubcc0\ud558\ub294 \uc2a4\uce7c\ub77c \uac12\uc774\uace0, at\ub294 \ub370\uc774\ud130\uc5d0 \ub530\ub77c \ubcc0\ud558\ub294 \ubca1\ud130 \uac12\uc774\uba70, \u03b3\ub294 \ub370\uc774\ud130\uc640 \ubb34\uad00\ud55c \uc0c1\uc218\uc784\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub294 MoM \ubaa8\ub378\uc758 \uba54\ubaa8\ub9ac \uc5c5\ub370\uc774\ud2b8 \uba54\ucee4\ub2c8\uc998\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc8fc\uba70, MoM \ubaa8\ub378\uc774 \uae30\uc874 \uc120\ud615 \uc21c\ucc28 \ubaa8\ub378\uacfc \uc5b4\ub5bb\uac8c \uad00\ub828\ub418\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2 MoM: Mixture-of-Memories"}, {"content": "| Scale | Model | FDA | SWDE | SQUAD | NQ | TriviaQA | Drop | Avg. |\n|---|---|---|---|---|---|---|---|---|\n| 340M Params<br>15B Tokens<br>L=24, d=1024 | Transformer++ | 46.14 | 25.87 | 33.22 | 18.94 | 45.97 | 20.03 | 31.70 |\n|  | RetNet | 5.90 | 9.28 | 22.41 | 6.91 | 40.05 | 18.59 | 17.19 |\n|  | HGRN2 | 11.53 | 17.34 | 24.08 | 12.67 | 43.84 | 17.35 | 21.14 |\n|  | GLA | 11.26 | 16.78 | 27.85 | 12.77 | 43.90 | 17.68 | 21.71 |\n|  | GSA | 6.36 | 16.87 | 21.90 | 14.60 | 42.18 | 16.72 | 19.77 |\n|  | Gated DeltaNet | 20.53 | 23.24 | 28.55 | 14.98 | 44.91 | 16.48 | 24.78 |\n|  | MoM | 30.79 | 26.05 | 29.63 | 13.84 | 44.79 | 20.41 | 27.59 |\n| 1.3B Params<br>100B Tokens<br>L=24, d=2048 | Transformer++<sup>\u2020</sup> | 44.32 | 32.43 | 42.59 | 24.49 | 58.47 | 21.56 | 37.31 |\n|  | RetNet<sup>\u2020</sup> | 13.62 | 22.59 | 33.46 | 15.43 | 53.79 | 19.79 | 26.45 |\n|  | HGRN2<sup>\u2020</sup> | 12.35 | 23.24 | 33.19 | 19.10 | 55.27 | 19.65 | 27.13 |\n|  | GLA<sup>\u2020</sup> | 27.61 | 30.93 | 35.04 | 22.27 | 56.28 | 19.45 | 31.93 |\n|  | GSA<sup>\u2020</sup> | 23.25 | 32.80 | 35.57 | 22.96 | 57.05 | 20.65 | 32.05 |\n|  | Gated DeltaNet | 30.25 | 27.65 | 34.06 | 23.22 | 58.23 | 20.36 | 32.30 |\n|  | MoM | 41.14 | 34.30 | 37.08 | 24.11 | 58.59 | 21.03 | 36.04 |", "caption": "Table 2: Results on Recall-Intensive Tasks. All inputs are truncated to a maximum length of 2K tokens. MoM significantly outperforms all other linear models across both model sizes. In the 1.3B model, MoM even achieves performance very close to that of Transformer models.", "description": "\ud45c 2\ub294 \uae30\uc5b5 \uc9d1\uc57d\uc801 \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \uc785\ub825\uc740 \ucd5c\ub300 2,000 \ud1a0\ud070 \uae38\uc774\ub85c \uc798\ub9bd\ub2c8\ub2e4. MoM\uc740 \ub450 \uac00\uc9c0 \ubaa8\ub378 \ud06c\uae30 \ubaa8\ub450\uc5d0\uc11c \ub2e4\ub978 \ubaa8\ub4e0 \uc120\ud615 \ubaa8\ub378\uc744 \ud06c\uac8c \ub2a5\uac00\ud569\ub2c8\ub2e4. 13\uc5b5 \ub9e4\uac1c\ubcc0\uc218 \ubaa8\ub378\uc5d0\uc11c MoM\uc740 Transformer \ubaa8\ub378\uacfc \uac70\uc758 \ub3d9\ub4f1\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "4 \uc2e4\ud5d8"}, {"content": "| Scale | Model | Wiki. ppl\u2193 | Lamb. ppl\u2193 | ARC-e acc\u2191 | ARC-c acc<sub>n</sub>\u2191 | Hella. acc<sub>n</sub>\u2191 | Lamb. acc\u2191 | PIQA acc\u2191 | Wino. acc\u2191 | Avg. | \n|---|---|---|---|---|---|---|---|---|---|---|\n| <span class=\"ltx_text ltx_font_italic\">340M Params</span> <br> <span class=\"ltx_text ltx_font_italic\">15B Tokens</span> <br> <span class=\"ltx_text ltx_font_italic\">L=24, d=1024</span> | Transformer++ | 26.88 | 76.46 | 44.91 | 25.94 | 34.95 | 26.90 | 64.31 | 51.07 | 41.35 |\n|  | RetNet | 31.07 | 87.11 | 44.49 | 23.04 | 33.86 | 23.93 | 63.49 | 52.33 | 40.19 |\n|  | HGRN2 | 27.90 | 77.40 | 45.24 | 23.63 | 35.61 | 24.74 | 65.45 | 54.06 | 41.46 |\n|  | GLA | 28.78 | 79.95 | 44.53 | 22.27 | 34.84 | 24.94 | 63.93 | 51.38 | 40.32 |\n|  | GSA | 28.17 | 82.50 | 45.50 | 24.23 | 35.00 | 24.02 | 64.85 | 50.43 | 40.67 |\n|  | Gated DeltaNet | 26.47 | 58.59 | 46.04 | 23.55 | 35.18 | 27.01 | 66.05 | 50.83 | 41.44 |\n|  | MoM | 26.00 | 51.25 | 46.13 | 24.15 | 35.91 | 28.26 | 65.61 | 52.57 | 42.11 |\n| <span class=\"ltx_text ltx_font_italic\">1.3B Params</span> <br> <span class=\"ltx_text ltx_font_italic\">100B Tokens</span> <br> <span class=\"ltx_text ltx_font_italic\">L=24, d=2048</span> | Transformer++<sup>\u2020</sup> | 17.61 | 19.29 | 55.01 | 28.07 | 49.21 | 40.95 | 70.08 | 56.27 | 49.93 |\n|  | RetNet<sup>\u2020</sup> | 18.18 | 21.97 | 57.49 | 26.88 | 48.09 | 37.75 | 69.37 | 53.28 | 48.81 |\n|  | HGRN2<sup>\u2020</sup> | 17.32 | 15.65 | 58.33 | 28.07 | 51.93 | 42.31 | 71.33 | 52.01 | 50.66 |\n|  | GLA<sup>\u2020</sup> | 17.61 | 19.66 | 55.18 | 27.56 | 48.89 | 40.03 | 69.86 | 53.91 | 49.24 |\n|  | GSA<sup>\u2020</sup> | 16.69 | 16.02 | 58.33 | 28.33 | 50.98 | 42.03 | 72.25 | 53.43 | 50.89 |\n|  | Gated DeltaNet<sup>\u2020</sup> | 17.14 | 18.80 | 56.82 | 27.39 | 49.77 | 39.94 | 71.76 | 51.78 | 49.58 |\n|  | MoM<sup>\u2020</sup> | 16.64 | 14.83 | 55.35 | 27.99 | 50.95 | 43.43 | 71.27 | 56.83 | 50.97 |", "caption": "Table 3: Results on Common-Sense Reasoning Tasks. The performance of linear models and Transformer models is comparable; however, MoM consistently achieves the best average performance across all model sizes.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc5b8\uc5b4 \ubaa8\ub378\uc5d0\uc11c \uc77c\ubc18\uc801\uc778 \uc0c1\uc2dd \ucd94\ub860 \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc120\ud615 \ubaa8\ub378\uacfc \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ube44\uc2b7\ud558\uc9c0\ub9cc, MoM\uc740 \ubaa8\ub4e0 \ubaa8\ub378 \ud06c\uae30\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \ucd5c\uace0\uc758 \ud3c9\uade0 \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc0c1\uc2dd \ucd94\ub860 \ub370\uc774\ud130\uc14b(WikiText, LAMBADA, ARC-e, ARC-c, HellaSwag, PiQA, Winograd Schema Challenge)\uc5d0\uc11c MoM, Transformer \ubaa8\ub378, \uae30\ud0c0 \uc120\ud615 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec, MoM\uc774 \uc0c1\uc2dd \ucd94\ub860 \ub2a5\ub825\uc5d0\uc11c \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, perplexity(\ub0ae\uc744\uc218\ub85d \uc88b\uc74c)\uc640 \uc815\ud655\ub3c4(\ub192\uc744\uc218\ub85d \uc88b\uc74c) \uce21\uba74\uc5d0\uc11c MoM\uc758 \uc6b0\uc218\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 Main Results"}, {"content": "| Wiki. | ppl\u2193 |", "caption": "Table 4: LongBench Results. All evaluations were done using Contributors (2023). Note: Sum = Summarization, FS = Few-shot, Syn = Synthetic.", "description": "\ud45c 4\ub294 LongBench \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LongBench\ub294 \ub2e4\uc591\ud55c \uc885\ub958\uc758 \uc7a5\ubb38 \ud14d\uc2a4\ud2b8 \uc774\ud574 \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\ub294 \ubca4\uce58\ub9c8\ud06c\uc774\uba70, \uc694\uc57d, \ud4e8\uc0f7 \ud559\uc2b5, \ud569\uc131 \uc791\uc5c5, \ucf54\ub4dc \uc644\uc131 \ub4f1 \uc5ec\ub7ec \uac00\uc9c0 \uc791\uc5c5\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \uc791\uc5c5\uc5d0 \ub300\ud55c MoM(Mixture-of-Memories) \ubaa8\ub378\uacfc \uae30\ud0c0 \uc5ec\ub7ec \uc120\ud615 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec MoM \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Sum\uc740 \uc694\uc57d, FS\ub294 \ud4e8\uc0f7 \ud559\uc2b5, Syn\uc740 \ud569\uc131 \uc791\uc5c5\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ubaa8\ub4e0 \ud3c9\uac00\ub294 Contributors (2023)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "4.2.3 Long Context Tasks"}, {"content": "| Lamb. | ppl\u2193 |\n|---|---|", "caption": "Table 5: Comparison Between Mixed Memory and Single Memory. We constructed MoM models using different memory update mechanisms. Separate memory segments yielded better performance compared to simply increasing the memory capacity of a single memory.", "description": "\ud45c 5\ub294 \ud63c\ud569 \uba54\ubaa8\ub9ac\uc640 \ub2e8\uc77c \uba54\ubaa8\ub9ac\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  MoM \ubaa8\ub378\uc740 \ub2e4\uc591\ud55c \uba54\ubaa8\ub9ac \uc5c5\ub370\uc774\ud2b8 \uba54\ucee4\ub2c8\uc998\uc744 \uc0ac\uc6a9\ud558\uc5ec \uad6c\uc131\ub418\uc5c8\uc73c\uba70, \uacb0\uacfc\uc801\uc73c\ub85c \ub2e8\uc77c \uba54\ubaa8\ub9ac\uc758 \uc6a9\ub7c9\uc744 \ub2e8\uc21c\ud788 \ub298\ub9ac\ub294 \uac83\ubcf4\ub2e4 \ubd84\ub9ac\ub41c \uba54\ubaa8\ub9ac \uc138\uadf8\uba3c\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc600\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uc5ec\ub7ec \uac1c\uc758 \ub3c5\ub9bd\uc801\uc778 \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \ub2e8\uc77c \uba54\ubaa8\ub9ac\uc758 \ud06c\uae30\ub97c \ub298\ub9ac\ub294 \uac83\ubcf4\ub2e4 \uba54\ubaa8\ub9ac \uac04\uc12d\uc744 \uc904\uc774\uace0 \uc7a5\uae30 \uae30\uc5b5 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ub354 \ud6a8\uacfc\uc801\uc784\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "3.3 MoM \ucd5c\uc801\ud654"}, {"content": "| Model       | Metric   |\n|--------------|-----------|\n| **ARC-e**   | acc\u2191      |", "caption": "Table 6: Ablation Study. We performed ablation studies on the number of memories and the use of shared memory. The table presents the average results across all recall-intensive tasks.", "description": "\ud45c 6\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 MoM \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc218\uc758 \uba54\ubaa8\ub9ac\uc640 \uacf5\uc720 \uba54\ubaa8\ub9ac \uc0ac\uc6a9 \uc5ec\ubd80\ub97c \ubcc0\ud654\uc2dc\ucf1c\uac00\uba70 recall-intensive \uc791\uc5c5\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc131\ub2a5\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c \uba54\ubaa8\ub9ac \uc218\uc640 \ud65c\uc131\ud654\ub41c \uba54\ubaa8\ub9ac \uc218\ub97c \ubcc0\uacbd\ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uace0 \uacf5\uc720 \uba54\ubaa8\ub9ac\uc758 \ud6a8\uacfc\ub97c \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 MoM \ubaa8\ub378\uc758 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\ub4e4\uc774 \uc131\ub2a5\uc5d0 \uc5b4\ub5bb\uac8c \uae30\uc5ec\ud558\ub294\uc9c0\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.3 MoM\uc5d0 \ub300\ud55c \ucd5c\uc801\ud654"}, {"content": "| Model | Accuracy |\n|---|---| \n| ARC-c | acc<sub>n</sub> \u2191 |", "caption": "Table 7: Complete Results of LongBench. (SQA: Single-doc QA, MQA: Multi-doc QA, Sum: Summarization, FS: Few-shot learning, Syn: Synthetic)", "description": "\ud45c 7\uc740 LongBench \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LongBench\ub294 \uc694\uc57d, \uba87 \uc0f7 \ud559\uc2b5, \ud569\uc131 \uc791\uc5c5 \ubc0f \ucf54\ub4dc \uc644\uc131\uc744 \ud3ec\ud568\ud55c \uc5ec\ub7ec \uc5b8\uc5b4 \uc774\ud574 \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\ub294 \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 SQA(\ub2e8\uc77c \ubb38\uc11c \uc9c8\uc758\uc751\ub2f5), MQA(\ub2e4\uc911 \ubb38\uc11c \uc9c8\uc758\uc751\ub2f5), \uc694\uc57d, \uba87 \uc0f7 \ud559\uc2b5 \ubc0f \ud569\uc131 \uc791\uc5c5\uc5d0 \ub300\ud55c \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c \uc911\uad6d\uc5b4 \ubc0f \uc601\uc5b4\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218\ub3c4 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \uc791\uc5c5\uc5d0\uc11c MoM \ubaa8\ub378\uc758 \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4.2 Main Results"}, {"content": "| Hella. |\n| acc<sub>n</sub> \u2191 |", "caption": "Table 8: Complete Ablation Study Results. The complete results of the ablation studies on recall-intensive tasks.", "description": "\ud45c 8\uc740 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc \ubd80\ubd84\uc5d0\uc11c \ub2e4\uc591\ud55c \ub9e4\uac1c\ubcc0\uc218\ub97c \ubcc0\uacbd\ud558\uba70 \uc218\ud589\ud55c \ubc18\ubcf5 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \uae30\uc5b5 \uc6a9\ub7c9 \ubc0f \uac04\uc12d \ubb38\uc81c\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd98 \uc5ec\ub7ec \uac00\uc9c0 \uae30\uc5b5 \uba54\ucee4\ub2c8\uc998\uc5d0 \ub300\ud55c \ube44\uad50 \ubd84\uc11d \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ub9e4\uac1c\ubcc0\uc218 \uc870\ud569(\uae30\uc5b5\uc758 \uac1c\uc218, \ud65c\uc131\ud654\ub41c \uae30\uc5b5\uc758 \uac1c\uc218, \uacf5\uc720 \uba54\ubaa8\ub9ac \uc0ac\uc6a9 \uc5ec\ubd80 \ub4f1)\uc5d0 \ub530\ub978 \uc7ac\ud604\uc728 \uc9d1\uc57d\uc801 \uc791\uc5c5(recall-intensive tasks)\uc758 \uc131\ub2a5 \uc9c0\ud45c(\uc815\ud655\ub3c4)\uac00 \uc218\uce58\ub85c \ub098\ud0c0\ub098 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 MoM \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc694\uc18c\ub4e4\uc744 \ubd84\uc11d\ud558\uace0, \ucd5c\uc801\uc758 \uc124\uc815\uc744 \ucc3e\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4.2.7 Ablation"}, {"content": "| Lamb. | acc \u2191 |\n", "caption": "Table 9: Complete Ablation Study Results. The complete results of the ablation studies on recall-intensive tasks.", "description": "\ud45c 9\ub294 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc \uc911 \uc7ac\ud604\uc728 \uc9d1\uc57d\uc801 \uacfc\uc81c\uc5d0 \ub300\ud55c \ucd94\uac00 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\ub7ec \uac00\uc9c0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(\uba54\ubaa8\ub9ac \uc218, \ud65c\uc131\ud654\ub41c \uba54\ubaa8\ub9ac \uc218, \uacf5\uc720 \uba54\ubaa8\ub9ac \uc0ac\uc6a9 \uc5ec\ubd80)\ub97c \ubcc0\uacbd\ud558\uba74\uc11c \uc131\ub2a5 \ubcc0\ud654\ub97c \uce21\uc815\ud558\uc5ec MoM \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc870\ud569\uc5d0 \ub530\ub978 \ub2e4\uc591\ud55c \uc7ac\ud604\uc728 \uc9d1\uc57d\uc801 \uacfc\uc81c(FDA, SWDE, SQUAD, NQ, TriviaQA, Drop)\uc758 \uc131\ub2a5 \uc9c0\ud45c\uac00 \uc790\uc138\ud788 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2.7 Ablation"}]