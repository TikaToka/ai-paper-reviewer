[{"content": "| Method | GSM8K | MBPP-Pro | ARC-Easy |\n|---|---|---|---| \n| Llama3-8B-Instruct | 75.89 (1.00) | 64.65 (1.00) | 88.59 (1.00) |\n| + LoRA | 77.18 (1.02) | 67.68 (1.05) | 88.97 (1.00) |\n| + SVF (Ours) | 79.15 (1.04) | 66.67 (1.03) | 89.56 (1.01) |\n| Mistral-7B-Instruct-v0.3 | 42.83 (1.00) | 49.50 (1.00) | 81.65 (1.00) |\n| + LoRA | 44.66 (1.04) | 51.52 (1.04) | 81.19 (0.98) |\n| + SVF (Ours) | 49.74 (1.16) | 51.52 (1.04) | 85.14 (1.04) |\n| Llama3-70B-Instruct | 85.29 (1.00) | 80.81 (1.00) | 89.10 (1.00) |\n| + LoRA | 77.26 (0.91) | 68.69 (0.85) | 88.55 (0.99) |\n| + SVF (Ours) | 88.32 (1.04) | 80.81 (1.00) | 88.47 (0.99) |", "caption": "Table 1: Fine-tuning results. LLM performance on the test splits of math, coding and reasoning. Normalized scores are in the parentheses.", "description": "\ud45c 1\uc740 \uc138 \uac00\uc9c0 \uacfc\uc81c(\uc218\ud559, \ucf54\ub529, \ucd94\ub860)\uc5d0 \ub300\ud55c \uc138 \uac00\uc9c0 \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 LLM\uc5d0 \ub300\ud574 \uae30\ubcf8 \uc131\ub2a5\uacfc LoRA \ubc0f SVF(Singular Value Fine-tuning) \uae30\uc220\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ud55c \ud6c4\uc758 \uc131\ub2a5\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uad04\ud638 \uc548\uc758 \uc810\uc218\ub294 \uc815\uaddc\ud654\ub41c \uc810\uc218\uc774\uba70, \uae30\ubcf8 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 1.00\uc73c\ub85c \ud558\uc5ec \uc0c1\ub300\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Method | MATH | Humaneval | ARC-Challenge |\n|---|---|---|---|\n| Llama3-8B-Instruct 3 | 24.54 (1.00) | 60.98 (1.00) | 80.63 (1.00) |\n| + LoRA | 24.12 (0.98) | 52.44 (0.86) | 81.06 (1.01) |\n| + Transformer<sup>2</sup> (Prompt) | 25.22 (1.03) | 61.59 (1.01) | 81.74 (1.01) |\n| + Transformer<sup>2</sup> (Cls-expert) | 25.18 (1.03) | 62.80 (1.03) | 81.37 (1.01) |\n| + Transformer<sup>2</sup> (Few-shot) | 25.47 (1.04) | 62.99 (1.03) | 82.61 (1.02) |\n| Mistral-7B-Instruct-v0.3 | 13.02 (1.00) | 43.29 (1.00) | 71.76 (1.00) |\n| + LoRA | 13.16 (1.01) | 37.80 (0.87) | 75.77 (1.06) |\n| + Transformer<sup>2</sup> (Prompt) | 11.86 (0.91) | 43.90 (1.01) | 72.35 (1.01) |\n| + Transformer<sup>2</sup> (Cls-expert) | 11.60 (0.89) | 43.90 (1.01) | 74.83 (1.04) |\n| + Transformer<sup>2</sup> (Few-shot) | 13.39 (1.03) | 47.40 (1.09) | 75.47 (1.05) |\n| Llama3-70B-Instruct | 40.64 (1.00) | 78.66 (1.00) | 87.63 (1.00) |\n| + LoRA | 25.40 (0.62) | 73.78 (0.94) | 83.70 (0.96) |\n| + Transformer<sup>2</sup> (Prompt) | 40.44 (1.00) | 79.88 (1.02) | 88.48 (1.01) |", "caption": "Table 2: Self-adaptation on unseen tasks. Normalized scores are in the parentheses.", "description": "\uc774 \ud45c\ub294 Transformer\u00b2 \ubaa8\ub378\uc758 \uc790\uac00 \uc801\uc751 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874\uc5d0 \ud559\uc2b5\ub418\uc9c0 \uc54a\uc740 \ub124 \uac00\uc9c0 \uacfc\uc81c(MATH, Humaneval, ARC-Challenge, OKVQA)\uc5d0 \ub300\ud574, Transformer\u00b2\uac00 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uc801\uc751 \uc804\ub7b5(\ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1, \ubd84\ub958 \uc804\ubb38\uac00, \ud4e8\uc0f7 \uc801\uc751)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5bc\ub9c8\ub098 \uc798 \uc801\uc751\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc815\uaddc\ud654\ub41c \uc810\uc218(\uad04\ud638 \uc548)\ub97c \uc81c\uc2dc\ud558\uc5ec, Transformer\u00b2\uc758 \uc131\ub2a5\uc744 \uae30\uc900 \ubaa8\ub378(LLAMA3-8B-INSTRUCT, MISTRAL-7B-INSTRUCT-V0.3, LLAMA3-70B-INSTRUCT) \ubc0f LoRA \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 Transformer\u00b2\uc758 \uc790\uac00 \uc801\uc751 \uc131\ub2a5\uacfc \ub2e4\uc591\ud55c \uc801\uc751 \uc804\ub7b5\uc758 \ud6a8\uacfc\ub97c \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"content": "| Task | 1st (s) | 2nd (s) |\n|---|---|---|\n| MATH | 42.64 (13%) | 321.19 |\n| Humaneval | 2.76 (19%) | 14.28 |\n| ARC-Challenge | 13.40 (47%) | 28.51 |", "caption": "Table 3: Time cost of 2-pass inference in prompt adaptation strategy of Transformer2superscriptTransformer2\\text{Transformer}^{2}Transformer start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for the entire problem set. 1st to 2nd pass inference time ratios are shown in parentheses.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 Transformer\u00b2 \ubaa8\ub378\uc5d0\uc11c \ud504\ub86c\ud504\ud2b8 \uc801\uc751 \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c, \uc804\uccb4 \ubb38\uc81c \uc9d1\ud569\uc5d0 \ub300\ud55c 2\ub2e8\uacc4 \ucd94\ub860\uc758 \uc2dc\uac04 \ube44\uc6a9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 1\ucc28 \ucd94\ub860\uc740 \ubb38\uc81c\uc758 \uc720\ud615\uc744 \ud30c\uc545\ud558\ub294 \ub370, 2\ucc28 \ucd94\ub860\uc740 \uc2e4\uc81c \ubb38\uc81c \ud574\uacb0\uc5d0 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ub2e8\uacc4\uc758 \ucd94\ub860 \uc2dc\uac04\uacfc 1\ucc28 \ucd94\ub860 \uc2dc\uac04 \ub300\ube44 2\ucc28 \ucd94\ub860 \uc2dc\uac04\uc758 \ube44\uc728\uc774 \uad04\ud638 \uc548\uc5d0 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 EXPERIMENTS / 4.2 EXPERIMENTAL RESULTS"}, {"content": "| # | Method | Objective Function | Module | #Params (\u2193) | GSM8K (\u2191) | MATH (\u2191) |\n|---|---|---|---|---|---|---|\n| 0 | LLAMA-3-8B-Instruct |  |  |  | 75.89 (1.00) | 24.54 (1.00) |\n| 1 | SVF | Policy gradient | MLP | 0.39M | 78.62 (1.04) | 24.20 (0.99) |\n| 2 | SVF | Policy gradient | attention | 0.16M | 76.19 (1.00) | 24.20 (0.99) |\n| 3 | SVF | Policy gradient | MLP + attention | 0.58M | 79.23 (1.04) | 25.04 (1.04) |\n| 4 | SVF | Next token pred | attention | 0.16M | 60.50 (0.80) | 18.52 (0.75) |\n| 5 | LoRA | Policy gradient | attention | 6.82M | 57.92 (0.76) | 15.72 (0.64) |\n| 6 | LoRA | Next token pred | attention | 6.82M | 77.18 (0.98) | 24.12 (0.96) |\n| 7 | LoRA | Next token pred | MLP + attention | 35.13M | 75.66 (0.96) | 22.12 (0.91) |", "caption": "Table 4: Ablation studies. We fine-tune Llama3-8B-Instruct on the GSM8K training split with different settings and the results on the test split along with zero-shot transfer results on MATH.", "description": "\ud45c 4\ub294 Llama3-8B-Instruct \ubaa8\ub378\uc744 GSM8K \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc758 \uc11c\ub85c \ub2e4\ub978 \uc124\uc815\uc73c\ub85c \ubbf8\uc138 \uc870\uc815\ud55c \uacb0\uacfc\uc640, \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc758 GSM8K \ud14c\uc2a4\ud2b8\uc14b \uc131\ub2a5 \ubc0f MATH \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc81c\ub85c\uc0f7 \uc804\uc774 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubbf8\uc138 \uc870\uc815 \uc124\uc815\uc5d0\ub294 \ucd5c\uc801\ud654 \ubaa9\uc801 \ud568\uc218(\uc815\ucc45 \uacbd\uc0ac \ub610\ub294 \ub2e4\uc74c \ud1a0\ud070 \uc608\uce21), \ubbf8\uc138 \uc870\uc815 \ubaa8\ub4c8(MLP, \uc5b4\ud150\uc158 \ub610\ub294 \ub458 \ub2e4), \ub9e4\uac1c\ubcc0\uc218 \uc218 \ub4f1\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc548\ub41c SVF \ubc29\ubc95\uc758 \uac15\uac74\uc131\uacfc \ud6a8\uc728\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4.3 \uc2e4\ud5d8 \uacb0\uacfc \ubd84\uc11d"}, {"content": "| Method | MATH | Humaneval | ARC-Challenge |\n|---|---|---|---|\n| _SVF training task_ | _GSM8K_ | _MBPP-pro_ | _ARC-Easy_ |\n| Mistral-7B-Instruct-v0.3 | 13.02 (1.00) | 43.29 (1.00) | 71.76 (1.00) |\n| + Llama SVF (ordered \u03c3<sub>i</sub>) | 11.96 (0.92) | 45.12 (1.04) | 72.01 (1.00) |\n| + Llama SVF (shuffled \u03c3<sub>i</sub>) | 10.52 (0.81) | 40.24 (0.93) | 70.82 (0.99) |\n| + Few-shot adaptation (cross-model) | 12.65 (0.97) | 46.75 (1.08) | 75.64 (1.05) |", "caption": "Table 5: Cross-model z\ud835\udc67\\bm{z}bold_italic_z vector transfer.\nResults from transferring the expert vectors trained on Llama3-8B-Instruct to Mistral-7B-Instruct-v0.3 with cross model few-shot adaptation.", "description": "\ubcf8 \ud45c\ub294 Llama3-8B-Instruct \ubaa8\ub378\uc5d0\uc11c \ud559\uc2b5\ub41c \uc804\ubb38\uac00 \ubca1\ud130\ub4e4\uc744 Mistral-7B-Instruct-v0.3 \ubaa8\ub378\uc5d0 \uc804\uc774 \ud559\uc2b5\ud558\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \uad50\ucc28 \ubaa8\ub378 \ud4e8\uc0f7 \uc801\uc751 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc804\uc774 \ud559\uc2b5\uc744 \uc218\ud589\ud588\uc73c\uba70,  GSM8K, MBPP-pro, ARC-Easy \uc138 \uac00\uc9c0 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \uacfc\uc81c\uc5d0 \ub300\ud55c \uae30\uc900 \uc131\ub2a5\uacfc Llama3-8B-Instruct\uc5d0\uc11c \ud559\uc2b5\ub41c \ubca1\ud130\ub97c \uc21c\uc11c\ub300\ub85c \uc801\uc6a9\ud588\uc744 \ub54c, \uc21c\uc11c\ub97c \uc11e\uc5b4 \uc801\uc6a9\ud588\uc744 \ub54c, \uadf8\ub9ac\uace0 \uad50\ucc28 \ubaa8\ub378 \ud4e8\uc0f7 \uc801\uc751\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uad50\ucc28 \ubaa8\ub378 \uc801\uc751 \uc804\ub7b5\uc758 \ud6a8\uacfc\uc131\uacfc SVF \ubca1\ud130\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| SVF Hyperparameters                                  |\n|-------------------------------------------------------|\n| Initial mean value of z                             | 0.1           |\n| Initial variance value of z                          | $1 \\times 10^{-3}$ |\n| Global batch size                                    | 256           |\n| Learning rate                                        | $2 \\times 10^{-3}$ |\n| Clip max norm                                         | $1 \\times 10^{-3}$ |\n| KL coefficient $\\lambda$                            | 0.0, 0.1, 0.2, 0.3 |\n| LoRA Hyperparameters                                 |\n|-------------------------------------------------------|\n| Rank                                                | 16            |\n| LoRA alpha                                           | 32            |\n| LoRA dropout                                         | 0.05          |\n| Global batch size                                    | 256           |\n| Learning rate                                        | $2 \\times 10^{-4}$, $5 \\times 10^{-4}$, $2 \\times 10^{-5}$, $5 \\times 10^{-5}$, $2 \\times 10^{-6}$, $5 \\times 10^{-6}$ |\n| Clip max norm                                         | $1 \\times 10^{-3}$, 1.0 |", "caption": "Table 6: Hyper-parameters used for SVF and LoRA training. We perform a sweep on certain sensitive hyper-parameters across methods for fair comparison.", "description": "\ud45c 6\uc740 SVF\uc640 LoRA \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \ud2b9\uc815 \ubbfc\uac10\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc5d0 \ub300\ud574 \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 SVF\uc640 LoRA \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ucd08\uae30 \ud3c9\uade0\uac12\uacfc \ubd84\uc0b0\uac12, \ubc30\uce58 \ud06c\uae30, \ud559\uc2b5\ub960, \ud074\ub9ac\ud551 \ucd5c\ub300 \uaddc\ubc94, KL \uacc4\uc218(SVF\uc758 \uacbd\uc6b0)\uc640 \uac19\uc740 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc774 \uc790\uc138\ud788 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \uc2e4\ud5d8 \uacb0\uacfc\uc758 \uc7ac\ud604\uc131\uc744 \ud655\ubcf4\ud558\uace0, \uc11c\ub85c \ub2e4\ub978 \ubc29\ubc95 \uac04\uc758 \ube44\uad50\ub97c \uc704\ud55c \uae30\uc900\uc744 \uc81c\uacf5\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "3. \ubc29\ubc95\ub860"}, {"content": "| Method | GSM8K | MBPP-Pro | ARC-Easy |\n|---|---|---|---| \n| Llama3-8B-Instruct | 75.89 (1.00) | 64.65 (1.00) | 88.59 (1.00) |\n| + IA3 | 78.01 (1.03) | 67.68 (1.05) | 89.10 (1.01) |\n| + DORA | 78.09 (1.03) | 64.65 (1.00) | 89.14 (1.01) |\n| + SVF(Ours) | **79.15 (1.04)** | 66.67 (1.03) | **89.56 (1.01)** |\n| Method | MATH | Humaneval | ARC-Challenge |\n|---|---|---|---| \n| Llama3-8B-Instruct | 24.54 (1.00) | 60.98 (1.00) | 80.63 (1.00) |\n| + IA3 | 23.64 (0.96) | 59.76 (0.98) | 81.57 (1.01) |\n| + DORA | 24.44 (0.99) | 52.44 (0.86) | 81.14 (1.01) |\n| + Transformer<sup>2</sup> (Prompt) | 25.22 (1.03) | 61.59 (1.01) | 81.74 (1.01) |\n| + Transformer<sup>2</sup> (Cls-expert) | 25.18 (1.03) | 62.80 (1.03) | 81.37 (1.01) |\n| + Transformer<sup>2</sup> (Few-shot) | **25.47 (1.04)** | **62.99 (1.03)** | **82.61 (1.02)** |", "caption": "Table 7: Additional Comparison Experiment. Normalized scores are in the parentheses.", "description": "\ud45c 7\uc740 \ucd94\uac00 \ube44\uad50 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\ub7ec\uac00\uc9c0 \ub9e4\uac1c\ubcc0\uc218 \ud6a8\uc728\uc801\uc778 \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubc29\ubc95\uc758 \uc815\uaddc\ud654\ub41c \uc810\uc218(\uad04\ud638 \uc548)\uc640 \ud568\uaed8 GSM8K, MBPP-Pro, ARC-Easy \ubc0f \uc138 \uac00\uc9c0 \ucd94\uac00\ub418\uc9c0 \uc54a\uc740 \uc791\uc5c5(MATH, Humaneval, ARC-Challenge)\uc5d0 \ub300\ud55c \uc131\ub2a5\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc0c1\ub300\uc801 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec Transformer\u00b2\uc758 \ud6a8\uc728\uc131\uacfc \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.", "section": "4.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Method | \\text{Transformer}^{2} | IA<sup>3</sup> 100 steps | IA<sup>3</sup> 1000 steps |\n|---|---|---|---| \n| Llama3-8B-Instruct | 80.63 (1.00) | 80.63 (1.00) | 80.63 (1.00) |\n| + 3-shot adaptation | 82.18 (1.02) | 81.83 (1.01) | 79.01 (0.98) |\n| + 5-shot adaptation | 82.38 (1.02) | 80.89 (1.00) | 79.41 (0.98) |\n| + 10-shot adaptation | **82.61 (1.02)** | **82.00** (1.02) | **79.78** (**0.99**) |\n| + 20-shot adaptation | **82.61 (1.02)** | 81.40 (1.01) | 79.61 (0.99) |", "caption": "Table 8: Few-shot adaptation scaling on the Arc-Challenge task. Performance varies with number of examples.", "description": "\ud45c 8\uc740 Arc-Challenge \uacfc\uc81c\uc5d0 \ub300\ud55c \uc18c\uc218 \uc0f7 \uc801\uc751 \ud655\uc7a5\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc218\uc758 \uc608\uc2dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  LLAMA3-8B-INSTRUCT \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c, 3-shot, 5-shot, 10-shot, \uadf8\ub9ac\uace0 20-shot \uc801\uc751 \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uac01 \uc804\ub7b5\ubcc4\ub85c Arc-Challenge \uacfc\uc81c\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \uce21\uc815\ud558\uace0, \uadf8 \uacb0\uacfc\ub97c \ubc31\ubd84\uc728(%)\ub85c \ud45c\uc2dc\ud558\uc5ec, \uc608\uc2dc\uc758 \uac1c\uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5 \ubcc0\ud654\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc18c\uc218 \uc0f7 \ud559\uc2b5 \uc804\ub7b5\uc758 \ud6a8\uc728\uc131 \ubc0f \ud655\uc7a5\uc131\uc744 \ud3c9\uac00\ud558\uace0, \uc801\uc808\ud55c \uc608\uc2dc \uac1c\uc218\ub97c \uacb0\uc815\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Method | GSM8K | MBPP-pro | ARC-Easy |\n|---|---|---|---| \n| Mistral-7B-Instruct-v0.3 | 42.83 (1.00) | 49.50 (1.00) | 81.65 (1.00) |\n| + Llama SVF (ordered \u03c3<sub>i</sub>) | 42.61 (0.99) | 48.48 (0.98) | 81.78 (1.00) |\n| + Llama SVF (shuffled \u03c3<sub>i</sub>) | 41.93 (0.98) | 46.34 (0.94) | 80.81 (0.99) |", "caption": "Table 9: \nCross-model z\ud835\udc67\\bm{z}bold_italic_z Vector Transfer.\nResults from transfering the SVF expert vectors trained on Llama3-8B-Instruct to Mistral-7B-Instruct-v0.3 in the respective training tasks.", "description": "\ud45c 9\ub294 Llama3-8B-Instruct \ubaa8\ub378\uc5d0\uc11c \ud559\uc2b5\ub41c SVF \uc804\ubb38\uac00 \ubca1\ud130\ub97c Mistral-7B-Instruct-v0.3 \ubaa8\ub378\ub85c \uc804\uc774\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud559\uc2b5 \uacfc\uc5c5(GSM8K, MBPP-pro, ARC-Easy)\uc5d0 \ub300\ud574 Llama3-8B-Instruct \ubaa8\ub378\uc5d0\uc11c \ud559\uc2b5\ub41c SVF \ubca1\ud130\ub97c Mistral-7B-Instruct-v0.3 \ubaa8\ub378\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc131\ub2a5\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378 \uac04 \uc804\uc774 \ud559\uc2b5\uc758 \ud6a8\uacfc\ub97c \ud655\uc778\ud558\uae30 \uc704\ud55c \uc2e4\ud5d8\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \uacfc\uc5c5\uc5d0 \ub300\ud55c Mistral-7B-Instruct-v0.3 \ubaa8\ub378\uc758 \uae30\ubcf8 \uc131\ub2a5\uacfc SVF \ubca1\ud130\ub97c \uc801\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ud5a5\uc0c1 \uc815\ub3c4\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, SVF \ubca1\ud130\uc758 \uc21c\uc11c\ub97c \uc720\uc9c0\ud588\uc744 \ub54c\uc640 \uc784\uc758\ub85c \uc11e\uc5c8\uc744 \ub54c\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ube44\uad50\ud558\uc5ec SVF \ubca1\ud130\uc758 \uc21c\uc11c\uac00 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4.2 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Method | ARC-Challenge |\n|---|---| \n| Llama3-8B-Instruct | 80.63 (1.00) |\n| + CEM 10-shot adaptation | **82.61 (1.02)** |\n| + CEM 3-shot (30% of prompts) | 82.18 (1.02) |\n| + CEM light (3% of prompts) | 82.08 (1.02) |", "caption": "Table 10: 3-shot and light variants Performance with different inference-time adaptation budgets.", "description": "\ud45c 10\uc740 \ucd94\ub860 \uc2dc\uac04 \uc801\uc751 \uc608\uc0b0\uc774 \ub2e4\ub978 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uc124\uc815\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \uc124\uc815\uc740 10\uac1c\uc758 \uc0d8\ud50c\uc744 \uc0ac\uc6a9\ud558\ub294 \ud45c\uc900 CEM(Cross-Entropy Method), \ud504\ub86c\ud504\ud2b8\uc758 30%\ub9cc \uc0ac\uc6a9\ud558\ub294 CEM\uc758 \ubcc0\ud615, \uadf8\ub9ac\uace0 \ud504\ub86c\ud504\ud2b8\uc758 3%\ub9cc \uc0ac\uc6a9\ud558\ub294 CEM light\uc785\ub2c8\ub2e4. \uac01 \uc124\uc815\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 ARC-Challenge \uc791\uc5c5\uc5d0 \ub300\ud574 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \ud45c\ub294 \uac01 \uc124\uc815\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \uae30\ubcf8 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}]