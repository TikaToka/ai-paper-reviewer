{"references": [{"fullname_first_author": "Andrea Agostinelli", "paper_title": "MusicLM: Generating music from text", "publication_date": "2023-01-26", "reason": "MusicLM is a groundbreaking model that generates high-fidelity music from text descriptions, setting a new standard for text-to-music generation."}, {"fullname_first_author": "Jade Copet", "paper_title": "Simple and controllable music generation", "publication_date": "2023-12-04", "reason": "MusicGen introduces a simple yet powerful framework for controllable music generation, enabling users to manipulate musical elements like genre and mood."}, {"fullname_first_author": "Zach Evans", "paper_title": "Stable Audio Open", "publication_date": "2024-07-24", "reason": "Stable Audio Open provides a flexible and efficient approach for generating diverse and high-fidelity music conditioned on text or audio prompts."}, {"fullname_first_author": "Shangzhe Di", "paper_title": "Video background music generation with controllable music transformer", "publication_date": "2021-10-20", "reason": "CMT presents a novel approach for generating background music tailored to video content by translating video dynamics into musical rhythms."}, {"fullname_first_author": "Zhe Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2023-12-28", "reason": "InternVL is a powerful multimodal model that excels at interpreting and generating both visual and textual content, making it a valuable foundation for multimodal music description."}]}