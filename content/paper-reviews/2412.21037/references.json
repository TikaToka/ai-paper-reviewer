{"references": [{"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-03-02", "reason": "This paper is foundational for the field of aligning LLMs, a crucial aspect also explored in the current paper for the text-to-audio domain."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2024-05-12", "reason": "This paper introduces Direct Preference Optimization (DPO), a key technique used and expanded upon in the current research for aligning the TTA model."}, {"fullname_first_author": "Hyung Won Chung", "paper_title": "Scaling instruction-finetuned language models", "publication_date": "2022-10-11", "reason": "This paper details scaling instruction-finetuned language models, a highly relevant topic due to the use of large language models for text encoding in the current work."}, {"fullname_first_author": "Zach Evans", "paper_title": "Stable audio open", "publication_date": "2024-07-14", "reason": "This paper introduces Stable Audio Open, a dataset and VAE model used for audio encoding, a critical component of the proposed architecture."}, {"fullname_first_author": "Haohe Liu", "paper_title": "AudioLDM 2: Learning holistic audio generation with self-supervised pretraining", "publication_date": "2024-08-05", "reason": "This paper introduces AudioLDM 2, a strong baseline text-to-audio model used for comparison, highlighting the advancement of the proposed work."}]}