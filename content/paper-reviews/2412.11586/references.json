{"references": [{"fullname_first_author": "Ben Poole", "paper_title": "DreamFusion: Text-to-3D using 2D Diffusion", "publication_date": "2022-01-01", "reason": "This paper introduces DreamFusion, a groundbreaking method that leverages pre-trained 2D diffusion models for text-to-3D generation, which significantly influences many following research works, and also serves as a core component of StrandHead."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-01-01", "reason": "This work presents Stable Diffusion, a powerful text-to-image generation model based on latent diffusion, which is widely used as a strong base model in many fields and also adopted by StrandHead to provide prior knowledge."}, {"fullname_first_author": "Tianchang Shen", "paper_title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis", "publication_date": "2021-01-01", "reason": "This paper introduces DMTet, a highly effective and efficient 3D representation that combines the strengths of signed distance functions (SDFs) and explicit meshes, which is employed by StrandHead to model and generate high-quality 3D heads and hair."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-01-01", "reason": "This work introduces CLIP, a widely used multimodal model that connects image and text, enabling the evaluation of the alignment between textual prompts and generated results."}, {"fullname_first_author": "Vanessa Sklyarova", "paper_title": "Text-Conditioned Generative Model of 3D Strand-Based Human Hairstyles", "publication_date": "2024-01-01", "reason": "This paper proposes HAAR, which is a pioneer work focusing on strand-based 3D hair modeling from textual descriptions, using diffusion models."}]}