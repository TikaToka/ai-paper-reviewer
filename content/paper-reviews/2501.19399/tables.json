[{"content": "| Parameter | Value |\n|---|---| \n| Number of Layers | 12 |\n| Number of Attention Heads | 12 |\n| Hidden Size | 768 |\n| Feedforward Size | 2,048 |\n| Vocabulary Size | 50,257 |", "caption": "Table 1: Model architecture details.", "description": "\ud45c 1\uc740 \ubcf8 \ub17c\ubb38\uc758 2.1\uc808\uacfc 3\uc808\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ubaa8\ub378\uc758 \uad6c\uc870\uc801 \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378\uc758 \ub808\uc774\uc5b4 \uc218, \uc5b4\ud150\uc158 \ud5e4\ub4dc \uc218, \ud788\ub4e0 \uc0ac\uc774\uc988, \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \uc0ac\uc774\uc988, \uadf8\ub9ac\uace0 \uc5b4\ud718\uc9d1 \ud06c\uae30\ub97c \ud3ec\ud568\ud558\uc5ec \ubaa8\ub378\uc758 \uc8fc\uc694 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \uba85\uc2dc\uc801\uc73c\ub85c \uae30\uc220\ud569\ub2c8\ub2e4. \uc774 \uc815\ubcf4\ub294 \ubaa8\ub378\uc758 \ud06c\uae30\uc640 \ubcf5\uc7a1\uc131\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub3d5\uace0, \uc2e4\ud5d8 \uacb0\uacfc \ud574\uc11d\uc5d0 \uc911\uc694\ud55c \ub9e5\ub77d\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "A. \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98 \uc138\ubd80 \uc815\ubcf4"}, {"content": "| Parameter | Value |\n|---|---| \n| Optimizer | AdamW |\n| Adam \\(\\beta\\) parameters | (0.9, 0.95) |\n| Weight decay | 0.1 (applied only to parameters of rank \\(\\geq 2\\)) |\n| Gradient clipping threshold | 1.0 |\n| Learning rate | <math alttext=\"6\\times 10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"A2.T2.3.3.1.m1.1\"><semantics id=\"A2.T2.3.3.1.m1.1a\"><mrow id=\"A2.T2.3.3.1.m1.1.1\"><mn id=\"A2.T2.3.3.1.m1.1.1.2\">6</mn><mo id=\"A2.T2.3.3.1.m1.1.1.1\" lspace=\"0.222em\" rspace=\"0.222em\">\u00d7</mo><msup id=\"A2.T2.3.3.1.m1.1.1.3\"><mn id=\"A2.T2.3.3.1.m1.1.1.3.2\">10</mn><mrow id=\"A2.T2.3.3.1.m1.1.1.3.3\"><mo id=\"A2.T2.3.3.1.m1.1.1.3.3a\">\u2212</mo><mn id=\"A2.T2.3.3.1.m1.1.1.3.3.2\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T2.3.3.1.m1.1b\"><apply id=\"A2.T2.3.3.1.m1.1.1\"><times id=\"A2.T2.3.3.1.m1.1.1.1\"></times><cn id=\"A2.T2.3.3.1.m1.1.1.2\" type=\"integer\">6</cn><apply id=\"A2.T2.3.3.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"A2.T2.3.3.1.m1.1.1.3.1.\"></csymbol><cn id=\"A2.T2.3.3.1.m1.1.1.3.2\" type=\"integer\">10</cn><apply id=\"A2.T2.3.3.1.m1.1.1.3.3\"><minus id=\"A2.T2.3.3.1.m1.1.1.3.3.1.\"></minus><cn id=\"A2.T2.3.3.1.m1.1.1.3.3.2\" type=\"integer\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T2.3.3.1.m1.1c\">6\\times 10^{-4}</annotation><annotation encoding=\"application/x-llamapun\" id=\"A2.T2.3.3.1.m1.1d\">6 \\times 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> |\n| Learning rate scheduler | Constant |\n| Warmup steps | 1,000 |\n| Sequence length | 1,024 |\n| Batch size (tokens per update) | 2,048 (2,097,152 tokens) |\n| RoPE <math alttext=\"\\theta\" class=\"ltx_Math\" display=\"inline\" id=\"A2.T2.4.4.1.m1.1\"><semantics id=\"A2.T2.4.4.1.m1.1a\"><mi id=\"A2.T2.4.4.1.m1.1.1\">\\theta</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T2.4.4.1.m1.1b\"><ci id=\"A2.T2.4.4.1.m1.1.1\">\ud835\udf03</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T2.4.4.1.m1.1c\">\\theta</annotation><annotation encoding=\"application/x-llamapun\" id=\"A2.T2.4.4.1.m1.1d\">italic_\u03b8</annotation></semantics></math> | 10,000 |\n| Dropout | 0.0 |\n| Data type | bfloat16 |", "caption": "Table 2: Pretraining hyperparameters.", "description": "\ud45c 2\ub294 \ub17c\ubb38\uc758 3.1\uc808(\ud559\uc2b5 \uace1\uc120 \ubd84\uc11d)\uc5d0\uc11c \uc0ac\uc6a9\ub41c Transformer \ubaa8\ub378\uc758 \uc0ac\uc804 \ud559\uc2b5 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  AdamW \ucd5c\uc801\ud654\uae30\ub97c \uc0ac\uc6a9\ud558\uc600\uace0, \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30, \ub4dc\ub86d\uc544\uc6c3 \ube44\uc728 \ub4f1\uc758 \uc138\ubd80 \uc124\uc815\uac12\ub4e4\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc0ac\uc804 \ud559\uc2b5 \uacfc\uc815\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uc5ec \uc7ac\ud604\uc131\uc744 \ub192\uc785\ub2c8\ub2e4.", "section": "3.1 \ud559\uc2b5 \uace1\uc120 \ubd84\uc11d"}, {"content": "| Parameter | Value |\n|---|---| \n| Optimizer | AdamW |\n| Adam \\(\\beta\\) parameters | (0.9, 0.999) |\n| Weight decay | 0.0 |\n| Gradient clipping threshold | 1.0 |\n| Learning rate | <math>2\\times 10^{-5}</math> |\n| Learning rate scheduler | Cosine |\n| Warmup period (epochs) | 1.0 |\n| Sequence length | 1,024 |\n| Batch size (tokens per update) | 128 (131,072 tokens) |\n| RoPE \\(\\theta\\) | 10,000 |\n| Dropout | 0.0 |\n| Data type | bfloat16 |", "caption": "Table 3: Fine-tuning hyperparameters.", "description": "\ud45c 3\uc740 \ubcf8 \ub17c\ubb38\uc758 3.3\uc808\uc5d0\uc11c \uc218\ud589\ub41c \uc9c0\ub3c4 \ud559\uc2b5 \ud30c\uc778\ud29c\ub2dd\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \ud559\uc2b5\ub960, \ubc30\uce58 \ud06c\uae30, \ub4dc\ub86d\uc544\uc6c3 \ube44\uc728, \uadf8\ub9ac\uace0 RoPE(Rotary Position Embedding)\uc758 \u03b8\uac12 \ub4f1 \ud30c\uc778\ud29c\ub2dd \uacfc\uc815\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ub2e4\uc591\ud55c \uc124\uc815 \uac12\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc2e4\ud5d8\uc758 \uc7ac\ud604\uc131\uc744 \ud655\ubcf4\ud558\uace0, \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc758 \uc138\ubd80\uc801\uc778 \ub0b4\uc6a9\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3. Evaluations"}]