{"references": [{"fullname_first_author": "Dongyang Liu", "paper_title": "Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT", "publication_date": "2025-02-10", "reason": "This is the main paper, introducing the Lumina-Video framework and its core components."}, {"fullname_first_author": "Zhuo Li", "paper_title": "Lumina-Next: Making Lumina-T2X stronger and faster with Next-DiT", "publication_date": "2024-06-18", "reason": "This paper introduces Next-DiT, a crucial building block of Lumina-Video, which significantly improves efficiency and performance."}, {"fullname_first_author": "Peng Gao", "paper_title": "Lumina-T2X: Transforming text into any modality, resolution, and duration via flow-based large diffusion transformers", "publication_date": "2024-05-05", "reason": "This paper introduces Lumina-T2X, the foundation upon which Lumina-Video is built, establishing a strong baseline for text-to-video generation."}, {"fullname_first_author": "Yutong Liu", "paper_title": "CogVideo: Large-scale pretraining for text-to-video generation via transformers", "publication_date": "2023-08-20", "reason": "This paper provides the CogVideo model that serves as a significant contribution to the development of large-scale video generation models."}, {"fullname_first_author": "Jona S. Lipman", "paper_title": "Flow matching for generative modeling", "publication_date": "2023-00-00", "reason": "This paper details the flow matching technique, a core component in Lumina-Video, enhancing the quality and efficiency of video generation."}]}