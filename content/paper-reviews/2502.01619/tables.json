[{"content": "| Model | UT Method | HE+Fix | MBPP+Fix | (Hard) |\n|---|---|---|---|---|\n| Llama-3 8B | No UT | 27.22 | 16.31 | 11.76 |\n|  | Random | 51.90 | 30.46 | 17.06 |\n|  | Prompted | 51.90 | 28.92 | 22.94 |\n|  | UTGen | 53.80 | 37.54 | 28.82 |\n| Llama-3.1 8B | No UT | 31.65 | 10.15 | 11.18 |\n|  | Random | 62.03 | 33.54 | 13.53 |\n|  | Prompted | 56.33 | 28.00 | 24.71 |\n|  | UTGen | 67.09 | 36.92 | 28.23 |\n| Qwen-2.5 7B | No UT | 52.53 | 23.08 | 16.47 |\n|  | Random | 79.75 | 34.77 | 17.06 |\n|  | Prompted | 75.32 | 32.92 | 24.12 |\n|  | UTGen | 82.91 | 37.54 | 29.41 |", "caption": "Table 1: Evaluation on intrinsic UT generation metrics of different UT generation baselines and UTGen across different model families on MBPP+Fix (Hard) over 3 runs. Higher is better for all three intrinsic metrics.", "description": "\ud45c 1\uc740 MBPP+Fix (Hard) \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc138 \uac00\uc9c0 \ubaa8\ub378(Llama-3 8B, Llama-3.1 8B, Qwen-2.5 7B)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc138 \ubc88\uc758 \uc2e4\ud589\uc5d0 \uac78\uccd0 \ub2e4\uc591\ud55c \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131 \uae30\uc900(UTGen \ud3ec\ud568)\uc758 \ub0b4\uc7ac\uc801 \uc9c0\ud45c\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \ubb34\uc791\uc704 \ub2e8\uc704 \ud14c\uc2a4\ud2b8, \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud55c \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131, \uadf8\ub9ac\uace0 UTGen\uc744 \uc774\uc6a9\ud55c \ud559\uc2b5\ub41c \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131\uc758 \uc138 \uac00\uc9c0 \ubc29\ubc95\uc744 \ube44\uad50\ud569\ub2c8\ub2e4.  \uc138 \uac00\uc9c0 \ub0b4\uc7ac\uc801 \uc9c0\ud45c(\uacf5\uaca9\ub960, \ucd9c\ub825 \uc815\ud655\ub3c4, \uc815\ud655\ub3c4 \ubc0f \uacf5\uaca9\ub960) \ubaa8\ub450 \ub192\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131\uae30\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ub294 \uc138 \uac00\uc9c0 \uce21\uc815 \uae30\uc900(\uacf5\uaca9 \uc131\uacf5\ub960, \ucd9c\ub825 \uc815\ud655\ub3c4, \uadf8\ub9ac\uace0 \ub450 \uc9c0\ud45c \ubaa8\ub450 \ucda9\uc871\ud558\ub294 \ube44\uc728)\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.1. \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131\uc5d0 \ub300\ud55c \ub0b4\uc7ac\uc801 \ud3c9\uac00"}, {"content": "| UT Method | Acc. | \u0394 |\n|---|---|---|\n| Randomly-sampled (Qwen2.5) | 34.77 |  |\n|  - Output Test-time Scaling | 30.77 | - 4.0 |\n|  - Backtracking | 32.61 | - 2.2 |\n| UTGen (Qwen2.5) | 37.54 |  |\n|  - Output Test-time Scaling | 26.15 | - 11.4 |\n|  - Backtracking | 34.38 | - 3.2 |", "caption": "Table 2: Evaluating pass@1 accuracies after debugging with UTDebug, using UTs generated by UTGen and other baselines for 3 rounds, on HumanEval+Fix (HE+Fix), MPBB+Fix, and MBPP+Fix (Hard).", "description": "\ud45c 2\ub294 UTGen \ubc0f \uae30\ud0c0 \uae30\uc900 \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ud55c \ub2e8\uc704 \ud14c\uc2a4\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec UTDebug\ub85c \ub514\ubc84\uae45\ud55c \ud6c4 3\ub77c\uc6b4\ub4dc\uc5d0 \uac78\uccd0 HumanEval+Fix (HE+Fix), MBPP+Fix \ubc0f MBPP+Fix (Hard)\uc5d0 \ub300\ud55c pass@1 \uc815\ud655\ub3c4\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uacfc \ub2e8\uc704 \ud14c\uc2a4\ud2b8 \uc0dd\uc131 \ubc29\ubc95\uc5d0 \ub530\ub77c \ucf54\ub4dc \ub514\ubc84\uae45 \ud6c4\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec, UTGen \uae30\ubc18 \ub2e8\uc704 \ud14c\uc2a4\ud2b8\uc758 \ud6a8\uacfc\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.2. \uc0dd\uc131\ub41c \ub2e8\uc704 \ud14c\uc2a4\ud2b8\uc758 \ub514\ubc84\uae45 \uc601\ud5a5"}, {"content": "| Model | UT Method | HE+Fix Attack Rate | HE+Fix Out Acc. | HE+Fix Acc. \u2229 Attack | MBPP+Fix Attack Rate | MBPP+Fix Out Acc. | MBPP+Fix Acc. \u2229 Attack |\n|---|---|---|---|---|---|---|---| \n| Llama-3 8B | Random | 89.63 | **72.97** | **72.97** | 62.56 | 41.85 | 24.28 |\n|  | Prompted | 95.73 | 39.59 | 38.78 | 62.67 | 29.64 | 16.41 |\n|  | UTGen | **96.34** | 53.27 | 52.04 | **67.18** | **42.67** | **26.87** |\n| Llama-3.1 8B | Random | 76.02 | **63.52** | **63.52** | 47.28 | 36.0 | 21.33 |\n|  | Prompted | 92.68 | 34.53 | 33.89 | 59.28 | 19.38 | 11.08 |\n|  | UTGen | **96.54** | 56.38 | 55.76 | **62.77** | **43.59** | **25.54** |\n| Qwen-2.5 7B | Random | 90.85 | **87.36** | **86.47** | 55.28 | **52.31** | 30.38 |\n|  | Prompted | 93.29 | 54.55 | 53.91 | 62.97 | 35.29 | 22.60 |\n|  | UTGen | **96.54** | 72.90 | 72.48 | **65.54** | **32.82** | **32.82** |", "caption": "Table 3: Ablating components of UTDebug\u2019s pipeline (cf. Section\u00a03.3) for two different unit test generation methods (including UTGen) on MBPP+Fix using Qwen2.5.", "description": "\uc774 \ud45c\ub294 Qwen2.5 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec MBPP+Fix \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub450 \uac00\uc9c0 \uc720\ub2db \ud14c\uc2a4\ud2b8 \uc0dd\uc131 \ubc29\ubc95(UTGen \ud3ec\ud568)\uc5d0 \ub300\ud574 UTDebug \ud30c\uc774\ud504\ub77c\uc778\uc758 \uad6c\uc131 \uc694\uc18c\ub4e4\uc744 \uc81c\uac70\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \ud655\uc7a5(test-time scaling)\uacfc \uc5ed\ucd94\uc801(backtracking) \uae30\ub2a5\uc744 \uac01\uac01 \uc81c\uac70\ud588\uc744 \ub54c \uc815\ud655\ub3c4(accuracy)\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 UTDebug \ud30c\uc774\ud504\ub77c\uc778\uc758 \uac01 \uad6c\uc131\uc694\uc18c\uc758 \uc911\uc694\uc131\uc744 \ud3c9\uac00\ud558\uace0, \uc720\ub2db \ud14c\uc2a4\ud2b8 \uc0dd\uc131 \ubc0f \ub514\ubc84\uae45 \uacfc\uc815\uc5d0\uc11c\uc758 \ud6a8\uc728\uc131\uc744 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.3 UTDEBUG \ud30c\uc774\ud504\ub77c\uc778\uc758 \ud6a8\uc728\uc131"}]