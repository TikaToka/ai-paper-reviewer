[{"content": "| T2V Model | Date | #Videos | #Anno Triplets | Resolution | Duration |\n|---|---|---|---|---|---|---|\n| **Pre-Sora-Era Models** |  |  |  |  |  |  |\n| Gen2 [2023] | 23.06 | 6k | 13k | 768 \u00d7 1408 | 4s |\n| SVD [2023] | 23.11 | 6k | 13k | 576 \u00d7 1024 | 4s |\n| Pika 1.0 [2023] | 23.12 | 6k | 13k | 720 \u00d7 1280 | 3s |\n| Vega [2023] | 23.12 | 6k | 13k | 576 \u00d7 1024 | 4s |\n| Pixverse v1 [2024] | 24.01 | 6k | 13k | 768 \u00d7 1408 | 4s |\n| HiDream [2024] | 24.01 | 0.3k | 0.3k | 768 \u00d7 1344 | 5s |\n| **Modern Models** |  |  |  |  |  |  |\n| Dreamina [2024] | 24.03 | 16k | 68k | 720 \u00d7 1280 | 6s |\n| Luma [2024] | 24.06 | 16k | 57k | 752 \u00d7 1360 | 5s |\n| Gen3 [2024] | 24.06 | 16k | 55k | 768 \u00d7 1280 | 5s |\n| Kling 1.0 [2024] | 24.06 | 6k | 33k | 384 \u00d7 672 | 5s |\n| Pixverse v2 [2024] | 24.07 | 16k | 58k | 576 \u00d7 1024 | 5s |\n| Kling 1.5 [2024] | 24.09 | 7k | 28k | 704 \u00d7 1280 | 5s |", "caption": "Table 1: Statistics of the collected training dataset. We utilized 12 text-to-video models to generate a total of 108k videos from 16k unique prompts. This process ultimately resulted in 182k annotated triplets, each consisting of a prompt paired with two videos and corresponding preference annotations.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc758 \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ucd1d 16,000\uac1c\uc758 \uace0\uc720 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec 12\uac1c\uc758 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \ubaa8\ub378\ub85c 108,000\uac1c\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud588\uc2b5\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc744 \ud1b5\ud574 \ud504\ub86c\ud504\ud2b8\uc640 \ub450 \uac1c\uc758 \ube44\ub514\uc624, \uadf8\ub9ac\uace0 \ud574\ub2f9 \uc120\ud638\ub3c4 \uc8fc\uc11d\uc73c\ub85c \uad6c\uc131\ub41c 182,000\uac1c\uc758 \uc5b4\ub178\ud14c\uc774\uc158\ub41c \ud2b8\ub9ac\ud50c\ub9bf\uc744 \uc5bb\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "3.1 \uc778\uac04 \uc120\ud638\ub3c4 \ub370\uc774\ud130 \uc218\uc9d1"}, {"content": "| Method | GenAI-Bench |  | VideoGen-RewardBench |  |  |  |  |  |  |  | \n|---|---|---|---|---|---|---|---|---|---|---|---| \n|  | Overall Accuracy |  | Overall Accuracy | VQ Accuracy |  | MQ Accuracy |  | TA Accuracy |  |  | \n|  | w/ Ties | w/o Ties | w/ Ties | w/o Ties | w/ Ties | w/o Ties | w/ Ties | w/o Ties | w/ Ties | w/o Ties | \n| Random | 33.67 | 49.84 | 41.86 | 50.30 | 47.42 | 49.86 | 59.07 | 49.64 | 37.25 | 50.40 | \n| VideoScore (He et al., 2024) | 49.03 | 71.69 | 41.80 | 50.22 | 47.41 | 47.72 | 59.05 | 51.09 | 37.24 | 50.34 | \n| LiFT* (Wang et al., 2024b) | 37.06 | 58.39 | 39.08 | 57.26 | 47.53 | 55.97 | 59.04 | 54.91 | 33.79 | 55.43 | \n| VisionRewrd (Xu et al., 2024a) | 51.56 | 72.41 | 56.77 | 67.59 | 47.43 | 59.03 | 59.03 | 60.98 | 46.56 | 61.15 | \n| Ours | 49.41 | 72.89 | 61.26 | 73.59 | 59.68 | 75.66 | 66.03 | 74.70 | 53.80 | 72.20 | ", "caption": "Table 2: Preference accuracy on GenAI-Bench and VideoGen-Eval. w/ Ties indicates that accuracy is calculated with ties included\u00a0(Deutsch et\u00a0al., 2023), and w/o Ties excludes tied pairs when calculating accuracy. * denotes that for LiFT, ties prediction are randomly converted to chosen/rejected with a 0.5 probability due to a large number of ties produced by the model. Bold: best performance.", "description": "\ud45c 2\ub294 GenAI-Bench\uc640 VideoGen-Eval \ub450 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc758 \uc120\ud638\ub3c4 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'w/ Ties'\ub294 \ub3d9\uc810\uc744 \ud3ec\ud568\ud558\uc5ec \uc815\ud655\ub3c4\ub97c \uacc4\uc0b0\ud55c \uacb0\uacfc\uc774\uace0, 'w/o Ties'\ub294 \ub3d9\uc810\uc744 \uc81c\uc678\ud558\uace0 \uacc4\uc0b0\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. LiFT \ubc29\ubc95\uc758 \uacbd\uc6b0, \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ub3d9\uc810 \uc608\uce21\uac12\uc774 \ub9ce\uc544 \ubb34\uc791\uc704\ub85c \uc120\ud0dd/\uac70\ubd80\ub85c \ubcc0\ud658(0.5 \ud655\ub960)\ud558\uc5ec \uc815\ud655\ub3c4\ub97c \uacc4\uc0b0\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc815\ud655\ub3c4\ub97c \uae30\ub85d\ud55c \ubc29\ubc95\uc740 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  GenAI-Bench\ub294 \uc774\uc804(pre-Sora) \uc2dc\ub300\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 VideoGen-Eval\uc740 \ucd5c\uc2e0 \ubaa8\ub378 \uc131\ub2a5 \ud3c9\uac00\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd98 \uc810\uc744 \ucc38\uace0\ud574\uc57c \ud569\ub2c8\ub2e4.", "section": "5. Experiments"}, {"content": "| Variants | RM Type | Separate Tokens | GenAI-Bench Overall Accuracy w/ Ties | GenAI-Bench Overall Accuracy w/o Ties | VideoGen-RewardBench Overall Accuracy w/ Ties | VideoGen-RewardBench Overall Accuracy w/o Ties | VideoGen-RewardBench VQ Accuracy w/ Ties | VideoGen-RewardBench VQ Accuracy w/o Ties | VideoGen-RewardBench MQ Accuracy w/ Ties | VideoGen-RewardBench MQ Accuracy w/o Ties | VideoGen-RewardBench TA Accuracy w/ Ties | VideoGen-RewardBench TA Accuracy w/o Ties |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| I | Regression |  | 48.28 | 71.13 | 58.39 | 70.16 | 54.23 | 73.61 | 61.16 | 65.56 | 52.60 | 70.95 |\n| II | BT |  | 47.74 | 71.21 | 61.22 | 72.58 | 52.33 | 77.10 | 59.43 | 73.50 | 53.06 | 71.62 |\n| III | BTT |  | 48.27 | 70.89 | 61.50 | 73.39 | 60.52 | 76.31 | 64.64 | 72.40 | 53.55 | 72.12 |\n| IV | BTT | \u2713 | 49.41 | 72.89 | 61.26 | 73.59 | 59.68 | 75.66 | 66.03 | 74.70 | 53.80 | 72.20 |", "caption": "Table 3: Ablation study on reward model type, seprate tokens and data augmentation. Bold: Best Performance.", "description": "\uc774 \ud45c\ub294 \ube44\ub514\uc624 \ubcf4\uc0c1 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, \ubcf4\uc0c1 \ubaa8\ub378 \uc720\ud615(\ud68c\uadc0, Bradley-Terry, Bradley-Terry-With-Ties), \ud1a0\ud070 \ubd84\ub9ac \uc0ac\uc6a9 \uc5ec\ubd80, \uadf8\ub9ac\uace0 \ub370\uc774\ud130 \uc99d\uac15\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uac01 \uc2e4\ud5d8 \uc870\uac74\uc5d0\uc11c GenAI-Bench \ubc0f VideoGen-RewardBench \ub450 \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc804\uccb4 \uc815\ud655\ub3c4\uc640 VQ, MQ, TA \uc138 \uac00\uc9c0 \ucc28\uc6d0\ubcc4 \uc815\ud655\ub3c4\ub97c \uc81c\uc2dc\ud558\uba70, \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 \uacb0\uacfc\ub97c \uad75\uac8c \ud45c\uc2dc\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub2e4\ucc28\uc6d0 \ube44\ub514\uc624 \ubcf4\uc0c1 \ubaa8\ub378\uc758 \uc124\uacc4 \uc120\ud0dd\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubd84\uc11d\ud558\uc5ec \ucd5c\uc801\uc758 \ubaa8\ub378 \uad6c\uc131\uc744 \ub3c4\ucd9c\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3. VideoReward"}, {"content": "| Method | VBench |  |  |  |  |  | VideoGen-Eval |  |  | TA-Hard |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|  | Total | Quality | Sementic | VQ | MQ | TA | VQ | MQ | TA | VQ | MQ | TA |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Pretrained | 83.19 | **84.37** | 78.46 | 50.0 | 50.0 | 50.0 | 50.0 | 50.0 | 50.0 | 50.0 | 50.0 | 50.0 |\n| SFT | 82.31 | 83.13 | 79.04 | 51.28 | 65.21 | 52.84 | 61.27 | 76.13 | 46.35 | 57.75 | 76.06 | 57.75 |\n| Flow-RWR | 82.27 | 83.19 | 78.59 | 51.55 | 63.9 | 53.43 | 59.05 | 69.7 | 48.35 | 61.97 | 78.87 | 55.71 |\n| Flow-DPO (<math alttext=\"\\beta_{t}=\\beta(1-t)^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T4.5.1.1.1.m1.1\"><semantics id=\"S5.T4.5.1.1.1.m1.1a\"><mrow id=\"S5.T4.5.1.1.1.m1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.cmml\"><msub id=\"S5.T4.5.1.1.1.m1.1.1.3\" xref=\"S5.T4.5.1.1.1.m1.1.1.3.cmml\"><mi id=\"S5.T4.5.1.1.1.m1.1.1.3.2\" xref=\"S5.T4.5.1.1.1.m1.1.1.3.2.cmml\">\u03b2</mi><mi id=\"S5.T4.5.1.1.1.m1.1.1.3.3\" xref=\"S5.T4.5.1.1.1.m1.1.1.3.3.cmml\">t</mi></msub><mo id=\"S5.T4.5.1.1.1.m1.1.1.2\" xref=\"S5.T4.5.1.1.1.m1.1.1.2.cmml\">=</mo><mrow id=\"S5.T4.5.1.1.1.m1.1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.cmml\"><mi id=\"S5.T4.5.1.1.1.m1.1.1.1.3\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.3.cmml\">\u03b2</mi><mo id=\"S5.T4.5.1.1.1.m1.1.1.1.2\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.2.cmml\">\u2062</mo><msup id=\"S5.T4.5.1.1.1.m1.1.1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.cmml\"><mrow id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.cmml\"><mo id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.cmml\"><mn id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.2\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.2.cmml\">1</mn><mo id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\">-</mo><mi id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.3\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.3.cmml\">t</mi></mrow><mo id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.cmml\">)</mo></mrow><mn id=\"S5.T4.5.1.1.1.m1.1.1.1.1.3\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.3.cmml\">2</mn></msup></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.5.1.1.1.m1.1b\"><apply id=\"S5.T4.5.1.1.1.m1.1.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1\"><eq id=\"S5.T4.5.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.2\"></eq><apply id=\"S5.T4.5.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S5.T4.5.1.1.1.m1.1.1.3.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.3\"><msub /></csymbol><ci id=\"S5.T4.5.1.1.1.m1.1.1.3.2.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.3.2\">\ud835\udefd</ci><ci id=\"S5.T4.5.1.1.1.m1.1.1.3.3.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.3.3\">\ud835\udc61</ci></apply><apply id=\"S5.T4.5.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1\"><times id=\"S5.T4.5.1.1.1.m1.1.1.1.2.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.2\"></times><ci id=\"S5.T4.5.1.1.1.m1.1.1.1.3.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.3\">\ud835\udefd</ci><apply id=\"S5.T4.5.1.1.1.m1.1.1.1.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T4.5.1.1.1.m1.1.1.1.1.2.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1\"><msup /></csymbol><apply id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1\"><minus id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.1\"></minus><cn id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.2.cmml\" type=\"integer\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.2\">1</cn><ci id=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.1.1.1.3\">\ud835\udc61</ci></apply><cn id=\"S5.T4.5.1.1.1.m1.1.1.1.1.3.cmml\" type=\"integer\" xref=\"S5.T4.5.1.1.1.m1.1.1.1.1.3\">2</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.5.1.1.1.m1.1c\">\\beta_{t}=\\beta(1-t)^{2}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S5.T4.5.1.1.1.m1.1d\">italic_\u03b2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_\u03b2 ( 1 - italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>) | 80.90 | 81.52 | 78.42 | 87.78 | **82.36** | 51.02 | 88.44 | **91.23** | 28.14 | **84.29** | **83.10** | 38.03 |\n| Flow-DPO | **83.41** | 84.19 | **80.26** | **93.42** | 69.08 | **75.43** | **90.95** | 81.01 | **68.26** | 77.46 | 71.43 | **73.24** |", "caption": "Table 4: Multi-dimensional alignment with VQ:MQ:TA = 1:1:1. Bold: Best performance. Although Flow-DPO with a timestep-dependent \u03b2\ud835\udefd\\betaitalic_\u03b2 achieves high VQ and MQ reward win rates, it exhibits significant reward hacking. In contrast, Flow-DPO with a constant \u03b2\ud835\udefd\\betaitalic_\u03b2 achieves high VQ, MQ, and TA scores while avoiding reward hacking.", "description": "\ud45c 4\ub294 VQ, MQ, TA \uc138 \uac00\uc9c0 \uce21\uba74\uc5d0 \ub300\ud574 1:1:1 \ube44\uc728\ub85c \ub2e4\ucc28\uc6d0 \uc815\ub82c\uc744 \uc218\ud589\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc2dc\uac04\uc5d0 \ub530\ub77c \ubcc0\ud654\ud558\ub294 \ubca0\ud0c0(\u03b2) \uac12\uc744 \uc0ac\uc6a9\ud55c Flow-DPO\ub294 VQ\uc640 MQ\uc5d0\uc11c \ub192\uc740 \ubcf4\uc0c1 \uc2b9\ub960\uc744 \ub2ec\uc131\ud558\uc9c0\ub9cc, \uc0c1\ub2f9\ud55c \ubcf4\uc0c1 \ud574\ud0b9 \ubb38\uc81c\ub97c \ubcf4\uc785\ub2c8\ub2e4. \ubc18\uba74, \uc77c\uc815\ud55c \ubca0\ud0c0(\u03b2) \uac12\uc744 \uc0ac\uc6a9\ud55c Flow-DPO\ub294 \ubcf4\uc0c1 \ud574\ud0b9 \uc5c6\uc774 VQ, MQ, TA \uc138 \uac00\uc9c0 \uce21\uba74 \ubaa8\ub450\uc5d0\uc11c \ub192\uc740 \uc810\uc218\ub97c \ub2ec\uc131\ud569\ub2c8\ub2e4.  \uc989, \uc2dc\uac04\uc5d0 \ub530\ub77c \ubcc0\ud558\ub294 \u03b2\ub294 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ub3c4\uc6c0\uc774 \ub418\uc9c0\ub9cc, \ubcf4\uc0c1 \ud574\ud0b9\uc774\ub77c\ub294 \ubd80\uc791\uc6a9\uc744 \ubc1c\uc0dd\uc2dc\ud0a4\ub294 \ubc18\uba74, \uc77c\uc815\ud55c \u03b2\ub294 \ubcf4\uc0c1 \ud574\ud0b9 \uc5c6\uc774\ub3c4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Video Alignment"}, {"content": "| Method | VBench Total | VBench Quality | VBench Semantic | VBench TA | VideoGen-Eval TA | TA-Hard TA |\n|---|---|---|---|---|---|---|\n| Pretrained | 83.19 | **84.37** | 78.46 | 50.00 | 50.00 | 50.00 |\n| SFT | 82.71 | 83.48 | 79.62 | 52.88 | 53.81 | 64.79 |\n| Flow-RWR | 82.40 | 83.36 | 78.58 | 59.66 | 49.50 | 66.20 |\n| Flow-DPO (<math alttext=\"\\beta_{t}=\\beta(1-t)^{2}\" class=\"ltx_Math\" display=\"inline\">\\beta_{t}=\\beta(1-t)^{2}</math>) | 82.35 | 83.00 | 79.75 | 63.67 | 55.95 | 71.83 |\n| Flow-DPO | **83.38** | 84.28 | **79.80** | **69.09** | **65.49** | **84.51** |", "caption": "Table 5: Single-dimensional alignment with TA. Bold: Best performance. Flow-DPO with a constant \u03b2\ud835\udefd\\betaitalic_\u03b2 is the most effective method, achieving best performance without reward hacking.", "description": "\ud45c 5\ub294 \ud14d\uc2a4\ud2b8 \uc815\ub82c(TA)\uc5d0 \ub300\ud55c \ub2e8\uc77c \ucc28\uc6d0 \uc815\ub82c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uad75\uc740 \uae00\uc528\ub294 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc77c\uc815\ud55c \u03b2\ub97c \uc0ac\uc6a9\ud55c Flow-DPO\uac00 \ubcf4\uc0c1 \ud574\ud0b9 \uc5c6\uc774 \ucd5c\uace0\uc758 \uc131\ub2a5\uc744 \ub2ec\uc131\ud55c \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778 \ubc29\ubc95\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95(SFT, Flow-RWR, \uc2dc\uac04\uc5d0 \ub530\ub978 \u03b2\ub97c \uc0ac\uc6a9\ud55c Flow-DPO, \uc77c\uc815\ud55c \u03b2\ub97c \uc0ac\uc6a9\ud55c Flow-DPO)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud14d\uc2a4\ud2b8 \uc815\ub82c(TA)\uc5d0 \ub300\ud55c \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc815\ub82c \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uac01 \ubc29\ubc95\uc758 \uc804\ubc18\uc801\uc778 \ud488\uc9c8, \uc758\ubbf8\ub860\uc801 \uc77c\uad00\uc131 \ubc0f TA \uc810\uc218\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc0c1 \ud574\ud0b9(reward hacking) \ubb38\uc81c \ubc1c\uc0dd \uc5ec\ubd80\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.", "section": "4. Video Alignment"}, {"content": "| VQ:MQ:TA | VQ | MQ | TA |\n|---|---|---|---|\n| 0:0:1 | 60.56 | 46.48 | 70.42 |\n| 0.1:0.1:0.8 | 66.50 | 63.73 | 60.86 |\n| 0.1:0.1:0.6 | 68.94 | 67.59 | 53.28 |\n| 0.5:0.5:0 | 86.43 | 93.23 | 26.65 |", "caption": "Table 6: Reward guidance using multi-dimensional rewards on VideoGen-Eval prompts. The weighted reward guidence allows users to apply arbitrary weightings to multiple alignment objectives during inference to meet personalized user requirements.", "description": "\ud45c 6\uc740 VideoGen-Eval \ud504\ub86c\ud504\ud2b8\uc5d0\uc11c \ub2e4\ucc28\uc6d0 \ubcf4\uc0c1\uc744 \uc0ac\uc6a9\ud55c \ubcf4\uc0c1 \uc548\ub0b4\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac00\uc911 \ubcf4\uc0c1 \uc548\ub0b4\ub294 \uc0ac\uc6a9\uc790\uac00 \ucd94\ub860 \uc911\uc5d0 \uc5ec\ub7ec \uc815\ub82c \ubaa9\ud45c\uc5d0 \uc784\uc758\uc758 \uac00\uc911\uce58\ub97c \uc801\uc6a9\ud558\uc5ec \uac1c\uc778 \ub9de\ucda4\ud615 \uc0ac\uc6a9\uc790 \uc694\uad6c \uc0ac\ud56d\uc744 \ucda9\uc871\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.  \ub2e4\uc2dc \ub9d0\ud574, \uc0ac\uc6a9\uc790\ub294 \ube44\uc8fc\uc5bc \ud488\uc9c8(VQ), \ubaa8\uc158 \ud488\uc9c8(MQ), \ud14d\uc2a4\ud2b8 \uc815\ub82c(TA) \uc138 \uac00\uc9c0 \uce21\uba74 \uc911 \uc5b4\ub5a4 \uce21\uba74\uc5d0 \ub354 \uc911\uc810\uc744 \ub458\uc9c0 \uac00\uc911\uce58\ub97c \uc870\uc808\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \ud488\uc9c8\uc744 \uc790\uc2e0\uc5d0\uac8c \ub9de\ucdb0 \uc870\uc815\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4.3 Noisy Reward Guidance"}, {"content": "|       | VQ   | MQ   | TA   |\n| :---- | :---- | :---- | :---- |\n| VDM w/o noise | 37.1 | 38.6 | 52.9 |\n| VDM w/ noise  | 66.2 | 74.6 | 32.4 |", "caption": "Table 7: Reward guidance using only MQ rewards on TA-Hard. The reward model trained with noised latents guides the generation effectively, while the model trained on cleaned latents fails to provide meaningful gradient guidance for noised latents.", "description": "\ud45c 7\uc740 TA-Hard \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud574 MQ \ubcf4\uc0c1\ub9cc\uc744 \uc0ac\uc6a9\ud55c \ubcf4\uc0c1 \uc548\ub0b4\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc7a1\uc74c\uc774 \ud3ec\ud568\ub41c \uc7a0\uc7ac \ubcc0\uc218\ub85c \ud6c8\ub828\ub41c \ubcf4\uc0c1 \ubaa8\ub378\uc740 \uc0dd\uc131\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc548\ub0b4\ud558\uc9c0\ub9cc, \uc815\uc81c\ub41c \uc7a0\uc7ac \ubcc0\uc218\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc740 \uc7a1\uc74c\uc774 \ud3ec\ud568\ub41c \uc7a0\uc7ac \ubcc0\uc218\uc5d0 \ub300\ud574 \uc758\ubbf8 \uc788\ub294 \uae30\uc6b8\uae30 \uc548\ub0b4\ub97c \uc81c\uacf5\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4.", "section": "5.2 Video Alignment"}, {"content": "| Evaluation Dimension | Key Points Summary |\n|---|---| \n| Visual Quality | - **Image Reasonableness**: The image should be objectively reasonable. <br> - **Clarity**: The image should be clear and visually sharp. <br> - **Detail Richness**: The level of intricacy in the generation of details. <br> - **Aesthetic Creativity**: The generated videos should be aesthetically pleasing. <br> - **Safety**: The generated video should not contain any disturbing or uncomfortable content. |\n| Motion Quality | - **Dynamic Stability**: The continuity and stability between frames. <br> - **Dynamic Reasonableness**: The dynamic movement should align with natural physical laws. <br> - **Motion Aesthetic Quality**: The dynamic elements should be harmonious and not stiff. <br> - **Naturalness of Dynamic Fusion**: The edges should be clear during the dynamic process. <br> - **Motion Clarity**: The motion should be easy to identify. <br> - **Dynamic Degree**: The movement should be clear, avoiding still scenes. |\n| Text Alignment | - **Subject Relevance**: Relevance to the described subject characteristics and subject details. <br> - **Dynamic Information Relevance**: Relevance to actions and postures as described in the text. <br> - **Environmental Relevance**: Relevance of the environment to the input text. <br> - **Style Relevance**: Relevance to the style descriptions, if exists. <br> - **Camera Movement Relevance**: Relevance to the camera descriptions, if exists. |", "caption": "Table 8: Key points summary outlined in annotation guidelines for each evaluation dimension.", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 \uc8fc\uc11d\uc5d0 \uc124\uba85\ub41c \uac83\ucc98\ub7fc \uac01 \ud3c9\uac00 \ucc28\uc6d0\uc5d0 \ub300\ud574 \uc5b4\ub178\ud14c\uc774\uc158 \uc9c0\uce68\uc5d0 \uc694\uc57d\ub41c \uc8fc\uc694 \uc694\uc810\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub354 \uc790\uc138\ud788 \uc124\uba85\ud558\uc790\uba74,  \uc2dc\uac01\uc801 \ud488\uc9c8, \ub3d9\uc791 \ud488\uc9c8, \uadf8\ub9ac\uace0 \ud14d\uc2a4\ud2b8 \uc815\ud569 \uc138 \uac00\uc9c0 \uc8fc\uc694 \ucc28\uc6d0\uc5d0 \ub300\ud55c \ud3c9\uac00 \uae30\uc900\uc744 \uc138\ubd84\ud654\ud558\uc5ec \uac01\uac01\uc5d0 \ub300\ud55c \ud3c9\uac00 \ud56d\ubaa9\ub4e4\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \uc2dc\uac01\uc801 \ud488\uc9c8\uc5d0\ub294 \ud569\ub9ac\uc131, \uc120\uba85\ub3c4, \ub514\ud14c\uc77c \ud48d\ubd80\ud568, \ubbf8\uc801 \ucc3d\uc758\uc131, \uc548\uc804\uc131 \ub4f1\uc758 \ud558\uc704 \ud56d\ubaa9\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uac01 \ud558\uc704 \ud56d\ubaa9\uc5d0 \ub300\ud574 \ud3c9\uac00\uc790\uac00 \uace0\ub824\ud574\uc57c \ud560 \uad6c\uccb4\uc801\uc778 \ub0b4\uc6a9\ub4e4\uc774 \uc790\uc138\ud788 \uae30\uc220\ub418\uc5b4 \uc788\uc5b4\uc11c, \ubcf4\ub2e4 \uc815\ud655\ud558\uace0 \uc77c\uad00\uc131 \uc788\ub294 \uc5b4\ub178\ud14c\uc774\uc158 \uc791\uc5c5\uc744 \uc720\ub3c4\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uc8fc\uad00\uc801\uc778 \ud310\ub2e8\uc744 \ucd5c\uc18c\ud654\ud558\uace0,  \uac1d\uad00\uc801\uc778 \ud3c9\uac00\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.", "section": "3.1. Human Preference Data Collection"}, {"content": "| Dimensions | Description |\n|---|---| \n| Image Reasonableness | The image should be objectively reasonable. |\n| Clarity | The image should be clear and visually sharp. |\n| Detail Richness | The level of intricacy in the generation of details. |\n| Aesthetic Creativity | The generated videos should be aesthetically pleasing. |\n| Safety | The generated video should not contain any disturbing or uncomfortable content. |", "caption": "Table 9: Comparison between GenAI-Bench and VideoGen-RewardBench. Eariler Models indicates that pre-Sora-era T2V models, and Modern Models indicates that T2V models after Sora.", "description": "\ud45c 9\ub294 GenAI-Bench\uc640 VideoGen-RewardBench\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubca4\uce58\ub9c8\ud06c \ubaa8\ub450 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ub370\uc774\ud130\uc14b\uc774\uc9c0\ub9cc, GenAI-Bench\ub294 Sora \uc774\uc804\uc758 \uad6c\ud615 \ubaa8\ub378\uc744 \uc911\uc2ec\uc73c\ub85c \uad6c\uc131\ub41c \ubc18\uba74, VideoGen-RewardBench\ub294 Sora \uc774\ud6c4 \ucd5c\uc2e0 \ubaa8\ub378\uc744 \uc911\uc2ec\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ub530\ub77c\uc11c, GenAI-Bench\ub294 \ub354 \uc9e7\uc740 \ube44\ub514\uc624 \uae38\uc774(2~2.5\ucd08)\uc640 \ub0ae\uc740 \ud574\uc0c1\ub3c4(\uc8fc\ub85c 320x512)\ub97c \uac16\ub294 \ubc18\uba74, VideoGen-RewardBench\ub294 \ub354 \uae34 \ube44\ub514\uc624 \uae38\uc774(4~6\ucd08)\uc640 \ub192\uc740 \ud574\uc0c1\ub3c4(480x720~576x1024)\ub97c \uac16\uc2b5\ub2c8\ub2e4. \ub610\ud55c,  VideoGen-RewardBench\ub294 \ucd5c\uc2e0 \ubaa8\ub378\uc758 \ub2e4\uc591\uc131\uc744 \ub354 \uc798 \ubc18\uc601\ud558\uba70, \ub354 \ud3ec\uad04\uc801\uc778 \uce21\uba74\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \ucd94\uac00\uc801\uc778 \ucc28\uc6d0\uc758 \ud3c9\uac00(\uc804\uccb4\uc801\uc778 \ud488\uc9c8)\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub450 \ubca4\uce58\ub9c8\ud06c\uc758 \uc8fc\uc694 \ucc28\uc774\uc810\uacfc \uac01 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ud3ec\ud568\ub41c \ubaa8\ub378 \uc218, \ud504\ub86c\ud504\ud2b8 \uc218, \ube44\ub514\uc624 \uc218, \uc8fc\uc11d \uc218, \ubc0f \ud3c9\uac00 \ucc28\uc6d0 \ub4f1\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1 Human Preference Data Collection"}, {"content": "| Dimensions | Description |\n|---|---| \n| **Dynamic Stability** | The continuity and stability between frames. |\n| **Dynamic Reasonableness** | The dynamic movement should align with natural physical laws. |\n| **Motion Aesthetic Quality** | The dynamic elements should be harmonious and not stiff. |\n| **Naturalness of Dynamic Fusion** | The edges should be clear during the dynamic process. |\n| **Motion Clarity** | The motion should be easy to identify. |\n| **Dynamic Degree** | The movement should be clear, avoiding still scenes. |", "caption": "Table 10: Hyperparameters for Alignment Algorithms", "description": "\ud45c 10\uc740 \ub17c\ubb38\uc758 \ube44\ub514\uc624 \uc815\ub82c \uc54c\uace0\ub9ac\uc998\uc5d0 \uc0ac\uc6a9\ub41c \ucd08\ub9e4\uac1c\ubcc0\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\uae30\uc5d0\ub294 \uc138 \uac00\uc9c0 \uc8fc\uc694 \uc54c\uace0\ub9ac\uc998\uc778 SFT(Supervised Fine-Tuning), Flow-RWR(Reward Weighted Regression for Flow), Flow-DPO(Direct Preference Optimization for Flow)\uc5d0 \ub300\ud55c \ucd08\ub9e4\uac1c\ubcc0\uc218\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uac01 \uc54c\uace0\ub9ac\uc998\uc5d0 \ub300\ud574 \ud559\uc2b5 \uc804\ub7b5, LoRA(Low-Rank Adaptation)\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(\uc54c\ud30c, \ub4dc\ub86d\uc544\uc6c3, R), \ucd5c\uc801\ud654\uae30, \ud559\uc2b5\ub960, \uc5d0\ud3ec\ud06c \uc218, \ubc30\uce58 \ud06c\uae30 \ub4f1\uc774 \uc0c1\uc138\ud788 \ub098\uc5f4\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. Flow-DPO\uc758 \uacbd\uc6b0 \uaddc\uc81c\ud654 \ud30c\ub77c\ubbf8\ud130\uc778 \ubca0\ud0c0(\u03b2)\uac12\ub3c4 \uba85\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Video Alignment"}, {"content": "| Considering the **relevance** to the input text prompt description. |\n|---|---| \n| - **Subject Relevance** Relevance to the described subject characteristics and subject details. | \n| - **Dynamic Information Relevance**: Relevance to actions and postures as described in the text. | \n| - **Environmental Relevance**: Relevance of the environment to the input text. | \n| - **Style Relevance**: Relevance to the style descriptions, if exists. | \n| - **Camera Movement Relevance**: Relevance to the camera descriptions, if exists. | ", "caption": "Table 11: Hyperparameters for reward modeling.", "description": "\ud45c 11\uc740 \ub17c\ubb38\uc758 \ubcf4\uc0c1 \ubaa8\ub378\ub9c1\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VLM(Vision-Language Model)\uacfc VDM(Video Diffusion Model) \ub450 \uac00\uc9c0 \ubaa8\ub378\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \uac01\uac01 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud559\uc2b5 \uc804\ub7b5, LoRA(Low-Rank Adaptation) \uad00\ub828 \uc124\uc815(\uc54c\ud30c, \ub4dc\ub86d\uc544\uc6c3, R, \ub300\uc0c1 \ubaa8\ub4c8), \ucd5c\uc801\ud654 \uae30\ubc95, \ud559\uc2b5\ub960, \uc5d0\ud3ed \uc218, \ubc30\uce58 \ud06c\uae30, \ubcf4\uc0c1 \ucc28\uc6d0 \ub4f1\uc758 \uc138\ubd80\uc801\uc778 \uc124\uc815 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubcf4\uc0c1 \ubaa8\ub378\uc758 \ud559\uc2b5 \uacfc\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "3. VideoReward"}]