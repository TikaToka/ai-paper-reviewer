{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report on GPT-4, a state-of-the-art large language model, which is relevant to the paper's study on medical hallucinations in LLMs."}, {"fullname_first_author": "Ziwei Ji", "paper_title": "Survey of hallucination in natural language generation", "publication_date": "2023-12-01", "reason": "This survey paper provides a comprehensive overview of the phenomenon of hallucination in LLMs, which is the central topic of the current paper."}, {"fullname_first_author": "Junyi Li", "paper_title": "HaluEval: A large-scale hallucination evaluation benchmark for large language models", "publication_date": "2023-05-11", "reason": "This paper introduces HaluEval, a benchmark for evaluating hallucination in LLMs, which the current paper builds upon and contrasts with its focus on medical hallucinations."}, {"fullname_first_author": "Tianyu Liu", "paper_title": "A token-level reference-free hallucination detection benchmark for free-form text generation", "publication_date": "2022-04-08", "reason": "This paper presents Hades, a benchmark for hallucination detection, which is relevant to the current paper's work on creating a benchmark specifically for medical hallucination detection."}, {"fullname_first_author": "Qiao Jin", "paper_title": "PubMedQA: A dataset for biomedical research question answering", "publication_date": "2019-11-01", "reason": "This paper introduces PubMedQA, the dataset used in the current paper to create its benchmark for medical hallucination detection.  It's a foundational dataset for the research."}]}