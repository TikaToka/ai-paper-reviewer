[{"figure_path": "https://arxiv.org/html/2502.02492/x2.png", "caption": "Figure 1: Text-to-video samples generated by VideoJAM. We present VideoJAM, a framework that explicitly instills a strong motion prior to any video generation model. Our framework significantly enhances motion coherence across a wide variety of motion types.", "description": "\uc774 \uadf8\ub9bc\uc740 VideoJAM\uc774 \uc0dd\uc131\ud55c \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0d8\ud50c\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoJAM\uc740 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc5d0 \uac15\ub825\ud55c \ubaa8\uc158 \uc0ac\uc804 \uc815\ubcf4\ub97c \uba85\uc2dc\uc801\uc73c\ub85c \uc801\uc6a9\ud558\ub294 \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4. VideoJAM \ud504\ub808\uc784\uc6cc\ud06c\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ub3d9\uc791\uc5d0\uc11c \ubaa8\uc158 \uc77c\uad00\uc131\uc744 \ud06c\uac8c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \ubc1c\ub808 \ubb34\uc6a9\uc218, \uc2a4\ucf00\uc774\ud2b8\ubcf4\ub354, \uc544\ud06c\ub85c\ubc43 \ub4f1 \ub2e4\uc591\ud55c \ub3d9\uc791\uc744 \uc218\ud589\ud558\ub294 \uc0ac\ub78c\ub4e4\uc758 \ube44\ub514\uc624 \uc0d8\ud50c\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \uc0d8\ud50c\uc740 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub85c\ubd80\ud130 \uc0dd\uc131\ub418\uc5c8\uc73c\uba70, VideoJAM \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ud1b5\ud574 \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub294 \ubaa8\uc158\uc774 \ub9e4\uc6b0 \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc77c\uad00\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.02492/x3.png", "caption": "Figure 2: Motion incoherence in video generation. Examples of incoherent generations by DiT-30B\u00a0(Peebles & Xie, 2023). The model struggles with (a) basic motion, e.g., jogging (stepping on the same leg repeatedly); (b) complex motion e.g., gymnastics; (c) physics, e.g., object dynamics (the hoop passes through the woman); and (d) rotational motion, failing to replicate simple repetitive patterns.", "description": "\ubcf8 \uadf8\ub9bc\uc740 DiT-30B \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \ub3d9\uc791 \ubd88\uc77c\uce58 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e8\uc21c\ud55c \ub3d9\uc791(\uc870\uae45)\uc5d0\uc11c \uac19\uc740 \ub2e4\ub9ac\ub85c \ubc18\ubcf5\uc801\uc73c\ub85c \ubc1c\uc744 \ub514\ub514\ub294 \ub4f1\uc758 \ubb38\uc81c\ub97c, (b)\ub294 \ubcf5\uc7a1\ud55c \ub3d9\uc791(\uccb4\uc870)\uc5d0\uc11c\uc758 \uc5b4\ub824\uc6c0\uc744, (c)\ub294 \ubb3c\ub9ac\uc801 \ubc95\uce59 \uc704\ubc30(\ud6cc\ub77c\ud6c4\ud504\uac00 \uc5ec\uc131\uc744 \ud1b5\uacfc\ud558\ub294 \ub4f1)\ub97c, (d)\ub294 \ub2e8\uc21c \ubc18\ubcf5 \ud328\ud134 \uc7ac\ud604 \uc2e4\ud328\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \uae30\uc874 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ud55c\uacc4\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "3. Motivation"}, {"figure_path": "https://arxiv.org/html/2502.02492/x4.png", "caption": "Figure 3: Motivation Experiment. We compare the model\u2019s loss before and after randomly permuting the video frames, using a \u201cvanilla\u201d DiT (orange) and our fine-tuned model (blue). The original model is nearly invariant to temporal perturbations for t\u226460\ud835\udc6160t\\leq 60italic_t \u2264 60.", "description": "\uc774 \uadf8\ub9bc\uc740 \ube44\ub514\uc624 \ud504\ub808\uc784\uc744 \ubb34\uc791\uc704\ub85c \ubc14\uafbc \ud6c4\uc640 \ubc14\uafb8\uae30 \uc804 \ubaa8\ub378\uc758 \uc190\uc2e4\uc744 \ube44\uad50\ud558\uc5ec, \uae30\uc874 DiT \ubaa8\ub378(\uc8fc\ud669\uc0c9)\uacfc \ubbf8\uc138 \uc870\uc815\ub41c VideoJAM \ubaa8\ub378(\ud30c\ub780\uc0c9)\uc758 \uc2dc\uac04\uc801 \uc12d\ub3d9\uc5d0 \ub300\ud55c \ubbfc\uac10\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  t\u226460 \uc5d0\uc11c \uae30\uc874 \ubaa8\ub378\uc740 \uc2dc\uac04\uc801 \uc12d\ub3d9\uc5d0 \uac70\uc758 \ubd88\ubcc0\uc774\uc9c0\ub9cc, VideoJAM \ubaa8\ub378\uc740 \uc2dc\uac04\uc801 \ubb34\uad00\uc131\uc5d0 \ub9e4\uc6b0 \ubbfc\uac10\ud558\uac8c \ubc18\uc751\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 VideoJAM\uc774 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3. Motivation"}, {"figure_path": "https://arxiv.org/html/2502.02492/x5.png", "caption": "Figure 4: VideoJAM Framework. VideoJAM is constructed of two units; (a) Training. Given an input video x1subscript\ud835\udc651x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and its motion representation d1subscript\ud835\udc511d_{1}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, both signals are noised and embedded to a single, joint latent representation using a linear layer, Wi\u2062n+subscriptsuperscriptW\ud835\udc56\ud835\udc5b\\textbf{W}^{+}_{in}W start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT. The diffusion model processes the input, and two linear projection layers predict both appearance and motion from the joint representation. (b) Inference. We propose Inner-Guidance, where the model\u2019s own noisy motion prediction is used to guide the video prediction at each step.", "description": "\uadf8\ub9bc 4\ub294 VideoJAM \ud504\ub808\uc784\uc6cc\ud06c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoJAM\uc740 \ub450 \uac00\uc9c0 \uad6c\uc131 \uc694\uc18c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. (a) \ud559\uc2b5 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc785\ub825 \ube44\ub514\uc624 x\u2081 \ubc0f \ud574\ub2f9 \ubaa8\uc158 \ud45c\ud604 d\u2081\uc744 \ubc1b\uc2b5\ub2c8\ub2e4. \ub450 \uc2e0\ud638 \ubaa8\ub450 \ub178\uc774\uc988\ub97c \ucd94\uac00\ud558\uace0 \uc120\ud615 \uacc4\uce35 Wi+n\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e8\uc77c \uacf5\uc720 \uc7a0\uc7ac \ud45c\ud604\uc73c\ub85c \uc784\ubca0\ub529\ud569\ub2c8\ub2e4. \ud655\uc0b0 \ubaa8\ub378\uc740 \uc785\ub825\uc744 \ucc98\ub9ac\ud558\uace0, \ub450 \uac1c\uc758 \uc120\ud615 \ud22c\uc601 \uacc4\uce35\uc740 \uacf5\uc720 \uc7a0\uc7ac \ud45c\ud604\uc73c\ub85c\ubd80\ud130 \uc678\uad00\uacfc \ubaa8\uc158\uc744 \ubaa8\ub450 \uc608\uce21\ud569\ub2c8\ub2e4. (b) \ucd94\ub860 \ub2e8\uacc4\uc5d0\uc11c\ub294 \ubaa8\ub378 \uc790\uccb4\uc758 \uc7a1\uc74c\uc774 \ud3ec\ud568\ub41c \ubaa8\uc158 \uc608\uce21\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac01 \ub2e8\uacc4\uc758 \ube44\ub514\uc624 \uc608\uce21\uc744 \uc548\ub0b4\ud558\ub294 Inner-Guidance\ub97c \uc81c\uc548\ud569\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uc0dd\uc131\ub41c \ud504\ub808\uc784\uc758 \ubaa8\uc158 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\ub3c4\ub85d \ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4. VideoJAM"}, {"figure_path": "https://arxiv.org/html/2502.02492/x6.png", "caption": "Figure 5: Text-to-video results by VideoJAM-30B. VideoJAM enables the generation of a wide variety of motion types, from basic motion (e.g., running) to complex motion (e.g., acrobatics), and improved physics (e.g., jumping over a hurdle).", "description": "\uc774 \uadf8\ub9bc\uc740 VideoJAM-30B \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VideoJAM\uc740 \ub2ec\ub9ac\uae30\uc640 \uac19\uc740 \uae30\ubcf8 \ub3d9\uc791\ubd80\ud130 \uace1\uc608\uc640 \uac19\uc740 \ubcf5\uc7a1\ud55c \ub3d9\uc791, \uc7a5\uc560\ubb3c \ub6f0\uc5b4\ub118\uae30\uc640 \uac19\uc774 \ud5a5\uc0c1\ub41c \ubb3c\ub9ac\uc801 \ud604\uc0c1\uae4c\uc9c0 \ub2e4\uc591\ud55c \uc885\ub958\uc758 \ub3d9\uc791 \uc0dd\uc131\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \ub2e4\uc591\ud55c \ub3d9\uc791\uacfc \uc0c1\ud669\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uac1c\uc758 \ube44\ub514\uc624 \uc2a4\ud2f8 \uc774\ubbf8\uc9c0\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, VideoJAM \ubaa8\ub378\uc774 \uc5bc\ub9c8\ub098 \ub2e4\uc591\ud558\uace0 \ud604\uc2e4\uc801\uc778 \ub3d9\uc791\uc744 \uc0dd\uc131\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. VideoJAM"}, {"figure_path": "https://arxiv.org/html/2502.02492/x7.png", "caption": "Figure 6: Qualitative comparisons between VideoJAM-30B and the leading baselines- Sora, Kling, and DiT-30B on representative prompts from VideoJAM-bench. The baselines struggle with basic motion, displaying \u201cbackward motion\u201d (Sora, 2nd row) or unnatural motion (Kling, 2nd row). The generated content defies the basic laws of physics e.g., people passing through objects (DiT, 1st row), or objects that appear or evaporate (Sora, DiT, 4th row). For complex motion, the baselines display static motion or deformations (Sora, Kling, 1st, 3rd row). Conversely, in all cases, VideoJAM produces temporally coherent videos that better adhere to the laws of physics.", "description": "\uadf8\ub9bc 6\uc740 VideoJAM-30B\uc640 \uc8fc\uc694 \uae30\uc900 \ubaa8\ub378(Sora, Kling, DiT-30B)\uc744 VideoJAM-bench\uc758 \ub300\ud45c\uc801\uc778 \ud504\ub86c\ud504\ud2b8\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \uc9c8\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc900 \ubaa8\ub378\ub4e4\uc740 \uae30\ubcf8 \ub3d9\uc791(\uc608: \ub2ec\ub9ac\uae30)\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uace0, Sora\uc758 \uacbd\uc6b0 \ub4a4\ub85c \uac00\ub294 \ub3d9\uc791\uc744 \ubcf4\uc774\uac70\ub098(\ub450 \ubc88\uc9f8 \ud589), Kling\uc758 \uacbd\uc6b0 \ube44\uc790\uc5f0\uc2a4\ub7ec\uc6b4 \ub3d9\uc791\uc744 \ubcf4\uc774\ub294 \ub4f1(\ub450 \ubc88\uc9f8 \ud589) \ubb38\uc81c\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc0dd\uc131\ub41c \ucf58\ud150\uce20\ub294 \uae30\ubcf8\uc801\uc778 \ubb3c\ub9ac \ubc95\uce59\uc744 \uc704\ubc30\ud558\ub294 \uacbd\uc6b0\uac00 \uc788\ub294\ub370, \uc608\ub97c \ub4e4\uc5b4 \uc0ac\ub78c\uc774 \ubb3c\uccb4\ub97c \ud1b5\uacfc\ud558\ub294 \uacbd\uc6b0(DiT, \uccab \ubc88\uc9f8 \ud589)\ub098 \ubb3c\uccb4\uac00 \ub098\ud0c0\ub098\uac70\ub098 \uc0ac\ub77c\uc9c0\ub294 \uacbd\uc6b0(Sora, DiT, \ub124 \ubc88\uc9f8 \ud589)\uac00 \uc788\uc2b5\ub2c8\ub2e4. \ubcf5\uc7a1\ud55c \ub3d9\uc791\uc758 \uacbd\uc6b0 \uae30\uc900 \ubaa8\ub378\ub4e4\uc740 \uc815\uc9c0\ub41c \ub3d9\uc791\uc774\ub098 \ubcc0\ud615\uc744 \ubcf4\uc785\ub2c8\ub2e4(Sora, Kling, \uccab \ubc88\uc9f8, \uc138 \ubc88\uc9f8 \ud589). \ubc18\ub300\ub85c VideoJAM\uc740 \ubaa8\ub4e0 \uacbd\uc6b0\uc5d0 \uc2dc\uac04\uc801\uc73c\ub85c \uc77c\uad00\uc131 \uc788\ub294 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\uba70 \ubb3c\ub9ac \ubc95\uce59\uc744 \ub354 \uc798 \uc900\uc218\ud569\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2502.02492/x8.png", "caption": "Figure 7: Limitations. Our method is less effective for: (a) motion observed in \u201czoom-out\u201d (the moving object covers a small part of the frame). (b) Complex physics of object interactions.", "description": "\uadf8\ub9bc 7\uc740 VideoJAM \uae30\ubc95\uc758 \ud55c\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 '\uc90c \uc544\uc6c3'\ub41c \uc601\uc0c1\uc5d0\uc11c \uc6c0\uc9c1\uc774\ub294 \ubb3c\uccb4\uac00 \uc804\uccb4 \ud504\ub808\uc784\uc758 \uc791\uc740 \ubd80\ubd84\ub9cc \ucc28\uc9c0\ud560 \ub54c VideoJAM\uc774 \ud6a8\uacfc\uc801\uc774\uc9c0 \ubabb\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc6c0\uc9c1\uc784\uc774 \ubbf8\uc138\ud558\uac8c \ub098\ud0c0\ub098\uae30 \ub54c\ubb38\uc5d0 \ubaa8\ub378\uc774 \uc6c0\uc9c1\uc784\uc744 \uc815\ud655\ud788 \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. (b)\ub294 \ubb3c\uccb4 \uac04\uc758 \uc0c1\ud638 \uc791\uc6a9\uc774 \ubcf5\uc7a1\ud55c \ubb3c\ub9ac \ud604\uc0c1\uc774 \uc788\uc744 \ub54c VideoJAM\uc774 \ud6a8\uacfc\uc801\uc774\uc9c0 \ubabb\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubb3c\ub9ac \ubc95\uce59\uc5d0 \uc5b4\uae0b\ub098\ub294 \uc6c0\uc9c1\uc784\uc774 \ubc1c\uc0dd\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.  \uc608\ub97c \ub4e4\uc5b4, \ucd95\uad6c\uacf5\uc774 \uc120\uc218\uc758 \ubc1c\uc5d0 \ub2ff\uae30 \uc804\uc5d0 \uada4\uc801\uc774 \ubc14\ub00c\ub294 \uacbd\uc6b0\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 VideoJAM\uc774 \ubb3c\ub9ac\uc801 \uc0c1\ud638\uc791\uc6a9\uc744 \uba85\uc2dc\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.", "section": "5. \uc81c\ud55c\uc810"}, {"figure_path": "https://arxiv.org/html/2502.02492/x9.png", "caption": "Figure 8: Qualitative motivation. We noise input videos to different timesteps (20,60,8020608020,60,8020 , 60 , 80) and continue the generation. By step 60606060, the video\u2019s coarse motion and structure are mostly determined.", "description": "\uadf8\ub9bc 8\uc740 \ube44\ub514\uc624 \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \uc2dc\uac04 \uc815\ubcf4\uc758 \uc911\uc694\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc18c\uc74c\uc774 \ucd94\uac00\ub41c \ube44\ub514\uc624\ub97c \uc11c\ub85c \ub2e4\ub978 \ub2e8\uacc4(20, 60, 80)\uc5d0\uc11c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\uc744 \uacc4\uc18d \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4.  60\ub2e8\uacc4\uae4c\uc9c0\ub294 \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \ub300\ub7b5\uc801\uc778 \uc6c0\uc9c1\uc784\uacfc \uad6c\uc870\uac00 \ub300\ubd80\ubd84 \uacb0\uc815\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \ucd08\uae30 \ub2e8\uacc4\uc5d0\uc11c \uc774\ubbf8 \ube44\ub514\uc624\uc758 \uc8fc\uc694 \ub3d9\uc791\uc774 \ud615\uc131\ub418\uba70, \ud6c4\ubc18\ubd80 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uc774 \uc870\uc815\ub418\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Motivation"}]