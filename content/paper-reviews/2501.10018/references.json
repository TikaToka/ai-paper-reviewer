{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2022-11-01", "reason": "This paper is highly relevant due to its focus on image editing instructions, a concept directly applicable to the video inpainting task."}, {"fullname_first_author": "Tsai-Shien Chen", "paper_title": "Panda-70M: Captioning 70M videos with multiple cross-modality teachers", "publication_date": "2024-01-01", "reason": "The Panda-70M dataset, introduced in this paper, is crucial to the research as it provides a large-scale dataset for training and evaluating video inpainting models."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Structure and content-guided video synthesis with diffusion models", "publication_date": "2023-01-01", "reason": "This paper is significant for its exploration of video synthesis using diffusion models, a technique that forms the core of the proposed DiffuEraser model."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen Video: High definition video generation with diffusion models", "publication_date": "2022-01-01", "reason": "This work is highly relevant because it details the development of Imagen Video, a high-definition video generation model based on diffusion models, which is closely related to the proposed method."}, {"fullname_first_author": "Minhyeok Lee", "paper_title": "Video diffusion models are strong video inpainter", "publication_date": "2024-01-01", "reason": "This paper directly addresses video inpainting using diffusion models, a core aspect of the proposed research, making it highly relevant."}]}