[{"figure_path": "https://arxiv.org/html/2404.07097/x1.png", "caption": "Figure 1: We present TracksTo4D, a method for mapping a set of 2D point tracks extracted from casual dynamic videos into their corresponding 3D locations and camera motion. At inference time, our network predicts the dynamic structure and camera motion in a single feed-forward pass. Our network takes as input a set of 2D point tracks (left) and uses several multi-head attention layers while alternating between the time dimension and the track dimension (middle). The network predicts cameras, per-frame 3D points, and per-world point movement value (right). The 3D point internal colors illustrate the predicted 3D movement level values, such that points with high/low 3D motion are presented in red/purple colors respectively. These outputs are used to reproject the predicted points into the frames for calculating the reprojection error losses. See details in the text. The reader is encouraged to watch the supplementary video visualizations.", "description": "\uadf8\ub9bc 1\uc740 TRACKSTO4D\uc758 \uac1c\ub150\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ubc29\ubc95\uc740 \uc77c\uc0c1\uc801\uc778 \ub3d9\uc801 \ube44\ub514\uc624\uc5d0\uc11c \ucd94\ucd9c\ub41c 2D \uc810 \ud2b8\ub799 \uc9d1\ud569\uc744 \ud574\ub2f9 3D \uc704\uce58\uc640 \uce74\uba54\ub77c \uc6c0\uc9c1\uc784\uc5d0 \ub9e4\ud551\ud558\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4. \ucd94\ub860 \uc2dc \ub124\ud2b8\uc6cc\ud06c\ub294 \ub2e8\uc77c \uc21c\ubc29\ud5a5 \uc804\ub2ec\uc744 \ud1b5\ud574 \ub3d9\uc801 \uad6c\uc870\uc640 \uce74\uba54\ub77c \uc6c0\uc9c1\uc784\uc744 \uc608\uce21\ud569\ub2c8\ub2e4. \ub124\ud2b8\uc6cc\ud06c\ub294 \uc785\ub825\uc73c\ub85c 2D \uc810 \ud2b8\ub799 \uc9d1\ud569(\uc67c\ucabd)\uc744 \ubc1b\uace0 \uc2dc\uac04 \ucc28\uc6d0\uacfc \ud2b8\ub799 \ucc28\uc6d0\uc744 \ubc88\uac08\uc544 \uac00\uba70 \uc5ec\ub7ec \ub2e4\uc911 \ud5e4\ub4dc \uc5b4\ud150\uc158 \uacc4\uce35\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4(\uac00\uc6b4\ub370). \ub124\ud2b8\uc6cc\ud06c\ub294 \uce74\uba54\ub77c, \ud504\ub808\uc784\ubcc4 3D \uc810, \uc804\uc5ed \uc810 \uc774\ub3d9 \uac12\uc744 \uc608\uce21\ud569\ub2c8\ub2e4(\uc624\ub978\ucabd). 3D \uc810\uc758 \ub0b4\ubd80 \uc0c9\uc0c1\uc740 \uc608\uce21\ub41c 3D \uc774\ub3d9 \uc218\uc900 \uac12\uc744 \ub098\ud0c0\ub0b4\uba70, 3D \uc774\ub3d9\uc774 \ub192\uc740/\ub0ae\uc740 \uc810\uc740 \uac01\uac01 \ube68\uac04\uc0c9/\ubcf4\ub77c\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ucd9c\ub825\uc740 \uc7ac\ud22c\uc601 \uc624\ub958 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \uc608\uce21\ub41c \uc810\uc744 \ud504\ub808\uc784\uc5d0 \uc7ac\ud22c\uc601\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ubcf8\ubb38\uc744 \ucc38\uc870\ud558\uc138\uc694. \ubcf4\ucda9 \ube44\ub514\uc624 \uc2dc\uac01\ud654\ub97c \uc2dc\uccad\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2404.07097/extracted/5694121/figures/symmetries.png", "caption": "Figure 2: The symmetry structure of our problem. Frames (vertical) have time translation symmetry while points (horizontal) have set permutation symmetry.", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc785\ub825 \ub370\uc774\ud130\uc778 \ud3ec\uc778\ud2b8 \ud2b8\ub799 \ud150\uc11c\uc758 \ub300\uce6d \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138\ub85c\ucd95\uc740 \ud504\ub808\uc784(\uc2dc\uac04)\uc744 \ub098\ud0c0\ub0b4\uba70, \uc2dc\uac04\uc801 \ubcc0\ud658 \ub300\uce6d\uc131(time translation symmetry)\uc744 \uac00\uc9d1\ub2c8\ub2e4. \uc989, \uc2dc\uac04\ucd95\uc744 \ub530\ub77c \uc2dc\ud504\ud2b8\ud574\ub3c4 \uacb0\uacfc\uac00 \uc77c\uad00\ub418\uac8c \uc2dc\ud504\ud2b8\ub429\ub2c8\ub2e4. \uac00\ub85c\ucd95\uc740 \ucd94\uc801\ub418\ub294 \uc810\ub4e4\uc744 \ub098\ud0c0\ub0b4\uba70, \uc9d1\ud569 \uc21c\uc5f4 \ub300\uce6d\uc131(set permutation symmetry)\uc744 \uac00\uc9d1\ub2c8\ub2e4. \ub2e4\uc2dc \ub9d0\ud574, \uc810\ub4e4\uc758 \uc21c\uc11c\ub97c \ubc14\uafd4\ub3c4 \ubb38\uc81c \uc790\uccb4\uc5d0\ub294 \uc601\ud5a5\uc774 \uc5c6\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ub300\uce6d\uc131\uc740 \ubaa8\ub378\uc774 \ub370\uc774\ud130\uc758 \uad6c\uc870\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud559\uc2b5\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "2 Method"}, {"figure_path": "https://arxiv.org/html/2404.07097/x2.png", "caption": "Figure 3: Qualitative Results.  Top. Frames from 2 different test video sequences with point tracks marked with corresponding colors. Bottom. A 3D visualization of our method\u2019s outputs, from two time stamps. The camera trajectory is present as gray frustums, whereas the current camera is marked in red. The reconstructed 3D scene points are presented in corresponding colors to the input\ntracks on the top. The scene is observed from the same viewpoint, enabling the visualization of the dynamic reconstructed structure.", "description": "\uadf8\ub9bc 3\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0c1\ub2e8\uc5d0\ub294 \ub450 \uac1c\uc758 \uc11c\ub85c \ub2e4\ub978 \ud14c\uc2a4\ud2b8 \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\uc758 \ud504\ub808\uc784\uc774 \ud45c\uc2dc\ub418\uba70, \uac01 \ud504\ub808\uc784\uc5d0\ub294 \ub300\uc751\ud558\ub294 \uc0c9\uc0c1\uc73c\ub85c \ud45c\uc2dc\ub41c \uc810 \ucd94\uc801\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ud558\ub2e8\uc5d0\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ucd9c\ub825\uc744 \ub450 \uac1c\uc758 \uc2dc\uac04 \uc2a4\ud0ec\ud504\uc5d0\uc11c 3D \uc2dc\uac01\ud654\ud55c \uacb0\uacfc\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uce74\uba54\ub77c \uada4\uc801\uc740 \ud68c\uc0c9 \ud3c9\uba74\uc73c\ub85c \ud45c\uc2dc\ub418\uace0, \ud604\uc7ac \uce74\uba54\ub77c \uc704\uce58\ub294 \ube68\uac04\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc7ac\uad6c\uc131\ub41c 3D \uc7a5\uba74 \uc810\uc740 \uc0c1\ub2e8\uc758 \uc785\ub825 \ud2b8\ub799\uacfc \uc77c\uce58\ud558\ub294 \uc0c9\uc0c1\uc73c\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc7a5\uba74\uc740 \ub3d9\uc77c\ud55c \uad00\uc810\uc5d0\uc11c \uad00\ucc30\ud558\uc5ec \ub3d9\uc801\uc73c\ub85c \uc7ac\uad6c\uc131\ub41c \uad6c\uc870\ub97c \uc2dc\uac01\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3 \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2404.07097/x3.png", "caption": "Figure 4: \u03b3\ud835\udefe\\gammaitalic_\u03b3 Visualization. We show a visualization of the \u03b3\ud835\udefe\\gammaitalic_\u03b3 outputs of our network that are described in Sec.\u00a02.2. In each video sequence, we show the input tracks, where each color visualizes its movement level value, \u03b3\ud835\udefe\\gammaitalic_\u03b3. Purple marks static points with low \u03b3\ud835\udefe\\gammaitalic_\u03b3 whereas red marks dynamic points with high \u03b3\ud835\udefe\\gammaitalic_\u03b3. Note, that our network did not get any direct supervision for these values, but only the raw point tracks predictions from [18]. The \u03b3\ud835\udefe\\gammaitalic_\u03b3 visualizations for cats were produced by the model that was only trained on dogs and vice versa. We note that our model generalizes well to out-of-domain (non-pet) cases as well.", "description": "\uadf8\ub9bc 4\ub294 \ub17c\ubb38\uc758 2.2\uc808\uc5d0\uc11c \uc124\uba85\ud558\ub294 \ub124\ud2b8\uc6cc\ud06c \ucd9c\ub825\uac12\uc778 \uac10\ub9c8(\u03b3) \uac12\uc744 \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uc785\ub825 \ud2b8\ub799\uc744 \ubcf4\uc5ec\uc8fc\uace0, \uac01 \uc0c9\uc0c1\uc740 \ud574\ub2f9 \uc9c0\uc810\uc758 \uc6c0\uc9c1\uc784 \uc218\uc900 \uac12(\u03b3)\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ubcf4\ub77c\uc0c9\uc740 \u03b3 \uac12\uc774 \ub0ae\uc740 \uc815\uc801 \uc9c0\uc810\uc744, \ube68\uac04\uc0c9\uc740 \u03b3 \uac12\uc774 \ub192\uc740 \ub3d9\uc801 \uc9c0\uc810\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub124\ud2b8\uc6cc\ud06c\ub294 \uc774\ub7ec\ud55c \uac12\uc5d0 \ub300\ud574 \uc9c1\uc811\uc801\uc778 \uac10\ub3c5\uc744 \ubc1b\uc9c0 \uc54a\uc558\uace0, [18]\uc758 \uc6d0\uc2dc \uc810 \ucd94\uc801 \uc608\uce21\ub9cc\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uace0\uc591\uc774\uc5d0 \ub300\ud55c \u03b3 \uc2dc\uac01\ud654\ub294 \uac1c\ub9cc\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc5d0 \uc758\ud574 \uc0dd\uc131\ub418\uc5c8\uace0, \uadf8 \ubc18\ub300\uc758 \uacbd\uc6b0\ub3c4 \ub9c8\ucc2c\uac00\uc9c0\uc785\ub2c8\ub2e4. \uc774\ub294 \uc81c\uc548\ub41c \ubaa8\ub378\uc774 \ub3c4\uba54\uc778 \uc678(\ube44-\uc560\uc644\ub3d9\ubb3c) \uc0ac\ub840\ub85c\ub3c4 \uc798 \uc77c\ubc18\ud654\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2 Method"}]