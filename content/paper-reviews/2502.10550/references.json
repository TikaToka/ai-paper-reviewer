{"references": [{"fullname_first_author": "Leslie Pack Kaelbling", "paper_title": "Reinforcement learning: A survey", "publication_date": "1996-01-01", "reason": "This paper provides a foundational overview of reinforcement learning, which is the core methodology of the discussed benchmark."}, {"fullname_first_author": "Marc G Bellemare", "paper_title": "The arcade learning environment: An evaluation platform for general agents", "publication_date": "2013-01-01", "reason": "This paper introduced a widely used benchmark in reinforcement learning, which is referenced as a comparison for the proposed robotic benchmark."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "publication_date": "1997-11-01", "reason": "This paper introduced LSTM networks, a crucial memory mechanism used in many reinforcement learning algorithms, directly relevant to the benchmark's focus on memory."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-07-01", "reason": "This paper introduced the Proximal Policy Optimization algorithm, a widely used RL algorithm employed as the baseline for evaluating the benchmark's effectiveness."}, {"fullname_first_author": "Egor Cherepanov", "paper_title": "Unraveling the complexity of memory in rl agents: an approach for classification and evaluation", "publication_date": "2024-12-01", "reason": "This paper, also by authors of the current work, proposes a taxonomy for memory in RL, directly informing the design and categorization of tasks within the benchmark."}]}