[{"content": "| Method / Metrics | KITTI [11] |  | Scannet [7] |  | Bonn [24] |  | NYUv2 [22] |  | Sintel [5] (~50 frames) |  | Scannet (170 frames [40]) | \u03b4\u2081 Rank | \n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| DAv2-L [42] | 0.137 | 0.815 | 0.150 | 0.768 | 0.127 | 0.864 | 0.094 | 0.928 | 0.390 | 0.541 | 1.140 | 3.6 |\n| NVDS [38] | 0.233 | 0.614 | 0.207 | 0.628 | 0.199 | 0.674 | 0.217 | 0.598 | 0.408 | 0.464 | 2.176 | 6.8 |\n| NVDS [38] + DAv2-L [42] | 0.227 | 0.617 | 0.194 | 0.658 | 0.191 | 0.700 | 0.184 | 0.679 | 0.449 | 0.503 | 2.536 | 5.8 |\n| ChoronDepth [32] | 0.243 | 0.576 | 0.199 | 0.665 | 0.199 | 0.665 | 0.173 | 0.771 | 0.192 | 0.673 | 1.022 | 5.2 |\n| DepthCrafter [13] | 0.164 | 0.753 | 0.169 | 0.730 | 0.153 | 0.803 | 0.141 | 0.822 | 0.299 | 0.695 | 0.639 | 3.4 |\n| DepthAnyVideo [40] | - | - | - | - | - | - | - | - | 0.405 | 0.659 | 0.967 | - |\n| VDA-S (Ours) | 0.086 | 0.942 | 0.110 | 0.876 | 0.083 | 0.950 | 0.077 | 0.959 | 0.339 | 0.584 | 0.703 | 2.6 |\n| VDA-L (Ours) | 0.083 | 0.944 | 0.089 | 0.926 | 0.071 | 0.959 | 0.062 | 0.971 | 0.295 | 0.644 | 0.570 | 1.6 |", "caption": "Table 1: Zero-shot video depth estimation results. We compare with representative single-image\u00a0[42] and video depth estimation models\u00a0[38, 32, 13, 40]. \u201cVDA-S\u201d denotes our model with ViT-Small backbone. \u201cVDA-L\u201d denotes our model with ViT-Large backbone. The best and the second best results are highlighted.", "description": "\ud45c 1\uc740 \uc81c\ub85c\uc0f7 \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf8 \uc5f0\uad6c\uc758 \ubaa8\ub378(VDA-S, VDA-L)\uc740 \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815 \ubaa8\ub378 [38, 32, 13, 40] \ubc0f \ub2e8\uc77c \uc774\ubbf8\uc9c0 \uae4a\uc774 \ucd94\uc815 \ubaa8\ub378 [42]\uacfc \ube44\uad50\ub429\ub2c8\ub2e4. VDA-S\ub294 ViT-Small \ubc31\ubcf8\uc744 \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc774\uace0, VDA-L\uc740 ViT-Large \ubc31\ubcf8\uc744 \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uc815\ud655\ub3c4(AbsRel, \u03b41) \ubc0f \uc77c\uad00\uc131(TAE) \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \ube44\ub514\uc624 \ub370\uc774\ud130\uc14b(KITTI, Scannet, Bonn, NYUv2, Sintel)\uc5d0 \ub300\ud55c \uc131\ub2a5\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\uc640 \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uacb0\uacfc\ub294 \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc81c\ub85c\uc0f7 \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815 \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4.2. Zero-shot Depth Estimation"}, {"content": "| Method / Metrics | KITTI AbsRel (\u2193) | KITTI  \u03b4\u2081 (\u2191) | Sintel AbsRel (\u2193) | Sintel  \u03b4\u2081 (\u2191) | NYUv2 AbsRel (\u2193) | NYUv2  \u03b4\u2081 (\u2191) | ETH3D AbsRel (\u2193) | ETH3D  \u03b4\u2081 (\u2191) | DIODE AbsRel (\u2193) | DIODE  \u03b4\u2081 (\u2191) | \u03b4\u2081 Rank | \n|---|---|---|---|---|---|---|---|---|---|---|---| \n| DepthCrafter [13] | 0.107 | 0.891 | 0.568 | 0.652 | 0.082 | 0.936 | 0.179 | 0.793 | 0.141 | 0.857 | 4 | \n| DepthAnyVideo [40] | **0.073** | **0.946** | 0.687 | 0.692 | 0.058 | 0.963 | **0.123** | **0.881** | 0.072 | 0.942 | 2.4 | \n| DAv2-L [42] | **0.074** | **0.946** | **0.487** | **0.752** | **0.045** | **0.979** | **0.131** | **0.865** | **0.066** | **0.952** | 1.4 | \n| VDA-L (Ours) | 0.075 | **0.946** | **0.496** | **0.754** | **0.046** | **0.978** | 0.132 | 0.863 | **0.067** | **0.950** | 2 |", "caption": "Table 2: Zero-shot single-image depth estimation results. We compare with representative single-image\u00a0[42] and video depth estimation models\u00a0[13, 40] with single-frame inputs. \u201cVDA-L\u201d denotes our model with ViT-Large backbone. The best and the second best results are highlighted.", "description": "\ud45c 2\ub294 \uc81c\ub85c\uc0f7 \ub2e8\uc77c \uc774\ubbf8\uc9c0 \uae4a\uc774 \ucd94\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcf8 \uc5f0\uad6c\uc758 \ubaa8\ub378(VDA-L, ViT-Large \ubc31\ubcf8 \uc0ac\uc6a9)\uc744 \ub2e8\uc77c \ud504\ub808\uc784 \uc785\ub825\uc73c\ub85c \ub2e8\uc77c \uc774\ubbf8\uc9c0 [42] \ubc0f \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815 \ubaa8\ub378 [13, 40]\uacfc \ube44\uad50 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4. \uac00\uc7a5 \uc6b0\uc218\ud55c \uacb0\uacfc\uc640 \ub450 \ubc88\uc9f8\ub85c \uc6b0\uc218\ud55c \uacb0\uacfc\ub294 \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubaa8\ub378\uc758 \uacf5\uac04\uc801 \uc815\ud655\ub3c4\ub97c \ud3c9\uac00\ud558\uace0, \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\uacfc\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "4.2 \uc81c\ub85c\uc0f7 \uae4a\uc774 \ucd94\uc815"}, {"content": "| Method | Precision | Latency (ms) |\n|---|---|---|\n| ChronoDepth | FP16 | 506 |\n| DepthCrafter | FP16 | 910 |\n| DepthAnyVideo | FP16 | 159 |\n| NVDS | FP32 | 204 |\n| DAv2-L | FP32 | 60 |\n| VDA-L (Ours) | FP32 | 67 |\n| VDA-S (Ours) | FP32 | 9.1 |", "caption": "Table 3: Inference latency comparisons for video depth estimation. We measure average runtime for each frame on a single A100 GPU with a resolution of 518\u00d7518518518518\\times 518518 \u00d7 518.", "description": "\ud45c 3\uc740 \ube44\ub514\uc624 \uae4a\uc774 \ucd94\uc815\uc744 \uc704\ud55c \uac01 \ud504\ub808\uc784\uc758 \ucd94\ub860 \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Nvidia A100 GPU\uc5d0\uc11c 518x518 \ud574\uc0c1\ub3c4\ub85c \uce21\uc815\ud55c \uacb0\uacfc\uc774\uba70, \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc2e4\ud589 \uc2dc\uac04\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  ChronoDepth, DepthCrafter, DepthAny Video, NVDS, Depth Anything V2, \uadf8\ub9ac\uace0 \uc81c\uc548\ub41c Video Depth Anything (VDA-L \ubc0f VDA-S) \ubaa8\ub378\uc758 \ucd94\ub860 \uc18d\ub3c4\ub97c \ube44\uad50\ud558\uc5ec \uc81c\uc548\ub41c \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.3 \uc288\ud37c \ub871 \uc2dc\ud000\uc2a4\ub97c \uc704\ud55c \ucd94\ub860 \uc804\ub7b5"}, {"content": "| Loss | AbsRel (\u2193) | \n\u03b4<sub>1</sub> (\u2191) | TAE (\u2193) |\n|---|---|---|---|\n| VideoAlign | **0.151** | **0.846** | 1.326 |\n| VideoAlign+SSI | **0.151** | **0.848** | 1.207 |\n| OPW [38]+SSI | 0.182 | 0.771 | 0.918 |\n| SE+SSI | 0.160 | 0.836 | **0.753** |\n| TGM+SSI (Ours) | 0.166 | 0.832 | **0.767** |", "caption": "Table 4: Ablation studies on the effectiveness of the temporal losses.\n\u201cVideoAlign\u201d denotes the spatial loss with a shared scale-shift alignment applied to the entire video. \u201cSSI\u201d is the image-level spatial loss used in\u00a0[42]. \u201cOPW\u201d refers to the optical flow-based warping loss described in\u00a0[38].\n\u201cSE\u201d refers to the stable error as introduced in Equation\u00a02. \u201cTGM\u201d represents our proposed temporal gradient matching loss.", "description": "\ud45c 4\ub294 \uc81c\uc548\ub41c \uc2dc\uac04\uc801 \uae30\uc6b8\uae30 \uc77c\uce58 \uc190\uc2e4(TGM)\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \uc190\uc2e4 \ud568\uc218\uc758 \ud6a8\uacfc\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\uad50 \ub300\uc0c1 \uc190\uc2e4 \ud568\uc218\ub294 \uc804\uccb4 \ube44\ub514\uc624\uc5d0 \uacf5\uc720\ub41c \uc2a4\ucf00\uc77c-\uc26c\ud504\ud2b8 \uc815\ub82c\uc744 \uc0ac\uc6a9\ud558\ub294 \uacf5\uac04 \uc190\uc2e4\uc778 \"VideoAlign\", \ub17c\ubb38 [42]\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc774\ubbf8\uc9c0 \uc218\uc900 \uacf5\uac04 \uc190\uc2e4\uc778 \"SSI\", \ub17c\ubb38 [38]\uc5d0\uc11c \uc124\uba85\ub41c \uad11\ud559 \ud750\ub984 \uae30\ubc18 \uc65c\uace1 \uc190\uc2e4\uc778 \"OPW\", \uadf8\ub9ac\uace0 \ubc29\uc815\uc2dd 2\uc5d0\uc11c \uc81c\uc2dc\ub41c \uc548\uc815\uc801\uc778 \uc624\ub958(SE)\uc785\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c \uc81c\uc548\ub41c TGM \uc190\uc2e4 \ud568\uc218\uac00 \ub2e4\ub978 \uc190\uc2e4 \ud568\uc218\ub4e4\uc5d0 \ube44\ud574 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uacfc \uae30\ud558\ud559\uc801 \uc815\ud655\ub3c4 \uce21\uba74\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 Temporal Gradient Matching loss"}, {"content": "| Strategy | Window | AbsRel (\u2193) | \u03b4\u2081 (\u2191) | TAE (\u2193) |\n|---|---|---|---|---|\n| Baseline | 16 | 0.157 | 0.826 | 0.874 |\n| OA | 16 | 0.146 | 0.845 | 0.792 |\n| OI | 16 | 0.157 | 0.826 | 0.783 |\n| OI+KR(Ours) | 16 | 0.145 | 0.849 | 0.761 |\n| OI+KR(Ours) | 32 | 0.144 | 0.851 | 0.718 |\n| OI+KR(Ours) | 48 | 0.143 | 0.852 | 0.732 |", "caption": "Table 5: Ablation studies on the effectiveness of different inference strategies and window sizes. \u201cBaseline\u201d denotes directly inference for video clips without overlapping. \u201cOA\u201d denotes inference with a overlap of 4 frames and perform scale-shift alignment across windows. \u201cOI\u201d denotes depth clip stitching with a overlap of 4 frames. \u201cOI+KR\u201d combines the \u201cOI\u201d with our proposed key-frame referencing with extra 2 key-frames.", "description": "\ud45c 5\ub294 \uc11c\ub85c \ub2e4\ub978 \ucd94\ub860 \uc804\ub7b5\uacfc \ucc3d \ud06c\uae30\uc758 \ud6a8\uacfc\uc5d0 \ub300\ud55c \ucd94\uac00 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \"\uae30\uc900\uc120(Baseline)\"\uc740 \uacb9\uce58\ub294 \ubd80\ubd84 \uc5c6\uc774 \ube44\ub514\uc624 \ud074\ub9bd\uc744 \uc9c1\uc811 \ucd94\ub860\ud558\ub294 \ubc29\ubc95\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \"OA(Overlap Alignment)\"\ub294 4\ud504\ub808\uc784 \uacb9\uce68\uc744 \uc0ac\uc6a9\ud558\uace0 \ucc3d \uac04\uc5d0 \ud06c\uae30-\uc774\ub3d9 \uc815\ub82c\uc744 \uc218\ud589\ud558\ub294 \ucd94\ub860 \ubc29\uc2dd\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \"OI(Overlap Interpolation)\"\ub294 4\ud504\ub808\uc784 \uacb9\uce68\uc744 \uc0ac\uc6a9\ud558\uc5ec \uae4a\uc774 \ud074\ub9bd\uc744 \uc5f0\uacb0\ud558\ub294 \ucd94\ub860 \ubc29\uc2dd\uc785\ub2c8\ub2e4.  \"OI+KR(OI with Key-Frame Referencing)\"\uc740 \uc81c\uc548\ub41c \ud0a4\ud504\ub808\uc784 \ucc38\uc870\ub97c OI\uc5d0 \ucd94\uac00\uc801\uc73c\ub85c \uc801\uc6a9\ud55c \ubc29\ubc95\uc785\ub2c8\ub2e4. \ud0a4\ud504\ub808\uc784 \ucc38\uc870\ub294 \uc774\uc804 \ucc3d\uc758 \ud0a4\ud504\ub808\uc784\ub4e4\uc744 \ud604\uc7ac \ucc3d\uc758 \ucd94\ub860\uc5d0 \ucd94\uac00\uc801\uc778 \ucc38\uc870\ub85c \uc0ac\uc6a9\ud558\ub294 \uae30\ubc95\uc785\ub2c8\ub2e4.", "section": "3.3 Super-long sequence\uc5d0 \ub300\ud55c \ucd94\ub860 \uc804\ub7b5"}, {"content": "| Datasets | Image-datasets |  | Video-datasets |  |  |\n|---|---|---|---|---|---|---|\n|  | AbsRel (\u2193) | \u03b4\u2081 (\u2191) | AbsRel (\u2193) | \u03b4\u2081 (\u2191) | TAE (\u2193) |\n|---|---|---|---|---|---|---|\n| Video | 0.180 | 0.876 | 0.145 | 0.849 | 0.761 |\n| Video + Image | **0.167** | **0.883** | **0.142** | **0.852** | **0.742** |", "caption": "Table 6: Ablation studies on the effectiveness of the image dataset distillation. \u201cVideo\u201d denotes training using only video datasets. \u201cVideo + Image\u201d merges video and image datasets for training using image-level distillation\u00a0[42].", "description": "\ud45c 6\uc740 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130 \uc99d\ub958\uc758 \ud6a8\uacfc\uc5d0 \ub300\ud55c \ucd94\uac00 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \"\ube44\ub514\uc624\"\ub294 \ube44\ub514\uc624 \ub370\uc774\ud130\uc14b\ub9cc\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uacb0\uacfc\uc774\uace0, \"\ube44\ub514\uc624 + \uc774\ubbf8\uc9c0\"\ub294 \uc774\ubbf8\uc9c0 \ub808\ubca8 \uc99d\ub958 \uae30\ubc95 [42]\uc744 \uc0ac\uc6a9\ud558\uc5ec \ube44\ub514\uc624\uc640 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc744 \uacb0\ud569\ud558\uc5ec \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uacb0\uacfc\uc785\ub2c8\ub2e4.  \uc989, \ube44\ub514\uc624 \ub370\uc774\ud130\ub9cc\uc73c\ub85c \ud559\uc2b5\ud55c \ubaa8\ub378\uacfc \ube44\ub514\uc624 \ubc0f \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uc774\ubbf8\uc9c0 \ub370\uc774\ud130 \uc99d\ub958\uc758 \ud6a8\uacfc\ub97c \ud655\uc778\ud558\ub294 \uc2e4\ud5d8\uc785\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ucd94\uac00\uc801\uc778 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud568\uc73c\ub85c\uc368 \ubaa8\ub378 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4.3 Ablation Studies"}, {"content": "| Method / Metrics | Params(M) | # Video Training Data(M) | KITTI(110) [11] |  | Bonn(110) [24] |  | Scannet(90) [7] |  |\n|---|---|---|---|---|---|---|---|---|\n| AbsRel (\u2193) | \u03b4\u2081 (\u2191) | AbsRel (\u2193) | \u03b4\u2081 (\u2191) | AbsRel (\u2193) | \u03b4\u2081 (\u2191) |\n| DepthCrafter | 2156.7 | 10.5~40.5 | 0.111 | 0.885 | 0.066 | 0.979 | 0.125 | 0.848 |\n| DepthAnyVideo | 1422.8 | 6 | **0.073** | **0.957** | **0.051** | **0.981** | 0.112 | 0.883 |\n| VDA-L (Ours) | 381.8 | 0.55 | **0.079** | **0.950** | **0.053** | 0.972 | **0.075** | **0.954** |", "caption": "Table 7: Zero-shot short video depth estimation results. We compare with DepthCrafter\u00a0[13] and DepthAnyVideo\u00a0[40] in short video depth benchmark. \u201cVDA-L\u201d denotes our model with ViT-Large backbone. The default inference resolution of our model is set to 518 pixels on the short side, maintaining the aspect ratio. The best and the second best results are highlighted.", "description": "\ud45c 7\uc740 \uc81c\ub85c\uc0f7 \ub2e8\uc77c \uc774\ubbf8\uc9c0 \uae4a\uc774 \ucd94\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc548\ub41c \ubaa8\ub378(VDA-L, ViT-Large \ubc31\ubcf8 \uc0ac\uc6a9)\uc758 \uc131\ub2a5\uc744 DepthCrafter [13] \ubc0f DepthAnyVideo [40]\uc640 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\uad50\ub294 \uc9e7\uc740 \ube44\ub514\uc624 \uae4a\uc774 \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc218\ud589\ub418\uc5c8\uc73c\uba70, \uae30\ubcf8 \ucd94\ub860 \ud574\uc0c1\ub3c4\ub294 \uc9e7\uc740 \ucabd\uc774 518\ud53d\uc140\ub85c \uc720\uc9c0\ub418\ub3c4\ub85d \uc885\ud6a1\ube44\ub97c \uc720\uc9c0\ud588\uc2b5\ub2c8\ub2e4. \ucd5c\uace0 \ubc0f \ucc28\uace0 \uc131\ub2a5 \uacb0\uacfc\uac00 \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc989,  \uc9e7\uc740 \ube44\ub514\uc624\uc5d0 \ub300\ud55c \uc81c\ub85c\uc0f7 \uae4a\uc774 \ucd94\uc815 \uc131\ub2a5\uc744 \uae30\uc874 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.", "section": "4.2 Zero-shot Depth Estimation"}]