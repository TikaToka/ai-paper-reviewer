[{"content": "|   | Task | #Sam. | Datasets |\n|---|---|---|---| \n|   | Gen. | 667M | LAION-Aesthetics [67], Megalith [52], SAM [33], Objects365 [69], ImageNet-1k [18], |\n| S.1 | Und. | 667M | Laion-En [67], COYO [6], SAM [33] |\n|   | Gen. | 170M | LAION-Aesthetics [67], Megalith [52], Objects365 [69], Unsplash [85], Dalle-3-HQ [3], JourneyDB [74], Internal Dataset |\n|   |   | 170M | **Captioning:** Laion-En [67], Laion-Zh [67], COYO [6], GRIT [60], COCO [40], TextCaps [71] |\n|   |   |   | **Detection:** Objects365 [69], GRIT [60], All-Seeing [90] |\n|   |   |   | **OCR (large):** Wukong-OCR [26], LaionCOCO-OCR [68], Common Crawl PDF |\n|   |   |   | **OCR (small):** MMC-Inst [41], LSVT [79], ST-VQA [5], RCTW-17 [70], ReCTs [106], ArT [13], SynthDoG [32], ChartQA [53], CTW [104], DocVQA [15], TextOCR [73], |\n| S.2 | Und. | 170M | COCO-Text [87], PlotQA [55], InfoVQA [54] |", "caption": "Table 1: Summary of datasets used in Visual Alignment Pretraining. \u201cS.1\u201d and \u201cS.2\u201d denote the first and second stage. \u201cGen.\u201d and \u201cUnd.\u201d denote the image generation and understanding task. \u201c#Sam.\u201d denotes the number of total samples seen during training of each task at each stage. Note that all data used for image understanding in the second stage is also used in InternVL-1.5\u00a0[11].", "description": "\uc774 \ud45c\ub294 SynerGen-VL\uc758 \uc2dc\uac01\uc801 \uc815\ub82c \uc0ac\uc804 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc744 \uc694\uc57d\ud55c \uac83\uc785\ub2c8\ub2e4. \"S.1\"\uacfc \"S.2\"\ub294 \uac01\uac01 \uccab \ubc88\uc9f8\uc640 \ub450 \ubc88\uc9f8 \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \"Gen.\"\uc740 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc791\uc5c5\uc744, \"Und.\"\ub294 \uc774\ubbf8\uc9c0 \uc774\ud574 \uc791\uc5c5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \"#Sam.\"\uc740 \uac01 \ub2e8\uacc4\uc758 \uac01 \uc791\uc5c5 \ud6c8\ub828 \uc911\uc5d0 \ud45c\uc2dc\ub41c \ucd1d \uc0d8\ud50c \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \ub2e8\uacc4\uc758 \uc774\ubbf8\uc9c0 \uc774\ud574\uc5d0 \uc0ac\uc6a9\ub41c \ubaa8\ub4e0 \ub370\uc774\ud130\ub294 InternVL-1.5 [11]\uc5d0\ub3c4 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "3.2. Training"}, {"content": "| Model | #A-Param | POPE | MMB | MMVet | MMMU | MME | MME-P | MathVista | SEED-I | OCRBench |\n|---|---|---|---|---|---|---|---|---|---|---| \n| **Understanding Only** | | | | | | | | | | |\n| *Encoder-based* | | | | | | | | | | |\n| LLaVA-1.5 [43] | 7B | 85.9 | 64.3 | 31.1 | 35.4 | - | 1512 | - | 58.6 | - |\n| Mini-Gemini-2B [38] | 3.5B | - | 59.8 | 31.1 | 31.7 | 1653 | - | 29.4 | - | - |\n| DeepSeek-VL-1.3B [48] | 2B | 87.6 | 64.6 | 34.8 | 32.2 | 1532 | - | 31.1 | 66.7 | 409 |\n| PaliGemma-3B [4] | 2.9B | 87.0 | 71.0 | 33.1 | 34.9 | 1686 | - | 28.7 | 69.6 | 614 |\n| MiniCPM-V2 [100] | 2.8B | - | 69.1 | 41.0 | 38.2 | 1809 | - | 38.7 | 67.1 | 605 |\n| InternVL-1.5 [11] | 2B | - | 70.9 | 39.3 | 34.6 | 1902 | - | 41.1 | 69.8 | 654 |\n| Qwen2-VL [88] | 2B | - | 74.9 | 49.5 | 41.1 | 1872 | - | 43.0 | - | 809 |\n| *Encoder-free* | | | | | | | | | | |\n| Fuyu-8B (HD) [2] | 8B | - | 10.7 | 21.4 | - | - | - | - | - | - |\n| EVE-7B [19] | 7B | 83.6 | 49.5 | 25.6 | 32.3 | 1483 | - | 25.2 | 61.3 | 327 |\n| Mono-InternVL [51] | 1.8B | - | 65.5 | 40.1 | 33.7 | 1875 | - | 45.7 | 67.4 | 767 |\n| **Understanding & Generation** | | | | | | | | | | |\n| *Encoder-based* | | | | | | | | | | |\n| Emu [78] | 14B | - | - | 36.3 | - | - | - | - | - | - |\n| Emu2 [76] | 37B | - | 63.6 | 48.5 | 34.1 | - | 1345 | - | 62.8 | - |\n| SEED-X [24] | 17B | 84.2 | 75.4 | - | 35.6 | - | 1436 | - | - | - |\n| LWM [45] | 7B | 75.2 | - | 9.6 | - | - | - | - | - | - |\n| DreamLLM [20] | 7B | - | 58.2 | 36.6 | - | - | - | - | - | - |\n| Janus [92] | 1.3B | 87.0 | 69.4 | 34.3 | 30.5 | - | 1338 | - | 63.7 | - |\n| *Encoder-free* | | | | | | | | | | |\n| Chameleon [8] | 7B | - | - | 8.3 | 22.4 | - | - | - | - | - |\n| Show-o [96] | 1.3B | 84.5 | - | - | 27.4 | - | 1233 | - | - | - |\n| VILA-U [94] | 7B | 85.8 | - | 33.5 | - | - | 1402 | - | 59.0 | - |\n| Emu3-Chat [91] | 8B | 85.2 | 58.5 | 37.2 | 31.6 | - | - | - | 68.2 | 687 |\n| SynerGen-VL (Ours) | 2.4B | 85.3 | 53.7 | 34.5 | 34.2 | 1837 | 1381 | 42.7 | 62.0 | 721 |", "caption": "Table 2: Results on general MLLM benchmarks. Our model with 2.4B parameters achieves competitive image understanding performance compared with significantly larger encoder-free unified MLLMs such as Emu3-Chat-8B\u00a0[91].", "description": "\uc774 \ud45c\ub294 \uc77c\ubc18\uc801\uc778 MLLM \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c SynerGen-VL\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SynerGen-VL\uc740 2.4B \ub9e4\uac1c\ubcc0\uc218\ub85c, Emu3-Chat-8B\uc640 \uac19\uc740 \ud6e8\uc52c \ub354 \ud070 \ub9e4\uac1c\ubcc0\uc218\ub97c \uac00\uc9c4 \uae30\uc874\uc758 \uc778\ucf54\ub354 \uc5c6\ub294 \ud1b5\ud569 MLLM\ubcf4\ub2e4 \uc774\ubbf8\uc9c0 \uc774\ud574 \uc131\ub2a5\uc774 \uc6b0\uc218\ud569\ub2c8\ub2e4. \ud2b9\ud788, SynerGen-VL\uc740 OCRBench\uc640 \uac19\uc774 \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \uc774\ud574\uac00 \ud544\uc694\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ud6e8\uc52c \ub354 \ud070 \uc778\ucf54\ub354 \uc5c6\ub294 \ud1b5\ud569 MLLM\ubcf4\ub2e4 \ub6f0\uc5b4\ub09c \uacb0\uacfc\ub97c \ub2ec\uc131\ud569\ub2c8\ub2e4. \ub610\ud55c SynerGen-VL\uc740 \uc678\ubd80 \ud655\uc0b0 \ubaa8\ub378 \uc5c6\uc774\ub3c4 \uacbd\uc7c1\ub825 \uc788\ub294 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | #A-Param | TextVQA | SQA-I | GQA | DocVQA | AI2D | ChartQA | InfoVQA |\n|---|---|---|---|---|---|---|---|---| \n| **Understanding Only** | | | | | | | | |\n| *Encoder-based* | | | | | | | | |\n| MobileVLM-V2 [14] | 1.7B | 52.1 | 66.7 | 59.3 | - | - | - | - |\n| Mini-Gemini-2B [39] | 3.5B | 56.2 | - | - | 34.2 | - | - | - |\n| PaliGemma-3B [4] | 2.9B |  | 68.1 | - | - | - | 68.3 | - |\n| MiniCPM-V2 [100] | 2.8B | 74.1 | - | - | 71.9 | - | - | - |\n| InternVL-1.5 [11] | 2B | 70.5 | 84.9 | 61.6 | 85.0 | 69.8 | 74.8 | 55.4 |\n| *Encoder-free* | | | | | | | | |\n| EVE-7B [19] | 7B | 51.9 | 63.0 | 60.8 | - | - | - | - |\n| Mono-InternVL [51] | 1.8B | 72.6 | 93.6 | 59.5 | 80.0 | 68.6 | 73.7 | 43.0 |\n| **Understanding & Generation** | | | | | | | | |\n| *Encoder-based* | | | | | | | | |\n| Emu2 [76] | 37B | 66.6 | - | 65.1 | - | - | - | - |\n| LWM [45] | 7B | 18.8 | 47.7 | 44.8 | - | - | - | - |\n| DreamLLM [20] | 7B | 41.8 | - | - | - | - | - | - |\n| MM-Interleaved [82] | 13B | 61.0 | - | 60.5 | - | - | - | - |\n| Janus [92] | 1.3B | - | - | 59.1 | - | - | - | - |\n| *Encoder-free* | | | | | | | | |\n| Chameleon\\* [8] | 7B | 4.8 | 47.2 | - | 1.5 | 46.0 | 2.9 | 5.0 |\n| Show-o [96] | 1.3B | - | - | 61.0 | - | - | - | - |\n| VILA-U [94] | 7B | 60.8 | - | 60.8 | - | - | - | - |\n| Emu3-Chat [91] | 8B | 64.7 | 89.2 | 60.3 | 76.3 | 70.0 | 68.6 | 43.8 |\n| **SynerGen-VL (Ours)** | 2.4B | 67.5 | 92.6 | 59.7 | 76.6 | 60.8 | 73.4 | 37.5 |", "caption": "Table 3: Comparison with existing MLLMs on visual question answering benchmarks. #A-Params denotes the number of activated parameters during inference. \u22c4Some results of Chameleon are sourced from [51].", "description": "\uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc9c8\ubb38 \ub2f5\ubcc0 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uae30\uc874 MLLM\uacfc SynerGen-VL\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. #A-Params\ub294 \ucd94\ub860 \uc911 \ud65c\uc131\ud654\ub41c \ub9e4\uac1c\ubcc0\uc218\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. SynerGen-VL\uc740 \ud65c\uc131\ud654\ub41c \ub9e4\uac1c\ubcc0\uc218 2.4B\uac1c\ub9cc\uc73c\ub85c Emu3-Chat-8B\uc640 \uac19\uc740 \ud6e8\uc52c \ub354 \ud070 \uc778\ucf54\ub354 \ud504\ub9ac \ud1b5\ud569 MLLM\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \uc774\ud574 \ub2a5\ub825\uc774 \ud544\uc694\ud55c OCRBench, TextVQA, DocVQA, ChartQA\uc640 \uac19\uc740 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c SynerGen-VL\uc740 \ud6e8\uc52c \ub354 \ud070 \uc778\ucf54\ub354 \ud504\ub9ac MLLM\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uacb0\uacfc\ub97c \ub2ec\uc131\ud558\uc5ec \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \ucc98\ub9ac \ub2a5\ub825\uc758 \uc7a5\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c SynerGen-VL\uc740 LLaVA-1.5\uc640 \uac19\uc740 \uc778\ucf54\ub354 \uae30\ubc18 \uc774\ud574 \uc804\uc6a9 MLLM\uacfc \ube44\uc2b7\ud55c \uc774\ubbf8\uc9c0 \uc774\ud574 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub3d9\uc2dc\uc5d0 EVE-7B \ubc0f Fuyu-8B(HD)\uc640 \uac19\uc740 \ub354 \ud070 \uc778\ucf54\ub354 \ud504\ub9ac \uc791\uc5c5\ubcc4 MLLM\ubcf4\ub2e4 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \uc774\ubbf8\uc9c0 \uc774\ud574\uc640 \uc0dd\uc131\uc744 \ud1b5\ud569\ud558\ub294 \ub370 \ud070 \uc7a0\uc7ac\ub825\uc774 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. Chameleon\uc758 \uc77c\ubd80 \uacb0\uacfc\ub294 [51]\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4.", "section": "4.2. Image Understanding"}, {"content": "| Method | # A-Param | Single Obj. | Two Obj. | Counting | Colors | Position | Color Attri. | Overall \u2191 | \n|---|---|---|---|---|---|---|---|---| \n| **Generation Only** | | | | | | | | | \n| LlamaGen [75] | 0.8B | 0.71 | 0.34 | 0.21 | 0.58 | 0.07 | 0.04 | 0.32 | \n| LDM [65] | 1.4B | 0.92 | 0.29 | 0.23 | 0.70 | 0.02 | 0.05 | 0.37 | \n| SDv1.5 [65] | 0.9B | 0.97 | 0.38 | 0.35 | 0.76 | 0.04 | 0.06 | 0.43 | \n| SDXL [61] | 2.6B | 0.98 | 0.74 | 0.39 | 0.85 | 0.15 | 0.23 | 0.55 | \n| PixArt-\u03b1 [9] | 0.6B | 0.98 | 0.50 | 0.44 | 0.80 | 0.08 | 0.07 | 0.48 | \n| DALL-E 2 [64] | 6.5B | 0.94 | 0.66 | 0.49 | 0.77 | 0.10 | 0.19 | 0.52 | \n| **Understanding & Generation** | | | | | | | | | \n| SEED-X\u2020 [24] | 17B | 0.97 | 0.58 | 0.26 | 0.80 | 0.19 | 0.14 | 0.49 | \n| Show-o [96] | 1.3B | 0.95 | 0.52 | 0.49 | 0.82 | 0.11 | 0.28 | 0.53 | \n| LWM [45] | 7B | 0.93 | 0.41 | 0.46 | 0.79 | 0.09 | 0.15 | 0.47 | \n| Chameleon [8] | 34B | - | - | - | - | - | - | 0.39 | \n| Emu3-Gen [91] | 8B | 0.98 | 0.71 | 0.34 | 0.81 | 0.17 | 0.21 | 0.54 | \n| Janus [92] | 1.3B | 0.97 | 0.68 | 0.30 | 0.84 | 0.46 | 0.42 | 0.61 | \n| **SynerGen-VL (Ours)** | 2.4B | 0.99 | 0.71 | 0.34 | 0.87 | 0.37 | 0.37 | 0.61 |", "caption": "Table 4: Evaluation of text-to-image generation on GenEval\u00a0[25] benchmark. #A-Params denotes the number of activated parameters during inference. \u2020\u2020{\\dagger}\u2020 indicates models with external pretrained diffusion model. Obj.: Object. Attri.: Attribution.", "description": "\uc774 \ud45c\ub294 GenEval \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \uc0dd\uc131 \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. #A-Params\ub294 \ucd94\ub860 \uc911 \ud65c\uc131\ud654\ub41c \ub9e4\uac1c\ubcc0\uc218\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \u2020\u2020\ub294 \uc678\ubd80\uc5d0\uc11c \ubbf8\ub9ac \ud559\uc2b5\ub41c \ud655\uc0b0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. Obj.\ub294 Object\ub97c, Attri.\ub294 Attribution\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uac1d\uccb4, \uac1d\uccb4 \uc218, \uc0c9\uc0c1, \uc704\uce58, \uc0c9\uc0c1 \uc18d\uc131\uacfc \uac19\uc740 \uac1d\uccb4 \uc218\uc900 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \uc815\ub82c \uae30\uc900\uc5d0 \ub530\ub77c \ubaa8\ub378 \uc131\ub2a5\uc744 \ube44\uad50\ud569\ub2c8\ub2e4.", "section": "4.3. Image Generation"}, {"content": "| Model | #A-Param | MS-COCO\u2193 | MJHQ\u2193 |\n|---|---|---|---| \n| **Generation Only** |  |  |  |\n| DALL-E [63] | 12B | 27.50 | - |\n| LDM [65] | 1.4B | 12.64 | - |\n| GLIDE [58] | 5B | 12.24 | - |\n| DALL-E 2 [64] | 6.5B | 10.39 | - |\n| RAPHAEL [97] | 3B | 6.61 | - |\n| Imagen [66] | 34B | 7.27 | - |\n| SDv1.5 [65] | 0.9B | 9.62 | - |\n| SDXL [61] | 0.9B | 7.38 | 8.76 |\n| PixArt-\u03b1 [9] | 0.6B | 7.32 | 6.14 |\n| **Understanding & Generation** |  |  |  |\n| NExT-GPT [93] | 13B | 11.18 | - |\n| SEED-X [24] | 17B | 14.99 | - |\n| Show-o [96] | 1.3B | 9.24 | 15.18 |\n| LWM [45] | 7B | 12.68 | 17.77 |\n| VILA-U [94] | 7B | - | 7.69 |\n| Emu3-Gen [91] | 8B | 19.3 | - |\n| Janus [92] | 1.3B | 8.53 | 10.10 |\n| **SynerGen-VL (Ours)** | 2.4B | 7.65 | 6.10 |", "caption": "Table 5: Image generation results on MSCOCO-30K\u00a0[40] and MJHQ-30K\u00a0[35] datasets. FID\u00a0[27] is reported. #A-Param denotes the number of activated parameters during inference.", "description": "\uc774 \ud45c\ub294 MSCOCO-30K\uc640 MJHQ-30K \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 FID \uc810\uc218\ub85c \ube44\uad50\ud569\ub2c8\ub2e4. #A-Param\uc740 \ucd94\ub860 \uc911 \ud65c\uc131\ud654\ub41c \ub9e4\uac1c\ubcc0\uc218\uc758 \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc804\uc6a9 \ubaa8\ub378\uacfc \uc774\ud574 \ubc0f \uc0dd\uc131 \uae30\ub2a5\uc744 \ubaa8\ub450 \uac16\ucd98 \ud1b5\ud569 \uba40\ud2f0\ubaa8\ub2ec \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uc758 \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \ud65c\uc131\ud654\ub41c \ub9e4\uac1c\ubcc0\uc218 \uc218\uc640 \ud568\uaed8 \ub450 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c FID \uc810\uc218\uac00 \ud45c\uc2dc\ub429\ub2c8\ub2e4.", "section": "4.3. Image Generation"}, {"content": "| Model | TextVQA | GQA | DocVQA | AI2D | ChartQA | InfoVQA |\n|---|---|---|---|---|---|---| \n| *w/o* token folding | 18.7 | 45.3 | 14.7 | 42.0 | 20.9 | 18.7 |\n| *w/* token folding | 35.0 | 45.1 | 36.7 | 42.1 | 49.7 | 21.1 |", "caption": "Table 6: Comparison between models with and without token-folding on VQA benchmarks. The model with token folding demonstrates significant performance improvements with the same image token sequence length.", "description": "\ud1a0\ud070 \uc811\uae30 \uc720\ubb34\uc5d0 \ub530\ub978 VQA \ubca4\uce58\ub9c8\ud06c \uc131\ub2a5 \ube44\uad50\ud45c\uc785\ub2c8\ub2e4. \ub3d9\uc77c\ud55c \uc774\ubbf8\uc9c0 \ud1a0\ud070 \uc2dc\ud000\uc2a4 \uae38\uc774\uc5d0\uc11c \ud1a0\ud070 \uc811\uae30\ub97c \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc774 \uc131\ub2a5\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \uc774\ud574\uc5d0 \ub300\ud55c \ud1a0\ud070 \uc811\uae30\uc758 \ud6a8\uacfc\ub97c \uac80\uc99d\ud558\uae30 \uc704\ud574 SynerGen-VL\uc774 \ud1a0\ud070 \uc811\uae30 \uc5c6\uc774, \uadf8\ub9ac\uace0 \ub3d9\uc801 \ud574\uc0c1\ub3c4 \uc804\ub7b5 \uc5c6\uc774 \uae30\uc900 \ubc84\uc804\uacfc \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc900 \ubaa8\ub378\uc740 \ud1a0\ud070 \uc811\uae30 \uc5c6\uc774 \ud1a0\ud070\ud654\ub41c \uc2dc\ud000\uc2a4\ub97c \uc785\ub825 \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4\ub85c \uc9c1\uc811 \uc0ac\uc6a9\ud558\uba70, \uc785\ub825 \uc774\ubbf8\uc9c0 \ud06c\uae30\ub294 256x256\uc774\uace0 \ud1a0\ud070\ud654\ub41c \uc2dc\ud000\uc2a4 \uae38\uc774\ub294 1024\uc785\ub2c8\ub2e4. \ud1a0\ud070 \uc811\uae30\ub97c \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc758 \uacbd\uc6b0, \uace0\ud574\uc0c1\ub3c4 \uc785\ub825 \uc774\ubbf8\uc9c0\ub97c \uc81c\uacf5\ud558\uae30 \uc704\ud574 \ub3d9\uc801 \ud574\uc0c1\ub3c4 \uc804\ub7b5\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4. \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \ud1a0\ud070 \uc811\uae30 \ube44\uc728\uc744 2x4\ub85c \uc0ac\uc6a9\ud558\uace0 \ud1a0\ud070 \uc811\uae30 \ud6c4 \uc774\ubbf8\uc9c0 \ud1a0\ud070 \uc2dc\ud000\uc2a4\uc758 \ud3c9\uade0 \uae38\uc774\uac00 1024\uac00 \ub418\ub3c4\ub85d \ub3d9\uc801 \uc774\ubbf8\uc9c0 \ud328\uce58\uc758 \ucd5c\ub300 \uac1c\uc218\ub97c \uc81c\uc5b4\ud569\ub2c8\ub2e4. 2\ub2e8\uacc4(S.2) \uc774\ud574 \ub370\uc774\ud130\uc758 \ud558\uc704 \uc9d1\ud569\uc73c\ub85c \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\uace0, VQA \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. TextVQA, DocVQA, ChartVQA, InfoVQA\uc640 \uac19\uc740 \uc0c1\uc138\ud55c \uc774\ubbf8\uc9c0 \uc815\ubcf4\uc5d0 \ub300\ud55c \uc815\ud655\ud55c \uc774\ud574\uac00 \ud544\uc694\ud55c \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ud1a0\ud070 \uc811\uae30\ub97c \uc0ac\uc6a9\ud55c \ubaa8\ub378\uc774 \ud6e8\uc52c \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \ub2ec\uc131\ud558\uc5ec \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \uc774\ud574\uc758 \uc774\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. Ablation Study"}, {"content": "| Stage | Strategy | TextVQA | GQA | DocVQA | AI2D | ChartQA | InfoVQA | MMLU | CMMLU | AGIEVAL | MATH | MSCOCO | \n|---|---|---|---|---|---|---|---|---|---|---|---|---| \n| Baseline (Qwen2-0.5B) | | - | - | - | - | - | - | 42.3 | 51.4 | 29.3 | 12.1 | - |\n| S.1 + S.2 | Full | 14.3 | 42.9 | 11.3 | 24.7 | 12.4 | 12.6 | 23.1 | 23.0 | 8.1 | 0.9 | 30.7 |\n| S.1 only | Progressive | 0.1 | 13.0 | 0.2 | 0.3 | 0.0 | 0.0 | 42.3 | 51.4 | 29.3 | 12.1 | 28.3 |\n| S.2 only | Progressive | 8.7 | 36.9 | 8.6 | 40.9 | 11.7 | 16.2 | 37.6 | 45.3 | 28.9 | 7.2 | 34.9 |\n| S.1 + S.2 | Progressive | 13.2 | 41.2 | 11.4 | 41.9 | 12.8 | 17.0 | 39.3 | 48.2 | 26.2 | 8.9 | 20.2 |", "caption": "Table 7: Zero-shot performance of different pre-training strategies. \u201cS.1\u201d and \u201cS.2\u201d denote the first and second pre-training stage. \u201cFull\u201d and \u201cProgressive\u201d denote the full parameter tuning and our progressive tuning strategy with MMoEs, respectively. FID\u00a0[27] is reported for text-to-image generation (T2I) on MSCOCO\u00a0[40].", "description": "\uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc0ac\uc804 \ud6c8\ub828 \uc804\ub7b5\uc758 \uc81c\ub85c\uc0f7 \uc131\ub2a5\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. \"S.1\"\uacfc \"S.2\"\ub294 \uac01\uac01 \uccab \ubc88\uc9f8 \ubc0f \ub450 \ubc88\uc9f8 \uc0ac\uc804 \ud6c8\ub828 \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \"\uc804\uccb4\"\ub294 \uc804\uccb4 \ub9e4\uac1c\ubcc0\uc218 \uc870\uc815\uc744 \ub098\ud0c0\ub0b4\uace0, \"\uc810\uc9c4\uc801\"\uc740 MMoE\ub97c \uc0ac\uc6a9\ud55c \uc810\uc9c4\uc801 \uc870\uc815 \uc804\ub7b5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. MSCOCO\uc5d0\uc11c \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \uc0dd\uc131(T2I)\uc5d0 \ub300\ud574 FID\uac00 \ubcf4\uace0\ub429\ub2c8\ub2e4.", "section": "5. Ablation Study"}, {"content": "| Configuration | Alignment Pre-training | Instruction |\n|---|---|---| \n|  | S.1 | S.2 | Tuning |\n| Maximum number of image tiles | 1 | 6 | 12 |\n| LLM sequence length | 4,096 | 8,192 | 16,384 |\n| Use thumbnail | \u2717 | \u2713 | \u2713 |\n| Global batch size (per-task) | 6,988 | 5,090 | 1,760 |\n| Peak learning rate | 1e^{-4} | 5e^{-5} | 5e^{-5} |\n| Learning rate schedule | constant with warm-up | cosine decay | cosine decay |\n| Weight decay | 0.05 | 0.05 | 0.01 |\n| Training steps | 95k | 35k | 12k |\n| Warm-up steps | 200 | 200 | 200 |\n| Optimizer | AdamW | AdamW | AdamW |\n| Optimizer hyperparameters | \\beta_{1}=0.9,\\beta_{2}=0.95,eps=1e^{-8} | \\beta_{1}=0.9,\\beta_{2}=0.95,eps=1e^{-8} | \\beta_{1}=0.9,\\beta_{2}=0.95,eps=1e^{-8} |\n| Gradient accumulation | 1 | 1 | 1 |\n| Numerical precision | bfloat16 | bfloat16 | bfloat16 |", "caption": "Table 8: Hyper-parameters used in the alignment pre-training and instruction tuning stages.", "description": "\uc774 \ud45c\ub294 SynerGen-VL \ubaa8\ub378\uc758 \uc0ac\uc804 \ud6c8\ub828 \ubc0f \uba85\ub839\uc5b4 \ubbf8\uc138 \uc870\uc815 \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0ac\uc804 \ud6c8\ub828 \ub2e8\uacc4\ub294 \ub450 \ub2e8\uacc4\ub85c \ub098\ub258\uba70, \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \uc774\ubbf8\uc9c0 \ud0c0\uc77c \ucd5c\ub300 \uac1c\uc218, LLM \uc2dc\ud000\uc2a4 \uae38\uc774, \uc378\ub124\uc77c \uc0ac\uc6a9 \uc5ec\ubd80, \uae00\ub85c\ubc8c \ubc30\uce58 \ud06c\uae30, \ucd5c\ub300 \ud559\uc2b5\ub960, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904, \uac00\uc911\uce58 \uac10\uc1e0, \ud6c8\ub828 \ub2e8\uacc4, \uc6dc\uc5c5 \ub2e8\uacc4, \uc635\ud2f0\ub9c8\uc774\uc800 \uc885\ub958 \ubc0f \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130, \uadf8\ub798\ub514\uc5b8\ud2b8 \ub204\uc801, \uadf8\ub9ac\uace0 \uc218\uce58 \uc815\ubc00\ub3c4 \ub4f1\uc758 \uc124\uc815\uac12\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\uace0, \uba85\ub839\uc5b4 \ubbf8\uc138 \uc870\uc815 \ub2e8\uacc4\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uac12\ub4e4\ub3c4 \ud568\uaed8 \ube44\uad50\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "A. Detailed Training Configurations"}]