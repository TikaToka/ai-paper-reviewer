[{"content": "| Stage | Input | Output | Input Cache Read | Input Cache Write | Qwen-2.5 | USD (%) | Total Cost |\n|---|---|---|---|---|---|---|---| \n| **Claude Sonnet-3.5 API Costs** |  |  |  |  |  |  |  |\n| Relevance | 0.00 | 0.00 | 0.00 | 0.00 | 334.02 | 334.02 (14.6%) |  |\n| Ranking | 0.00 | 11.92 | 1.10 | 6.90 | 0.00 | 19.92 (0.9%) |  |\n| Gen. tests | 10.60 | 295.15 | 21.60 | 112.64 | 0.00 | 439.99 (19.2%) |  |\n| Gen. edits | 14.67 | 353.95 | 636.82 | 360.58 | 0.00 | 1366.02 (59.6%) |  |\n| Selection | 0.52 | 51.12 | 15.17 | 65.14 | 0.00 | 131.95 (5.8%) |  |\n| **Total** | 25.79 | 712.14 | 674.69 | 545.26 | 334.02 | 2291.90 (100.0%) |  |", "caption": "Table 1: Breaking down the costs of running CodeMonkeys on all GitHub issues from SWE-bench Verified. All costs are in USD. Our system uses two LLMs: a primary model used for the ranking, generation, and selection stages (we use the Claude 3.5 Sonnet API [3]), and a cheaper model used for scanning codebases to identify relevant files (we run Qwen2.5-Coder-32B-Instruct [24] locally). For measuring costs with the Claude API, we use prices of $3/million input tokens, $0.3/million cache read tokens, $3.75/million cache write tokens, and $15/million output tokens. For details about estimating local inference costs, see Appendix C.", "description": "\ud45c 1\uc740 CodeMonkeys \uc2dc\uc2a4\ud15c\uc744 SWE-bench Verified \ub370\uc774\ud130\uc14b\uc758 \ubaa8\ub4e0 GitHub \uc774\uc288\uc5d0 \uc801\uc6a9\ud588\uc744 \ub54c \ubc1c\uc0dd\ud558\ub294 \ube44\uc6a9\uc744 \uc138\ubd80\uc801\uc73c\ub85c \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4. \ube44\uc6a9\uc740 \ubaa8\ub450 \ubbf8\uad6d \ub2ec\ub7ec($) \ub2e8\uc704\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc2dc\uc2a4\ud15c\uc740 \ub450 \uac1c\uc758 \uac70\ub300 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc744 \uc0ac\uc6a9\ud558\ub294\ub370, \uc8fc\uc694 \ubaa8\ub378\uc740 \uc21c\uc704 \uc9c0\uc815, \uc0dd\uc131, \uc120\ud0dd \ub2e8\uacc4\uc5d0 \uc0ac\uc6a9\ub418\uba70 (Claude 3.5 Sonnet API [3] \uc0ac\uc6a9), \ubcf4\uc870 \ubaa8\ub378\uc740 \ucf54\ub4dc\ubca0\uc774\uc2a4\uc5d0\uc11c \uad00\ub828 \ud30c\uc77c\uc744 \uc2a4\uce94\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4 (Qwen-2.5-Coder-32B-Instruct [24] \ub85c\uceec \uc2e4\ud589). Claude API\ub97c \uc0ac\uc6a9\ud55c \ube44\uc6a9 \uce21\uc815\uc5d0\ub294 1\ubc31\ub9cc \uac1c\uc758 \uc785\ub825 \ud1a0\ud070\ub2f9 3\ub2ec\ub7ec, 1\ubc31\ub9cc \uac1c\uc758 \uce90\uc2dc \uc77d\uae30 \ud1a0\ud070\ub2f9 0.3\ub2ec\ub7ec, 1\ubc31\ub9cc \uac1c\uc758 \uce90\uc2dc \uc4f0\uae30 \ud1a0\ud070\ub2f9 3.75\ub2ec\ub7ec, 1\ubc31\ub9cc \uac1c\uc758 \ucd9c\ub825 \ud1a0\ud070\ub2f9 15\ub2ec\ub7ec\uc758 \uac00\uaca9\uc774 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ub85c\uceec \ucd94\ub860 \ube44\uc6a9 \uc0b0\uc815\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ubd80\ub85d C\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "2. CodeMonkeys\uc758 \uc124\uacc4: \ud14c\uc2a4\ud2b8 \uc2dc\uac04 \uacc4\uc0b0 \ud655\uc7a5"}, {"content": "| Method | Score |\n|---|---| \n| Barrel of Monkeys (Oracle Selection) | 80.8 |\n| o3 | 71.7 |\n| CodeMonkeys (Oracle Selection) | 69.8 |\n| Barrel of Monkeys | 66.2 |\n| Blackbox AI Agent | 62.8 |\n| CodeStory | 62.2 |\n| Learn-by-interact | 60.2 |\n| devlo | 58.2 |\n| CodeMonkeys | 57.4 |\n| Emergent E1 | 57.2 |\n| Gru | 57.0 |", "caption": "Table 2: Comparing final SWE-bench Verified scores between the methods explored in this paper (bolded) and existing top approaches. Note that the Barrel of Monkeys results rely on the generations from existing submissions on the SWE-bench Verified leaderboard, and oracle selection methods are coverage numbers.", "description": "\ud45c 2\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ubc29\ubc95(\uad75\uc740 \uae00\uc528\uccb4)\uacfc \uae30\uc874 \ucd5c\uace0 \uc131\ub2a5 \ubc29\ubc95\ub4e4\uc744 \ube44\uad50\ud558\uc5ec \ucd5c\uc885 SWE-bench Verified \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Barrel of Monkeys \uacb0\uacfc\ub294 SWE-bench Verified \ub9ac\ub354\ubcf4\ub4dc\uc5d0 \uc788\ub294 \uae30\uc874 \uc81c\ucd9c\ubb3c\uc758 \uc0dd\uc131 \uacb0\uacfc\uc5d0 \uc758\uc874\ud558\uba70, \uc624\ub77c\ud074 \uc120\ud0dd \ubc29\ubc95\uc740 \uc801\uc6a9 \ubc94\uc704\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "2.3 \ud6c4\ubcf4 \ucf54\ub4dc \ud3b8\uc9d1 \uc120\ud0dd"}, {"content": "| **Testing State Machine** | **Editing State Machine** | **Selection State Machine** |\n|---|---|---|\n| **Information in Initial Prompt** | GitHub issue description. | GitHub issue description, codebase context, final test script from a testing state machine, execution output when running the provided test on the unedited codebase. | GitHub issue description, candidate edits in git diff form, full contents of any codebase files that have been edited, test script from the edit that passed the most generated tests (breaking ties by using the shortest edit). |\n| **Initial Task** | Write a test script that reproduces the issue. The script should exit with code 0 if the issue is fixed and exit with code 2 if the issue is not fixed. | Write a codebase edit that resolves the issue. | Write a test script for distinguishing between candidates and assessing their correctness. |\n| **Information in Iteration Prompt** | Execution output when running the test on the codebase (which has not yet been edited). | Execution outputs when running the testing script on the unedited codebase and edited codebase. | Execution outputs when running the test script on a codebase after each edit has been applied, in addition to the unedited codebase. |\n| **Iteration Task** | Rewrite the test script or approve of it (terminating the state machine). | Rewrite the edit, rewrite the test script, or approve of the (edit, test) pairs (terminating the state machine). | Write a new testing script, or make a selection among the candidate edits (terminating the state machine). |", "caption": "Table 3: Details of the Testing, Editing, and Selection State Machines.", "description": "\uc774 \ud45c\ub294 CodeMonkeys \uc2dc\uc2a4\ud15c\uc758 \uc138 \uac00\uc9c0 \uc0c1\ud0dc \uba38\uc2e0(\ud14c\uc2a4\ud2b8, \ud3b8\uc9d1, \uc120\ud0dd)\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uba38\uc2e0\uc758 \ucd08\uae30 \ud504\ub86c\ud504\ud2b8, \ucd08\uae30 \uc791\uc5c5, \uac01 \ubc18\ubcf5\uc5d0\uc11c \uc81c\uacf5\ub418\ub294 \uc815\ubcf4, \uac01 \ubc18\ubcf5\uc758 \uc791\uc5c5\uc744 \uc124\uba85\ud569\ub2c8\ub2e4. \ud14c\uc2a4\ud2b8 \uc0c1\ud0dc \uba38\uc2e0\uc740 \ubb38\uc81c\ub97c \uc7ac\ud604\ud558\ub294 \ud14c\uc2a4\ud2b8 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc791\uc131\ud558\uace0, \ud3b8\uc9d1 \uc0c1\ud0dc \uba38\uc2e0\uc740 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ucf54\ub4dc\ubca0\uc774\uc2a4 \ud3b8\uc9d1\uc744 \uc791\uc131\ud558\uba70, \uc120\ud0dd \uc0c1\ud0dc \uba38\uc2e0\uc740 \ud6c4\ubcf4 \ud3b8\uc9d1\uc744 \uad6c\ubd84\ud558\uace0 \uc815\ud655\uc131\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ud14c\uc2a4\ud2b8 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc791\uc131\ud569\ub2c8\ub2e4.", "section": "2.2 \ud6c4\ubcf4 \ucf54\ub4dc\ubca0\uc774\uc2a4 \ud3b8\uc9d1 \ubc0f \ud574\ub2f9 \ud14c\uc2a4\ud2b8 \uc0dd\uc131"}, {"content": "| Subtask | Stage | Parameter | Value |\n|---|---|---|---| \n| **Context** | Relevance | Model | Qwen-2.5-Coder-32B-Instruct |\n|  |  | Hardware | 8xL40S |\n|  |  | Temperature | 0.0 |\n|  | Ranking | Model | Claude Sonnet 3.5 |\n|  |  | Temperature | 0.0 |\n|  |  | Repetitions | 3 |\n| **Generation** | Testing & Editing | Temperature (Sonnet 3.5) | 0.5 |\n|  |  | Temperature (DeepSeek-V3) | 0.6 |\n|  |  | Number of State Machines per Instance | 10 |\n|  |  | Maximum Iterations | 8 |\n|  |  | Generated Test Timeout (seconds) | 100 |\n| **Selection** | \u2014 | Temperature | 0.0 |\n|  |  | Maximum Iterations | 10 |\n|  |  | Generated Test Timeout (seconds) | 100 |", "caption": "Table 4: CodeMonkeys hyperparameter summary.", "description": "\ud45c 4\ub294 CodeMonkeys \uc2dc\uc2a4\ud15c\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc744 \uc694\uc57d\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 \uc2dc\uc2a4\ud15c\uc758 \uc138 \uac00\uc9c0 \uc8fc\uc694 \ub2e8\uacc4(Context, Generation, Selection)\uc640 \uac01 \ub2e8\uacc4\uc758 \ud558\uc704 \ub2e8\uacc4\uc5d0 \ub530\ub77c \ub098\ub258\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc758 \uac12\uacfc \uc0ac\uc6a9\ub41c \ubaa8\ub378 (\uc608: Claude Sonnet 3.5, Qwen-2.5-Coder-32B-Instruct)\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc5b4 CodeMonkeys \uc2dc\uc2a4\ud15c\uc758 \uad6c\ud604 \uc138\ubd80 \uc0ac\ud56d\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788, \uc628\ub3c4(Temperature), \ubc18\ubcf5 \ud69f\uc218(Repetitions), \uc0c1\ud0dc \uba38\uc2e0 \uc218(Number of State Machines), \ucd5c\ub300 \ubc18\ubcf5 \ud69f\uc218(Maximum Iterations), \uc81c\ud55c \uc2dc\uac04(Timeout)\uacfc \uac19\uc740 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\ubbc0\ub85c, \uc774 \ud45c\ub97c \ud1b5\ud574 CodeMonkeys \uc2dc\uc2a4\ud15c\uc758 \uc131\ub2a5 \uc870\uc815\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 Designing a SWE-bench Solver that Scales Test-Time Compute"}]