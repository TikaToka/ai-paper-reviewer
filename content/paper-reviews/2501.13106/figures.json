[{"figure_path": "https://arxiv.org/html/2501.13106/x1.png", "caption": "Figure 1: Performance Comparison of VideoLLaMA3 with the previous advanced image/video MLLM on various representative benchmarks. As shown in the figure, VideoLLaMA3 has achieved very competitive results on various benchmarks. Specifically, VideoLLaMA3 not only demonstrates strong video understanding capabilities\u00a0(VideoMME, PerceptionTest, MLVU) but also maintains excellent document comprehension abilities\u00a0(DocVQA) and multimodal mathematical reasoning skills\u00a0(MathVista).\nNote that LLaVA-OneVision is only used for evaluating image benchmarks, while LLaVA-Video is only used for evaluating video benchmarks.", "description": "\uadf8\ub9bc 1\uc740 VideoLLaMA3\uc758 \uc131\ub2a5\uc744 \uc774\uc804\uc758 \uace0\uae09 \uc774\ubbf8\uc9c0/\ube44\ub514\uc624 \ub2e4\uc911 \ubaa8\ub4dc \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uacfc \ub2e4\uc591\ud55c \ub300\ud45c\uc801\uc778 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoLLaMA3\ub294 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uacbd\uc7c1\ub825 \uc788\ub294 \uacb0\uacfc\ub97c \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 VideoLLaMA3\ub294 VideoMME, PerceptionTest, MLVU\uc640 \uac19\uc740 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825 \ubfd0\ub9cc \uc544\ub2c8\ub77c DocVQA\uc640 \uac19\uc740 \ubb38\uc11c \uc774\ud574 \ub2a5\ub825\uacfc MathVista\uc640 \uac19\uc740 \ub2e4\uc911 \ubaa8\ub4dc \uc218\ud559\uc801 \ucd94\ub860 \ub2a5\ub825\ub3c4 \ub6f0\uc5b4\ub0ac\uc2b5\ub2c8\ub2e4. LLaVA-OneVision\uc740 \uc774\ubbf8\uc9c0 \ubca4\uce58\ub9c8\ud06c \ud3c9\uac00\uc5d0\ub9cc \uc0ac\uc6a9\ub418\uc5c8\uace0, LLaVA-Video\ub294 \ube44\ub514\uc624 \ubca4\uce58\ub9c8\ud06c \ud3c9\uac00\uc5d0\ub9cc \uc0ac\uc6a9\ub418\uc5c8\ub2e4\ub294 \uc810\uc5d0 \uc720\uc758\ud574\uc57c \ud569\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.13106/x2.png", "caption": "Figure 2: Training paradigm of VideoLLaMA3. The training of VideoLLaMA3 has four stages: (1) Vision Encoder Adaptation, (2) Vision-Language Alignment, (3) Multi-task Fine-tuning, and (4) Video-centric Fine-tuning.", "description": "\uadf8\ub9bc 2\ub294 VideoLLaMA3\uc758 \ud6c8\ub828 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoLLaMA3\uc758 \ud6c8\ub828\uc740 \ud06c\uac8c \ub124 \ub2e8\uacc4\ub85c \ub098\ub258\ub294\ub370, \uac01 \ub2e8\uacc4\ub294 \ud2b9\uc815 \ubaa9\ud45c\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4. 1\ub2e8\uacc4\uc778 Vision Encoder Adaptation\uc5d0\uc11c\ub294 \ub2e4\uc591\ud55c \ud574\uc0c1\ub3c4\uc758 \uc774\ubbf8\uc9c0\ub97c \ucc98\ub9ac\ud560 \uc218 \uc788\ub3c4\ub85d \ube44\uc804 \uc778\ucf54\ub354\ub97c \uc870\uc815\ud569\ub2c8\ub2e4. 2\ub2e8\uacc4\uc778 Vision-Language Alignment\ub294 \ub300\uaddc\ubaa8 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \ube44\uc804 \uc778\ucf54\ub354\uc640 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ub3d9\uc2dc\uc5d0 \uc870\uc815\ud558\uc5ec \uc2dc\uac01\uc801 \ubc0f \uc5b8\uc5b4\uc801 \uc774\ud574 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. 3\ub2e8\uacc4\uc778 Multi-task Fine-tuning\uc740 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \ucd94\uac00\uc801\uc778 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \ubc0f \ube44\ub514\uc624 \ub370\uc774\ud130\ub85c \ubbf8\uc138 \uc870\uc815\ud558\ub294 \ub2e8\uacc4\uc785\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 4\ub2e8\uacc4\uc778 Video-centric Fine-tuning\uc740 \ube44\ub514\uc624 \uc774\ud574 \ub2a5\ub825\uc744 \ub354\uc6b1 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \ube44\ub514\uc624 \uc911\uc2ec\uc758 \ubbf8\uc138 \uc870\uc815\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \ub370\uc774\ud130\uc758 \uc885\ub958\uc640 \uc591\ub3c4 \uadf8\ub9bc\uc5d0 \uc790\uc138\ud788 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3 Training"}, {"figure_path": "https://arxiv.org/html/2501.13106/x3.png", "caption": "Figure 3: The overall pipeline of our VideoLLaMA3. There are two key technical points: \u2776 Any-resolution Vision Tokenization\u00a0(AVT): AVT converts images or videos of any resolution into a set of 1-D token sequences, enabling compatibility with varying amounts of input images and videos of different resolutions, thereby supporting more flexible vision input; \u2777 Differential Frame Pruner\u00a0(DiffFP): Serving as a video compressor, DiffFP eliminates video content with minimal differences between adjacent frames. This approach enhances video processing efficiency, particularly for long-form videos.", "description": "\uadf8\ub9bc 3\uc740 VideoLLaMA3\uc758 \uc804\uccb4 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uac00\uc9c0 \ud575\uc2ec \uae30\uc220\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uccab\uc9f8, \uc784\uc758 \ud574\uc0c1\ub3c4 \ube44\uc804 \ud1a0\ud070\ud654(AVT)\ub294 \ubaa8\ub4e0 \ud574\uc0c1\ub3c4\uc758 \uc774\ubbf8\uc9c0\ub098 \ube44\ub514\uc624\ub97c 1\ucc28\uc6d0 \ud1a0\ud070 \uc2dc\ud000\uc2a4 \uc9d1\ud569\uc73c\ub85c \ubcc0\ud658\ud558\uc5ec \ub2e4\uc591\ud55c \uc591\uc758 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uc11c\ub85c \ub2e4\ub978 \ud574\uc0c1\ub3c4\uc758 \ube44\ub514\uc624\ub97c \uc9c0\uc6d0\ud568\uc73c\ub85c\uc368 \ubcf4\ub2e4 \uc720\uc5f0\ud55c \ube44\uc804 \uc785\ub825\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \ub458\uc9f8, \ucc28\ubcc4\uc801 \ud504\ub808\uc784 \uac00\uc9c0\uce58\uae30(DiffFP)\ub294 \ube44\ub514\uc624 \uc555\ucd95\uae30 \uc5ed\ud560\uc744 \ud558\uba70 \uc778\uc811\ud55c \ud504\ub808\uc784 \uac04\uc758 \ucc28\uc774\uac00 \ucd5c\uc18c\uc778 \ube44\ub514\uc624 \ucf58\ud150\uce20\ub97c \uc81c\uac70\ud569\ub2c8\ub2e4. \uc774 \ubc29\ubc95\uc740 \ud2b9\ud788 \uae34 \ube44\ub514\uc624\uc758 \uacbd\uc6b0 \ube44\ub514\uc624 \ucc98\ub9ac \ud6a8\uc728\uc131\uc744 \ub192\uc785\ub2c8\ub2e4.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2501.13106/x4.png", "caption": "Figure 4: The calculation flow of our DiffFP. We prune video tokens based on patch similarities in pixel space, removing patches with smaller distances to the previous frame.", "description": "\uadf8\ub9bc 4\ub294 VideoLLaMA3 \ubaa8\ub378\uc758 DiffFP(Differential Frame Pruner) \ub3d9\uc791 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. DiffFP\ub294 \ube44\ub514\uc624 \ud1a0\ud070\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uae30 \uc704\ud574 \uc124\uacc4\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, DiffFP\ub294 \uc774\uc804 \ud504\ub808\uc784\uacfc\uc758 \ud53d\uc140 \uacf5\uac04\uc5d0\uc11c\uc758 \ud328\uce58 \uc720\uc0ac\ub3c4\ub97c \uae30\ubc18\uc73c\ub85c \ube44\ub514\uc624 \ud1a0\ud070\uc744 \uc81c\uac70\ud569\ub2c8\ub2e4.  \uc989, \uc774\uc804 \ud504\ub808\uc784\uacfc \ub9e4\uc6b0 \uc720\uc0ac\ud55c \ud328\uce58(\uc601\uc5ed)\ub294 \uc911\ubcf5 \uc815\ubcf4\ub85c \uac04\uc8fc\ub418\uc5b4 \uc81c\uac70\ub418\uace0, \uc774\ub97c \ud1b5\ud574 \ube44\ub514\uc624\uc758 \ud6a8\uc728\uc801\uc778 \ud45c\ud604\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \ud504\ub808\uc784 \uac04 \ucc28\uc774 \uacc4\uc0b0, \ud328\uce58 \uc81c\uac70 \uacfc\uc815\uc774 \uc21c\ucc28\uc801\uc73c\ub85c \ub098\ud0c0\ub098 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacfc\uc815\uc744 \uac70\uccd0 \ube44\ub514\uc624 \ud1a0\ud070\uc758 \uc218\ub97c \uc904\uc784\uc73c\ub85c\uc368, \ud2b9\ud788 \uae34 \ube44\ub514\uc624\uc758 \ucc98\ub9ac \ud6a8\uc728\uc744 \ub192\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 Methodology"}, {"figure_path": "https://arxiv.org/html/2501.13106/x5.png", "caption": "Figure 5: Data formats for different data types. \u2776 For image sequence, we use \"\\n\" to separate image tokens from different image; \u2777 For video sequence, we use \"Time: xxs\" to indicate timestamps of each frame, \",\" to separate different frames, and \"\\n\" to separate tokens from different videos; \u2778 For streaming video sequence, videos and texts are organized in an interleaved format.", "description": "\uadf8\ub9bc 5\ub294 \uc11c\ub85c \ub2e4\ub978 \ub370\uc774\ud130 \uc720\ud615\uc5d0 \ub300\ud55c \ub370\uc774\ud130 \ud615\uc2dd\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4\uc758 \uacbd\uc6b0 \uac01 \uc774\ubbf8\uc9c0\uc758 \ud1a0\ud070\uc744 \uad6c\ubd84\ud558\uae30 \uc704\ud574 \"\\n\"\uc744 \uc0ac\uc6a9\ud558\uace0, \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\uc758 \uacbd\uc6b0 \uac01 \ud504\ub808\uc784\uc758 \ud0c0\uc784\uc2a4\ud0ec\ud504\ub97c \ub098\ud0c0\ub0b4\uae30 \uc704\ud574 \"Time: xxs\"\ub97c, \uc11c\ub85c \ub2e4\ub978 \ud504\ub808\uc784\uc744 \uad6c\ubd84\ud558\uae30 \uc704\ud574 \",\"\ub97c, \uc11c\ub85c \ub2e4\ub978 \ube44\ub514\uc624\uc758 \ud1a0\ud070\uc744 \uad6c\ubd84\ud558\uae30 \uc704\ud574 \"\\n\"\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc2a4\ud2b8\ub9ac\ubc0d \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\uc758 \uacbd\uc6b0 \ube44\ub514\uc624\uc640 \ud14d\uc2a4\ud2b8\uac00 \uc11e\uc5ec\uc11c \uad6c\uc131\ub429\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ud615\ud0dc\uc758 \uc2dc\uac01\uc801 \ub370\uc774\ud130 (\uc774\ubbf8\uc9c0, \ube44\ub514\uc624, \uc2a4\ud2b8\ub9ac\ubc0d \ube44\ub514\uc624)\ub97c \ucc98\ub9ac\ud558\ub294 \ubaa8\ub378\uc758 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc911\uc810\uc744 \ub450\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4\ub294 \uc5ec\ub7ec \uc774\ubbf8\uc9c0\uc758 \ud1a0\ud070\ub4e4\uc744 \"\\n\"\uc73c\ub85c \uad6c\ubd84\ud558\uc5ec \ub098\ud0c0\ub0b4\uace0, \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\ub294 \uac01 \ud504\ub808\uc784\uc758 \ud0c0\uc784\uc2a4\ud0ec\ud504\ub97c \"Time: xxs\"\ub85c \ud45c\uc2dc\ud558\uba70 \ud504\ub808\uc784\ub4e4 \uac04\uc5d0\ub294 \",\"\ub85c \uad6c\ubd84\ud558\uace0, \ub2e4\ub978 \ube44\ub514\uc624\uc758 \ud1a0\ud070\ub4e4\uc740 \ub2e4\uc2dc \"\\n\"\uc73c\ub85c \uad6c\ubd84\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uc2a4\ud2b8\ub9ac\ubc0d \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\ub294 \ube44\ub514\uc624\uc640 \ud14d\uc2a4\ud2b8 \ud1a0\ud070\uc774 \ubc88\uac08\uc544 \ub098\ud0c0\ub0a9\ub2c8\ub2e4.", "section": "3.1 \ub370\uc774\ud130 \ud615\uc2dd"}, {"figure_path": "https://arxiv.org/html/2501.13106/x6.png", "caption": "Figure 6: Case study of chart images understanding.", "description": "\uadf8\ub9bc 6\uc740 VideoLLaMA3 \ubaa8\ub378\uc774 \ucc28\ud2b8 \uc774\ubbf8\uc9c0\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840 \uc5f0\uad6c\uc785\ub2c8\ub2e4.  \ub450 \uac00\uc9c0 \ucc28\ud2b8 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc9c8\ubb38\uacfc VideoLLaMA3\uc758 \uc751\ub2f5\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \uc0ac\ub840\ub294 \uc8fc\uc2dd \ucc28\ud2b8\uc5d0 \ub300\ud55c \ubd84\uc11d\uacfc \ud22c\uc790 \uc81c\uc548\uc744 \ubcf4\uc5ec\uc8fc\uace0, \ub450 \ubc88\uc9f8 \uc0ac\ub840\ub294 \uc5ec\ub7ec MLLM \ubaa8\ub378\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 VideoLLaMA3\uac00 \ucc28\ud2b8 \uc774\ubbf8\uc9c0 \ub0b4\uc758 \ub370\uc774\ud130\uc640 \ud328\ud134\uc744 \uc815\ud655\ud558\uac8c \ud30c\uc545\ud558\uace0 \ubd84\uc11d\ud558\uc5ec, \uc720\uc758\ubbf8\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud558\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.13106/x7.png", "caption": "Figure 7: Case study of OCR and document images.", "description": "\uadf8\ub9bc 7\uc740 VideoLLaMA3 \ubaa8\ub378\uc774 OCR \ubc0f \ubb38\uc11c \uc774\ubbf8\uc9c0\ub97c \ucc98\ub9ac\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840 \uc5f0\uad6c\uc785\ub2c8\ub2e4.  \uccab \ubc88\uc9f8 \uc608\uc2dc\ub294 \ub514\uc790\uc778 \ud3ec\uc2a4\ud130\uc5d0 \uc788\ub294 \ud14d\uc2a4\ud2b8\ub97c \ubd84\uc11d\ud558\uace0, \ud3ec\uc2a4\ud130\uc758 \uac1c\uc120\uc810\uc744 \uc81c\uc548\ud558\ub294 VideoLLaMA3\uc758 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 \uc608\uc2dc\uc5d0\uc11c\ub294 VideoLLaMA3\uac00 \ubb38\uc11c \uc774\ubbf8\uc9c0\uc5d0\uc11c \ud14d\uc2a4\ud2b8\ub97c \uc131\uacf5\uc801\uc73c\ub85c \uc778\uc2dd\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 VideoLLaMA3\uac00 \uc774\ubbf8\uc9c0 \ub0b4\uc758 \ubc00\uc9d1\ub41c \uc815\ubcf4\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc774 \ub6f0\uc5b4\ub0a8\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 VideoLLaMA3\uc758 \ub2e4\uc591\ud55c \uc774\ubbf8\uc9c0 \uc774\ud574 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc608\uc2dc\ub4e4\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.13106/x8.png", "caption": "Figure 8: Case study of multi-image understanding.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub2e4\uc911 \uc774\ubbf8\uc9c0 \uc774\ud574\uc5d0 \ub300\ud55c \uc0ac\ub840 \uc5f0\uad6c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac1c\uc758 \ub2e4\ub978 \uc608\uc2dc\uac00 \uc788\ub294\ub370, \uac01 \uc608\uc2dc\ub294 \uc11c\ub85c \ub2e4\ub978 \uc720\ud615\uc758 \ub2e4\uc911 \uc774\ubbf8\uc9c0 \uc774\ud574 \uc791\uc5c5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \uc608\uc2dc\ub294 \ub450 \uc885\ub958\uc758 \uc0c8\ub97c \uad6c\ubcc4\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\uace0, \ub450 \ubc88\uc9f8 \uc608\uc2dc\ub294 \uae34 \ubb38\uc11c\uc5d0\uc11c \ub2f5\uc744 \ucc3e\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uc138 \ubc88\uc9f8 \uc608\uc2dc\ub294 \ub9cc\ud654\uc5d0\uc11c \uc904\uac70\ub9ac\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 VideoLLaMA3 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc774\ubbf8\uc9c0 \uc774\ud574 \uc791\uc5c5\uc5d0\uc11c \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.13106/x9.png", "caption": "Figure 9: Case study of images with general knowledge.", "description": "\uc774 \uadf8\ub9bc\uc740 VideoLLaMA3 \ubaa8\ub378\uc774 \uc77c\ubc18\uc801\uc778 \uc9c0\uc2dd\uc744 \ubc14\ud0d5\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \uc774\ud574\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840 \uc5f0\uad6c \uc138 \uac00\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \uc608\uc2dc\ub294 \ub18d\uad6c \uacbd\uae30 \uc911 \uc790\uc720\ud22c \uc0c1\ud669\uc744 \uc124\uba85\ud558\uace0, \ub450 \ubc88\uc9f8 \uc608\uc2dc\ub294 \ubaa8\ub098\ub9ac\uc790\uc758 \uc5ed\uc0ac\uc801 \uc601\ud5a5\uacfc \uc758\ubbf8\ub97c \ub17c\ud558\uba70, \uc138 \ubc88\uc9f8 \uc608\uc2dc\ub294 \uc6b0\uc8fc\uc120 \uc548\uc5d0 \uac15\uc544\uc9c0 \uc6b0\uc8fc\ube44\ud589\uc0ac\uac00 \ud0d1\uc2b9\ud558\uc5ec \uc6b0\uc8fc\uc640 \uc9c0\uad6c\ub97c \uc5ec\ud589\ud558\ub294 \uc601\uc0c1\uc744 \uc790\uc138\ud558\uac8c \ubb18\uc0ac\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 VideoLLAMA3 \ubaa8\ub378\uc758 \ub6f0\uc5b4\ub09c \uc2dc\uac01\uc801 \uc774\ud574 \ub2a5\ub825\uacfc \uad11\ubc94\uc704\ud55c \uc9c0\uc2dd \uae30\ubc18\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.13106/x10.png", "caption": "Figure 10: Case study of video understanding.", "description": "\uadf8\ub9bc 10\uc740 \ube44\ub514\uc624 \uc774\ud574\uc5d0 \ub300\ud55c \uc0ac\ub840 \uc5f0\uad6c\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01\uac01\uc758 \uc0ac\ub840\ub294 \ube44\ub514\uc624\uc5d0 \ub098\ud0c0\ub09c \uac1d\uccb4\uc758 \uc885\ub958\uc640 \uc704\uce58, \ud0a4\ubcf4\ub4dc\uc5d0\uc11c \uc0ac\ub77c\uc9c0\ub294 \ub9c8\uc9c0\ub9c9 \ud0a4, \ube44\ub514\uc624\uc758 \ud2b9\uc774\ud55c \uc810, \ube44\ub514\uc624\uc758 \uc138\ubd80 \ub0b4\uc6a9, \uadf8\ub9ac\uace0 \uacbd\uae30\uc758 \uc2b9\uc790\ub97c \uc9c8\ubb38\ud558\uace0 VideoLLaMA 3 \ubaa8\ub378\uc774 \uc774\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc744 \uc81c\uc2dc\ud558\ub294 \ud615\ud0dc\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 VideoLLaMA 3 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \uc774\ud574\ud558\uace0 \ucc98\ub9ac\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.13106/x11.png", "caption": "Figure 11: Case study of long video understanding, temporal grounding, and video-image joint understanding.", "description": "\uadf8\ub9bc 11\uc740 VideoLLaMA3 \ubaa8\ub378\uc758 \uc7a5\uae30 \ube44\ub514\uc624 \uc774\ud574, \uc2dc\uac04\uc801 \uae30\ubc18, \uadf8\ub9ac\uace0 \ube44\ub514\uc624-\uc774\ubbf8\uc9c0 \uacb0\ud569 \uc774\ud574 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840 \uc5f0\uad6c\uc785\ub2c8\ub2e4.  \uc67c\ucabd \uc704 \uadf8\ub9bc\uc740 \uc7a5\uc2dc\uac04\uc5d0 \uac78\uccd0 \ub2e4\uc591\ud55c \ub7ec\uc2dc\uc544 \ud48d\uacbd\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ube44\ub514\uc624\uc758 \uc5ec\ub7ec \uc7a5\uba74\uc744 \ucea1\uccd0\ud55c \uc2a4\ud2f8 \uc774\ubbf8\uc9c0\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc67c\ucabd \uc544\ub798 \uadf8\ub9bc\uc740 \ucf5c\ub77c\ub97c \ucef5\uc5d0 \ub530\ub974\ub294 \ub3d9\uc791\uc744 \ub2f4\uc740 \ube44\ub514\uc624\uc758 \ud504\ub808\uc784\ub4e4\uc744 \uc5f0\uc18d\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uace0, \ud2b9\uc815 \uc2dc\uac04\ub300(\uc2dc\uc791 \ubc0f \uc885\ub8cc \uc2dc\uac04)\ub97c \ud2b9\uc815\ud558\ub294 \uc2dc\uac04\uc801 \uae30\ubc18 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.  \uc624\ub978\ucabd \uadf8\ub9bc\uc740 \uace0\uc591\uc774\uc640 \ubcd1\uc544\ub9ac\uac00 \uc11c\ub85c \uaef4\uc548\uace0 \uc788\ub294 \ube44\ub514\uc624\uc640 \ubc24\uac70\ub9ac\ub97c \uac77\ub294 \uc5ec\uc131\uc758 \uc0ac\uc9c4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370, \ube44\ub514\uc624\uc640 \uc774\ubbf8\uc9c0\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\ub294 \ube44\ub514\uc624-\uc774\ubbf8\uc9c0 \uacb0\ud569 \uc774\ud574 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc804\uccb4\uc801\uc73c\ub85c, \uadf8\ub9bc\uc740 VideoLLaMA3\uac00 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc744 \uc218\ud589\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \uc0ac\ub840 \uc5f0\uad6c"}]