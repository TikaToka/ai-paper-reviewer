---
title: "Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge"
summary: "êµ°ì¤‘ ë¹„êµ ì¶”ë¡ ì„ í™œìš©, LLM ê¸°ë°˜ ìë™ í‰ê°€ì˜ ì‹ ë¢°ì„±ê³¼ í¬ê´„ì„± í–¥ìƒ!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ City University of Hong Kong",]
showSummary: true
date: 2025-02-18
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.12501 {{< /keyword >}}
{{< keyword icon="writer" >}} Qiyuan Zhang et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-19 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.12501" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.12501" target="_self" >}}
â†— Hugging Face
{{< /button >}}




### TL;DR


{{< lead >}}

LLM ê¸°ë°˜ ìë™ í‰ê°€ëŠ” ë¹„ìš© íš¨ìœ¨ì ì´ì§€ë§Œ, **CoT ì¶”ë¡ ì˜ í•œê³„ë¡œ ì¸í•´ ì‹ ë¢°ì„±ì´ ë–¨ì–´ì§€ëŠ” ë¬¸ì œ**ê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ë‹¤ìˆ˜ê²° íˆ¬í‘œë‚˜ ê¸°ì¤€ í™•ì¥ì— ì˜ì¡´í•˜ì—¬ ì´ ë¬¸ì œë¥¼ ì œëŒ€ë¡œ í•´ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.  ì´ ë…¼ë¬¸ì€ **LLMì´ ìƒì„±í•œ ì‘ë‹µê³¼ êµ°ì¤‘ ë°˜ì‘ì„ ë¹„êµí•˜ì—¬ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ Crowd-based Comparative Evaluation (CCE) ë°©ë²•ë¡ **ì„ ì œì•ˆí•©ë‹ˆë‹¤.



CCEëŠ” **êµ°ì¤‘ ë°˜ì‘ì„ í†µí•´ LLMì˜ í‰ê°€ë¥¼ ë³´ì™„**, **ë”ìš± í¬ê´„ì ì´ê³  ì„¸ë¶€ì ì¸ CoT ì¶”ë¡ ì„ ìœ ë„**í•©ë‹ˆë‹¤.  ì‹¤í—˜ ê²°ê³¼, CCEëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê·  6.7%ì˜ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìœ¼ë©°, **ë”ìš± ì§ˆ ë†’ì€ CoTë¥¼ ìƒì„±í•˜ê³  SFT íš¨ìœ¨ì„ ë†’ì´ëŠ” ë“± ìš°ìˆ˜í•œ ì„±ëŠ¥**ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.  ë³¸ ì—°êµ¬ëŠ” **LLM ìë™ í‰ê°€ì˜ ì‹ ë¢°ì„± ë° íš¨ìœ¨ì„± ê°œì„ ì— í¬ê²Œ ê¸°ì—¬**í•˜ë©°, í–¥í›„ LLM ì—°êµ¬ ë°œì „ì— ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} êµ°ì¤‘ ë°˜ì‘ ë¹„êµë¥¼ í†µí•´ LLMì˜ ìë™ í‰ê°€ ì‹ ë¢°ë„ í–¥ìƒ (í‰ê·  ì •í™•ë„ 6.7% ì¦ê°€) {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ë”ìš± í’ë¶€í•˜ê³  ì§ˆ ë†’ì€ CoT (Chain-of-Thought) ì¶”ë¡  ìƒì„± ë° íŒë³„ ëª¨ë¸ íš¨ìœ¨ í–¥ìƒ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Crowd rejection samplingì„ í†µí•œ SFT (Supervised Fine-Tuning) íš¨ìœ¨ ì¦ëŒ€ {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **LLM ê¸°ë°˜ ìë™ í‰ê°€ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” í˜ì‹ ì ì¸ ë°©ë²•ë¡ **ì„ ì œì‹œí•˜ì—¬, **LLMì˜ í‰ê°€ ë° ê°œì„ ì— ëŒ€í•œ ì—°êµ¬**ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•©ë‹ˆë‹¤.  **ê¸°ì¡´ì˜ í•œê³„ì ì„ ê·¹ë³µí•˜ê³  ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œ**í•¨ìœ¼ë¡œì¨, LLM ë¶„ì•¼ì˜ ë°œì „ì— í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  íŠ¹íˆ, **ë”ìš± íš¨ìœ¨ì ì´ê³  ì •í™•í•œ LLM ê°œë°œ ë° í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œ**í•œë‹¤ëŠ” ì ì—ì„œ ì—°êµ¬ìë“¤ì—ê²Œ í° ì˜ë¯¸ê°€ ìˆìŠµë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.12501/x1.png)

> ğŸ”¼ ë³¸ ê·¸ë¦¼ì€ ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. í›„ë³´ ì‘ë‹µ A/Bì™€ í•¨ê»˜ êµ°ì¤‘ ì‘ë‹µì„ í‰ê°€í•¨ìœ¼ë¡œì¨, ìƒì„±ëœ êµ°ì¤‘ íŒë‹¨ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ A/B ì‘ë‹µ í‰ê°€ë¥¼ í’ë¶€í•˜ê²Œ í•˜ê³ , ë³´ë‹¤ í¬ê´„ì ì¸ CoT íŒë‹¨ì„ ë„ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  êµ°ì¤‘ ì‘ë‹µì€ í›„ë³´ ì‘ë‹µê³¼ ë¹„êµí•˜ì—¬ í‰ê°€ë˜ê³ , ì´ë¥¼ í†µí•´ í›„ë³´ ì‘ë‹µ ë‚´ì˜ ë” ê¹Šê³  í¬ê´„ì ì¸ ì„¸ë¶€ ì •ë³´ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ LLM-as-a-Judgeê°€ ë”ìš± ìƒì„¸í•œ CoT íŒë‹¨ì„ ì œê³µí•˜ë„ë¡ íš¨ê³¼ì ìœ¼ë¡œ ìœ ë„í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: An overview of our method. By evaluating the candidate responses A/B alongside the crowd responses, the resulting crowd judgment can be used as context to enrich the evaluation of A/B responses, leading to a more comprehensive CoT judgment.
> </details>





{{< table-caption >}}
| Model | Reward | HelpSteer2 | MTBench | Judge | EvalBias | Avg. |
|---|---|---|---|---|---|---|
| **GPT-4o** |  |  |  |  |  |  |
| _Vanilla_ | 85.2 | 66.1 | 82.1 | 66.3 | 68.5 | 73.6 |
| _LongPrompt_ | 86.9 | 67.3 | 81.8 | 63.5 | 70.5 | 74.0 |
| _EvalPlan_ | 88.7 | 65.5 | 81.4 | 62.9 | 74.4 | 74.6 |
| _16-Criteria_ | 87.3 | 69.1 | 82.8 | 66.6 | 73.7 | 75.9 |
| _Maj@16_ | 87.9 | 68.9 | 82.4 | 68.6 | 75.5 | 76.7 |
| _Agg@16_ | 88.1 | 68.7 | 82.6 | 67.2 | 77.9 | 76.9 |
| CCE-_random@16_ | 91.2 | 69.5 | 83.1 | 68.9 | 80.1 | 78.6 |
| **CCE**_@16_ | **91.8** | **70.6** | **83.6** | **70.4** | **85.0** | **80.3** |
| **Qwen 2.5 7B-Instruct** |  |  |  |  |  |  |
| _Vanilla_ | 78.2 | 60.7 | 76.1 | 58.3 | 57.4 | 66.1 |
| **CCE**_@16_ | **80.4** | **64.2** | **76.7** | **64.0** | **79.4** | **72.9** |
| **Qwen 2.5 32B-Instruct** |  |  |  |  |  |  |
| _Vanilla_ | 87.4 | **72.3** | 79.0 | 68.9 | 71.1 | 75.7 |
| **CCE**_@16_ | **90.8** | 72.1 | **82.1** | **70.6** | **80.5** | **79.2** |
| **Qwen 2.5 72B-Instruct** |  |  |  |  |  |  |
| _Vanilla_ | 85.2 | **69.5** | 79.5 | 68.3 | 68.5 | 74.0 |
| **CCE**_@16_ | **93.7** | 68.5 | **88.9** | **75.7** | **85.9** | **82.7** |
| **Llama 3.3 70B-Instruct** |  |  |  |  |  |  |
| _Vanilla_ | 86.4 | 70.4 | 81.1 | 67.1 | 70.6 | 75.1 |
| **CCE**_@16_ | **91.7** | **71.3** | **83.5** | **69.7** | **79.2** | **79.1** |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ìŒë°© ë¹„êµ ë²¤ì¹˜ë§ˆí¬ì—ì„œ LLM-as-a-Judgeì˜ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ LLMê³¼ ë²¤ì¹˜ë§ˆí¬ì— ê±¸ì³ CCE(Crowd-based Comparative Evaluation)ê°€ LLM-as-a-Judgeì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, maj@16ê³¼ ê°™ì€ ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ë§ ì¶”ë¡  ì „ëµì— ë¹„í•´ ìƒë‹¹íˆ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ê°€ì¥ ë†’ì€ ê°’ì€ êµµê²Œ í‘œì‹œë˜ì–´ ìˆìœ¼ë©°, CCE-randomì€ 'ë¹„íŒì  ì„ íƒ ë° ê²°ê³¼ ì œê±° ì²˜ë¦¬'ë¥¼ 'ë¬´ì‘ìœ„ ì„ íƒ'ìœ¼ë¡œ ëŒ€ì²´í•œ ê²½ìš°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ë‹¤ì„¯ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬(REWARDBENCH, HELPSTEER2, MTBENCH HUMAN, JUDGEBENCH, EVALBIAS)ì—ì„œì˜ í‰ê·  ì •í™•ë„ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Accuracy of LLM-as-a-Judge on pair-wise comparison benchmarks. CCE can consistently enhance the LLM-as-a-Judgeâ€™s performance across 5 benchmarks, especially considerably outperforming other scaling inference strategies, like maj@16. The highest values are bolded. Here, CCE-random refers to replacing the â€œCriticizing Selection+++Outcome-Removal Processingâ€ with â€œRandom Selectionâ€.
> </details>





### In-depth insights


#### CrowdEval: A New Paradigm
CrowdEvalì´ë¼ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ìë™ í‰ê°€ ë°©ì‹ì„ í˜ì‹ ì ìœ¼ë¡œ ê°œì„ **í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ì ‘ê·¼ë²•ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ LLM í‰ê°€ ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë”ìš± í¬ê´„ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  íŠ¹íˆ, **ë‹¤ìˆ˜ì˜ ì‘ë‹µì„ ë¹„êµ ë¶„ì„**í•˜ì—¬ LLMì˜ íŒë‹¨ ê·¼ê±°ë¥¼ ë”ìš± ì‹¬ì¸µì ìœ¼ë¡œ íŒŒì•…í•˜ê³ , **í‰ê°€ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ë„ë¥¼ ë†’ì´ëŠ” ë° ì¤‘ì **ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´, LLMì˜ ì„±ëŠ¥ì„ ë”ìš± ì •í™•í•˜ê²Œ ì¸¡ì •í•˜ê³ , í–¥í›„ ë°œì „ ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë° í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼**ë¥¼ í†µí•´ CrowdEvalì˜ ìš°ìˆ˜ì„±ì„ ê²€ì¦í•˜ê³ , ê·¸ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒì…ë‹ˆë‹¤.  **ì‹¤ì œ ì‘ìš© ê°€ëŠ¥ì„±**ì„ ë†’ì´ê¸° ìœ„í•´, CrowdEvalì˜ í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  ë˜í•œ, **ë‹¤ì–‘í•œ ìœ í˜•ì˜ LLM ë° í‰ê°€ ê¸°ì¤€ì— ëŒ€í•œ ì ìš© ê°€ëŠ¥ì„±**ì„ ê²€í† í•˜ê³ , **ì ì¬ì ì¸ í¸í–¥ì„± ë° í•œê³„ì **ì„ ë¶„ì„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

#### CCE Mechanism
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” CCE(Crowd-based Comparative Evaluation) ë©”ì»¤ë‹ˆì¦˜ì€ **LLM ê¸°ë°˜ ìë™ í‰ê°€ì˜ ì‹ ë¢°ì„±ê³¼ í¬ê´„ì„±ì„ ë†’ì´ê¸° ìœ„í•œ í•µì‹¬**ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ìˆœ ë‹¤ìˆ˜ê²° íˆ¬í‘œë‚˜ ê¸°ì¤€ í™•ì¥ ë°©ì‹ê³¼ ë‹¬ë¦¬, CCEëŠ” **í›„ë³´ ì‘ë‹µê³¼ ì¶”ê°€ì ì¸ êµ°ì¤‘ ì‘ë‹µì„ ë¹„êµ**í•˜ì—¬ í›„ë³´ ì‘ë‹µì˜ ì„¸ë¶€ì ì¸ ë‚´ìš©ì„ ë”ìš± ì‹¬ì¸µì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLMì´ **ë”ìš± í’ë¶€í•˜ê³  ìì„¸í•œ CoT(Chain-of-Thought) ì¶”ë¡ **ì„ ìƒì„±í•˜ì—¬ í‰ê°€ì˜ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **êµ°ì¤‘ ì‘ë‹µì˜ ë‹¤ì–‘ì„±**ì€ í›„ë³´ ì‘ë‹µì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ ë“œëŸ¬ë‚´ëŠ” ë‹¤ì–‘í•œ í‰ê°€ ê¸°ì¤€ì„ ì œê³µí•˜ë©°, **LLMì˜ íŒë‹¨ì„ ë³´ë‹¤ í¬ê´„ì ì´ê³  ì‹¬ì¸µì **ìœ¼ë¡œ ìœ ë„í•©ë‹ˆë‹¤.  ì´ëŠ” ë‹¨ìˆœíˆ ì •ë‹µ/ì˜¤ë‹µ ì—¬ë¶€ë¥¼ ë„˜ì–´, ì‘ë‹µì˜ ì§ˆì  ì¸¡ë©´ê¹Œì§€ ê³ ë ¤í•œ **ì„¸ë°€í•œ í‰ê°€**ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  **CCEì˜ í•µì‹¬ì€ êµ°ì¤‘ ì‘ë‹µì„ í™œìš©í•œ ë¹„êµ ë¶„ì„**ì„ í†µí•´ LLMì˜ í‰ê°€ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ìˆìŠµë‹ˆë‹¤. ì´ ë©”ì»¤ë‹ˆì¦˜ì€ LLM ê¸°ë°˜ í‰ê°€ ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë”ìš± ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

#### SFT Rejection Sampling
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ 'SFT Rejection Sampling'ì€ ê¸°ì¡´ì˜ ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •(SFT) ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. **ê¸°ì¡´ SFTëŠ” ì €í’ˆì§ˆ ì‘ë‹µì„ ê±¸ëŸ¬ë‚´ëŠ” ë° ì–´ë ¤ì›€**ì„ ê²ªëŠ”ë° ë°˜í•´, ë³¸ ë°©ë²•ì€ **í¬ë¼ìš°ë“œ ê¸°ë°˜ ë¹„êµ í‰ê°€(CCE)ë¥¼ í†µí•´ ê³ í’ˆì§ˆ ì‘ë‹µì„ íš¨ê³¼ì ìœ¼ë¡œ ì„ ë³„**í•©ë‹ˆë‹¤. CCEëŠ” í›„ë³´ ì‘ë‹µì„ ì—¬ëŸ¬ ê°œì˜ í¬ë¼ìš°ë“œ ì‘ë‹µê³¼ ë¹„êµí•˜ì—¬ ì„¸ë¶€ì ì¸ ì°¨ì´ë¥¼ ë“œëŸ¬ë‚´ê³ , ì´ë¥¼ í†µí•´ LLM-as-a-Judgeê°€ ë”ìš± í¬ê´„ì ì´ê³  ì •êµí•œ í‰ê°€ë¥¼ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.  **í¬ë¼ìš°ë“œ ì‘ë‹µì˜ ë‹¤ì–‘ì„±**ì€ í›„ë³´ ì‘ë‹µì— ëŒ€í•œ ë‹¤ì°¨ì›ì  í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬, ë‹¨ìˆœí•œ ë‹¤ìˆ˜ê²° íˆ¬í‘œë‚˜ ê¸°ì¤€ í™•ì¥ ë°©ì‹ë³´ë‹¤ ë”ìš± ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ê²°ê³¼ì ìœ¼ë¡œ, ë³¸ ì—°êµ¬ì˜ SFT Rejection Samplingì€ **ë”ìš± íš¨ìœ¨ì ì´ê³  ì‹ ë¢°ë„ ë†’ì€ SFT ëª¨ë¸ í•™ìŠµ**ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, íŠ¹íˆ **í¸í–¥ì„±ì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” íš¨ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤.  **í¬ë¼ìš°ë“œ ê¸°ë°˜ì˜ ìƒ˜í”Œë§ ì „ëµ**ì€ ë‹¨ìˆœíˆ í’ˆì§ˆì´ ë†’ì€ ì‘ë‹µë§Œì„ ì„ ë³„í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ëª¨ë¸ í•™ìŠµì— ì í•©í•œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‘ë‹µì„ í¬í•¨í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜**ì„ í†µí•´ ê·¸ íš¨ê³¼ê°€ ê²€ì¦ë˜ì—ˆë‹¤ëŠ” ì ì—ì„œ, ë³¸ ë°©ë²•ì€ SFTì˜ ì‹¤ìš©ì„±ì„ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

#### CoT Enhancement
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ 'CoT Enhancement' ì „ëµì€ **LLM ê¸°ë°˜ í‰ê°€ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•œ í•µì‹¬**ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ ë‹¤ìˆ˜ê²° íˆ¬í‘œë‚˜ ê¸°ì¤€ í™•ì¥ ë°©ì‹ì—ì„œ ë²—ì–´ë‚˜, **í¬ë¼ìš°ë“œ ì‘ë‹µì„ í™œìš©í•˜ì—¬ í›„ë³´ ì‘ë‹µ ê°„ì˜ ë¹„êµ ë¶„ì„ì„ ì‹¬í™”**ì‹œí‚¤ëŠ” ì ‘ê·¼ ë°©ì‹ì„ ì·¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLMì´ **ë”ìš± í¬ê´„ì ì´ê³  ì„¸ë¶€ì ì¸ ë§¥ë½ì„ ê³ ë ¤í•œ CoT ì¶”ë¡ **ì„ ìˆ˜í–‰í•˜ë„ë¡ ìœ ë„í•˜ë©°, í‰ê°€ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. íŠ¹íˆ, **ë‹¤ì–‘í•œ í¬ë¼ìš°ë“œ ì‘ë‹µì„ ë¹„êµ ë¶„ì„í•˜ëŠ” ê³¼ì •ì€ ì¸ê°„ì˜ í‰ê°€ í–‰íƒœë¥¼ ëª¨ë°©**í•˜ì—¬ LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤. ë˜í•œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **í¬ë¼ìš°ë“œ ê¸°ë°˜ ê±°ì ˆ ìƒ˜í”Œë§**ì„ í†µí•´ SFTì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ëŠ” ë°©ì•ˆë„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.  **í¬ë¼ìš°ë“œ ì‘ë‹µì˜ ì§ˆì  ê°œì„ **ì€  LLM ê¸°ë°˜ í‰ê°€ì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•˜ë©°, **ì¶”ë¡  ê·œëª¨ í™•ì¥ì— ë”°ë¥¸ ì •í™•ë„ í–¥ìƒ** ë˜í•œ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.  ì¦‰, ë³¸ ë…¼ë¬¸ì˜ CoT í–¥ìƒ ì „ëµì€ ë‹¨ìˆœí•œ ê¸°ìˆ ì  ê°œì„ ì„ ë„˜ì–´, LLM ê¸°ë°˜ í‰ê°€ì˜ ê·¼ë³¸ì ì¸ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ ì´ì •í‘œê°€ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Limitations and Future
ë³¸ ë…¼ë¬¸ì€ êµ°ì¤‘ ê¸°ë°˜ ë¹„êµ í‰ê°€(CCE) ë°©ë²•ì„ ì œì•ˆí•˜ì—¬ LLM ê¸°ë°˜ íŒë‹¨ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê³ , ê·¸ í•œê³„ì ì„ ê·¹ë³µí•˜ê³ ì ë…¸ë ¥í•˜ì˜€ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, **ìì²´ ë°˜ë³µ(self-iteration) ê³¼ì •ì˜ ë¶€ì¬**ëŠ” í–¥í›„ ê°œì„ ì˜ ì—¬ì§€ë¡œ ë‚¨ìŠµë‹ˆë‹¤. ë°˜ë³µì ì¸ ì •ì œë¥¼ í†µí•´ í‰ê°€ì˜ ì •í™•ì„±ì„ ë”ìš± ë†’ì¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, **LLM ê¸°ë°˜ êµ°ì¤‘ ë°˜ì‘ ì„ íƒ ì „ëµì˜ ê°œì„ ** ë˜í•œ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ LLMì„ í™œìš©í•œ êµ°ì¤‘ ë°˜ì‘ ìƒì„±ì€ íš¨ìœ¨ì ì´ì§€ë§Œ, ì–´ë–¤ LLMì˜ ë°˜ì‘ì´ íŒë‹¨ì— ë” í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.  **ì œí•œëœ ê·œëª¨ì˜ ë°ì´í„°ì…‹** ë˜í•œ í•œê³„ì ìœ¼ë¡œ ì§€ì ë  ìˆ˜ ìˆìœ¼ë©°, ë”ìš± ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹¤í—˜ì„ í†µí•´ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤.  ë§ˆì§€ë§‰ìœ¼ë¡œ, **ë‹¤ì–‘í•œ ê³¼ì œ ë° ì§€í‘œ**ì— ëŒ€í•œ ì ìš©ì„±ì„ íƒìƒ‰í•˜ì—¬ CCEì˜ ë²”ìš©ì„±ì„ í™•ëŒ€í•˜ê³ , ë‹¤ì–‘í•œ LLM ì•„í‚¤í…ì²˜ì™€ì˜ í˜¸í™˜ì„±ì„ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ì ë“¤ì„ ê·¹ë³µí•˜ê¸° ìœ„í•œ ì§€ì†ì ì¸ ì—°êµ¬ë¥¼ í†µí•´ CCEëŠ” LLM ê¸°ë°˜ ìë™ í‰ê°€ì˜ ì‹ ë¢°ë„ë¥¼ ë”ìš± í–¥ìƒì‹œí‚¤ê³ , ë”ìš± íš¨ìœ¨ì ì´ê³  í¬ê´„ì ì¸ í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ê¸°ì—¬í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.12501/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” ì œì•ˆëœ êµ°ì¤‘ ê¸°ë°˜ ë¹„êµ í‰ê°€ ë°©ì‹ì˜ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¸ìŠ¤í„´ìŠ¤ (x, yA, yB)ì— ëŒ€í•´, LLMì„ ì‚¬ìš©í•˜ì—¬ xë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì¤‘ ì‘ë‹µ {yi|iâˆˆ{C,D,E,â€¦}}ì„ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ ì‘ë‹µë“¤ì„ yAì™€ yBì™€ ë¹„êµí•˜ì—¬ ì´ˆê¸° êµ°ì¤‘ íŒë‹¨ ğ’¥ë¥¼ ìƒì„±í•˜ê³ , ì„ íƒ ë° ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì³ ğ’¥Ì‚ë¡œ ì •ì œí•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ ğ’¥Ì‚ë¥¼ ë¬¸ë§¥ ì •ë³´ë¡œ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ (x, yA, yB)ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Pipeline of our proposed crowd-based comparative evaluation. For a given instance (x,yA,yB)ğ‘¥superscriptğ‘¦ğ´superscriptğ‘¦ğµ(x,y^{A},y^{B})( italic_x , italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT ), we first use the LLM to generate crowd responses {yi|iâˆˆ{C,D,E,â€¦}}conditional-setsuperscriptğ‘¦ğ‘–ğ‘–ğ¶ğ·ğ¸â€¦\left\{y^{i}|i\in\{C,D,E,...\}\right\}{ italic_y start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | italic_i âˆˆ { italic_C , italic_D , italic_E , â€¦ } } based on xğ‘¥xitalic_x. These responses are then compared with yAsuperscriptğ‘¦ğ´y^{A}italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT and yBsuperscriptğ‘¦ğµy^{B}italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT to produce initial crowd judgments ğ’¥ğ’¥\mathcal{J}caligraphic_J, which are subsequently refined into ğ’¥^^ğ’¥\hat{\mathcal{J}}over^ start_ARG caligraphic_J end_ARG after selection and processing. Finally, ğ’¥^^ğ’¥\hat{\mathcal{J}}over^ start_ARG caligraphic_J end_ARG are used as contextual input to evaluate the instance (x,yA,yB)ğ‘¥superscriptğ‘¦ğ´superscriptğ‘¦ğµ(x,y^{A},y^{B})( italic_x , italic_y start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_B end_POSTSUPERSCRIPT ).
> </details>



![](https://arxiv.org/html/2502.12501/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ì¶”ê°€ë˜ëŠ” ì°¸ì—¬ì ë°˜ì‘(crowd judgments)ì˜ ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ í‰ê°€ ì •í™•ë„ì™€ CoT(Chain-of-Thought) ê¸¸ì´ê°€ ì¼ë°˜ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì¦‰, ë” ë§ì€ ì°¸ì—¬ì ì˜ê²¬ì„ í™œìš©í• ìˆ˜ë¡ í‰ê°€ì˜ ì •í™•ì„±ì´ ë†’ì•„ì§€ê³ , ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ì¶”ë¡  ê³¼ì •(CoT) ë˜í•œ ë”ìš± ìì„¸í•´ì§ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ê·¸ë˜í”„ì…ë‹ˆë‹¤. ì´ëŠ” ì œì•ˆëœ ë°©ë²•(Crowd-based Comparative Evaluation)ì˜ íš¨ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ì£¼ìš” ì‹¤í—˜ ê²°ê³¼ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Evaluation performance under scaling crowd judgments in the context. As the number of crowd judgments grows, both accuracy and CoT length generally increase.
> </details>



![](https://arxiv.org/html/2502.12501/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” CCE(Crowd-based Comparative Evaluation)ì™€ ê¸°ì¡´ ë°©ë²•ì˜ CoT(Chain-of-Thought) ë¹„êµ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. CCEì˜ CoTëŠ” ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê· ì ìœ¼ë¡œ ë” ë§ì€ ì£¼ìš” ì§€ì (key points)ê³¼ ë” ë†’ì€ ì ìš© ë²”ìœ„(coverage rate)ë¥¼ ë³´ì…ë‹ˆë‹¤. ì£¼ìš” ì§€ì ì€ CoTê°€ ë‹¤ë£¨ëŠ” í•µì‹¬ ë‚´ìš© ë° ì„¸ë¶€ ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ë©°, ì ìš© ë²”ìœ„ëŠ” CoTê°€ í›„ë³´ ì‘ë‹µì˜ ì„¸ë¶€ ì‚¬í•­ì„ ì–¼ë§ˆë‚˜ í¬ê´„ì ìœ¼ë¡œ ë‹¤ë£¨ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ëŠ” CCEê°€ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë”ìš± í¬ê´„ì ì´ê³  ì‹¬ì¸µì ì¸ í‰ê°€ë¥¼ ì œê³µí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: CoT Comparison. CCEâ€™s CoT consistently yields a higher average number of key points and a higher coverage rate across all benchmarks.
> </details>



![](https://arxiv.org/html/2502.12501/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ë°©ë²•ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLMì´ ë‘ ê°œì˜ AIê°€ ìƒì„±í•œ ì‘ë‹µì„ ë¹„êµí•˜ê³  í‰ê°€í•˜ëŠ” ì—­í• ì„ í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ê³µì •í•˜ê³  í¬ê´„ì ì¸ í‰ê°€ë¥¼ í•˜ë„ë¡ ì§€ì‹œí•˜ë©°, ë‹¤ì–‘í•œ í‰ê°€ ê¸°ì¤€ (ë„ì›€ì´ ë˜ëŠ” ì •ë„, ê´€ë ¨ì„±, ì •í™•ì„±, ì™„ì „ì„±, ëª…í™•ì„±, ê¹Šì´, ì¶”ë¡  í’ˆì§ˆ, ì°½ì˜ì„±, ì„¸ë¶€ ìˆ˜ì¤€ ë“±)ì„ ê³ ë ¤í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤. ë˜í•œ, í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ë¥¸ ì‘ë‹µì˜ íŠ¹ì§•ì„ ë°°ê²½ ì§€ì‹ìœ¼ë¡œ í™œìš©í•˜ì—¬ í‰ê°€ì˜ ì¼ê´€ì„±ê³¼ í¬ê´„ì„±ì„ ë†’ì´ê³ , ì‘ë‹µì˜ ê¸¸ì´, ìŠ¤íƒ€ì¼, ìˆœì„œ, ì–´ì‹œìŠ¤í„´íŠ¸ ì´ë¦„ ë“±ì— ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ, ì–´ì‹œìŠ¤í„´íŠ¸ Aê°€ ë” ë‚˜ì€ ì‘ë‹µì„ ì œê³µí•œ ê²½ìš° '[[A]]', ì–´ì‹œìŠ¤í„´íŠ¸ Bê°€ ë” ë‚˜ì€ ì‘ë‹µì„ ì œê³µí•œ ê²½ìš° '[[B]]' í˜•ì‹ìœ¼ë¡œ ìµœì¢… íŒë‹¨ì„ ë‚´ë¦¬ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Prompt of Our Method.
> </details>



![](https://arxiv.org/html/2502.12501/x6.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ ê¸°ì¡´ì˜ LLM-as-a-Judge ë°©ì‹ì—ì„œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê°„ê²°í•œ ê¸°ì¡´ ì„¤ëª…ê³¼ ë‹¬ë¦¬, ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLMì—ê²Œ ë‘ ê°œì˜ AI ì‘ë‹µì„ ë¹„êµ í‰ê°€í•˜ê³ ,  ìœ ìš©ì„±, ê´€ë ¨ì„±, ì •í™•ì„±, ê¹Šì´, ì°½ì˜ì„±, ì„¸ë¶€ ìˆ˜ì¤€ ë“± ì—¬ëŸ¬ ê¸°ì¤€ì„ ê³ ë ¤í•˜ì—¬ ì–´ë–¤ ì‘ë‹µì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë” ì˜ ë‹µí•˜ëŠ”ì§€ íŒë‹¨í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.  ì‘ë‹µì˜ ê¸¸ì´, ìŠ¤íƒ€ì¼, ìˆœì„œ, ì–´ì‹œìŠ¤í„´íŠ¸ ì´ë¦„ ë“±ì´ í‰ê°€ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šë„ë¡ ê³µì •í•˜ê³  ê°ê´€ì ì¸ í‰ê°€ë¥¼ ê°•ì¡°í•˜ë©°, ì™¸ë¶€ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ëª…ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœì¢… í‰ê²°ì€ '[[A]]' (Aê°€ ë” ìš°ìˆ˜í•œ ê²½ìš°) ë˜ëŠ” '[[B]]' (Bê°€ ë” ìš°ìˆ˜í•œ ê²½ìš°) í˜•ì‹ìœ¼ë¡œ ì œì¶œí•˜ë„ë¡ ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Prompt of Vanilla LLM-as-a-Judge.
> </details>



![](https://arxiv.org/html/2502.12501/x7.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ ë…¼ë¬¸ì˜ 3.2ì ˆ Crowd Response and Judgment Generationì—ì„œ ì œì‹œëœ 16ê°œì˜ í‰ê°€ ê¸°ì¤€ì„ ì‚¬ìš©í•˜ëŠ” LLM-as-a-Judge í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê¸°ì¡´ì˜ ë‹¨ìˆœí•œ í‰ê°€ ê¸°ì¤€ì„ ë„˜ì–´,  ì •í™•ì„±, ì¼ê´€ì„±, ëª…í™•ì„± ë“± 16ê°€ì§€ ì„¸ë¶€ì ì¸ ì¸¡ë©´ì„ ê³ ë ¤í•˜ì—¬ ë”ìš± í¬ê´„ì ì´ê³  ì •êµí•œ í‰ê°€ë¥¼ ìœ ë„í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.  ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLMì´ í›„ë³´ ì‘ë‹µë“¤ì„ ë³´ë‹¤ ì‹¬ì¸µì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•˜ê³ ,  ë³´ë‹¤ ì •í™•í•˜ê³  ì„¸ë°€í•œ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Prompt of 16-Criteria LLM-as-a-Judge.
> </details>



![](https://arxiv.org/html/2502.12501/x8.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ ë…¼ë¬¸ì˜ '3.5 SFTì—ì„œì˜ êµ°ì¤‘ ê±°ë¶€ ìƒ˜í”Œë§' ì„¹ì…˜ì— ì†í•˜ë©°, LongPrompt ë°©ì‹ì˜ LLM-as-a-Judge í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê¸°ì¡´ì˜ LLM-as-a-Judge í”„ë¡¬í”„íŠ¸ì™€ ë‹¬ë¦¬,  ì‘ë‹µì˜ ì§ˆì„ í‰ê°€í•˜ëŠ” ê³¼ì •ì—ì„œ LLMì´ ê°€ëŠ¥í•œ í•œ ìì„¸í•˜ê³  ê¸´ ë§¥ë½ ì¶”ë¡ (Chain-of-Thought, CoT)ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.  ì¦‰,  LLMì´ ë‹¨ìˆœíˆ ì¢‹ì€/ë‚˜ìœ ì‘ë‹µì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ê·¸ ì´ìœ ë¥¼ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ê¸´ CoTë¥¼ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í‰ê°€ì˜ ì‹ ë¢°ì„±ê³¼ íˆ¬ëª…ì„±ì„ ë†’ì´ê³ ì í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Prompt of LongPrompt LLM-as-a-Judge.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | # of Training Samples | RewardBench | HelpSteer2 | MTBench Human | JudgeBench | EvalBias | Avg. | 
|---|---|---|---|---|---|---|---| 
| **JudgeLM-7B** (Zhu et al., 2023a) | 100,000 | **46.4** | **60.1** | 64.1 | 32.6 | **42.4** | **49.1** | 
| **PandaLM-7B** (Wang et al., 2024c) | 300,000 | 45.7 | 57.6 | **75.0** | 36.0 | 27.0 | 48.3 | 
| **Auto-J-13B** (Li et al., 2024b) | 4,396 | **47.5** | **65.1** | **75.2** | **50.9** | 16.5 | **51.0** | 
| **Prometheus-7B** (Kim et al., 2024a) | 100,000 | 34.6 | 30.8 | 52.8 | 9.3 | 11.7 | 27.8 | 
| **Prometheus-2-7B** (Kim et al., 2024b) | 300,000 | 43.7 | 37.6 | 55.0 | **39.4** | **39.8** | 43.1 | 
| **Llama-3.1-8B-Tuned** |  |  |  |  |  |  |  | 
| *Synthetic Judgment from Vanilla* | 10,000 | 66.8 | 56.0 | 71.6 | **60.1** | 34.2 | 57.7 | 
| *Synthetic Judgment from Vanilla* | 30,000 | **72.5** | **58.6** | **73.9** | 50.4 | **46.2** | 60.3 | 
| *Synthetic Judgment from CCE* | 10,000 | 69.7 | **58.6** | 72.7 | **66.4** | 38.7 | **61.2** | 
| *Synthetic Judgment from CCE* | 30,000 | **70.0** | **60.1** | **74.3** | 50.3 | **50.7** | **61.1** | 
| **Qwen 2.5-7B-Tuned** |  |  |  |  |  |  |  | 
| *Synthetic Judgment from Vanilla* | 10,000 | 68.1 | 55.6 | 70.7 | **50.2** | 38.4 | 56.6 | 
| *Synthetic Judgment from Vanilla* | 30,000 | 71.4 | 56.2 | 75.1 | 48.2 | 54.7 | 61.1 | 
| *Synthetic Judgment from CCE* | 10,000 | 68.8 | 56.7 | 71.3 | 49.8 | 40.2 | 57.4 | 
| *Synthetic Judgment from CCE* | 30,000 | **73.3** | **59.5** | **74.9** | 50.1 | **57.1** | **63.0** | 
| *Mix Synthetic Judgment from CCE&Vanilla* | 60,000 | **74.1** | **60.7** | **76.6** | **61.6** | **60.6** | **66.7** |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ì†Œê·œëª¨ LLM-as-a-Judge ëª¨ë¸ì„ ìŒë°©í–¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë™ì¼í•œ ì„ í˜¸ë„ ë°ì´í„° ìŒì„ ì‚¬ìš©í–ˆì„ ë•Œ, CCEë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ íŒë‹¨ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ ë”ìš± ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤. ê°€ì¥ ë†’ì€ ê°’ì€ êµµê²Œ í‘œì‹œí•˜ê³ , ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ê°’ì€ ë°‘ì¤„ì„ ì³¤ìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Accuracy of Trained small LLM-as-a-Judge on pair-wise comparison benchmarks. Under the same preference pairs data, the model trained with judgments synthesized using CCE achieves more reliable evaluation results. The highest values are bolded, and the second highest is underlined.
> </details>

{{< table-caption >}}
| Rejection Sampling Method | MTBench | AlpacaEval-2 |
|---|---|---|
| **Llama 3.1 8B Base** |  |  |
| **Instructions from LIMA # 1K** |  |  |
| *Random Sampling* | 4.33 | 2.89/3.29 |
| *Vanilla Rejection Sampling* | 4.28 | **2.91/3.29** |
| *Crowd Rejection Sampling* | **4.53** | **3.02/3.31** |
| **Instructions from Tulu 3 # 10K** |  |  |
| *Random Sampling* | 7.51 | 12.81/12.45 |
| *Vanilla Rejection Sampling* | **7.56** | **19.92/17.17** |
| *Crowd Rejection Sampling* | **7.63** | **22.23/19.74** |
| **Qwen 2.5 7B Base** |  |  |
| **Instructions from LIMA # 1K** |  |  |
| *Random Sampling* | **8.06** | **14.52/9.40** |
| *Vanilla Rejection Sampling* | 7.91 | 14.40/9.44 |
| *Crowd Rejection Sampling* | **8.63** | **14.86/9.59** |
| **Instructions from Tulu 3 # 10K** |  |  |
| *Random Sampling* | 8.36 | 21.39/13.68 |
| *Vanilla Rejection Sampling* | **8.46** | **22.71/16.44** |
| *Crowd Rejection Sampling* | **8.41** | **23.78/17.56** |{{< /table-caption >}}
> ğŸ”¼ ë³¸ í‘œëŠ” ì§€ì‹œì‚¬í•­ ë”°ë¥´ê¸° ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ SFT(Supervised Fine-Tuning) ê±°ë¶€ ìƒ˜í”Œë§ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. CCE(Crowd-based Comparative Evaluation) ë°©ì‹ìœ¼ë¡œ ìƒ˜í”Œë§ëœ ì‘ë‹µì„ ì‚¬ìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ í–¥ìƒëœ ìƒì„± ì„±ëŠ¥ì„ ë³´ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  êµ¬ì²´ì ìœ¼ë¡œëŠ”, LIMAì™€ TULU3-SFT ë‘ ë°ì´í„°ì…‹ì—ì„œ ì„¸ ê°€ì§€ ìƒ˜í”Œë§ ë°©ë²•(ë¬´ì‘ìœ„ ìƒ˜í”Œë§, ì¼ë°˜ì ì¸ ê±°ë¶€ ìƒ˜í”Œë§, CCE ê¸°ë°˜ ê±°ë¶€ ìƒ˜í”Œë§)ì„ ë¹„êµí•˜ì—¬, CCE ê¸°ë°˜ ê±°ë¶€ ìƒ˜í”Œë§ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì´ëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ì˜ ìƒì„± ëŠ¥ë ¥ì„ í‰ê°€í•˜ì—¬ í™•ì¸ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: SFT Rejection Sampling Performance on the Instruction-Following Benchmark. The model fine-tuned with responses sampled using CCE demonstrates improved generative performance.
> </details>

{{< table-caption >}}
| Strategy | # of Selection Samples | RewardBench | HelpSteer2 | MTBench Human | JudgeBench | EvalBias | Avg. | 
|---|---|---|---|---|---|---|---| 
| _Random-Selection_ | 8 | 91.0 | 69.9 | 82.6 | 68.7 | 78.4 | 78.1 | 
| _Praising-Selection_ | 8 | 86.6 | 64.2 | 81.5 | 67.1 | 77.7 | 75.4 | 
| _Criticizing-Selection_ | 8 | 91.2 | 69.2 | 83.0 | 68.9 | 79.1 | 78.3 | 
| _Balanced-Selection_ | 8 | 90.7 | 68.6 | 82.8 | 67.4 | 78.7 | 77.6 | 
| _Outcome-Removal Random-Selection_ | 8 | 91.5 | 69.9 | 83.0 | 69.4 | 79.5 | 78.7 | 
| _Outcome-Removal Criticizing-Selection (Sota)_ | 8 | 91.5 | 70.1 | 83.2 | 69.5 | 79.9 | 78.8 | 
| _Random-Selection_ | 16 | 91.2 | 69.5 | 83.1 | 68.9 | 80.1 | 78.6 | 
| _Praising-Selection_ | 16 | 87.0 | 68.4 | 82.0 | 67.1 | 77.9 | 76.5 | 
| _Criticizing-Selection_ | 16 | 90.8 | 69.7 | 83.0 | 69.6 | 82.9 | 79.2 | 
| _Balanced-Selection_ | 16 | 90.6 | 69.3 | 82.9 | 68.0 | 79.6 | 78.1 | 
| _Outcome-Removal Random-Selection_ | 16 | 91.7 | 69.7 | 83.2 | 70.0 | 81.5 | 79.2 | 
| _Outcome-Removal Criticizing-Selection(Sota)_ | 16 | 91.8 | 70.6 | 83.6 | 70.4 | 85.0 | 80.3 | {{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” ìŒë°© ë¹„êµ ë²¤ì¹˜ë§ˆí¬ì—ì„œ LLM-as-a-Judgeì˜ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í‘œëŠ” ì œì•ˆëœ ë°©ë²•ì¸ CCE(Crowd-based Comparative Evaluation)ê°€ LLM-as-a-Judgeì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° íš¨ê³¼ì ì„ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ, CCEëŠ” ê¸°ì¡´ì˜ ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë°©ì‹(maj@16)ì´ë‚˜ ê¸°ì¤€ í™•ì¥ ë°©ì‹(16-Criteria)ë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë™ì¼í•œ ì„ í˜¸ë„ ìŒ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ, CCEë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ íŒë‹¨ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ ë”ìš± ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  í…ŒìŠ¤íŠ¸ ì‹œê°„ ì¶”ë¡  ë‹¨ê³„ì—ì„œ CCEê°€ LLM-as-a-Judgeì˜ ì„±ëŠ¥ì„ ì¼ê´€ë˜ê²Œ í–¥ìƒì‹œí‚¤ê³ , íŠ¹íˆ maj@16 ë° 16-Criteriaë³´ë‹¤ í›¨ì”¬ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.  ê°™ì€ ì„ í˜¸ë„ ë°ì´í„° ìŒì„ ì‚¬ìš©í–ˆì„ ë•Œ, CCEë¡œ í•©ì„±ëœ íŒë‹¨ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ ë”ìš± ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ê²°ê³¼ë¥¼ ë„ì¶œí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Accuracy of LLM-as-a-Judge on pair-wise comparison benchmarks. CCE can consistently enhance the LLM-as-a-Judgeâ€™s performance during the test-time inference phase, especially considerably outperforming maj@16 and 16-Criteria; under the same preference pairs data, the model trained with judgments synthesized using CCE achieves more reliable evaluation results.
> </details>

{{< table-caption >}}
| Instruction | Response A | Response B | Vanilla LLM-as-a-Judge | CCE |
|---|---|---|---|---|
| Classify this tweet from the categories of positive, negative, or neutral. Tweet: Iâ€™m so thankful for all the wonderful people in my life | <p style="color:#FF0000;"><b>Response A</b></p>  The sentiment of this social media comment is positive. The use of the word "grateful" implies appreciation and thankfulness, while "amazing experiences" suggest that these experiences have been very fulfilling or enjoyable. | <p style="color:#32CD32;"><b>Response B</b></p> Positive | Assistant Aâ€™s response is more detailed than Assistant Bâ€™s. <p style="color:#000000;background-color:#FBE5D6;">It highlights specific words and phrases in the tweet, such as â€œthankfulâ€ and â€œwonderful people,â€ to justify the positive sentiment classification. This explanation adds depth and clarity to the response, making it more helpful and informative.</p> Assistant Bâ€™s response is less informative and helpful.  - Final Verdict: <p style="color:#FF0000;">[[A]]</p> | <p style="font-weight:bold;font-variant:small-caps;">CCE</p> <p style="font-style:italic;font-weight:bold;">AC Judgment</p> <p style="text-decoration:underline;text-decoration-style:wavy;">However, Assistant A makes a mistake by referencing words not present in the tweet, such as "grateful" and "amazing experiences,"</p> Assistant C also classifies the tweet as positive and provides a detailed explanation. Assistant A <p style="color:#000000;background-color:#E2F0D9;">, but it inaccurately references words not present in the tweet, such as "grateful" and "amazing experiences." This detracts from the accuracy of the response and could potentially confuse the user.</p> Assistant B <p style="color:#000000;background-color:#E2F0D9;">is concise and correctly classifies the tweet as positive. However, it lacks any explanation or reasoning, which limits its helpfulness and depth.</p> In comparing the two, <p style="color:#000000;background-color:#E2F0D9;">Given the importance of accuracy and explanation in sentiment analysis,</p> - Final Verdict: <p style="color:#00FF00;">[[B]]</p> |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ì„œë¡œ ë‹¤ë¥¸ í‰ê°€ ë°©ë²•ìœ¼ë¡œ í‰ê°€ëœ ì§ ë¹„êµ ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'Preference'ëŠ” ì •ë‹µì„, 'Preference'ëŠ” ì˜¤ë‹µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì˜¤ë Œì§€ìƒ‰ì€ í‰ê°€ì—ì„œ ë…¸ì´ì¦ˆê°€ ë§ì€ ìš”ì†Œë¥¼, ì—°ë‘ìƒ‰ì€ ìœ ìš©í•œ ìš”ì†Œë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ í‘œëŠ” ì¸ê°„ í‰ê°€ìì™€ ìœ ì‚¬í•˜ê²Œ LLM ê¸°ë°˜ íŒë‹¨ì´ ì¡ìŒì´ ë§ê³  ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ëŒ€í‘œì ì¸ ì‚¬ë¡€ë¥¼ ì œì‹œí•˜ë©°, ì œì•ˆëœ Crowd Comparative Evaluation (CCE) ë°©ë²•ì´ ì´ëŸ¬í•œ ë¬¸ì œì ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.  CCEëŠ” ë‹¤ì–‘í•œ ê´€ì ì„ ì œê³µí•˜ëŠ” ì¶”ê°€ì ì¸ ì‘ë‹µì„ í™œìš©í•˜ì—¬, ë” í¬ê´„ì ì´ê³  ì •í™•í•œ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: A pairwise comparison case evaluated by different methods. Preference refers to right result and Preference refers to wrong result. We emphasize the noisy evaluation elements in  orange, while highlighting the useful elements of the evaluation in  limongreen.
> </details>

{{< table-caption >}}
| Benchmarks | Size | Focus |
|---|---|---|
| *RewardBench* | 2,985 | It covers multiple scenarios, including Chat, Chat-Hard, Safety, and Reasoning. |
| *HelpSteeer2* | 519 | It provides multiple fine-grained dimensions for evaluation, like Helpfulness, Coherence, Correctness, Complexity, Verbosity. |
| *MTBench Human* | 2,665 | It provides multi-turn conversation for evaluation, and we filter the samples whose outcome is â€œTieâ€. |
| *JudgeBench* | 350 | It focuses on challenging response pairs spanning knowledge, reasoning, math, and coding |
| *EvalBias* | 1,000 | It tests the robustness of judges on various scenarios containing evaluation biases. |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë‹¤ì„¯ ê°€ì§€ ì„ í˜¸ë„ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ì…ë‹ˆë‹¤. ê° ë²¤ì¹˜ë§ˆí¬ëŠ” íŠ¹ì •í•œ í‰ê°€ ëª©í‘œë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤(ëŒ€í™”, ì•ˆì „, ì¶”ë¡  ë“±)ì™€ ì„¸ë¶€ í‰ê°€ ê¸°ì¤€(ìœ ìš©ì„±, ì¼ê´€ì„±, ì •í™•ì„±, ë³µì¡ì„±, ìì„¸í•¨ ë“±)ì„ í¬í•¨í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ ë‹¤ì„¯ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM-as-a-Judgeì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: The brief description of Preference Benchmarks for testing.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}