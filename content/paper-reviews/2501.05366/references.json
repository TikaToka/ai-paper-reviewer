{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-06", "reason": "This paper is foundational to the field of large language models and their few-shot learning capabilities, which is central to the current paper's discussion of Large Reasoning Models (LRMs)."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting technique, which is directly relevant to the current paper's focus on enhancing LRMs' reasoning abilities."}, {"fullname_first_author": "Patrick Lewis", "paper_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks", "publication_date": "2020-12-01", "reason": "This paper is highly influential in the area of retrieval-augmented generation (RAG), a key technique used and improved upon in the current paper."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-01-01", "reason": "This paper introduces a significant advancement in transfer learning for text-based tasks, which serves as a foundation for many of the large language models discussed in the current paper."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "DeepSeek-R1-lite-preview is now live: unleashing supercharged reasoning power!", "publication_date": "2024-11-01", "reason": "This paper introduces a specific large reasoning model that is directly compared to in the experiments, making it a critical component to the current research."}]}