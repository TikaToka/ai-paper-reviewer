[{"figure_path": "https://arxiv.org/html/2501.01895/x1.png", "caption": "Figure 1: The overview of our proposed EnerVerse model, consisting of three key components. First, Initial Reconstruction uses observation images from cameras mounted on the robot to build an initial 3D point cloud, with anchor views set to adapt to the environment and meet task-specific requirements. Second, Free Anchor View Renders generates rendered images from these anchor perspectives to provide comprehensive scene representations. Finally, Chunk-wise Autoregressive Generation employs a multi-view video diffusion to produce image sequences in chunks based on task instructions. When integrated with a policy head, this module can generate robotic actions to execute the given task.", "description": "\uadf8\ub9bc 1\uc740 \uc81c\uc548\ub41c EnerVerse \ubaa8\ub378\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. \uccab\uc9f8, \ucd08\uae30 \uc7ac\uad6c\uc131(Initial Reconstruction)\uc740 \ub85c\ubd07\uc5d0 \uc7a5\ucc29\ub41c \uce74\uba54\ub77c\uc758 \uad00\uce21 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc575\ucee4 \ubdf0(anchor view)\ub97c \uc124\uc815\ud558\uace0 \ud658\uacbd\uc5d0 \uc801\uc751\ud558\uace0 \uc791\uc5c5\ubcc4 \uc694\uad6c\uc0ac\ud56d\uc744 \ucda9\uc871\ud558\ub294 \ucd08\uae30 3D \uc810 \uad6c\ub984\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub458\uc9f8, \uc790\uc720 \uc575\ucee4 \ubdf0 \ub80c\ub354\ub9c1(Free Anchor View Renders)\uc740 \uc774\ub7ec\ud55c \uc575\ucee4 \ubdf0\uc5d0\uc11c \ub80c\ub354\ub9c1\ub41c \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uc5ec \ud3ec\uad04\uc801\uc778 \uc7a5\uba74 \ud45c\ud604\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc14b\uc9f8, \uccad\ud06c \ub2e8\uc704 \uc790\uae30 \ud68c\uadc0 \uc0dd\uc131(Chunk-wise Autoregressive Generation)\uc740 \uc791\uc5c5 \uc9c0\uce68\uc5d0 \ub530\ub77c \uccad\ud06c \ub2e8\uc704\ub85c \uc774\ubbf8\uc9c0 \uc2dc\ud000\uc2a4\ub97c \uc0dd\uc131\ud558\ub294 \ub2e4\uc911 \ubdf0 \ube44\ub514\uc624 \ud655\uc0b0(multi-view video diffusion)\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc815\ucc45 \ud5e4\ub4dc(policy head)\uc640 \ud1b5\ud569\ub418\uba74 \uc774 \ubaa8\ub4c8\uc740 \uc8fc\uc5b4\uc9c4 \uc791\uc5c5\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud55c \ub85c\ubd07 \ub3d9\uc791\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2501.01895/x2.png", "caption": "Figure 2: The architecture of our proposed next-chunk diffusion model. As shown in Figure (a), a sequence of observational frames, captured by camera i\ud835\udc56iitalic_i and accompanied by the corresponding ray direction map, is utilized as observation priors. Leveraging these camera observations, an initial 3D reconstruction is obtained through depth wrapping and rendering\u00a0Lassner and Zollhofer (2021), then several Free Anchor Views are established accordingly. In addition to camera observational frames, a render frame from the FAV is also employed as context priors for the subsequent chunk diffusion models. To synthesize the anchor view i+1\ud835\udc561i+1italic_i + 1 sequence, the respective ray direction map is concatenated with the video latent. Notably, the observational image from the camera is optional and used only when the camera is static. If all sensors are in motion, the rendered image alone can serve as the context prior. In the context of the chunk-wise autoregressive training process, as depicted in Figure (b), clean frames selected at random from consecutive sequences are concatenated with noisy frames to forecast denoised latents. During the inference phase, once denoised frames are produced, they are utilized as the new set of clean frames for the following inference step. This iterative process persists until the predefined End-Of-Sequence (EOS) frame is encountered. Notably, we visualize only one view in Figure (b) to simplify the demonstration of the autoregressive generation process, but multi-view generation is fully supported by the model.", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c \ucc28\ub840\ub300\ub85c \ud655\uc0b0 \ubaa8\ub378\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\uc5d0\uc11c\ub294 \uce74\uba54\ub77c i\uc5d0\uc11c \ucea1\ucc98\ud55c \uad00\uce21 \ud504\ub808\uc784 \uc2dc\ud000\uc2a4\uc640 \ud574\ub2f9 \uad11\uc120 \ubc29\ud5a5 \ub9f5\uc744 \uad00\uce21 \uc0ac\uc804 \uc815\ubcf4\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uce74\uba54\ub77c \uad00\uce21\uc744 \ud65c\uc6a9\ud558\uc5ec \uae4a\uc774 \ub798\ud551 \ubc0f \ub80c\ub354\ub9c1\uc744 \ud1b5\ud574 \ucd08\uae30 3D \uc7ac\uad6c\uc131\uc744 \uc5bb\uc740 \ub2e4\uc74c, \uc5ec\ub7ec \uac1c\uc758 \uc790\uc720 \uc575\ucee4 \ubdf0(FAV)\ub97c \uc124\uc815\ud569\ub2c8\ub2e4. \uce74\uba54\ub77c \uad00\uce21 \ud504\ub808\uc784 \uc678\uc5d0\ub3c4 FAV\uc758 \ub80c\ub354\ub9c1 \ud504\ub808\uc784\uc744 \ud6c4\uc18d \uccad\ud06c \ud655\uc0b0 \ubaa8\ub378\uc758 \ucee8\ud14d\uc2a4\ud2b8 \uc0ac\uc804 \uc815\ubcf4\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc575\ucee4 \ubdf0 i+1 \uc2dc\ud000\uc2a4\ub97c \ud569\uc131\ud558\uae30 \uc704\ud574 \ud574\ub2f9 \uad11\uc120 \ubc29\ud5a5 \ub9f5\uc744 \ube44\ub514\uc624 \uc7a0\uc7ac \ubcc0\uc218\uc640 \uc5f0\uacb0\ud569\ub2c8\ub2e4. \uce74\uba54\ub77c\uac00 \uc815\uc9c0\ud574 \uc788\uc744 \ub54c\ub9cc \uce74\uba54\ub77c\uc758 \uad00\uce21 \uc774\ubbf8\uc9c0\ub97c \uc120\ud0dd\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\uace0, \ubaa8\ub4e0 \uc13c\uc11c\uac00 \uc6c0\uc9c1\uc774\ub294 \uacbd\uc6b0 \ub80c\ub354\ub9c1\ub41c \uc774\ubbf8\uc9c0\ub9cc \ucee8\ud14d\uc2a4\ud2b8 \uc0ac\uc804 \uc815\ubcf4\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (b)\ub294 \uccad\ud06c \ub2e8\uc704 \uc790\uae30 \ud68c\uadc0 \ud6c8\ub828 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5f0\uc18d \uc2dc\ud000\uc2a4\uc5d0\uc11c \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ud55c \uae68\ub057\ud55c \ud504\ub808\uc784\uc744 \ub178\uc774\uc988 \ud504\ub808\uc784\uacfc \uc5f0\uacb0\ud558\uc5ec \uc7a1\uc74c \uc81c\uac70\ub41c \uc7a0\uc7ac \ubcc0\uc218\ub97c \uc608\uce21\ud569\ub2c8\ub2e4. \ucd94\ub860 \ub2e8\uacc4\uc5d0\uc11c \uc7a1\uc74c \uc81c\uac70\ub41c \ud504\ub808\uc784\uc774 \uc0dd\uc131\ub418\uba74 \ub2e4\uc74c \ucd94\ub860 \ub2e8\uacc4\ub97c \uc704\ud55c \uc0c8\ub85c\uc6b4 \uae68\ub057\ud55c \ud504\ub808\uc784\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc18\ubcf5\uc801\uc778 \uacfc\uc815\uc740 \ubbf8\ub9ac \uc815\uc758\ub41c EOS(End-Of-Sequence) \ud504\ub808\uc784\uc774 \ubc1c\uc0dd\ud560 \ub54c\uae4c\uc9c0 \uacc4\uc18d\ub429\ub2c8\ub2e4. \uc790\uae30 \ud68c\uadc0 \uc0dd\uc131 \uacfc\uc815\uc744 \uac04\uc18c\ud654\ud558\uae30 \uc704\ud574 (b)\uc5d0\uc11c\ub294 \ud558\ub098\uc758 \ubdf0\ub9cc \uc2dc\uac01\ud654\ud558\uc9c0\ub9cc, \ubaa8\ub378\uc740 \ub2e4\uc911 \ubdf0 \uc0dd\uc131\uc744 \uc644\ubcbd\ud558\uac8c \uc9c0\uc6d0\ud569\ub2c8\ub2e4.", "section": "3 Methods"}, {"figure_path": "https://arxiv.org/html/2501.01895/x3.png", "caption": "Figure 3: The pipeline for EnerVerse as a data engine. Observation images captured from multiple cameras, along with rendered images from anchor views, are processed by the multi-view video generator to produce denoised multi-view videos. These videos, paired with their corresponding camera poses, are utilized in 4D Gaussian Splatting (4D GS) for 4D scene reconstruction. The reconstructed content is rendered from anchor views to generate high-precision images, which are iteratively fed back into the pipeline to enhance motion consistency and reconstruction quality. This iterative loop combines geometric consistency with generative refinement, delivering high-fidelity outputs for tasks such as robotic manipulation.", "description": "\uadf8\ub9bc 3\uc740 EnerVerse\uc758 \ub370\uc774\ud130 \uc5d4\uc9c4\uc73c\ub85c\uc11c\uc758 \ud30c\uc774\ud504\ub77c\uc778\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\ub7ec \ub300\uc758 \uce74\uba54\ub77c\uc5d0\uc11c \ucea1\ucc98\ud55c \uad00\uce21 \uc774\ubbf8\uc9c0\uc640 \uc575\ucee4 \ubdf0\uc5d0\uc11c \ub80c\ub354\ub9c1\ub41c \uc774\ubbf8\uc9c0\uac00 \ub2e4\uc911 \ubdf0 \ube44\ub514\uc624 \uc0dd\uc131\uae30\ub97c \ud1b5\ud574 \ucc98\ub9ac\ub418\uc5b4 \uc7a1\uc74c\uc774 \uc81c\uac70\ub41c \ub2e4\uc911 \ubdf0 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ube44\ub514\uc624\ub294 \ud574\ub2f9\ud558\ub294 \uce74\uba54\ub77c \ud3ec\uc988\uc640 \ud568\uaed8 4D \uac00\uc6b0\uc2dc\uc548 \uc2a4\ud50c\ub798\ud305(4D GS)\uc5d0 \uc0ac\uc6a9\ub418\uc5b4 4D \uc7a5\uba74 \uc7ac\uad6c\uc131\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uc7ac\uad6c\uc131\ub41c \ucf58\ud150\uce20\ub294 \uc575\ucee4 \ubdf0\uc5d0\uc11c \ub80c\ub354\ub9c1\ub418\uc5b4 \uace0\uc815\ubc00 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uba70, \uc774 \uc774\ubbf8\uc9c0\ub294 \ubaa8\uc158 \uc77c\uad00\uc131\uacfc \uc7ac\uad6c\uc131 \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uae30 \uc704\ud574 \ubc18\ubcf5\uc801\uc73c\ub85c \ud30c\uc774\ud504\ub77c\uc778\uc5d0 \ub2e4\uc2dc \uc785\ub825\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc18\ubcf5 \ub8e8\ud504\ub294 \uae30\ud558\ud559\uc801 \uc77c\uad00\uc131\uacfc \uc0dd\uc131\uc801 \uac1c\uc120\uc744 \uacb0\ud569\ud558\uc5ec \ub85c\ubd07 \uc870\uc791\uacfc \uac19\uc740 \uc791\uc5c5\uc5d0 \ub300\ud574 \uace0\ud488\uc9c8 \ucd9c\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.2 4D Generation"}, {"figure_path": "https://arxiv.org/html/2501.01895/x4.png", "caption": "Figure 4: Visualization of FAVs generation on the LIBERO benchmark. Anchor View 1 represents the observation image captured by a mounted camera. Anchor View 2 and Anchor View 3 are generated by rendering from a point cloud reconstructed from Anchor View 1 using depth wrapping.", "description": "\uadf8\ub9bc 4\ub294 LIBERO \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc790\uc720 \uc575\ucee4 \ubdf0(FAV) \uc0dd\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc575\ucee4 \ubdf0 1\uc740 \uc7a5\ucc29\ub41c \uce74\uba54\ub77c\ub85c \ucea1\ucc98\ud55c \uad00\ucc30 \uc774\ubbf8\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc575\ucee4 \ubdf0 2\uc640 \uc575\ucee4 \ubdf0 3\uc740 \uae4a\uc774 \ub798\ud551\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc575\ucee4 \ubdf0 1\uc5d0\uc11c \uc7ac\uad6c\uc131\ub41c \uc810 \uad6c\ub984\uc73c\ub85c\ubd80\ud130 \ub80c\ub354\ub9c1\ud558\uc5ec \uc0dd\uc131\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub85c\ubd07\uc774 \ub2e4\uc591\ud55c \uac01\ub3c4\uc5d0\uc11c \uc7a5\uba74\uc744 \uad00\ucc30\ud560 \uc218 \uc788\ub3c4\ub85d \uc5ec\ub7ec \uad00\uc810\uc744 \uc81c\uacf5\ud558\ub294 FAV\uc758 \uac1c\ub150\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae4a\uc774 \ub798\ud551\uc744 \ud1b5\ud574 \ud558\ub098\uc758 \uce74\uba54\ub77c \uad00\ucc30\ub9cc\uc73c\ub85c\ub3c4 \ub2e4\uc591\ud55c \uc575\ucee4 \ubdf0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.3 Application"}, {"figure_path": "https://arxiv.org/html/2501.01895/x5.png", "caption": "Figure 5: Qualitative comparison for single view video generation between EnerVerse and DynamiCrafter(FN) on RT-1 dataset. Since EnerVerse predict EOS frame at 42th frame for this task, we visualize 8th, 16th, 24th and 41th frame sampled from both generated sequence. The sequences generated by DynamiCrafter(FN) did not maintain the logic of the long-range task, producing many hallucinations as the sequence grew. In contrast, the sequence generated by EnerVerse was logically coherent, continuously and completely generating the future space of the entire task, and accurately predicting the EOS (End of Sequence) frame.", "description": "\uadf8\ub9bc 5\ub294 RT-1 \ub370\uc774\ud130\uc14b\uc5d0\uc11c EnerVerse\uc640 DynamiCrafter(FN)\uc758 \ub2e8\uc77c \ubdf0 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \ub300\ud55c \uc815\uc131\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. EnerVerse\ub294 42\ubc88\uc9f8 \ud504\ub808\uc784\uc5d0\uc11c EOS(End of Sequence) \ud504\ub808\uc784\uc744 \uc608\uce21\ud558\ubbc0\ub85c, \uc0dd\uc131\ub41c \uc2dc\ud000\uc2a4\uc5d0\uc11c 8\ubc88\uc9f8, 16\ubc88\uc9f8, 24\ubc88\uc9f8, 41\ubc88\uc9f8 \ud504\ub808\uc784\uc744 \uc2dc\uac01\ud654\ud558\uc5ec \ube44\uad50\ud569\ub2c8\ub2e4. DynamiCrafter(FN)\uc5d0 \uc758\ud574 \uc0dd\uc131\ub41c \uc2dc\ud000\uc2a4\ub294 \uc7a5\uae30 \uc791\uc5c5\uc758 \ub17c\ub9ac\ub97c \uc720\uc9c0\ud558\uc9c0 \ubabb\ud558\uace0 \uc2dc\ud000\uc2a4\uac00 \uae38\uc5b4\uc9d0\uc5d0 \ub530\ub77c \ub9ce\uc740 \ud658\uac01\uc744 \uc0dd\uc131\ud558\ub294 \ubc18\uba74, EnerVerse\uc5d0 \uc758\ud574 \uc0dd\uc131\ub41c \uc2dc\ud000\uc2a4\ub294 \ub17c\ub9ac\uc801\uc73c\ub85c \uc77c\uad00\ub418\uace0 \uc9c0\uc18d\uc801\uc73c\ub85c \uc791\uc5c5\uc758 \uc804\uccb4 \ubbf8\ub798 \uacf5\uac04\uc744 \uc0dd\uc131\ud558\uba70 EOS \ud504\ub808\uc784\uc744 \uc815\ud655\ud558\uac8c \uc608\uce21\ud569\ub2c8\ub2e4.", "section": "4.2 \ube44\uad50 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.01895/x6.png", "caption": "Figure 6: Qualitative results for multi anchor view generation on LIBERO benchmark (left) and real-world manipulation data (right), collected from AgiBot World\u00a0AgiBot (2024). One view is overlapped with a fixed RGB sensor and other views are manully set. Visualized Frames are uniformly sampled from generated sequence. We emphasize the consistency of objects across views by highlighting them with a red rectangle.", "description": "\uadf8\ub9bc 6\uc740 \uc81c\uc2dc\ub41c EnerVerse \ubaa8\ub378\uc774 \uc5ec\ub7ec \uac01\ub3c4\uc5d0\uc11c \uc0dd\uc131\ud55c \ube44\ub514\uc624 \ud504\ub808\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc740 LIBERO \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uc2dc\ubbac\ub808\uc774\uc158 \uacb0\uacfc\uc774\uace0, \uc624\ub978\ucabd\uc740 AgiBot World AgiBot (2024) \ub370\uc774\ud130\uc14b\uc73c\ub85c\ubd80\ud130 \uc218\uc9d1\ub41c \uc2e4\uc81c \ub85c\ubd07 \uc870\uc791 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. \ud558\ub098\uc758 \ubdf0\ub294 \uace0\uc815\ub41c RGB \uc13c\uc11c\uc640 \uc911\ubcf5\ub418\uace0, \ub2e4\ub978 \ubdf0\ub4e4\uc740 \uc218\ub3d9\uc73c\ub85c \uc124\uc815\ub429\ub2c8\ub2e4. \uc2dc\uac01\ud654\ub41c \ud504\ub808\uc784\ub4e4\uc740 \uc0dd\uc131\ub41c \uc2dc\ud000\uc2a4\uc5d0\uc11c \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1\ub429\ub2c8\ub2e4. \ub2e4\uc591\ud55c \ubdf0\uc5d0\uc11c \uac1d\uccb4\uc758 \uc77c\uad00\uc131\uc744 \uac15\uc870\ud558\uae30 \uc704\ud574 \ube68\uac04\uc0c9 \uc0ac\uac01\ud615\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4.  \uc774\ub294 EnerVerse \ubaa8\ub378\uc758 \ub2e4\uc911 \uad00\uc810 \ube44\ub514\uc624 \uc0dd\uc131 \ub2a5\ub825\uacfc \uc2e4\uc81c \ub85c\ubd07 \uc870\uc791 \ud658\uacbd\uc5d0 \ub300\ud55c \uc801\uc751\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc815\uc131\uc801 \uacb0\uacfc\uc785\ub2c8\ub2e4.", "section": "4.3 \ucd94\uac00 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.01895/x7.png", "caption": "Figure 7: Ablation results for context memory mechanism in video generation. Providing history information to the generation model with consecutive context (first line) often leads to unexpected model collapse while the model with sparse memory (second line) shows robust performance and save mush computing resources.", "description": "\uadf8\ub9bc 7\uc740 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0\uc11c \ub9e5\ub77d \uba54\ubaa8\ub9ac \uba54\ucee4\ub2c8\uc998\uc758 \uc81c\uac70 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5f0\uc18d\uc801\uc778 \ub9e5\ub77d\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131 \ubaa8\ub378\uc5d0 \uacfc\uac70 \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uba74 (\uccab \ubc88\uc9f8 \uc904), \uc608\uc0c1\uce58 \ubabb\ud55c \ubaa8\ub378 \ubd95\uad34\uac00 \ubc1c\uc0dd\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc2b5\ub2c8\ub2e4. \ubc18\uba74\uc5d0,  \ud76c\uc18c \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc740 (\ub450 \ubc88\uc9f8 \uc904) \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\uba70 \ucef4\ud4e8\ud305 \uc790\uc6d0\uc744 \uc808\uc57d\ud569\ub2c8\ub2e4.  \uccab \ubc88\uc9f8 \uc904\uc740 \uc5f0\uc18d\ub41c \ud504\ub808\uc784\ub4e4\uc744 \ubaa8\ub450 \uc0ac\uc6a9\ud558\ub294 \ubc18\uba74, \ub450 \ubc88\uc9f8 \uc904\uc740 \uc77c\ubd80 \ud504\ub808\uc784\ub9cc \uc120\ud0dd\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec \uba54\ubaa8\ub9ac \ud6a8\uc728\uc744 \ub192\uc774\uace0, \uacfc\ub3c4\ud55c \uc815\ubcf4\ub85c \uc778\ud55c \ubd80\uc815\ud655\uc131\uc744 \uc904\uc774\ub294 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \ucd94\uac00 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2501.01895/x8.png", "caption": "Figure 8: Attention maps from different attention heads and layers of the model. The y-axis represents the predicted action space (the Query), spanning 8 steps, while the x-axis represents the Key-Value space. The first 4 columns in the KV space correspond to information from the Sparse Memory space, while the last 8 columns correspond to the predicted future space. These maps highlight how the model attends to sparse memory conditions (left) and future space conditions (right) when predicting actions. The bright yellow indicates a higher attention score while dark red indicates a lower one.", "description": "\uadf8\ub9bc 8\uc740 \ubaa8\ub378\uc758 \uc5ec\ub7ec \uc5b4\ud150\uc158 \ud5e4\ub4dc\uc640 \ub808\uc774\uc5b4\uc5d0\uc11c\uc758 \uc5b4\ud150\uc158 \ub9f5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Y\ucd95\uc740 8\ub2e8\uacc4\uc5d0 \uac78\uce5c \uc608\uce21\ub41c \uc561\uc158 \uacf5\uac04(\ucffc\ub9ac)\uc744 \ub098\ud0c0\ub0b4\uace0, X\ucd95\uc740 \ud0a4-\uac12 \uacf5\uac04\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. KV \uacf5\uac04\uc758 \ucc98\uc74c 4\uc5f4\uc740 \uc2a4\ud30c\uc2a4 \uba54\ubaa8\ub9ac \uacf5\uac04\uc758 \uc815\ubcf4\uc5d0 \ud574\ub2f9\ud558\uace0, \ub098\uba38\uc9c0 8\uc5f4\uc740 \uc608\uce21\ub41c \ubbf8\ub798 \uacf5\uac04\uc5d0 \ud574\ub2f9\ud569\ub2c8\ub2e4. \uc774 \ub9f5\ub4e4\uc740 \ubaa8\ub378\uc774 \uc561\uc158\uc744 \uc608\uce21\ud560 \ub54c \uc2a4\ud30c\uc2a4 \uba54\ubaa8\ub9ac \uc870\uac74(\uc67c\ucabd)\uacfc \ubbf8\ub798 \uacf5\uac04 \uc870\uac74(\uc624\ub978\ucabd)\uc5d0 \uc5b4\ub5bb\uac8c \uc8fc\uc758\ub97c \uae30\uc6b8\uc774\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc1d\uc740 \ub178\ub780\uc0c9\uc740 \ub354 \ub192\uc740 \uc5b4\ud150\uc158 \uc810\uc218\ub97c, \uc5b4\ub450\uc6b4 \ube68\uac04\uc0c9\uc740 \ub354 \ub0ae\uc740 \uc5b4\ud150\uc158 \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \uc5f4\uc740 \ud2b9\uc815 \uc2dc\uc810\uc758 \uc815\ubcf4\ub97c \ub098\ud0c0\ub0b4\uba70, \ubaa8\ub378\uc774 \uc2dc\uac04\uc774 \uc9c0\ub0a8\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \uc8fc\uc758\ub97c \uc9d1\uc911\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3 \ucd94\uac00 \uc5f0\uad6c"}]