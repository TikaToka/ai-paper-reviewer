{"references": [{"fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA: Open and efficient foundation language models", "publication_date": "2023-02-23", "reason": "This paper introduces LLaMA, a foundational large language model used extensively in the experiments, making it a crucial reference for understanding the context and performance comparisons."}, {"fullname_first_author": "Edward J. Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2022-00-00", "reason": "This paper introduces LoRA, the core parameter-efficient fine-tuning method upon which the proposed LORAM method is based, making it the most essential reference for understanding the baseline technique."}, {"fullname_first_author": "Tim Dettmers", "paper_title": "QLoRA: Efficient finetuning of quantized LLMs", "publication_date": "2023-00-00", "reason": "This paper presents QLoRA, a quantization technique integrated into LORAM for enhanced memory efficiency, thus representing an important component of the proposed approach."}, {"fullname_first_author": "Elias Frantar", "paper_title": "SparseGPT: Massive language models can be accurately pruned in one-shot", "publication_date": "2023-00-00", "reason": "This paper introduces SparseGPT, a pruning method used in the LORAM experiments to reduce model size and improve training efficiency, making it highly relevant to the proposed method."}, {"fullname_first_author": "Mingyang Zhang", "paper_title": "LoRAPrune: Structured pruning meets low-rank parameter-efficient fine-tuning", "publication_date": "2024-00-00", "reason": "This paper explores the combination of structured pruning and LoRA, providing related work highly relevant to LORAM, which also combines pruning and LoRA for efficient fine-tuning."}]}