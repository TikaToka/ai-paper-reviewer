[{"figure_path": "https://arxiv.org/html/2502.13533/x1.png", "caption": "Figure 1: Idea of LoRAM", "description": "\uadf8\ub9bc 1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 LoRAM\uc758 \ud575\uc2ec \uc544\uc774\ub514\uc5b4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 LoRA\ub294 \ud559\uc2b5\uacfc \ucd94\ub860 \ubaa8\ub450 \ub3d9\uc77c\ud55c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc9c0\ub9cc, LoRAM\uc740 \ud559\uc2b5 \uc2dc\uc5d0\ub294 \uac00\uc9c0\uce58\uae30\ub41c \uc791\uc740 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uace0 \ucd94\ub860 \uc2dc\uc5d0\ub294 \uc6d0\ub798 \ud070 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 LoRA \ud559\uc2b5 \uc2dc \ubc1c\uc0dd\ud558\ub294 \uba54\ubaa8\ub9ac \ubb38\uc81c\ub97c \uc644\ud654\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \uac00\uc9c0\uce58\uae30\ub41c \ubaa8\ub378\uc5d0\uc11c \ud559\uc2b5\ub41c \uac00\uc911\uce58(\ub178\ub780\uc0c9 \ube14\ub85d)\uac00 \uc6d0\ub798 \ubaa8\ub378\uc5d0 \ud1b5\ud569\ub418\ub294 \uacfc\uc815\uacfc \ucd94\ub860 \uc2dc \uac00\uc9c0\uce58\uae30\ub41c \uac00\uc911\uce58(\ud30c\ub780\uc0c9 \ube14\ub85d)\uac00 \ud65c\uc6a9\ub418\ub294 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2 Memory-efficient LoRA Training - LoRAM"}, {"figure_path": "https://arxiv.org/html/2502.13533/x2.png", "caption": "Figure 2: \nComparison of LoRAM and LoRA: Training (subfigures a and b) and Inference (c and d). Key stages include the offline process of the frozen full-rank matrix \ud835\udc160\u2217superscriptsubscript\ud835\udc160\\mathbf{W}_{0}^{*}bold_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT (subfigure e) and the online generation of the learnable low-rank matrix \ud835\udc16\u0394\u2217superscriptsubscript\ud835\udc16\u0394\\mathbf{W}_{\\Delta}^{*}bold_W start_POSTSUBSCRIPT roman_\u0394 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT (f) during LoRAM training (b) and inference (d).", "description": "\uadf8\ub9bc 2\ub294 LoRAM\uacfc LoRA\uc758 \ud559\uc2b5 \ubc0f \ucd94\ub860 \uacfc\uc815\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\uc640 (b)\ub294 \uac01\uac01 LoRA\uc640 LoRAM\uc758 \ud559\uc2b5 \uacfc\uc815\uc744, (c)\uc640 (d)\ub294 \ucd94\ub860 \uacfc\uc815\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc8fc\uc694 \ub2e8\uacc4\ub294 \uc624\ud504\ub77c\uc778\uc73c\ub85c \uc9c4\ud589\ub418\ub294 \uace0\uc815\ub41c \uc644\uc804 \uacc4\uae09 \ud589\ub82c W0*\uc758 \ucc98\ub9ac \uacfc\uc815 (e)\uacfc LoRAM \ud559\uc2b5 (b) \ubc0f \ucd94\ub860 (d) \uc911\uc5d0 \uc628\ub77c\uc778\uc73c\ub85c \uc0dd\uc131\ub418\ub294 \ud559\uc2b5 \uac00\ub2a5\ud55c \uc800\uacc4\uae09 \ud589\ub82c W\u0394*\uc758 \uacfc\uc815 (f)\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. LoRAM\uc740 LoRA\uc640 \ub2ec\ub9ac \ud559\uc2b5\uacfc \ucd94\ub860 \ub2e8\uacc4\uc5d0\uc11c \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294\ub370, \uc774\ub294 \ud559\uc2b5 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uac00\uc9c0\uce58\uae30\ub41c \uc791\uc740 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uace0 \ucd94\ub860 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc6d0\ub798\uc758 \ud070 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc811\uadfc \ubc29\uc2dd\uc740 \uba54\ubaa8\ub9ac \ud6a8\uc728\uc744 \ub192\uc774\uace0 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "2 \uba54\ubaa8\ub9ac \ud6a8\uc728\uc801\uc778 LoRA \ud559\uc2b5 - LoRAM"}, {"figure_path": "https://arxiv.org/html/2502.13533/x5.png", "caption": "Figure 3: The test perplexity of training LLaMA-2-13B & LLaMA-2-70B on OpenHermes.", "description": "\ubcf8 \uadf8\ub9bc\uc740 OpenHermes \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec LLaMA-2-13B \ubc0f LLaMA-2-70B \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a8 \uacb0\uacfc\uc5d0 \ub300\ud55c \ud14c\uc2a4\ud2b8 \ud37c\ud50c\ub809\uc11c\ud2f0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud558\uc704 \uadf8\ub9bc\uc740 \ub2e4\ub978 \ubaa8\ub378 \ud06c\uae30\uc640 \ub370\uc774\ud130\uc14b \uc870\ud569\uc5d0 \ub300\ud55c \ud37c\ud50c\ub809\uc11c\ud2f0 \ubcc0\ud654\ub97c \ub098\ud0c0\ub0b4\uba70, \ub2e4\uc591\ud55c LoRAM \ubcc0\ud615 \ubaa8\ub378\ub4e4(LORAM-Rand, LORAM-Stru, LORAM-Semi, LORAM-Unst)\uacfc \uae30\uc874 LoRA \ubaa8\ub378(7B, 13B, 70B)\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uadf8\ub9bc\uc744 \ud1b5\ud574 \uac01 \ubaa8\ub378\uc758 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c\uc758 \ud37c\ud50c\ub809\uc11c\ud2f0 \ubcc0\ud654 \ucd94\uc774\ub97c \ud30c\uc545\ud558\uace0, LoRAM\uc758 \ud6a8\uc728\uc131\uacfc \uc131\ub2a5\uc744 LoRA\uc640 \ube44\uad50 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 Fine-Tuning Convergence"}, {"figure_path": "https://arxiv.org/html/2502.13533/x6.png", "caption": "Figure 4: The test perplexity of training LLaMA-2-13B & LLaMA-2-70B on OpenOrca.", "description": "\uadf8\ub9bc 4\ub294 OpenOrca \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec LLaMA-2-13B \ubc0f LLaMA-2-70B \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\ub294 \ub3d9\uc548\uc758 \ud14c\uc2a4\ud2b8 \ub2f9\ud669\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\ub7ec \uac00\uc9c0 \uc790\ub974\uae30 \uc54c\uace0\ub9ac\uc998(LORAM-Rand, LORAM-Stru, LORAM-Semi, LORAM-Unst)\uacfc \uc591\uc790\ud654(QLORAM)\ub97c \uc801\uc6a9\ud55c LORAM\uc758 \uc131\ub2a5\uc744 \uae30\uc900 \ubaa8\ub378(LoRA\ub85c \ubbf8\uc138 \uc870\uc815\ub41c 7B \ubc0f 13B \ubaa8\ub378, \ubbf8\uc138 \uc870\uc815\ub418\uc9c0 \uc54a\uc740 13B \ubc0f 70B \ubaa8\ub378)\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \ubbf8\uc138 \uc870\uc815 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub978 \ub2f9\ud669\ub3c4\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \uac01 \ubc29\ubc95\uc758 \uc218\ub834 \uc18d\ub3c4\uc640 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ud2b9\ud788, 70B \ubaa8\ub378\uc5d0\uc11c QLORAM\uc758 \ud6a8\uc728\uc131\uacfc \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 \ubbf8\uc138 \uc870\uc815 \uc218\ub834"}, {"figure_path": "https://arxiv.org/html/2502.13533/x7.png", "caption": "Figure 5: The test perplexity & downstream performance of training LLaMA-3.1-70B on OpenHermes.", "description": "\uc774 \uadf8\ub9bc\uc740 OpenHermes \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec LLaMA-3.1-70B \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud588\uc744 \ub54c\uc758 \ud14c\uc2a4\ud2b8 \ud37c\ud50c\ub809\uc11c\ud2f0\uc640 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \ub2e4\uc591\ud55c \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95(\uc608: LoRA, QLoRAM-Stru)\uacfc \ud6c8\ub828 \ubc18\ubcf5 \ud69f\uc218\uc5d0 \ub530\ub978 \ud37c\ud50c\ub809\uc11c\ud2f0 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, LoRAM\uc758 \ud6a8\uc728\uc131\uacfc \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788, QLoRAM-Stru\ub294 \ub9e4\uac1c\ubcc0\uc218 \uc800\uc7a5 \ube44\uc6a9\uc744 \ud06c\uac8c \uc904\uc774\uba74\uc11c\ub3c4 LoRA \uae30\ubc18 \ubc29\ubc95\ub4e4\uacfc \ube44\uad50\ud588\uc744 \ub54c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub2e4\ub978 LoRAM \ubcc0\ud615\ub4e4\uacfc\uc758 \ube44\uad50\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \uac00\uc9c0\uce58\uae30 \uc804\ub7b5\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uace0, \ud6c8\ub828 \uacfc\uc815 \uc911 \ud37c\ud50c\ub809\uc11c\ud2f0 \ubcc0\ud654 \ucd94\uc138\ub97c \ud655\uc778\ud558\uc5ec, \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \uc131\ub2a5\uacfc \ud559\uc2b5 \uc548\uc815\uc131\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ud65c\uc6a9\ub429\ub2c8\ub2e4.", "section": "3.2 FINE-TUNING CONVERGENCE"}, {"figure_path": "https://arxiv.org/html/2502.13533/x8.png", "caption": "Figure 6: Necessity of Recovery & Alignment across different pruning strategies on LLaMA-2-13B.", "description": "\uadf8\ub9bc 6\uc740 LLaMA-2-13B \ubaa8\ub378\uc5d0\uc11c \ub2e4\uc591\ud55c \uac00\uc9c0\uce58\uae30 \uc804\ub7b5\uc5d0 \ub530\ub978 \ubcf5\uc6d0 \ubc0f \uc815\ub82c\uc758 \ud544\uc694\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uac00\uc9c0\uce58\uae30 \uc804\ub7b5(\ubb34\uc791\uc704, \uad6c\uc870\uc801, \ubc18\uad6c\uc870\uc801, \ube44\uad6c\uc870\uc801)\uc5d0 \ub300\ud574 \ubcf5\uc6d0 \uacfc\uc815\uc774 \uc5c6\uc744 \ub54c\uc640 \uc815\ub82c \uacfc\uc815\uc774 \uc5c6\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \uc54c\ud30c\uce74(Alpaca) \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \ud14c\uc2a4\ud2b8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70, \ubcf5\uc6d0 \ubc0f \uc815\ub82c \uacfc\uc815\uc774 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud2b9\ud788, \uad6c\uc870\uc801 \uac00\uc9c0\uce58\uae30\uc758 \uacbd\uc6b0 \ubcf5\uc6d0 \uacfc\uc815\uc774 \uc5c6\uc73c\uba74 \uc131\ub2a5 \uc800\ud558\uac00 \uc2ec\uac01\ud558\uac8c \ub098\ud0c0\ub0a9\ub2c8\ub2e4.", "section": "3.5 \ubcf5\uc6d0 \ubc0f \uc815\ub82c\uc758 \ud544\uc694\uc131"}, {"figure_path": "https://arxiv.org/html/2502.13533/x9.png", "caption": "Figure 7: Effect of scaling parameter reduction ratio.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub9e4\uac1c\ubcc0\uc218 \uac10\uc18c \ube44\uc728\uc744 \ud655\uc7a5\ud588\uc744 \ub54c\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LoRA \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ub41c LLaMA-2-13B \ubaa8\ub378\uc740 \ub9e4\uac1c\ubcc0\uc218 \uac10\uc18c \ube44\uc728\uc774 5.30\ubc30\uc5d0 \ub2ec\ud558\ub294 \ubc18\uba74, QLORAM-STRU\ub294 \ub450 \uac00\uc9c0 \uc9c0\uc2dc\uc5b4 \uc870\uc815 \ub370\uc774\ud130 \uc138\ud2b8 \ubaa8\ub450\uc5d0\uc11c \uc6b0\uc218\ud55c \ud37c\ud50c\ub809\uc11c\ud2f0\ub97c \uc720\uc9c0\ud558\uba74\uc11c \ub9e4\uac1c\ubcc0\uc218\ub97c \ub354\uc6b1 \uac10\uc18c\uc2dc\ucf30\uc2b5\ub2c8\ub2e4. \ubc18\uba74\uc5d0 \ub2e8\uc21c\ud55c \uac00\uc9c0\uce58\uae30\ub294 \ub9e4\uac1c\ubcc0\uc218 \uac10\uc18c \ube44\uc728\uc774 \uc801\uc744 \ub54c \ud37c\ud50c\ub809\uc11c\ud2f0\uac00 \ud06c\uac8c \uc99d\uac00\ud569\ub2c8\ub2e4. \ub9e4\uac1c\ubcc0\uc218 \uac10\uc18c \ube44\uc728\uc774 28.56\ubc30\uc5d0 \uc774\ub974\uba74 QLORAM-STRU\ub294 \uc57d 2.5\uc758 \ud6a8\uacfc\uc801\uc778 \ud37c\ud50c\ub809\uc11c\ud2f0\ub97c \uc720\uc9c0\ud558\ub294 \ubc18\uba74, \ub2e8\uc21c\ud55c \uac00\uc9c0\uce58\uae30\ub294 621.98\ub85c \uae09\uc99d\ud569\ub2c8\ub2e4. \uc774\ub294 LoRAM\uc774 \uae30\ubc18 \ubaa8\ub378\uc758 \uba54\ubaa8\ub9ac\ub97c \uadf9\uc801\uc73c\ub85c \uc904\uc774\uba74\uc11c \ucd94\ub860 \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.6 \ub9e4\uac1c\ubcc0\uc218 \uac10\uc18c\uc5d0 \ub300\ud55c LoRAM\uc758 \uc2a4\ucf00\uc77c\ub9c1 \ubc95\uce59"}, {"figure_path": "https://arxiv.org/html/2502.13533/x18.png", "caption": "Figure 8: Performance of downstream tasks across different parameter reduction ratios.", "description": "\uadf8\ub9bc 8\uc740 \ub2e4\uc591\ud55c \ud30c\ub77c\ubbf8\ud130 \ucd95\uc18c \ube44\uc728\uc5d0\uc11c \uc5ec\ub7ec \uac00\uc9c0 downstream \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \ud30c\ub77c\ubbf8\ud130 \ucd95\uc18c \ube44\uc728\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\uba70, \ud2b9\uc815 \uc791\uc5c5\uc5d0 \ub300\ud55c \ucd5c\uc801\uc758 \ud30c\ub77c\ubbf8\ud130 \ucd95\uc18c \ube44\uc728\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \ud2b9\ud788,  9.82\ubc30\uc5d0\uc11c 16.95\ubc30 \uc0ac\uc774\uc758 \ud30c\ub77c\ubbf8\ud130 \uac10\uc18c \ube44\uc728\uc5d0\uc11c \ucd5c\uc801\uc758 \uc131\ub2a5\uc774 \ub098\ud0c0\ub098\uba70, \uc774\ub294 13B LoRA\uc640 70B w/o FT\ub97c \uc77c\uad00\ub418\uac8c \ub2a5\uac00\ud558\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc, \ud30c\ub77c\ubbf8\ud130 \uac10\uc18c \ube44\uc728\uc774 28.56\ubc30\ub85c \uacfc\ub3c4\ud558\uac8c \ub192\uc544\uc9c0\uba74 \uc624\ud788\ub824 \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 Downstream Task Performance"}]