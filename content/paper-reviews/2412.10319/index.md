---
title: "SCBench: A KV Cache-Centric Analysis of Long-Context Methods"
summary: "SCBenchëŠ” ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ Microsoft Corporation",]
showSummary: true
date: 2024-12-13
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2412.10319 {{< /keyword >}}
{{< keyword icon="writer" >}} Yucheng Li et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2024-12-16 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2412.10319" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2412.10319" target="_self" >}}
â†— Hugging Face
{{< /button >}}
{{< button href="https://paperswithcode.com/paper/scbench-a-kv-cache-centric-analysis-of-long" target="_self" >}}
â†— Papers with Code
{{< /button >}}




### TL;DR


{{< lead >}}

**ì¥ë¬¸ ë§¥ë½ LLMì€ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ ì¶”ë¡ ì— í•„ìš”í•œ ê³„ì‚° ë° ë©”ëª¨ë¦¬ ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤.** ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë‹¨ì¼ ìš”ì²­ì— ì¤‘ì ì„ ë‘ê³  ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œì˜ KV ìºì‹œ ì¬ì‚¬ìš©ì„ ë¬´ì‹œí•˜ì—¬ ë¬¸ì œê°€ ë©ë‹ˆë‹¤. **KV ìºì‹œ ì¬ì‚¬ìš©ì€ vLLM ë° SGLangê³¼ ê°™ì€ í”„ë ˆì„ì›Œí¬ì™€ OpenAI, Microsoft, Google, Anthropicê³¼ ê°™ì€ LLM ì œê³µì—…ì²´ì—ì„œ ë„ë¦¬ ì‚¬ìš©**ë©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë¥¼ ì™„ì „íˆ í‰ê°€í•˜ì§€ ëª»í•©ë‹ˆë‹¤. **ë©€í‹°í„´ ëŒ€í™” ë° ë©€í‹°ë‹¨ê³„ ì¶”ë¡ ì—ì„œ ì»¨í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ í„´ ë˜ëŠ” ìš”ì²­ì— ê±¸ì³ ê³µìœ **ë  ë•Œ KV ìºì‹œ ì¬ì‚¬ìš©ì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤. í•˜ìœ„ O(n) ë©”ëª¨ë¦¬ ë°©ì‹ì€ ì´ëŸ¬í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œëŠ” ì´ì „ ì •ë³´ì˜ ì••ì¶•ìœ¼ë¡œ ì¸í•´ í›„ì† ì¿¼ë¦¬ì— ëŒ€í•œ ì‘ë‹µì´ ì–´ë ¤ì›Œì§„ë‹¤ëŠ” ë³´ê³ ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ì‹¤ì œ ì¥ë¬¸ ë§¥ë½ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°˜ì˜í•˜ëŠ” í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ê°€ í•„ìš”**í•©ë‹ˆë‹¤. 

SCBenchëŠ” **ë©€í‹°ë¼ìš´ë“œ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•˜ëŠ” í˜„ì‹¤ì ì¸ KV ìºì‹œ ì¬ì‚¬ìš©**ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë¬¸ìì—´ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, ì „ì—­ ì •ë³´, ë©€í‹°íƒœìŠ¤í‚¹ê³¼ ê°™ì€ **ë„¤ ê°€ì§€ ì£¼ìš” ì¥ë¬¸ ë§¥ë½ ê¸°ëŠ¥ì„ í‰ê°€**í•©ë‹ˆë‹¤. ë˜í•œ ë‘ ê°€ì§€ ì»¨í…ìŠ¤íŠ¸ ê³µìœ  ëª¨ë“œì¸ ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ í†µí•©í•©ë‹ˆë‹¤. SCBenchëŠ” Llama, Qwen, GLMê³¼ ê°™ì€ 8ê°œì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ì¥ë¬¸ ë§¥ë½ LLMê³¼ Codestal Mamba, Jambaì™€ ê°™ì€ ê²Œì´íŠ¸ ì„ í˜• RNNì„ í¬í•¨í•˜ì—¬ 13ê°œì˜ ë‹¤ë¥¸ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë¥¼ í‰ê°€í•©ë‹ˆë‹¤. **KV ìºì‹œ ìƒì„±, ì••ì¶•, ê²€ìƒ‰ ë° ë¡œë“œì˜ ë„¤ ê°€ì§€ í•µì‹¬ ë‹¨ê³„ë¡œ ë¶„ë¥˜**ëœ ì´ëŸ¬í•œ ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. SCBenchë¥¼ í†µí•´ ì—°êµ¬ìë“¤ì€ **ë‹¤ì–‘í•œ í¬ì†Œì„± ê¸°ë²•, ì‘ì—… ë³µì¡ì„± ë° ë©€í‹°í„´ ìƒí˜¸ ì‘ìš©ì˜ ì˜í–¥ì— ëŒ€í•œ ì¤‘ìš”í•œ í†µì°°ë ¥**ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê¶ê·¹ì ìœ¼ë¡œ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì¥ë¬¸ ë§¥ë½ LLMì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê³  í–¥í›„ ì•„í‚¤í…ì²˜ ì„¤ê³„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} O(n) ë©”ëª¨ë¦¬ ë°©ì‹ì€ ì¥ë¬¸ ë””ì½”ë”©ì— í•„ìˆ˜ì ì´ë©°, í•˜ìœ„ O(n) ë°©ì‹ì€ ë©€í‹°í„´ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} í¬ì†Œ ì¸ì½”ë”©ì€ ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ê³¼ì ì´ë©° ë™ì  í¬ì†Œì„±ì´ ê³ ì • íŒ¨í„´ë³´ë‹¤ ìš°ìˆ˜í•©ë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ì¥ë¬¸ ìƒì„±ì€ ì¤‘ìš”ë„ ë¶„í¬ ë³€í™”ë¡œ ì¸í•´ ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
**LLM ì—°êµ¬ìë“¤ì—ê²Œ SCBenchëŠ” ì¥ë¬¸ ë§¥ë½ ë°©ë²• í‰ê°€ë¥¼ ìœ„í•œ ì¤‘ìš”í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œê³µ**í•©ë‹ˆë‹¤. **ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ KV ìºì‹œ ì¬ì‚¬ìš©ì— ì¤‘ì **ì„ ë‘ì–´ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ í•œê³„ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í˜„ì‹¤ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì¥ë¬¸ ë§¥ë½ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ëŒ€í•œ **ìƒˆë¡œìš´ í†µì°°ë ¥ì„ ì œê³µ**í•˜ê³ , ì¥ë¬¸ ë§¥ë½ LLMì˜ **íš¨ìœ¨ì ì¸ ê°œë°œ ë° ë°°í¬**ë¥¼ ìœ„í•œ ê·€ì¤‘í•œ ë„êµ¬ê°€ ë©ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2412.10319/x1.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ KV ìºì‹œì˜ ìˆ˜ëª… ì£¼ê¸°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë‹¨ì¼ ìš”ì²­ì— ì¤‘ì ì„ ë‘ëŠ” ë°˜ë©´ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ì—¬ëŸ¬ ìš”ì²­ì— ê±¸ì³ KV ìºì‹œë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤. SCBenchëŠ” KV ìºì‹œ ìƒì„±, ì••ì¶•, ê²€ìƒ‰ ë° ë¡œë“œì˜ ë„¤ ê°€ì§€ ë‹¨ê³„ë¡œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1:  KV Cache lifecycle. Prior benchmarks focus on single-request, while real-world applications reuse KV cache across requests. We propose SCBench and categorize long-context methods into KV Cache Generation, Compression, Retrieval, and Loading from a KV-cache-centric perspective.
> </details>





{{< table-caption >}}
| Methods | Taxonomy | Stage | P-stage Efficient | D-stage Efficient | KV Cache Size | Prefilling Complexity | Decoding Complexity | 
|---|---|---|---|---|---|---|---| 
| Codestral Mamba (team, 2024) | Gated Linear RNN | â¶ | âœ“ | âœ“ | O(k) | O(kn) | O(km) | 
| Jamba (Lieber etÂ al., 2024) | Gated Linear RNN + Full Attention | â¶ | âœ“ | âœ“ | O(n) | O(nÂ²) | O(nm) | 
| LLMLingua-2 (Pan etÂ al., 2024) | Prompt Compression | â¶ | âœ“ | âœ— | O(Î±n) | O(Î±Â²nÂ²) | O(Î±nm) | 
| A-shape (Xiao etÂ al., 2024b) | Sparse Attention | â¶ | âœ“ | âœ— | O(n) | O(kn) | O(nm) | 
| Tri-shape | Sparse Attention | â¶ | âœ“ | âœ— | O(n) | O(kn) | O(nm) | 
| MInference (Jiang etÂ al., 2024) | Sparse Attention | â¶ | âœ“ | âœ— | O(n) | O(kn) | O(nm) | 
| StreamingLLM (Xiao etÂ al., 2024b) | KV Cache Dropping | â· | âœ— | âœ“ | O(k) | O(nÂ²) | O(km) | 
| SnapKV (Li etÂ al., 2024c) | KV Cache Dropping | â· | âœ— | âœ“ | O(k) | O(nÂ²) | O(km) | 
| PyramidKV (Cai etÂ al., 2024) | KV Cache Dropping | â· | âœ— | âœ“ | O(k) | O(nÂ²) | O(km) | 
| KIVI (Liu etÂ al., 2024e) | KV Cache Quantitation | â· | âœ— | âœ“ | O(n) | O(nÂ²) | O(nm) | 
| CacheBlend (Yao etÂ al., 2024a) | KV Cache Retrieval | â¸ | âœ“ | âœ— | O(n) | O(nÂ²) | O(nm) | 
| Quest (Tang etÂ al., 2024) | KV Cache Loading | â¹ | âœ— | âœ“ | O(n) | O(nÂ²) | O(km) | 
| RetrievalAttention (Liu etÂ al., 2024b) | KV Cache Loading | â¹ | âœ— | âœ“ | O(n) | O(nÂ²) | O(km) |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” SCBenchì—ì„œ í‰ê°€ëœ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½(long-context) ë©”ì„œë“œë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì…ë ¥ í”„ë¡¬í”„íŠ¸ì˜ í† í° í¬ê¸°ë¥¼ *n*, ìƒì„± í† í° í¬ê¸°ë¥¼ *m*ìœ¼ë¡œ í‘œì‹œí•˜ë©°, *n*ì€ *m*ë³´ë‹¤ í›¨ì”¬ í½ë‹ˆë‹¤(*n* >> *m*). í‘œëŠ” ê° ë©”ì„œë“œì˜ ë¶„ë¥˜, pre-filling ë° decoding ë‹¨ê³„ì˜ íš¨ìœ¨ì„±, KV ìºì‹œ í¬ê¸°, pre-filling ë° decoding ë‹¨ê³„ì˜ ê³„ì‚° ë³µì¡ë„, ê·¸ë¦¬ê³  pre-filling ë° decoding ë‹¨ê³„ì—ì„œ íš¨ìœ¨ì ì¸ ì—°ì‚° ìˆ˜í–‰ ì—¬ë¶€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²Œì´íŠ¸ ì„ í˜• RNN, SSM-ì–´í…ì…˜ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸, Sparse Attention, KV ìºì‹œ ì‚­ì œ, KV ìºì‹œ ì–‘ìí™”, KV ìºì‹œ ê²€ìƒ‰, KV ìºì‹œ ë¡œë”© ë“± ë‹¤ì–‘í•œ ë©”ì„œë“œë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë…¼ë¬¸ì˜ ì„¹ì…˜ 2ì—ì„œ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì— ëŒ€í•œ KV ìºì‹œ ì¤‘ì‹¬ì  ê´€ì ì„ ì†Œê°œí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: We evaluated long-context methods on SCBench, where nğ‘›nitalic_n represents the token size of the input prompt and mğ‘šmitalic_m represents the generation token size, with nâ‰«mmuch-greater-thanğ‘›ğ‘šn\gg mitalic_n â‰« italic_m.
> </details>





### In-depth insights


#### KV Cache Focus
**KV ìºì‹œ**ì— ì¤‘ì ì„ ë‘” ì ‘ê·¼ ë°©ì‹ì€ **ê¸´ ì»¨í…ìŠ¤íŠ¸ LLM**ì˜ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. KV ìºì‹œëŠ” ì´ì „ í† í°ì˜ í‘œí˜„ì„ ì €ì¥í•˜ì—¬ ëª¨ë¸ì´ ê¸´ í…ìŠ¤íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. **ìºì‹œ ìƒì„±, ì••ì¶•, ê²€ìƒ‰ ë° ë¡œë”©**ì„ í¬í•¨í•œ KV ìºì‹œ ìˆ˜ëª… ì£¼ê¸°ì˜ ê° ë‹¨ê³„ë¥¼ ìµœì í™”í•˜ë©´ LLMì˜ ê¸°ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íš¨ìœ¨ì ì¸ ìºì‹œ ìƒì„± ê¸°ìˆ ì€ ì´ˆê¸° ì²˜ë¦¬ ë¹„ìš©ì„ ì¤„ì´ëŠ” ë°˜ë©´ ì§€ëŠ¥ì ì¸ ì••ì¶• ë°©ë²•ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë˜í•œ íš¨ê³¼ì ì¸ ê²€ìƒ‰ ë° ë¡œë”© ì „ëµì€ ëª¨ë¸ì´ ì´ì „ ì •ë³´ì— ë¹ ë¥´ê²Œ ì•¡ì„¸ìŠ¤í•˜ì—¬ ì‹ ì†í•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë“  ìµœì í™”ëŠ” ì „ì²´ì ìœ¼ë¡œ ë” ë¹ ë¥¸ ì¶”ë¡ , ë” ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ë” ë‚˜ì€ ì„±ëŠ¥ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.

#### SCBench Design
**SCBench**ëŠ” **KV ìºì‹œ** ì¤‘ì‹¬ì˜ ë¡± ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œ í‰ê°€ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. **ë©€í‹° ë¼ìš´ë“œ ë° ë©€í‹° ìš”ì²­ ì‹œë‚˜ë¦¬ì˜¤**ì—ì„œ KV ìºì‹œ **ì¬ì‚¬ìš©**ì— ì¤‘ì ì„ ë‘ì–´ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë” ì˜ ë°˜ì˜í•©ë‹ˆë‹¤. ë¬¸ìì—´ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, ì „ì—­ ì •ë³´ ì²˜ë¦¬, ë©€í‹°íƒœìŠ¤í‚¹ ë“± ë„¤ ê°€ì§€ ì£¼ìš” **ë¡± ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥**ì„ í‰ê°€í•˜ëŠ” 12ê°€ì§€ ì‘ì—…ì„ í¬í•¨í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ëŠ” **ë©€í‹° í„´ ëª¨ë“œì™€ ë©€í‹° ìš”ì²­ ëª¨ë“œ**ì˜ ë‘ ê°€ì§€ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì´ëŸ¬í•œ ì‘ì—…ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ ì„¤ê³„ë¥¼ í†µí•´ SCBenchëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë¡± ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œì˜ ê°•ì ê³¼ ì•½ì ì— ëŒ€í•œ **í¬ê´„ì ì¸ ë¶„ì„**ì„ ì œê³µí•˜ì—¬ ì‹¤ì œ í™˜ê²½ì—ì„œ ì„±ëŠ¥ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

#### Long-Ctx Analysis
**ê¸´ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„(Long-Ctx Analysis)**ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ê¸´ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì¡°ì‚¬ì…ë‹ˆë‹¤. ì´ ë¶„ì„ì€ **KV ìºì‹œ ì‚¬ìš© ìµœì í™”**ì— ì¤‘ì ì„ ë‘ì–´ ì»¨í…ìŠ¤íŠ¸ ì°½ì„ í™•ì¥í•˜ëŠ” ë°©ë²•ì„ ëª¨ìƒ‰í•©ë‹ˆë‹¤. **í•µì‹¬ ê³¼ì œ**ëŠ” ê¸´ ì‹œí€€ìŠ¤ì˜ ê³„ì‚° ë° ë©”ëª¨ë¦¬ ë¹„ìš© ì¦ê°€ë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Long-Ctx AnalysisëŠ” **ë‹¤ì–‘í•œ ì „ëµ**ì„ í‰ê°€í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” **í¬ì†Œ ì£¼ì˜ ê¸°ë²•**ê³¼ KV ìºì‹œ ì••ì¶•, ê²€ìƒ‰ ë° ë¡œë“œì™€ ê°™ì€ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµì´ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ ë©€í‹°í„´ ëŒ€í™” ë° ë‹¤ì¤‘ ìš”ì²­ê³¼ ê°™ì€ **ê³µìœ  ì»¨í…ìŠ¤íŠ¸**ì—ì„œ ì´ëŸ¬í•œ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë¶„ì„í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ ë¬¸ì œë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ëª©í‘œëŠ” ì„œë¡œ ë‹¤ë¥¸ ê¸´ ì»¨í…ìŠ¤íŠ¸ ë°©ë²•ì„ ë¹„êµí•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ **ì¥ì ê³¼ ë‹¨ì **ì„ ê°•ì¡°í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ì´ ë¶„ì„ì€ ëª¨ë¸ì´ ê¸´ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ **ê¸€ë¡œë²Œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬**í•˜ëŠ” ëŠ¥ë ¥ì„ ê³ ë ¤í•©ë‹ˆë‹¤. ê¶ê·¹ì ìœ¼ë¡œ Long-Ctx AnalysisëŠ” ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ **ê¸´ ì»¨í…ìŠ¤íŠ¸ LLM ì„¤ê³„ë¥¼ ìœ„í•œ í†µì°°ë ¥**ì„ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

#### Multi-Turn Limits
**ë©€í‹°í„´ ëŒ€í™”ì—ì„œì˜ í•œê³„ì **ì€ í˜„ì¬ LLM ì—°êµ¬ì˜ ì¤‘ìš”í•œ ê³¼ì œì…ë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ ì°½ í¬ê¸° ì œí•œ, ì´ì „ ëŒ€í™” ê¸°ì–µ ìœ ì§€ ì–´ë ¤ì›€, ëˆ„ì ë˜ëŠ” ê³„ì‚° ë¹„ìš© ì¦ê°€ ë“± ì—¬ëŸ¬ ìš”ì¸ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤. íŠ¹íˆ, ê¸´ ëŒ€í™”ì—ì„œ **ì •ë³´ ì†ì‹¤**ì´ ë°œìƒí•˜ê³ , **ì¼ê´€ì„± ìœ ì§€**ê°€ ì–´ë ¤ì›Œì§€ë©°, **ìƒˆë¡œìš´ ì •ë³´ í†µí•©** ëŠ¥ë ¥ë„ ì €í•˜ë©ë‹ˆë‹¤. ë˜í•œ, **ëŒ€í™” ë§¥ë½ì— ë”°ë¥¸ ë°˜ì‘ ìƒì„±** ëŠ¥ë ¥ê³¼ **ì‚¬ìš©ì ì˜ë„ íŒŒì•…** ëŠ¥ë ¥ í–¥ìƒë„ ì¤‘ìš”í•œ ì—°êµ¬ ì£¼ì œì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì—°êµ¬ê°€ ì§„í–‰ ì¤‘ì´ë©°, ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì•„í‚¤í…ì²˜, ì§€ì‹ ì¦ê°• ê¸°ë²•, íš¨ê³¼ì ì¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì „ëµ ë“±ì´ í™œë°œíˆ ê°œë°œë˜ê³  ìˆìŠµë‹ˆë‹¤.

#### Sparsity Insights
**í¬ì†Œì„±**ì€ ê¸¸ê³  ë³µì¡í•œ ì…ë ¥ì„ ì²˜ë¦¬í•  ë•Œ ê³„ì‚° ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. **í¬ì†Œ ì¸ì½”ë”©**ì„ ì‚¬ìš©í•˜ë©´ ì „ì²´ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì§€ ì•Šê³ ë„ ì¤‘ìš”í•œ ì •ë³´ë¥¼ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë””ì½”ë”© ë‹¨ê³„ì—ì„œ **í¬ì†Œì„±**ì„ ì ìš©í•˜ë©´ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ í’ˆì§ˆê³¼ ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ë™ì  í¬ì†Œì„±**ì€ ì •ì  íŒ¨í„´ë³´ë‹¤ ìœ ì—°ì„±ì´ ë†’ìœ¼ë©° ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ì—ì„œ ê³„ì¸µ ìˆ˜ì¤€ í¬ì†Œì„±ì„ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ë©´ì„œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì¤‘ ìš”ì²­ ì‹œë‚˜ë¦¬ì˜¤ì˜ ê²½ìš° ì…ë ¥ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” **í¬ì†Œ ì¸ì½”ë”©**ì´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ **í¬ì†Œ ë””ì½”ë”©**ì€ ê° ìš”ì²­ì— ëŒ€í•´ ì¤‘ìš”í•œ í† í°ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í¬ì†Œì„± ê¸°ë°˜ ë°©ë²•ì˜ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ë¥¼ ìµœì í™”í•˜ë ¤ë©´ ì¸ì½”ë”© ë° ë””ì½”ë”© ë‹¨ê³„ì—ì„œ **í¬ì†Œì„± íŒ¨í„´**ì„ ì‹ ì¤‘í•˜ê²Œ ì„¤ê³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2412.10319/x2.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‘ ê°€ì§€ ì¼ë°˜ì ì¸ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ íŒ¨í„´, ì¦‰ ë‹¤ì¤‘ í„´ ëª¨ë“œì™€ íŒíŠ¸ëœ KV ìºì‹œ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì¤‘ í„´ ëª¨ë“œì—ì„œ ì»¨í…ìŠ¤íŠ¸ëŠ” ë‹¨ì¼ ì„¸ì…˜ ë‚´ì— ìºì‹œë˜ê³ , íŒíŠ¸ëœ KV ìºì‹œ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œì—ì„œëŠ” ì—¬ëŸ¬ ì„¸ì…˜ì— ê±¸ì³ ìºì‹œë©ë‹ˆë‹¤. ê° ëª¨ë“œëŠ” ê³µìœ  ì»¨í…ìŠ¤íŠ¸ì™€ ì—¬ëŸ¬ í›„ì† ì¿¼ë¦¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Two Shared Context Modes
> </details>



![](https://arxiv.org/html/2412.10319/x3.png)

> ğŸ”¼ SCBenchëŠ” ê³µìœ  ì»¨í…ìŠ¤íŠ¸ì™€ ë‹¤ì¤‘ ë¼ìš´ë“œ ìƒí˜¸ ì‘ìš©ì— ì¤‘ì ì„ ë‘” íš¨ìœ¨ì ì¸ ê¸´ ì»¨í…ìŠ¤íŠ¸ ë°©ë²•ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ëœ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ê·¸ë¦¼ 2bì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, SCBenchëŠ” ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ ë‘ ê°€ì§€ì—ì„œ 12ê°€ì§€ ì‘ì—…ì— ëŒ€í•œ ë„¤ ê°€ì§€ ì£¼ìš” ê¸´ ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ê° í…ŒìŠ¤íŠ¸ ì˜ˆì‹œì—ëŠ” ê³µìœ  ì»¨í…ìŠ¤íŠ¸ì™€ ì—¬ëŸ¬ í›„ì† ì¿¼ë¦¬ê°€ í¬í•¨ë©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ê¸´ ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥ì—ëŠ” ë¬¸ìì—´ ê²€ìƒ‰ ê¸°ëŠ¥(NIAH ë° Multi-NIAHì™€ ê°™ì€ ì´ì „ ê²€ìƒ‰ ì‘ì—…ì„ í™•ì¥í•˜ì—¬ í¬ê´„ì ì¸ ë¬¸ìì—´ ê²€ìƒ‰ ì‘ì—… 3ê°€ì§€ë¥¼ ë„ì…), ì˜ë¯¸ ê²€ìƒ‰ ê¸°ëŠ¥(ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ë‹¤ì–‘í•œ ì˜ë¯¸ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê³ ë ¤í•˜ì—¬ ë„¤ ê°€ì§€ ê³ ìœ í•œ í…ŒìŠ¤íŠ¸ êµ¬ì¶•), ê¸€ë¡œë²Œ ì •ë³´ ê¸°ëŠ¥(ë‹¤ì¤‘ ìƒ· ì¸ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ, ìš”ì•½ ë° ê¸´ ë°°ì—´ í†µê³„ì™€ ê°™ì€ ì„¸ ê°€ì§€ ì‘ì—…ì„ í†µí•´ ê¸´ ì»¨í…ìŠ¤íŠ¸ LLMì˜ ê¸€ë¡œë²Œ ì •ë³´ ì²˜ë¦¬ ë° ì§‘ê³„ ê¸°ëŠ¥ í‰ê°€), ë‹¤ì¤‘ ì‘ì—… ê¸°ëŠ¥(NIAHê°€ í¬í•¨ëœ RepoQA ë° KV ê²€ìƒ‰ì´ í¬í•¨ëœ ìš”ì•½ì´ë¼ëŠ” ë‘ ê°€ì§€ ì‘ì—…ì„ í†µí•´ ê³µìœ  ê¸´ ì»¨í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ì—¬ëŸ¬ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” LLMì˜ ê¸°ëŠ¥ í‰ê°€)ì´ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ ë²¤ì¹˜ë§ˆí¬ì—ëŠ” ë‹¤ì¤‘ í„´ ëª¨ë“œì™€ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œë¼ëŠ” ë‘ ê°€ì§€ ì¼ë°˜ì ì¸ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œê°€ í¬í•¨ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Overview of SCBench
> </details>



![](https://arxiv.org/html/2412.10319/x4.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‘ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (a)ëŠ” ë‘ ê°€ì§€ ì¼ë°˜ì ì¸ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ íŒ¨í„´, ì¦‰ ë‹¤ì¤‘ í„´ ëª¨ë“œì™€ íŒíŠ¸ëœ KV ìºì‹œ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì¤‘ í„´ ëª¨ë“œì—ì„œëŠ” ì»¨í…ìŠ¤íŠ¸ê°€ ë‹¨ì¼ ì„¸ì…˜ ë‚´ì— ìºì‹œë˜ê³ , íŒíŠ¸ëœ KV ìºì‹œ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œì—ì„œëŠ” ì—¬ëŸ¬ ì„¸ì…˜ì— ê±¸ì³ ìºì‹œë©ë‹ˆë‹¤. (b)ëŠ” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ë£¨ëŠ” ì‘ì—…ê³¼ ì‹œë‚˜ë¦¬ì˜¤ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¬¸ìì—´ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, ì „ì—­ ì •ë³´, ë‹¤ì¤‘ ì‘ì—…ì˜ ë„¤ ê°€ì§€ ë²”ì£¼ì˜ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥ê³¼ ë‘ ê°€ì§€ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ(ë‹¤ì¤‘ í„´ ë° ë‹¤ì¤‘ ìš”ì²­)ê°€ í¬í•¨ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: Long-context tasks often involve contexts sharing, e.g., multi-turn dialogues, multi-step reasoning, and repository-level tasks. (a) Illustration of two common shared-context patterns. (b) Overview of tasks and scenarios covered by our benchmark, encompassing four categories of long-context abilities and two shared-context modes.
> </details>



![](https://arxiv.org/html/2412.10319/x5.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ê¸°ë²•ë“¤ì´ ì—¬ëŸ¬ ìš”ì²­ì— ê±¸ì³ ì–´ë–¤ ì„±ëŠ¥ ì¶”ì„¸ë¥¼ ë³´ì´ëŠ”ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë””ì½”ë”© ì‹œ O(n) ë©”ëª¨ë¦¬ ë¹„ìš©ì´ ë“œëŠ” ê¸°ë²•ë“¤ì€ ìš”ì²­ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ë””ì½”ë”© ì‹œ sub-O(n) KV ìºì‹œë¥¼ ì‚¬ìš©í•˜ëŠ” ê¸°ë²•ë“¤, ì˜ˆë¥¼ ë“¤ì–´ KV ìºì‹œ ì‚­ì œ ê¸°ë²•ë“¤ì€ ì²« ë²ˆì§¸ ìš”ì²­ì—ì„œë§Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) Performance Across Different Requests
> </details>



![](https://arxiv.org/html/2412.10319/x6.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ë¡± ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œê°€ SCBenchì—ì„œ ì—¬ëŸ¬ ë¡± ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥(ë¬¸ìì—´ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, ì „ì—­ ì •ë³´, ë©€í‹°íƒœìŠ¤í‚¹)ì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ë¡± ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œëŠ” ê²€ìƒ‰ ê¸°ëŠ¥ì—ì„œ ì–´ëŠ ì •ë„ ì„±ëŠ¥ ì €í•˜ë¥¼ ë³´ì´ëŠ” ë°˜ë©´, ì „ì—­ ì •ë³´ ì²˜ë¦¬ ê¸°ëŠ¥ì—ì„œëŠ” ì„±ëŠ¥ì„ ëŒ€ì²´ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Performance in Different Abilities
> </details>



![](https://arxiv.org/html/2412.10319/x7.png)

> ğŸ”¼ SCBench ì„±ëŠ¥ ê²°ê³¼ì— ëŒ€í•œ ê°œìš”ì…ë‹ˆë‹¤. (a)ëŠ” ì—¬ëŸ¬ ìš”ì²­ì— ê±¸ì¹œ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë°©ì‹ì˜ ì„±ëŠ¥ ì¶”ì„¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë””ì½”ë”© ì‹œ O(n) ë©”ëª¨ë¦¬ ë¹„ìš©ì´ ë“œëŠ” ë°©ì‹ì€ ìš”ì²­ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, KV ìºì‹œ ì‚­ì œ ë°©ì‹ê³¼ ê°™ì´ sub-O(n) KV ìºì‹œë¥¼ ë””ì½”ë”©ì— ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì€ ì²« ë²ˆì§¸ ìš”ì²­ì—ì„œë§Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. (b)ëŠ” ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ê¸°ëŠ¥ ì‘ì—…ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ì¥ë¬¸ ë§¥ë½ ë°©ì‹ì˜ êµ¬ì²´ì ì¸ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í‰ê°€ëœ ëª¨ë“  ì¥ë¬¸ ë§¥ë½ ë°©ì‹ì€ ê²€ìƒ‰ ê¸°ëŠ¥ì—ì„œ ì•½ê°„ì˜ ì†ì‹¤ì„ ë³´ì´ì§€ë§Œ, ì „ì—­ ì •ë³´ ì²˜ë¦¬ ê¸°ëŠ¥ì€ ëŒ€ì²´ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.   sub-O(n) ë°©ì‹ì€ ì—¬ëŸ¬ ì°¨ë¡€ì˜ ë””ì½”ë”©ì—ì„œ ë¹„ì‹¤ìš©ì ì´ë©°, O(n) ë©”ëª¨ë¦¬ë¥¼ ê°€ì§„ í¬ì†Œ ì¸ì½”ë”©ì´ ì—¬ëŸ¬ ì¿¼ë¦¬ì—ì„œ ì „ì²´ ì–´í…ì…˜ ì •í™•ë„ì— ê·¼ì ‘í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  O(n) ë©”ëª¨ë¦¬ ë°©ì‹ì€ ì •í™•í•œ ì¼ì¹˜ ê²€ìƒ‰ ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ëª¨ë“  ì¥ë¬¸ ë§¥ë½ ë°©ì‹ì€ ì˜ˆì‚°ì´ ê°ì†Œí•¨ì— ë”°ë¼ ì„±ëŠ¥ì´ ì €í•˜ë˜ì§€ë§Œ, sub-O(n) ë©”ëª¨ë¦¬ ë°©ì‹ì€ ë” í° ì„±ëŠ¥ ì €í•˜ë¥¼ ë³´ì…ë‹ˆë‹¤. ì¥ë¬¸ ìƒì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ë¶„í¬ ë³€í™” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Overview of performance results for SCBench. (a) Performance trends of various long-context methods across multiple requests. Methods with Oâ¢(n)ğ‘‚ğ‘›O(n)italic_O ( italic_n ) memory cost in decoding show improving performance as requests increase. In contrast, methods with sub-Oâ¢(n)ğ‘‚ğ‘›O(n)italic_O ( italic_n ) KV cache in decoding, like KV cache dropping methods, perform well only in the first request. (b) Specific performance of different long-context methods across various long-context capability tasks. All evaluated long-context methods exhibit some loss in Retrieval capability while largely maintaining Global Information processing capability.
> </details>



![](https://arxiv.org/html/2412.10319/x8.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì••ì¶•ë¥ ì—ì„œ ì—¬ëŸ¬ê°€ì§€ Long-context ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ Llama-3.1-8B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ SCBenchì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì••ì¶•ë¥ ì´ ë‚®ì„ìˆ˜ë¡(ì˜ˆ: 1/32) ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ì¤„ì–´ë“¤ì§€ë§Œ ì„±ëŠ¥ ì €í•˜ê°€ ë” ì»¤ì§‘ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ì••ì¶•ë¥ ì´ ë†’ì„ìˆ˜ë¡(ì˜ˆ: 1) ì„±ëŠ¥ì€ ì¢‹ì•„ì§€ì§€ë§Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ëŠ˜ì–´ë‚©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ì••ì¶•ë¥ ê³¼ ì„±ëŠ¥ ì‚¬ì´ì˜ trade-off ê´€ê³„ë¥¼ ë³´ì—¬ì£¼ë©°, MInferenceì™€ ê°™ì´ ë” ì •í™•í•œ sparse ë©”ì„œë“œëŠ” ë” ë†’ì€ ì••ì¶•ë¥ ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, RetreivalAttention ë° KIVIì™€ ê°™ì€ O(n) ë©”ëª¨ë¦¬ë¥¼ ìœ ì§€í•˜ëŠ” ë©”ì„œë“œëŠ” ë†’ì€ ì••ì¶•ë¥ ì—ì„œë„ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ìœ ì§€í•¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Performance of various long-context methods at different compression rates on SCBench using Llama-3.1-8BÂ (Dubey etÂ al., 2024).
> </details>



![](https://arxiv.org/html/2412.10319/x9.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ A-shapeì™€ Tri-shapeë¼ëŠ” ë‘ ê°€ì§€í¬ì†Œ ì–´í…ì…˜ ë°©ë²•ì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. A-shapeëŠ” ì‹±í¬ í† í°ê³¼ ë¡œì»¬ ìœˆë„ìš° ì˜ì—­ì„ ìœ ì§€í•˜ëŠ” ë°˜ë©´, Tri-shapeëŠ” ë§ˆì§€ë§‰ ìœˆë„ìš° ì¿¼ë¦¬ ì˜ì—­ë„ ìœ ì§€í•˜ì—¬ ì‚¬ì „ ì±„ìš°ê¸° ë‹¨ê³„ì—ì„œ ì‚¼ê°í˜• íŒ¨í„´ì„ í˜•ì„±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¶”ê°€ëŠ” ì²« ë²ˆì§¸ í„´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: The sparse attention methods framework.
> </details>



![](https://arxiv.org/html/2412.10319/x10.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë¬¸ìì—´ ê²€ìƒ‰ ëŠ¥ë ¥ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ ì—¬ëŸ¬ í„´ì— ê±¸ì³ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²°ê³¼ëŠ” í…ŒìŠ¤íŠ¸ëœ ëª¨ë“  ê¸°ë³¸ LLMì—ì„œ í‰ê· ì„ ë‚¸ ê°’ì…ë‹ˆë‹¤. ë‹¤ì¤‘ ì‘ì—… ì‘ì—…ì— ëŒ€í•œ ê²°ê³¼ëŠ” ê·¸ë¦¼ 10ì— ë‚˜ì™€ ìˆìœ¼ë©°, ìì„¸í•œ ë‚´ìš©ì€ 4ì ˆì— ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë°©ë²•ì˜ ì„±ëŠ¥ì´ ì¿¼ë¦¬ê°€ ë°˜ë³µë¨ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€, íŠ¹íˆ ë¬¸ìì—´ ê²€ìƒ‰ ì‘ì—…ì—ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤. O(n) ë©”ëª¨ë¦¬ ë°©ë²•ì´ ì¼ë°˜ì ìœ¼ë¡œ ì—¬ëŸ¬ í„´ì— ê±¸ì³ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” ë°˜ë©´, sub-O(n) ë°©ë²•ì€ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ì¥ë¬¸ ë§¥ë½ ë°©ë²•ì˜ ê°•ì ê³¼ ì•½ì ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ë§¥ë½ì„ ì œê³µí•˜ë©°, íŠ¹íˆ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ê³¼ ë‹¤ì¤‘ í„´ ì„±ëŠ¥ ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë°©ë²•ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (a) String Retrieval
> </details>



![](https://arxiv.org/html/2412.10319/x11.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë“¤ì´ ì‹œë§¨í‹± ê²€ìƒ‰ ëŠ¥ë ¥ì—ì„œ ì—¬ëŸ¬ í„´ì— ê±¸ì³ ì–´ë–¤ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€ ë¹„êµí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” í…ŒìŠ¤íŠ¸ëœ ëª¨ë“  ê¸°ë³¸ LLMì— ëŒ€í•´ í‰ê· í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (b) Semantic Retrieval
> </details>



![](https://arxiv.org/html/2412.10319/x12.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ê¸°ë²•ë“¤ì´ ì „ì—­ ì •ë³´ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ ë¹„êµí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ í„´ì— ê±¸ì³ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬, ë™ì  í¬ì†Œ ì–´í…ì…˜ ê¸°ë²•(MInference)ì´ ì „ì—­ ì •ë³´ë¥¼ ì˜ í™œìš©í•˜ëŠ” ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°˜ë©´, KV ìºì‹œ ì••ì¶• ê¸°ë²•(StreamingLLM, SnapKV)ì€ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> (c) Global Information
> </details>



![](https://arxiv.org/html/2412.10319/x13.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì‘ì—…ê³¼ í„´ì— ë”°ë¥¸ ì—¬ëŸ¬ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¬¸ìì—´ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, ì „ì—­ ì •ë³´ì™€ ê°™ì€ ì‘ì—… ìœ í˜•ë³„ë¡œ í•˜ìœ„ ê·¸ë¦¼ì´ ë‚˜ë‰©ë‹ˆë‹¤. ê° í•˜ìœ„ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œ(FullAttention, Tri-shape, MInference, A-shape, StreamingLLM, SnapKV, LLMLingua-2, Quest)ì˜ 5ê°œ í„´ì— ê±¸ì¹œ ì„±ëŠ¥ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²°ê³¼ëŠ” í…ŒìŠ¤íŠ¸ëœ ëª¨ë“  ê¸°ë³¸ LLMì—ì„œ í‰ê· ì„ ë‚¸ ê²ƒì…ë‹ˆë‹¤. ë©€í‹°íƒœìŠ¤í‚¹ ì‘ì—…ì˜ ê²°ê³¼ëŠ” ê·¸ë¦¼ 10ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Performance of different long-context methods across various tasks and turns. The results for multi-tasking tasks are shown in Fig.Â 10, and the results are averaged across all tested base LLMs.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Task | Description | Capability | Avg. Input Length | Avg. Output Length | #Sessions / #Turns |
|---|---|---|---|---|---| 
| Retr.KV | Key-value retrieval from many key-value pairs | String Retrieval | 125K | 943 | 100/500 |
| Retr.Prefix-Suffix | Find string with specific prefix and suffix in a dict | String Retrieval | 112K | 914 | 100/500 |
| Retr.MultiHop | Tracking variables assignment in a long input | String Retrieval | 124K | 410 | 90/450 |
| Code.RepoQA | Functions retrieval from a GitHub repo | Semantic Retrieval | 65K | 6,058 | 88/440 |
| En.QA | English Question Answering | Semantic Retrieval | 198K | 272 | 69/351 |
| Zh.QA | Chinese Question Answering | Semantic Retrieval | 1.5M | 322 | 35/189 |
| En.MultiChoice | English Multi-Choice Questions | Semantic Retrieval | 188K | 215 | 58/299 |
| Math.Find | Math computation tasks within long sequence arrays | Global Information | 120K | 172 | 100/240 |
| ICL.ManyShot | Hundreds-shot in-context learning | Global Information | 22K | 975 | 54/270 |
| En.Sum | Summarize a doc given multiple docs as input | Global Information | 104K | 1,170 | 79/350 |
| Mix.Sum+NIAH | Multi-tasking of En.Sum and Needle in A Haystack | Multi-tasking | 105K | 3,441 | 70/560 |
| Mix.RepoQA+KV | Multi-tasking of RepoQA and KV retrieval | Multi-tasking | 68K | 5,318 | 88/704 |
| **Total** | - | - | **227K** | **1,684** | **931/4,853** |{{< /table-caption >}}
> ğŸ”¼ SCBench ë²¤ì¹˜ë§ˆí¬ì— í¬í•¨ëœ ì‘ì—…ë“¤ì˜ ê°œìš”ë¥¼ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤. ê° ì‘ì—…ì— ëŒ€í•œ ì„¤ëª…, ì¸¡ì •ë˜ëŠ” ëŠ¥ë ¥, í‰ê·  ì…ë ¥ ê¸¸ì´, í‰ê·  ì¶œë ¥ ê¸¸ì´, ì„¸ì…˜ ìˆ˜ ë° í„´ ìˆ˜ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Overview of SCBench tasks.
> </details>

{{< table-caption >}}
| Task | Source | Configuration | Example |
|---|---|---|---| 
| Retr.KV | Lost in the Middle <br> (Liu etÂ al., 2024d) | num kv pairs = 2500 <br> len of key & value = 36 <br> metric = Accuracy | Input: {`<key #1>`: `<value #1>`, â€¦, `<key #100>`: `<value #100>`} <br> Turn 1: The value of the `<key #1>` is? Answer 1: â€¦`<value #1>`â€¦ <br> Turn 2: The value of the `&lt;key #20&gt;` is? Answer 2: â€¦`&lt;value #20&gt;`â€¦ <br> Turn 3: The value of the `&lt;key #40&gt;` is? Answer 3: â€¦`&lt;value #40&gt;`â€¦ | 
| Retr.Prefix-Suffix | Ours | size of dict = 6000 <br> len of string = [65, 123) <br> metric = Accuracy | Input: Dictionary = [`<str #1>`, `<str #2>`, â€¦, `<str #100>`] <br> Turn 1: Prefix: `<px #1>`; Suffix: `<sx #1>`. The word with both prefix and suffix from the dict is? Answer: `<str>` <br> Turn 2: Prefix: `<px #2>`; Suffix: `<sx #2>`. Answer: `<str>` | 
| Retr.MultiHop | RULER <br> (Hsieh etÂ al., 2024) | num chains = 2 <br> num hops = 2 <br> metric = Accuracy | Input: VAR `X1` = `12345` â€¦â€¦ VAR Y1 = 54321 â€¦..`<noise>` <br> VAR `X2` = X1 â€¦â€¦ VAR Y2 = Y1 â€¦â€¦`<noise>` <br> VAR `X3` = X2 â€¦â€¦ VAR Y3 = Y2 â€¦â€¦`<noise>` <br> Turn 1: Variables that are assigned to `12345`? Answer 1: `X1 X2 X3` <br> Turn 2: Variables that are assigned to 54321? Answer 1: Y1 Y2 Y3 | 
| Code.RepoQA | RepoQA <br> (Liu etÂ al., 2024c) | func description from GPT-4 <br> metric = Pass@1 | Input: `<func 1>` + `<func 2>` + â€¦ + `<func 100>` <br> Turn 1: `<description of func 1>`. Answer 1: `<func 1>` <br> Turn 2: `<description of func 20>`. Answer 2: `<func 20>` | 
| En.QA <br> Zh.QA | InfiniteBench <br> (Zhang etÂ al., 2024a) | ground_truth from human <br> metric = Accuracy | Input: Read the book below and answer a question. `<context>` <br> Turn 1: `<question>` Be very concise. Answer 1: â€¦`<ans>`â€¦ <br> Turn 2: `<question>` Be very concise. Answer 2: â€¦`<ans>`â€¦ | 
| En.MultiChoice | InfiniteBench <br> (Zhang etÂ al., 2024a) | ground_truth from human <br> metric = Accuracy | Input: Read the book and answer the question. `<context>` <br> Turn 1: `<question>` + `<Option A,B,C,D>`. Answer 1: â€¦`<ans>`â€¦ <br> Turn 2: `<question>` + `<Option A,B,C,D>`. Answer 2: â€¦`<ans>`â€¦ | 
| Math.Find | Ours | len_array=30000 <br> num_digits=3 <br> metric = Accuracy | Input: `<a large array of number>` <br> Turn 1: The `max number` in the array is? Answer 1: â€¦`<max number>`â€¦ <br> Turn 2: The `max number` in the array is? Answer 2: â€¦`<max number>`â€¦ | 
| ICL.ManyShot | ManyShotICL <br> (Srivastava etÂ al., 2023) | num_examples = ~150 <br> Tasks = date, salient, tracking7 <br> metric = Accuracy | Input: ICL Demo. 1 + Demo. 2 + â€¦.. + Demo. 1000 <br> Turn 1: `<question>`. Answer 1: â€¦`<ans>`â€¦ <br> Turn 2: `<question>`. Answer 2: â€¦`<ans>`â€¦ | 
| En.Sum | Ours | Concatenated arXiv papers <br> ground_truth from GPT-4 <br> num document = ~8 <br> metric = ROUGE | Input: `Doc 1` + Doc 2 + Doc 3 + â€¦ + Doc 10. <br> Turn 1: Please summarize `Doc 1`. Answer 1: â€¦ `<summary of Doc 1>`â€¦ <br> Turn 2: Please summarize Doc 3. Answer 2: â€¦ `<summary of Doc 3>`â€¦ <br> Turn 3: Please summarize Doc 5. Answer 2: â€¦ `<summary of Doc 5>`â€¦ | 
| Mix.Sum+NIAH | Ours | num needle = 5 <br> num document = ~8 <br> metric = ROUGE + Acc | Input: `Doc 1` + `<Passkeys>` + Doc 2 + â€¦ + `<Passkeys>` + Doc 10. <br> Turn 1: Please summarize `Doc 1`. Answer 1: â€¦`<summary of Doc 1>`â€¦ <br> Turn 2: What is the needle? Answer 2: ..`<needle>`â€¦ | 
| Mix.RepoQA+KV | Ours | num KV pairs = ~100 <br> metric = Pass@1 + Acc | Input: `<func 1>` + KV pairs + `<func 2>` + â€¦ + KV pairs + `<func 100>` <br> Turn 1: `<description of func 1>`. Answer 1: `<func 1>` <br> Turn 2: The value of the `<key #1>` is? Answer 2: â€¦`<value #1>`.. |{{< /table-caption >}}
> ğŸ”¼ SCBenchì˜ ì‘ì—… ì˜ˆì‹œì™€ ì„¤ì •ì„ ë³´ì—¬ì£¼ëŠ” í‘œì…ë‹ˆë‹¤. ì§ˆë¬¸, ë‹µë³€, ì˜¤ë‹µì€ ê°ê° ë‹¤ë¥¸ ìƒ‰ê¹”ë¡œ ê°•ì¡°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Task examples and configurations in SCBench. We use different colors to highlight the questions, answers, and distractors in our examples.
> </details>

{{< table-caption >}}
|Retr.KV|
|---|{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë‹¤ì–‘í•œ ê¸°ë³¸ ëª¨ë¸ê³¼ ë‘ ê°€ì§€ ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ(ë©€í‹°í„´ ë° ë©€í‹°ìš”ì²­)ì—ì„œ ë‹¤ì–‘í•œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œì˜ SCBenchì— ëŒ€í•œ í‰ê·  ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama-3.1-70B, Qwen2.5-32B ë° Llama-3-8B-262Kì™€ ê°™ì€ ê¸°ë³¸ ëª¨ë¸ì— ëŒ€í•œ ì¶”ê°€ ê²°ê³¼ëŠ” Â§Dì˜ í‘œ 10ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤. ì—¬ê¸°ì„œ Ï„ëŠ” ëª©í‘œ ì••ì¶•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Average performance of various long-context methods across different base models in two shared context modes on SCBench. For additional results on base models such as Llama-3.1-70B, Qwen2.5-32B, and Llama-3-8B-262K, see TableÂ 10 in Â§D. Here, Ï„ğœ\tauitalic_Ï„ denotes the target compression rate.
> </details>

{{< table-caption >}}
| Lost in the Middle |
|---| 
| (Liu etÂ al., 2024d) |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì¿¼ë¦¬ ì¸ì‹ ë° ë¹„ì¸ì‹ ë¡± ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œ(SnapKV, Tri-shape, MInference)ì˜ ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì¿¼ë¦¬ ì¸ì‹ì€ ì²« ë²ˆì§¸ ê²°ê³¼ì— í•´ë‹¹í•˜ê³ , ì¿¼ë¦¬ ë¹„ì¸ì‹ì€ ë‘ ë²ˆì§¸ ê²°ê³¼ì— í•´ë‹¹í•˜ë©°, ë°‘ì¤„ì€ ì¿¼ë¦¬ ë¶€ì¬ ì‹œ ì„±ëŠ¥ ì €í•˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Results of query-awareness long-context methods. w/ (first) and w/o (later) query.
> </details>

{{< table-caption >}}
| num kv pairs = 2500 |
| --- |
| len of key & value = 36 |
| metric = Accuracy |{{< /table-caption >}}
> ğŸ”¼ í‘œ 6ì€ ë‹¤ì–‘í•œ ë¡± ì»¨í…ìŠ¤íŠ¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë¹„êµí•˜ê³  ìˆìŠµë‹ˆë‹¤. í‰ê°€ë˜ëŠ” ë¡± ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥, ê³ ë ¤ë˜ëŠ” ìš”ì²­ ìœ í˜• ë° êµ¬í˜„ëœ ì‚¬í•­ì— ë”°ë¼ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Comparison of Long-Context Benchmarks.
> </details>

{{< table-caption >}}
| Retr.Prefix-Suffix |
|---|{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ìš”ì•½ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. ì´ì „ ë²¤ì¹˜ë§ˆí¬(InfiniteBench ë° LongBench)ì™€ SCBenchì—ì„œ Llama-3.1-8B-Inst ëª¨ë¸ì— ëŒ€í•´ A-Shape, Tri-shape, MInference, StreamingLLM, SnapKV, LLMLinguaì™€ ê°™ì€ ì—¬ëŸ¬ ë©”ì„œë“œì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ SCBenchê°€ ë‹¤ì¤‘ ìš”ì²­ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë©”ì„œë“œì˜ ì•½ì ì„ ë” ì˜ ì‹ë³„í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Comparing the summarization capability of efficient long-context methods on prior benchmarks and our SCBench.
> </details>

{{< table-caption >}}
| Ours |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë‹¤ì–‘í•œ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì˜ ê²€ìƒ‰ ëŠ¥ë ¥ì„ ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬(InfiniteBench, LongBench)ì™€ SCBenchì—ì„œ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. SCBenchëŠ” íŠ¹íˆ ë‹¤ì¤‘ ìš”ì²­ ë° ë‹¤ì¤‘ í„´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ë§¥ë½ ë°©ë²•ì˜ ì•½ì ì„ ë” ì˜ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 8: Comparing the retrieval capability of efficient long-context methods on prior benchmarks and our SCBench.
> </details>

{{< table-caption >}}
| size of dict = 6000 |
|---| 
| len of string = [65, 123) |
| metric = Accuracy |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” SCBenchì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì— ëŒ€í•œ êµ¬ì„±ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. SSM(State Space Model), í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸, í¬ì†Œ ì£¼ì˜(Sparse Attention), KV ìºì‹œ ì••ì¶•, ì–‘ìí™”, ê²€ìƒ‰ ë° ë¡œë”©, í”„ë¡¬í”„íŠ¸ ì••ì¶•ì„ í¬í•¨í•œ ì—¬ëŸ¬ ë²”ì£¼ì˜ ë°©ë²•ì— ëŒ€í•œ íŠ¹ì • ë§¤ê°œë³€ìˆ˜ì™€ ì„¤ì •ì´ í‘œì— ìš”ì•½ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ë°©ë²•ì— ëŒ€í•œ êµ¬ì„± ì„¸ë¶€ ì •ë³´ì—ëŠ” ì²­í¬ í¬ê¸°, ì»¤ë„ í¬ê¸°, ì€ë‹‰ í¬ê¸°, ë ˆì´ì–´ ìˆ˜, ì£¼ì˜ í—¤ë“œ ìˆ˜, í¬ì†Œì„± ì˜ˆì‚°, ë¡œì»¬ ë° ì´ˆê¸° í† í° í¬ê¸°, ê´€ì¸¡ ì°½, ìµœëŒ€ ìš©ëŸ‰, ì»¤ë„ í¬ê¸° ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì˜ êµ¬í˜„ê³¼ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” íŠ¹ì • ì„¤ì •ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 9: Configurations of long-context methods in SCBench.
> </details>

{{< table-caption >}}
| Retr.MultiHop |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Llama-3.1-70B, Qwen2.5-32B, Llama-3-8B-262K ëª¨ë¸ì—ì„œ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½(long-context) ë©”ì„œë“œì˜ SCBenchì—ì„œì˜ í‰ê·  ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ê°€ì§€ ê³µìœ  ë§¥ë½ ëª¨ë“œ(multi-turn ë° multi-request)ì—ì„œ Retr.String, Retr.Semantic, Global, Multi-task ì‘ì—…ì— ëŒ€í•œ ê° ë©”ì„œë“œì˜ í‰ê·  ì •í™•ë„ê°€ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì‘ì—…ì—ì„œ ë‹¤ì–‘í•œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œì˜ íš¨ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 10: The average results of various long-context methods on Llama-3.1-70B, Qwen2.5-32B, and Llama-3-8B-262K with two shared context modes on SCBench.
> </details>

{{< table-caption >}}
| RULER |
| -------- |
| [Hsieh etÂ al. (2024)](https://arxiv.org/html/2412.10319/2412.10319v1#bib.bib34) |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë‹¤ì¤‘ í„´ ëª¨ë“œì—ì„œ ëª¨ë“  í•˜ìœ„ ì‘ì—…ì— ëŒ€í•œ SCBenchì˜ ì„¸ë¶€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ê³¼ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì ‘ê·¼ ë°©ì‹ì—ì„œ En.Sum ì‘ì—…ì— ëŒ€í•œ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ìš”ì•½ì˜ í’ˆì§ˆì€ ëª¨ë¸ ê·œëª¨ì™€ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ Llama-3.1-70B ë° Qwen2.5-72BëŠ” ë‹¤ë¥¸ ëª¨ë¸ì— ë¹„í•´ ë” í¬ê´„ì ì´ê³  ì„¸ë¶„í™”ëœ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì ‘ê·¼ ë°©ì‹ì˜ ê²½ìš°, Tri-Shape ë° MInferenceì™€ ê°™ì€ ê³ ë°€ë„ ë””ì½”ë”©ì„ ì‚¬ìš©í•˜ëŠ” í¬ì†Œ ì¸ì½”ë”© ë°©ë²•ì€ ì„¸ë¶€ì ì¸ ë‚´ìš©ì„ í¬ì°©í•˜ëŠ” ë° íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ StreamingLLMê³¼ ê°™ì€ í¬ì†Œ ë””ì½”ë”© ë°©ë²•ì€ ì‹¤íŒ¨í•˜ì—¬ ì„ì˜ì ì´ê³  ì¼ê´€ì„± ì—†ëŠ” ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.Retr.Prefix-Suffix ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. í¥ë¯¸ë¡­ê²Œë„ Mamba-Attention í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ Jambaê°€ ê°€ì¥ ì •í™•í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. Retr.Prefix-Suffix ì‘ì—…ì—ëŠ” ìƒë‹¹íˆ í° ê³µê°„ê³¼ ì‹œê°„ ë³µì¡ë„ê°€ í•„ìš”í•˜ë©° Mamba ë ˆì´ì–´ëŠ” ì´ëŸ¬í•œ ì°¨ì›ì—ì„œ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤ê³  ë³´ê³ ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ëŠ” ì¤‘ìš”í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, Llama ë° Qwen ì‹œë¦¬ì¦ˆ ëª¨ë¸ê³¼ ê°™ì€ ì „ì²´ ì£¼ì˜ LLMsëŠ” ëª¨ë‘ ì´ ì‘ì—…ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ì—¬ì „íˆ ê°€ë³€ ê¸¸ì´ì˜ ì ‘ë‘ì‚¬ë¥¼ ê¸°ì–µí•  ìˆ˜ ìˆì§€ë§Œ ì¢…ì¢… ì „ì²´ ë¬¸ìì—´ì„ ì¬í˜„í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ MInferenceë¥¼ ì‚¬ìš©í•˜ëŠ” Llama-70BëŠ” ê±°ì˜ ì „ì²´ ë¬¸ìì—´ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆì§€ë§Œ ì¤‘ê°„ì— ìˆëŠ” ì—¬ëŸ¬ ë¬¸ìì˜ ì² ìê°€ í‹€ë¦½ë‹ˆë‹¤. ì´ëŠ” Transformer ì–´í…ì…˜ í—¤ë“œì—ì„œ ìœ ë„ í—¤ë“œ(Olsson et al., 2022)ì˜ ì•½ì  ë•Œë¬¸ì¼ ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ¬í•œ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë°©ë²•ì— ëŒ€í•œ í¬ì†Œ ì…ë ¥ìœ¼ë¡œ ì¸í•´ ë°œìƒí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.ë˜í•œ, ë‹¤ì¤‘ ì‘ì—… í…ŒìŠ¤íŠ¸, ì¦‰ í‘œ 16ì˜ Mix.RepoQA+KVì— ëŒ€í•œ ì¼ë¶€ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì •ë‹µì€ KV ê²€ìƒ‰ì˜ ë‹µë³€ í•˜ë‚˜ì™€ reporqaì˜ ë‹µë³€ í•˜ë‚˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Llama-3.1-70Bì™€ MInferenceë¥¼ ì‚¬ìš©í•˜ëŠ” ë³€í˜•ì€ ëª¨ë‘ ê°’ì„ ì •í™•í•˜ê²Œ ê²€ìƒ‰í•˜ì—¬ í‚¤-ê°’ ê²€ìƒ‰ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Python í•¨ìˆ˜ë¥¼ ì¬í˜„í•œ ê²°ê³¼ëŠ” í¥ë¯¸ë¡œìš´ ì°¨ì´ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ ë“¤ì—¬ì“°ê¸°ë¥¼ ìœ ì§€í•˜ë©´ì„œ í•¨ìˆ˜ ë¡œì§ì— ì—¬ëŸ¬ ìˆ˜ì • ì‚¬í•­ì„ ë„ì…í•©ë‹ˆë‹¤. Llama-3.1-70BëŠ” ì˜ëª»ëœ í•¨ìˆ˜ ì´ë¦„ì„ ì¬í˜„í•˜ê³  ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ì§€ë§Œ ì›ë˜ ìš”ì†ŒëŠ” ì œí•œì ìœ¼ë¡œë§Œ ìœ ì§€í•©ë‹ˆë‹¤. MInference ë³€í˜•ì€ ê¸°ë³¸ ëª¨ë¸ì˜ ì¶œë ¥ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ë©° Python ì½”ë“œ ë¸”ë¡ ì‹ë³„ì ì¶”ê°€ì™€ ê°™ì€ ì‚¬ì†Œí•œ ì°¨ì´ì ë§Œ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë‘ ëª¨ë¸ ëª¨ë‘ ì •ë‹µ í•¨ìˆ˜ë¥¼ ì •í™•í•˜ê²Œ ë³µì œí•˜ì§€ ì•Šì•„ ì •í™•í•œ í•¨ìˆ˜ ì¬í˜„ì— ì–´ë ¤ì›€ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ MInferenceì˜ ê²°ê³¼ëŠ” ì¸ì½”ë”© ë°©ì‹ì˜ í¬ì†Œ íŠ¹ì„±ë³´ë‹¤ëŠ” ê¸°ë³¸ Llama ëª¨ë¸ì˜ ì œí•œëœ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ê¸°ëŠ¥ ë•Œë¬¸ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.í‘œ 17ì—ì„œëŠ” Retr.KVì—ì„œ A-shape ë° Tri-shape ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤. íŠ¹íˆ Tri-shapeëŠ” ì²« ë²ˆì§¸ í„´ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° ëª¨ë¸ì˜ ì§€ì¹¨ ì¤€ìˆ˜ ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ A-shapeëŠ” ëª¨ë¸ì˜ ì´ˆê¸° ì‘ë‹µì„ ë°©í•´í•˜ì—¬ ì „ë°˜ì ì¸ ì‘ì—… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì°¨ì´ì ì€ Tri-shapeê°€ ì²˜ìŒë¶€í„° ì‘ì—… êµ¬ì¡°ì™€ ì´í•´ë¥¼ ìœ ì§€í•˜ëŠ” ë° ìœ ë¦¬í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì´ëŸ¬í•œ ê²°ê³¼ê°€ ì´ì „ ë²¤ì¹˜ë§ˆí¬ì˜ ê²°ê³¼ì™€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì„¤ëª…í•˜ê³ , í¬ì†Œ ì¸ì½”ë”©ê³¼ ë””ì½”ë”© ë°©ë²•ì˜ ì„±ëŠ¥ ì°¨ì´, ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì‘ì—… ì í•©ì„±, ê·¸ë¦¬ê³  ì˜¤ë¥˜ ì „íŒŒ ë° ëª¨ë¸ ìƒì„±ì˜ ì˜í–¥ê³¼ ê°™ì€ ëª‡ ê°€ì§€ ì¤‘ìš”í•œ ì§ˆë¬¸ì„ ë‹¤ë£¹ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 11: The results breakdown of SCBench for all sub-tasks in multi-turn mode.
> </details>

{{< table-caption >}}
| num chains = 2 |
| -------- |
| num hops = 2 |
| metric = Accuracy |{{< /table-caption >}}
> ğŸ”¼ ì´ í…Œì´ë¸”ì€ ë‹¤ì–‘í•œ í•˜ìœ„ ì‘ì—…ì— ëŒ€í•œ ì—¬ëŸ¬ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë‹¤ì¤‘ ìš”ì²­ ëª¨ë“œì—ì„œ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. Retr.KV ë° Retr.PSì™€ ê°™ì€ ê²€ìƒ‰ ì‘ì—…, En.QA ë° Zh.QAì™€ ê°™ì€ QA, En.Sumê³¼ ê°™ì€ ìš”ì•½, RepoQAì™€ ê°™ì€ ì½”ë“œ ì´í•´, ìˆ˜í•™ ë° ICLê³¼ ê°™ì€ ë¬¸ë§¥ ë‚´ í•™ìŠµì„ í¬í•¨í•©ë‹ˆë‹¤. ê° ë°©ë²•ì€ ì´ëŸ¬í•œ ì˜ì—­ì—ì„œ ë‹¤ì–‘í•œ ê°•ì ê³¼ ì•½ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ StreamingLLM ë° SnapKVì™€ ê°™ì€ ì¼ë¶€ ë°©ë²•ì€ ì—¬ëŸ¬ ëª¨ë“œì—ì„œ ê²€ìƒ‰ ë° ìˆ˜í•™ ì‘ì—…ì—ì„œ ê±°ì˜ ë˜ëŠ” ì „í˜€ ì„±ëŠ¥ì„ ë³´ì´ì§€ ì•ŠëŠ” ë°˜ë©´ GLM-4-1M ë° MInferenceì™€ ê°™ì€ ë‹¤ë¥¸ ë°©ë²•ì€ ê²€ìƒ‰, QA ë° ICLì—ì„œ ì§€ì†ì ìœ¼ë¡œ ì˜ ìˆ˜í–‰ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 12: The results breakdown of SCBench for all sub-tasks in multi-requests mode.
> </details>

{{< table-caption >}}
| Code.RepoQA |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ ë‹¤ìŒ ì§ˆë¬¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°(ì¦‰, ì •ë‹µì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°)ì˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. í‘œì˜ ë‘ ë²ˆì§¸ ìˆ«ìëŠ” ì •ë‹µì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì™€ ë¹„êµí•œ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 13: Results when disabling golden answer as context. The later number indicate the gap compared to golden-answer-as-context.
> </details>

{{< table-caption >}}
| RepoQA |
| -------- |
| [Liu etÂ al., 2024c](https://arxiv.org/html/2412.10319/bib.bib52) |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ê³¼ ì¥ë¬¸ ë§¥ë½ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•œ En.Sum ê³¼ì œì— ëŒ€í•œ ìš”ì•½ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. í‘œì—ì„œ íŒŒë€ìƒ‰ì€ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŒì„ ë‚˜íƒ€ë‚´ê³  ì£¼í™©ìƒ‰ì€ ëª¨ë¸ì´ í™˜ê°ì„ ì¼ìœ¼ì¼°ì„ ê°€ëŠ¥ì„±ì´ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìš”ì•½ì˜ í’ˆì§ˆì€ ëª¨ë¸ í¬ê¸°ì™€ ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ Llama-3.1-70Bì™€ Qwen2.5-72BëŠ” ë‹¤ë¥¸ ëª¨ë¸ì— ë¹„í•´ ë” í¬ê´„ì ì´ê³  ì„¸ë¶„í™”ëœ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ì¥ë¬¸ ë§¥ë½ ì ‘ê·¼ ë°©ì‹ì˜ ê²½ìš°, Tri-Shape ë° MInferenceì™€ ê°™ì€ dense ë””ì½”ë”©ì„ ì‚¬ìš©í•œ sparse ì¸ì½”ë”© ë°©ë²•ì€ ì„¸ë¶€ì ì¸ ë‚´ìš©ì„ íŒŒì•…í•˜ëŠ” ë° ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ StreamingLLMê³¼ ê°™ì€ sparse ë””ì½”ë”© ë°©ë²•ì€ ì‹¤íŒ¨í•˜ì—¬ ë¬´ì‘ìœ„ì ì´ê³  ì¼ê´€ì„± ì—†ëŠ” ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 14: Case Study of En.Sum. We use blue to indicate mising informaiton, and orange to mark potential hallucination.
> </details>

{{< table-caption >}}
| func description from GPT-4 |
| ------------------------- |
| metric = Pass@1 |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë¬¸ìì—´ ê²€ìƒ‰ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” Retr.Prefix-Suffix ê³¼ì œì— ëŒ€í•œ ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ ì—°êµ¬ì…ë‹ˆë‹¤. ê° ëª¨ë¸ì€ ì£¼ì–´ì§„ ì ‘ë‘ì‚¬ì™€ ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§„ ë¬¸ìì—´ì„ ê²€ìƒ‰í•´ì•¼ í•˜ë©°, ì˜ˆì‹œ ì‘ë‹µì€ ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ ë‹¤ë¥¸ ë¶€ë¶„ì„ ì£¼í™©ìƒ‰ìœ¼ë¡œ ê°•ì¡° í‘œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° ëª¨ë¸ì´ ì ‘ë‘ì‚¬ì™€ ì ‘ë¯¸ì‚¬ë¥¼ ì •í™•í•˜ê²Œ ì¼ì¹˜ì‹œí‚¤ëŠ” ëŠ¥ë ¥ê³¼ ë¬¸ìì—´ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì„ ì˜¬ë°”ë¥´ê²Œ ì¬í˜„í•˜ëŠ” ëŠ¥ë ¥ì„ ìì„¸íˆ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, Jamba-1.5-Mini ëª¨ë¸ì€ ê°€ì¥ ì •í™•í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°˜ë©´, Llama ë° Qwen ì‹œë¦¬ì¦ˆì™€ ê°™ì€ Full-attention LLMì€ ì´ ì‘ì—…ì— ì‹¤íŒ¨í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì ‘ê·¼ ë°©ì‹ ì¤‘ì—ì„œ Sparse Encoding with Dense Decoding ë°©ì‹ì¸ Tri-Shape ë° MInferenceê°€ ì„¸ë¶€ ì •ë³´ë¥¼ ì˜ ìº¡ì²˜í•˜ëŠ” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°˜ë©´, StreamingLLMê³¼ ê°™ì€ Sparse Decoding ë°©ì‹ì€ ì‹¤íŒ¨í•˜ì—¬ ë¬´ì‘ìœ„ì ì´ê³  ì¼ê´€ì„± ì—†ëŠ” ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 15: Case Study of Retr.Prefix-Suffix. Orange is used to mark the difference of model response compared to the ground truth.
> </details>

{{< table-caption >}}
| En.QA |
| --- |
| Zh.QA |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Mix.RepoQA + KV ì‘ì—…ì— ëŒ€í•œ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì£¼í™©ìƒ‰ì€ ëª¨ë¸ì˜ ì ì¬ì  í™˜ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Llama-3.1-70Bì™€ MInference ë³€í˜• ëª¨ë‘ KV ê²€ìƒ‰ì—ì„œ ì •í™•í•˜ê²Œ ê°’ì„ ê²€ìƒ‰í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ë§Œ, Python í•¨ìˆ˜ë¥¼ ì¬í˜„í•  ë•ŒëŠ” ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ ì „ì²´ êµ¬ì¡°ì™€ ë“¤ì—¬ì“°ê¸°ë¥¼ ìœ ì§€í•˜ì§€ë§Œ í•¨ìˆ˜ ë¡œì§ì— ëª‡ ê°€ì§€ ìˆ˜ì • ì‚¬í•­ì„ ë„ì…í•©ë‹ˆë‹¤. Llama-3.1-70BëŠ” ì˜ëª»ëœ í•¨ìˆ˜ ì´ë¦„ì„ ì¬í˜„í•˜ê³  ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ë©´ì„œ ì›ë³¸ ìš”ì†Œë§Œ ì œí•œì ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤. MInference ë³€í˜•ì€ ê¸°ë³¸ ëª¨ë¸ì˜ ì¶œë ¥ê³¼ ê±°ì˜ ìœ ì‚¬í•˜ë©° Python ì½”ë“œ ë¸”ë¡ ì‹ë³„ì ì¶”ê°€ì™€ ê°™ì€ ì‚¬ì†Œí•œ ì°¨ì´ë§Œ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë‘ ëª¨ë¸ ëª¨ë‘ ì •í™•í•˜ê²Œ í•¨ìˆ˜ë¥¼ ë³µì œí•˜ì§€ ëª»í•˜ì—¬ ì •í™•í•œ í•¨ìˆ˜ ì¬í˜„ì— ì–´ë ¤ì›€ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. MInference ê²°ê³¼ëŠ” ì¸ì½”ë”© ì ‘ê·¼ ë°©ì‹ì˜ í¬ì†Œ íŠ¹ì„±ì´ ì•„ë‹Œ ê¸°ë³¸ Llama ëª¨ë¸ì˜ ì œí•œëœ ì¥ê¸° ë¬¸ë§¥ ê¸°ëŠ¥ ë•Œë¬¸ì¸ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 16: Case Study of Mix.RepoQA + KV. Orange indicate the potential model hallucination.
> </details>

{{< table-caption >}}
| InfiniteBench |
| --- |
| [Zhang etÂ al., 2024a](https://arxiv.org/html/2412.10319/2412.10319v1#bib.bib93) |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” Retr.KV ì‘ì—…ì—ì„œ A-shapeì™€ Tri-shapeë¥¼ ë¹„êµí•œ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Tri-shapeëŠ” ì²« ë²ˆì§¸ í„´ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ ëª¨ë¸ì˜ ì§€ì‹œ ë”°ë¥´ê¸° ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœ ì§€í•˜ëŠ” ë°˜ë©´, A-shapeëŠ” ëª¨ë¸ì˜ ì´ˆê¸° ì‘ë‹µì„ ë°©í•´í•˜ì—¬ ì „ë°˜ì ì¸ ì‘ì—… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 17: Case Study of Retr.KV to compare A-shape and Tri-shape.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}