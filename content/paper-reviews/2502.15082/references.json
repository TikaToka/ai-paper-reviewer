{"references": [{"fullname_first_author": "Meng", "paper_title": "Locating and editing factual associations in GPT", "publication_date": "2022-12-01", "reason": "This paper is foundational to the current work as it introduces model editing, a core concept explored and extended in this research."}, {"fullname_first_author": "Cao", "paper_title": "Towards making systems forget with machine unlearning", "publication_date": "2015-05-18", "reason": "This paper is crucial because it pioneers the concept of machine unlearning, the central focus of the current study."}, {"fullname_first_author": "Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-12-01", "reason": "This work is highly relevant as it introduces a widely-used unlearning method, Refusal, which is evaluated and compared in this research."}, {"fullname_first_author": "Maini", "paper_title": "TOFU: A task of fictitious unlearning for LLMs", "publication_date": "2024-01-01", "reason": "This paper provides the benchmark dataset used for evaluating unlearning methods, thus providing the context and metrics for evaluating the proposed approach."}, {"fullname_first_author": "Zhang", "paper_title": "Negative preference optimization: From catastrophic collapse to effective unlearning", "publication_date": "2024-04-01", "reason": "This work introduces another significant unlearning method, Negative Preference Optimization (NPO), which is a key component of the comparative analysis."}]}