[{"figure_path": "https://arxiv.org/html/2502.06329/x1.png", "caption": "Figure 1: FailSafeQA: Robustness and Context Grounding Evaluation We evaluate the resilience of an LLM-based QA system in two case studies: Query Failure and Context Failure. In the Query Failure scenario, we perturb the original query into three variants: containing spelling errors (Misspelled Query), query-term form (Incomplete Query), rephrased to exclude in-domain terminology (Out-of-Domain Query). In the Context Failure case, we assume users can either fail to upload the document (Missing Context) , use degraged quality documents due to OCR (OCRed Context) or upload a document irrelevant to the query (Irrelevant Context). Robustness involves maintaining consistent model performance across perturbations (A)-(C) and (E), which preserve the intended meaning, while Context Grounding involves preventing hallucinations in scenarios (D) and (F).", "description": "\uadf8\ub9bc 1\uc740 FailSafeQA \ubca4\uce58\ub9c8\ud06c\uc758 \ud575\uc2ec \uac1c\ub150\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  FailSafeQA\ub294 \uae08\uc735 \ubd84\uc57c\uc5d0\uc11c LLM \uae30\ubc18 \uc9c8\uc758\uc751\ub2f5 \uc2dc\uc2a4\ud15c\uc758 \uac15\uac74\uc131\uacfc \ub9e5\ub77d \uc778\uc2dd \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \uc9c8\uc758 \uc624\ub958(Query Failure) \uc2dc\ub098\ub9ac\uc624\uc640 \ub9e5\ub77d \uc624\ub958(Context Failure) \uc2dc\ub098\ub9ac\uc624\uc758 \ub450 \uac00\uc9c0 \uc0ac\ub840 \uc5f0\uad6c\uc5d0 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4. \uc9c8\uc758 \uc624\ub958 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c\ub294 \ucca0\uc790 \uc624\ub958, \uc9c8\uc758\uc5b4 \ud615\ud0dc \ubcc0\uacbd, \ub3c4\uba54\uc778 \uc804\ubb38 \uc6a9\uc5b4 \uc81c\uc678\ub97c \ud1b5\ud55c \uc9c8\uc758 \uc218\uc815 \ub4f1 \uc138 \uac00\uc9c0 \ubcc0\ud615\uc744 \ud1b5\ud574 \uc6d0\ub798 \uc9c8\uc758\ub97c \ubcc0\uacbd\ud569\ub2c8\ub2e4. \ub9e5\ub77d \uc624\ub958 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c\ub294 \uc0ac\uc6a9\uc790\uac00 \ubb38\uc11c\ub97c \uc5c5\ub85c\ub4dc\ud558\uc9c0 \ubabb\ud558\uac70\ub098, OCR\ub85c \uc778\ud574 \uc800\ud558\ub41c \ud488\uc9c8\uc758 \ubb38\uc11c\ub97c \uc0ac\uc6a9\ud558\uac70\ub098, \uc9c8\uc758\uc640 \uad00\ub828 \uc5c6\ub294 \ubb38\uc11c\ub97c \uc5c5\ub85c\ub4dc\ud558\ub294 \uc138 \uac00\uc9c0 \uc0c1\ud669\uc744 \uc2dc\ubbac\ub808\uc774\uc158\ud569\ub2c8\ub2e4. \uac15\uac74\uc131(Robustness) \uc810\uc218\ub294 \uc758\ub3c4\ub41c \uc758\ubbf8\ub97c \uc720\uc9c0\ud558\ub294 \ubcc0\ud615(A~C, E)\uc5d0 \ub300\ud55c \ubaa8\ub378 \uc131\ub2a5\uc758 \uc77c\uad00\uc131\uc744 \ud3c9\uac00\ud558\uace0, \ub9e5\ub77d \uae30\ubc18(Context Grounding) \uc810\uc218\ub294 \uc2dc\ub098\ub9ac\uc624(D, F)\uc5d0\uc11c\uc758 \ud658\uac01\uc744 \ubc29\uc9c0\ud558\ub294 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "1 Introduction"}, {"figure_path": "https://arxiv.org/html/2502.06329/extracted/6191732/assets/verb_dobj_base_new.png", "caption": "Figure 2: The Dataset Analysis of root verbs and their direct objects from the first sentence of each normalized query shows the top 20 verbs and their top five direct objects22footnotemark: 2. This distribution can be used as a proxy measure for the diversity of tasks in the dataset, with 83.0% related to question answering (QA) and 17.0% involving text generation (TG).", "description": "\uadf8\ub9bc 2\ub294 \uc815\uaddc\ud654\ub41c \uac01 \uc9c8\ubb38\uc758 \uccab \ubc88\uc9f8 \ubb38\uc7a5\uc5d0\uc11c \uc8fc\uc5b4 \ub3d9\uc0ac\uc640 \ubaa9\uc801\uc5b4\ub97c \ubd84\uc11d\ud558\uc5ec \uc0c1\uc704 20\uac1c \ub3d9\uc0ac\uc640 \uc0c1\uc704 5\uac1c \ubaa9\uc801\uc5b4\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ubd84\ud3ec\ub294 \uc9c8\ubb38 \ub2f5\ubcc0(QA) \uad00\ub828 \uc791\uc5c5\uc774 83.0%, \ud14d\uc2a4\ud2b8 \uc0dd\uc131(TG) \uad00\ub828 \uc791\uc5c5\uc774 17.0%\ub97c \ucc28\uc9c0\ud558\ub294 \ub370\uc774\ud130\uc14b\uc758 \uc791\uc5c5 \ub2e4\uc591\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub300\ub7b5\uc801\uc778 \uc9c0\ud45c\ub85c \ud65c\uc6a9\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 FailSafeQA Dataset"}, {"figure_path": "https://arxiv.org/html/2502.06329/x2.png", "caption": "Figure 3: Answer Relevance Classes We evaluate two scenarios in our benchmark: when models should provide an answer (ANSWER QUERY) and when they must decline to answer (REFUSE QUERY) due to lack of relevant context. Our findings reveal that all the tested models are more adept at offering suitable answers than providing a justified refusal in situations where the context lacks sufficient information. Among all models evaluated, Palmyra-Fin-128k-Instruct demonstrates the most effective balance between these capabilities.", "description": "\uadf8\ub9bc 3\uc740 \ubaa8\ub378\uc774 \ub2f5\ubcc0\uc744 \uc81c\uacf5\ud574\uc57c \ud558\ub294 \uacbd\uc6b0(ANSWER QUERY)\uc640 \uad00\ub828 \ucee8\ud14d\uc2a4\ud2b8\uac00 \ubd80\uc871\ud558\uc5ec \ub2f5\ubcc0\uc744 \uac70\ubd80\ud574\uc57c \ud558\ub294 \uacbd\uc6b0(REFUSE QUERY)\uc758 \ub450 \uac00\uc9c0 \uc2dc\ub098\ub9ac\uc624\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\ud5d8 \uacb0\uacfc, \ubaa8\ub4e0 \ubaa8\ub378\uc774 \ucee8\ud14d\uc2a4\ud2b8\uac00 \ucda9\ubd84\ud558\uc9c0 \uc54a\uc740 \uc0c1\ud669\uc5d0\uc11c \uc815\ub2f9\ud55c \uac70\ubd80\ubcf4\ub2e4 \uc801\uc808\ud55c \ub2f5\ubcc0\uc744 \uc81c\uacf5\ud558\ub294 \ub370 \ub354 \ub2a5\uc219\ud55c \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \ud3c9\uac00\ub41c \ubaa8\ub4e0 \ubaa8\ub378 \uc911\uc5d0\uc11c Palmyra-Fin-128k-Instruct \ubaa8\ub378\uc774 \ub450 \uac00\uc9c0 \uae30\ub2a5 \uac04\uc758 \uade0\ud615\uc744 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc73c\ub85c \ub9de\ucd98 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.", "section": "3 Metrics"}, {"figure_path": "https://arxiv.org/html/2502.06329/x3.png", "caption": "Figure 4: Robustness and Compliance (Left) All models lose with respect to the baseline when input perturbations are applied. The biggest drop is observed for Out-Of-Domain and OCR context perturbations. Among the 24242424 tested models, OpenAI o3-mini is the most robust. (Right) Reasoning models like OpenAI-o1/o3-mini and the DeepSeek-R1 series reach scores up to 0.590.590.590.59, while Qwen models consistently surpass 0.600.600.600.60. Palmyra-Fin-128k-Instruct excels with the highest Context Grounding score of 0.800.800.800.80.", "description": "\uadf8\ub9bc 4\ub294 \ubaa8\ub378\uc758 \uac15\uac74\uc131(Robustness)\uacfc \ub9e5\ub77d \uae30\ubc18(Context Grounding) \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ub2e4\uc591\ud55c \uc785\ub825 \uc12d\ub3d9(perturbation)\uc774 \uc801\uc6a9\ub418\uc5c8\uc744 \ub54c, 24\uac1c \ubaa8\ub378\uc758 \uc131\ub2a5 \uc800\ud558\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, \ub3c4\uba54\uc778 \uc678\ubd80 \uc9c8\ubb38(Out-of-Domain)\uacfc OCR \uc624\ub958\uac00 \ud3ec\ud568\ub41c \ub9e5\ub77d(OCR context)\uc5d0\uc11c \uc131\ub2a5 \uc800\ud558\uac00 \uac00\uc7a5 \ucef8\uc2b5\ub2c8\ub2e4. OpenAI o3-mini \ubaa8\ub378\uc774 \uac00\uc7a5 \uac15\uac74\ud55c \ubaa8\ub378\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 OpenAI-o1/o3-mini \ubc0f DeepSeek-R1 \uacc4\uc5f4\uacfc \uac19\uc740 \ucd94\ub860 \ubaa8\ub378\uc774 \ucd5c\ub300 0.59\uc810\uc758 \uc810\uc218\ub97c \ub2ec\uc131\ud55c \ubc18\uba74, Qwen \ubaa8\ub378\uc740 \uc77c\uad00\ub418\uac8c 0.60\uc810\uc744 \uc0c1\ud68c\ud558\ub294 \uc131\ub2a5\uc744 \ubcf4\uc600\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Palmyra-Fin-128k-Instruct \ubaa8\ub378\uc740 0.80\uc810\uc758 \ucd5c\uace0 \ub9e5\ub77d \uae30\ubc18 \uc810\uc218\ub97c \uae30\ub85d\ud588\uc2b5\ub2c8\ub2e4.", "section": "4 Evaluation"}, {"figure_path": "https://arxiv.org/html/2502.06329/extracted/6191732/assets2/robustness_query_type.png", "caption": "Figure 5: Robustness vs. Query Type. (Left) Across all models, the decrease in robustness is more prominent in text generation (TG) than in question-answering (QA) tasks. (Right) Similar statement also holds true for Context Grounding - when a model is asked to generate text (e.g., a blog post), it is more likely to ignore the lack of relevant information and fabricate details. For almost all models, it is easier to refuse to answer based on a wrong document (irrelevant context) than to deal with empty context (e.g., due to a failed document upload).", "description": "\uadf8\ub9bc 5\ub294 \uc9c8\ubb38 \uc720\ud615\uc5d0 \ub530\ub978 \uacac\uace0\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ubaa8\ub4e0 \ubaa8\ub378\uc5d0\uc11c \uc9c8\ubb38 \ub2f5\ubcc0(QA) \uc791\uc5c5\ubcf4\ub2e4 \ud14d\uc2a4\ud2b8 \uc0dd\uc131(TG) \uc791\uc5c5\uc5d0\uc11c \uacac\uace0\uc131 \uac10\uc18c\uac00 \ub354 \ub450\ub4dc\ub7ec\uc9d0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 \uc798\ubabb\ub41c \ubb38\uc11c(\ubb34\uad00\ud55c \ub9e5\ub77d)\ub97c \uae30\ubc18\uc73c\ub85c \ub2f5\ubcc0\uc744 \uac70\ubd80\ud558\ub294 \uac83\uc774 \ube48 \ub9e5\ub77d(\uc608: \ubb38\uc11c \uc5c5\ub85c\ub4dc \uc2e4\ud328)\uc744 \ucc98\ub9ac\ud558\ub294 \uac83\ubcf4\ub2e4 \uac70\uc758 \ubaa8\ub4e0 \ubaa8\ub378\uc5d0\uc11c \ub354 \uc27d\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788 \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud558\ub3c4\ub85d \uc694\uccad\ubc1b\uc558\uc744 \ub54c(\uc608: \ube14\ub85c\uadf8 \uac8c\uc2dc\ubb3c), \uad00\ub828 \uc815\ubcf4\uc758 \ubd80\uc871\uc744 \ubb34\uc2dc\ud558\uace0 \uc138\ubd80 \uc815\ubcf4\ub97c \uc870\uc791\ud560 \uac00\ub2a5\uc131\uc774 \ub354 \ud07d\ub2c8\ub2e4.", "section": "5 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2502.06329/extracted/6191732/assets2/context_grounding_query_type.png", "caption": "Figure 6: Context Grounding vs. Query Type. (Left) Across all models, the decrease in robustness is more prominent in text generation (TG) than in question-answering (QA) tasks. (Right) Similar statement also holds true for Context Grounding - when a model is asked to generate text (e.g., a blog post), it is more likely to ignore the lack of relevant information and fabricate details. For all models, it is easier to refuse to answer based on a wrong document (irrelevant context) than to deal with empty context (e.g., due to a failed document upload).", "description": "\uadf8\ub9bc 6\uc740 \ubaa8\ub378\uc758 \ub9e5\ub77d \uae30\ubc18 \uc774\ud574 \ub2a5\ub825(Context Grounding)\uc774 \uc9c8\uc758 \uc720\ud615(\uc9c8\ubb38/\ub2f5\ubcc0(QA) vs. \ud14d\uc2a4\ud2b8 \uc0dd\uc131(TG))\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ub2ec\ub77c\uc9c0\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504\ub294 \ubaa8\ub4e0 \ubaa8\ub378\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uc791\uc5c5\uc758 \uac15\uac74\uc131(Robustness)\uc774 \uc9c8\ubb38/\ub2f5\ubcc0 \uc791\uc5c5\ubcf4\ub2e4 \ub354 \ud06c\uac8c \uac10\uc18c\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504\ub294 \ub9e5\ub77d \uae30\ubc18 \uc774\ud574 \ub2a5\ub825 \uc5ed\uc2dc \uc720\uc0ac\ud55c \uacbd\ud5a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8(\uc608: \ube14\ub85c\uadf8 \uac8c\uc2dc\ubb3c)\ub97c \uc0dd\uc131\ud558\ub77c\ub294 \uc694\uccad\uc744 \ubc1b\uc73c\uba74 \uad00\ub828 \uc815\ubcf4\uac00 \ubd80\uc871\ud558\ub354\ub77c\ub3c4 \ubb34\uc2dc\ud558\uace0 \uc138\ubd80 \uc815\ubcf4\ub97c \ub9cc\ub4e4\uc5b4\ub0bc \uac00\ub2a5\uc131\uc774 \ub354 \ub192\uc2b5\ub2c8\ub2e4. \ubaa8\ub4e0 \ubaa8\ub378\uc5d0\uc11c \uc798\ubabb\ub41c \ubb38\uc11c(\ubb34\uad00\ud55c \ub9e5\ub77d)\ub97c \uae30\ubc18\uc73c\ub85c \ub2f5\ubcc0\uc744 \uac70\ubd80\ud558\ub294 \uac83\uc774 \ube48 \ub9e5\ub77d(\uc608: \ubb38\uc11c \uc5c5\ub85c\ub4dc \uc2e4\ud328)\uc744 \ub2e4\ub8e8\ub294 \uac83\ubcf4\ub2e4 \ub354 \uc27d\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5 Results"}]