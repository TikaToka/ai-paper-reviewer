---
title: "Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation"
summary: "Show-o Turbo: 이미지와 텍스트 생성 속도를 획기적으로 향상시킨 다중 모달리티 모델"
categories: ["AI Generated", "🤗 Daily Papers"]
tags: ["Multimodal Learning", "Vision-Language Models", "🏢 Shanghai Jiao Tong University",]
showSummary: true
date: 2025-02-08
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.05415 {{< /keyword >}}
{{< keyword icon="writer" >}} Chenkai Xu et el. {{< /keyword >}}
 
{{< keyword >}} 🤗 2025-02-11 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.05415" target="_self" >}}
↗ arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.05415" target="_self" >}}
↗ Hugging Face
{{< /button >}}




### TL;DR


{{< lead >}}

기존의 통합 다중 모달리티 모델인 Show-o는 이미지와 텍스트를 생성하는 데 많은 샘플링 단계가 필요하여 비효율적이었습니다. 이는 **이미지 토큰의 점진적 잡음 제거 및 텍스트 토큰의 자동 회귀적 디코딩**으로 인해 발생했습니다. 이러한 문제를 해결하기 위해, 연구진은 Show-o Turbo를 제안했습니다.

Show-o Turbo는 **이미지와 텍스트 생성을 통합된 잡음 제거 관점**으로 해석하여, **일관성 증류 기법을 다중 모달리티에 적용**함으로써 모델의 샘플링 단계를 줄였습니다.  **트래젝토리 분할 전략과 커리큘럼 학습**을 통해 학습 과정의 안정성을 높였고, 벤치마크 평가 결과 텍스트-이미지 생성에서 샘플링 단계를 줄이면서 성능을 개선하고, 이미지-텍스트 생성에서 속도 향상을 달성했습니다.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} Show-o Turbo는 **일관성 증류 기법을 활용하여 이미지와 텍스트 생성 속도를 크게 향상**시켰습니다. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} 본 연구는 **텍스트 생성에 대한 통합된 잡음 제거 관점**을 제시하고, 이미지와 텍스트 생성 과정을 통합적으로 다루었습니다. {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} Show-o Turbo는 다양한 벤치마크에서 **경쟁력 있는 성능**을 보였으며, 특히 이미지 생성의 경우 샘플링 단계를 줄이면서도 **GenEval 점수가 0.625**로 향상되었습니다. {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
본 논문은 **다양한 모달리티를 통합하는 통합 모델의 효율성을 높이는 데 크게 기여**합니다. 기존의 느린 처리 속도 문제를 해결하여 실제 응용 분야에서의 활용 가능성을 높였으며, **일관성 증류 기법을 다중 모달리티에 확장 적용**한 혁신적인 접근 방식을 제시합니다. 이는 향후 **다중 모달리티 연구 분야의 발전에 큰 영향**을 미칠 것으로 예상되며, 새로운 연구 방향을 제시할 수 있습니다.  특히, **대규모 모델의 효율적인 학습 및 추론에 대한 연구**에 중요한 시사점을 제공합니다.

------
#### Visual Insights



![](https://arxiv.org/html/2502.05415/x1.png)

> 🔼 그림 1은 Show-o Turbo 모델이 다양한 텍스트 프롬프트를 받아 생성한 512x512 픽셀 이미지들을 보여줍니다.  상단부터 하단으로 이미지는 각각 8, 4, 2개의 샘플링 단계를 거쳐 생성되었으며, 분류기 없는 안내(classifier-free guidance) [20]를 사용하지 않았습니다. 이는 Show-o Turbo 모델이 적은 샘플링 단계로도 고품질 이미지 생성이 가능함을 시각적으로 보여주는 예시입니다.
> <details>
> <summary>read the caption</summary>
> Figure 1: 512 ×\times× 512 images generated by Show-o Turbo given various text prompts. From top to bottom, the images are generated by Show-o Turbo in 8, 4, and 2 sampling steps without reliance on classifier-free guidance [20].
> </details>





{{< table-caption >}}
| Steps | Model | CFG | AVG | TO | CT | P | CL | SO | CA | HPS ↑ | IR ↑ | CS ↑ | Time (sec) ↓ |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---| 
| 16 | Show-o | 10 | **0.674** | **0.823** | 0.647 | 0.288 | 0.838 | 0.984 | **0.463** | **0.277** | **0.992** | **0.318** | 1.39 |
|  | Show-o | 5 | 0.672 | 0.778 | 0.666 | 0.293 | 0.835 | 0.991 | 0.468 | 0.270 | 0.885 | **0.318** | 1.39 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.649 | 0.793 | 0.644 | 0.253 | 0.809 | 0.956 | 0.440 | 0.266 | 0.768 | 0.315 | 0.77 |
|  | Show-o Turbo | 0 | 0.646 | 0.818 | 0.597 | 0.218 | 0.827 | 0.984 | 0.430 | 0.273 | 0.925 | **0.318** | 0.77 |
| 8 | Show-o | 10 | 0.578 | 0.631 | 0.519 | 0.235 | 0.811 | 0.991 | 0.280 | 0.257 | 0.672 | 0.313 | 0.76 |
|  | Show-o | 5 | 0.580 | 0.647 | 0.584 | 0.225 | 0.766 | 0.984 | 0.275 | 0.255 | 0.632 | 0.313 | 0.76 |
|  | Show-o Turbo<sup>∗</sup> | 0 | **0.642** | 0.788 | 0.631 | 0.253 | 0.787 | 0.981 | 0.413 | 0.264 | 0.800 | 0.315 | 0.46 |
|  | Show-o Turbo | 0 | 0.638 | 0.813 | 0.541 | 0.250 | 0.814 | 0.991 | 0.420 | **0.273** | **0.963** | **0.318** | 0.46 |
| 4 | Show-o | 10 | 0.353 | 0.237 | 0.325 | 0.095 | 0.540 | 0.863 | 0.060 | 0.197 | -0.560 | 0.283 | 0.44 |
|  | Show-o | 5 | 0.396 | 0.298 | 0.334 | 0.158 | 0.572 | 0.925 | 0.088 | 0.207 | -0.300 | 0.294 | 0.44 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.596 | 0.692 | 0.553 | 0.218 | 0.758 | 0.978 | 0.375 | 0.249 | 0.633 | 0.312 | 0.30 |
|  | Show-o Turbo | 0 | **0.625** | 0.770 | 0.553 | 0.245 | 0.806 | 0.978 | 0.398 | **0.269** | **0.934** | **0.318** | 0.30 |
| 2 | Show-o | 10 | 0.181 | 0.025 | 0.131 | 0.008 | 0.327 | 0.588 | 0.008 | 0.140 | -1.756 | 0.246 | 0.29 |
|  | Show-o | 5 | 0.251 | 0.051 | 0.188 | 0.038 | 0.442 | 0.778 | 0.010 | 0.152 | -1.456 | 0.260 | 0.29 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.459 | 0.407 | 0.422 | 0.148 | 0.668 | 0.925 | 0.185 | 0.201 | -0.259 | 0.295 | 0.22 |
|  | Show-o Turbo | 0 | **0.557** | 0.614 | 0.478 | 0.180 | 0.793 | 0.972 | 0.305 | **0.247** | **0.680** | **0.312** | 0.22 |{{< /table-caption >}}

> 🔼 표 1은 GenEval, HPS, IR, CS 네 가지 지표를 사용하여 512x512 해상도의 텍스트-이미지 생성 성능을 비교한 표입니다.  각 지표는 이미지 생성 품질의 다양한 측면을 평가합니다. GenEval은 전반적인 품질, HPS는 사람의 선호도, IR은 보상 점수, CS는 CLIP 점수를 나타냅니다.  추가적으로, TO(두 개체), CT(계산), P(위치), CL(색상), SO(단일 개체), CLA(색상 속성) 등의 세분화된 지표들도 함께 제시하여 이미지 생성의 다양한 측면을 더욱 자세히 분석합니다. Show-o와 Show-o Turbo 모델의 여러 가지 설정(CFG 사용 유무, 샘플링 단계 수)에 따른 결과를 비교하여 Show-o Turbo의 효율성을 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Table 1: Comparison of 512 ×\times× 512 T2I performance on GenEval, HPS, IR, and CS. AVG: average, TO: Two Object, CT: Counting, P: Position, CL: colors, SO: Single Object, CLA: Color Attr.
> </details>





### In-depth insights


#### Unified Multimodal View
통합 다중 모드 관점은 텍스트와 이미지 생성에 대한 통합된 틀을 제공하여 **모델 효율성을 높이는 데 중점**을 둡니다. 이는 텍스트 토큰의 병렬 디코딩을 통해 이미지와 텍스트 생성의 차이를 해소하고 **일관된 잡음 제거 관점**을 제시합니다.  **일관성 증류(CD)** 기법을 다중 모드 잡음 제거 경로에 확장하여, 모델이 샘플링 경로의 임의 지점을 동일한 종착점에 일관되게 매핑하도록 학습시키는 것이 핵심입니다.  여기에는 **경로 분할 전략과 교육 과정 학습**이 포함되어 학습 과정의 효율성을 높입니다.  **병렬 디코딩 알고리즘**은 텍스트 토큰을 동시에 다루도록 하여 모델 추론 속도를 높이는 데 기여하며, 이미지와 텍스트 생성 모두에서 **효율적인 샘플링 경로**를 가능하게 합니다.  결과적으로, 이러한 통합된 접근 방식은 다중 모드 생성 모델의 속도와 성능을 모두 향상시키는 효과적인 방법을 제시합니다.

#### Consistency Distillation
일관성 증류는 확률적 과정의 여러 시점을 동일한 최종 결과로 매핑하여 확률적 모델의 학습 및 추론 속도를 높이는 강력한 기술입니다. **이 기법은 노이즈 제거 과정을 단축시켜 효율성을 높입니다.**  본 논문에서는 이 기법을 다양한 모드(이미지 및 텍스트)의 데이터에 적용하는 방법과, 다중 모드의 노이즈 제거 과정에서의 일관성을 유지하는 전략을 제시합니다. 특히, **트레이젝토리 분할 및 커리큘럼 학습을 통해 모델의 수렴성을 개선**하고, **다양한 평가 지표에서 우수한 성능**을 보이는 것을 실험적으로 확인했습니다.  **평행 디코딩 기법과의 결합**을 통해 이미지 및 텍스트 생성에 대한 통합적인 관점을 제시하여, 모델의 효율성을 향상시키는 데 기여했습니다.  **일관성 증류의 성공적인 적용**은 다양한 모드의 데이터 생성 및 이해를 위한 효율적인 모델 개발에 중요한 의미를 지닌다고 할 수 있습니다.

#### Parallel Decoding Boost
본 논문의 "병렬 디코딩 부스트" 섹션은 **병렬 디코딩 기법이 모델의 추론 속도를 향상시키는 데 중요한 역할**을 한다는 점을 강조합니다.  기존의 순차적 디코딩 방식과 달리, 병렬 디코딩은 여러 토큰을 동시에 처리하여 처리 시간을 단축시킵니다. 이는 특히 이미지와 텍스트를 동시에 생성하는 다중 모드 모델에서 효과적입니다.  **자코비 디코딩과 같은 병렬 디코딩 알고리즘**을 통해 모델은 여러 텍스트 토큰을 동시에 정제하여 수렴 속도를 높입니다.  하지만 단순한 병렬 디코딩 적용만으로는 충분한 성능 향상을 기대하기 어렵다는 점도 언급하며, **일관성 증류(CD) 기법과의 결합**을 통해 더 큰 효과를 얻을 수 있음을 시사합니다.  즉, 병렬 디코딩은 속도 향상을 위한 기반 기술이며, 다른 최적화 기법과의 시너지 효과를 통해 최종적인 성능 개선을 달성한다는 점이 핵심입니다.

#### Curriculum Learning
본 논문에서 제시된 커리큘럼 학습(Curriculum Learning) 전략은 **모델의 수렴성을 개선**하기 위해 고안되었습니다.  이는 다양한 길이의 샘플링 경로를 단계적으로 학습시키는 방식으로, **초기 단계에서는 짧은 경로를 통해 빠른 학습을 유도하고, 점차적으로 경로 길이를 늘려 모델의 정확도를 높이는 방식**입니다. 이는 마치 어린 아이가 쉬운 문제부터 차례대로 어려운 문제를 풀어나가는 과정과 유사합니다. **단계적인 학습을 통해 모델은 더욱 안정적으로 학습하고, 과적합(Overfitting)을 방지하며, 최종적으로 더 나은 성능을 달성**할 수 있습니다. 특히, 다양한 모드(텍스트, 이미지)를 통합하는 다중 모드 모델에서 각 모드의 샘플링 경로를 단계적으로 학습시키는 것은 **모델의 효율성과 안정성을 향상**시키는 데 중요한 역할을 합니다.  **모델의 훈련 과정에서 발생할 수 있는 불안정성 문제 해결에 도움**이 되며, **최종적인 성능 향상**에도 기여할 수 있습니다.

#### Future Acceleration
미래의 가속화에 대한 심도있는 논의는 본 논문의 범위를 벗어나지만, 제시된 Show-o Turbo 모델의 성능 향상을 바탕으로 몇 가지 중요한 통찰력을 얻을 수 있습니다. **Show-o Turbo는 일관성 증류(CD)와 경험적 일반화를 통해 다중 모드 잡음 제거 과정을 단축하여 이미지와 텍스트 생성 속도를 크게 향상시켰습니다.** 이는 **병렬 디코딩 알고리즘**을 통해 이미지와 텍스트 생성을 통합된 관점에서 바라봄으로써 가능해졌습니다.  **향후 연구는 더욱 효율적인 다중 모드 잡음 제거 전략**, 예를 들어, **더욱 정교한 경로 분할 및 커리큘럼 학습 전략**에 초점을 맞춰야 합니다.  또한, **다양한 모달리티를 아우르는 통합된 모델** 개발 및 **대규모 언어 모델(LLM) 가속화 기술**과의 시너지 효과를 탐구하는 것도 중요합니다.  **Show-o Turbo의 성공은 단순한 성능 향상을 넘어서, 미래의 통합된 다중 모드 모델 개발에 대한 중요한 방향을 제시합니다.**


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.05415/x2.png)

> 🔼 그림 2는 Show-o 모델에서 텍스트와 이미지 토큰의 샘플링 경로를 보여줍니다.  두 경로 모두 잡음 제거 패턴을 보이며, 특히 텍스트 생성 경로는 Jacobi Decoding [47]을 통해 생성됩니다. 검은색 선은 다중 모드 경로의 통합된 추상화를 나타내고, 빨간색 선은 Show-o Turbo의 목표, 즉 샘플링 경로의 임의 지점을 최종 지점에 매핑하는 것을 보여줍니다.  설명의 간결성을 위해 경로 분할 전략은 생략되었습니다.  Show-o Turbo는 다중 모드 샘플링 경로의 효율성을 높이기 위해 임의의 중간점을 최종 결과와 일치시키는 것을 목표로 합니다. 이 그림은 Show-o와 Show-o Turbo의 작동 방식을 비교하여 이해하는 데 도움이 됩니다.
> <details>
> <summary>read the caption</summary>
> Figure 2: Illustration of the sampling trajectories of text and image tokens in Show-o. As shown, they both display a denoising pattern. In particular, the trajectory of text generation is yielded by Jacobi Decoding [47]. The black line denotes the unified abstraction of the multimodal trajectory, and the red lines illustrate the objective of our Show-o Turbo—to map an arbitrary point on the sampling trajectory to the endpoint. Note that we omit the trajectory segmentation strategy here for brevity.
> </details>



![](https://arxiv.org/html/2502.05415/x3.png)

> 🔼 그림 3은 Show-o Turbo의 MMU(다중 모드 이해) 작업에서 텍스트 샘플링 경로를 보여줍니다. 기존의 방법과 달리 Show-o Turbo는 한 번의 반복에서 여러 개의 연속 토큰을 예측하고 이후 토큰을 정확하게 추측하여 가속화를 달성합니다. 이 그림은 Show-o Turbo가 효율적으로 여러 토큰을 동시에 처리하여 샘플링 속도를 높이는 과정을 시각적으로 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Figure 3:  The text sampling trajectory of Show-o Turbo in MMU cases. Show-o Turbo realizes acceleration by predicting multiple successive tokens in one iteration and correctly guessing the later tokens.
> </details>



![](https://arxiv.org/html/2502.05415/x6.png)

> 🔼 그림 4는 텍스트-이미지 생성(T2I) 작업에서 Show-o와 Show-o Turbo의 512 해상도 성능을 비교한 것입니다. Show-o는 2단계 샘플링에서 실패하는 반면, Show-o Turbo는 양호한 성능을 유지합니다. 이 그림은 Show-o Turbo가 기존 Show-o 모델보다 샘플링 단계를 줄이면서도 이미지 생성 품질을 유지하는 향상된 효율성을 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Figure 4: Comparison between Show-o and Show-o Turbo on 512 resolution in T2I generation. The former crashes in two-step sampling, while the latter maintains good performance.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Method | Decoding | Speed (tokens/s) ↑ | POPE ↑ | MME ↑ | MMMU ↑ | Flickr30K ↑ | NoCaps ↑ |
|---|---|---|---|---|---|---|---| 
| Show-o | AR | 40.3 | **83.2** | **1042.5** | 24.6 | **26.6** | **38.9** |
|  | Jacobi | 36.9 | **83.2** | **1042.5** | 24.6 | **26.6** | **38.9** |
| Show-o Turbo* | Jacobi | 49.93 | 81.8 | 1003.6 | 25.4 | 20.3 | 29.6 |
| Show-o Turbo | Jacobi | **61.1** | 78.4 | 865.8 | **26.3** | 20.4 | 30.3 |{{< /table-caption >}}
> 🔼 표 2는 다양한 벤치마크에서 512x512 해상도의 다중 모드 이해(MMU) 성능 비교를 보여줍니다. Flickr30K와 NoCaps는 이미지 설명 능력을 평가하고, POPE, MME, MMMU는 질문 응답 능력을 평가합니다. 즉, 이 표는 Show-o Turbo를 포함한 여러 모델이 이미지 캡션 생성 및 질문 응답 과제에서 얼마나 잘 수행되는지 보여주는 종합적인 성능 비교 결과를 담고 있습니다.
> <details>
> <summary>read the caption</summary>
> Table 2: Comparison of 512 ×\times× 512 MMU performance on multiple benchmarks. Note that Flickr30K and NoCaps evaluate the ability of image description, and POPE, MME, and MMMU measure question-answering ability.
> </details>

{{< table-caption >}}
| Show-o (CFG=10) | Show-o Turbo |
|---|---| 
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **16 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **8 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **4 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **2 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **16 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **8 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **4 Steps** |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_0.png" width="598" height="598"> <br> **2 Steps** |  |
| *A cybernetic owl perched on a neon-lit branch, its mechanical feathers reflecting holographic patterns…* |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_1.png" width="598" height="598"> |  |
| *A modern electric guitar with a flame maple top, its wood grain catching studio lights…* |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_3.png" width="598" height="598"> |  |
| *A small succulent plant in a ceramic pot, its leaves forming a perfect geometric pattern…* |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_5.png" width="598" height="598"> |  |
| *A traditional wooden chess piece on a marble board, its polished surface reflecting soft light…* |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_10.png" width="598" height="598"> |  |
| *A detailed macro shot of a dragonfly perched on a thin blade of grass, its wings iridescent in the sunlight…* |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o16/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o8/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o4/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/o2/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t16/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t8/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t4/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| <img src="https://arxiv.org/html/2502.05415/extracted/6183602/showo512-2/t2/test_lmcm_x_photo_14.png" width="598" height="598"> |  |
| *A single, colorful autumn leaf floating on the surface of a calm pond…* |  |{{< /table-caption >}}
> 🔼 표 3은 256 해상도에서 다양한 요소에 대한 추가 연구 결과를 보여줍니다.  이 표는 자코비 디코딩을 사용하여 16개의 토큰을 디코딩하는 데 필요한 반복 횟수(#IT)를 포함하여 Show-o Turbo 모델의 성능에 영향을 미치는 요소들을 분석합니다.  구체적인 내용은 본문을 참조하십시오.  분석된 요소는 세그먼트 수, 전체 매개변수 조정 대비 LORA(Low-Rank Adaptation), 그리고 정규화 항의 유무 및 강도입니다. 각 요소 변경에 따른 성능 변화(POPE, MME, IR, CS)를 통해 Show-o Turbo 모델의 최적화 방향을 제시합니다.
> <details>
> <summary>read the caption</summary>
> Table 3: Ablation studies regarding various aspects on 256 resolution. #IT represents the number of iterations required by Jacobi decoding to decode 16 tokens. Refer to the text for more details.
> </details>

{{< table-caption >}}
| Settings | #IT ↓ | POPE ↑ | MME ↑ | IR ↑ | CS ↑ |
|---|---|---|---|---|---| 
| **Number of Segments** |  |  |  |  |  |
| 4 Segments | **10.57** | 72.6 | **803.4** | **0.586** | **0.307** |
| 2 Segments | 12.48 | 69.8 | 595.8 | 0.500 | 0.306 |
| 1 Segment | 11.71 | **74.1** | 675.3 | 0.270 | 0.304 |
| **Full-parameter Tuning vs. LoRA** |  |  |  |  |  |
| Full-parameter | **10.57** | 72.6 | 803.4 | **0.586** | **0.307** |
| LoRA | 13.14 | **78.1** | **881.2** | 0.472 | 0.304 |
| **Regularization** |  |  |  |  |  |
| β=0, γ=0 | **2.85** | 0.0 | 4.91 | -2.278 | 0.184 |
| β=10, γ=50 | 12.71 | **74.8** | 798.4 | 0.483 | **0.307** |
| β=20, γ=100 | 10.57 | 72.6 | **803.4** | **0.586** | **0.307** |{{< /table-caption >}}
> 🔼 표 4는 256 해상도에서 샘플링 전략을 비교한 결과를 보여줍니다.  기존의 다항 분포 샘플링과 비교했을 때, Show-o Turbo의 경우 top-k 샘플링이 유익한 반면, 원본 Show-o 모델에서는 그 효과가 미미함을 보여줍니다.  즉, Show-o Turbo는 top-k 샘플링 전략을 사용함으로써 성능 향상을 얻지만, 원본 Show-o 모델은 top-k 샘플링의 효과를 크게 보지 못한다는 것을 의미합니다.
> <details>
> <summary>read the caption</summary>
> Table 4: Comparison on sampling strategy on 256 resolution. Top-k sampling is beneficial to Show-o Turbo compared to regular multinomial samples, but the benefits for the original Show-o are minor.
> </details>

{{< table-caption >}}
| Model | Steps | Top-k | HPS ↑ | IR ↑ | CS ↑ |
|---|---|---|---|---|---| 
| Show-o Turbo | 4 | - | 0.245 | 0.621 | 0.306 |
|  | 4 | 200 | **0.252** | **0.706** | **0.309** |
|  | 2 | - | 0.216 | 0.027 | 0.291 |
|  | 2 | 10 | **0.240** | **0.529** | **0.306** |
| Show-o | 4 | - | 0.228 | 0.219 | 0.301 |
|  | 4 | 200 | **0.230** | **0.286** | **0.302** |
|  | 2 | - | **0.169** | **-1.257** | **0.254** |
|  | 2 | 10 | 0.168 | -1.263 | **0.254** |{{< /table-caption >}}
> 🔼 표 5는 256 해상도에서 다양한 CFG(Classifier-Free Guidance) 값을 사용했을 때 Show-o 모델과 Show-o Turbo 모델의 성능을 보여줍니다.  CFG는 이미지 생성 과정에서 추가적인 제약 조건을 부여하는 기법이며, 적절한 CFG 값을 사용하면 Show-o와 Show-o Turbo 모델 모두의 성능 향상을 기대할 수 있습니다. 이 표는 다양한 CFG 값을 적용했을 때 각 모델의 성능 지표(HPS, IR, CS) 변화를 정량적으로 비교 분석하여, 최적의 CFG 설정을 찾는 데 도움을 줍니다.  즉,  CFG 값을 조절함으로써 이미지 생성 품질을 개선할 수 있음을 보여주는 실험 결과를 제시합니다.
> <details>
> <summary>read the caption</summary>
> Table 5: Results with different CFG on 256 resolution. A proper CFG can enhance the performance of Show-o and Show-o Turbo.
> </details>

{{< table-caption >}}
| Model | Steps | CFG | HPS ↑ | IR ↑ | CS ↑ |
|---|---|---|---|---|---| 
| Show-o | 16 | 0 | 0.174 | -1.097 | 0.272 |
|  |  | 10 | **0.254** | **0.739** | **0.310** |
|  | 8 | 0 | 0.181 | -0.916 | 0.276 |
|  |  | 10 | **0.249** | **0.665** | **0.308** |
|  | 4 | 0 | 0.178 | -0.877 | 0.276 |
|  |  | 10 | **0.228** | **0.219** | **0.301** |
|  | 2 | 0 | 0.159 | -1.661 | 0.234 |
|  |  | 10 | **0.169** | **-1.257** | **0.254** |
| Show-o Turbo | 16 | 0 | **0.258** | 0.752 | **0.310** |
|  |  | 1 | **0.258** | **0.816** | **0.310** |
|  | 8 | 0 | **0.255** | 0.738 | **0.309** |
|  |  | 1 | **0.255** | **0.782** | **0.310** |
|  | 4 | 0 | **0.252** | 0.706 | **0.309** |
|  |  | 1 | **0.252** | **0.731** | **0.309** |
|  | 2 | 0 | **0.240** | **0.529** | **0.306** |
|  |  | 1 | 0.235 | 0.420 | 0.302 |{{< /table-caption >}}
> 🔼 표 6은 256x256 해상도의 이미지 생성 품질을 GenEval, HPS, IR, CS 지표를 사용하여 Show-o와 Show-o Turbo 모델의 성능을 비교한 표입니다. Show-o Turbo*는 첫 번째 학습 단계 이후의 모델을 나타내며, AVG는 평균, TO는 두 개의 개체, CT는 계산, P는 위치, CL은 색상, SO는 단일 개체, CLA는 색상 속성을 의미합니다.  표는 다양한 샘플링 단계(16, 8, 4, 2단계)에서 Show-o와 Show-o Turbo의 성능 차이를 보여주며, Show-o Turbo가 효율적인 이미지 생성을 달성함을 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Table 6: Comparison of 256 ×\times× 256 T2I performance on GenEval, HPS, IR, and CS. Show-o Turbo∗ refers to the model after the first stage of training. AVG: average, TO: Two Object, CT: Counting, P: Position, CL: colors, SO: Single Object, CLA: Color Attr.
> </details>

{{< table-caption >}}
| Steps | Model | CFG | AVG | TO | CT | P | CL | SO | CA | HPS | IR | CS | Time (sec) |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---| 
| 16 | Show-o | 10 | 0.591 | 0.692 | 0.478 | 0.165 | 0.859 | 0.978 | 0.378 | 0.254 | 0.739 | 0.310 | 0.44 |
|  | Show-o | 5 | 0.571 | 0.631 | 0.469 | 0.155 | 0.846 | 0.994 | 0.333 | 0.253 | 0.642 | 0.309 | 0.44 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.543 | 0.593 | 0.447 | 0.130 | 0.814 | 0.953 | 0.323 | 0.251 | 0.586 | 0.307 | 0.27 |
|  | Show-o Turbo | 0 | 0.562 | 0.689 | 0.366 | 0.140 | 0.814 | 0.991 | 0.373 | 0.258 | 0.752 | 0.310 | 0.27 |
| 8 | Show-o | 10 | 0.540 | 0.578 | 0.428 | 0.145 | 0.838 | 0.969 | 0.285 | 0.249 | 0.665 | 0.308 | 0.24 |
|  | Show-o | 5 | 0.530 | 0.558 | 0.441 | 0.133 | 0.825 | 0.972 | 0.255 | 0.247 | 0.602 | 0.308 | 0.24 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.518 | 0.518 | 0.400 | 0.123 | 0.809 | 0.972 | 0.285 | 0.250 | 0.597 | 0.307 | 0.15 |
|  | Show-o Turbo | 0 | 0.552 | 0.669 | 0.353 | 0.128 | 0.817 | 0.963 | 0.385 | 0.255 | 0.738 | 0.309 | 0.15 |
| 4 | Show-o | 10 | 0.425 | 0.333 | 0.334 | 0.100 | 0.700 | 0.950 | 0.135 | 0.228 | 0.219 | 0.301 | 0.14 |
|  | Show-o | 5 | 0.429 | 0.351 | 0.369 | 0.078 | 0.707 | 0.947 | 0.120 | 0.228 | 0.225 | 0.302 | 0.14 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.504 | 0.513 | 0.375 | 0.130 | 0.787 | 0.962 | 0.257 | 0.245 | 0.586 | 0.307 | 0.09 |
|  | Show-o Turbo | 0 | 0.494 | 0.530 | 0.334 | 0.093 | 0.787 | 0.959 | 0.260 | 0.240 | 0.529 | 0.306 | 0.06 |
| 2 | Show-o | 10 | 0.206 | 0.046 | 0.140 | 0.033 | 0.330 | 0.678 | 0.010 | 0.169 | -1.257 | 0.254 | 0.08 |
|  | Show-o | 5 | 0.229 | 0.068 | 0.122 | 0.023 | 0.378 | 0.763 | 0.020 | 0.182 | -0.917 | 0.263 | 0.08 |
|  | Show-o Turbo<sup>∗</sup> | 0 | 0.439 | 0.358 | 0.313 | 0.075 | 0.755 | 0.941 | 0.193 | 0.224 | 0.174 | 0.302 | 0.06 |{{< /table-caption >}}
> 🔼 표 7은 다양한 벤치마크에서 256x256 해상도의 다중 모드 이해(MMU) 성능 비교를 보여줍니다. Flickr30K, NoCaps, TextCaps는 이미지 설명 능력을 평가하고, POPE, MME, MMMU는 질문 응답 능력을 측정합니다.  표는 각 모델의 디코딩 속도(토큰/초)와 Flickr30K, NoCaps, TextCaps의 BLEU 점수, POPE, MME, MMMU의 정확도를 보여줍니다.
> <details>
> <summary>read the caption</summary>
> Table 7: Comparison of 256 ×\times× 256 MMU performance on multiple benchmarks. Note that Flickr30K, NoCaps, and TextCaps evaluate the ability of image description, and POPE, MME, and MMMU measure question-answering ability.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}