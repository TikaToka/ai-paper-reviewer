[{"figure_path": "https://arxiv.org/html/2412.17747/x1.png", "caption": "Figure 1: Overview of the proposed architecture. The input sequence is processed by a frozen LLM, generating a kv-cache. This cache is then passed to a coprocessor, along with trainable soft tokens. The coprocessor outputs latent embeddings which are used to augment the original kv-cache before being fed back into the LLM for output generation.", "description": "\uadf8\ub9bc 1\uc740 \uc81c\uc548\ub41c \uc544\ud0a4\ud14d\ucc98\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc785\ub825 \uc2dc\ud000\uc2a4\ub294 \ub3d9\uacb0\ub41c LLM(Large Language Model)\uc5d0 \uc758\ud574 \ucc98\ub9ac\ub418\uc5b4 kv-cache\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 cache\ub294 \ud559\uc2b5 \uac00\ub2a5\ud55c \uc18c\ud504\ud2b8 \ud1a0\ud070\uacfc \ud568\uaed8 coprocessor\ub85c \uc804\ub2ec\ub429\ub2c8\ub2e4. coprocessor\ub294 \uc6d0\ub798 kv-cache\ub97c \uc99d\uac15\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub418\ub294 \uc7a0\uc7ac\uc801 \uc784\ubca0\ub529\uc744 \ucd9c\ub825\ud55c \ub2e4\uc74c, \ucd9c\ub825 \uc0dd\uc131\uc744 \uc704\ud574 \ub3d9\uacb0\ub41c LLM\uc73c\ub85c \ub2e4\uc2dc \uc804\ub2ec\ub429\ub2c8\ub2e4.  \uc989, \ub3d9\uacb0\ub41c LLM\uc774 \uc785\ub825\uc744 \ucc98\ub9ac\ud558\uc5ec kv-cache\ub97c \uc0dd\uc131\ud558\uace0, \uc774 cache\uac00 \ucd94\uac00\uc801\uc778 \uacc4\uc0b0\uc744 \uc704\ud574 coprocessor\ub85c \uc804\ub2ec\ub429\ub2c8\ub2e4. coprocessor\ub294 \ucd94\uac00\uc801\uc778 \uc815\ubcf4\ub97c \ub2f4\uc740 \uc7a0\uc7ac\uc801 \uc784\ubca0\ub529\uc744 \uc0dd\uc131\ud558\uc5ec kv-cache\ub97c \ubcf4\uac15\ud558\uace0, \uc774 \ubcf4\uac15\ub41c cache\ub294 \ucd5c\uc885 \ucd9c\ub825\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud574 \ub2e4\uc2dc LLM\uc73c\ub85c \uc804\ub2ec\ub418\ub294 \uad6c\uc870\uc785\ub2c8\ub2e4.  coprocessor\ub294 offline \ubc0f \ube44\ub3d9\uae30\uc801\uc73c\ub85c \uc791\ub3d9\ud560 \uc218 \uc788\uc73c\ubbc0\ub85c, \ucd94\uac00\uc801\uc778 \uacc4\uc0b0\uc774 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uc5d0\ub294 LLM\uc774 \uc815\uc0c1\uc801\uc73c\ub85c \uae30\ub2a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.2. Model architecture"}, {"figure_path": "https://arxiv.org/html/2412.17747/x2.png", "caption": "Figure 2: Our coprocessor training framework. (a) Illustration of multi-position augmentation and ahead token prediction. For each selected augmentation position, latent embeddings are generated by the coprocessor and inserted after the corresponding token\u2019s embedding. The target tokens for prediction (\"ahead tokens\") are then appended. A causal mask is applied to all sequences following these insertion points. (b) Structure of the modified input and attention mask for model training. We show an example of 1 latent embedding and 1 ahead token here for simplicity.", "description": "\uadf8\ub9bc 2\ub294 \uc81c\uc548\ub41c \ubaa8\ub378 \uad6c\uc870\uc758 \ud6c8\ub828 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \ub2e4\uc911 \uc704\uce58 \uc99d\uac15 \ubc0f \uc55e\ucabd \ud1a0\ud070 \uc608\uce21 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc120\ud0dd\ub41c \uc99d\uac15 \uc704\uce58\ub9c8\ub2e4 \ucf54\ud504\ub85c\uc138\uc11c\uac00 \uc7a0\uc7ac \uc784\ubca0\ub529\uc744 \uc0dd\uc131\ud558\uace0 \ud574\ub2f9 \ud1a0\ud070 \uc784\ubca0\ub529 \ub4a4\uc5d0 \uc0bd\uc785\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \uc608\uce21\uc744 \uc704\ud55c \ub300\uc0c1 \ud1a0\ud070( \"\uc55e\ucabd \ud1a0\ud070\")\uc774 \ucd94\uac00\ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc0bd\uc785 \uc9c0\uc810 \ub4a4\uc5d0 \uc624\ub294 \ubaa8\ub4e0 \uc2dc\ud000\uc2a4\uc5d0 \uc778\uacfc\uc801 \ub9c8\uc2a4\ud06c\uac00 \uc801\uc6a9\ub429\ub2c8\ub2e4. (b)\ub294 \uc218\uc815\ub41c \uc785\ub825\uacfc \uc8fc\uc758 \ub9c8\uc2a4\ud06c\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac04\ub7b5\ud558\uac8c \ud558\uae30 \uc704\ud574 1\uac1c\uc758 \uc7a0\uc7ac \uc784\ubca0\ub529\uacfc 1\uac1c\uc758 \uc55e\ucabd \ud1a0\ud070 \uc608\uc2dc\ub9cc \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4.", "section": "2. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.17747/x3.png", "caption": "Figure 3: Validation perplexity of the baseline frozen Gemma-2 2B model and augmented models with varying numbers of latents (8, 16, 32, 64), when predicting the 1st and 32nd tokens following latent augmentation. Lower perplexity indicates better performance.", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \uc218\uc758 \uc7a0\uc7ac \ubcc0\uc218(8, 16, 32, 64)\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud6c8\ub828\ub41c \uc99d\uac15 \ubaa8\ub378\uacfc \uae30\uc900 \ub3d9\uacb0\ub41c Gemma-2 2B \ubaa8\ub378\uc758 \uac80\uc99d perplexity\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc7a0\uc7ac \ubcc0\uc218 \ucd94\uac00 \ud6c4 \uccab \ubc88\uc9f8 \ud1a0\ud070\uacfc 32\ubc88\uc9f8 \ud1a0\ud070\uc744 \uc608\uce21\ud560 \ub54c\uc758 perplexity\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. perplexity\uac00 \ub0ae\uc744\uc218\ub85d \uc131\ub2a5\uc774 \uc88b\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc7a0\uc7ac \ubcc0\uc218 \ucd94\uac00\uac00 \ubaa8\ub378\uc758 \uc608\uce21 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294\uc9c0, \uadf8\ub9ac\uace0 \uc7a0\uc7ac \ubcc0\uc218\uc758 \uc218\uac00 \uc131\ub2a5\uc5d0 \uc5b4\ub5a4 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "3. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.17747/x4.png", "caption": "Figure 4: Finetuning the coprocessor from Gemma-2 2B pretrained weights significantly improves GSM8K accuracy compared to training from scratch. Lines represent the mean and shaded areas represent the 95% confidence interval, both estimated from the last 5 checkpoints.", "description": "\uadf8\ub9bc 4\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c Gemma-2 2B \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucf54\ud504\ub85c\uc138\uc11c\ub97c \ubbf8\uc138 \uc870\uc815\ud558\uba74 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\ud558\ub294 \uac83\ubcf4\ub2e4 GSM8K \uc815\ud655\ub3c4\uac00 \ud06c\uac8c \ud5a5\uc0c1\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\uc120\uc740 \ud3c9\uade0\uc744 \ub098\ud0c0\ub0b4\uace0 \uc74c\uc601 \uc601\uc5ed\uc740 \ub9c8\uc9c0\ub9c9 5\uac1c\uc758 \uccb4\ud06c\ud3ec\uc778\ud2b8\uc5d0\uc11c \ucd94\uc815\ub41c 95% \uc2e0\ub8b0 \uad6c\uac04\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ucf54\ud504\ub85c\uc138\uc11c\uc758 \uc0ac\uc804 \ud6c8\ub828\ub41c \uac00\uc911\uce58\ub97c \ud65c\uc6a9\ud558\ub294 \uac83\uc774 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.17747/x5.png", "caption": "Figure 5: Scaling of GSM8K accuracy and validation perplexity with increasing training steps for the coprocessor (using 32 latent embeddings). The baseline performance of the frozen Gemma-2 2B model is shown for reference.", "description": "\uadf8\ub9bc 5\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \uc131\ub2a5\uc774 \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uc591\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 32\uac1c\uc758 \uc7a0\uc7ac \uc784\ubca0\ub529\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucf54\ud504\ub85c\uc138\uc11c\ub97c \ud6c8\ub828\uc2dc\ud0a8 \uacb0\uacfc, \ud6c8\ub828 \ub2e8\uacc4\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c GSM8K \uc815\ud655\ub3c4\ub294 \ud5a5\uc0c1\ub418\uace0 \uac80\uc99d \ud37c\ud50c\ub809\uc11c\ud2f0\ub294 \uac10\uc18c\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \ucf54\ud504\ub85c\uc138\uc11c\uac00 \ub354 \ub9ce\uc740 \ub370\uc774\ud130\ub97c \uc811\ud560\uc218\ub85d \ub354 \uc720\uc6a9\ud55c \uc7a0\uc7ac \uc784\ubca0\ub529\uc744 \uc0dd\uc131\ud558\uace0 \uace0\uc815\ub41c LLM\uacfc \ub354 \uc798 \ud1b5\ud569\ub418\uc5b4 \ub2e4\uc74c \ud1a0\ud070 \uc608\uce21 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\ub294 \uae30\uc900 \uc131\ub2a5(\uace0\uc815\ub41c Gemma-2 2B \ubaa8\ub378)\ub3c4 \ud568\uaed8 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.17747/x6.png", "caption": "Figure 6: Accuracy on GSM8K\u2019s test set after LoRA finetuning. Our augmented model shows a significant improvement compared to the baseline.", "description": "\uadf8\ub9bc 6\uc740 LoRA \ubbf8\uc138 \uc870\uc815 \ud6c4 GSM8K \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec, \uc81c\uc548\ub41c \uc99d\uac15 \ubaa8\ub378\uc740 \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \uc99d\uac15 \ubaa8\ub378\uc774 \ud558\uc704 \uc791\uc5c5\uc5d0 \ub354 \uc798 \uc801\uc751\ud558\uace0 \uae30\uc900 \ubaa8\ub378\ubcf4\ub2e4 \ud6e8\uc52c \ub098\uc740 \uc131\ub2a5\uc744 \ubc1c\ud718\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3. Experiments"}]