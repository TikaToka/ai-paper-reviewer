{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces a foundational model for learning transferable visual models from natural language, which is highly relevant to the subject-consistent video generation task."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-07-01", "reason": "This paper presents a crucial method for taming transformers, enabling the generation of high-resolution images, a key component for high-quality video generation."}, {"fullname_first_author": "Adam Polyak", "paper_title": "Movie gen: A cast of media foundation models", "publication_date": "2024-10-01", "reason": "This paper introduces MovieGen, a large-scale foundational model for video generation, providing a strong basis for the current research on subject-consistent video generation."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "This work details scalable diffusion models combined with transformers, providing a critical method for generating high-quality and diverse videos."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama: Open and efficient foundation language models", "publication_date": "2023-02-01", "reason": "This paper introduces LLAMA, a large language model that is crucial for handling and understanding textual instructions for video generation, improving the model's response to text prompts."}]}