[{"content": "| Method | INSCIT | Doc2Dial | TopicCQA | Qrecc | QuAC | Average |\n|---|---|---|---|---|---|---|\n| Contriever, Sequential | 19.97 | 23.85 | 30.49 | 46.75 | 26.57 | 29.53 |\n| Contriever, APE | 19.88 | 23.28 | 28.84 | 46.28 | 26.80 | 29.02 |\n| \u0394 | -0.09 | -0.57 | -1.65 | -0.47 | +0.23 | -0.51 |\n| GTE-base, Sequential | 21.58 | 32.35 | 33.41 | 46.54 | 30.69 | 32.91 |\n| GTE-base, APE | 20.85 | 30.99 | 31.92 | 45.83 | 30.35 | 31.99 |\n| \u0394 | -0.73 | -1.36 | -1.49 | -0.71 | -0.34 | -0.92 |\n| Dragon-multiturn, Sequential | 25.42 | 36.27 | 36.10 | 49.01 | 35.12 | 36.38 |\n| Dragon-multiturn, APE | 23.84 | 34.93 | 33.80 | 48.70 | 34.92 | 35.24 |\n| \u0394 | -1.58 | -1.34 | -2.30 | -0.31 | -0.20 | -1.14 |\n| All texts, APE | 27.22 | 36.13 | 35.72 | 49.15 | 35.70 | 36.78 |", "caption": "Table 1: Comparison between APE and sequential encoding using three retrievers on ChatRAG-Bench.", "description": "\uc774 \ud45c\ub294 ChatRAG-Bench\ub77c\ub294 \ubca4\uce58\ub9c8\ud06c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc138 \uac00\uc9c0 \uac80\uc0c9 \uc2dc\uc2a4\ud15c(Contriever, GTE-base, Dragon-multiturn)\uc5d0\uc11c APE(Adaptive Parallel Encoding)\uc640 \uc21c\ucc28\uc801 \uc778\ucf54\ub529 \ubc29\uc2dd\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uac80\uc0c9 \uc2dc\uc2a4\ud15c\uc5d0 \ub300\ud574 \uc21c\ucc28\uc801 \uc778\ucf54\ub529\uacfc APE\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 INSCIT, Doc2Dial, TopicCQA, Qrecc, QuAC \ub2e4\uc12f \uac00\uc9c0 \ud558\uc704 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5(\ud3c9\uade0 F1 \uc810\uc218)\uc744 \ube44\uad50\ud558\uc5ec APE\uc758 \ud6a8\uc728\uc131\uacfc \uc815\ud655\uc131\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  APE\ub294 \uc21c\ucc28\uc801 \uc778\ucf54\ub529\uacfc \uc720\uc0ac\ud55c \uc218\uc900\uc758 \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \uc0c1\ub2f9\ud55c \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \uc81c\uacf5\ud558\ub294\uc9c0 \uc5ec\ubd80\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc774 \ubaa9\ud45c\uc785\ub2c8\ub2e4.", "section": "5.1 Retrieval-Augmented Generation"}, {"content": "| Model | MuSiQue | Qasper | 2WikiMQA | DuRead | HotpotQA | NarratQA | MFQA_zh | MFQA_en | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| LLaMA-3-8B-Instruct | 20.70 | 41.05 | 30.02 | 9.55 | 45.90 | 20.98 | **58.54** | 45.04 | 33.97 |\n| C200\u00d720, Sequential | **27.93** | **42.71** | 38.35 | 12.65 | 49.60 | 22.78 | 57.82 | **48.94** | 37.60 |\n| C4000\u00d720, PCW | 18.82 | 42.59 | 40.99 | 21.57 | 47.09 | 23.29 | 54.40 | 45.05 | 36.73 |\n| C4000\u00d720, APE | 26.19 | 42.32 | **44.43** | **23.13** | **49.71** | **30.71** | 55.03 | 45.41 | **39.62** |\n| Mistral-7B-Instruct-v0.3 | 10.05 | 31.08 | 22.12 | 17.68 | 32.09 | 19.68 | 32.03 | 40.38 | 25.64 |\n| C200\u00d720, Sequential | 11.58 | 21.98 | 24.44 | 20.80 | 32.79 | 16.06 | 34.43 | 38.40 | 25.06 |\n| C4000\u00d720, PCW | 17.58 | 35.57 | 32.97 | 18.70 | 37.05 | 14.10 | 34.69 | 40.14 | 28.85 |\n| C4000\u00d720, APE | **20.30** | **36.81** | **34.37** | **21.89** | **42.33** | **20.49** | **40.20** | **44.03** | **32.55** |\n| Gemma-2-9b-it | 22.57 | 39.99 | 48.06 | 27.40 | 47.49 | 23.11 | 50.81 | 45.35 | 38.10 |\n| C200\u00d710, Sequential | 30.69 | 42.86 | **53.55** | 28.04 | 52.05 | 24.45 | 50.25 | 48.34 | 41.28 |\n| C2000\u00d720, PCW | 26.27 | 46.69 | 47.59 | 23.43 | 48.95 | 27.11 | **56.69** | 49.81 | 40.82 |\n| C2000\u00d720, APE | **33.38** | **47.72** | 49.49 | **28.43** | **56.62** | **30.41** | 56.52 | **50.84** | **44.18** |\n| LLaMA-3.1-8B-Instruct | 22.18 | **46.81** | 40.58 | **34.61** | 43.97 | 23.08 | 61.60 | 51.89 | 38.98 |\n| 128K, Sequential | 28.35 | 47.20 | 40.81 | 33.34 | 53.46 | 30.57 | 61.97 | 53.25 | 42.24 |\n| C200\u00d720, Sequential | **30.62** | 42.33 | 44.39 | 33.51 | 49.97 | 23.87 | 56.87 | **55.14** | 40.22 |\n| C4000\u00d720, PCW | 21.23 | 41.52 | 44.87 | 31.11 | 49.47 | 19.98 | 60.90 | 51.19 | 38.44 |\n| C4000\u00d720, APE | 26.88 | 43.03 | **50.11** | 32.10 | **55.41** | **30.50** | **62.02** | 52.51 | **42.86** |", "caption": "Table 2: Comparison between APE and baselines on LongBench across different models using RAG. C denotes Contriever, and M\u00d7N\ud835\udc40\ud835\udc41M\\times Nitalic_M \u00d7 italic_N indicates retrieval of the top-N\ud835\udc41Nitalic_N\nchunks, each containing M\ud835\udc40Mitalic_M words.", "description": "\ud45c 2\ub294 RAG\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ubaa8\ub378\uc5d0\uc11c LongBench\uc5d0 \ub300\ud55c APE\uc640 \uae30\uc900 \ubaa8\ub378 \uac04\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. C\ub294 Contriever\ub97c \ub098\ud0c0\ub0b4\uba70, M\u00d7N\uc740 \uac01\uac01 M\uac1c\uc758 \ub2e8\uc5b4\ub97c \ud3ec\ud568\ud558\ub294 \uc0c1\uc704 N\uac1c\uc758 \uccad\ud06c\ub97c \uac80\uc0c9\ud588\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(LLAMA-3-8B-INSTRUCT, MISTRAL-7B-INSTRUCT-V0.3, GEMMA-2-9B-IT, LLAMA-3.1-8B-INSTRUCT)\uc5d0\uc11c \ub2e4\uc591\ud55c \uac80\uc0c9 \ud06c\uae30(M\uacfc N\uc758 \ubcc0\ud654)\ub97c \uc0ac\uc6a9\ud558\uc5ec APE\uac00 \uae30\uc900 \ubaa8\ub378\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc5bc\ub9c8\ub098 \ud5a5\uc0c1\ub418\uc5c8\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uacfc \uac80\uc0c9 \ud06c\uae30\uc5d0 \ub530\ub978 APE\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \ud1b5\ud574 APE\uc758 \ud6a8\uc728\uc131\uacfc \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788,  PCW(Parallel Context Window) \uae30\ubc95\uacfc\uc758 \ube44\uad50\ub97c \ud1b5\ud574 APE\uc758 \uc6b0\uc218\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.1 Retrieval-Augmented Generation"}, {"content": "| Method | ArguAna | FEVER | NQ | SciFact | Date | Salient | Tracking7 | Web |\n|---|---|---|---|---|---|---|---|---|\n| Sequential, Zero-shot | 11.15 | 7.78 | 17.78 | 7.74 | 20.00 | 8.89 | 1.12 | 8.89 |\n| Sequential, Few-shot | 11.20 | 9.78 | 17.81 | 9.49 | 36.64 | 38.89 | 6.67 | 38.89 |\n| Sequential, Half-shot | 15.34 | 13.12 | 19.64 | 16.12 | 45.55 | 42.22 | 8.89 | 55.56 |\n| Sequential, Full-shot | 12.84 | 14.19 | **24.54** | **16.88** | **46.67** | **46.67** | **8.89** | **58.89** |\n| APE, Full-shot | **16.32** | **14.70** | 21.91 | 15.72 | 43.33 | 45.55 | **8.89** | **58.89** |", "caption": "Table 3: Comparison between APE and sequential encoding in various many-shot RAG and ICL tasks.", "description": "\ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ub2e4\uc911 \uc2dc\ub3c4 RAG \ubc0f ICL \uc791\uc5c5\uc5d0\uc11c APE\uc640 \uc21c\ucc28\uc801 \uc778\ucf54\ub529 \uac04\uc758 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  APE\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \ub9e4\uac1c\ubcc0\uc218(\uc608: \ucee8\ud14d\uc2a4\ud2b8 \uc218, \uc791\uc5c5\uc758 \ubcf5\uc7a1\uc131)\uc5d0 \ub530\ub77c \ud3c9\uac00\ud558\uace0 \uc21c\ucc28\uc801 \uc778\ucf54\ub529\uacfc \ube44\uad50\ud558\uc5ec APE\uc758 \ud6a8\uc728\uc131 \ubc0f \uc815\ud655\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.3 Many-shot Context-Augmented Generation"}, {"content": "| Task | Model | Latency (ms) | Accuracy (%) | Hallucination | Missing | Score<sup>a</sup> | \n|---|---|---|---|---|---|---| \n| LLM only | Llama-3-8B-Instruct | 682 | 22.14 | 48.97 | 28.90 | -26.83 | \n| Task 1 | Llama-3-8B-Instruct | 1140 | 23.28 | 29.49 | 47.22 | -6.21 | \n|  +APE |  | 1054 | **25.53** | **21.30** | **37.93** | **-0.41** | \n| Task 2 | Llama-3-8B-Instruct | 1830 | 24.46 | 28.38 | 47.15 | -3.92 | \n|  +APE |  | 1672 | **27.04** | **18.74** | **37.32** | **2.16** | ", "caption": "Table 4: Performance and latency comparison using the Llama-3-8B-Instruct model on CRAG benchmark.", "description": "\ud45c 4\ub294 CRAG \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c Llama-3-8B-Instruct \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5\uacfc \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc2e4\ud5d8\uc740  'LLM only',  'Task 1', 'Task 2' \uc138 \uac00\uc9c0 \uc0c1\ud669\uc5d0\uc11c \uc218\ud589\ub418\uc5c8\uc73c\uba70 \uac01 \uc0c1\ud669 \ubcc4\ub85c  Llama-3-8B-Instruct \ubaa8\ub378\ub9cc \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc640 APE\ub97c \uc801\uc6a9\ud55c \uacbd\uc6b0\uc758 \uc9c0\uc5f0 \uc2dc\uac04(\ubc00\ub9ac\ucd08), \uc815\ud655\ub3c4(%), \ud658\uac01 \ube44\uc728(%), \ub204\ub77d \uc810\uc218\ub97c \ube44\uad50\ud558\uc5ec APE\uc758 \ud6a8\uacfc\ub97c \ubd84\uc11d\ud569\ub2c8\ub2e4.  Task 1\uacfc Task 2\ub294  \ucd94\uac00\uc801\uc778 \uc815\ubcf4\uc6d0(\uc6f9\ud398\uc774\uc9c0, \uc9c0\uc2dd \uadf8\ub798\ud504)\uc744 \uc0ac\uc6a9\ud558\ub294 \ubcf5\uc7a1\ud55c \uc9c8\uc758\uc751\ub2f5 \uc2dc\ub098\ub9ac\uc624\ub97c \ub098\ud0c0\ub0b4\uba70, APE\uac00 \uc774\ub7ec\ud55c \ubcf5\uc7a1\ud55c \uc0c1\ud669\uc5d0\uc11c\ub3c4 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.1 Retrieval-Augmented Generation"}, {"content": "| P | T | S | GSM8K | TriviaQA | MMLU |\n|---|---|---|---|---|---| \n|  |  |  | 38.25% | 67.99% | 63.09% |\n| \u2713 |  |  | 50.42% | 70.76% | 63.70% |\n| \u2713 | \u2713 |  | 51.15% | 71.03% | 64.49% |\n| \u2713 | \u2713 | \u2713 | **53.62%** | **72.64%** | **66.62%** |", "caption": "Table 5: Ablation study of APE components on ICL tasks. P\ud835\udc43Pitalic_P: shared prefix, T\ud835\udc47Titalic_T: attention temperature, S\ud835\udc46Sitalic_S: scaling factor.", "description": "\ud45c 5\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \uc801\uc751\uc801 \ubcd1\ub82c \uc778\ucf54\ub529(APE) \ubc29\ubc95\uc758 \uc131\ub2a5\uc5d0 \uac01 \uad6c\uc131 \uc694\uc18c\uac00 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  APE\ub294 \uc138 \uac00\uc9c0 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\uc778 \uacf5\uc720 \uc811\ub450\uc0ac(Shared Prefix, P), \uc5b4\ud150\uc158 \uc628\ub3c4(Attention Temperature, T), \uadf8\ub9ac\uace0 \uc2a4\ucf00\uc77c\ub9c1 \uacc4\uc218(Scaling Factor, S) \ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \uad6c\uc131 \uc694\uc18c\ub97c \uc81c\uac70\ud558\uac70\ub098 \uc870\ud569\ud558\uc5ec \uc2e4\ud5d8\ud588\uc744 \ub54c\uc758 \uc138 \uac00\uc9c0 \ub2e4\ub978 ICL(In-context Learning) \uc791\uc5c5(GSM8K, TriviaQA, MMLU)\uc5d0 \ub300\ud55c \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uc911\uc694\uc131\uacfc \uc0c1\ud638 \uc791\uc6a9\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5.2 In-context Learning"}, {"content": "| Method | NarratQA | Qasper | MultiFQA | GovReport | QMSum | LCC |\n|---|---|---|---|---|---|---|\n| LLaMA-3-8B-Instruct | 19.32 | 32.83 | 43.38 | 27.89 | 22.40 | 53.22 |\n| +APE | **26.87** | **39.14** | **59.12** | **29.10** | **23.08** | **66.09** |\n| Method | RepoBench-P | HotpotQA | 2WikiMQA | MuSiQue | MultiNews | Average |\n|---|---|---|---|---|---|---|\n| LLaMA-3-8B-Instruct | 38.15 | 44.24 | 21.01 | 20.47 | **23.63** | 31.50 |\n| +APE | **49.43** | **50.11** | **28.06** | **25.79** | 22.40 | **38.11** |", "caption": "Table 6: Performance comparison across different long-context tasks on LongBench\u00a0(Bai et\u00a0al., 2023).", "description": "\ud45c 6\uc740 Bai et al.(2023)\uc758 LongBench \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ub2e4\uc591\ud55c \uc7a5\ubb38 \ucee8\ud14d\uc2a4\ud2b8 \uc791\uc5c5\uc5d0 \ub300\ud55c APE\uc640 \uae30\uc900 \ubaa8\ub378\uc758 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  APE\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uacfc \uc791\uc5c5\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uc7a5\ubb38 \ucee8\ud14d\uc2a4\ud2b8\uac00 \uc81c\ud55c\ub41c \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50\ud588\uc744 \ub54c, APE\ub294 \uac80\uc0c9\ub41c \ud14d\uc2a4\ud2b8\ub97c 8K \ucee8\ud14d\uc2a4\ud2b8 \ucc3d \ub0b4\uc5d0 \ubc30\uce58\ud558\uc5ec '\uc911\uac04\uc5d0 \uc190\uc2e4' \ud604\uc0c1\uc744 \uc644\ud654\ud568\uc73c\ub85c\uc368 \ub354\uc6b1 \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.1.2 Retrieval for Long-context Understanding"}, {"content": "| Method | NarratQA | Qasper | MultiFQA | GovReport | QMSum | LCC |\n|---|---|---|---|---|---|---|\n| LLaMA-3-8B-Instruct | 19.32 | 32.83 | 43.38 | 27.89 | 22.40 | 53.22 |\n| LLMLingua2 | 21.00 | 25.78 | 48.92 | 27.09 | 22.34 | 16.41 |\n| StreamingLLM | 16.99 | 28.94 | 11.99 | 25.65 | 19.91 | 40.02 |\n| Long-context FT | 14.88 | 21.70 | 47.79 | **32.65** | **24.76** | 55.12 |\n| Self-Extend | 24.82 | 37.94 | 50.99 | 30.48 | 23.36 | 58.01 |\n| +APE | **26.87** | **39.14** | **59.12** | 29.10 | 23.08 | **66.09** |\n| Method | RepoBench-P | HotpotQA | 2WikiMQA | MuSiQue | MultiNews | Average |\n|---|---|---|---|---|---|---|\n| LLaMA-3-8B-Instruct | 38.15 | 44.24 | 21.01 | 20.47 | 23.63 | 31.50 |\n| LLMLingua2 | 20.56 | 40.16 | 24.72 | 20.85 | 21.34 | 26.29 |\n| StreamingLLM | 26.16 | 32.76 | 20.12 | 17.32 | 21.49 | 23.76 |\n| Long-context FT | 43.05 | 15.89 | 10.49 | 8.74 | 24.28 | 27.21 |\n| Self-Extend | 41.83 | **51.09** | 24.17 | **28.73** | **24.11** | 35.96 |\n| +APE | **49.43** | 50.11 | **28.06** | 25.79 | 22.40 | **38.11** |", "caption": "Table 7: Performance comparison between APE and long-context LLMs on LongBench\u00a0(Bai et\u00a0al., 2023).", "description": "\ud45c 7\uc740 LongBench \ub370\uc774\ud130\uc14b(Bai et al., 2023)\uc744 \uc0ac\uc6a9\ud558\uc5ec APE\uc640 \uc7a5\ubb38\ub9e5\ub77d LLM\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  APE\ub294 \ub2e4\uc591\ud55c \uc7a5\ubb38\ub9e5\ub77d \uc791\uc5c5\uc5d0\uc11c \uae30\uc874\uc758 \uc7a5\ubb38\ub9e5\ub77d LLM\ub4e4\uc744 \ub2a5\uac00\ud558\ub294 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(LLAMA-3-8B-INSTRUCT, LLMLingua2, StreamingLLM, Long-context FT, Self-Extend)\uacfc \uc5ec\ub7ec \uac00\uc9c0 \ud3c9\uac00 \uc9c0\ud45c(NarratQA, Qasper, MultiFQA, GovReport, QMSum, LCC, RepoBench-P, HotpotQA, 2WikiMQA, MuSiQue, MultiNews)\uc5d0 \ub300\ud55c \uc131\ub2a5 \uacb0\uacfc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 APE\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\uace0, \ub2e4\uc591\ud55c \uc7a5\ubb38\ub9e5\ub77d \uc791\uc5c5\uc5d0\uc11c\uc758 \uc801\uc6a9 \uac00\ub2a5\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5. Experiments"}]