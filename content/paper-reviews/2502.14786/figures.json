[{"figure_path": "https://arxiv.org/html/2502.14786/x1.png", "caption": "Figure 1: SigLIP 2 adds the captioning-based pretraining from LocCa\u00a0[62] as well as self-distillation and masked prediction from SILC\u00a0[45] and TIPS\u00a0[38] (during the last 20% of training) to the sigmoid loss from SigLIP\u00a0[71]. For some variants, the recipe additionally involves fine-tuning with data curation\u00a0[61] or adaptation to native aspect ratio and variable sequence length\u00a0[6, 12].", "description": "\uadf8\ub9bc 1\uc740 SigLIP 2\uc758 \ud6c8\ub828 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SigLIP 2\ub294 SigLIP [71]\uc758 sigmoid \uc190\uc2e4 \ud568\uc218\uc5d0 LocCa [62]\uc758 \ucea1\uc158 \uae30\ubc18 \uc0ac\uc804 \ud6c8\ub828, SILC [45]\uc640 TIPS [38]\uc758 \uc790\uae30 \uc99d\ub958 \ubc0f \ub9c8\uc2a4\ud06c \uc608\uce21 \uae30\ubc95\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4. \ud2b9\ud788 \ub9c8\uc2a4\ud06c \uc608\uce21\uacfc \uc790\uae30 \uc99d\ub958\ub294 \ud6c8\ub828 \ud6c4\ubc18 20%\uc5d0\uc11c \uc801\uc6a9\ub429\ub2c8\ub2e4.  \uc77c\ubd80 \ubcc0\ud615 \ubaa8\ub378\uc758 \uacbd\uc6b0 \ub370\uc774\ud130 \uc815\uc81c [61] \ub610\ub294 \uace0\uc720 \uc885\ud6a1\ube44 \ubc0f \uac00\ubcc0 \uc2dc\ud000\uc2a4 \uae38\uc774 [6, 12]\uc5d0 \ub300\ud55c \ubbf8\uc138 \uc870\uc815\uc774 \ucd94\uac00\uc801\uc73c\ub85c \ud3ec\ud568\ub429\ub2c8\ub2e4.  \uc989, SigLIP 2\ub294 \uae30\uc874 SigLIP\uc758 \uac15\uc810\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ucea1\uc158 \uc0dd\uc131, \uc790\uae30\uc9c0\ub3c4 \ud559\uc2b5, \uadf8\ub9ac\uace0 \ub370\uc774\ud130 \uac1c\uc120 \ub4f1 \ub2e4\uc591\ud55c \uae30\uc220\uc744 \ud1b5\ud569\ud558\uc5ec \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8 \ubaa8\ub378\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2. \ud6c8\ub828 \ub808\uc2dc\ud53c"}, {"figure_path": "https://arxiv.org/html/2502.14786/x2.png", "caption": "Figure 2: \nPer-language image-text retrieval performance for SigLIP, SigLIP\u00a02 and mSigLIP on Crossmodal-3600\u00a0[58]. SigLIP\u00a02 almost matches the performance of mSigLIP (SigLIP trained on multilingual data) despite performing substantially better on English vision-language tasks (Table\u00a01).", "description": "\uadf8\ub9bc 2\ub294 SigLIP, SigLIP 2, \uadf8\ub9ac\uace0 \ub2e4\uad6d\uc5b4 \ub370\uc774\ud130\ub85c \ud559\uc2b5\ub41c mSigLIP \ubaa8\ub378\uc758 Crossmodal-3600 \ub370\uc774\ud130\uc14b \uae30\ubc18 \uc5b8\uc5b4\ubcc4 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \uac80\uc0c9 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SigLIP 2\ub294 \uc601\uc5b4 \uae30\ubc18 \uc2dc\uac01-\uc5b8\uc5b4 \uc791\uc5c5\uc5d0\uc11c SigLIP\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0\ub9cc(\ud45c 1 \ucc38\uc870), \ub2e4\uad6d\uc5b4 \ub370\uc774\ud130\ub85c \ud559\uc2b5\ub41c mSigLIP \ubaa8\ub378\uacfc \uac70\uc758 \uc720\uc0ac\ud55c \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub294 SigLIP 2\uac00 \ub2e4\uad6d\uc5b4 \uc774\ud574 \ub2a5\ub825\uc744 \ud5a5\uc0c1\uc2dc\ucf30\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3. \uc2e4\ud5d8 \uacb0\uacfc \ubc0f \ubd84\uc11d"}, {"figure_path": "https://arxiv.org/html/2502.14786/x3.png", "caption": "Figure 3: Comparing the NaFlex (a single checkpoint per model size supporting native aspect ratio and variable sequence length/resolution) and the standard square-input SigLIP\u00a02 variants which use a separate checkpoint for each sequence length/resolution. The sequence lengths annotated on the x-axis correspond to training sequence lengths for NaFlex. NaFlex interpolates fairly well between training resolutions, but does not extrapolate well (not shown).", "description": "\uadf8\ub9bc 3\uc740 \ub2e4\uc591\ud55c \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \ud574\uc0c1\ub3c4\ub97c \uc9c0\uc6d0\ud558\ub294 \ub2e8\uc77c \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uac00\uc9c4 NaFlex \ubaa8\ub378\uacfc \uac01 \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \ud574\uc0c1\ub3c4\uc5d0 \ub300\ud574 \ubcc4\ub3c4\uc758 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc0ac\uc6a9\ud558\ub294 \ud45c\uc900 \uc815\uc0ac\uac01\ud615 \uc785\ub825 SigLIP 2 \ubcc0\ud615 \ubaa8\ub378\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. x\ucd95\uc5d0 \ud45c\uc2dc\ub41c \uc2dc\ud000\uc2a4 \uae38\uc774\ub294 NaFlex\uc758 \ud559\uc2b5 \uc2dc\ud000\uc2a4 \uae38\uc774\uc5d0 \ud574\ub2f9\ud558\uba70, NaFlex\ub294 \ud559\uc2b5 \ud574\uc0c1\ub3c4 \uac04\uc5d0 \uc0c1\ub2f9\ud788 \uc798 \ubcf4\uac04\ud558\uc9c0\ub9cc \uc678\uc0bd\uc740 \uc798 \ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4(\ud45c\uc2dc\ub418\uc9c0 \uc54a\uc74c).", "section": "2.4.2. \uac00\ubcc0 \uc885\ud6a1\ube44 \ubc0f \ud574\uc0c1\ub3c4(NaFlex)"}, {"figure_path": "https://arxiv.org/html/2502.14786/x4.png", "caption": "Figure 4: Comparison of different vision encoders after training a Gemma\u00a02 LLM for 50M steps with a frozen vision encoder (PaliGemma\u00a0[7] stage 1), followed by fine-tuning the VLM on individual datasets (PaliGemma stage 3). SigLIP\u00a02 performs better than SigLIP and AIMv2\u00a0[20] for different model sizes and resolutions. Same data as in Table\u00a06.", "description": "\uadf8\ub9bc 4\ub294 \uc5bc\uc5b4\ubd99\uc740 \ube44\uc804 \uc778\ucf54\ub354(PaliGemma [7] 1\ub2e8\uacc4)\ub97c \uc0ac\uc6a9\ud558\uc5ec Gemma 2 LLM\uc744 50M \ub2e8\uacc4 \ub3d9\uc548 \ud6c8\ub828\ud55c \ud6c4 \uac1c\ubcc4 \ub370\uc774\ud130\uc14b\uc5d0\uc11c VLM\uc744 \ubbf8\uc138 \uc870\uc815\ud55c \ud6c4 \ub2e4\uc591\ud55c \ube44\uc804 \uc778\ucf54\ub354\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4(PaliGemma 3\ub2e8\uacc4). SigLIP 2\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378 \ud06c\uae30\uc640 \ud574\uc0c1\ub3c4\uc5d0\uc11c SigLIP \ubc0f AIMv2 [20]\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc6b0\uc218\ud569\ub2c8\ub2e4. \ud45c 6\uacfc \ub3d9\uc77c\ud55c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "section": "3.2 SigLIP 2\ub97c VLM\uc6a9 \ube44\uc804 \uc778\ucf54\ub354\ub85c \uc0ac\uc6a9"}, {"figure_path": "https://arxiv.org/html/2502.14786/x5.png", "caption": "Figure 5: 10-shot and 0-shot accuracy for geographically diverse object classification tasks (Dollar Street, GeoDE), as well as geolocalization (GeoDE country/region) and landmark localization (GLDv2) tasks. SigLIP\u00a02 consistently performs better than SigLIP (see Table\u00a08 for additional results).", "description": "\uadf8\ub9bc 5\ub294 \uc9c0\ub9ac\uc801\uc73c\ub85c \ub2e4\uc591\ud55c \uac1c\uccb4 \ubd84\ub958 \uc791\uc5c5(Dollar Street, GeoDE)\uacfc \uc9c0\ub9ac\uc801 \uc704\uce58 \ud655\uc778(GeoDE \uad6d\uac00/\uc9c0\uc5ed) \ubc0f \ub79c\ub4dc\ub9c8\ud06c \uc704\uce58 \ud655\uc778(GLDv2) \uc791\uc5c5\uc5d0 \ub300\ud55c 10\uc0f7 \ubc0f 0\uc0f7 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SigLIP 2\ub294 SigLIP\ubcf4\ub2e4 \uc77c\uad00\ub418\uac8c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4(\ucd94\uac00 \uacb0\uacfc\ub294 \ud45c 8 \ucc38\uc870).  \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc9c0\uc5ed\uacfc \ubb38\ud654\uc801 \ubc30\uacbd\uc744 \uac00\uc9c4 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec, SigLIP 2 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc5d0 \ub300\ud574 \ub354 \uac15\uac74\ud558\uace0 \uc77c\ubc18\ud654\ub41c \uc131\ub2a5\uc744 \uac00\uc9d0\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.5. \ubb38\ud654\uc801 \ub2e4\uc591\uc131 \ubc0f \uacf5\uc815\uc131"}, {"figure_path": "https://arxiv.org/html/2502.14786/x6.png", "caption": "Figure 6: Representation bias (association of random objects with gender; lower is better) for different models.", "description": "\uadf8\ub9bc 6\uc740 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc5d0 \ub300\ud55c \ud45c\ud604 \ud3b8\ud5a5(\ubb34\uc791\uc704 \uac1c\uccb4\uc640 \uc131\ubcc4\uc758 \uc5f0\uad00\uc131)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub0ae\uc740 \uac12\uc774 \ub354 \uc88b\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 SigLIP 2 \ubaa8\ub378\uc774 \uc774\uc804 \ubaa8\ub378\uc778 SigLIP\uc5d0 \ube44\ud574 \ubb34\uc791\uc704 \uac1c\uccb4\ub97c \ud2b9\uc815 \uc131\ubcc4\uacfc \uc5f0\uad00\uc2dc\ud0a4\ub294 \uacbd\ud5a5\uc774 \ud6e8\uc52c \uc801\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub610\ud55c, \ub354 \ud070 \ubaa8\ub378\uc77c\uc218\ub85d \ud3b8\ud5a5\uc774 \ub354 \uc801\uc740 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc774\uc804 \uc5f0\uad6c \uacb0\uacfc\uc640 \uc77c\uce58\ud569\ub2c8\ub2e4.", "section": "3.5. \ubb38\ud654\uc801 \ub2e4\uc591\uc131 \ubc0f \uacf5\uc815\uc131"}]