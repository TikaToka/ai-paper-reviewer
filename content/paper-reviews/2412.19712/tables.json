[{"content": "| Methods | (i) | (ii) | (iii) | (iv) | (v) | Val | Ove | Ali | Und<sub>l</sub> | Und<sub>s</sub> |\n|---|---|---|---|---|---|---|---|---|---|---|\n| FlexDM [11] | 5.34 | 5.29 | 5.41 | 5.09 | 4.54 | 0.8757 | 0.3242 | **0.0016** | 0.7286 | 0.7298 |\n| GPT-4o [1] | 6.53 | 6.49 | 6.60 | 6.27 | 5.69 | 0.9968 | 0.0595 | 0.0001 | 0.3780 | 0.5708 |\n| LaDeCo (Ours) | **8.08** | **7.92** | **8.00** | **7.82** | **6.98** | **0.9365** | **0.0865** | 0.0013 | **0.6922** | **0.6580** |\n| GT | 8.35 | 8.21 | 8.30 | 8.01 | 7.26 | 0.9265 | 0.0768 | 0.0015 | 0.6848 | 0.6732 |", "caption": "Table 1: Quantitative comparison on the design composition task. LLaVA-OV evaluation includes the following aspects: (i) design and layout, (ii) content relevance, (iii) typography and color, (vi) graphics and images, and (v) innovation and originality. The score closest to the one calculated from real data (denoted as GT) is highlighted in bold, indicating the best performance among different methods.", "description": "\ud45c 1\uc740 \ub514\uc790\uc778 \uad6c\uc131 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ub7c9\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LLaVA-OV \ud3c9\uac00\ub294 \ub514\uc790\uc778 \ubc0f \ub808\uc774\uc544\uc6c3, \ucf58\ud150\uce20 \uad00\ub828\uc131, \ud0c0\uc774\ud3ec\uadf8\ub798\ud53c \ubc0f \uc0c9\uc0c1, \uadf8\ub798\ud53d \ubc0f \uc774\ubbf8\uc9c0, \ud601\uc2e0\uc131 \ubc0f \ub3c5\ucc3d\uc131\uc758 \ub2e4\uc12f \uac00\uc9c0 \uce21\uba74\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc2e4\uc81c \ub370\uc774\ud130(GT\ub85c \ud45c\uc2dc)\uc5d0\uc11c \uacc4\uc0b0\ub41c \uc810\uc218\uc5d0 \uac00\uc7a5 \uac00\uae4c\uc6b4 \uc810\uc218\ub294 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uc774\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95 \uc911\uc5d0\uc11c \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "| Settings | (i) | (ii) | (iii) | (iv) | (v) | Val | Ove | Ali | Und<sub>l</sub> | Und<sub>s</sub> |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Llama-3.1-8B (rank 16) | 8.03 | 7.89 | 8.00 | 7.75 | 6.90 | 0.9347 | 0.0796 | 0.0012 | 0.6900 | 0.6564 |\n| Llama-3.1-8B (rank 64) | 8.10 | 7.94 | 8.04 | 7.83 | 6.98 | 0.9352 | 0.0787 | 0.0013 | 0.7084 | 0.6715 |\n| llava-v1.5-7b (rank 32) | 8.00 | 7.86 | 8.02 | 7.78 | 6.90 | 0.9403 | 0.0940 | 0.0015 | 0.6703 | 0.6208 |\n| Llama-3.1-8B-Instruct (rank 32) | 8.08 | 7.89 | 8.03 | 7.82 | 6.99 | 0.9388 | 0.0804 | 0.0015 | 0.6867 | 0.6640 |\n| w/o LP, w/o LDC (rank 32) | 7.23 | 7.12 | 7.28 | 6.99 | 6.29 | 0.9325 | 0.0954 | 0.0013 | 0.6194 | 0.5875 |\n| w/ LP, w/o LDC (rank 32) | 7.84 | 7.67 | 7.78 | 7.56 | 6.66 | 0.9389 | 0.0843 | 0.0013 | 0.6568 | 0.6242 |\n| Llama-3.1-8B* (rank 32) | 8.22 | 8.06 | 8.22 | 7.94 | 7.09 | 0.9335 | 0.1029 | 0.0005 | 0.7321 | 0.7116 |\n| Llama-3.1-8B (rank 32) | 8.08 | 7.92 | 8.00 | 7.82 | 6.98 | 0.9365 | 0.0865 | 0.0013 | 0.6922 | 0.6580 |\n| GT | 8.35 | 8.21 | 8.30 | 8.01 | 7.26 | 0.9265 | 0.0768 | 0.0015 | 0.6848 | 0.6732 |", "caption": "Table 2: Ablation studies. Our investigation covers four aspects (from top to bottom): (1) the rank number in LoRA, (2) the base model, (3) the key techniques in LaDeCo, where LP denotes layer planning , and LDC represents layered design composition, (4) dataset size.\nThe model with * to is trained on the combined Crello and LargeCrello datasets, while the models without * are trained on Crello only.", "description": "\ud45c 2\ub294 LaDeCo \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uc694\uc778\ub4e4\uc744 \ubd84\uc11d\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd1d 4\uac00\uc9c0 \uce21\uba74\uc744 \ub2e4\ub8e8\uace0 \uc788\ub294\ub370, (1) LoRA(Low-Rank Adaptation)\uc5d0\uc11c rank\uc758 \ud06c\uae30, (2) \uae30\ubc18 \ubaa8\ub378\uc758 \uc885\ub958, (3) LaDeCo\uc758 \ud575\uc2ec \uae30\ubc95\uc778 \uacc4\uce35\uc801 \ub808\uc774\uc5b4 \uacc4\ud68d(Layer Planning, LP)\uacfc \uacc4\uce35\uc801 \ub514\uc790\uc778 \uad6c\uc131(Layered Design Composition, LDC)\uc758 \uc801\uc6a9 \uc5ec\ubd80, (4) \ub370\uc774\ud130\uc14b \ud06c\uae30\uc785\ub2c8\ub2e4.  \ud45c\uc5d0\uc11c \ubcc4\ud45c(*)\uac00 \ud45c\uc2dc\ub41c \ubaa8\ub378\uc740 Crello\uc640 LargeCrello \ub370\uc774\ud130\uc14b\uc744 \uacb0\ud569\ud558\uc5ec \ud559\uc2b5\ud55c \ubaa8\ub378\uc774\uace0, \ubcc4\ud45c\uac00 \uc5c6\ub294 \ubaa8\ub378\uc740 Crello \ub370\uc774\ud130\uc14b\ub9cc \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uac01 \uc694\uc778\uc774 LaDeCo\uc758 \uc131\ub2a5\uc5d0 \uc5b4\ub5a4 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "| Methods | Val | Ove | Ali | Und<sub>l</sub> | Und<sub>s</sub> | Uti | Occ | Rea |\n|---|---|---|---|---|---|---|---|---|\n| PosterLLaVa [32] | **0.9269** | 0.0685 | 0.0011 | 0.7879 | 0.7375 | 0.4199 | 0.1936 | **0.0747** |\n| PosterLlama [27] | 0.8701 | 0.0868 | 0.0014 | 0.8483 | 0.7798 | 0.4115 | **0.1772** | 0.0694 |\n| LaDeCo (Ours) | 0.9340 | **0.0805** | **0.0016** | **0.6851** | **0.6540** | **0.4414** | 0.1835 | 0.0768 |\n| GT | 0.9265 | 0.0768 | 0.0015 | 0.6848 | 0.6732 | 0.4737 | 0.1628 | 0.0709 |", "caption": "Table 3: Quantitative results on the content-aware layout generation subtask. The score closest to\nthe one calculated from real data (denoted as GT) is highlighted in bold, indicating the best performance among different methods.", "description": "\ud45c 3\uc740 \ucf58\ud150\uce20 \uc778\uc2dd \ub808\uc774\uc544\uc6c3 \uc0dd\uc131 \ud558\uc704 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ub7c9\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\uc81c \ub370\uc774\ud130(GT\ub85c \ud45c\uc2dc)\uc5d0\uc11c \uacc4\uc0b0\ub41c \uc810\uc218\uc640 \uac00\uc7a5 \uac00\uae4c\uc6b4 \uc810\uc218\ub294 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uc774\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95 \uc911\uc5d0\uc11c \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \ub514\uc790\uc778 \ubc0f \ub808\uc774\uc544\uc6c3, \ucf58\ud150\uce20 \uad00\ub828\uc131, \ud0c0\uc774\ud3ec\uadf8\ub798\ud53c \ubc0f \uc0c9\uc0c1, \uadf8\ub798\ud53d \ubc0f \uc774\ubbf8\uc9c0, \ud601\uc2e0\uc131 \ubc0f \ub3c5\ucc3d\uc131\uc758 \ub2e4\uc12f \uac00\uc9c0 \uce21\uba74\uc744 \ud3c9\uac00\ud558\ub294 LLaVA-OV \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \ub610\ud55c, \uc694\uc18c \uc720\ud6a8\uc131(Val), \uc911\ucca9(Ove), \uc815\ub82c(Ali), \ud558\uc704 \ud6a8\uacfc(Und\u2081, Unds), \ud65c\uc6a9\ub3c4(Uti), \ud3d0\uc0c9(Occ), \uac00\ub3c5\uc131(Rea)\uacfc \uac19\uc740 \uae30\ud558\ud559\uc801 \uc9c0\ud45c\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec \ub808\uc774\uc544\uc6c3\uc758 \uc9c8\uc744 \ub2e4\uac01\uc801\uc73c\ub85c \ubd84\uc11d\ud558\uc600\uc2b5\ub2c8\ub2e4.", "section": "4.5. \uc791\uc5c5\ubcc4 \uae30\uc900\uacfc\uc758 \ube44\uad50"}]