[{"figure_path": "https://arxiv.org/html/2412.12091/x2.png", "caption": "Figure 1: Visual results generated by Wonderland. Given a single image, Wonderland reconstructs 3D scenes from the latent space of a camera-guided video diffusion model in a feed-forward manner.", "description": "Wonderland\ub294 \ub2e8\uc77c \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \uce74\uba54\ub77c\ub85c \uc548\ub0b4\ub418\ub294 \ube44\ub514\uc624 \ud655\uc0b0 \ubaa8\ub378\uc758 \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c 3D \uc7a5\uba74\uc744 \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ubc29\uc2dd\uc73c\ub85c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e8\uc77c \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc0dd\uc131\ub41c \uc2dc\uac01\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ub450 \uc5f4\uc5d0\ub294 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \ud574\ub2f9 3D \uc7a5\uba74\uc758 \ub450 \uac00\uc9c0 \ub2e4\ub978 \ubcf4\uae30\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc624\ub978\ucabd \ub450 \uc5f4\uc5d0\ub294 \ub2e4\ub978 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \ud574\ub2f9 3D \uc7a5\uba74\uc758 \ub450 \uac00\uc9c0 \ub2e4\ub978 \ubcf4\uae30\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. Wonderland\ub294 \uac1d\uccb4\uc758 \ud615\uc0c1\uacfc \uc0c9\uc0c1\uc744 \uc815\ud655\ud558\uac8c \uc7ac\uad6c\uc131\ud558\uace0 \ubc30\uacbd\uc744 \uc0ac\uc2e4\uc801\uc73c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "Abstract"}, {"figure_path": "https://arxiv.org/html/2412.12091/x3.png", "caption": "Figure 2: Overview of Wonderland. Given a single image, a camera-guided video diffusion model follows the camera trajectory and generates a 3D-aware video latent, which is leveraged by the latent-based large reconstruction model to construct the 3D scene in a feed-forward manner. The video diffusion model involves dual-branch camera conditioning to fulfill precise pose control. The LaLRM operates in latent space and efficiently reconstructs a wide-scope and high-fidelity 3D scene.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub2e8\uc77c \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \uce74\uba54\ub77c \uacbd\ub85c\ub97c \ub530\ub77c 3D \uc778\uc2dd \ube44\ub514\uc624 \uc7a0\uc7ac \uacf5\uac04\uc744 \uc0dd\uc131\ud558\ub294 \uce74\uba54\ub77c \uc720\ub3c4 \ube44\ub514\uc624 \ud655\uc0b0 \ubaa8\ub378\uacfc, \uc774 \uc7a0\uc7ac \uacf5\uac04\uc744 \ud65c\uc6a9\ud558\uc5ec 3D \uc7a5\uba74\uc744 \uad6c\uc131\ud558\ub294 \uc7a0\uc7ac \uae30\ubc18 \ub300\uaddc\ubaa8 \uc7ac\uad6c\uc131 \ubaa8\ub378(LaLRM)\ub85c \uad6c\uc131\ub41c Wonderland \uc2dc\uc2a4\ud15c\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\ub514\uc624 \ud655\uc0b0 \ubaa8\ub378\uc740 \uc815\ud655\ud55c \ud3ec\uc988 \uc81c\uc5b4\ub97c \uc704\ud574 \uc774\uc911 \ubd84\uae30 \uce74\uba54\ub77c \uc870\uac74\ud654\ub97c \uc0ac\uc6a9\ud558\uace0, LaLRM\uc740 \uc7a0\uc7ac \uacf5\uac04\uc5d0\uc11c \uc791\ub3d9\ud558\uc5ec \uad11\ubc94\uc704\ud558\uace0 \uace0\ud488\uc9c8\uc758 3D \uc7a5\uba74\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.12091/x4.png", "caption": "Figure 3: Qualitative comparison to prior arts in camera-guided video generation.\nThe 14thsubscript14th14_{\\mathrm{th}}14 start_POSTSUBSCRIPT roman_th end_POSTSUBSCRIPT frame in each sample is shown for comparison, with the first column displaying the conditional image and camera trajectory (bottom-right).\nBlue bounding boxes denote reference areas to assist comparison and orange bounding boxes highlight low-quality generations.\nWe also show our last frames in the rightmost column.\nOur method outperforms the priors in both precise camera control and high-quality and wide-scope video generation.", "description": "\uc774 \uadf8\ub9bc\uc740 \uce74\uba54\ub77c \uacbd\ub85c\uac00 \uc8fc\uc5b4\uc9c4 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0\uc11c \uae30\uc874 \ubc29\ubc95\ub4e4(MotionCtrl, VD3D, ViewCrafter)\uacfc \uc81c\uc548\ub41c Wonderland \ubaa8\ub378\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \uc0d8\ud50c\uc758 14\ubc88\uc9f8 \ud504\ub808\uc784\uc774 \ube44\uad50\ub97c \uc704\ud574 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uccab \ubc88\uc9f8 \uc5f4\uc740 \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc640 \uce74\uba54\ub77c \uacbd\ub85c(\uc624\ub978\ucabd \ud558\ub2e8)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud30c\ub780\uc0c9 \uacbd\uacc4 \uc0c1\uc790\ub294 \ube44\uad50\ub97c \ub3d5\uae30 \uc704\ud55c \ucc38\uc870 \uc601\uc5ed\uc744 \ub098\ud0c0\ub0b4\uace0 \uc8fc\ud669\uc0c9 \uacbd\uacc4 \uc0c1\uc790\ub294 \ud488\uc9c8\uc774 \ub0ae\uc740 \uc0dd\uc131 \uacb0\uacfc\ub97c \uac15\uc870\ud569\ub2c8\ub2e4. \ub610\ud55c, \uc624\ub978\ucabd \uc5f4\uc5d0\ub294 \uc81c\uc548\ub41c \ubaa8\ub378\uc758 \ub9c8\uc9c0\ub9c9 \ud504\ub808\uc784\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4. Wonderland \ubaa8\ub378\uc740 \uc815\ud655\ud55c \uce74\uba54\ub77c \uc81c\uc5b4\uc640 \uace0\ud488\uc9c8\uc758 \uad11\ubc94\uc704\ud55c \ube44\ub514\uc624 \uc0dd\uc131 \uce21\uba74\uc5d0\uc11c \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4.1. Comparison of Camera-Guided Video Generation"}, {"figure_path": "https://arxiv.org/html/2412.12091/x5.png", "caption": "Figure 4: Qualitative comparison for 3D scene generation. Blue bounding boxes show visible regions from conditional images and yellow bounding boxes show low-quality regions. Our approach generates much higher quality novel views from one conditional image.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub2e8\uc77c \uc774\ubbf8\uc9c0\uc5d0\uc11c 3D \uc7a5\uba74\uc744 \uc0dd\uc131\ud558\ub294 \uc5ec\ub7ec \uac00\uc9c0 \ubc29\ubc95\ub4e4\uc744 \uc9c8\uc801\uc73c\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \ud30c\ub780\uc0c9 \uc0c1\uc790\ub294 \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ubcfc \uc218 \uc788\ub294 \uc601\uc5ed\uc744, \ub178\ub780\uc0c9 \uc0c1\uc790\ub294 \ud488\uc9c8\uc774 \ub0ae\uc740 \uc601\uc5ed\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc81c\uc548\ub41c \uc811\uadfc \ubc29\uc2dd\uc740 \ud558\ub098\uc758 \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ud6e8\uc52c \ub354 \ub192\uc740 \ud488\uc9c8\uc758 \uc0c8\ub85c\uc6b4 \ubdf0\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4.2. 3D \uc7a5\uba74 \uc0dd\uc131 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2412.12091/x6.png", "caption": "Figure 5: Comparison with ViewCrafter (left) and WonderJourney (right) for in-the-wild 3D scene generation from single input images.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec ViewCrafter, WonderJourney\uc640 \uc800\uc790\ub4e4\uc758 \ubc29\ubc95\uc744 \ube44\uad50\ud558\uc5ec \uc57c\uc0dd\uc5d0\uc11c 3D \uc7a5\uba74 \uc0dd\uc131\uc5d0 \ub300\ud55c \uc9c8\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ViewCrafter\ub294 \uc81c\ud55c\ub41c \uc601\uc5ed\uc5d0\uc11c\ub9cc 3D \uc7a5\uba74\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc73c\uba70, \ubdf0 \ubc94\uc704\uac00 \ucee4\uc9c0\uba74 \ud488\uc9c8\uc774 \ud06c\uac8c \uc800\ud558\ub429\ub2c8\ub2e4. WonderJourney\ub294 \ub354 \ub113\uc740 \uc2dc\uc57c\uc758 \uc7a5\uba74\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc9c0\ub9cc \uc0dd\uc131\ub41c \ubdf0\ub294 \ud750\ub9bf\ud558\uace0 \uc544\ud2f0\ud329\ud2b8\uac00 \ud3ec\ud568\ub418\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uc640 \ub300\uc870\uc801\uc73c\ub85c, \uc800\uc790\ub4e4\uc758 \ubc29\ubc95\uc740 \ub192\uc740 \uc0ac\uc2e4\uc131\uc744 \uc720\uc9c0\ud558\uace0 \uc678\uad00\uacfc 3D \uae30\ud558\ud559 \ubaa8\ub450\uc5d0\uc11c \uc77c\uad00\ub41c \ud655\uc7a5\ub41c \uc7a5\uba74\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4.2. Comparison of 3D Scene Generation"}, {"figure_path": "https://arxiv.org/html/2412.12091/x7.png", "caption": "Figure 6: Comparison to ZeroNVS and Cat3D with Mip-Nerf dataset on 3D scene generation from single input images. For each scene, the conditional image is shown in the left-most column. We show renderings from two viewpoints, one at the conditional image (starting) view (upper) and another at around 120\u00b0-rotation from the starting view(lower).", "description": "\uc774 \uadf8\ub9bc\uc740 Mip-NeRF \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e8\uc77c \uc785\ub825 \uc774\ubbf8\uc9c0\uc5d0\uc11c 3D \uc7a5\uba74\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \uc788\uc5b4 ZeroNVS, Cat3D\uc640 \uc800\ud76c \ubc29\ubc95\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \uc7a5\uba74\uc5d0\uc11c \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0(\uc2dc\uc791) \ubcf4\uae30(\uc704)\uc640 \uc2dc\uc791 \ubcf4\uae30\uc5d0\uc11c \uc57d 120\ub3c4 \ud68c\uc804\ud55c \ub2e4\ub978 \ubcf4\uae30(\uc544\ub798)\uc758 \ub450 \uac00\uc9c0 \uad00\uc810\uc5d0\uc11c \ub80c\ub354\ub9c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc5d0 \uac00\uae4c\uc6b4 \ubcf4\uae30\uc758 \uacbd\uc6b0 \uc800\ud76c \ubc29\ubc95\uc740 Cat3D\uc640 \uc720\uc0ac\ud55c \ub80c\ub354\ub9c1 \ud488\uc9c8\uc744 \ub2ec\uc131\ud558\uba70 ZeroNVS\ubcf4\ub2e4 \ub208\uc5d0 \ub744\uac8c \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ubcf4\uae30\uac00 \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ubc97\uc5b4\ub0a8\uc5d0 \ub530\ub77c Cat3D\ub294 \ud2b9\ud788 \ubc30\uacbd\uc5d0\uc11c \uc2ec\ud55c \ube14\ub7ec\ub9c1 \ud604\uc0c1\uc774 \ub098\ud0c0\ub0a9\ub2c8\ub2e4. \ubc18\ub300\ub85c \uc800\ud76c \ubc29\ubc95\uc740 \ub354 \uc120\uba85\ud55c \ud14d\uc2a4\ucc98, \ub354 \uc120\uba85\ud55c \ub514\ud14c\uc77c, \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc640 \ub354 \ub192\uc740 \uc77c\uad00\uc131\uc744 \uac00\uc9c4 \uc7a5\uba74\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "4.2. 3D \uc7a5\uba74 \uc0dd\uc131 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2412.12091/x8.png", "caption": "Figure A1: Comparison of video generations between the source model (upper row) and the model fine-tuned on static-scene datasets with LoRA modules (lower row). The results demonstrate that fine-tuning the model on static-scene datasets equipped with LoRA produces significantly more static scenes.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0ac\uc804 \ud6c8\ub828\ub41c \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378(\uc717\uc904)\uacfc LoRA \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc815\uc801 \uc7a5\uba74 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378(\uc544\ub7ab\uc904) \uac04\uc758 \ube44\ub514\uc624 \uc0dd\uc131 \uacb0\uacfc\ub97c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uacb0\uacfc\ub294 LoRA\ub97c \uac16\ucd98 \uc815\uc801 \uc7a5\uba74 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\uba74 \uc2dc\uac01\uc801 \ud488\uc9c8 \uc800\ud558 \uc5c6\uc774 \ud6e8\uc52c \ub354 \uc815\uc801\uc778 \uc7a5\uba74\uc774 \uc0dd\uc131\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "A. More Analysis on Controllable Video Generation"}, {"figure_path": "https://arxiv.org/html/2412.12091/x9.png", "caption": "Figure A2: Comparison of 3D rendering performance between latent reconstruction models fine-tuned without in-the-wild dataset (upper row) and with in-the-wild dataset (lower row). Involving in-the-wild datasets during fine-tuning improves the generalization capability.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc2e4\uc81c \ud658\uacbd \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ub41c \uc7a0\uc7ac \uc7ac\uad6c\uc131 \ubaa8\ub378\uacfc \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740 \ubaa8\ub378\uc758 3D \ub80c\ub354\ub9c1 \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc704\ucabd \ud589\uc740 \uc2e4\uc81c \ud658\uacbd \ub370\uc774\ud130\uc14b \uc5c6\uc774 \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c, \uc544\ub798\ucabd \ud589\uc740 \uc2e4\uc81c \ud658\uacbd \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc2e4\uc81c \ud658\uacbd \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \ubbf8\uc138 \uc870\uc815\uc774 \uc77c\ubc18\ud654 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "B. More Analysis on 3D Reconstruction"}, {"figure_path": "https://arxiv.org/html/2412.12091/x10.png", "caption": "Figure A3: Structure of Dual-branch Camera-guided Video Diffusion Model. We show the skeletons of the training pipeline, where random noise is added to the video latents. The conditional image is merged to the noisy latents via feature concatenation. The camera guidance is integrated with LoRA-branch (left) and ControlNet-branch (right). We ignore the text tokens, the diffusion time embeddings, the positional embeddings, and some reshaping operations for simplicity in the figure. In the foundation diffusion transformer, the text tokens are concatenated along number-of-token dimension with visual tokens. Thus we apply zero-padding to camera tokens to guarantee the same length before concatenation or element-wise sum. By default, we use SiLu as our activation function.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc774\uc911 \ubd84\uae30 \uce74\uba54\ub77c \uc720\ub3c4 \ube44\ub514\uc624 \ud655\uc0b0 \ubaa8\ub378\uc758 \ud6c8\ub828 \ud30c\uc774\ud504\ub77c\uc778 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\ub514\uc624 \uc7a0\uc7ac \uacf5\uac04\uc5d0 \ubb34\uc791\uc704 \ub178\uc774\uc988\uac00 \ucd94\uac00\ub418\uace0 \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uac00 \ud2b9\uc9d5 \uc5f0\uacb0\uc744 \ud1b5\ud574 \ub178\uc774\uc988\uac00 \uc788\ub294 \uc7a0\uc7ac \uacf5\uac04\uc5d0 \ubcd1\ud569\ub429\ub2c8\ub2e4. \uce74\uba54\ub77c \uc548\ub0b4\ub294 LoRA \ubd84\uae30(\uc67c\ucabd)\uc640 ControlNet \ubd84\uae30(\uc624\ub978\ucabd)\ub85c \ud1b5\ud569\ub429\ub2c8\ub2e4. \ub2e8\uc21c\ud654\ub97c \uc704\ud574 \ud14d\uc2a4\ud2b8 \ud1a0\ud070, \ud655\uc0b0 \uc2dc\uac04 \uc784\ubca0\ub529, \uc704\uce58 \uc784\ubca0\ub529 \ubc0f \uc77c\ubd80 \uc7ac\uad6c\uc131 \uc791\uc5c5\uc740 \uadf8\ub9bc\uc5d0\uc11c \uc0dd\ub7b5\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uae30\ubcf8 \ud655\uc0b0 \ubcc0\ud658\uae30\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \ud1a0\ud070\uc740 \ud1a0\ud070 \uc218 \ucc28\uc6d0\uc744 \ub530\ub77c \uc2dc\uac01\uc801 \ud1a0\ud070\uacfc \uc5f0\uacb0\ub429\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc5f0\uacb0 \ub610\ub294 \uc694\uc18c\ubcc4 \ud569\uacc4 \uc804\uc5d0 \uce74\uba54\ub77c \ud1a0\ud070\uc5d0 \uc81c\ub85c \ud328\ub529\uc744 \uc801\uc6a9\ud558\uc5ec \ub3d9\uc77c\ud55c \uae38\uc774\ub97c \ubcf4\uc7a5\ud569\ub2c8\ub2e4. \uae30\ubcf8\uc801\uc73c\ub85c SiLu\ub97c \ud65c\uc131\ud654 \ud568\uc218\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "section": "D.1. More Details for Model Architectures"}]