[{"figure_path": "https://arxiv.org/html/2502.04363/x3.png", "caption": "Figure 1. Open-Sora\u00a0(Zheng et\u00a0al., 2024) generates realistic videos from the user prompt (text) through three stages: 1) prompt embedding, 2) latent video generation, and 3) video decoding.", "description": "\uadf8\ub9bc 1\uc740 Open-Sora\uc758 \uc791\ub3d9 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0ac\uc6a9\uc790\uc758 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc785\ub825\ubc1b\uc544 1) \ud504\ub86c\ud504\ud2b8 \uc784\ubca0\ub529 \ub2e8\uacc4\ub97c \uac70\uccd0 \ud14d\uc2a4\ud2b8\ub97c \ubca1\ud130\ub85c \ubcc0\ud658\ud558\uace0, 2) \uc7a0\uc7ac\uc801 \ube44\ub514\uc624 \uc0dd\uc131 \ub2e8\uacc4\uc5d0\uc11c \ubcc0\ud658\ub41c \ubca1\ud130\ub97c \uae30\ubc18\uc73c\ub85c \uc7a0\uc7ac\uc801\uc778 \ube44\ub514\uc624 \ud45c\ud604\uc744 \uc0dd\uc131\ud558\uba70, 3) \ube44\ub514\uc624 \ub514\ucf54\ub529 \ub2e8\uacc4\ub97c \ud1b5\ud574 \uc7a0\uc7ac\uc801 \ube44\ub514\uc624 \ud45c\ud604\uc744 \uc2e4\uc81c \ube44\ub514\uc624\ub85c \ubcc0\ud658\ud558\ub294 \uacfc\uc815\uc744 \uc138 \ub2e8\uacc4\ub85c \ub098\ub204\uc5b4 \uc124\uba85\ud569\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \uc0ac\uc6a9\ub418\ub294 \ubaa8\ub378 (T5, STDiT, VAE)\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.1 \ubc30\uacbd: Open-Sora"}, {"figure_path": "https://arxiv.org/html/2502.04363/x4.png", "caption": "Figure 2. On-device Sora enables efficient text-to-video generation directly on the device by employing three key approaches: 1) Linear Proportional Leap, 2) Temporal Dimension Token Merging, and 3) Concurrent Inference with Dynamic Loading.", "description": "\uadf8\ub9bc 2\ub294 On-device Sora\uac00 \ubaa8\ubc14\uc77c \uae30\uae30\uc5d0\uc11c \ud6a8\uc728\uc801\uc778 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0dd\uc131\uc744 \uac00\ub2a5\ud558\uac8c \ud558\ub294 \uc138 \uac00\uc9c0 \ud575\uc2ec \uae30\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 1) \uc120\ud615 \ube44\ub840 \ub3c4\uc57d(Linear Proportional Leap): \ube44\ub514\uc624 \ud655\uc0b0\uc5d0\uc11c \uacfc\ub3c4\ud55c \uc7a1\uc74c \uc81c\uac70 \ub2e8\uacc4\ub97c \uc904\uc5ec \ucc98\ub9ac \uc18d\ub3c4\ub97c \ub192\uc785\ub2c8\ub2e4. 2) \uc2dc\uac04 \ucc28\uc6d0 \ud1a0\ud070 \ubcd1\ud569(Temporal Dimension Token Merging): \uc2dc\uac04\uc801\uc73c\ub85c \uc5f0\uc18d\ub41c \ud1a0\ud070\uc744 \ubcd1\ud569\ud558\uc5ec \uc5b4\ud150\uc158 \uacc4\uce35\uc5d0\uc11c\uc758 \uacc4\uc0b0\ub7c9\uc744 \uc904\uc785\ub2c8\ub2e4. 3) \ub3d9\uc2dc \ucd94\ub860 \ubc0f \ub3d9\uc801 \ub85c\ub529(Concurrent Inference with Dynamic Loading): \ub300\uc6a9\ub7c9 \ubaa8\ub378\uc744 \uc791\uc740 \ube14\ub85d\uc73c\ub85c \ubd84\ud560\ud558\uc5ec \uba54\ubaa8\ub9ac\uc5d0 \ub3d9\uc2dc\uc5d0 \ub85c\ub529\ud558\uace0 \ucd94\ub860\ud568\uc73c\ub85c\uc368 \uc81c\ud55c\ub41c \uba54\ubaa8\ub9ac \uc6a9\ub7c9 \ubb38\uc81c\ub97c \ud574\uacb0\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 On-device Sora\uc758 \uc791\ub3d9 \uc6d0\ub9ac\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uac1c\ub150\ub3c4\uc785\ub2c8\ub2e4.", "section": "3 Overview: On-device Sora"}, {"figure_path": "https://arxiv.org/html/2502.04363/x6.png", "caption": "Figure 3. The size of Open-Sora models: T5\u00a0(Raffel et\u00a0al., 2020) (18.00 GB), STDiT\u00a0(Zheng et\u00a0al., 2024) (4.50 GB), and VAE\u00a0(Doersch, 2016) (0.82 GB), which exceeds the available memory capacity of iPhone 15 Pro\u00a0(Apple, 2023) (3.3 GB).", "description": "\uadf8\ub9bc 3\uc740 Open-Sora \ubaa8\ub378\uc758 \ud06c\uae30\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. T5(Raffel et al., 2020)\ub294 18GB, STDiT(Zheng et al., 2024)\ub294 4.5GB, VAE(Doersch, 2016)\ub294 0.82GB\uc785\ub2c8\ub2e4. \uc774\ub294 iPhone 15 Pro(Apple, 2023)\uc758 \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba54\ubaa8\ub9ac \uc6a9\ub7c9\uc778 3.3GB\ub97c \ucd08\uacfc\ud558\ub294 \ud06c\uae30\uc785\ub2c8\ub2e4.  \uc989, Open-Sora \ubaa8\ub378\uc740 \ubaa8\ubc14\uc77c \uae30\uae30\uc758 \uba54\ubaa8\ub9ac \uc6a9\ub7c9\uc744 \ucd08\uacfc\ud558\uc5ec, \ubaa8\ubc14\uc77c \uae30\uae30\uc5d0\uc11c \uc9c1\uc811 \uc2e4\ud589\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc774 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2.2 \ubaa8\ubc14\uc77c \uae30\uae30\uc5d0\uc11c\uc758 \ube44\ub514\uc624 \uc0dd\uc131\uc758 \uacfc\uc81c"}, {"figure_path": "https://arxiv.org/html/2502.04363/x7.png", "caption": "Figure 4. An abstracted illustration of trajectories and latent visualizations for K=30\ud835\udc3e30K=30italic_K = 30 and n=15\ud835\udc5b15n=15italic_n = 15: (a) Rectified Flow\u00a0(Liu et\u00a0al., 2022) with full k=30\ud835\udc5830k=30italic_k = 30 denoising steps, generating intact and complete data, (b) Rectified Flow\u00a0(Liu et\u00a0al., 2022) with n+1=16\ud835\udc5b116n+1=16italic_n + 1 = 16 denoising steps without applying Linear Proportional Leap, resulting in low-quality data generation from variance with high step sizes (d\u2062tk\ud835\udc51subscript\ud835\udc61\ud835\udc58dt_{k}italic_d italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT), and (c) Linear Proportional Leap with n+1=15+1\ud835\udc5b1151n+1=15+1italic_n + 1 = 15 + 1 denoising steps, producing data nearly equivalent to (a).", "description": "\uadf8\ub9bc 4\ub294 K=30, n=15\uc77c \ub54c\uc758 \uada4\uc801\uacfc \uc7a0\uc7ac\uc801 \uc2dc\uac01\ud654\ub97c \ucd94\uc0c1\uc801\uc73c\ub85c \ub098\ud0c0\ub0b8 \uadf8\ub9bc\uc785\ub2c8\ub2e4. (a)\ub294 Liu et al.(2022)\uc758 Rectified Flow\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc804\uccb4 30\ub2e8\uacc4\uc758 \ub514\ub178\uc774\uc9d5 \uacfc\uc815\uc744 \uac70\uccd0 \uc644\uc804\ud55c \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 Liu et al.(2022)\uc758 Rectified Flow\ub97c \uc0ac\uc6a9\ud558\uc5ec Linear Proportional Leap\uc744 \uc801\uc6a9\ud558\uc9c0 \uc54a\uace0 16\ub2e8\uacc4\uc758 \ub514\ub178\uc774\uc9d5 \uacfc\uc815\uc744 \uac70\ucce4\uc744 \ub54c, \ud070 \ub2e8\uacc4 \ud06c\uae30(dtk)\ub85c \uc778\ud574 \ubd84\uc0b0\uc774 \ucee4\uc838 \uc800\ud488\uc9c8\uc758 \ub370\uc774\ud130\uac00 \uc0dd\uc131\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (c)\ub294 Linear Proportional Leap\uc744 \uc801\uc6a9\ud558\uc5ec 16\ub2e8\uacc4\uc758 \ub514\ub178\uc774\uc9d5 \uacfc\uc815\uc744 \uac70\ucce4\uc744 \ub54c, (a)\uc640 \uac70\uc758 \ub3d9\ub4f1\ud55c \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, Linear Proportional Leap\uc774 \ud6a8\uc728\uc801\uc778 \ub514\ub178\uc774\uc9d5\uc744 \uac00\ub2a5\ud558\uac8c \ud568\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.", "section": "4 Linear Proportional Leap"}, {"figure_path": "https://arxiv.org/html/2502.04363/x8.png", "caption": "Figure 5. An example of cosine similarities between two consecutive drifts estimated from STDiT\u00a0(Zheng et\u00a0al., 2024), i.e., \ud835\udc97\u2062(Pn,tn)\ud835\udc97subscript\ud835\udc43\ud835\udc5bsubscript\ud835\udc61\ud835\udc5b\\boldsymbol{v}(P_{n},t_{n})bold_italic_v ( italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) and \ud835\udc97\u2062(Pn\u22121,tn\u22121)\ud835\udc97subscript\ud835\udc43\ud835\udc5b1subscript\ud835\udc61\ud835\udc5b1\\boldsymbol{v}(P_{n-1},t_{n-1})bold_italic_v ( italic_P start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ) for 30 (red) and 50 steps (blue).", "description": "\uadf8\ub9bc 5\ub294 Open-Sora\uc758 \ud575\uc2ec \uad6c\uc131 \uc694\uc18c\uc778 STDiT \ubaa8\ub378\uc5d0\uc11c \ucd94\ucd9c\ud55c \ub450 \uc5f0\uc18d\uc801\uc778 \ub4dc\ub9ac\ud504\ud2b8 \ubca1\ud130(v(Pn, tn)\uacfc v(Pn-1, tn-1)) \uc0ac\uc774\uc758 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub4dc\ub9ac\ud504\ud2b8 \ubca1\ud130\ub294 video generation \uacfc\uc815\uc5d0\uc11c \ud2b9\uc815 \uc2dc\uac04(tn \ub610\ub294 tn-1)\uc5d0 \ub300\ud55c video frame\uc758 \ubcc0\ud654\ub7c9\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uadf8\ub798\ud504\ub294 \ubc18\ubcf5 \ud69f\uc218(denoising step)\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ub4dc\ub9ac\ud504\ud2b8 \ubca1\ud130 \uac04\uc758 \uc720\uc0ac\ub3c4\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube68\uac04\uc0c9 \uc120(30 steps)\uacfc \ud30c\ub780\uc0c9 \uc120(50 steps)\uc740 \uac01\uac01 30\ubc88\uacfc 50\ubc88\uc758 denoising step\uc744 \uac70\ucce4\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \uadf8\ub798\ud504\ub97c \ud1b5\ud574, denoising step\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \ub4dc\ub9ac\ud504\ud2b8 \ubca1\ud130 \uac04\uc758 \uc720\uc0ac\ub3c4\uac00 1\uc5d0 \uac00\uae4c\uc6cc\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub294 \ud6c4\ubc18\ubd80\uc758 \ub4dc\ub9ac\ud504\ud2b8 \ubca1\ud130\ub4e4\uc774 \uac70\uc758 \uc120\ud615\uc801\uc778 \uacbd\ud5a5\uc744 \ubcf4\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc120\ud615\uc801\uc778 \uacbd\ud5a5\uc740 Linear Proportional Leap (LPL) \uae30\ubc95\uc758 \ud6a8\uc728\uc131\uc744 \ub4b7\ubc1b\uce68\ud558\ub294 \uadfc\uac70\uac00 \ub429\ub2c8\ub2e4. LPL\uc740 \uc774 \uc120\ud615\uc801\uc778 \uacbd\ud5a5\uc744 \uc774\uc6a9\ud558\uc5ec video generation \uacfc\uc815\uc758 denoising step\uc744 \uc904\uc784\uc73c\ub85c\uc368 \ud6a8\uc728\uc131\uc744 \ub192\uc785\ub2c8\ub2e4.", "section": "4 Linear Proportional Leap"}, {"figure_path": "https://arxiv.org/html/2502.04363/x9.png", "caption": "Figure 6. In attention layers of STDiT\u00a0(Zheng et\u00a0al., 2024), two consecutive tokens are merged along the temporal dimension and subsequently unmerged after processing, reducing the token size by half and the computational complexity up to a quarter.", "description": "\uadf8\ub9bc 6\uc740 STDiT(Zheng et al., 2024)\uc758 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0\uc11c \uc2dc\uac04\uc801 \ucc28\uc6d0\uc744 \ub530\ub77c \ub450 \uac1c\uc758 \uc5f0\uc18d\ub41c \ud1a0\ud070\uc744 \ubcd1\ud569\ud558\uace0, \ucc98\ub9ac \ud6c4\uc5d0 \ub2e4\uc2dc \ubd84\ub9ac\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ud1a0\ud070\uc758 \ud06c\uae30\ub294 \uc808\ubc18\uc73c\ub85c \uc904\uc774\uace0, \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\ub294 \ucd5c\ub300 4\ubd84\uc758 1\uae4c\uc9c0 \uc904\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c\ub294, \uc5f0\uc18d\ub41c \ud504\ub808\uc784\ub4e4\uc744 \ud558\ub098\uc758 \ud1a0\ud070\uc73c\ub85c \ud569\uccd0\uc11c \ucc98\ub9ac\ub7c9\uc744 \uc904\uc774\uace0, \uc774\ud6c4 \ub2e4\uc2dc \uc6d0\ub798\ub300\ub85c \ubd84\ub9ac\ud558\uc5ec \uc2dc\uac04\uc801 \uc815\ubcf4\ub97c \uc720\uc9c0\ud569\ub2c8\ub2e4. \uc774 \ubc29\ubc95\uc740 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc744 \uc904\uc774\uace0, \uc18d\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ud6a8\uacfc\uac00 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5 Temporal Dimension Token Merging"}, {"figure_path": "https://arxiv.org/html/2502.04363/x10.png", "caption": "Figure 7. An illustration of the token merging and unmerging process over the temporal dimension.", "description": "\uadf8\ub9bc 7\uc740 Temporal Dimension Token Merging (TDTM) \uae30\ubc95\uc744 \uc124\uba85\ud558\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4. TDTM\uc740 \ube44\ub514\uc624 \ud504\ub808\uc784\ub4e4\uc744 \uc2dc\uacc4\uc5f4\uc801\uc73c\ub85c \ubb36\uc5b4 \ud1a0\ud070\uc758 \ud06c\uae30\ub97c \uc904\uc774\ub294 \uae30\ubc95\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 \uc5f0\uc18d\uc801\uc778 \ub450 \ud504\ub808\uc784\uc758 \ud1a0\ud070\uc744 \ud3c9\uade0\ub0b4\uc5b4 \ud558\ub098\uc758 \ud1a0\ud070\uc73c\ub85c \ud569\uce58\ub294 \uacfc\uc815(Merge)\uacfc, attention \uc5f0\uc0b0 \ud6c4 \ub2e4\uc2dc \uc6d0\ub798\uc758 \ud06c\uae30\ub85c \ub418\ub3cc\ub9ac\ub294 \uacfc\uc815(Unmerge)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 attention \uc5f0\uc0b0\uc5d0 \ud544\uc694\ud55c \uacc4\uc0b0\ub7c9\uc744 \uc904\uc5ec \ucc98\ub9ac \uc18d\ub3c4\ub97c \ub192\uc785\ub2c8\ub2e4.", "section": "5 Temporal Dimension Token Merging"}, {"figure_path": "https://arxiv.org/html/2502.04363/x11.png", "caption": "Figure 8. The block loading and inference cycles for (a) sequential loading and inference, and (b) concurrent inference.", "description": "\uadf8\ub9bc 8\uc740 \ubaa8\ub378 \ube14\ub85d \ub85c\ub529 \ubc0f \ucd94\ub860 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc21c\ucc28\uc801 \ub85c\ub529 \ubc0f \ucd94\ub860 \ubc29\uc2dd\uc73c\ub85c, GPU\uac00 \uac01 \ube14\ub85d\uc744 \ub85c\ub529\ud560 \ub54c\uae4c\uc9c0 \ub300\uae30\ud558\uba70, \ub85c\ub529\uc774 \uc644\ub8cc\ub41c \ud6c4\uc5d0\uc57c \uc2e4\ud589\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc774\ub85c \uc778\ud574 \ubaa8\ub378 \ucd94\ub860\uc758 \uc804\uccb4 \uc9c0\uc5f0 \uc2dc\uac04\uc774 \ud06c\uac8c \uc99d\uac00\ud569\ub2c8\ub2e4. (b)\ub294 \uc81c\uc548\ub41c \ubcd1\ub82c \ucc98\ub9ac \ubc29\uc2dd\uc73c\ub85c, CPU\ub294 (i+1)\ubc88\uc9f8 \ube14\ub85d\uc744 \ub85c\ub529\ud558\ub294 \ub3d9\uc548 GPU\ub294 i\ubc88\uc9f8 \ube14\ub85d\uc758 \ucd94\ub860\uc744 \ub3d9\uc2dc\uc5d0 \uc218\ud589\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 CPU \ubc0f GPU\uc758 \ubcd1\ub82c \ucc98\ub9ac\ub97c \ucd5c\ub300\ud654\ud558\uc5ec \ubaa8\ub378 \ucd94\ub860\uc758 \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ub2e8\ucd95\ud569\ub2c8\ub2e4.  \uac01 \ube14\ub85d\uc758 \ub85c\ub529 \ubc0f \ucd94\ub860 \uc8fc\uae30\ub294 \ube68\uac04\uc0c9(\ub85c\ub529)\uacfc \uac80\uc740\uc0c9(\ucd94\ub860) \uc0c1\uc790\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "6 \ub3d9\uc2dc \ucd94\ub860 \ubc0f \ub3d9\uc801 \ub85c\ub529"}, {"figure_path": "https://arxiv.org/html/2502.04363/x12.png", "caption": "Figure 9. Example videos generated by On-device Sora and Open-Sora\u00a0(Zheng et\u00a0al., 2024) (68 frames, 256\u00d7256 resolution).", "description": "\uadf8\ub9bc 9\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 On-device Sora\uc640 \uae30\uc874\uc758 Open-Sora (Zheng et al., 2024)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \ubaa8\ub378 \ubaa8\ub450 \"\ub9d0\ub77c\ubd99\uc740 \ub099\uc5fd\uc774 \uc232\uc5d0\uc11c \ud0c0\uc624\ub974\ub294 \ubaa8\uc2b5\" \uacfc \"\uc5ec\uc6b0\uc6d0\uc22d\uc774 \ud074\ub85c\uc988\uc5c5\" \uc774\ub77c\ub294 \ub450 \uac00\uc9c0 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec 68\ud504\ub808\uc784, 256x256 \ud574\uc0c1\ub3c4\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud588\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 On-device Sora\uac00 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \ucf58\ud150\uce20\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc2dc\uac01\uc801 \uc99d\uac70\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.  On-device Sora\uac00 \uc0dd\uc131\ud55c \ube44\ub514\uc624\ub294 Open-Sora\uc640 \ube44\uad50\ud558\uc5ec \ube44\uc2b7\ud55c \uc218\uc900\uc758 \ud654\uc9c8\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \ubaa8\ubc14\uc77c \uae30\uae30\uc5d0\uc11c \ud6a8\uc728\uc801\uc73c\ub85c \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "8.1 \ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5"}, {"figure_path": "https://arxiv.org/html/2502.04363/x13.png", "caption": "Figure 10. The block loading and inference cycle for Dynamic Loading applied with Concurrent Inference.", "description": "\uadf8\ub9bc 10\uc740 \ub3d9\uc2dc \ucd94\ub860\uacfc \ud568\uaed8 \ub3d9\uc801 \ub85c\ub529\uc774 \uc801\uc6a9\ub41c \uacbd\uc6b0\uc758 \ube14\ub85d \ub85c\ub529 \ubc0f \ucd94\ub860 \uc8fc\uae30\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc801 \ub85c\ub529\uc740 \uc0ac\uc6a9 \uac00\ub2a5\ud55c \uba54\ubaa8\ub9ac\uc5d0 \ub530\ub77c \ubaa8\ub378 \ube14\ub85d\uc758 \ud558\uc704 \uc9d1\ud569\uc744 \uba54\ubaa8\ub9ac\uc5d0 \uc720\uc9c0\ud558\ub294 \ub3d9\uc2dc\uc5d0, CPU\ub294 (i+1)\ubc88\uc9f8 \ube14\ub85d\uc744 \ub85c\ub529\ud558\ub294 \ub3d9\uc548 GPU\ub294 i\ubc88\uc9f8 \ube14\ub85d\uc744 \ub3d9\uc2dc\uc5d0 \uc2e4\ud589\ud558\ub294 \ub3d9\uc2dc \ucd94\ub860\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ube14\ub85d \ub85c\ub529 \uc2dc\uac04\uacfc \ucd94\ub860 \uc2dc\uac04\uc758 \uacb9\uce68\uc774 \ubc1c\uc0dd\ud558\uc5ec \uc804\ubc18\uc801\uc778 \ucd94\ub860 \uc9c0\uc5f0 \uc2dc\uac04\uc774 \ub2e8\ucd95\ub429\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \ube68\uac04\uc0c9 \uc0c1\uc790\ub294 \ub85c\ub529 \uc8fc\uae30\ub97c \ub098\ud0c0\ub0b4\uace0, \uac80\uc740\uc0c9 \uc0c1\uc790\ub294 \ucd94\ub860 \uc8fc\uae30\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub3d9\uc2dc \ucd94\ub860\uc744 \uc0ac\uc6a9\ud558\uba74 GPU\uac00 \uac70\uc758 \uc720\ud734 \uc0c1\ud0dc\uac00 \ub418\uc9c0 \uc54a\uace0 \ube14\ub85d \ub85c\ub529 \ubc0f \ucd94\ub860\uc774 \ubcd1\ub82c\ub85c \uc218\ud589\ub429\ub2c8\ub2e4. \uc774\ub294 \uc21c\ucc28 \ub85c\ub529 \ubc0f \ucd94\ub860\uc5d0 \ube44\ud574 \uc804\uccb4 \ucd94\ub860 \uc18d\ub3c4\ub97c \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \ub3d9\uc801 \ub85c\ub529\uc740 CPU \ubc0f GPU \uc0ac\uc6a9\ub960\uc744 \ucd5c\uc801\ud654\ud558\uc5ec 3.3GB\uc758 \uc81c\ud55c\ub41c \uba54\ubaa8\ub9ac\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uad00\ub9ac\ud569\ub2c8\ub2e4.", "section": "6 Concurrent Inference with Dynamic Loading"}, {"figure_path": "https://arxiv.org/html/2502.04363/x14.png", "caption": "Figure 11. A visual comparison of videos generated by On-device Sora and Open-Sora\u00a0(Zheng et\u00a0al., 2024), evaluated using VBench\u00a0(Huang et\u00a0al., 2024).", "description": "\uadf8\ub9bc 11\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ub41c On-device Sora\uc640 Open-Sora (Zheng et al., 2024)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub97c VBench (Huang et al., 2024)\ub97c \uc774\uc6a9\ud558\uc5ec \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ubc94\uc8fc\uc758 \ube44\ub514\uc624(\ub3d9\ubb3c, \uac74\ucd95\ubb3c, \uc74c\uc2dd, \uc0ac\ub78c, \ub77c\uc774\ud504 \uc2a4\ud0c0\uc77c, \uc2dd\ubb3c, \ud48d\uacbd, \ucc28\ub7c9)\uc5d0 \ub300\ud574 On-device Sora\uc640 Open-Sora\uac00 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \uc2dc\uac01\uc801 \ud488\uc9c8\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec, \uac01 \ube44\ub514\uc624\uc758 \uc2dc\uac04\uc801 \uc77c\uad00\uc131, \ubc30\uacbd \uc77c\uad00\uc131, \uae5c\ubc15\uc784, \uc6c0\uc9c1\uc784 \ubd80\ub4dc\ub7ec\uc6c0, \uc5ed\ub3d9\uc131, \ubbf8\uc801 \ud488\uc9c8, \uc601\uc0c1 \ud488\uc9c8 \ub4f1\uc758 \uc5ec\ub7ec \uc694\uc18c\ub97c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 On-device Sora\uc758 \uc131\ub2a5\uacfc Open-Sora\uc640\uc758 \ucc28\uc774\uc810\uc744 \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "8.1 \ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5"}, {"figure_path": "https://arxiv.org/html/2502.04363/x15.png", "caption": "Figure 12. The snapshots of videos (68 frames, 256\u00d7256 resolution) applied with various LPL settings (Table\u00a03).", "description": "\uadf8\ub9bc 12\ub294 \ubcf8 \ub17c\ubb38\uc758 4\uc7a5\uc5d0\uc11c \uc81c\uc548\ub41c \uc120\ud615 \ube44\ub840 \ub3c4\uc57d(LPL) \uae30\ubc95\uc758 \ub2e4\uc591\ud55c \uc124\uc815(\ud45c 3 \ucc38\uc870)\uc744 \uc801\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uc2a4\ub0c5\uc0f7\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ube44\ub514\uc624\ub294 68\ud504\ub808\uc784\uc73c\ub85c \uad6c\uc131\ub418\uba70, \ud574\uc0c1\ub3c4\ub294 256x256 \ud53d\uc140\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 LPL \uc124\uc815\uc5d0 \ub530\ub978 \ube44\ub514\uc624\uc758 \uc2dc\uac01\uc801 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud55c \uc608\uc2dc\ub85c, \uc11c\ub85c \ub2e4\ub978 LPL \uc124\uc815\uc5d0\uc11c \uc0dd\uc131\ub41c \ube44\ub514\uc624\uac00 \uc720\uc0ac\ud55c \uc758\ubbf8\ub97c \uc720\uc9c0\ud558\uba74\uc11c\ub3c4, \uc120\ud615 \ube44\ub840 \ub3c4\uc57d\uc758 \ud6a8\uacfc\ub97c \ud1b5\ud574 \uc0dd\uc131 \uc2dc\uac04\uc774 \ub2e8\ucd95\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "8.2 \uc120\ud615 \ube44\ub840 \ub3c4\uc57d"}]