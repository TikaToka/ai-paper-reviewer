---
title: "Analyze Feature Flow to Enhance Interpretation and Steering in Language Models"
summary: "ë³¸ ì—°êµ¬ëŠ” í¬ì†Œ ìë™ ì¸ì½”ë”ë¥¼ ì´ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ íŠ¹ì§• íë¦„ì„ ì¶”ì í•˜ê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ í•´ì„ì„± ë° ì œì–´ ê¸°ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤."
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Large Language Models", "ğŸ¢ T-Tech",]
showSummary: true
date: 2025-02-05
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.03032 {{< /keyword >}}
{{< keyword icon="writer" >}} Daniil Laptev et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-07 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.03032" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.03032" target="_self" >}}
â†— Hugging Face
{{< /button >}}




### TL;DR


{{< lead >}}

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë›°ì–´ë‚œ ì„±ëŠ¥ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‚´ë¶€ ë™ì‘ì´ ë¶ˆíˆ¬ëª…í•˜ì—¬ í•´ì„ê³¼ ì œì–´ê°€ ì–´ë µë‹¤ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ë‹¨ì¼ ê³„ì¸µ ë˜ëŠ” ì”ì°¨ íë¦„ì—ë§Œ ì´ˆì ì„ ë§ì¶°ì™”ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)ë¥¼ í™œìš©í•˜ì—¬ LLMì˜ ì—°ì†ì ì¸ ê³„ì¸µì— ê±¸ì³ íŠ¹ì§•ì˜ íë¦„ì„ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤.

ë³¸ ë…¼ë¬¸ì˜ í•µì‹¬ ë°©ë²•ì€ ë°ì´í„°ê°€ í•„ìš” ì—†ëŠ” ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê° ê³„ì¸µì—ì„œ íŠ¹ì§•ì˜ ì§€ì†ì„±, ë³€í™˜, ìµœì´ˆ ì¶œí˜„ ì—¬ë¶€ë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´, ê° ê³„ì¸µì—ì„œ íŠ¹ì§•ì˜ ì§„í™” ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ì„¸ë¶„í™”ëœ íë¦„ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³ , ëª¨ë¸ì˜ ê³„ì‚° ê³¼ì •ì— ëŒ€í•œ ì •êµí•œ í•´ì„ê³¼ ê¸°ê³„ì ì¸ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, ì„ íƒëœ íŠ¹ì§•ì„ ì¦í­ ë˜ëŠ” ì–µì œí•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ í–‰ë™ì„ ì§ì ‘ì ìœ¼ë¡œ ì œì–´í•˜ê³ , í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œ ì£¼ì œë¥¼ ëª©í‘œ ì§€í–¥ì ìœ¼ë¡œ ì œì–´í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì›í™œí•˜ê³  íˆ¬ëª…í•œ ëª¨ë¸ ì¡°ì‘ì„ ìœ„í•œ ìƒˆë¡œìš´ ìˆ˜ë‹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)ë¥¼ ì´ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ë°œê²¬ëœ íŠ¹ì§•ë“¤ì„ ì—°ì†ì ì¸ ê³„ì¸µì— ê±¸ì³ ì²´ê³„ì ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²• ì œì‹œ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} ê³„ì¸µ ê°„ íŠ¹ì§• íë¦„ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ì—¬ ëª¨ë¸ì˜ ê³„ì‚° ê³¼ì •ì— ëŒ€í•œ ì„¸ë¶„í™”ëœ í•´ì„ì„±ê³¼ ê¸°ê³„ì ì¸ í†µì°°ë ¥ ì œê³µ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ê³„ì¸µ ê°„ íŠ¹ì§• ì§€ë„ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ í–‰ë™ì„ ì§ì ‘ì ìœ¼ë¡œ ì œì–´í•˜ê³ , í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œ ëª©í‘œ ì§€í–¥ì ì¸ ì£¼ì œ ì œì–´ ë‹¬ì„± {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í•´ì„ì„±ê³¼ ì œì–´ ê¸°ëŠ¥ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹™ë‹ˆë‹¤. **ë°ì´í„°ê°€ ì—†ëŠ” ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì˜ ë‚´ë¶€ ë™ì‘ì„ ë¶„ì„í•˜ê³  ì¡°ì‘**í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì‹œí•˜ì—¬, í–¥í›„ ì—°êµ¬ì—ì„œ **ëª¨ë¸ì˜ íˆ¬ëª…ì„±ê³¼ ì œì–´ ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ë° í¬ê²Œ ê¸°ì—¬**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, **ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ ëª¨ë¸ì˜ í–‰ë™ì„ ëª©í‘œ ì§€í–¥ì ìœ¼ë¡œ ì œì–´**í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì—´ì–´ì£¼ëŠ” ì¤‘ìš”í•œ ë°œê±¸ìŒì´ ë  ê²ƒì…ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.03032/x1.png)

> ğŸ”¼ ê·¸ë¦¼ 1ì€ ëª¨ë¸ ë‚´ë¶€ì˜ íŠ¹ì§• ë§¤í•‘ ê³¼ì •ì„ ë„ì‹ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ê³„ì¸µì˜ ì¶œë ¥ì—ì„œ í•™ìŠµëœ SAE(Sparse Autoencoder)ì˜ íŠ¹ì§• ì¤‘ í•˜ë‚˜(ì¸ë±ìŠ¤ i)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì´ íŠ¹ì§•ì˜ ì„ë² ë”© ë²¡í„°(f)ëŠ” í•´ë‹¹ SAEì˜ ë””ì½”ë” ê°€ì¤‘ì¹˜ì˜ ië²ˆì§¸ ì—´ì— í•´ë‹¹í•©ë‹ˆë‹¤.  ì„ íƒëœ íŠ¹ì§• ë²¡í„°ëŠ” ê°™ì€ ê³„ì¸µì˜ ë‹¤ë¥¸ SAE(MLP ë° ì–´í…ì…˜ ë¸”ë¡ ì´í›„, ê·¸ë¦¬ê³  ì´ì „ ê³„ì¸µì˜ ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì˜ SAE)ì˜ ëª¨ë“  ì—´ë“¤ê³¼ ë¹„êµë©ë‹ˆë‹¤. ì´ ë¹„êµë¥¼ í†µí•´ íŠ¹ì§•ì˜ ê¸°ì›(source)ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ 3.3ì ˆì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Schematic illustration of inner-layer matching. We select a feature with index iğ‘–iitalic_i on the SAE trained at the layer output. Its embedding ğŸğŸ\mathbf{f}bold_f, which is the iğ‘–iitalic_ith column of this SAEâ€™s decoder weight, is compared to every column of other SAEs on the same layer (after the MLP and attention blocks, as well as with the SAE on the residual stream before some layer). These comparisons indicate the featureâ€™s source. See Section 3.3 for more details.
> </details>





{{< table-caption >}}
| Feature index | Interpretation from Neuronpedia |
|---|---| 
| 3/res/9811 | terms related to gravity and its influences |
| 18/res/14053 | terms related to theoretical frameworks and conceptual models |
| 18/res/1336 | references to Dark Matter and astronomical phenomena |
| 20/res/4506 | terms related to physical laws and scientific principles |
| 21/res/13226 | references to quantum concepts and theories |
| 22/res/9002 | terms related to models and their specifications, |
| 22/res/15105 | terms related to force and energy dynamics |
| 23/res/4086 | terms related to forces and dynamics in physical systems |
| 24/res/7017 | terms related to electromagnetic interactions and properties |
| 24/res/14548 | terms and references related to particle physics and standard model parameters |{{< /table-caption >}}

> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 'Scientific concepts and entities' ì£¼ì œì˜ ë¹„í™œì„±í™”ë¥¼ ìœ„í•´ ì´ˆê¸° ì„ íƒëœ íŠ¹ì§•ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° íŠ¹ì§•ì€ í•´ë‹¹ ë ˆì´ì–´, ëª¨ë“ˆ, ê·¸ë¦¬ê³  Neuronpediaì— ì˜í•´ ì œê³µëœ í•´ì„ê³¼ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤. ì´ í‘œëŠ” ëª¨ë¸ì˜ íŠ¹ì§•ë“¤ì´ ì–´ë–»ê²Œ ì£¼ì œì™€ ê´€ë ¨ë˜ëŠ”ì§€ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Features initially chosen for deactivation of â€œScientific concepts and entitiesâ€ theme.
> </details>





### In-depth insights


#### Cross-Layer Feature Flow
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” 'ê³„ì¸µ ê°„ íŠ¹ì§• íë¦„(Cross-Layer Feature Flow)' ë¶„ì„ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í•´ì„ì„±ê³¼ ì œì–´ëŠ¥ë ¥ í–¥ìƒ**ì´ë¼ëŠ” ì¤‘ìš”í•œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ í•µì‹¬ ì „ëµì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ì¼ ê³„ì¸µ ë¶„ì„ ë°©ì‹ì„ ë„˜ì–´, **ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì³ íŠ¹ì§•ë“¤ì˜ ìƒì„±, ë³€í™˜, ì†Œë©¸ ê³¼ì •ì„ ì¶”ì **í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ ë‚´ë¶€ ë™ì‘ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, **í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)**ë¥¼ í™œìš©í•˜ì—¬ ì¶”ì¶œëœ í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì§•ë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê³„ì¸µ ê°„ ì—°ê²° ê´€ê³„ë¥¼ ì‹œê°í™”í•˜ê³ , ì´ë¥¼ í†µí•´ **íŠ¹ì§•ì˜ ìˆ˜ëª… ì£¼ê¸°, ê³„ì¸µ ê°„ ìƒí˜¸ ì‘ìš©, ì •ë³´ íë¦„ ê²½ë¡œ** ë“±ì„ ëª…í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ìœ ë™ ê·¸ë˜í”„(flow graph)**ë¥¼ í†µí•´ ì‹œê°í™”ëœ íŠ¹ì§•ì˜ íë¦„ì€ ë‹¨ìˆœíˆ ëª¨ë¸ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…í•˜ëŠ” ê²ƒì— ê·¸ì¹˜ì§€ ì•Šê³ , **ëª¨ë¸ì˜ í–‰ë™ì„ ì§ì ‘ì ìœ¼ë¡œ ì œì–´**í•˜ëŠ” ë° í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì§•ì˜ í™œì„±í™” ë˜ëŠ” ì–µì œë¥¼ í†µí•´ **í…ìŠ¤íŠ¸ ìƒì„±ì˜ ì£¼ì œë¥¼ ëª©í‘œ ì§€í–¥ì ìœ¼ë¡œ ì¡°ì ˆ**í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” **íˆ¬ëª…í•˜ê³  ì œì–´ ê°€ëŠ¥í•œ LLM ì¡°ì‘**ì„ ìœ„í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.  ê²°ë¡ ì ìœ¼ë¡œ, ë³¸ ì—°êµ¬ëŠ” LLMì˜ ë¸”ë™ë°•ìŠ¤ì„±ì„ ê·¹ë³µí•˜ê³ , ëª¨ë¸ì˜ í•´ì„ì„±ê³¼ ì œì–´ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í˜ì‹ ì ì¸ ë°©ë²•ë¡ ì„ ì œì‹œí•˜ë©°, í–¥í›„ LLM ì—°êµ¬ ë°œì „ì— í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

#### Data-Free SAE Matching
ë°ì´í„° ì—†ëŠ” SAE ë§¤ì¹­ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ì˜ ë‚´ë¶€ í‘œí˜„ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì–»ê¸° ìœ„í•´ **ì‚¬ì „ í›ˆë ¨ëœ í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)**ë¥¼ í™œìš©í•˜ëŠ” ë°ì´í„° ê¸°ë°˜ì´ ì•„ë‹Œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ì´ ê¸°ë²•ì€ LLMì˜ ì—°ì†ì ì¸ ê³„ì¸µ ê°„ì— ë°œê²¬ëœ íŠ¹ì§•ì˜ ì „íŒŒì™€ ë³€í˜•ì„ ì¶”ì í•˜ì—¬ **íŠ¹ì§• íë¦„ ê·¸ë˜í”„**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì˜ ê³„ì‚°ì  ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì„¸ë¶€ì ì¸ í•´ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, íŠ¹ì§•ì˜ ê¸°ì›, ì§€ì†ì„±, ë³€í™˜ì„ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.  **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì¸µ ê°„ì˜ SAE íŠ¹ì§•ì„ ë¹„êµ ë¶„ì„í•¨ìœ¼ë¡œì¨, ì´ ë°©ë²•ì€ íŠ¹ì§•ì˜ ì¶œí˜„ê³¼ ì†Œë©¸ íŒ¨í„´ì„ ë°í˜€ë‚´ê³ , ì´ëŸ¬í•œ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì˜ ë™ì‘ì„ ì§ì ‘ì ìœ¼ë¡œ ì œì–´í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.  **ë°ì´í„°ê°€ í•„ìš” ì—†ë‹¤ëŠ” ì **ì´ íŠ¹ì§•ì´ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì— ëŒ€í•œ ë°ì´í„° ë…ë¦½ì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ê°€ ë©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í•´ì„ì„±ì„ í–¥ìƒì‹œí‚¤ê³ , íˆ¬ëª…í•œ ë°©ì‹ìœ¼ë¡œ LLMì„ ì¡°ì‘í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

#### Multi-Layer Model Steer
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ë‹¤ì¸µ ëª¨ë¸ ì¡°ì •(Multi-Layer Model Steering) ê¸°ë²•ì€ **ë‹¨ì¼ ê³„ì¸µ ë¶„ì„ì˜ í•œê³„ë¥¼ ê·¹ë³µ**í•˜ê³ , **ëª¨ë¸ì˜ ë‹¤ì¸µì  êµ¬ì¡°ë¥¼ ê³ ë ¤**í•˜ì—¬ ë³´ë‹¤ íš¨ê³¼ì ì´ê³  ì •êµí•œ ëª¨ë¸ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  ê¸°ì¡´ì˜ ë‹¨ì¼ ê³„ì¸µ ì ‘ê·¼ ë°©ì‹ì€ íŠ¹ì • ê³„ì¸µì—ì„œì˜ íŠ¹ì§•ë§Œì„ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ ë™ì‘ì„ ì œí•œì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ë°˜ë©´, ë‹¤ì¸µ ëª¨ë¸ ì¡°ì • ê¸°ë²•ì€ **ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì³ íŠ¹ì§•ì˜ íë¦„(flow graphs)ì„ ì¶”ì **í•˜ê³ , **ì„ íƒì ì¸ íŠ¹ì§•ì˜ ì¦í­ ë˜ëŠ” ì–µì œ**ë¥¼ í†µí•´ ëª¨ë¸ì˜ í–‰ë™ì„ ëª©í‘œ ì§€í–¥ì ìœ¼ë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ **í…ìŠ¤íŠ¸ ìƒì„± ê³¼ì •ì—ì„œ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í…Œë§ˆ ì œì–´ë¥¼ ë³´ë‹¤ ì •ë°€í•˜ê²Œ ìˆ˜í–‰**í•  ìˆ˜ ìˆìœ¼ë©°, **ëª¨ë¸ì˜ ë‚´ë¶€ ë™ì‘ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì´ëŠ” ë° ê¸°ì—¬**í•©ë‹ˆë‹¤.  **SAE(Sparse Autoencoder) íŠ¹ì§•ì„ í™œìš©**í•˜ì—¬ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³ , **ë°ì´í„°ê°€ í•„ìš” ì—†ëŠ”(data-free) ë°©ì‹**ìœ¼ë¡œ ëª¨ë¸ì˜ ë‹¤ì¸µì  êµ¬ì¡°ì™€ íŠ¹ì§•ì˜ ë™ì  ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.  ê²°ê³¼ì ìœ¼ë¡œ ë‹¤ì¸µ ëª¨ë¸ ì¡°ì • ê¸°ë²•ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í•´ì„ì„±ê³¼ ì œì–´ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê°•ë ¥í•œ ë„êµ¬ë¡œì„œ, ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ í™œìš©ë  ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

#### Circuit-Like Computations
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ 'ìˆœí™˜ì  ê³„ì‚°(Circuit-Like Computations)' ê°œë…ì€ **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)** ë‚´ë¶€ì˜ íŠ¹ì§•ë“¤ì´ **ë‹¤ì¸µì ì´ê³  ìƒí˜¸ì‘ìš©ì ì¸ ë°©ì‹**ìœ¼ë¡œ ì²˜ë¦¬ë˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.  **í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)**ë¥¼ í™œìš©í•˜ì—¬ ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì€ ë‹¨ìˆœíˆ ê° ì¸µì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **ë‹¤ì–‘í•œ ëª¨ë“ˆ(MLP, ì–´í…ì…˜)**ì„ ê±°ì¹˜ë©´ì„œ **ì§„í™”í•˜ê³  ë³€í˜•**ë˜ë©°, ì´ëŸ¬í•œ ê³¼ì •ì´ ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.  ì´ëŠ” ë§ˆì¹˜ ì „ì íšŒë¡œì²˜ëŸ¼ íŠ¹ì§•ë“¤ì´ ì—°ê²°ë˜ê³  ìƒí˜¸ ì‘ìš©í•˜ëŠ” **íë¦„ ê·¸ë˜í”„(flow graph)**ë¡œ ì‹œê°í™”ë  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ **ëª¨ë¸ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ì´í•´**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ë‹¤ì¸µì  íŠ¹ì§• íë¦„ ë¶„ì„**ì€ ëª¨ë¸ì˜ ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ ë°íˆëŠ” ë° ë„ì›€ì„ ì¤„ ë¿ë§Œ ì•„ë‹ˆë¼, **ëª©í‘œ ì§€í–¥ì ì¸ ëª¨ë¸ ì¡°ì‘**ì„ ìœ„í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.  íŠ¹ì • íŠ¹ì§•ì„ ì¦í­í•˜ê±°ë‚˜ ì–µì œí•¨ìœ¼ë¡œì¨ í…ìŠ¤íŠ¸ ìƒì„±ì˜ ì£¼ì œë‚˜ ìŠ¤íƒ€ì¼ì„ ì œì–´í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì€ **LLMì˜ í•´ì„ë ¥ ë° ì œì–´ë ¥ í–¥ìƒ**ì— í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

#### Future Research: Circuits
ë¯¸ë˜ ì—°êµ¬ì˜ ì´ˆì ì€ **ìˆœí™˜ ì‹ ê²½ë§(RNN)** ë° **ìˆœí™˜ì  êµ¬ì¡°**ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ì„œì˜ íšŒë¡œ(circuit) ê°œë…ì„ ë”ìš± ì‹¬ì¸µì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ë§ì¶°ì ¸ì•¼ í•©ë‹ˆë‹¤.  ì´ëŠ” ë‹¨ìˆœíˆ íšŒë¡œì˜ ì¡´ì¬ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì„ ë„˜ì–´, **íšŒë¡œì˜ ê¸°ëŠ¥, ìƒí˜¸ ì‘ìš©, ê·¸ë¦¬ê³  ëª¨ë¸ì˜ ì „ì²´ ë™ì‘ì— ë¯¸ì¹˜ëŠ” ì˜í–¥**ì„ ì •í™•í•˜ê²Œ ê·œëª…í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. íŠ¹íˆ, **ë‹¤ì–‘í•œ ìœ í˜•ì˜ íšŒë¡œì™€ ê·¸ ì—­í• **, ê·¸ë¦¬ê³  **íšŒë¡œ ê°„ì˜ ìƒí˜¸ ì‘ìš©**ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì˜ˆì¸¡ ë° ìƒì„± ê³¼ì •ì— ëŒ€í•œ ë”ìš± ê¹Šì´ ìˆëŠ” í†µì°°ë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë˜í•œ, **íšŒë¡œì˜ ìƒì„± ë° ì§„í™” ê³¼ì •**ì„ ê·œëª…í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ê³¼ì • ìì²´ì— ëŒ€í•œ ìƒˆë¡œìš´ ì´í•´ë¥¼ ë„ì¶œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë”ìš± íš¨ìœ¨ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸**ì„ ì„¤ê³„í•˜ëŠ” ë° í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê¶ê·¹ì ìœ¼ë¡œëŠ”, ì´ëŸ¬í•œ ì—°êµ¬ë¥¼ í†µí•´ **ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ì‹ ë¢°ì„± ë° ì„¤ëª… ê°€ëŠ¥ì„±ì„ í–¥ìƒ**ì‹œí‚¤ê³ , ë³´ë‹¤ ì•ˆì „í•˜ê³  ì±…ì„ê° ìˆëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


### More visual insights

<details>
<summary>More on figures
</summary>


![](https://arxiv.org/html/2502.03032/x2.png)

> ğŸ”¼ ê·¸ë¦¼ 2ëŠ” ë³¸ ë…¼ë¬¸ì˜ 5.2ì ˆ ë¹„í™œì„±í™” ì‹¤í—˜ì—ì„œ ì‚¬ìš©ëœ íŠ¹ì§• íë¦„ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  24ë²ˆì§¸ ë ˆì´ì–´ì˜ ì”ì°¨(residual) ìŠ¤íŠ¸ë¦¼ì—ì„œ ì¸ë±ìŠ¤ 14548ë²ˆ íŠ¹ì§•ì„ ì‹œì‘ì ìœ¼ë¡œ í•˜ì—¬, í•´ë‹¹ íŠ¹ì§•ì´ ëª¨ë¸ì˜ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ ê±°ì¹˜ë©´ì„œ ì–´ë–»ê²Œ ë³€í™”í•˜ê³  ì „íŒŒë˜ëŠ”ì§€ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ê° ë ˆì´ì–´ì—ì„œì˜ MLP, ì–´í…ì…˜, ê·¸ë¦¬ê³  ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì˜ íŠ¹ì§• ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬, íŠ¹ì§•ì˜ ê¸°ì›ê³¼ ì§„í™” ê³¼ì •ì„ ì¶”ì í•©ë‹ˆë‹¤.  ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ Eë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
> <details>
> <summary>read the caption</summary>
> Figure 2: An illustration of the resulting flow graph, which we also use in the deactivation experiment (section 5.2). As a starting point, we select the feature on the 24th-layer residual with index 14548. For a detailed explanation of this graph, see Appendix E.
> </details>



![](https://arxiv.org/html/2502.03032/x3.png)

> ğŸ”¼ ê·¸ë¦¼ 3ì€ ì´ì „ ì¸µ(predecessor)ê³¼ ë™ì‹œ í™œì„±í™”ì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì˜ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì¸µì—ì„œ 350ê°œì˜ íŠ¹ì§•ì„ ìƒ˜í”Œë§í•˜ì—¬ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.  'From MLP' ê·¸ë£¹ì€ s(M)ì´ ë†’ê³  s(R)ì´ ë‚®ì€ ë°˜ë©´, 'From RES' ê·¸ë£¹ì€ ê·¸ ë°˜ëŒ€ì…ë‹ˆë‹¤.  ì´ëŠ” MLP ëª¨ë“ˆê³¼ì˜ ë™ì‹œ í™œì„±í™”ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ê³µìœ ëœ ì˜ë¯¸ ë° ê¸°ì „ì  íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì¢‹ì€ ì§€í‘œë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 3: Example of cosine similarity vs. simultaneous activation with a predecessor (350 features were sampled per layer). â€œFrom MLPâ€ and â€œFrom RESâ€ groups are notably different: high s(M)superscriptğ‘ ğ‘€s^{(M)}italic_s start_POSTSUPERSCRIPT ( italic_M ) end_POSTSUPERSCRIPT and low s(R)superscriptğ‘ ğ‘…s^{(R)}italic_s start_POSTSUPERSCRIPT ( italic_R ) end_POSTSUPERSCRIPT suggest simultaneous activation with an MLP-module match. Cosine similarity serves as a good proxy for shared semantic and mechanistic properties.
> </details>



![](https://arxiv.org/html/2502.03032/x4.png)

> ğŸ”¼ ê·¸ë¦¼ 4ëŠ” ê° ëª¨ë“ˆì˜ ìœ ì‚¬ë„ ì ìˆ˜ì— ëŒ€í•œ ê·¸ë£¹ ê°„ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. AOëŠ” ëª¨ë“ˆ Pê°€ í•œ ê·¸ë£¹ì—ì„œë§Œ í™œì„±í™”ë¨ì„ ì˜ë¯¸í•˜ê³ , ABëŠ” ë‘ ê·¸ë£¹ ëª¨ë‘ì—ì„œ í™œì„±í™”ë¨ì„, IBëŠ” ë‘ ê·¸ë£¹ ëª¨ë‘ì—ì„œ ë¹„í™œì„±í™”ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. MLPì˜ ê²½ìš°, MLPê°€ ë‘ ê·¸ë£¹ ëª¨ë‘ì—ì„œ í™œì„±í™”ë  ë•Œ ë‘ ê·¸ë£¹ì˜ s(R)ì´ ì„œë¡œ ë‹¤ë¥¸ ê²½ìš°ëŠ” 87%ì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì´ëŠ” MLP ëª¨ë“ˆì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œë„ ë‘ ê·¸ë£¹ ê°„ì— ê³µí†µëœ íŠ¹ì§•ì´ ìƒë‹¹íˆ ì¡´ì¬í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 4: Percentage of statistically significant differences between groups for each moduleâ€™s similarity scores. AO means module Pğ‘ƒPitalic_P is active in only one group, AB means active in both, and IB means inactive in both. For MLP, two groups differ in s(R)superscriptğ‘ ğ‘…s^{(R)}italic_s start_POSTSUPERSCRIPT ( italic_R ) end_POSTSUPERSCRIPT only 87% of the time when MLP is active in both groups.
> </details>



![](https://arxiv.org/html/2502.03032/x5.png)

> ğŸ”¼ ê·¸ë¦¼ 5ëŠ” Gemma 2-2B ëª¨ë¸ì˜ ê° ê³„ì¸µì—ì„œ ê° ê·¸ë£¹ì˜ ë°±ë¶„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ëª¨ë¸ì—ì„œ íŠ¹ì§•(feature)ì´ ì–´ë–»ê²Œ í˜•ì„±ë˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì  ìë£Œì…ë‹ˆë‹¤.  ê° ê³„ì¸µë³„ë¡œ 'From nowhere', 'From RES', 'From MLP', 'From ATT', ê·¸ë¦¬ê³  ì´ë“¤ì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì—¬ëŸ¬ ê·¸ë£¹ë“¤ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ë‚´ì–´, ëª¨ë¸ ë‚´ì—ì„œ íŠ¹ì§•ì´ ì–´ë–»ê²Œ ìƒì„±ë˜ê³ , ë‹¤ë¥¸ ê³„ì¸µì˜ íŠ¹ì§•ë“¤ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, ì´ˆê¸° ê³„ì¸µì—ì„œëŠ” 'From nowhere'ì™€ 'From RES' ê·¸ë£¹ì˜ ë¹„ì¤‘ì´ ë†’ê³ , ê³„ì¸µì´ ê¹Šì–´ì§ì— ë”°ë¼ 'From MLP' ê·¸ë£¹ì˜ ë¹„ì¤‘ì´ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ê³„ì¸µì  êµ¬ì¡°ì™€ íŠ¹ì§• í˜•ì„± ê³¼ì •ì„ ì´í•´í•˜ëŠ”ë° ì¤‘ìš”í•œ ì‹œê°ì  ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 5: Percentages of each group at each layer of GemmaÂ 2â€‰2B, illustrating how feature formation proceeds in the model.
> </details>



![](https://arxiv.org/html/2502.03032/x6.png)

> ğŸ”¼ ê·¸ë¦¼ 6ì€ ë‹¤ì–‘í•œ ë¹„í™œì„±í™” ë°©ë²•ì„ ë¹„êµí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ê·¸ë£¹ì˜ ë ˆì´ë¸”ì€ ì–´ë–¤ í™œì„± ì „ì„ìê°€ ë¹„í™œì„±í™”ë˜ì—ˆëŠ”ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë¬´ì‘ìœ„ ì ‘ê·¼ ë°©ì‹ì€ ì„±ëŠ¥ì´ ì €ì¡°í•˜ì—¬ ìµœìƒìœ„ 1ê°œ íŠ¹ì§•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì´ë¯¸ ì¸ê³¼ ë¶„ì„ì— ì˜ë¯¸ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì¦‰, íŠ¹ì • íŠ¹ì§•ì˜ í™œì„±í™” ì—¬ë¶€ê°€ ë‹¤ë¥¸ íŠ¹ì§•ì˜ í™œì„±í™”ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ì¸ê³¼ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ë° ìˆì–´ ìµœìƒìœ„ 1ê°œ íŠ¹ì§•ì˜ ì„ íƒì´ íš¨ê³¼ì ì¸ ë°©ë²•ì„ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤í—˜ ê²°ê³¼ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 6: Deactivation methods compared. Group labels show which active predecessors were deactivated. The random approach underperforms, suggesting that choosing the top1subscripttop1\operatorname{top}_{1}roman_top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT feature is already meaningful for causal analysis.
> </details>



![](https://arxiv.org/html/2502.03032/x7.png)

> ğŸ”¼ ê·¸ë¦¼ 7ì€ í•œ ë²ˆì— í•˜ë‚˜ì˜ ì „êµ¬ì²´ë¥¼ ë¹„í™œì„±í™”í•  ë•Œ í‰ê·  í™œì„±í™” ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì–´ë–¤ ì „êµ¬ì²´ì˜ ë¹„í™œì„±í™”ëŠ” ê·¸ ì „êµ¬ì²´ê°€ ë‹¨ë…ìœ¼ë¡œ í™œì„±í™”ë˜ì§€ ì•Šì„ ê²½ìš° ì˜í–¥ì´ ì ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ëŠ”ë°, ì´ëŠ” ê²°í•©ëœ ê·¸ë£¹ì´ íšŒë¡œì™€ ê°™ì€ ë™ì‘ì„ í•œë‹¤ëŠ” ê²°ë¡ ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤. ì¦‰, ì—¬ëŸ¬ íŠ¹ì§•ë“¤ì´ í•¨ê»˜ ì‘ìš©í•˜ì—¬ íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ”, ë§ˆì¹˜ ì „ê¸° íšŒë¡œì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 7: Mean activation changes when deactivating one predecessor at a time. Deactivation of some predecessor causes less impact if this predecessor is not activated alone, which leads to the conclusion that combined groups exhibit circuit-like behavior.
> </details>



![](https://arxiv.org/html/2502.03032/x8.png)

> ğŸ”¼ ê·¸ë¦¼ 8ì€ ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì„ í–‰ ìš”ì†Œë¥¼ ì¬ì¡°ì •í•˜ì—¬ ë¹„í™œì„±í™” ì„±ê³µë¥ ì— ë¯¸ì¹˜ëŠ” ë‹¤ì–‘í•œ r ê°’ì˜ ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. rì´ 1ë³´ë‹¤ ì‘ì„ ë•Œ í™œì„±í™” ë³€í™”ëŠ” ë¹„ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ”ë°, ì´ëŠ” ëŒ€ì²´ ì¸ê³¼ ê²½ë¡œê°€ ì—¬ì „íˆ ì •ë³´ë¥¼ ì „ë‹¬í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (Lnew - Lold)/Lold ë¡œ ì¸¡ì •ëœ ìƒëŒ€ì  ì†ì‹¤ ë³€í™”ëŠ” ìˆœë°©í–¥ ì „ë‹¬ ì˜í–¥ì— ëŒ€í•œ ëŒ€ìš© ì§€í‘œì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 8: Impact of different rğ‘Ÿritalic_r values on deactivation success, with rescaling of all available predecessors. When r<1ğ‘Ÿ1r<1italic_r < 1, the activation change grows nonlinearly, indicating alternative causal pathways still convey information. Relative loss change measured as (Lnewâˆ’Lold)/Loldsubscriptğ¿newsubscriptğ¿oldsubscriptğ¿old(L_{\text{new}}-L_{\text{old}})/L_{\text{old}}( italic_L start_POSTSUBSCRIPT new end_POSTSUBSCRIPT - italic_L start_POSTSUBSCRIPT old end_POSTSUBSCRIPT ) / italic_L start_POSTSUBSCRIPT old end_POSTSUBSCRIPT is a proxy for forward pass impact.
> </details>



![](https://arxiv.org/html/2502.03032/x9.png)

> ğŸ”¼ ê·¸ë¦¼ 9ëŠ” ëª¨ë¸ì˜ ìƒì„±ë¬¼ì—ì„œ 'ê³¼í•™ì  ê°œë… ë° ì‹¤ì²´'ë¼ëŠ” ì£¼ì œë¥¼ ì œê±°í•˜ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì ì„  ê²€ì€ìƒ‰ ì„ ì€ ê¸°ë³¸ ìƒì„± ì ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ê³ , ë¹¨ê°„ìƒ‰ ì ì€ ë‹¨ì¼ ê³„ì¸µ ë°©ë²•ì—ì„œ ê° r ê°’ì— ëŒ€í•œ ìµœì ì˜ ê³„ì¸µì„ í‘œì‹œí•©ë‹ˆë‹¤. r ê°’ì´ í´ìˆ˜ë¡ ì„±ëŠ¥ì€ í–¥ìƒë˜ì§€ë§Œ ìµœì ì˜ ê³„ì¸µì€ ë” ì•ìª½ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. ì¦‰, íŠ¹ì • ì£¼ì œë¥¼ ì–µì œí•˜ê¸° ìœ„í•´ ëª¨ë¸ì˜ íŠ¹ì • ë¶€ë¶„ì„ ì¡°ì‘í•˜ë©´ íš¨ê³¼ê°€ ë” ì»¤ì§ˆ ìˆ˜ ìˆì§€ë§Œ, ê·¸ íš¨ê³¼ëŠ” ëª¨ë¸ì˜ ì•ë¶€ë¶„ì—ì„œ ë” ë‘ë“œëŸ¬ì§€ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 9: Deactivating the â€œScientific concepts and entitiesâ€ theme. The dashed black line shows the default generation score. Red points mark the best layer for each rğ‘Ÿritalic_r in the single-layer method. Larger rğ‘Ÿritalic_r boosts performance but shifts the optimal layer earlier.
> </details>



![](https://arxiv.org/html/2502.03032/x10.png)

> ğŸ”¼ ê·¸ë¦¼ 10ì€ ìµœì  ë¹„í™œì„±í™” ì ìˆ˜ë¥¼ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. ë…¹ìƒ‰ ì„ ì€ ì´ˆê¸° íŠ¹ì§• ì§‘í•©ë§Œ ì‚¬ìš©í•˜ì—¬ ë¹„í™œì„±í™”í–ˆì„ ë•Œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì¹œ ê°œì…(ì£¼í™©ìƒ‰, íŒŒë€ìƒ‰)ì€ ë‹¤ì–‘í•œ rê°’ì— ê±¸ì³ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ë°, ì´ëŠ” ì¶”ê°€ë¡œ ë°œê²¬ëœ íŠ¹ì§•ë“¤ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ë¥¼ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.  ì¦‰, ë‹¨ì¼ ê³„ì¸µì—ì„œì˜ ì¡°ì‘ë³´ë‹¤ ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì³ íŠ¹ì§•ì„ ì¡°ì‘í•˜ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’(r)ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ê°€ ì¤„ì–´ë“¤ì–´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì´ í–¥ìƒë˜ì—ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 10: Comparison of best deactivation scores. The green line indicates deactivation using only the initial feature set. Multi-layer interventions (orange, blue) perform better across different rğ‘Ÿritalic_r values, suggesting additional discovered features reduce hyperparameter sensitivity.
> </details>



![](https://arxiv.org/html/2502.03032/x11.png)

> ğŸ”¼ ê·¸ë¦¼ 11ì€ íŠ¹ì • ì£¼ì œë¥¼ í™œì„±í™”ì‹œí‚¤ëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¨ì¼ ê³„ì¸µ ì¡°ì •ê³¼ ëˆ„ì  ì¡°ì • ë°©ë²•ì„ ì„¸ ê°€ì§€ í¬ê¸° ì¡°ì • ì „ëµ(ë¶€ë¡ B ì°¸ì¡°)ê³¼ ë¹„êµí•˜ì—¬, ì—¬ëŸ¬ ìœ ì‚¬í•œ íŠ¹ì§•ì„ í™œì„±í™”í•˜ë©´ ì£¼ì œì˜ ì¡´ì¬ê°ì€ ì»¤ì§€ì§€ë§Œ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì¼ê´€ì„±ì€ ì €í•˜ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 11: Activation of specific topics. We compare single-layer steering and cumulative approaches with three rescaling strategies (AppendixÂ B). Activating multiple similar features amplifies a topicâ€™s presence but may degrade overall text coherence.
> </details>



![](https://arxiv.org/html/2502.03032/x12.png)

> ğŸ”¼ ê·¸ë¦¼ 12ëŠ” ì œì•ˆëœ ë°©ë²•ì˜ íƒ€ë‹¹ì„±ì„ ë³´ì—¬ì£¼ëŠ” ë‘ ê°€ì§€ ì¸¡ë©´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (a)ëŠ” ë„¤ ê°€ì§€ ë°ì´í„°ì…‹(FineWeb, TinyStories, Python Code, AutoMathText)ì— ëŒ€í•´ ê° ê·¸ë£¹ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ë°ì´í„°ì…‹ì€ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì—, ê° ê·¸ë£¹ì˜ ë¹„ìœ¨ì´ ì„œë¡œ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ì°¨ì´ëŠ” ëª¨ë¸ì´ ë°ì´í„°ì…‹ì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ íŠ¹ì§•ì„ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. (b)ëŠ” 8ë²ˆì§¸ ë ˆì´ì–´ì™€ 18ë²ˆì§¸ ë ˆì´ì–´ì— ëŒ€í•œ ì ìˆ˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ê·¸ë£¹ì€ ê³ ìœ í•œ ì ìˆ˜ ë¶„í¬ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ì´ëŠ” ê·¸ë£¹ ê°„ì˜ ëª…í™•í•œ êµ¬ë¶„ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ì œì•ˆëœ ë°©ë²•ì´ ëª¨ë¸ ë‚´ì—ì„œ íŠ¹ì§•ì˜ ê¸°ì›ê³¼ ì „íŒŒë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 12: (a) Percentage of feature groups obtained for each dataset. (b) Distribution of scores for layers 8 and 18. We observe a clear distinction between groups, which additionally indicates the validity of the proposed method.
> </details>



![](https://arxiv.org/html/2502.03032/x13.png)

> ğŸ”¼ ê·¸ë¦¼ 13ì€ ëª¨ë“  ë ˆì´ì–´ì— ê±¸ì³ ì§‘ê³„ëœ ê·¸ë£¹ A(í–‰)ê°€ ê·¸ë£¹ B(ì—´)ì— ë‚˜íƒ€ë‚  í™•ë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'From ATT' ê·¸ë£¹ì„ ì‚´í´ë³´ë©´, ì´ ê·¸ë£¹ì˜ íŠ¹ì§•ì´ 'From RES & ATT' ê·¸ë£¹ì— ë‚˜íƒ€ë‚  í™•ë¥ ì´ 0.45ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'From nowhere' ê·¸ë£¹ì˜ ë†’ì€ ì ìˆ˜ëŠ” í•´ë‹¹ ê·¸ë£¹ì˜ í™•ë¥ ì  íŠ¹ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ê° ë ˆì´ì–´ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì´ ë‹¤ë¥¸ ë ˆì´ì–´ì˜ íŠ¹ì§•ë“¤ê³¼ ì–´ë–»ê²Œ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” í™•ë¥ ì  ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, ê° ê·¸ë£¹ì— ì†í•œ íŠ¹ì§•ë“¤ì´ ë‹¤ë¥¸ ê·¸ë£¹ì— ë‚˜íƒ€ë‚  í™•ë¥ ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì œì‹œí•˜ì—¬ ëª¨ë¸ ë‚´ë¶€ì˜ íŠ¹ì§• íë¦„ê³¼ ìƒí˜¸ ì‘ìš©ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 13: Probability of group A (row) to appear in group B (column), aggregated over all layers. For example, if we take the â€œFrom ATTâ€ group, then with a probability of 0.45, features from this group would appear in the â€œFrom RES & ATTâ€ group. High scores for the â€œFrom nowhereâ€ group represent its stochasticity.
> </details>



![](https://arxiv.org/html/2502.03032/x14.png)

> ğŸ”¼ ê·¸ë¦¼ 14ëŠ” ê° ëª¨ë“ˆì˜ ìœ ì‚¬ë„ ì ìˆ˜ì— ëŒ€í•œ ê·¸ë£¹ ê°„ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ê·¸ë£¹ì€ ì´ì „ ê³„ì¸µì˜ íŠ¹ì§•ì´ í™œì„±í™”ëœ ë°©ì‹ì— ë”°ë¼ ë¶„ë¥˜ë©ë‹ˆë‹¤ (ì˜ˆ: ì´ì „ ì”ì°¨ íŠ¹ì§•ë§Œ í™œì„±í™”ëœ ê²½ìš° 'RES ì „ìš©', ì´ì „ MLPì™€ ì”ì°¨ íŠ¹ì§• ëª¨ë‘ í™œì„±í™”ëœ ê²½ìš° 'RES ë° MLP' ë“±).  ê° ë§‰ëŒ€ëŠ” íŠ¹ì • ëª¨ë“ˆ(ì”ì°¨, MLP, ì–´í…ì…˜)ì˜ í™œì„±í™” ìƒíƒœ(ë‘ ê·¸ë£¹ ëª¨ë‘ì—ì„œ í™œì„±í™”, í•œ ê·¸ë£¹ì—ì„œë§Œ í™œì„±í™”, ë‘ ê·¸ë£¹ ëª¨ë‘ì—ì„œ ë¹„í™œì„±í™”)ì— ë”°ë¼ ë‘ ê·¸ë£¹ì˜ ìœ ì‚¬ë„ ì ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ë‹¤ë¥¸ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ê° ëª¨ë“ˆì˜ í™œì„±í™”ê°€ íŠ¹ì§•ì˜ ê¸°ì› ë° ì „íŒŒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë†’ì€ ë¹„ìœ¨ì€ í•´ë‹¹ ëª¨ë“ˆì˜ í™œì„±í™”ê°€ íŠ¹ì§•ì˜ ì „íŒŒì— í° ì˜í–¥ì„ ë¯¸ì¹¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 14: Percentage of statistically significant differences between groups with respect to a certain score.
> </details>



![](https://arxiv.org/html/2502.03032/x15.png)

> ğŸ”¼ ê·¸ë¦¼ 15ëŠ” íŠ¹ì§• ë§¤ì¹­ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. (a)ëŠ” ë„¤ ê°€ì§€ ë§¤ì¹­ ì „ëµ(random, permutation, top1, top5)ì„ ê° íŠ¹ì§•ì— ì ìš©í•˜ì—¬, ê° ê·¸ë£¹ì— ì†í•œ íŠ¹ì§•ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. top5 ë°©ë²•ì´ ë‹¤ë¥¸ ë°©ë²•ë“¤ë³´ë‹¤ ë” ë§ì€ ê²°í•© ê·¸ë£¹(íŠ¹íˆ, â€œFrom RES & MLPâ€)ì„ íƒì§€í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. (b)ëŠ” íŠ¹ì • ê·¸ë£¹ì— ì†í•œ íŠ¹ì§•ì´ ì„ í–‰ íŠ¹ì§• ë¹„í™œì„±í™” í›„ ë‹¤ë¥¸ ê·¸ë£¹ìœ¼ë¡œ ì´ë™í•  í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê° ë§‰ëŒ€ëŠ” íŠ¹ì§•ì´ ìƒˆë¡œìš´ ê·¸ë£¹ì— ì†í•  íšŸìˆ˜ì˜ ë°±ë¶„ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ íŠ¹ì§•ì˜ ê¸°ì›ê³¼ ì „íŒŒ ê³¼ì •ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 15: (a) Percentage of features per each method. There was a total of 13106 activated features, and for every feature, four matching strategies were applied. We see that top5subscripttop5\operatorname{top}_{5}roman_top start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT method detects many more combined groups than other methods, especially â€œFrom RES & MLPâ€. (b) Probability for a feature from some group Ağ´Aitalic_A (labeled as the subplot title) to become from group BğµBitalic_B (shown in legend) after deactivation of some predecessor. Each bar shows the percentage of times the feature falls into a new category.
> </details>



![](https://arxiv.org/html/2502.03032/x16.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ ì œì–´ ì „ëµ(ë‹¨ì¼ ê³„ì¸µ, ì¼ì •, ì§€ìˆ˜, ì„ í˜•)ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ê³„ì¸µ(ğ‘™)ì—ì„œ ì„ íƒëœ íŠ¹ì§•ì„ ì œì–´í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì „ëµì— ëŒ€í•´ ëª¨ë“  ì ìˆ˜(ğ‘ ) ì¤‘ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì€ ê³„ì¸µì„ í‘œì‹œí•©ë‹ˆë‹¤. ê·¸ë¦¼ì€ 12ê³„ì¸µ ì´ì™¸ì˜ ê³„ì¸µì—ì„œ ì œì–´ë¥¼ ìˆ˜í–‰í–ˆì„ ë•Œ ê²°ê³¼ê°€ í–¥ìƒë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 16: From each flow graph, we select features on a particular layer lğ‘™litalic_l and perform steering with the four different strategies. Bars represent the best result for each layer among all scores sğ‘ sitalic_s. In some cases, steering on a layer other than 12 may improve results.
> </details>



![](https://arxiv.org/html/2502.03032/x17.png)

> ğŸ”¼ ê·¸ë¦¼ 17ì€ 'ì—°êµ¬ ë°©ë²•ë¡  ë° ì‹¤í—˜' ì£¼ì œì˜ í™œì„±í™”ë¥¼ ìœ„í•´ ì„ íƒëœ íŠ¹ì§•ì˜ ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ë¡œì„ ì€ ì´ˆê¸° ì„ íƒëœ íŠ¹ì§•ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (b)ëŠ” ì„ íƒëœ íŠ¹ì§•ì˜ ì¡°í–¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì ìˆ˜ëŠ” í–‰ë™ ì ìˆ˜ì™€ ëˆ„ì  ì ìˆ˜ë¥¼ ê³±í•œ ê°’ìœ¼ë¡œ ì¸¡ì •ë˜ëŠ” ì¢…í•© ì§€í‘œì…ë‹ˆë‹¤. ì´ˆê¸° íŠ¹ì§•ì´ 5ë²ˆì§¸ ê³„ì¸µì— ë°°ì¹˜ë˜ì§€ ì•Šì•˜ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 17: (a) Amount of features selected for activation of â€œResearch methodology and experimentationâ€ theme. Vertical lines represent the placement of the initially selected features. (b) Results for steering of selected features. Score is a total metric measured as BehavioralÃ—CumulativeBehavioralCumulative\text{Behavioral}\times\text{Cumulative}Behavioral Ã— Cumulative. We can see that despite none of the initial features being placed on the 5th layer, it gives us the best result.
> </details>



![](https://arxiv.org/html/2502.03032/x18.png)

> ğŸ”¼ ê·¸ë¦¼ 18ì€ Llama Scopeì— ëŒ€í•œ íŠ¹ì§• ê·¸ë£¹ì˜ ë¶„í¬ì™€ Gemma Scope ê²°ê³¼ì™€ì˜ ë¹„êµ, ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì¹œ ê·¸ë£¹ ë¶„í¬, ì„œë¡œ ë‹¤ë¥¸ ê·¸ë£¹ì— ëŒ€í•œ ì ìˆ˜ ë¶„í¬, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê·¸ë£¹ ë¶„ë¦¬ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Llama Scopeì˜ ê·¸ë£¹ ë¶„í¬ëŠ” Gemma Scopeì™€ ë‹¬ë¦¬ í›¨ì”¬ ë¶€ë“œëŸ¬ìš´ ë¶„í¬ë¥¼ ë³´ì´ëŠ”ë°, ì´ëŠ” ëª¨ë¸ì´ë‚˜ SAEì˜ ì•„í‚¤í…ì²˜, í•™ìŠµ ì ˆì°¨, ë°ì´í„° ë¶„í¬ì˜ ì°¨ì´ ë“± ë‹¤ì–‘í•œ ìš”ì¸ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì¹œ ê·¸ë£¹ ë¶„í¬ëŠ” Gemma Scopeì™€ ê±°ì˜ ë™ì¼í•œ íŒ¨í„´ì„ ë³´ì—¬ ëª¨ë¸ ê°„ ê³µìœ  íŠ¹ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ê·¸ë£¹ ì ìˆ˜ ë¶„í¬ëŠ” Gemma Scopeì— ë¹„í•´ ê·¸ë£¹ ê°„ êµ¬ë¶„ì´ ë‹¤ì†Œ ëª¨í˜¸í•˜ì§€ë§Œ ì—¬ì „íˆ êµ¬ë¶„ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê·¸ë£¹ ë¶„ë¦¬ ê°€ëŠ¥ì„± ì—­ì‹œ ì´ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 18: (a) Distribution of groups for Llama Scope. We observe a clear distinction from Gemma Scope results (Figure 12) due to a much smoother distribution. This may be a consequence of various factors: the architecture of the models or SAEs, the training procedure, differences in data distribution, etc. (b) Distribution of groups across multiple layers. We observe approximately the same pattern as for Gemma Scope (Figure 5), indicating shared properties between the models. (c) Distribution of scores for different groups. We see that the groups are slightly less distinct from each other compared to the case of Gemma Scope (Figure 12), but they are still present. This is also reflected in (d) the separability of different groups based on their cosine similarity relations.
> </details>



![](https://arxiv.org/html/2502.03032/x19.png)

> ğŸ”¼ ê·¸ë¦¼ 19ëŠ” 12/res/14455 íŠ¹ì§•ì— ëŒ€í•œ íë¦„ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Chalnev ë“±ì˜ ì—°êµ¬(2024)ì— ë”°ë¥´ë©´, ì´ íŠ¹ì§•ì„ ì¡°ì •í•˜ë©´ íŒ¨ì…˜ ê´€ë ¨ ì£¼ì œê°€ ìƒì„±ë  ìˆ˜ ìˆìœ¼ë©°, ì´ ê·¸ë˜í”„ì˜ ì´ˆê¸° ë ˆì´ì–´ì—ì„œ ì´ëŸ¬í•œ ì˜ë¯¸ë¡ ì´ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ëª¨ë¸ì˜ ì—¬ëŸ¬ ë ˆì´ì–´ì— ê±¸ì³ íŠ¹ì§•ì´ ì–´ë–»ê²Œ ì§„í™”í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‹œê°ì  í‘œí˜„ì…ë‹ˆë‹¤. ê° ë…¸ë“œëŠ” íŠ¹ì • ë ˆì´ì–´ì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ê³ , ê°„ì„ ì€ ë ˆì´ì–´ ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ ëª¨ë¸ì˜ ë‚´ë¶€ ë™ì‘ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì–»ê³ , íŠ¹ì • ì£¼ì œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì–µì œí•˜ê¸° ìœ„í•œ ëª¨ë¸ ì¡°ì •ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 19: Flow graph for the 12/res/14455 feature. As reported in Chalnev etÂ al. (2024), steering of that feature might produce themes related to fashion, and we clearly observe that our flow graph captures this semantics in the earlier layers.
> </details>



![](https://arxiv.org/html/2502.03032/x20.png)

> ğŸ”¼ ê·¸ë¦¼ 20ì€ ëª¨ë¸ì˜ 12/res/4230 íŠ¹ì§•ì— ëŒ€í•œ íë¦„ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ì—ì„œ ëª¨ë¸ì˜ í›„ë°˜ë¶€ê°€ ê²°í˜¼ì‹ ë° ê²°í˜¼ì‹ê³¼ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì´ˆê¸° ê³„ì¸µì—ì„œ íŠ¹ì§• í•´ì„ì˜ 'ê³µì‹ì ì¸' ì¸¡ë©´ì´ ê²°í˜¼ì‹ ë° ê²°í˜¼ì´ë¼ëŠ” íŠ¹ì • ìœ í˜•ì˜ ëŒ€ì¸ ê´€ê³„ ë“±ë¡ì´ë¼ëŠ” ê³µì‹ ì ˆì°¨ ìì²´ì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 20: Flow graph for the 12/res/4230 feature. In this case, we observe that the second half of the model is closely related to wedding and marriage ceremonies. We believe that the â€œofficialâ€ aspect in the interpretation of features in earlier layers is closely related to the fact that wedding ceremonies and marriage are themselves official proceduresâ€”the registration of a specific type of interpersonal relationship.
> </details>



![](https://arxiv.org/html/2502.03032/x21.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë‘ ê°œì˜ í¬ì†Œ ìë™ ì¸ì½”ë”(SAE)ì™€ í•™ìŠµëœ ì „ì´ í–‰ë ¬ Të¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ê° ë ˆì´ì–´ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì„ ì—°ê²°í•˜ëŠ” ë°©ì‹ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° SAEëŠ” ëª¨ë¸ì˜ ì—°ì†ì ì¸ ë ˆì´ì–´(tì™€ t+1)ì—ì„œ ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì „ì´ í–‰ë ¬ TëŠ” ë ˆì´ì–´ tì˜ íŠ¹ì§•ë“¤ì„ ë ˆì´ì–´ t+1ì˜ íŠ¹ì§•ë“¤ë¡œ ë§¤í•‘í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ ê·¸ë¦¼ì€ ë‘ ê°œì˜ SAEì™€ ì „ì´ í–‰ë ¬ Të¥¼ ê²°í•©í•˜ì—¬ ë ˆì´ì–´ tì—ì„œ t+1ë¡œì˜ íŠ¹ì§• ë³€í™˜ ê³¼ì •ì„ í•˜ë‚˜ì˜ íŠ¸ëœìŠ¤ì½”ë”ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ ë‚´ë¶€ì—ì„œ íŠ¹ì§•ë“¤ì´ ì–´ë–»ê²Œ ë³€í™˜ë˜ê³  ì „íŒŒë˜ëŠ”ì§€ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 21: Two SAEs with a learned transition matrix Tğ‘‡Titalic_T can be seen as a transcoder from layer tğ‘¡titalic_t to layer t+1ğ‘¡1t+1italic_t + 1.
> </details>



![](https://arxiv.org/html/2502.03032/x22.png)

> ğŸ”¼ ê·¸ë¦¼ 22ëŠ” ë‹¤ì–‘í•œ ìˆœì—´ ë³€ì´ì²´ì˜ ì„¤ëª…ëœ ë¶„ì‚°ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì€ ì—¬ëŸ¬ ê°€ì§€ ìˆœì—´ ìƒì„± ë°©ë²•ì„ ë¹„êµí•˜ì—¬ ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ê³¼ íŠ¹ì§• ê°„ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  ê° ìˆœì—´ ë³€ì´ì²´ëŠ” íŠ¹ì§• ê°„ì˜ ê´€ê³„ë¥¼ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚´ë©°, ì„¤ëª…ëœ ë¶„ì‚°ì„ í†µí•´ ê° ë°©ë²•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë””ì½”ë” ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Ix>0 top1 Wdec(14)âŠ¤Wdec(15))ê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ Fë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
> <details>
> <summary>read the caption</summary>
> Figure 22: Explained variance of the various permutation variants. Cosine similarity between decodersâ€™ vectors (ğˆx>0â¢Â topÂ 1â¢ğ‘¾dec(14)âŠ¤â¢ğ‘¾decÂ (15)subscriptğˆğ‘¥0subscriptÂ topÂ 1superscriptsubscriptğ‘¾declimit-from14topsuperscriptsubscriptğ‘¾decÂ 15\mathbf{I}_{x>0}\text{ top }_{1}\boldsymbol{W}_{\text{dec}}^{(14)\top}% \boldsymbol{W}_{\text{dec }}^{(15)}bold_I start_POSTSUBSCRIPT italic_x > 0 end_POSTSUBSCRIPT top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 14 ) âŠ¤ end_POSTSUPERSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 15 ) end_POSTSUPERSCRIPT) performs best. See Appendix F for more details.
> </details>



![](https://arxiv.org/html/2502.03032/x23.png)

> ğŸ”¼ ê·¸ë¦¼ 23ì€ ë‹¤ì–‘í•œ topk ì—°ì‚°ìì™€ SAE ê°€ì¤‘ì¹˜ì˜ ë¹„êµ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ì—¬ê¸°ì„œ këŠ” topk ì—°ì‚°ìì˜ ë§¤ê°œë³€ìˆ˜ì´ê³ ,  SAE ê°€ì¤‘ì¹˜ëŠ” ê° ë ˆì´ì–´ì˜ ë””ì½”ë” ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ë‹¤ì–‘í•œ topk ì—°ì‚°ìì™€ ê°€ì¤‘ì¹˜ ì¡°í•©ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§• ë§¤ì¹­ì˜ ì„±ëŠ¥ì„ í‰ê°€í–ˆìœ¼ë©°, ê·¸ ê²°ê³¼ Cosine ìœ ì‚¬ë„ (Ix>0 top1Wdec(14)TWdec(15)) ê¸°ë°˜ ë°©ë²•ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ Fë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
> <details>
> <summary>read the caption</summary>
> Figure 23: Comparison of various kğ‘˜kitalic_k in topksubscripttopğ‘˜\operatorname{top}_{k}roman_top start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT operator and different weights of the SAE. Cosine similarity (ğˆx>0â¢Â topÂ 1â¢ğ‘¾dec(14)âŠ¤â¢ğ‘¾dec(15)subscriptğˆğ‘¥0subscriptÂ topÂ 1superscriptsubscriptğ‘¾declimit-from14topsuperscriptsubscriptğ‘¾dec15\mathbf{I}_{x>0}\text{ top }_{1}\boldsymbol{W}_{\text{dec}}^{(14)\top}% \boldsymbol{W}_{\text{dec}}^{(15)}bold_I start_POSTSUBSCRIPT italic_x > 0 end_POSTSUBSCRIPT top start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 14 ) âŠ¤ end_POSTSUPERSCRIPT bold_italic_W start_POSTSUBSCRIPT dec end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 15 ) end_POSTSUPERSCRIPT) performs best. See Appendix F for more details.
> </details>



</details>




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Theme | Feature index | Interpretation |
|---|---|---|
| Anger and frustration | 12/res/4111 | expressions of anger and frustration |
| Mental health issues | 12/res/16226 | ref. to mental health issues and their connections to other health conditions |
| Wedding and marriage | 12/res/4230 | terms related to weddings and marriage ceremonies |
| Religion and God | 12/res/5483 | spiritual themes related to faith and divine authority |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” ë…¼ë¬¸ì˜ ì‹¤í—˜ ì„¤ì •(Experimental setup) ë¶€ë¶„ì—ì„œ 'ì£¼ì œ í™œì„±í™”'(Activation of theme) ì‹¤í—˜ì„ ìœ„í•´ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì„ íƒëœ íŠ¹ì§•ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° íŠ¹ì§•ì€ Gemma Scope SAE íŒ¨í‚¤ì§€ì—ì„œ í›ˆë ¨ëœ Sparse Autoencoder(SAE)ì˜ ë””ì½”ë” ê°€ì¤‘ì¹˜ì˜ ì—´(column)ì— í•´ë‹¹í•˜ë©°, Neuronpediaë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ì„ëœ ì˜ë¯¸ê°€ í•¨ê»˜ ì œì‹œë©ë‹ˆë‹¤.  í‘œëŠ” ê° ê³„ì¸µ(layer)ì—ì„œ ì„ íƒëœ íŠ¹ì§•ì˜ ì¸ë±ìŠ¤ì™€ í•´ë‹¹ íŠ¹ì§•ì˜ Neuronpediaë¥¼ í†µí•œ ì˜ë¯¸ í•´ì„ì„ ë‚˜ì—´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ í‘œì˜ ë°ì´í„°ëŠ” 'ì£¼ì œ í™œì„±í™”' ì‹¤í—˜ì—ì„œ ëª¨ë¸ì˜ í–‰ë™ì„ íŠ¹ì • ì£¼ì œ(ì˜ˆ: ê²°í˜¼ ë° ê²°í˜¼ì‹)ë¡œ ìœ ë„í•˜ê¸° ìœ„í•œ ì´ˆê¸° ì§€ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Initial choice of feature for activation task.
> </details>

{{< table-caption >}}
| Feature index | Interpretation from Neuronpedia |
|---|---| 
| 12/res/6778 | references to testing and experimentation processes |
| 16/res/13806 | references to experimental studies and methodologies |
| 18/res/1056 | references to experiments and experimental protocols |
| 18/res/7505 | terms and phrases related to research activities and methodologies |
| 23/res/10746 | terms related to modeling and model-building in scientific contexts |
| 24/res/11794 | terms and phrases related to scientific reasoning and methodology |
| 24/res/1027 | concerns related to study validity and bias in research methodologies |
| 24/res/7391 | phrases related to inquiry and questioning |
| 24/res/1714 | references to academic studies and their outcomes |
| 25/res/6821 | terms related to experimental methods and results in scientific research |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ë…¼ë¬¸ì˜ 'ì—°êµ¬ ë°©ë²•ë¡  ë° ì‹¤í—˜' ì£¼ì œë¥¼ í™œì„±í™”í•˜ê¸° ìœ„í•´ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì„ íƒëœ íŠ¹ì§•ë“¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° íŠ¹ì§•ì˜ ì¸ë±ìŠ¤ì™€ Neuronpediaì—ì„œ ì œê³µí•˜ëŠ” í•´ë‹¹ íŠ¹ì§•ì— ëŒ€í•œ ì„¤ëª…ì„ í¬í•¨í•©ë‹ˆë‹¤.  ì´ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ ë™ì‘ì„ ì´í•´í•˜ê³  íŠ¹ì • ì£¼ì œì— ëŒ€í•œ í…ìŠ¤íŠ¸ ìƒì„±ì„ ì œì–´í•˜ê¸° ìœ„í•œ ì—°êµ¬ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: Features initially chosen for activation of â€œResearch methodology and experimentationâ€ theme.
> </details>

{{< table-caption >}}
| Layer | Feature index | Interpretation |
|---|---|---|
| 0 | 0/mlp/12987 | punctuation, particularly quotation marks and dialogue indicators |
| 0 | 0/res/14403 | elements that indicate neglect or care in familial relationships |
| 1 | 1/mlp/16168 | mentions of astronomical phenomena and their characteristics |
| 1 | 1/res/13755 | metaphorical language and scientific terminologies related to variables and coefficients |
|  | 2/res/12939 | numerical data or metrics related to surveys and observations |
|  | 3/res/16138 | scientific terminology related to study results and causes |
|  | 4/res/11935 | terms related to particle physics and their interactions |
|  | 5/res/14558 | numeric or symbolic representations related to mathematical notation or scientific data |
|  | 6/res/2452 | key terms related to Dark Matter detection and experimental setups |
| 7 | 7/mlp/6110 | terms related to datasets and classification in statistical or machine learning contexts |
| 7 | 7/res/16335 | technical terminologies related to particle physics measurements |
|  | 8/res/9666 | scientific measurements and data related to particle physics |
|  | 9/res/8318 | references to particle physics concepts and measurements |
|  | 10/res/13754 | technical terms and measurements related to particle physics |
|  | 11/res/7614 | terms related to particle physics and specifically the properties of W and Z bosons |
|  | 12/res/2812 | statistical terms and measurements associated with quark interactions |
|  | 13/res/4955 | terms and concepts related to particle physics experiments and measurementsâ€¦ |
|  | 14/res/5262 | keywords related to particle physics, specifically concerning quarks and their properties |
|  | 15/res/9388 | concepts related to particle physics measurements and events |
|  | 16/res/10649 | complex scientific terms and metrics related to particle physics experiments |
| 17 | 17/mlp/8454 | theoretical concepts and key terms related to physics and gauge theories |
| 17 | 17/res/8130 | terms related to gauge bosons and their interactions within the context of particle physics |
|  | 18/res/11987 | technical and scientific terminology related to particle physics |
|  | 19/res/15694 | references to scientific measurements and results related to particle physicsâ€¦ |
| 20 | 20/mlp/601 | terms associated with quantum mechanics and transformations |
| 20 | 20/res/12523 | terms and concepts related to particle physics and the Standard Model |
| 21 | 21/mlp/594 | technical terminology and classifications related to data or performance metrics |
| 21 | 21/res/14511 | scientific terminology and concepts related to fundamental physicsâ€¦ |
| 22 | 22/mlp/14728 | references to gauge symmetries in theoretical physics |
| 22 | 22/res/11460 | terms and concepts related to particle physics and theoretical frameworks |
| 23 | 23/mlp/6936 | terms related to theoretical physics and particle interactions |
| 23 | 23/res/9592 | terms related to particle physics and their interactions |
| 24 | 24/mlp/11342 | terms and concepts related to theoretical physics and particle interactions |
| 24 | 24/res/14548 | terms and references related to particle physics and standard model parameters |
|  | 25/res/1646 | technical terms and measurements related to particle physics and the Standard Model |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” 24/res/14548 íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—¬ê¸°ì„œ MLP íŠ¹ì§•ì€ ì„ê³„ê°’ t(M) = 0.25ë¥¼ ì‚¬ìš©í•˜ì—¬ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ëª¨ë¸ì˜ ì—¬ëŸ¬ ê³„ì¸µì— ê±¸ì³ íŠ¹ì§•ì´ ì–´ë–»ê²Œ ì§„í™”í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” íŠ¹ì§• íë¦„ ê·¸ë˜í”„ì˜ ì¼ë¶€ë¶„ì…ë‹ˆë‹¤. ê° í–‰ì€ íŠ¹ì • ê³„ì¸µ(Layer)ì—ì„œ ë°œê²¬ëœ íŠ¹ì§•(Feature index)ê³¼ í•´ë‹¹ íŠ¹ì§•ì— ëŒ€í•œ í•´ì„(Interpretation)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹ì§• í•´ì„ì€ Neuronpediaë¼ëŠ” ë„êµ¬ë¥¼ í†µí•´ ì–»ì–´ì§„ ê²ƒìœ¼ë¡œ, ê° íŠ¹ì§•ì´ ëª¨ë¸ ë‚´ì—ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°–ëŠ”ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 24/res/14548 íŠ¹ì§•ì€ ì…ì ë¬¼ë¦¬í•™ê³¼ í‘œì¤€ ëª¨í˜• ë§¤ê°œë³€ìˆ˜ì™€ ê´€ë ¨ëœ ìš©ì–´ ë° ì°¸ì¡°ë¡œ í•´ì„ë©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4: Graph built from 24/res/14548 feature with MLP features dropped by threshold t(M)=0.25superscriptğ‘¡ğ‘€0.25t^{(M)}=0.25italic_t start_POSTSUPERSCRIPT ( italic_M ) end_POSTSUPERSCRIPT = 0.25.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}