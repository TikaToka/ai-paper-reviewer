{"references": [{"fullname_first_author": "Schwarzschild", "paper_title": "Datasets for Studying Generalization from Easy to Hard Examples", "publication_date": "2021-08-06", "reason": "This paper introduces a benchmark dataset designed to evaluate the ability of models to generalize from simpler to more complex tasks, a key concept relevant to the current research on scaling test-time computation."}, {"fullname_first_author": "Bansal", "paper_title": "End-to-end Algorithm Synthesis with Recurrent Networks: Extrapolation without Overthinking", "publication_date": "2022-10-26", "reason": "This paper explores recurrent models' ability to solve complex algorithmic tasks and extrapolate to unseen problem instances, directly addressing the core theme of test-time scaling in latent space."}, {"fullname_first_author": "Bai", "paper_title": "Deep Equilibrium Models", "publication_date": "2019-12-01", "reason": "This foundational paper introduces the concept of deep equilibrium models, which are closely related to the recurrent depth approach used in this work for scaling test-time computation."}, {"fullname_first_author": "Anil", "paper_title": "Path Independent Equilibrium Models Can Better Exploit Test-Time Computation", "publication_date": "2022-10-26", "reason": "This paper establishes the theoretical underpinnings of path independence in equilibrium models, a crucial property leveraged in the proposed model's design for stable iterative computation during both training and inference."}, {"fullname_first_author": "Kaplan", "paper_title": "Scaling Laws for Neural Language Models", "publication_date": "2020-01-24", "reason": "This highly influential work introduces scaling laws for neural language models, providing a crucial context and theoretical basis for understanding the impact of model size and compute on performance, which is directly relevant to the current research on scaling test-time compute."}]}