{"references": [{"fullname_first_author": "Yang", "paper_title": "Qwen2.5-math technical report: Toward mathematical expert model via self-improvement", "publication_date": "2024-09-12", "reason": "This paper is directly compared against throughout the paper, serving as a key benchmark and baseline for the AceMath models."}, {"fullname_first_author": "Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper introduces GSM8K, a benchmark dataset heavily used in evaluating the mathematical capabilities of LLMs, making it highly influential in the field."}, {"fullname_first_author": "Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "publication_date": "2021-03-03", "reason": "This paper presents MATH, another key benchmark dataset for evaluating LLMs' math capabilities, used extensively for comparison in the current work."}, {"fullname_first_author": "Chiang", "paper_title": "Vicuna: An open-source chatbot impressing GPT-4 with 90%* chatGPT quality", "publication_date": "2023-03-30", "reason": "This paper introduces ShareGPT, a significant dataset used for general-domain supervised fine-tuning (SFT), which is a crucial first step in AceMath's training process."}, {"fullname_first_author": "Dubey", "paper_title": "The Llama 3 herd of models", "publication_date": "2024-07-21", "reason": "This paper introduces Llama-3, a prominent large language model (LLM) that serves as the base model for several models compared in the paper, highlighting its importance in the field."}]}