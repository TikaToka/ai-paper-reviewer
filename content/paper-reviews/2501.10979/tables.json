[{"content": "| Model | MathHard | Math | GSM8K | Avg. | ARC | GPQA | MMLU | MMLUP | Avg. | Avg. |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Llama3.1-8B-Instruct | 23.7 | 50.9 | 85.6 | 52.1 | 83.4 | 29.9 | 72.4 | 46.7 | 60.5 | 56.3 |\n| OpenMath2-Llama3.1 | 38.4 | 64.1 | 90.3 | 64.3 | 45.8 | 1.3 | 4.5 | 19.5 | 12.9 | 38.6 |\n| Full Param Tune | 38.5 | 63.7 | 90.2 | 63.9 | 58.2 | 1.1 | 7.3 | 23.5 | 16.5 | 40.1 |\n| Partial Param Tune | 36.4 | 61.4 | 89.0 | 61.8 | 66.2 | 6.0 | 25.7 | 30.9 | 29.3 | 45.6 |\n| Stack Expansion | 35.6 | 61.0 | 90.8 | 61.8 | 69.3 | 18.8 | 61.8 | 43.1 | 53.3 | 57.6 |\n| Hybrid Expansion | 34.4 | 61.1 | 90.1 | 61.5 | 81.8 | 25.9 | 67.2 | 43.9 | 57.1 | 59.3 |\n| Control LLM* | 38.1 | 62.7 | 90.4 | 63.2 | 79.7 | 25.2 | 68.1 | 43.6 | 57.2 | 60.2 |", "caption": "Table 1: [Result] CSFT on mathematical(0-shot): Open-source models, various CPT approaches, and ControlLLM(Concat-Lerp-MSE).", "description": "\ud45c 1\uc740 \uc5f0\uc18d\uc801\uc778 \uc9c0\ub3c4 \ud559\uc2b5 \ubbf8\uc138 \uc870\uc815(CSFT)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub41c 0-shot \uc218\ud559\uc801 \ucd94\ub860 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c CPT(\uc5f0\uc18d\uc801 \uc0ac\uc804 \ud559\uc2b5) \uc811\uadfc \ubc29\uc2dd\uacfc \uc624\ud508 \uc18c\uc2a4 \ubaa8\ub378\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec ControlLLM(Concat-Lerp-MSE)\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, Llama3.1-8B-Instruct \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c MathHard, Math, GSM8K, ARC, GPQA, MMLU, MMLUP \ub4f1 \ub2e4\uc591\ud55c \uc9c0\ud45c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \uc81c\uc2dc\ud558\uba70, ControlLLM\uc774 \uae30\uc874 \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "| Model | MBPP+ | MBPPS | HE+ | HE | Avg. | ARC | GPQA | MMLU | MMLUP | Avg. | Avg. |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| Llama3.1-8B-Ins | 70.4 | 67.7 | 66.5 | 70.7 | 69.1 | 83.4 | 29.9 | 72.4 | 46.7 | 60.5 | 64.8 |\n| OpenCoder-8B-Ins | 81.2 | 76.3 | 78.0 | 82.3 | 79.5 | 8.2 | 25.4 | 37.4 | 11.3 | 24.6 | 52.1 |\n| Full Param Tune | 75.1 | 69.6 | 71.3 | 76.8 | 73.3 | 24.4 | 21.9 | 43.0 | 19.2 | 31.5 | 52.4 |\n| Partial Param Tune | 75.7 | 71.6 | 74.4 | 79.3 | 75.0 | 70.2 | 28.1 | 60.7 | 32.4 | 48.3 | 61.7 |\n| Stack Expansion | 77.2 | 72.8 | 73.2 | 78.7 | 75.6 | 80.0 | 26.3 | 66.6 | 38.2 | 54.2 | 64.9 |\n| Hybrid Expansion* | 77.5 | 73.5 | 76.2 | 82.3 | 77.1 | 80.9 | 32.6 | 68.1 | 40.3 | 56.0 | 66.6 |\n| Control LLM* | 80.4 | 75.9 | 74.4 | 81.1 | 78.3 | 82.5 | 29.7 | 68.2 | 40.9 | 56.3 | 67.3 |", "caption": "Table 2: [Result] CSFT on coding(0-shot). ControlLLM(Concat-Lerp-MSE).\nAbbr.(e.g. MBPP+, HE+, MMLUP) in Section\u00a04.1.3.", "description": "\ud45c 2\ub294 \uc9c0\uc18d\uc801\uc778 \uc9c0\ub3c4 \ubbf8\uc138 \uc870\uc815(CSFT)\uc5d0\uc11c \uc81c\ub85c\uc0f7(0-shot) \ucf54\ub4dc \uc0dd\uc131 \uc791\uc5c5\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ControlLLM(Concat-Lerp-MSE) \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uae30\uc900(MBPP+, HE+, MMLUP \ub4f1)\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 4.1.3\uc808\uc5d0\uc11c \uc57d\uc5b4\ub97c \uc124\uba85\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  ControlLLM \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \ubca4\uce58\ub9c8\ud06c\uc640 \ud3c9\uac00 \uc9c0\ud45c\ub97c \uc790\uc138\ud788 \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "| Model | CEval | CEvalC | CMMLU | CMMLUC | Avg. | BBH | MMLU | MMLUP | Avg. | Avg. |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Llama3.1-8B | 48.3 | 12.8 | 51.1 | 14.1 | 29.1 | 65.2 | 65.4 | 35.5 | 55.4 | 42.3 |\n| Llama-3-SynE | 57.7 | 22.3 | 57.1 | 22.8 | 32.5 | 61.9 | 64.0 | 32.6 | 52.8 | 42.7 |\n| Full Param Tune* | 59.0 | 40.2 | 60.2 | 44.3 | 51.2 | 64.8 | 64.9 | 35.0 | 55.0 | 53.1 |\n| Stack Expansion | 56.0 | 32.7 | 55.2 | 33.4 | 44.3 | 62.3 | 65.6 | 35.3 | 54.4 | 49.4 |\n| Concat-Lerp* | 57.1 | 34.8 | 57.0 | 37.4 | 46.6 | 64.4 | 64.6 | 35.8 | 55.0 | 50.8 |\n| Hybrid Expansion* | 58.9 | 44.7 | 57.9 | 44.3 | 51.5 | 65.1 | 65.7 | 36.9 | 55.9 | 53.7 |\n| Control LLM* | 57.0 | 44.7 | 56.0 | 44.9 | 50.7 | 68.2 | 65.6 | 37.9 | 57.2 | 54.0 |", "caption": "Table 3: [Result] CPT on Chinese. Control LLM(Concat-Dlerp). Abbr.: CEvalC(C-Eval-0shot-CoT), CMMLUC(CMMLU-0shot-CoT).", "description": "\ud45c 3\uc740 \uc9c0\uc18d\uc801 \uc0ac\uc804 \ud6c8\ub828(CPT) \uc911 \uc911\uad6d\uc5b4\uc5d0 \ub300\ud55c Control LLM\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Control LLM\uc740 Concat-Dlerp \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud588\uc73c\uba70, CEvalC\ub294 C-Eval-0shot-CoT\ub97c, CMMLUC\ub294 CMMLU-0shot-CoT\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378(Llama-3-SynE, Llama-3-8B,  Control LLM\uc758 \uc5ec\ub7ec \ubcc0\ud615)\uc744 \uc0ac\uc6a9\ud558\uc5ec  \uc911\uad6d\uc5b4 \uad00\ub828 \ubca4\uce58\ub9c8\ud06c(C-Eval, C-Eval-CoT, CMMLU, CMMLU-CoT)\uc5d0\uc11c\uc758 \uc131\ub2a5\uacfc \uc6d0\ub798 \uae30\ub2a5\uc744 \ube44\uad50\ud558\uc5ec  Control LLM\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc911\uad6d\uc5b4 \ub2a5\ub825 \ud5a5\uc0c1 \uc815\ub3c4\uc640 \uc6d0\ub798 \uae30\ub2a5 \uc720\uc9c0 \uc218\uc900\uc744 \uc218\uce58\ud654\ud558\uc5ec \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"content": "| Dataset | Task | Samples | Tokens |\n|---|---|---|---| \n| Llama3-SynE (-EN) | Multilingual | 47M | 35.8B |\n| OpenMath2 | Mathematics | 13.27M | 5.1B |\n| OpenCoder-SFT-Phase1 | Coding | 4.02M | 2.4B |\n| OpenCoder-SFT-Phase2 | Coding | 0.43M | 245.4M |", "caption": "Table 4: [What] Summary of datasets used in experiments, categorized by task type, with sample and token counts.", "description": "\ud45c 4\ub294 \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc744 \uc694\uc57d\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc791\uc5c5 \uc720\ud615\ubcc4\ub85c \ubd84\ub958\ud558\uace0, \uac01 \ub370\uc774\ud130\uc14b\uc758 \uc0d8\ud50c \uc218\uc640 \ud1a0\ud070 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc9c0\uc18d\uc801 \uc0ac\uc804 \ud6c8\ub828 \ubc0f \uc9c0\uc18d\uc801 \uc9c0\ub3c4 \ubbf8\uc138 \uc870\uc815 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \uc2e4\ud5d8\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc73c\ub85c,  \uc2e4\ud5d8\uc758 \uaddc\ubaa8\uc640 \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc720\uc6a9\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4.1. \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Model | MathH | G8K | GPQA | MMLU | Avg. |\n|---|---|---|---|---|---| \n| **Model** | **Math** |  | **Original** |  | **Avg.** |\n|  | **MathH** | **G8K** | **GPQA** | **MMLU** |  |\n| Full-Param | **38.5** | 90.2 | 1.1 | 7.3 | 34.3 |\n| Lerp8 | 36.1 | 90.2 | 18.5 | 58.8 | 50.9 |\n| Lerp8-MSE | 35.9 | 90.1 | 28.4 | **71.7** | **56.5** |\n| Lerp8-Cos | 34.9 | 89.2 | 29.5 | 71.0 | 56.2 |\n| Dlerp8 | **36.7** | 90.0 | **28.8** | 69.1 | 56.2 |\n| Dlerp8-MSE | 35.6 | 89.5 | 19.9 | 66.1 | 52.8 |\n| Dlerp8-Cos | 36.5 | **90.2** | 26.1 | 69.1 | 55.5 |\n| DlerpIn8 | 34.1 | 87.6 | **25.7** | **68.2** | **53.9** |\n| Plerp8 | **36.5** | **90.9** | 9.2 | 41.9 | 44.6 |\n| MoE8 | 34.1 | 89.7 | 20.5 | 63.3 | 51.9 |\n| Lerp16-MSE | 38.1 | 90.4 | **25.2** | **68.1** | **55.5** |\n| Dlerp16 | 37.7 | **91.1** | 22.3 | 64.2 | 53.8 |\n| Dlerp32 | **38.6** | 91.4 | 22.1 | 60.9 | 53.3 |\n| Lerp8MSE0 | **35.8** | **90.6** | 7.4 | 53.4 | 46.8 |\n| Lerp8MSE0* | 35.1 | 89.3 | 31.3 | **72.4** | **57.0** |\n| Lerp8MSE0*M | 33.9 | 89.1 | **32.4** | 72.2 | 56.9 |\n| Lerp8MSE\u03b1 | 32.6 | 87.3 | 29.8 | 71.8 | 55.4 |", "caption": "Table 5: [Where] Ablation Study. Abbr. MathH(Math Hard), Cos(Cosine), G8K(GSM8K)", "description": "\ud45c 5\ub294 \ub2e4\uc591\ud55c \uc124\uc815(\ubcf4\uac04 \uc804\ub7b5, \uc190\uc2e4 \ud568\uc218, \uce35 \uc218)\uc744 \uc0ac\uc6a9\ud558\uc5ec OpenMath2 \ub370\uc774\ud130\uc14b\uc5d0\uc11c Llama-3.1-8B-Instruct \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc124\uc815\uc5d0 \ub530\ub978 Math Hard \uc815\ud655\ub3c4, GSM8K \uc815\ud655\ub3c4, GPQA \uc815\ud655\ub3c4, MMLU \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec \ucd5c\uc801\uc758 \uc124\uc815\uc744 \ucc3e\uace0\uc790 \ud558\uc600\uc2b5\ub2c8\ub2e4.  Math Hard\ub294 \uc0c8\ub85c \ud559\uc2b5\ud55c \uacfc\uc81c\uc758 \uc131\ub2a5\uc744, MMLU\ub294 \uae30\uc874 \uc9c0\uc2dd\uc758 \ubcf4\uc874 \uc815\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 Catastrophic Forgetting (CF) \uc644\ud654\uc640 \uc0c8\ub85c\uc6b4 \uc9c0\uc2dd \uc2b5\ub4dd \uc0ac\uc774\uc758 \uade0\ud615\uc744 \ucc3e\ub294 \ub370 \ucd08\uc810\uc744 \ub9de\ucd94\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "4.2.3. ABLATION STUDIES"}, {"content": "| Category | Analogous Word Pairs | Sentences(Examples) |\n|---|---|---|\n| **Gender Pairs** | king:queen, man:woman, actor:actress, waiter:waitress, uncle:aunt, nephew:niece | king is to queen |\n| **Verb Tenses** | swim:swam, fly:flew, see:saw, go:went, walking:walked, swimming:swam | swim is to swam |\n| **Capital-Country** | Paris:France, Tokyo:Japan, Brasilia:Brazil, Ottawa:Canada | Paris is to France |\n| **Country-Currency** | Russia:ruble, Japan:yen, United States:dollar, United Kingdom:pound | Russia is to ruble |\n| **Singular-Plural** | dog:dogs, cat:cats, mouse:mice, goose:geese, child:children, person:people | mouse is to mice |\n| **Comparative Forms** | good:better, cold:colder | good is to better |\n| **Entity-Product** | Apple:iPhone, Microsoft:Windows | Apple is to iPhone |\n| **Language-Nationality** | Spain:Spanish, Italy:Italian | Spain is to Spanish |\n| **Family Relations** | uncle:aunt, nephew:niece | uncle is to aunt |\n| **Other Relations** | tree:forest, building:city | tree is to forest |", "caption": "Table 6: Categorized Probe Data with Compiled Sentences", "description": "\ubcf8 \ub17c\ubb38\uc758 \ud45c 6\ub294 \uc228\uaca8\uc9c4 \uc0c1\ud0dc \uc815\ub82c \ubd84\uc11d\uc744 \uc704\ud55c \ud0d0\uce68 \ubb38\uc7a5(Probe Sentences)\ub4e4\uc744 \ubc94\uc8fc\ud654\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc94\uc8fc (\uc131\ubcc4 \uc30d, \ub3d9\uc0ac \uc2dc\uc81c, \uc218\ub3c4-\uad6d\uac00, \uad6d\uac00-\ud1b5\ud654, \ub2e8\uc218-\ubcf5\uc218, \ube44\uad50 \ud615\ud0dc, \uac1c\uccb4-\uc81c\ud488, \uc5b8\uc5b4-\uad6d\uc801, \uac00\uc871 \uad00\uacc4, \uae30\ud0c0 \uad00\uacc4)\uc5d0 \ud574\ub2f9\ud558\ub294 \ubb38\uc7a5 \uc608\uc2dc\ub4e4\uc744 \uc81c\uc2dc\ud558\uc5ec,  \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc758\ubbf8 \uad00\uacc4\ub97c \ud3ec\uad04\ud558\ub294 \ud0d0\uce68 \ubb38\uc7a5\ub4e4\uc758 \uad6c\uc131\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574,  \ubaa8\ub378\uc758 \uc228\uaca8\uc9c4 \uc0c1\ud0dc \ubca1\ud130 \uac04\uc758 \uc758\ubbf8\uc801 \uc720\uc0ac\uc131\uacfc \uc77c\uad00\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ub294 \ub370\uc774\ud130\uc758 \ub2e4\uc591\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "B. Hidden State Alignment"}, {"content": "| Task | Dataset (Abbreviation) | Data Source | Prompt Template |\n|---|---|---|---|\n| **Math** | Math-0shot (Math) | [1] | [15]* |\n|  | Math-Hard-0shot (MathH) | [2] | [16]* |\n|  | GSM8K (G8K) | [3] | [17]* |\n| **Coding** | MBPP-Sanitize-0shot (MBPPS) | [4] | [18]* |\n|  | MBPP-Plus-0shot (MBPP+) | [5] | [19]* |\n|  | HumanEval-Greedy (HE) | [6] | [20]* |\n|  | HumanEval-Plus-Greedy (HE+) | [7] | [21]* |\n| **Chinese** | C-Eval-0shot (CEval) | [8] | [22]* |\n|  | C-Eval-0shot-CoT (CEvalC) | [8] | C.1 |\n|  | CMMLU-0shot (CMMLU) | [9] | [23]* |\n|  | CMMLU-0shot-CoT (CMMLUC) | [9] | C.1 |\n| **Original Capabilities-CSFT** | ARC_Challenge-0shot (ARC) | [10] | [10]* |\n|  | GPQA-0shot (GPQA) | [11] | [11]* |\n|  | MMLU-0shot (MMLU) | [12] | [12]* |\n|  | MMLU_Pro-5shot (MMLUP) | [13] | [13]* |\n| **Original Capabilities-CPT** | BBH-3shot (BBH) | [14] | [14]* |\n|  | MMLU-5shot (MMLU) | [12] | [12]* |\n|  | MMLU_Pro-5shot (MMLUP) | [13] | [13]* |", "caption": "Table 7: Evaluation datasets, abbreviations, data source, and prompt templates. \u2217*\u2217 - input_final_prompts column", "description": "\ud45c 7\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud3c9\uac00 \ub370\uc774\ud130\uc14b, \uc57d\uc5b4, \ub370\uc774\ud130 \ucd9c\ucc98, \ud504\ub86c\ud504\ud2b8 \ud15c\ud50c\ub9bf\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud589\uc740 \ud2b9\uc815 \uacfc\uc81c(\uc218\ud559, \ucf54\ub529, \uc911\uad6d\uc5b4, \uc6d0\ubcf8 \uae30\ub2a5)\uc5d0 \ub300\ud55c \ub370\uc774\ud130\uc14b\uc744 \ub098\ud0c0\ub0b4\uba70, \uc57d\uc5b4, \ub370\uc774\ud130 \ucd9c\ucc98\uac00 \ud568\uaed8 \uc81c\uc2dc\ub429\ub2c8\ub2e4.  `*` \ud45c\uc2dc\ub294 `input_final_prompts` \uc5f4\uc758 \ub370\uc774\ud130\uac00 \ucd5c\uc885 \uc785\ub825 \ud504\ub86c\ud504\ud2b8\uc784\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uacfc\uc81c\uc5d0 \ub300\ud55c \ub370\uc774\ud130\uc14b\uacfc \ud504\ub86c\ud504\ud2b8 \uc815\ubcf4\ub97c \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \uc815\ub9ac\ud55c \uac83\uc785\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc774\ud574\ud558\ub294 \ub370 \ud544\uc218\uc801\uc778 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Question | Answer |\n|---|---| \n| \u5728\u4ee5\u4e0b\u95ee\u9898\u548c\u56db\u4e2a\u5019\u9009\u7b54\u6848\uff08A\u3001B\u3001C \u548c D\uff09\u4e2d\uff0c\u9009\u62e9\u6700\u4f73\u7b54\u6848\u3002\u95ee\u9898\uff1a\u2026 | A. \u2026 |\n|  | B. \u2026 |\n|  | C. \u2026 |\n|  | D. \u2026 |\n| \u5bf9\u4e8e\u7b80\u5355\u7684\u95ee\u9898\uff1a\u5c3d\u91cf\u7b80\u6d01\u5730\u89e3\u91ca, \u5e76\u63d0\u4f9b\u7b54\u6848\u3002\u5bf9\u4e8e\u590d\u6742\u7684\u95ee\u9898\uff1a\u4f7f\u7528\u4ee5\u4e0b\u9010\u6b65\u683c\u5f0f\uff1a |  \u6b65\u9aa4 1: [\u7b80\u660e\u63cf\u8ff0] [\u7b80\u8981\u89e3\u91ca] |\n|  | \u6b65\u9aa4 2: [\u7b80\u660e\u63cf\u8ff0] [\u7b80\u8981\u89e3\u91ca] |\n|  | \u65e0\u8bba\u91c7\u7528\u54ea\u79cd\u65b9\u6cd5\uff0c\u59cb\u7ec8\u4ee5\u4ee5\u4e0b\u5185\u5bb9\u7ed3\u675f\uff1a \u6700\u4f73\u7b54\u6848\u662f [\u7b54\u6848\u5b57\u6bcd]\u3002[\u7b54\u9898\u7ed3\u675f] \u5176\u4e2d [\u7b54\u6848\u5b57\u6bcd] \u662f A\u3001B\u3001C \u6216 D \u4e2d\u7684\u4e00\u4e2a\u3002\u8ba9\u6211\u4eec\u4e00\u6b65\u4e00\u6b65\u601d\u8003\u3002 | ", "caption": "Table 8: Chain-of-Thought Prompt for Chinese Benchmarks - CEvalC and CMMLUC", "description": "\ubcf8 \ud45c\ub294 \ub17c\ubb38\uc758 C.1\uc808\uc5d0\uc11c \uc5b8\uae09\ub41c CEvalC\uc640 CMMLUC\uc5d0 \ub300\ud55c Chain-of-Thought \ud504\ub86c\ud504\ud2b8\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc911\uad6d\uc5b4 \uae30\ubc18\uc758 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ubcf5\uc7a1\ud55c \ubb38\uc81c\uc5d0 \ub300\ud55c \uad6c\uc870\uc801 \ucd94\ub860\uacfc \uac04\ub2e8\ud55c \ubb38\uc81c\uc5d0 \ub300\ud55c \uac04\uacb0\ud55c \ub2f5\ubcc0\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \uc124\uacc4\ub41c \ud504\ub86c\ud504\ud2b8\uc758 \uad6c\uc870\uc640 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc77c\uad00\ub41c \ud3c9\uac00\ub97c \uc704\ud574 \ub2e8\uacc4\ubcc4 \ucd94\ub860 \ubc29\uc2dd\uc744 \uad8c\uc7a5\ud558\ub294 \ub0b4\uc6a9\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.", "section": "C. Chain-of-Thought Evaluation for Chinese Benchmarks"}]