{"references": [{"fullname_first_author": "Yuval Alaluf", "paper_title": "Cross-image attention for zero-shot appearance transfer", "publication_date": "2024-00-00", "reason": "This paper proposes a novel method for zero-shot appearance transfer using cross-image attention, which is highly relevant to the consistent image editing task addressed in the main paper."}, {"fullname_first_author": "Mingdeng Cao", "paper_title": "MasaCtrl: Tuning-free mutual self-attention control for consistent image synthesis and editing", "publication_date": "2023-00-00", "reason": "This work presents MasaCtrl, a training-free method for consistent image editing that modifies self-attention modules, providing a comparative baseline for the proposed method."}, {"fullname_first_author": "Tim Brooks", "paper_title": "InstructPix2Pix: Learning to follow image editing instructions", "publication_date": "2023-00-00", "reason": "InstructPix2Pix introduces a training-based approach for image editing guided by instructions, offering a contrasting technique to the training-free method proposed in the main paper."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat GANs on image synthesis", "publication_date": "2021-00-00", "reason": "This paper is foundational as it demonstrates the superiority of diffusion models over GANs for image synthesis, forming the basis for many modern image editing techniques, including the one presented in the main paper."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This work introduces high-resolution image synthesis using latent diffusion models, providing a core technology utilized by the proposed method and many others in consistent image editing."}]}