---
title: "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis"
summary: "LLasa: ë‹¨ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ TTS ëª¨ë¸ë¡œ í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê³  í‘œí˜„ë ¥ ë†’ì€ ìŒì„± í•©ì„± ë‹¬ì„±!"
categories: ["AI Generated", "ğŸ¤— Daily Papers"]
tags: ["Natural Language Processing", "Text-to-Speech", "ğŸ¢ Hong Kong University of Science and Technology",]
showSummary: true
date: 2025-02-06
draft: false
---

<br>

{{< keywordList >}}
{{< keyword icon="fingerprint" >}} 2502.04128 {{< /keyword >}}
{{< keyword icon="writer" >}} Zhen Ye et el. {{< /keyword >}}
 
{{< keyword >}} ğŸ¤— 2025-02-07 {{< /keyword >}}
 
{{< /keywordList >}}

{{< button href="https://arxiv.org/abs/2502.04128" target="_self" >}}
â†— arXiv
{{< /button >}}
{{< button href="https://huggingface.co/papers/2502.04128" target="_self" >}}
â†— Hugging Face
{{< /button >}}




### TL;DR


{{< lead >}}

ìµœê·¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì— í˜ì‹ ì„ ê°€ì ¸ì™”ì§€ë§Œ, LLMì„ í™œìš©í•œ ìŒì„± í•©ì„±(TTS) ì‹œìŠ¤í…œì€ ì—¬ì „íˆ ë‹¤ë‹¨ê³„ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì´ ì–´ë µë‹¤ëŠ” ë¬¸ì œì ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ TTS ì‹œìŠ¤í…œì€ ì£¼ë¡œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ ì— ì´ˆì ì„ ë§ì¶° ì—°êµ¬ë˜ì–´ ì™”ìœ¼ë©°, LLMì—ì„œì²˜ëŸ¼ í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì— ëŒ€í•œ ì—°êµ¬ëŠ” ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” TTS ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ í–¥ìƒì— ì œì•½ì´ ë˜ëŠ” ìš”ì¸ì´ì—ˆìŠµë‹ˆë‹¤.

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¨ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ ê¸°ë°˜ì˜ ìƒˆë¡œìš´ TTS ëª¨ë¸ì¸ Llasaë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.  LlasaëŠ” LLMê³¼ì˜ í˜¸í™˜ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë‹¨ì¼ ê³„ì¸µ ë²¡í„° ì–‘ìí™”(VQ) ì½”ë±ì„ ì‚¬ìš©í•˜ë©°, í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì„ í†µí•´ í•©ì„± ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ì›€, í‘œí˜„ë ¥, ì •í™•ì„±ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.  íŠ¹íˆ, ì¶”ë¡  ë‹¨ê³„ì—ì„œ ìŒì„± ì´í•´ ëª¨ë¸ì„ ê²€ì¦ìë¡œ í™œìš©í•˜ì—¬ ê³„ì‚° ê·œëª¨ë¥¼ ì¡°ì •í•¨ìœ¼ë¡œì¨ ê°ì • í‘œí˜„, ìŒìƒ‰ ì¼ê´€ì„±, ë‚´ìš© ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¨ ì ì´ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.

{{< /lead >}}


#### Key Takeaways

{{< alert "star" >}}
{{< typeit speed=10 lifeLike=true >}} LLM ê¸°ë°˜ TTS ëª¨ë¸ì¸ Llasaë¥¼ ì œì•ˆí•˜ì—¬ ë‹¨ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ë¥¼ ì‚¬ìš©, íš¨ìœ¨ì„± ì¦ëŒ€ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=1000 lifeLike=true >}} í›ˆë ¨ ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì„ í†µí•´ í•©ì„± ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ í‘œí˜„ë ¥ í–¥ìƒ {{< /typeit >}}
{{< /alert >}}

{{< alert "star" >}}
{{< typeit speed=10 startDelay=2000 lifeLike=true >}} ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì„ í†µí•´ íŠ¹ì • ê²€ì¦ìì˜ ì„ í˜¸ë„ì— ë§ì¶° ìƒì„± ê²°ê³¼ ê°œì„  {{< /typeit >}}
{{< /alert >}}

#### Why does it matter?
ë³¸ ë…¼ë¬¸ì€ **LLM ê¸°ë°˜ ìŒì„± í•©ì„± ë¶„ì•¼ì˜ í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •**ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ì—°êµ¬ë¥¼ ì œì‹œí•˜ì—¬, **TTS ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ í–¥ìƒê³¼ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥ ì œì‹œ**ì— ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹™ë‹ˆë‹¤.  LLMì˜ ë°œì „ê³¼ TTS ê¸°ìˆ ì˜ ìœµí•©ì— ëŒ€í•œ ìµœì‹  ë™í–¥ì„ ë°˜ì˜í•˜ë©°, íš¨ìœ¨ì ì¸ ëª¨ë¸ ì„¤ê³„ ë° í›ˆë ¨ ì „ëµì„ ì œì‹œí•¨ìœ¼ë¡œì¨ ê´€ë ¨ ì—°êµ¬ìë“¤ì—ê²Œ ê·€ì¤‘í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, **ì¶”ë¡  ì‹œê°„ ê³„ì‚° ê·œëª¨ ì¡°ì •ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ ì „ëµ**ì€ ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ìƒˆë¡œìš´ ì—°êµ¬ ì˜ì—­ì„ ê°œì²™í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ì´ëŠ” í–¥í›„ **ë”ìš± ìì—°ìŠ¤ëŸ½ê³  í‘œí˜„ë ¥ì´ í’ë¶€í•œ ìŒì„± í•©ì„± ì‹œìŠ¤í…œ ê°œë°œ**ì„ ìœ„í•œ ì¤‘ìš”í•œ ë°œíŒì´ ë  ê²ƒì…ë‹ˆë‹¤.

------
#### Visual Insights



![](https://arxiv.org/html/2502.04128/extracted/6183923/comparison_plot.png)

> ğŸ”¼ ì´ ê·¸ë¦¼ì€ ë…¼ë¬¸ì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê·¸ë¦¼ìœ¼ë¡œ, ì¤‘êµ­ì–´ì™€ ì˜ì–´ ìŒì„± í•©ì„±ì— ëŒ€í•œ ì „ë¬¸ê°€ í‰ê°€ ì ìˆ˜ì˜ í‰ê· ì„ ë¹„êµí•œ ê²ƒì…ë‹ˆë‹¤. ì¤‘êµ­ì–´ì˜ ê²½ìš° ê°ì •, ì–µì–‘, ì‹œ, ë‹¤ì˜ì–´, ì˜ë¬¸ë¬¸, í˜€ ê¼¬ì„, í¬ê·€í•œ ê¸€ì ë“± 7ê°€ì§€ ë²”ì£¼ì— ëŒ€í•œ í‰ê·  ì ìˆ˜ê°€ í‘œì‹œë˜ì–´ ìˆê³ , ì˜ì–´ì˜ ê²½ìš° ë³µí•© ëª…ì‚¬, ê°ì •, ì™¸êµ­ì–´, ì–µì–‘, êµ¬ë‘ì , ì˜ë¬¸ë¬¸, ë³µì¡í•œ êµ¬ë¬¸ ë“± 7ê°€ì§€ ë²”ì£¼ì— ëŒ€í•œ í‰ê·  ì ìˆ˜ê°€ ë¹„êµë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ë²”ì£¼ì— ëŒ€í•œ ì ìˆ˜ëŠ” ëª¨ë¸ í¬ê¸°(1B, 3B, 8B)ì™€ í›ˆë ¨ ë°ì´í„° í¬ê¸°(80k, 160k, 250k ì‹œê°„)ì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ê·¸ë¦¼ì„ í†µí•´ ëª¨ë¸ í¬ê¸°ì™€ í›ˆë ¨ ë°ì´í„° í¬ê¸°ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì „ë°˜ì ì¸ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  íŠ¹íˆ 8B ëª¨ë¸ì˜ ê²½ìš° ì–´ë ¤ìš´ ê³¼ì œ(ì˜ˆ: í˜€ ê¼¬ì„, ì‹œ)ì—ì„œ ë”ìš± í° ì„±ëŠ¥ í–¥ìƒì„ ë³´ì…ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Figure 1: Comparison of mean expert score for Chinese and English
> </details>





{{< table-caption >}}
| Model | Token Rate | Codebook Size | Codebook Layer | Frame Rate | WER â†“ | STOI â†‘ | PESQ-WB â†‘ | PESQ-NB â†‘ | SPK-SIM â†‘ | UT MOS â†‘ |
|---|---|---|---|---|---|---|---|---|---|---|
| Ground Truth | - | - | - | - |  |  |  |  |  | 4.09 |
| DAC | 600 | 1024 | 12 | 50 | **2.00** | **0.95** | **4.01** | **4.15** | **0.95** | **4.00** |
| Encodec | 600 | 1024 | 8 | 75 | 2.15 | 0.94 | 2.77 | 3.18 | 0.89 | 3.09 |
| Encodec | 150 | 1024 | 2 | 75 | 4.90 | 0.85 | 1.56 | 1.94 | 0.60 | 1.58 |
| DAC | 100 | 1024 | 2 | 50 | 13.27 | 0.73 | 1.13 | 1.40 | 0.32 | 1.29 |
| SpeechTokenizer | 100 | 1024 | 2 | 50 | 3.92 | 0.77 | 1.25 | 1.59 | 0.36 | 2.28 |
| Mimi | 100 | 2048 | 8 | 12.5 | 2.96 | **0.91** | 2.25 | 2.80 | **0.73** | 3.56 |
| X-codec | 100 | 1024 | 2 | 50 | **2.49** | 0.86 | **2.33** | **2.88** | 0.72 | **4.21** |
| BigCodec | 80 | 8192 | 1 | 80 | **2.76** | **0.93** | **2.68** | **3.27** | **0.84** | **4.11** |
| WavTokenizer | 75 | 4096 | 1 | 75 | 3.98 | 0.90 | 2.13 | 2.63 | 0.65 | 3.79 |
| Mimi | 75 | 2048 | 6 | 12.5 | 3.61 | 0.89 | 1.99 | 2.51 | 0.65 | 3.38 |
| Encodec | 75 | 1024 | 1 | 75 | 28.92 | 0.77 | 1.23 | 1.48 | 0.25 | 1.25 |
| DAC | 50 | 1024 | 1 | 50 | 74.55 | 0.62 | 1.06 | 1.20 | 0.08 | 1.25 |
| SpeechTokenizer | 50 | 1024 | 1 | 50 | 5.01 | 0.64 | 1.14 | 1.30 | 0.17 | 1.27 |
| Mimi | 50 | 2048 | 4 | 12.5 | 4.89 | 0.85 | 1.64 | 2.09 | 0.50 | 3.03 |
| StableCodec | 50 | 15625 | 2 | 25 | 5.12 | 0.91 | 2.24 | 2.91 | 0.62 | **4.23** |
| SemantiCodec | 50 | 32768/8192 | 2 | 25 | 6.89 | 0.84 | 1.66 | 2.18 | 0.58 | 2.71 |
| X-codec | 50 | 1024 | 1 | 50 | 3.42 | 0.83 | 1.84 | 2.38 | 0.52 | 4.05 |
| WavTokenizer | 40 | 4096 | 1 | 40 | 11.20 | 0.85 | 1.62 | 2.06 | 0.48 | 3.57 |
| X-codec2 (ours) | 50 | 65536 | 1 | 50 | **2.47** | **0.92** | **2.43** | **3.04** | **0.82** | 4.13 |{{< /table-caption >}}

> ğŸ”¼ í‘œ 1ì€ ë‹¤ì–‘í•œ ì½”ë± ëª¨ë¸ ê°„ì˜ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° í† í° ë¹„ìœ¨ì— ëŒ€í•´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê°’ì€ êµµê²Œ í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¹„íŠ¸ìœ¨ ëŒ€ì‹  í† í° ë¹„ìœ¨ì„ ì‚¬ìš©í•œ ì´ìœ ëŠ” LLM ê´€ì ì—ì„œ ë” ì§ê´€ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìŒì„± ì»¨í…ìŠ¤íŠ¸ ì°½ ê¸¸ì´ë¥¼ í† í° ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ë©´ ìƒì„±ëœ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‘œì—ëŠ” ê° ëª¨ë¸ì˜ í† í° ë¹„ìœ¨, ì½”ë“œë¶ í¬ê¸°, ì½”ë“œë¶ ë ˆì´ì–´ ìˆ˜, í”„ë ˆì„ ë¹„ìœ¨, ë‹¨ì–´ ì˜¤ë¥˜ìœ¨(WER), ìŒì„± í’ˆì§ˆ ê°ê´€ì  í‰ê°€ ì§€í‘œ(STOI), PESQ, ì£¼ê´€ì  í‰ê°€ ì§€í‘œ(MOS) ë“± ë‹¤ì–‘í•œ ì§€í‘œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ í‘œë¥¼ í†µí•´ ì œì‹œëœ ì½”ë± ëª¨ë¸ë“¤ì˜ ìƒëŒ€ì  ì„±ëŠ¥ê³¼ íŠ¹ì§•ì„ ë¹„êµ ë¶„ì„í•˜ê³ , ìµœì ì˜ ëª¨ë¸ ì„ íƒì— ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 1: Comparison between different codec models. Bold values indicate the best for each token rate. We use token rate instead of bitrate because, from the perspective of LLMs, it is more intuitive: dividing the speech context window length by the token rate directly gives the generated audio duration in seconds.
> </details>





### In-depth insights


#### LLM-TTS Scaling Laws
LLM ê¸°ë°˜ TTS(í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜)ì˜ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ê·œëª¨ í™•ì¥ ë²•ì¹™ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ ë…¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. **ëª¨ë¸ í¬ê¸°, í›ˆë ¨ ë°ì´í„° í¬ê¸°, ê³„ì‚°ëŸ‰**ê³¼ ê°™ì€ ìš”ì†Œë“¤ì´ TTS í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, íš¨ìœ¨ì ì¸ ìì› ë°°ë¶„ ì „ëµì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.  **í›ˆë ¨ ì‹œê°„ê³¼ ì¶”ë¡  ì‹œê°„ì˜ ê· í˜•**ì„ ë§ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, í›ˆë ¨ ì‹œê°„ì„ ëŠ˜ë ¤ ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ê²ƒë§Œí¼ì´ë‚˜ ì¶”ë¡  ì‹œê°„ì„ íš¨ìœ¨í™”í•˜ì—¬ ì‹¤ì‹œê°„ ì‘ìš© ë¶„ì•¼ì— ì ìš© ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. **ë°ì´í„°ì…‹ì˜ ì§ˆì  í–¥ìƒ** ë˜í•œ ì„±ëŠ¥ í–¥ìƒì— í° ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ, ë‹¤ì–‘í•˜ê³  ê³ í’ˆì§ˆì˜ ë°ì´í„° í™•ë³´ ì „ëµ ë˜í•œ í•„ìš”í•©ë‹ˆë‹¤.  **ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ**ë¥¼ í™œìš©í•˜ì—¬ ì£¼ê´€ì ì¸ í’ˆì§ˆ í‰ê°€ë¿ë§Œ ì•„ë‹ˆë¼, ì •ëŸ‰ì ì¸ ë¶„ì„ì„ í†µí•´ ê°ê´€ì ì¸ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„ì´ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.  **ì¸ì‹ ëª¨ë¸ê³¼ì˜ í†µí•©**ì„ í†µí•´ TTS ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ëª¨ìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì—°êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¤ì œ ì„œë¹„ìŠ¤ í™˜ê²½**ì— ì ìš© ê°€ëŠ¥í•œ ìµœì ì˜ ê·œëª¨ í™•ì¥ ì „ëµì„ ì œì‹œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  **ë‹¤êµ­ì–´ ì§€ì›** ë° **ë‹¤ì–‘í•œ ìŒì„± ìŠ¤íƒ€ì¼** ì§€ì› ë“± ì‚¬ìš©ì ê²½í—˜ì„ ê³ ë ¤í•œ ì¶”ê°€ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

#### X-Codec2 Tokenization
X-Codec2 í† í°í™”ëŠ” ìŒì„± í•©ì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ, ê¸°ì¡´ì˜ ë³µì¡í•œ ë‹¤ë‹¨ê³„ TTS ì‹œìŠ¤í…œê³¼ ë‹¬ë¦¬ **ë‹¨ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ê°„ê²°í•œ êµ¬ì¡°**ë¥¼ ì±„íƒí•˜ì—¬ ì£¼ëª©í•  ë§Œí•©ë‹ˆë‹¤.  ì´ëŠ” **í…ìŠ¤íŠ¸ LLMê³¼ì˜ ì™„ë²½í•œ ì •ë ¬**ì„ ëª©í‘œë¡œ í•˜ì—¬,  í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ ì»´í“¨íŒ… ê·œëª¨ ì¡°ì •ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.  **ìŒì„± í† í°í™” ê³¼ì •**ì€ ì˜ë¯¸ë¡ ì  ì¸ì½”ë”ì™€ ìŒí–¥ ì¸ì½”ë”ë¥¼ ê²°í•©í•˜ì—¬ **ì„¸ë¶„í™”ëœ ìŒì„± íŠ¹ì§•**ì„ í¬ì°©í•˜ê³ , ë‹¨ì¼ ë²¡í„° ì–‘ìí™”(VQ)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë“¤ì„ **ë¶„ë¦¬ëœ í† í°**ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì„ ì·¨í•©ë‹ˆë‹¤.  ì´ëŠ” ê¸°ì¡´ì˜ ì”ì°¨ ë²¡í„° ì–‘ìí™” ë°©ì‹ ëŒ€ì‹  **1ì°¨ì› ì¸ê³¼ì  ì¢…ì†ì„±**ì„ ìœ ì§€í•˜ì—¬ LLMì˜ ìë™ íšŒê·€ ë©”ì»¤ë‹ˆì¦˜ê³¼ì˜ í˜¸í™˜ì„±ì„ ë†’ì…ë‹ˆë‹¤.  **ë””ì½”ë”**ëŠ” ì–‘ìí™”ëœ í‘œí˜„ìœ¼ë¡œë¶€í„° ì˜ë¯¸ë¡ ì  ë° ìŒí–¥ì  ì •ë³´ë¥¼ ì¬êµ¬ì„±í•˜ì—¬ ìµœì¢…ì ì¸ ìŒì„± íŒŒí˜•ì„ ìƒì„±í•©ë‹ˆë‹¤. X-Codec2ì˜ ì´ëŸ¬í•œ ì„¤ê³„ëŠ” **ëª¨ë“ˆí™”ëœ TTS ì‹œìŠ¤í…œ**ì˜ ìœ ì—°ì„±ê³¼ **ë‹¨ìˆœí™”ëœ LLM ê¸°ë°˜ TTS**ì˜ íš¨ìœ¨ì„±ì„ ê²°í•©í•¨ìœ¼ë¡œì¨, í–¥í›„ TTS ì—°êµ¬ ë° ê°œë°œì— ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

#### Inference-Time Search
ì¶”ë¡  ì‹œê°„ ê²€ìƒ‰ì€ **ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì¡°ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹œê°„ì— ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•**ì…ë‹ˆë‹¤. ì´ëŠ” ê¸°ë³¸ ëª¨ë¸ì—ì„œ ì—¬ëŸ¬ í›„ë³´ ì¶œë ¥ì„ ìƒì„±í•œ ë‹¤ìŒ, ì‚¬í›„ í•„í„°ë§ ë° ì •ì œë¥¼ í†µí•´ ìƒì„±ëœ ì½˜í…ì¸ ì˜ í’ˆì§ˆì„ ë†’ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.  **ê²€ì¦ì ë˜ëŠ” ì±„ì  ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ìƒì„±ëœ ì—¬ëŸ¬ ìŒì„± í›„ë³´ë¥¼ í‰ê°€í•˜ê³ , íŠ¹ì • ê²€ì¦ìì˜ í¸í–¥ì— ë” ë§ì¶° ìƒì„± ê²°ê³¼ë¥¼ ì •ë ¬**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ê°ì • í‘œí˜„, ìŒìƒ‰ ì¼ê´€ì„±, ì½˜í…ì¸  ì •í™•ë„ë¥¼ ê°œì„ **í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìœ¼ë©°, íŠ¹íˆ **ì¸ì‹ ëª¨ë¸ì´ë‚˜ ë‹¤ë¥¸ ì´í•´ ëª¨ë¸ì„ ê²€ì¦ìë¡œ í™œìš©**í•  ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤.  **ë¹” ì„œì¹˜ë‚˜ ìµœìƒìœ„ Nê°œ ì„ íƒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´** ë”ìš± ë¯¸ì„¸í•œ ì œì–´ê°€ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” íŠ¹íˆ **ë³µì¡í•œ ì‘ì—…ì´ë‚˜ ë‹¤ì–‘í•œ í‰ê°€ ê¸°ì¤€ì„ ì‚¬ìš©í•  ë•Œ ìœ ìš©**í•©ë‹ˆë‹¤.  ê·¸ëŸ¬ë‚˜, **ì¤‘ê°„ ë³´ìƒì— ëŒ€í•œ ê³¼ì í•©ì´ë‚˜ ì§€ì—­ì  ìµœì ì ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ìœ„í—˜ì„±**ë„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

#### Zero-Shot TTS
ì œë¡œìƒ· TTSëŠ” ì‚¬ì „ì— ì ‘í•´ë³´ì§€ ëª»í•œ í™”ìë‚˜ ê°ì •, í˜¹ì€ ìŒìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ ë§í•©ë‹ˆë‹¤. ì´ëŠ” **ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥**ì„ í‰ê°€í•˜ëŠ” ì¤‘ìš”í•œ ì§€í‘œì´ë©°, **ë°ì´í„° íš¨ìœ¨ì„±**ê³¼ **ì‹¤ìš©ì„±** ì¸¡ë©´ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.  ê¸°ì¡´ TTS ëª¨ë¸ë“¤ì€ íŠ¹ì • í™”ìë‚˜ ìŒìƒ‰ì— ëŒ€í•œ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ í™”ìë‚˜ ìŒìƒ‰ì„ ì²˜ë¦¬í•˜ë ¤ë©´ ì¶”ê°€ì ì¸ í›ˆë ¨ì´ í•„ìš”í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì œë¡œìƒ· TTSëŠ” **ì ì€ ì–‘ì˜ ë°ì´í„°** í˜¹ì€ **ì¶”ê°€ í›ˆë ¨ ì—†ì´** ìƒˆë¡œìš´ ë°ì´í„°ì— ì ì‘í•  ìˆ˜ ìˆì–´ **ì‹œê°„ ë° ë¹„ìš© ì ˆê°** íš¨ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.  **ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ìŒì„± ë°ì´í„°**ì— ëŒ€í•œ ì ì‘ë ¥ ë˜í•œ ì¤‘ìš”í•˜ë©°,  **ìƒˆë¡œìš´ ì–¸ì–´ë‚˜ ìŒì„± ë°ì´í„°**ì— ëŒ€í•œ í›ˆë ¨ ì—†ì´ë„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì´ ì´ìƒì ì…ë‹ˆë‹¤.  ì œë¡œìƒ· TTS ê¸°ìˆ ì˜ ë°œì „ì€ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ **TTS ê¸°ìˆ ì˜ ì ‘ê·¼ì„±ê³¼ í™œìš©ë„**ë¥¼ ë†’ì´ëŠ” ë° í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  íŠ¹íˆ **ë‹¤êµ­ì–´ ì§€ì›**ì´ë‚˜ **ê°œì¸ ë§ì¶¤í˜• ìŒì„± í•©ì„±** ì‹œìŠ¤í…œ ê°œë°œì— ì¤‘ìš”í•œ ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Llasa Limitations
LLasaëŠ” ë‹¨ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ TTS ëª¨ë¸ë¡œ, **ê°„ê²°ì„±ê³¼ í™•ì¥ì„±**ì— ì¤‘ì ì„ ë‘ê³  ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë‹¨ìˆœí™”ëŠ” ëª‡ ê°€ì§€ ì œí•œ ì‚¬í•­ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ë†’ì€ ê³„ì‚° ë¹„ìš©**ì€ LLMsì˜ ì¼ë°˜ì ì¸ ë¬¸ì œì´ë©°, LLasaë„ ì˜ˆì™¸ëŠ” ì•„ë‹™ë‹ˆë‹¤. íŠ¹íˆ ì¶”ë¡  ì‹œê°„ ê³„ì‚° ë¹„ìš©ì„ ëŠ˜ë¦¬ëŠ” ë°©ë²•ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, **ì‹¤ì‹œê°„ ì‘ìš© í”„ë¡œê·¸ë¨ì—ëŠ” ë¶€ì í•©**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¨ì¼ ê³„ì¸µ ë²¡í„° ì–‘ìí™” ì½”ë±ì€ ë‹¤ë¥¸ ê³ ê¸‰ ì½”ë±ì— ë¹„í•´ **ìŒì§ˆ ë©´ì—ì„œ ë‹¤ì†Œ ë‚®ì€ ì„±ëŠ¥**ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  **ë°ì´í„° í¸í–¥** ë¬¸ì œ ë˜í•œ ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • ì–¸ì–´ë‚˜ í™”ìì— ëŒ€í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš° ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì €í•˜ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, LLasaëŠ” ì£¼ë¡œ **ìŒì„± í•©ì„±ì— ì¤‘ì **ì„ ë‘ê³  ìˆê¸° ë•Œë¬¸ì—, ìŒì„± ì´í•´ë‚˜ ë‹¤ë¥¸ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ëŒ€í•œ ì ìš©ì€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë”°ë¼ì„œ, LLasaì˜ ì‹¤ì§ˆì ì¸ ì ìš© ê°€ëŠ¥ì„±ì€ íŠ¹ì • ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìš”êµ¬ì‚¬í•­ ë° ì œì•½ ì¡°ê±´ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


### More visual insights




<details>
<summary>More on tables
</summary>


{{< table-caption >}}
| Model | test-zh |  | test-en |  | test-hard |  | 
|---|---|---|---|---|---|---|---| 
|  | CER â†“ | sim-o â†‘ | WER â†“ | sim-o â†‘ | WER â†“ | sim-o â†‘ | 
| Human | 1.26 | 0.755 | 2.14 | 0.734 | - | - | 
| Our Codec Resyn. | 1.92 | 0.677 | 2.91 | 0.619 | - | - | 
| Seed-TTS â€  | 1.12 | 0.796 | 2.25 | 0.762 | 7.59 | 0.776 | 
| FireRedTTS | 1.51 | 0.635 | 3.82 | 0.460 | 17.45 | 0.621 | 
| MaskGCT | 2.27 | 0.774 | 2.62 | 0.714 | 10.27 | 0.748 | 
| E2 TTS (32 NFE) â€  | 1.97 | 0.730 | 2.19 | 0.710 | - | - | 
| F5-TTS (32 NFE) | 1.56 | 0.741 | 1.83 | 0.647 | 8.67 | 0.713 | 
| CosyVoice | 3.63 | 0.723 | 4.29 | 0.609 | 11.75 | 0.709 | 
| CosyVoice 2 | 1.45 | 0.748 | 2.57 | 0.652 | 6.83 | 0.724 | 
| Train-time Scaling |  |  |  |  |  |  | 
| llasa 1b 80k | 2.69 | 0.648 (0.779) | 3.71 | 0.541 (0.685) | 17.11 | 0.618 (0.765) | 
| llasa 1b 160k | 2.22 | 0.658 (0.783) | 3.60 | 0.563 (0.701) | 16.73 | 0.627 (0.770) | 
| llasa 1b 250k | 1.89 | 0.669 (0.794) | 3.22 | 0.572 (0.708) | 12.13 | 0.638 (0.779) | 
| llasa 3b 250k | 1.60 | 0.675 (0.792) | 3.14 | 0.579 (0.708) | 13.37 | 0.652 (0.782) | 
| llasa 8b 250k | 1.59 | 0.684 (0.798) | 2.97 | 0.574 (0.706) | 11.09 | 0.660 (0.787) | 
| Partial PRM (spk sim) |  |  |  |  |  |  | 
| llasa 1b 80k | 1.52 | 0.811 (0.849) | 2.30 | 0.761 (0.798) | 16.09 | 0.759 (0.824) | 
| llasa 1b 160k | 1.29 | 0.815 (0.851) | 2.29 | 0.774 (0.804) | 14.10 | 0.768 (0.830) | 
| llasa 1b 250k | 1.11 | 0.818 (0.855) | 2.03 | 0.781 (0.809) | 11.30 | 0.773 (0.833) | 
| llasa 3b 250k | 1.06 | 0.824 (0.856) | 1.89 | 0.784 (0.812) | 11.22 | 0.780 (0.836) | 
| llasa 8b 250k | 1.04 | 0.827 (0.856) | 1.84 | 0.783 (0.806) | 10.59 | 0.785 (0.839) | 
| Partial PRM (spk sim)+ORM (WER) |  |  |  |  |  |  | 
| llasa 1b 80k | 0.53 | 0.809 (0.840) | 1.43 | 0.761 (0.792) | 7.22 | 0.732 (0.789) | 
| llasa 1b 160k | 0.53 | 0.812 (0.841) | 1.49 | 0.775 (0.798) | 6.35 | 0.745 (0.799) | 
| llasa 1b 250k | **0.45** | 0.818 (0.845) | 1.46 | 0.782 (0.801) | 5.24 | 0.750 (0.803) | 
| llasa 3b 250k | 0.50 | 0.823 (0.848) | **1.31** | 0.783 (0.803) | 5.39 | 0.759 (0.808) | 
| llasa 8b 250k | 0.47 | 0.825 (0.848) | 1.39 | 0.783 (0.799) | **4.38** | 0.767 (0.812) | 
| llasa 8b 250k |  Chunking: if len(char)&gt;100â†’2 chunks, &gt;200â†’3 chunks,â€¦ |  |  |  | **3.12** | 0.770 (0.791) |{{< /table-caption >}}
> ğŸ”¼ í‘œ 2ëŠ” SEED í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ Llasa ë° ìµœê·¼ TTS ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. â€ ëŠ” íì‡„í˜• ëª¨ë¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Llasa ì‹œë¦¬ì¦ˆì˜ ê²½ìš° sim-o ê°’ì—ëŠ” (ê´„í˜¸ ì•ˆì—) sim-r ê°’ì´ í¬í•¨ë©ë‹ˆë‹¤.  ì´ í‘œëŠ” ë‹¤ì–‘í•œ TTS ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ Llasa ëª¨ë¸ì˜ ê²½ìŸë ¥ì„ ë³´ì—¬ì£¼ê³ , íŠ¹íˆ íì‡„í˜• ëª¨ë¸ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ Llasa ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë”ìš± ëª…í™•í•˜ê²Œ ì œì‹œí•©ë‹ˆë‹¤.  sim-oì™€ sim-r ì§€í‘œë¥¼ í•¨ê»˜ ì œì‹œí•˜ì—¬ ëª¨ë¸ì˜ ìŒì„± ìì—°ë„ ë° ìœ ì‚¬ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 2: Results of llasa and recent TTS models on the SEED test sets. â€  denotes close-sourced models. For llasa series, sim-o values include sim-r in parentheses.
> </details>

{{< table-caption >}}
| Model | Test Clean | Test Other |
|---|---|---|
| whisper large v3 | 1.8 | 3.6 |
| whisper large v2 | 2.7 | 5.2 |
| llasa asr 1b | 2.3 | 7.2 |
| llasa asr 3b | 1.9 | 5.9 |{{< /table-caption >}}
> ğŸ”¼ LibriSpeech í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ë‹¤ì–‘í•œ ìŒì„± ì¸ì‹(ASR) ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ í‘œì…ë‹ˆë‹¤.  Whisper Large v2 ì™€ Whisper Large v3 ëª¨ë¸ê³¼ Llasa ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸ ì •í™•ë„ì™€ í…ŒìŠ¤íŠ¸ ì™¸ ë°ì´í„° ì„¸íŠ¸ì—ì„œ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  í…ŒìŠ¤íŠ¸ ì •í™•ë„ëŠ” ì¼ë°˜ì ì¸ ìŒì„± ì¸ì‹ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì´ê³ , í…ŒìŠ¤íŠ¸ ì™¸ ë°ì´í„° ì„¸íŠ¸ëŠ” ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì…ë‹ˆë‹¤.  ì´ í‘œë¥¼ í†µí•´ Llasa ì‹œìŠ¤í…œì´ ê¸°ì¡´ì˜ ìµœì²¨ë‹¨ ìŒì„± ì¸ì‹ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ ì„±ëŠ¥ì´ ì–´ëŠ ì •ë„ì¸ì§€, ê·¸ë¦¬ê³  ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ì–´ë– í•œì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 3: ASR Performance on LibriSpeech Test Sets
> </details>

{{< table-caption >}}
| Model | en | zh |
|---|---|---|
| GT | 0.94 | 0.94 |
| **Train-time scaling** |  |  |
| llasa 1b (80k) | 0.753 | 0.815 |
| llasa 1b (160k) | 0.762 | 0.822 |
| llasa 1b (250k) | 0.768 | 0.836 |
| llasa 3b (250k) | 0.769 | 0.852 |
| llasa 8b (250k) | 0.778 | 0.861 |
| **Process Reward Models (emotion sim)** |  |  |
| llasa 1b (80k) | 0.933 | 0.970 |
| llasa 1b (160k) | 0.936 | 0.971 |
| llasa 1b (250k) | 0.937 | 0.974 |
| llasa 3b (250k) | 0.949 | 0.975 |
| llasa 8b (250k) | 0.951 | 0.974 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 4ëŠ” Llasa TTS ëª¨ë¸ì˜ ê°ì • í‘œí˜„ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ìˆ˜í–‰ëœ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  'en'ì€ ì˜ì–´, 'zh'ëŠ” ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ì„ ì˜ë¯¸í•˜ë©°, Emotion SimilarityëŠ” ê°ì • ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•œ ì§€í‘œì…ë‹ˆë‹¤.  í‘œì—ëŠ” ë‹¤ì–‘í•œ Llasa ëª¨ë¸ ë³€í˜•(ëª¨ë¸ í¬ê¸°, í•™ìŠµ ë°ì´í„° í¬ê¸° ë“±)ì— ë”°ë¥¸ ê°ì • ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì œì‹œë˜ì–´ ìˆìœ¼ë©°,  ê¸°ì¤€ ëª¨ë¸(Ground Truth, Our Codec Resyn.) ë° ë‹¤ë¥¸ ìµœì²¨ë‹¨ TTS ëª¨ë¸ê³¼ì˜ ì„±ëŠ¥ ë¹„êµë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ì´ëŠ” Llasa ëª¨ë¸ì˜ í•™ìŠµ ë° ì¶”ë¡  ì‹œê°„ í™•ì¥ì´ ê°ì • í‘œí˜„ ëŠ¥ë ¥ í–¥ìƒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 4:  en, zh Emotion Similarity
> </details>

{{< table-caption >}}
| System | WER-H | SIM-o | SIM-r |
|---|---|---|---|
| Ground Truth | 2.15 | 0.668 | - |
| Our Codec Resyn. | 2.49 | 0.580 | 0.638 |
| ELLA-V * | 2.91 | 0.303 | 0.340 |
| VALL-E R â€  | 2.32 | 0.363 | 0.397 |
| CLaM-TTS | 2.36 | 0.477 | 0.513 |
| VALL-E | 3.8 | - | 0.508 |
| VALL-E 2 â€  | 2.32 | 0.504 | 0.529 |
| Voicebox | 2.0 | 0.593 | 0.616 |
| MELLE | 1.98 | 0.508 | 0.539 |
| **Train-time Scaling** |  |  |  |
| LLaSA-TTS 1b 80k | 2.57 | 0.457 | 0.614 |
| LLaSA-TTS 1b 160k | 2.48 | 0.475 | 0.625 |
| LLaSA-TTS 1b 250k | 2.47 | 0.478 | 0.627 |
| LLaSA-TTS 3b 250k | 2.35 | 0.484 | 0.628 |
| LLaSA-TTS 8b 250k | 2.29 | 0.483 | 0.626 |
| **PRM (spk sim)** |  |  |  |
| LLaSA-TTS-80k 1b | 2.43 | 0.699 | 0.738 |
| LLaSA-TTS-160k 1b | 2.36 | 0.712 | 0.744 |
| LLaSA-TTS 1b 250k | 2.37 | 0.712 | 0.743 |
| LLaSA-TTS 3b 250k | 2.26 | 0.715 | 0.745 |
| LLaSA-TTS 8b 250k | 2.24 | 0.714 | 0.741 |
| **PRM (spk sim)+ORMs (WER)** |  |  |  |
| LLaSA-TTS-80k 1b | 1.76 | 0.700 | 0.738 |
| LLaSA-TTS-160k 1b | 1.66 | 0.710 | 0.743 |
| LLaSA-TTS 1b 250k | 1.62 | 0.712 | 0.744 |
| LLaSA-TTS 3b 250k | 1.57 | 0.714 | 0.742 |
| LLaSA-TTS 8b 250k | 1.49 | 0.714 | 0.740 |{{< /table-caption >}}
> ğŸ”¼ í‘œ 5ëŠ” ì§€ì†ì ì¸ ì œë¡œìƒ· ìŒì„± í•©ì„± ì‘ì—…ì— ëŒ€í•œ ê°ê´€ì  ì„±ëŠ¥ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. WER-H(%)ëŠ” HuBERT-Large ASR ëª¨ë¸ì„ ì‚¬ìš©í•œ í‰ê°€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë³¼ë“œì²´ëŠ” ìµœê³ ì˜ ê²°ê³¼ë¥¼, ë°‘ì¤„ì€ ë‘ ë²ˆì§¸ë¡œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. *Han et al.[2024]ì˜ ì¬í˜„ ê²°ê³¼ë¥¼ ì¸ìš©í–ˆëŠ”ë°, ì´ëŠ” ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. â€ ì› ë…¼ë¬¸ì— ë³´ê³ ë˜ì§€ ì•Šì€ ì§€í‘œì— ëŒ€í•´ì„œëŠ” ì €ìë“¤ì´ ì œê³µí•œ ì˜¤ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì´ í‘œëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì œë¡œìƒ· ìŒì„± í•©ì„± ëŠ¥ë ¥ì„ ê°ê´€ì ì¸ ì§€í‘œ(WER-H, SIM-o, SIM-r)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµ ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤. íŠ¹íˆ, HuBERT-Large ASR ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìŒì„± ì¸ì‹ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ê³ , ì›ë³¸ ìŒì„±ê³¼ ì¬êµ¬ì„± ìŒì„± ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ ì—°êµ¬ì˜ ì¬í˜„ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ë”ìš± í­ë„“ì€ ë¹„êµ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 5: Objective performance comparison on continuation zero-shot speech synthesis tasks. WER-H (%) denotes evaluation with the HuBERT-Large ASR model. The boldface indicates the best result, and the underline denotes the second best. *We quote Han et al. [2024]â€™s reproduction results, which demonstrate better performance. â€ We evaluate metrics not reported in the original paper, using the audios provided by the authors.
> </details>

{{< table-caption >}}
| Category | 1 | 2 | 3 |
|---|---|---|---| 
| **Emotion** | No detectable emotion / æ— å¯æ£€æµ‹çš„æƒ…æ„Ÿ | Emotion present but not convincingly rendered / å­˜åœ¨æƒ…æ„Ÿä½†è¡¨è¾¾ä¸å¤Ÿä»¤äººä¿¡æœ | Correct emotion recognition and appropriate rendering / æ­£ç¡®è¯†åˆ«æƒ…æ„Ÿå¹¶æ°å½“è¡¨è¾¾ |
| **Paralinguistic** | No recognition of paralinguistic cues like interjections / æœªè¯†åˆ«å‡ºè¯­è°ƒå­¦å…³é”®è¯ï¼Œå¦‚â€œå“å‘€â€æˆ–â€œå˜˜â€ | Attempts to render paralinguistic cues but unnatural / æ˜ç¡®æ„å›¾è¡¨è¾¾å…³é”®è¯ï¼Œä½†è¡¨è¾¾ä¸è‡ªç„¶ | Natural rendering of paralinguistic cues with appropriate emphasis / è‡ªç„¶è¡¨è¾¾è¯­è°ƒå­¦å…³é”®è¯ï¼Œæ°å½“å¼ºè°ƒ |
| **Chinese Poetry** | Fails to capture the poetic structure and imagery / æœªèƒ½æ•æ‰è¯—æ­Œçš„ç»“æ„å’Œæ„è±¡ | Captures some poetic elements but lacks depth / æ•æ‰äº†ä¸€äº›è¯—æ­Œå…ƒç´ ä½†ç¼ºä¹æ·±åº¦ | Accurately captures the poetic structure, imagery, and emotional depth / å‡†ç¡®æ•æ‰è¯—æ­Œçš„ç»“æ„ã€æ„è±¡å’Œæƒ…æ„Ÿæ·±åº¦ |
| **Polyphonic Characters** | Incorrect pronunciation and meaning of polyphonic characters / å¤šéŸ³å­—å‘éŸ³é”™è¯¯ï¼Œæ„ä¹‰ä¸æ­£ç¡® | Attempts correct pronunciation but with minor errors / å°è¯•æ­£ç¡®å‘éŸ³ä½†æœ‰å°é”™è¯¯ | Correct pronunciation and meaning of polyphonic characters / å¤šéŸ³å­—å‘éŸ³å’Œæ„ä¹‰æ­£ç¡® |
| **Questions** | Intonation pattern incorrect, failing to convey questioning tone / è¯­è°ƒæ¨¡å¼ä¸æ­£ç¡®ï¼Œæœªèƒ½ä¼ è¾¾é—®å¥çš„è¯­æ°” | Intonation pattern largely correct but with minor flaws / è¯­è°ƒæ¨¡å¼å¤§ä½“æ­£ç¡®ï¼Œä½†æœ‰ç»†å¾®ç‘•ç–µ | Correct intonation patterns that clearly convey the questioning nature / è¯­è°ƒæ¨¡å¼æ­£ç¡®ï¼Œæ¸…æ™°ä¼ è¾¾é—®å¥çš„æ€§è´¨ |
| **Tongue Twisters** | Inability to articulate the tongue twister, resulting in errors / æ— æ³•æ¸…æ™°è¡¨è¾¾ç»•å£ä»¤ï¼Œå¯¼è‡´é”™è¯¯ | Attempts articulation with some errors / å°è¯•è¡¨è¾¾ç»•å£ä»¤ä½†æœ‰éƒ¨åˆ†é”™è¯¯ | Clear and accurate articulation of the tongue twister without errors / æ¸…æ™°å‡†ç¡®åœ°è¡¨è¾¾ç»•å£ä»¤ï¼Œæ— é”™è¯¯ |
| **Rare Characters** | Mispronunciation or incorrect interpretation of rare characters / ç”Ÿåƒ»å­—å‘éŸ³é”™è¯¯æˆ–è§£é‡Šä¸æ­£ç¡® | Attempts correct pronunciation and interpretation with minor mistakes / å°è¯•æ­£ç¡®å‘éŸ³å’Œè§£é‡Šä½†æœ‰å°é”™è¯¯ | Accurate pronunciation and insightful interpretation of rare characters / ç”Ÿåƒ»å­—å‘éŸ³å’Œè§£é‡Šå‡†ç¡® |{{< /table-caption >}}
> ğŸ”¼ ì´ í‘œëŠ” ì¤‘êµ­ì–´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ í‰ê°€ ê¸°ì¤€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê° ë²”ì£¼(ê°ì •, ë‹´í™”ì  íŠ¹ì§•, ì‹œ, ë‹¤ì˜ì–´, ì§ˆë¬¸, í˜€ ê¼¬ì„, í¬ê·€í•œ ê¸€ì)ì— ëŒ€í•´ ì„¸ ê°€ì§€ ì ìˆ˜ ê¸°ì¤€ì´ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, ê° ì ìˆ˜ëŠ” TTS ì‹œìŠ¤í…œì´ í•´ë‹¹ ë²”ì£¼ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ”ì§€ì— ëŒ€í•œ ìˆ˜ì¤€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 1ì ì€ í•´ë‹¹ ë²”ì£¼ë¥¼ ì „í˜€ ì¸ì‹í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì˜ëª» ìƒì„±í•œ ê²½ìš°, 2ì ì€ ë¶€ë¶„ì ìœ¼ë¡œ ì¸ì‹í•˜ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ì§€ ì•Šê²Œ ìƒì„±í•œ ê²½ìš°, 3ì ì€ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•œ ê²½ìš°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ê° ë²”ì£¼ì— ëŒ€í•œ ì„¸ë¶€ì ì¸ ê¸°ì¤€ì„ í†µí•´ TTS ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ë³´ë‹¤ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 6: Evaluation Criteria for Chinese Test Set
> </details>

{{< table-caption >}}
| Categories | Example sentence | Evaluation criteria |
|---|---|---|
| **Compound Nouns** | The Beckhams decided to rent a charming stone-built quaint countryside holiday cottage. | 1 = fails to recognise compound nouns <br> 2 = fails to realise the phrasal stress naturally <br> 3 = natural phrasal stress |
| **Emotions** | â€Oh my gosh! Are we really going to the Maldives? Thatâ€™s unbelievable!â€ Jennie squealed, bouncing on her toes with uncontained glee. | 1 = no audible emotions <br> 2 = emotion present but insufficient <br> 3 = correct emotion recognition and appropriate rendering |
| **Foreign Words** | Mr. Henry, renowned for his mise en place, orchestrated a seven-course meal, each dish a piÃ¨ce de rÃ©sistance. | 1 = pronounces foreign words with incorrect anglicized pronunciation <br> 2 = applies foreign accent but not entirely correctly <br> 3 = correct rendering in the intended language or accepted anglicized reading |
| **Paralinguistics** | â€Shh, Lucy, shhh, we mustnâ€™t wake your baby brother,â€ Tom whispered, as they tiptoed past the nursery. | 1 = no recognition of paralinguistic keywords such as â€shhhâ€ or â€phewâ€ <br> 2 = clear intention to render keywords distinctly, but rendering unnatural <br> 3 = natural rendering, e.g. making speech voiceless on â€shhhâ€ and other whispered speech |
| **Punctuations** | She received an odd text from her brother: â€™Emergency @ home; call ASAP! Mom &amp; Dad are worriedâ€¦#familymatters.â€™ | 1 = glitches on uncommon punctuations such as # or &amp; <br> 2 = no glitch but incorrect rendering <br> 3 = no glitch and correct pausing and verbalization, e.g. @ as â€atâ€. |
| **Questions** | But the Brexit question remains: After all the trials and tribulations, will the ministers find the answers in time? | 1 = intonation pattern incorrect <br> 2 = intonation pattern largely correct but with minor flaws <br> 3 = correct intonation |
| **Syntactic Complexities** | The movie that De Moya who was recently awarded the lifetime achievement award starred in 2022 was a box-office hit, despite the mixed reviews. | 1 = failure to parse the syntax correctly <br> 2 = parses the syntax largely correctly but the rendering is not entirely natural <br> 3 = parsing correct and rendering natural |{{< /table-caption >}}
> ğŸ”¼ í‘œ 7ì€ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìœ í˜•(ë³µí•© ëª…ì‚¬, ê°ì • í‘œí˜„, ì™¸êµ­ì–´ ë‹¨ì–´, ë§¥ë½ ì •ë³´, êµ¬ë‘ì , ì§ˆë¬¸, ë³µì¡í•œ êµ¬ë¬¸)ì— ëŒ€í•´ TTS ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ìœ í˜•ì— ëŒ€í•´ ì„¸ ê°€ì§€ ë“±ê¸‰(1, 2, 3)ìœ¼ë¡œ í‰ê°€ ê¸°ì¤€ì´ ì œì‹œë˜ì–´ ìˆìœ¼ë©°, ê° ë“±ê¸‰ì€ TTS ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•˜ê³  ìŒì„±ìœ¼ë¡œ ë³€í™˜í–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'ë³µí•© ëª…ì‚¬'ì˜ ê²½ìš° 1ì ì€ ë³µí•© ëª…ì‚¬ë¥¼ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í•œ ê²½ìš°, 2ì ì€ ì–´ëŠ ì •ë„ ì¸ì‹í–ˆì§€ë§Œ ìì—°ìŠ¤ëŸ½ì§€ ì•Šì€ ê²½ìš°, 3ì ì€ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ì¸ì‹í•œ ê²½ìš°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ í‘œëŠ” TTS ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì´í•´ ëŠ¥ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
> <details>
> <summary>read the caption</summary>
> Table 7: Emergent abilities testset by category and evaluation criteria.
> </details>

</details>




### Full paper

{{< gallery >}}
<img src="paper_images/1.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/2.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/3.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/4.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/5.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/6.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/7.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/8.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/9.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/10.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/11.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/12.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/13.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/14.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/15.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/16.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/17.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/18.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/19.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
<img src="paper_images/20.png" class="grid-w50 md:grid-w33 xl:grid-w25" />
{{< /gallery >}}