{"references": [{"fullname_first_author": "Rombach, R.", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper is foundational for the field of high-resolution image synthesis using diffusion models, which is the basis of the proposed MakeAnything model."}, {"fullname_first_author": "Peebles, W.", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-01-01", "reason": "This paper introduces the Diffusion Transformer (DiT), a core component of MakeAnything, enabling scalable and efficient generation of long sequences."}, {"fullname_first_author": "Song, Y.", "paper_title": "ProcessPainter: Learn painting process from sequence data", "publication_date": "2024-06-01", "reason": "This paper is highly relevant as it focuses on procedural sequence generation for painting, which is directly comparable and improved upon by MakeAnything."}, {"fullname_first_author": "Ho, J.", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-01-01", "reason": "This is a seminal paper introducing denoising diffusion probabilistic models, providing the theoretical foundation upon which many subsequent diffusion models, including the one used in MakeAnything, are built."}, {"fullname_first_author": "Zhang, L.", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-02-01", "reason": "This paper addresses controllable generation in diffusion models, which is a key challenge that MakeAnything aims to improve by using LoRA for efficient and effective control."}]}