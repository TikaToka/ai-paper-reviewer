[{"content": "| Methods | Hellaswag |  |  | PIQA |  |  | Winogrande |  |  | RACE-mid |  |  | RACE-high |  |  | Average |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Metric | Mean | Std | Top | Mean | Std | Top | Mean | Std | Top | Mean | Std | Top | Mean | Std | Top | Mean | Std | Top |\n| Base Model | 47.36 | \u00b19.78 | 0% | 74.68 | \u00b16.24 | 0% | 45.15 | \u00b111.78 | 0% | 71.39 | \u00b17.33 | 0% | 67.62 | \u00b16.78 | 0% | 61.24 | \u00b18.38 | 0% |\n| user-specified prompt | 92.35 | \u00b12.78 | 0% | 77.87 | \u00b12.36 | 0% | 78.16 | \u00b17.97 | 0% | 79.88 | \u00b16.32 | 22% | 81.05 | \u00b14.45 | 4% | 81.86 | \u00b14.78 | 5% |\n| TopAccuracy prompt | 91.27 | \u00b12.79 | 86% | 75.96 | \u00b13.89 | 0% | 66.77 | \u00b13.94 | 0% | 84.81 | \u00b14.06 | 59% | 82.45 | \u00b13.26 | 14% | 80.25 | \u00b13.63 | 32% |\n| BATprompt | 90.30 | \u00b11.79 | 78% | 83.41 | \u00b11.74 | 16% | 69.01 | \u00b14.45 | 0% | 83.92 | \u00b15.38 | 65% | 81.33 | \u00b14.21 | 12% | 81.56 | \u00b13.51 | 34% |\n| ZOPO prompt | 92.46 | \u00b12.43 | 86% | 83.52 | \u00b12.23 | 27% | 74.75 | \u00b13.81 | 0% | 83.50 | \u00b15.05 | 51% | 82.36 | \u00b14.53 | 35% | 83.32 | \u00b13.61 | 40% |\n| PAFT | 93.83 | \u00b10.70 | 100% | 89.33 | \u00b10.63 | 100% | 82.09 | \u00b10.81 | 100% | 87.26 | \u00b12.23 | 94% | 85.17 | \u00b11.71 | 73% | 87.57 | \u00b11.57 | 94% |\n| PAFT Improvement | +1.37 | -1.09 | 14% | +5.81 | -1.11 | 73% | +3.93 | -3.00 | 100% | +2.45 | -1.83 | 29% | +2.72 | -1.55 | 38% | +4.25 | -1.94 | 54% |", "caption": "Table 1: Performance comparison of different fine-tuning methods on the test prompt sets across various reasoning and reading comprehension tasks using the LLaMA3-8B Meta (2024) with LoRA rank 8. Results are reported as average accuracy, standard deviation, and percentage of test prompts exceeding a specific score threshold (90% for Hellaswag, 80% for Winogrande, and 85% for other datasets). The Base Model represents the pre-trained model without fine-tuning, user-specified prompt Wei et\u00a0al. (2024) refers to fine-tuning with LoRA using human-designed prompts, TopAccuracy prompt refers to fine-tuning with LoRA using the prompt exhibiting the highest accuracy on the training set, BATprompt refers to fine-tuning with LoRA using the most robust prompt generated by BATprompt Shi et\u00a0al. (2024), and ZOPO prompt refers to fine-tuning with LoRA using the optimal prompt selected by ZOPO Hu et\u00a0al. (2024) from the training prompt set. PAFT (our proposed method) demonstrates superior performance, achieving the highest accuracy and lowest variance across all tasks. The last rows show the comparison of PAFT with the second-best performing method (underlined). The Top column indicates the percentage of test prompts with a correct rate of 90% for Hellaswag, 80% for Winogrande, and 85% for other datasets.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ucd94\ub860 \ubc0f \ub3c5\ud574 \uc774\ud574 \uacfc\uc81c\uc5d0\uc11c \uc5ec\ub7ec \uac00\uc9c0 \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4.  LLaMA3-8B \ubaa8\ub378(LoRA rank 8 \uc0ac\uc6a9)\uc744 \uae30\ubc18\uc73c\ub85c, \ud14c\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8 \uc138\ud2b8\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc815\ud655\ub3c4, \ud45c\uc900 \ud3b8\ucc28, \ud2b9\uc815 \uc810\uc218 \uc784\uacc4\uac12(Hellaswag\ub294 90%, Winogrande\ub294 80%, \uae30\ud0c0 \ub370\uc774\ud130\uc14b\uc740 85%)\uc744 \ucd08\uacfc\ud558\ub294 \ud14c\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc900 \ubaa8\ub378(\ubbf8\uc138 \uc870\uc815 \uc5c6\uc74c), \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ud504\ub86c\ud504\ud2b8(Wei et al., 2024), \ucd5c\uace0 \uc815\ud655\ub3c4 \ud504\ub86c\ud504\ud2b8(\ud6c8\ub828 \uc138\ud2b8\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc815\ud655\ub3c4\ub97c \ubcf4\uc774\ub294 \ud504\ub86c\ud504\ud2b8 \uc0ac\uc6a9), BATprompt(Shi et al., 2024, \uac00\uc7a5 \uac15\ub825\ud55c \ud504\ub86c\ud504\ud2b8 \uc0ac\uc6a9), ZOPO(Hu et al., 2024, \ucd5c\uc801 \ud504\ub86c\ud504\ud2b8 \uc0ac\uc6a9)\ub97c \ube44\uad50 \ub300\uc0c1\uc73c\ub85c \ud558\uc600\uc2b5\ub2c8\ub2e4. PAFT(\uc81c\uc548\ub41c \ubc29\ubc95)\ub294 \ubaa8\ub4e0 \uacfc\uc81c\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc815\ud655\ub3c4\uc640 \uac00\uc7a5 \ub0ae\uc740 \ubd84\uc0b0\uc744 \ub2ec\uc131\ud558\uc5ec \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub9c8\uc9c0\ub9c9 \ud589\uc740 \ub450 \ubc88\uc9f8\ub85c \uc131\ub2a5\uc774 \uc88b\uc740 \ubc29\ubc95\uacfc PAFT\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc8fc\uba70, 'Top' \uc5f4\uc740 Hellaswag\uc758 \uacbd\uc6b0 90%, Winogrande\uc758 \uacbd\uc6b0 80%, \uae30\ud0c0 \ub370\uc774\ud130\uc14b\uc758 \uacbd\uc6b0 85%\uc758 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud55c \ud14c\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc758 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "5. Empirical Results"}, {"content": "| Inference time/h | Hellaswag | PIQA | Winogrande | RACE | Average |\n|---|---|---|---|---|---| \n| Base Model | 3.97 | 1.35 | 1.72 | 6.24 | 3.32 |\n| user-specified prompt | 6.52 | 0.98 | 3.27 | 8.23 | 4.75 |\n| TopAccuracy prompt | 5.75 | 1.13 | 2.76 | 7.56 | 4.30 |\n| BATprompt | 4.57 | 1.57 | 3.14 | 7.98 | 4.32 |\n| ZOPO prompt | 5.12 | 0.87 | 3.23 | 8.28 | 4.38 |\n| **PAFT** | **1.19** | **0.39** | **0.45** | **2.08** | **1.02** |\n| PAFT Improvement | $\\times$3.3 | $\\times$2.23 | $\\times$3.82 | $\\times$3.00 | $\\times$3.25 |", "caption": "Table 2: Comparison of inference time (in hours) for different fine-tuning methods. The base model represents the pre-trained model without fine-tuning, while the other rows show the inference time of models fine-tuned with LoRA using different prompts. PAFT shows better inference efficiency than other methods. The last line shows the multiple of PAFT improvement.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc5d0 \ub300\ud55c \ucd94\ub860 \uc2dc\uac04(\uc2dc\uac04)\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uae30\uc900 \ubaa8\ub378\uc740 \ubbf8\uc138 \uc870\uc815 \uc5c6\uc774 \uc0ac\uc804 \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \ub098\ud0c0\ub0b4\uba70, \ub2e4\ub978 \ud589\uc740 \uc11c\ub85c \ub2e4\ub978 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec LoRA\ub85c \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc758 \ucd94\ub860 \uc2dc\uac04\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. PAFT\ub294 \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \ub354 \ub098\uc740 \ucd94\ub860 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \ud589\uc740 PAFT \uac1c\uc120\uc758 \ubc30\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubbf8\uc138 \uc870\uc815 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub3d9\uc77c\ud55c \uc791\uc5c5\uc5d0 \ub300\ud574 \ubaa8\ub378 \ucd94\ub860 \uc2dc\uac04\uc744 \ube44\uad50 \ubd84\uc11d\ud558\uc5ec PAFT\uc758 \ucd94\ub860 \uc18d\ub3c4 \ud5a5\uc0c1 \ud6a8\uacfc\ub97c \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. Empirical Results"}, {"content": "| # K and T | Hellaswag | PIQA | Winogrande | RACE-mid | RACE-high | Average |\n|---|---|---|---|---|---|---|\n| K = 1, T = 3 | 93.58 (\u00b1 1.47) | 89.33 (\u00b1 0.63) | 81.78 (\u00b1 1.11) | 86.30 (\u00b1 2.73) | 84.35 (\u00b1 2.24) | 87.07 (\u00b1 1.64) |\n| K = 2, T = 3 | 93.59 (\u00b1 1.24) | 88.37 (\u00b1 0.49) | 82.09 (\u00b1 0.81) | 86.30 (\u00b1 2.64) | 84.02 (\u00b1 2.24) | 86.87 (\u00b1 1.48) |\n| K = 4, T = 3 | 93.83 (\u00b1 1.10) | 89.07 (\u00b1 0.53) | 81.96 (\u00b1 1.15) | 87.26 (\u00b1 2.23) | 85.17 (\u00b1 1.71) | 87.46 (\u00b1 1.34) |\n| K = 8, T = 3 | 93.83 (\u00b1 0.70) | 88.99 (\u00b1 0.59) | 82.69 (\u00b1 0.97) | 86.25 (\u00b1 2.75) | 84.36 (\u00b1 2.06) | 87.22 (\u00b1 1.41) |\n| K = 1, T = 6 | 93.37 (\u00b1 1.47) | 88.32 (\u00b1 0.68) | 81.05 (\u00b1 3.44) | 84.40 (\u00b1 2.30) | 83.34 (\u00b1 1.66) | 86.10 (\u00b1 1.91) |", "caption": "Table 3: Performance comparison of PAFT with varying hyperparameters K\ud835\udc3eKitalic_K (number of iterations per prompt) and T\ud835\udc47Titalic_T (number of epochs) across multiple reasoning and reading comprehension tasks. Results are reported as mean accuracy (\u00b1plus-or-minus\\pm\u00b1 standard deviation) on the Hellaswag, PIQA, Winogrande, RACE-mid, and RACE-high datasets. The best results for each metric are highlighted in bold.", "description": "\uc774 \ud45c\ub294 PAFT \ubaa8\ub378\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 K(\ud504\ub86c\ud504\ud2b8\ub2f9 \ubc18\ubcf5 \ud69f\uc218)\uc640 T(\uc5d0\ud3ec\ud06c \uc218)\ub97c \ub2e4\ub974\uac8c \ud558\uc5ec \uc5ec\ub7ec \ucd94\ub860 \ubc0f \ub3c5\ud574 \uc774\ud574 \uacfc\uc81c\uc5d0\uc11c \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Hellaswag, PIQA, Winogrande, RACE-mid, RACE-high \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud3c9\uade0 \uc815\ud655\ub3c4(\ud45c\uc900 \ud3b8\ucc28 \ud3ec\ud568)\ub97c \uc81c\uc2dc\ud558\uba70, \uac01 \uc9c0\ud45c\uc5d0 \ub300\ud55c \ucd5c\uace0 \uc131\ub2a5\uc740 \uad75\uc740 \uae00\uc528\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5\uc758 \uc548\uc815\uc131\uacfc \ucd5c\uc801 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc744 \ud655\uc778\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5.3 Ablation Studies"}, {"content": "| Number of samples | train dataset | validation dataset | test dataset |\n|---|---|---|---| \n| Hellaswag | 39900 | 10000 | 10000 |\n| PIQA | 16000 | 2000 | 3000 |\n| Winogrande | 40398 | 1267 | 1767 |\n| RACE | 87866 | 4887 | 4934 |", "caption": "Table 4: Number of samples in the train, validation, and test datasets for various dateset.", "description": "\ud45c 4\ub294 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b(Hellaswag, PIQA, Winogrande, RACE)\uc5d0 \ub300\ud55c \ud559\uc2b5, \uac80\uc99d \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b\uc758 \uc0d8\ud50c \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \ud559\uc2b5 \ub370\uc774\ud130\uc758 \uc0d8\ud50c \uc218, \uac80\uc99d \ub370\uc774\ud130\uc758 \uc0d8\ud50c \uc218, \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc0d8\ud50c \uc218\uac00 \uba85\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc2e4\ud5d8 \uc124\uc815 \ubd80\ubd84\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "A.1 Dataset"}, {"content": "| Methods | LoRA Target | Max Length | SFT Samples | LR | Training Prompts | Epoch |\n|---|---|---|---|---|---|---|\n| LoRA | q & v Proj | 1024 | 20000 | 0.0001 | 1 | 3 |\n| PAFT | q & v Proj | 1024 | 20000 | 0.0001 | 400 | 3 |", "caption": "Table 5: Detailed experimental parameters. This table lists the specific parameters we used in the experiments for various methods. These parameters include the target module of LoRA (Lora Target), the maximum sequence length (Max Length), the number of samples for supervised fine-tuning (SFT Samples), the learning rate (LR), the number of training prompts (Training Prompts). Epoch(Epoch) represents the epoch of training. All other parameters not listed here remain consistent across all experiments.", "description": "\ud45c 5\ub294 \ubcf8 \ub17c\ubb38\uc758 \uc2e4\ud5d8\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c \ubc29\ubc95\ub4e4\uc5d0 \ub300\ud55c \uc138\ubd80 \uc2e4\ud5d8 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 LoRA\uc758 \ub300\uc0c1 \ubaa8\ub4c8(Lora Target), \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774(Max Length), \uc9c0\ub3c4 \ud559\uc2b5 \ubbf8\uc138 \uc870\uc815\uc744 \uc704\ud55c \uc0d8\ud50c \uc218(SFT Samples), \ud559\uc2b5\ub960(LR), \ud6c8\ub828 \ud504\ub86c\ud504\ud2b8 \uc218(Training Prompts) \ub4f1\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  Epoch\ub294 \ud6c8\ub828 \uc5d0\ud3ec\ud06c \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud45c\uc5d0 \ub098\uc5f4\ub418\uc9c0 \uc54a\uc740 \ub2e4\ub978 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc740 \ubaa8\ub4e0 \uc2e4\ud5d8\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \uc720\uc9c0\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \uc2e4\ud5d8 \uc124\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \uba85\ud655\ud558\uac8c \uc81c\uc2dc\ud558\uc5ec \uc2e4\ud5d8 \uacb0\uacfc\uc758 \uc7ac\ud604\uc131\uacfc \uc2e0\ub8b0\ub3c4\ub97c \ub192\uc774\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "A \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Training time/h | Hellaswag | PIQA | Winogrande | RACE | Average |\n|---|---|---|---|---|---| \n| LoRA + user-specified prompt | 3.01 | 2.35 | 3.27 | 3.95 | 3.15 |\n| LoRA + TopAccuracy prompt | 3.00 | 2.29 | 2.98 | 3.93 | 3.05 |\n| LoRA + BATprompt | 3.02 | 2.23 | 3 | 3.93 | 3.05 |\n| LoRA + ZOPO prompt | 2.97 | 2.3 | 2.97 | 3.83 | 3.02 |\n| PAFT | 2.98 | 2.32 | 3.38 | 3.81 | 3.12 |", "caption": "Table 6: Training Time Comparison of Different Fine-tuning Methods on the Test Prompt Sets Across Various Reasoning and Reading Comprehension Tasks Using the LLaMA3-8BMeta (2024) Model with LoRA Rank 8. Experiments were conducted on an NVIDIA RTX 4090 GPU. Results are reported as training time in hours. LoRA + TopAccuracy prompt  prompt refers to the prompt with the highest accuracy in the training set, LoRA + user-specified prompt Wei et\u00a0al. (2024) refers to fine-tuning with human-designed prompts, LoRA + BATprompt Shi et\u00a0al. (2024) uses the most robust prompt generated by BATprompt, and LoRA + ZOPO prompt Hu et\u00a0al. (2024) employs the optimal prompt selected by ZOPO from the training prompt set.", "description": "\ud45c 6\uc740 LLaMA3-8B(Meta, 2024) \ubaa8\ub378\uacfc LoRA Rank 8\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ucd94\ub860 \ubc0f \ub3c5\ud574 \uc774\ud574 \uacfc\uc81c\uc5d0 \ub300\ud55c \ud14c\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8 \uc9d1\ud569\uc5d0\uc11c \uc5ec\ub7ec \ubbf8\uc138 \uc870\uc815 \ubc29\ubc95\uc758 \ud6c8\ub828 \uc2dc\uac04\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. NVIDIA RTX 4090 GPU\uc5d0\uc11c \uc2e4\ud5d8\uc744 \uc218\ud589\ud588\uc73c\uba70 \uacb0\uacfc\ub294 \uc2dc\uac04(\uc2dc\uac04)\uc73c\ub85c \ubcf4\uace0\ub429\ub2c8\ub2e4. LoRA + TopAccuracy \ud504\ub86c\ud504\ud2b8\ub294 \ud6c8\ub828 \uc138\ud2b8\uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 \uc815\ud655\ub3c4\ub97c \uac00\uc9c4 \ud504\ub86c\ud504\ud2b8\ub97c \ub098\ud0c0\ub0b4\uba70, LoRA + \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ud504\ub86c\ud504\ud2b8(Wei et al., 2024)\ub294 \uc0ac\ub78c\uc774 \ub514\uc790\uc778\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud55c \ubbf8\uc138 \uc870\uc815\uc744 \ub098\ud0c0\ub0b4\uace0, LoRA + BATprompt(Shi et al., 2024)\ub294 BATprompt\ub85c \uc0dd\uc131\ub41c \uac00\uc7a5 \uac15\ub825\ud55c \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uba70, LoRA + ZOPO \ud504\ub86c\ud504\ud2b8(Hu et al., 2024)\ub294 ZOPO\uac00 \ud6c8\ub828 \ud504\ub86c\ud504\ud2b8 \uc138\ud2b8\uc5d0\uc11c \uc120\ud0dd\ud55c \ucd5c\uc801\uc758 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "section": "5 Empirical Results"}, {"content": "| Tokens | Hellaswag | PIQA | Winogrande | RACE | Average |\n|---|---|---|---|---|---| \n| Total Tokens | 11.7k | 12.1k | 10.9k | 12.3k | 11.75k |", "caption": "Table 7: Token Usage for Candidate Prompt Generation. This table shows the number of tokens used to generate approximately 400 candidate prompts for each task. The average token usage is 11.75k. The number of generated prompts can be adjusted based on the scaling law observed in Figure\u00a05 to control costs.", "description": "\ud45c 7\uc740 \ud6c4\ubcf4 \ud504\ub86c\ud504\ud2b8 \uc0dd\uc131\uc744 \uc704\ud574 \uc0ac\uc6a9\ub41c \ud1a0\ud070 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \uacfc\uc81c\uc5d0 \ub300\ud574 \uc57d 400\uac1c\uc758 \ud6c4\ubcf4 \ud504\ub86c\ud504\ud2b8\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uc0ac\uc6a9\ub41c \ud1a0\ud070\uc758 \uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud3c9\uade0 \ud1a0\ud070 \uc0ac\uc6a9\ub7c9\uc740 11.75k\uc785\ub2c8\ub2e4. \uc0dd\uc131\ub41c \ud504\ub86c\ud504\ud2b8\uc758 \uc218\ub294 \ube44\uc6a9\uc744 \uad00\ub9ac\ud558\uae30 \uc704\ud574 \uadf8\ub9bc 5\uc5d0\uc11c \uad00\ucc30\ub41c \uc2a4\ucf00\uc77c\ub9c1 \ubc95\uce59\uc5d0 \ub530\ub77c \uc870\uc815\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc989, \uadf8\ub9bc 5\uc758 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c \uc0dd\uc131\ud560 \ud504\ub86c\ud504\ud2b8\uc758 \uc218\ub97c \uc870\uc808\ud558\uc5ec \ube44\uc6a9\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \uad00\ub9ac\ud560 \uc218 \uc788\ub2e4\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4.", "section": "4.1 Candidate Prompt Construction"}]