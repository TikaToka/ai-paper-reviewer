{"references": [{"fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "publication_date": "2023", "reason": "This paper is a technical report on the Qwen large language model, which is frequently cited in the research and used as a benchmark model in the evaluation of the proposed PAFT framework."}, {"fullname_first_author": "Edward J Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2022", "reason": "This paper introduces the Low-Rank Adaptation (LoRA) technique, a parameter-efficient fine-tuning method that is used extensively in the experiments and compared with the proposed PAFT framework."}, {"fullname_first_author": "Hyung Won Chung", "paper_title": "Scaling instruction-finetuned language models", "publication_date": "2022", "reason": "This paper explores scaling instruction-finetuned language models, providing insights into the training of LLMs for various downstream tasks, and its impact on the prompt robustness which the PAFT framework tries to address."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019", "reason": "This paper introduces BERT, a widely used pre-trained language model that serves as the foundation for many downstream tasks and LLMs, which are used in the related work and experiments of this paper."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022", "reason": "This paper investigates the training of language models to follow instructions using human feedback, providing insights into the supervised fine-tuning techniques used in the PAFT framework and related work."}]}