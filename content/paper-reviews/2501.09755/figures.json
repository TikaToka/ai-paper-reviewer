[{"figure_path": "https://arxiv.org/html/2501.09755/x1.png", "caption": "Figure 1: Our learnings from scaling ViTok. We showcase our ViTok architecture (left) and key findings (right) from scaling auto-encoders for image and video reconstruction and generation. We enhance traditional CNN-based auto-encoders by integrating Vision Transformers (ViTs) with an upgraded Llama architecture into an asymmetric auto-encoder framework forming Vision Transformer Tokenizer or ViTok. Visual inputs are embedded as patches or tubelets, processed by a compact Llama Encoder, and bottlenecked to create a latent code. The encoded representation is then upsampled and handled by a larger Llama Decoder to reconstruct the input. Color-coded text boxes highlight the effects of scaling the encoder, adjusting the bottleneck size, and expanding the decoder. Additionally, we discuss trade-offs in loss optimization and the model\u2019s adaptability to video data. Our best performing ViTok variant achieves competitive performance with prior state-of-the-art tokenizers while reducing computational burden.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c ViTok \uc544\ud0a4\ud14d\ucc98\uc640 \ud06c\uae30 \uc870\uc815\uc5d0 \ub300\ud55c \uc8fc\uc694 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc5d0\ub294 \ube44\ub300\uce6d \uc624\ud1a0\uc778\ucf54\ub354 \ud504\ub808\uc784\uc6cc\ud06c\uc778 ViTok\uc758 \uc544\ud0a4\ud14d\ucc98\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. ViTok\uc740 \uae30\uc874 CNN \uae30\ubc18 \uc624\ud1a0\uc778\ucf54\ub354\ub97c \uac1c\uc120\ud558\uc5ec \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38(ViT)\uc640 \uc5c5\uadf8\ub808\uc774\ub4dc\ub41c Llama \uc544\ud0a4\ud14d\ucc98\ub97c \ud1b5\ud569\ud569\ub2c8\ub2e4. \uc2dc\uac01\uc801 \uc785\ub825\uc740 \ud328\uce58 \ub610\ub294 \ud29c\ube14\ub9bf\uc73c\ub85c \uc784\ubca0\ub529\ub418\uace0, \ucef4\ud329\ud2b8\ud55c Llama \uc778\ucf54\ub354\ub85c \ucc98\ub9ac\ub418\uc5b4 \uc7a0\uc7ac \ucf54\ub4dc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc778\ucf54\ub529\ub41c \ud45c\ud604\uc740 \uc5c5\uc0d8\ud50c\ub9c1\ub418\uc5b4 \ub354 \ud070 Llama \ub514\ucf54\ub354\ub85c \ucc98\ub9ac\ub418\uc5b4 \uc785\ub825\uc744 \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4. \uc624\ub978\ucabd\uc5d0\ub294 \uc778\ucf54\ub354 \ud06c\uae30 \uc870\uc815, \ubcd1\ubaa9 \ud06c\uae30 \uc870\uc815, \ub514\ucf54\ub354 \ud06c\uae30 \uc870\uc815\uc758 \ud6a8\uacfc\ub97c \uac15\uc870\ud558\ub294 \uc0c9\uc0c1 \ucf54\ub4dc\uac00 \ud3ec\ud568\ub41c \ud14d\uc2a4\ud2b8 \uc0c1\uc790\uac00 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc190\uc2e4 \ucd5c\uc801\ud654\uc758 \uc808\ucda9 \ubc0f \ube44\ub514\uc624 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ubaa8\ub378 \uc801\uc751\uc131\uc744 \ub17c\uc758\ud569\ub2c8\ub2e4. \ucd5c\uace0 \uc131\ub2a5\uc758 ViTok \ubcc0\ud615\uc740 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ud1a0\ud070\ud654\uae30\uc640 \ube44\uad50\ud558\uc5ec \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\uba74\uc11c \uacc4\uc0b0 \ubd80\ub2f4\uc744 \uc904\uc785\ub2c8\ub2e4.", "section": "3 Bottlenecks, Scaling, and Trade-offs in Visual Tokenization"}, {"figure_path": "https://arxiv.org/html/2501.09755/x10.png", "caption": "Figure 2: 256p image reconstruction sweep over floating points E\ud835\udc38Eitalic_E. We evaluate ViTok S-B trained with stage 1 (Section\u00a02.3) using combinations of patch sizes p\u22088,16,32\ud835\udc5d81632p\\in{8,16,32}italic_p \u2208 8 , 16 , 32 and channel widths c\u22084,8,16,32,64\ud835\udc5048163264c\\in{4,8,16,32,64}italic_c \u2208 4 , 8 , 16 , 32 , 64 to investigate how the total floating points E=2562p2\u22c5c\ud835\udc38\u22c5superscript2562superscript\ud835\udc5d2\ud835\udc50E=\\frac{256^{2}}{p^{2}}\\cdot citalic_E = divide start_ARG 256 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG \u22c5 italic_c influences FID, IS, SSIM, and PSNR in reconstruction tasks. Our findings reveal a strong correlation between log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and log\u2061(rFID)rFID\\log(\\text{rFID})roman_log ( rFID ), log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rIS, log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rSSIM, as well as log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and rPSNR, independent of the number of FLOPs utilized by the auto-encoder. This indicates that E\ud835\udc38Eitalic_E is the primary bottleneck for reconstruction, irrespective of the code shape or FLOPs expended. Additionally, similar trends are observed across the ImageNet-1K and COCO datasets, indicating that these patterns are consistent regardless of the dataset used.", "description": "\ubcf8 \uadf8\ub9bc\uc740 256\ud53d\uc140 \ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0\uc758 \uc7ac\uad6c\uc131 \uc791\uc5c5\uc5d0\uc11c \ucd1d \ubd80\ub3d9 \uc18c\uc218\uc810 \uc5f0\uc0b0 \uc218(E)\uc758 \uc601\ud5a5\uc744 \uc870\uc0ac\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ViTok S-B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud328\uce58 \ud06c\uae30(p)\uc640 \ucc44\ub110 \uc218(c)\ub97c \ub2e4\uc591\ud558\uac8c \uc870\ud569\ud558\uc5ec E \uac12\uc744 \ubcc0\ud654\uc2dc\ud0a4\uba74\uc11c, \uc7ac\uad6c\uc131 \uc131\ub2a5 \ud3c9\uac00 \uc9c0\ud45c\uc778 FID, IS, SSIM, PSNR\uc758 \ubcc0\ud654\ub97c \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \uc2e4\ud5d8 \uacb0\uacfc, E\uc758 \ub85c\uadf8 \uac12\uacfc \uc7ac\uad6c\uc131 \uc131\ub2a5 \uc9c0\ud45c\ub4e4\uc758 \ub85c\uadf8 \uac12 \uc0ac\uc774\uc5d0 \uac15\ud55c \uc0c1\uad00\uad00\uacc4\uac00 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \uc624\ud1a0\uc778\ucf54\ub354\uac00 \uc0ac\uc6a9\ud558\ub294 FLOPs\uc758 \uc218\uc640\ub294 \ubb34\uad00\ud558\uac8c, E\uac00 \uc7ac\uad6c\uc131 \uc131\ub2a5\uc758 \uc8fc\uc694 \ubcd1\ubaa9 \ud604\uc0c1\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \ub610\ud55c, ImageNet-1K\uc640 COCO \ub370\uc774\ud130\uc14b \ubaa8\ub450\uc5d0\uc11c \uc720\uc0ac\ud55c \uacbd\ud5a5\uc774 \uad00\ucc30\ub418\uc5b4, \uc774\ub7ec\ud55c \ud328\ud134\uc774 \ub370\uc774\ud130\uc14b \uc885\ub958\uc640 \ubb34\uad00\ud558\uac8c \uc77c\uad00\ub428\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4.", "section": "3 Bottlenecks, Scaling, and Trade-offs in Visual Tokenization"}, {"figure_path": "https://arxiv.org/html/2501.09755/x11.png", "caption": "Figure 3:  256p image reconstruction visualization over floating points E\ud835\udc38Eitalic_E. Example reconstructions for varying the number of floating points E\ud835\udc38Eitalic_E values on ViTok S-B/16, achieved by adjusting the channel size c=64,32,16,8,4\ud835\udc5064321684c={64,32,16,8,4}italic_c = 64 , 32 , 16 , 8 , 4 for each image across the row. As E\ud835\udc38Eitalic_E decreases, high-frequency details diminish, with small colors and fine details gradually lost. When E<4096\ud835\udc384096E<4096italic_E < 4096, textures merge, and significant detail loss becomes apparent.", "description": "\uadf8\ub9bc 3\uc740 ViTok S-B/16 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucc44\ub110 \ud06c\uae30(c)\ub97c 64, 32, 16, 8, 4\ub85c \uc870\uc808\ud568\uc73c\ub85c\uc368 \uc5bb\uc740, \ub2e4\uc591\ud55c \ubd80\ub3d9\uc18c\uc218\uc810 E \uac12\uc5d0 \ub530\ub978 256p \uc774\ubbf8\uc9c0 \uc7ac\uad6c\uc131 \uc2dc\uac01\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ucc44\ub110 \ud06c\uae30\uac00 \ub2e4\ub978 \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\uba70, E \uac12\uc774 \uac10\uc18c\ud568\uc5d0 \ub530\ub77c \uace0\uc8fc\ud30c\uc218 \ub514\ud14c\uc77c\uc774 \uc904\uc5b4\ub4e4\uace0 \uc791\uc740 \uc0c9\uc0c1\uacfc \ubbf8\uc138\ud55c \ub514\ud14c\uc77c\uc774 \uc810\ucc28 \uc0ac\ub77c\uc9c0\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. E\uac00 4096\ubcf4\ub2e4 \uc791\uc73c\uba74 \uc9c8\uac10\uc774 \uc11e\uc774\uace0 \ub514\ud14c\uc77c \uc190\uc2e4\uc774 \uc0c1\ub2f9\ud788 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.  \uc989, E \uac12(\uc7a0\uc7ac \uacf5\uac04\uc758 \ucc28\uc6d0)\uc774 \ud074\uc218\ub85d \ub354\uc6b1 \uc815\uad50\ud558\uace0 \uc138\ubc00\ud55c \uc774\ubbf8\uc9c0 \uc7ac\uad6c\uc131\uc774 \uac00\ub2a5\ud558\uc9c0\ub9cc, E \uac12\uc774 \ub108\ubb34 \uc791\uc73c\uba74 \uc774\ubbf8\uc9c0\uc758 \uc911\uc694\ud55c \ub514\ud14c\uc77c\uc774 \uc190\uc2e4\ub418\uc5b4 \uc7ac\uad6c\uc131 \ud488\uc9c8\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1 E as the Main Bottleneck in Image Reconstruction"}, {"figure_path": "https://arxiv.org/html/2501.09755/x12.png", "caption": "Figure 4: 512p Image reconstruction over E\ud835\udc38Eitalic_E. We evaluate ViTok S-B trained with stage 1 (Section\u00a02.3) across all combinations of patch sizes p\u22088,16,32\ud835\udc5d81632p\\in{8,16,32}italic_p \u2208 8 , 16 , 32 and a fixed channel width c=16\ud835\udc5016c=16italic_c = 16, analyzing how the total floating-point operations, calculated as E=5122p2\u22c5c\ud835\udc38\u22c5superscript5122superscript\ud835\udc5d2\ud835\udc50E=\\frac{512^{2}}{p^{2}}\\cdot citalic_E = divide start_ARG 512 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG \u22c5 italic_c, influence reconstruction metrics such as FID, IS, SSIM, and PSNR. E\ud835\udc38Eitalic_E shows trends similar to 256p results (Figure\u00a02). However, achieving comparable rPSNR/rSSIM to 256p requires 4\u00d7E4\ud835\udc384\\times E4 \u00d7 italic_E for 512p reconstruction, which indicates that compression ratio of pixels to channels should be fixed to maintain performance.", "description": "\uadf8\ub9bc 4\ub294 512\ud53d\uc140 \ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc7ac\uad6c\uc131 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ViTok S-B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud328\uce58 \ud06c\uae30(p)\ub97c 8, 16, 32\ub85c \ub2e4\uc591\ud558\uac8c \ubcc0\uacbd\ud558\uba74\uc11c \ucc44\ub110 \ub108\ube44(c)\ub294 16\uc73c\ub85c \uace0\uc815\ud558\uace0 \uc2e4\ud5d8\ud558\uc600\uc2b5\ub2c8\ub2e4.  \ucd1d \ubd80\ub3d9 \uc18c\uc218\uc810 \uc5f0\uc0b0 \ud69f\uc218(E)\ub294 512\u00b2/(p\u00b2) * c \ub85c \uacc4\uc0b0\ub429\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 E\uac00 FID, IS, SSIM, PSNR\uacfc \uac19\uc740 \uc7ac\uad6c\uc131 \uc9c0\ud45c\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4. 256\ud53d\uc140 \ud574\uc0c1\ub3c4 \uacb0\uacfc(\uadf8\ub9bc 2)\uc640 \uc720\uc0ac\ud55c \uacbd\ud5a5\uc744 \ubcf4\uc774\uc9c0\ub9cc, 512\ud53d\uc140 \ud574\uc0c1\ub3c4\uc5d0\uc11c 256\ud53d\uc140 \ud574\uc0c1\ub3c4\uc640 \ub3d9\uc77c\ud55c rPSNR/rSSIM\uc744 \ub2ec\uc131\ud558\ub824\uba74 E \uac12\uc774 4\ubc30 \ud544\uc694\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\ub824\uba74 \ud53d\uc140 \ub300\ube44 \ucc44\ub110 \ube44\uc728\uc744 \uace0\uc815\ud574\uc57c \ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3.1 E as the Main Bottleneck in Image Reconstruction"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/gen_viz_processed/cfg_main_256p.png", "caption": "Figure 5: 256p image generation over E\ud835\udc38Eitalic_E. We evaluate each tokenizer from Figure\u00a02 on DiT following Section\u00a02.3. Results for CFG scales of 1.5 and 3.0 are on the left two and right two plots respectively. Our results show no strong linear correlation between log\u2061(E)\ud835\udc38\\log(E)roman_log ( italic_E ) and generation performance. Instead, a second-order trend reveals an optimal E\ud835\udc38Eitalic_E for each patch size p\ud835\udc5dpitalic_p, indicating a complex interplay between E\ud835\udc38Eitalic_E and c\ud835\udc50citalic_c. This highlights the necessity of optimizing both parameters to balance reconstruction quality with generative capabilities.", "description": "\uadf8\ub9bc 5\ub294 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc7a0\uc7ac \ucf54\ub4dc(E)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc 2\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud1a0\ud06c\ub098\uc774\uc800\ub97c DiT \ubaa8\ub378\uc5d0 \uc801\uc6a9\ud558\uc5ec CFG(classifier-free guidance) \ube44\uc728 1.5\uc640 3.0\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \uac01\uac01 \uc67c\ucabd\uacfc \uc624\ub978\ucabd\uc5d0 \ub098\ud0c0\ub0c8\uc2b5\ub2c8\ub2e4. log(E)\uc640 \uc0dd\uc131 \uc131\ub2a5 \uac04\uc5d0\ub294 \uac15\ud55c \uc120\ud615 \uc0c1\uad00\uad00\uacc4\uac00 \uc5c6\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub300\uc2e0, \uac01 \ud328\uce58 \ud06c\uae30(p)\uc5d0 \ub300\ud574 \ucd5c\uc801\uc758 E \uac12\uc774 \uc874\uc7ac\ud558\ub294 2\ucc28 \ud568\uc218 \ud615\ud0dc\uc758 \uacbd\ud5a5\uc774 \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4. \uc989, E\uc640 \ucc44\ub110 \uc218(c) \uac04\uc758 \ubcf5\uc7a1\ud55c \uc0c1\ud638\uc791\uc6a9\uc774 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc7ac\uad6c\uc131 \ud488\uc9c8\uacfc \uc0dd\uc131 \uc131\ub2a5 \uac04\uc758 \uade0\ud615\uc744 \ub9de\ucd94\ub824\uba74 \ub450 \ub9e4\uac1c\ubcc0\uc218(E\uc640 c)\ub97c \ubaa8\ub450 \ucd5c\uc801\ud654\ud574\uc57c \ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3 Bottlenecks, Scaling, and Trade-offs in Visual Tokenization"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/gen_viz_processed/cfg_main_512p.png", "caption": "Figure 6: Encoder scaling on 256p image reconstruction. We evaluate reconstruction metrics of ViTok trained with stage 1 (Section\u00a02.3) over model sizes S-S, B-S, S-B, B-B, B-L, L-L with fixed p=16,c=16,L=256,E=4096formulae-sequence\ud835\udc5d16formulae-sequence\ud835\udc5016formulae-sequence\ud835\udc3f256\ud835\udc384096p=16,c=16,L=256,E=4096italic_p = 16 , italic_c = 16 , italic_L = 256 , italic_E = 4096. There is no correlation between encoder size and reconstruction performance indicating that scaling the encoder is unhelpful in improving reconstruction capabilities. This argues that visual encoding does not require much computation.", "description": "\uadf8\ub9bc 6\uc740 256p \uc774\ubbf8\uc9c0 \uc7ac\uad6c\uc131\uc5d0 \ub300\ud55c \uc778\ucf54\ub354 \ud06c\uae30 \uc870\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uace0\uc815\ub41c \ud328\uce58 \ud06c\uae30(p=16), \ucc44\ub110 \uc218(c=16), \ud1a0\ud070 \uc218(L=256), \ucd1d \ubd80\ub3d9 \uc18c\uc218\uc810 \uc218(E=4096)\ub97c \uc720\uc9c0\ud55c \ucc44, \uc778\ucf54\ub354 \ud06c\uae30\ub97c S-S, B-S, S-B, B-B, B-L, L-L \ub85c \ubcc0\uacbd\ud558\uba74\uc11c \uc2e4\ud5d8\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4.  \uc2e4\ud5d8 \uacb0\uacfc, \uc778\ucf54\ub354 \ud06c\uae30\uc640 \uc7ac\uad6c\uc131 \uc131\ub2a5 \uac04\uc5d0\ub294 \uc0c1\uad00\uad00\uacc4\uac00 \uc5c6\uc74c\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4. \uc989, \uc778\ucf54\ub354 \ud06c\uae30\ub97c \ud0a4\uc6b4\ub2e4\uace0 \ud574\uc11c \uc7ac\uad6c\uc131 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc558\ub2e4\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4. \uc774\ub294 \uc2dc\uac01\uc801 \uc778\ucf54\ub529\uc5d0 \ub9ce\uc740 \uacc4\uc0b0\uc774 \ud544\uc694\ud558\uc9c0 \uc54a\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3.3 Auto-Encoding \ud06c\uae30 \uc870\uc815 \ucd94\uc138"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figure_videos_1024.png", "caption": "Figure 7: Decoder scaling on 256p image reconstruction. Using the results from Figure\u00a06, we plot various decoder sizes (S, B, L) over reconstruction performance. There is a strong correlation between decoder size and reconstruction performance, which indicates scaling the decoder improves reconstruction. Although, increasing the decoder size from Base to Large does not provide the same boost of performance as doubling E\ud835\udc38Eitalic_E to 8192819281928192 from 4096409640964096.", "description": "\uadf8\ub9bc 7\uc740 256p \uc774\ubbf8\uc9c0 \uc7ac\uad6c\uc131\uc5d0 \ub300\ud55c \ub514\ucf54\ub354 \ud06c\uae30 \uc870\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc 6\uc758 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c, \ub2e4\uc591\ud55c \ub514\ucf54\ub354 \ud06c\uae30(S, B, L)\uc5d0 \ub530\ub978 \uc7ac\uad6c\uc131 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4. \ubd84\uc11d \uacb0\uacfc, \ub514\ucf54\ub354 \ud06c\uae30\uc640 \uc7ac\uad6c\uc131 \uc131\ub2a5 \uac04\uc5d0\ub294 \uac15\ud55c \uc0c1\uad00\uad00\uacc4\uac00 \uc788\uc74c\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4. \uc989, \ub514\ucf54\ub354 \ud06c\uae30\ub97c \ud0a4\uc6b8\uc218\ub85d \uc7ac\uad6c\uc131 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub429\ub2c8\ub2e4. \ud558\uc9c0\ub9cc, \ub514\ucf54\ub354 \ud06c\uae30\ub97c Base\uc5d0\uc11c Large\ub85c \uc99d\uac00\uc2dc\ud0a4\ub294 \uac83\ubcf4\ub2e4 E\ub97c 4096\uc5d0\uc11c 8192\ub85c \ub450 \ubc30 \uc99d\uac00\uc2dc\ud0a4\ub294 \uac83\uc774 \uc7ac\uad6c\uc131 \uc131\ub2a5 \ud5a5\uc0c1\uc5d0 \ub354 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.3 Auto-Encoding \ud06c\uae30 \uc870\uc815 \ucd94\uc138"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figures_videos_512.png", "caption": "Figure 8: Encoder scaling on 256p image generation. We evaluate each tokenizer from Figure\u00a06 on DiT following Section\u00a02.3. We plot encoder size over generation metric results for CFG scales of 1.5 and 3.0 on the left two and right two plots respectively. There is a weak negative correlation between encoder size and final performance indicating that scaling the encoder is harmful for generation results. This is coupled by the fact that increased encoder sizes make training slower due to increased computational overhead.", "description": "\uadf8\ub9bc 8\uc740 256p \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc5d0 \ub300\ud55c \uc778\ucf54\ub354 \ud06c\uae30 \uc870\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc 6\uc758 \uac01 \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc139\uc158 2.3\uc5d0 \ub530\ub77c DiT\uc5d0\uc11c \ud3c9\uac00\ud558\uace0, \uc778\ucf54\ub354 \ud06c\uae30\uc5d0 \ub530\ub978 \uc0dd\uc131 \uc9c0\ud45c \uacb0\uacfc\ub97c CFG \ubc30\uc728 1.5\uc640 3.0\uc5d0 \ub300\ud574 \uac01\uac01 \uc67c\ucabd \ub450 \uadf8\ub798\ud504\uc640 \uc624\ub978\ucabd \ub450 \uadf8\ub798\ud504\uc5d0 \ud45c\uc2dc\ud569\ub2c8\ub2e4. \uc778\ucf54\ub354 \ud06c\uae30\uac00 \ucee4\uc9c8\uc218\ub85d \uc131\ub2a5\uc774 \ub2e4\uc18c \uc800\ud558\ub418\ub294 \uc57d\ud55c \uc74c\uc758 \uc0c1\uad00\uad00\uacc4\uac00 \ub098\ud0c0\ub098\uba70, \uc778\ucf54\ub354 \ud06c\uae30 \uc99d\uac00\ub294 \ud6c8\ub828 \uc18d\ub3c4 \uc800\ud558\ub85c \uc774\uc5b4\uc9d1\ub2c8\ub2e4.", "section": "3.3 Auto-Encoding \ud06c\uae30 \uc870\uc815 \ucd94\uc138"}, {"figure_path": "https://arxiv.org/html/2501.09755/extracted/6134830/figs/gen_figures_videos_256.png", "caption": "Figure 9: Decoder scaling on 256p image generation. Using the results from Figure\u00a06, we plot various decoder sizes (S, B, L) over generation performance. We plot decoder size over generation metric results for CFG scales of 1.5 and 3.0 on the left two and right two plots respectively. Unlike reconstruction, there is no clear correlation between decoder size and generation performance. This indicates that scaling the decoder has minimal benefits overall for auto-encoding.", "description": "\uadf8\ub9bc 9\ub294 256\ud53d\uc140 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc5d0 \ub300\ud55c \ub514\ucf54\ub354 \ud06c\uae30 \uc870\uc815 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc 6\uc758 \uacb0\uacfc\ub97c \ubc14\ud0d5\uc73c\ub85c, \ub2e4\uc591\ud55c \ub514\ucf54\ub354 \ud06c\uae30(S, B, L)\uc5d0 \ub530\ub978 \uc0dd\uc131 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. CFG \ubc30\uc728 1.5\uc640 3.0\uc5d0 \ub300\ud55c \uc0dd\uc131 \uc9c0\ud45c \uacb0\uacfc\ub97c \uc67c\ucabd \ub450 \uadf8\ub798\ud504\uc640 \uc624\ub978\ucabd \ub450 \uadf8\ub798\ud504\uc5d0 \uac01\uac01 \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4. \uc7ac\uad6c\uc131\uacfc \ub2ec\ub9ac, \ub514\ucf54\ub354 \ud06c\uae30\uc640 \uc0dd\uc131 \uc131\ub2a5 \uac04\uc5d0\ub294 \uba85\ud655\ud55c \uc0c1\uad00\uad00\uacc4\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub514\ucf54\ub354 \ud06c\uae30 \uc870\uc815\uc774 \uc790\ub3d9 \uc778\ucf54\ub529\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc774 \ubbf8\ubbf8\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "3.3 Scaling Trends in Auto-Encoding"}]