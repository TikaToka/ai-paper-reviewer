[{"figure_path": "https://arxiv.org/html/2501.00599/x3.png", "caption": "Figure 1: Comparisons with previous general and specialized MLLMs. Our VideoRefer excels in multiple fine-grained regional and temporal video understanding tasks, including basic video object referring, complex video relationship analysis, and video object retrieval.", "description": "\uadf8\ub9bc 1\uc740 \uae30\uc874\uc758 \uc77c\ubc18\uc801\uc778 \ub2e4\uc911 \ubaa8\ub4dc \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(MLLM)\uacfc \ud2b9\uc218\ud654\ub41c MLLM\uacfc \ube44\uad50\ud558\uc5ec VideoRefer\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoRefer\ub294 \uae30\uc874 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc138\ubd84\ud654\ub41c \uc9c0\uc5ed \ubc0f \uc2dc\uac04\uc801 \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc5d0\uc11c \ub6f0\uc5b4\ub09c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 \uae30\ubcf8\uc801\uc778 \ube44\ub514\uc624 \uac1d\uccb4 \ucc38\uc870, \ubcf5\uc7a1\ud55c \ube44\ub514\uc624 \uad00\uacc4 \ubd84\uc11d \ubc0f \ube44\ub514\uc624 \uac1d\uccb4 \uac80\uc0c9 \ub4f1\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.00599/x4.png", "caption": "Figure 2: A multi-agent data engine for the construction of our VideoRefer-700K.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 VideoRefer-700K \ub370\uc774\ud130\uc14b \uad6c\ucd95\uc744 \uc704\ud55c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ub370\uc774\ud130 \uc5d4\uc9c4\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc740 Analyzer(\uba85\uc0ac \ucd94\ucd9c), Annotator(\uac1d\uccb4 \uc218\uc900 \ucea1\uc158 \uc0dd\uc131), Segmentor(\ub9c8\uc2a4\ud06c \uc0dd\uc131), Reviewer(\uc77c\uad00\uc131 \uac80\uc99d), Refiner(\uc694\uc57d \ubc0f \uac1c\uc120)\uc758 \ub2e4\uc12f \uac00\uc9c0 \uad6c\uc131 \uc694\uc18c\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \uad6c\uc131 \uc694\uc18c\ub294 \ube44\ub514\uc624 \ub370\uc774\ud130\uc5d0\uc11c \uac1d\uccb4 \uc218\uc900\uc758 \uc124\uba85\uacfc \ub9c8\uc2a4\ud06c\ub97c \uc0dd\uc131\ud558\uace0, \uc774\ub97c \uac80\uc99d \ubc0f \uac1c\uc120\ud558\uc5ec \uace0\ud488\uc9c8\uc758 \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4dc\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \ub370\uc774\ud130 \uc5d4\uc9c4\uc740 \uc5ec\ub7ec \uc804\ubb38 \ubaa8\ub378\uc744 \ud611\uc5c5\ud558\uc5ec \ub2e4\uc591\ud55c \uac1d\uccb4 \uc218\uc900\uc758 \uc9c0\uce68 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.  \ucd5c\uc885\uc801\uc73c\ub85c \uc0dd\uc131\ub41c VideoRefer-700K\ub294 \uac1d\uccb4 \uc218\uc900\uc758 \uc0c1\uc138\ud55c \uc124\uba85, \uc9e7\uc740 \uc124\uba85, \uadf8\ub9ac\uace0 \ub2e4\uc911 \ub77c\uc6b4\ub4dc \uc9c8\uc758\uc751\ub2f5 \uc30d\uc73c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K Dataset"}, {"figure_path": "https://arxiv.org/html/2501.00599/x5.png", "caption": "Figure 3: Model architecture of our VideoRefer for spatial-temporal video object understanding.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 VideoRefer \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoRefer\ub294 \uc601\uc0c1 \ub0b4\uc758 \ud2b9\uc815 \uac1d\uccb4\uc5d0 \ub300\ud55c \uc815\ud655\ud55c \uacf5\uac04-\uc2dc\uac04\uc801 \uc774\ud574\ub97c \uac00\ub2a5\ud558\uac8c \ud558\ub294 \ube44\ub514\uc624 LLM(\ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378)\uc785\ub2c8\ub2e4.  \uc544\ud0a4\ud14d\ucc98\ub294 \uacf5\uc720\ub41c \uc2dc\uac01\uc801 \uc778\ucf54\ub354, \ub2e4\uc591\ud55c \uc785\ub825(\ub2e8\uc77c \ud504\ub808\uc784 \ubc0f \ub2e4\uc911 \ud504\ub808\uc784)\uc744 \ucc98\ub9ac\ud560 \uc218 \uc788\ub294 \ub2e4\ubaa9\uc801 \uacf5\uac04-\uc2dc\uac04\uc801 \uac1d\uccb4 \uc778\ucf54\ub354(\uacf5\uac04 \ud1a0\ud070 \ucd94\ucd9c\uae30\uc640 \uc2dc\uac04 \ud1a0\ud070 \ubcd1\ud569 \ubaa8\ub4c8 \ud3ec\ud568), \uadf8\ub9ac\uace0 \uc5b8\uc5b4 \ub514\ucf54\ub529\uc744 \uc704\ud55c \uc9c0\uc2dc \uc0ac\ud56d \ub530\ub974\ub294 LLM\uc73c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \ub2e8\uc77c \ud504\ub808\uc784 \ubaa8\ub4dc\uc5d0\uc11c\ub294 \ub2e8\uc77c \ud504\ub808\uc784\uacfc \uc0ac\uc6a9\uc790\uac00 \uc9c0\uc815\ud55c \uc601\uc5ed\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uace0, \ub2e4\uc911 \ud504\ub808\uc784 \ubaa8\ub4dc\uc5d0\uc11c\ub294 \uc5ec\ub7ec \ud504\ub808\uc784\uacfc \ud574\ub2f9 \uc601\uc5ed\uc744 \uc785\ub825\ubc1b\uc544 \uc2dc\uac04\uc801 \ub9e5\ub77d \uc815\ubcf4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud3ec\ucc29\ud569\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c, \uc774 \ubaa8\ub378\uc740 \ub2e8\uc77c \ud504\ub808\uc784 \ubc0f \ub2e4\uc911 \ud504\ub808\uc784 \uac1d\uccb4\uc5d0 \ub300\ud55c \uc815\ud655\ud558\uace0 \ud48d\ubd80\ud55c \ud45c\ud604\uc744 \uc0dd\uc131\ud558\uc5ec \ub2e4\uc591\ud55c \uacf5\uac04-\uc2dc\uac04\uc801 \uc601\uc0c1 \uc774\ud574 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.", "section": "3.2 VideoRefer Model"}, {"figure_path": "https://arxiv.org/html/2501.00599/x6.png", "caption": "Figure 4: Exemplar visual illustration of VideoRefer-Bench.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 VideoRefer-Bench\uc5d0 \ub300\ud55c \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VideoRefer-Bench\ub294 \ube44\ub514\uc624 \uac1d\uccb4\uc5d0 \ub300\ud55c \ucc38\uc870 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud55c \ubca4\uce58\ub9c8\ud06c\uc774\uba70, \uc774 \uadf8\ub9bc\uc740 \ub2e4\ucc28\uc6d0 \ud3c9\uac00\ub97c \ud1b5\ud574 \uc0dd\uc131\ub41c \uc124\uba85\uc758 \ub2e4\uc591\ud55c \uce21\uba74(\uc8fc\uc5b4 \uc77c\uce58, \uc678\ubaa8 \ubb18\uc0ac, \uc2dc\uac04\uc801 \ubb18\uc0ac, \ud658\uac01 \ud0d0\uc9c0)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uce21\uba74\uc740 GPT-40 \ubaa8\ub378\uc744 \uc774\uc6a9\ud558\uc5ec \uc810\uc218\uac00 \ub9e4\uaca8\uc9c0\uba70, \uadf8\ub9bc\uc740 \uc774\ub7ec\ud55c \ud3c9\uac00 \uacfc\uc815\uacfc \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc608\uc2dc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \ube44\ub514\uc624 \ud074\ub9bd\uacfc \ud568\uaed8 \uc0dd\uc131\ub41c \ubb18\uc0ac, \uadf8\ub9ac\uace0 \uac01 \uce21\uba74\uc5d0 \ub300\ud55c \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 VideoRefer-Bench\uc758 \ud3c9\uac00 \ubc29\uc2dd\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3.3 VideoRefer-Bench"}, {"figure_path": "https://arxiv.org/html/2501.00599/x7.png", "caption": "Figure 5: Data characteristics of VideoRefer-Bench.", "description": "Figure 5\ub294 VideoRefer-Bench \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4. (a)\ub294 VideoRefer-Bench\uc5d0 \ud3ec\ud568\ub41c \uce74\ud14c\uace0\ub9ac \ubaa9\ub85d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0ac\ub78c, \ub3d9\ubb3c, \uad50\ud1b5\uc218\ub2e8, \ubb3c\uac74, \ud658\uacbd, \uac00\uad6c \ub4f1 \ub2e4\uc591\ud55c \uc885\ub958\uc758 \uac1d\uccb4\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. (b)\ub294 VideoRefer-Bench\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc9c8\ubb38 \uc720\ud615\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\ubcf8\uc801\uc778 \uc9c8\ubb38, \uc21c\ucc28\uc801\uc778 \uc9c8\ubb38, \uad00\uacc4 \uc9c8\ubb38, \ucd94\ub860 \uc9c8\ubb38, \ubbf8\ub798 \uc608\uce21 \uc9c8\ubb38 \ub4f1 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\ub4e4\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4 \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc9c8\ubb38 \uc720\ud615\ubcc4 \ube44\uc728\uc744 \ud1b5\ud574 \uc5b4\ub5a4 \uc720\ud615\uc758 \uc9c8\ubb38\uc774 \uc5bc\ub9c8\ub098 \ub9ce\uc774 \uc0ac\uc6a9\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 VideoRefer-Bench"}, {"figure_path": "https://arxiv.org/html/2501.00599/x8.png", "caption": "Figure 6: Visual comparisons between our VideoRefer with general GPT-4o and regional video-level Elysium and Artemis. Here we provide detailed illustrations on VideoRefer-BenchDD{}^{\\text{D}}start_FLOATSUPERSCRIPT D end_FLOATSUPERSCRIPT.", "description": "\uadf8\ub9bc 6\uc740 VideoRefer-BenchD\uc5d0\uc11c VideoRefer \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc77c\ubc18\uc801\uc778 GPT-4\uc640 \uc9c0\uc5ed\uc801 \ube44\ub514\uc624 \uc218\uc900\uc758 Elysium \ubc0f Artemis \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  VideoRefer \ubaa8\ub378\uc740 \ub2e8\uc77c \uac1d\uccb4 \ucc38\uc870, \ubcf5\uc7a1\ud55c \ucd94\ub860, \ubbf8\ub798 \uc608\uce21, \ube44\ub514\uc624 \uac1c\uccb4 \uac80\uc0c9 \ubc0f \uc77c\ubc18\uc801\uc778 \ube44\ub514\uc624 \uc774\ud574\uc640 \uac19\uc740 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uac01 \ubaa8\ub378\uc758 \ucd9c\ub825 \uacb0\uacfc\uc640 \ube44\uad50\ud558\uc5ec VideoRefer \ubaa8\ub378\uc758 \uc815\ud655\uc131\uacfc \uc138\ubd80\uc801\uc778 \ubb18\uc0ac \ub2a5\ub825\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.  \uc138 \ubaa8\ub378 \ubaa8\ub450 \uac19\uc740 \ube44\ub514\uc624 \ud074\ub9bd\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uc558\uc9c0\ub9cc, VideoRefer \ubaa8\ub378\uc740 \uac1d\uccb4\uc758 \uc678\uad00, \ub3d9\uc791 \ubc0f \uc8fc\ubcc0 \ud658\uacbd\uc5d0 \ub300\ud55c \ubcf4\ub2e4 \uc815\ud655\ud558\uace0 \ud48d\ubd80\ud55c \uc124\uba85\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "3.3 VideoRefer-Bench"}, {"figure_path": "https://arxiv.org/html/2501.00599/x9.png", "caption": "Figure 7: Visualizations of similarity among adjacent object-level token pairs across the temporal dimension. Here, we use cosine similarity as the measurement.", "description": "\uadf8\ub9bc 7\uc740 \ube44\ub514\uc624\uc758 \uc2dc\uac04\uc801 \ucc28\uc6d0\uc5d0 \uac78\uccd0 \uc778\uc811\ud55c \uac1d\uccb4 \uc218\uc900 \ud1a0\ud070 \uc30d \uac04\uc758 \uc720\uc0ac\uc131\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ube44\ub514\uc624 \ud074\ub9bd\uc758 \uc5ec\ub7ec \ud504\ub808\uc784\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc77c\ub828\uc758 \uc774\ubbf8\uc9c0\uac00 \uc788\uc73c\uba70, \uac01 \ud504\ub808\uc784\ub9c8\ub2e4 \uac1d\uccb4\uc758 \ub9c8\uc2a4\ud06c\uc640 \ud574\ub2f9 \ub9c8\uc2a4\ud06c\uc5d0 \ub300\ud55c \ud1a0\ud070 \ud45c\ud604\uc774 \ud45c\uc2dc\ub429\ub2c8\ub2e4.  \uc778\uc811 \ud504\ub808\uc784\uc758 \ud1a0\ud070 \uc30d \uc0ac\uc774\uc758 \uc720\uc0ac\uc131\uc740 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uce21\uc815\ub418\uba70, \uc5f4 \uc9c0\ub3c4 \ud615\ud0dc\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc720\uc0ac\ub3c4\uc758 \uc815\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc0c9\uc0c1\uc774 \ubc1d\uc744\uc218\ub85d \uc720\uc0ac\ub3c4\uac00 \ub192\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub294 \uc2dc\uac04 \uacbd\uacfc\uc5d0 \ub530\ub978 \uac1d\uccb4 \ud45c\ud604\uc758 \ubcc0\ud654\ub97c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.  \uc608\ub97c \ub4e4\uc5b4, \uac1d\uccb4\uac00 \uc2dc\uac04\uc774 \uc9c0\ub0a8\uc5d0 \ub530\ub77c \uc720\uc0ac\ud55c \ubaa8\uc591\uc744 \uc720\uc9c0\ud558\uba74 \ub192\uc740 \uc720\uc0ac\ub3c4 \uac12\uc744 \uac16\uac8c \ub418\uace0, \ubc18\ub300\ub85c \uac1d\uccb4\uc758 \ubaa8\uc591\uc774 \ud06c\uac8c \ubcc0\ud558\uba74 \ub0ae\uc740 \uc720\uc0ac\ub3c4 \uac12\uc744 \uac16\uac8c \ub429\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc2dc\uac01\ud654\ub294 \ube44\ub514\uc624 \ub0b4\uc758 \uac1d\uccb4 \ucd94\uc801 \ubc0f \uc0c1\ud638 \uc791\uc6a9\uc744 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "3.2.2 A Versatile Spatial-Temporal Object Encoder"}, {"figure_path": "https://arxiv.org/html/2501.00599/x10.png", "caption": "Figure 8: Visual illustrations of the data distribution for each training stage.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 VideoRefer Suite\uc5d0 \ub300\ud55c \uc124\uba85 \uc911 \ub370\uc774\ud130\uc14b \uad6c\uc131 \ubd80\ubd84(3.1 VideoRefer-700K Dataset)\uc5d0 \ud574\ub2f9\ud558\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.  \uac01 \ud6c8\ub828 \ub2e8\uacc4\ubcc4 \ub370\uc774\ud130 \ubd84\ud3ec\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd1d \ub124 \ub2e8\uacc4(Stage 1~3, 2.5)\ub85c \ub098\ub258\uba70, \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uc885\ub958\uc640 \uac1c\uc218\ub97c \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8\ub97c \ud1b5\ud574 \uc124\uba85\ud569\ub2c8\ub2e4. Stage 1\uc740 Image-Text Alignment Pre-training, Stage 2\ub294 Region-Text Alignment Pre-training, Stage 2.5\ub294 High-Quality Knowledge Learning, Stage 3\ub294 Visual Instruction Tuning \ub2e8\uacc4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\ubcc4\ub85c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uc885\ub958\uc640 \uc591\uc744 \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc8fc\uc5b4 VideoRefer \ubaa8\ub378\uc758 \ud6c8\ub828 \uacfc\uc815\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K Dataset"}, {"figure_path": "https://arxiv.org/html/2501.00599/x11.png", "caption": "Figure 9: Data distributions of our VideoRefer-700K dataset, encompassing five different data types.", "description": "\uadf8\ub9bc 9\ub294 VideoRefer-700K \ub370\uc774\ud130\uc14b\uc758 \ub370\uc774\ud130 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ub370\uc774\ud130\uc14b\uc740 \uc9e7\uc740 \uc124\uba85, \uc0c1\uc138 \uc124\uba85, \uadf8\ub9ac\uace0 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\uacfc \ub2f5\ubcc0 \uc30d(QA pairs)\uc744 \ud3ec\ud568\ud55c \ub2e4\uc12f \uac00\uc9c0 \uc720\ud615\uc758 \ub370\uc774\ud130\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130 \uc720\ud615\uc758 \uac1c\uc218\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uc5b4 \ub370\uc774\ud130\uc14b\uc758 \uad6c\uc131\uc744 \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc9e7\uc740 \uc124\uba85 \ub370\uc774\ud130\ub294 \uc601\uc0c1 \uc18d \uac1d\uccb4\uc5d0 \ub300\ud55c \uac04\ub7b5\ud55c \uc124\uba85\uc744 \ud3ec\ud568\ud558\uba70, \uc0c1\uc138 \uc124\uba85 \ub370\uc774\ud130\ub294 \uac1d\uccb4\uc5d0 \ub300\ud55c \ub354\uc6b1 \uc790\uc138\ud558\uace0 \ud48d\ubd80\ud55c \uc124\uba85\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. QA pairs\ub294 \uac1d\uccb4, \uac1d\uccb4 \uac04 \uad00\uacc4, \ub610\ub294 \ubbf8\ub798 \uc608\uce21 \ub4f1\uc5d0 \uad00\ud55c \ub2e4\uc591\ud55c \uc9c8\ubb38\uacfc \ub2f5\ubcc0\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 VideoRefer \ubaa8\ub378\uc758 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \uaddc\ubaa8\uc640 \ub2e4\uc591\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc911\uc694\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K \ub370\uc774\ud130\uc14b"}, {"figure_path": "https://arxiv.org/html/2501.00599/x12.png", "caption": "Figure 10: Visual illustrations of human check process. TP, TN, FP and FN are introduced for the assessment on Reviewer.", "description": "\uadf8\ub9bc 10\uc740 VideoRefer-700K \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c Reviewer\uc758 \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud55c \uc218\ub3d9 \uac80\uc99d \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Reviewer\ub294 \uc0dd\uc131\ub41c \uac1d\uccb4 \uc218\uc900\uc758 \ucea1\uc158\uacfc \ub9c8\uc2a4\ud06c\uc758 \uc815\ud655\uc131\uc744 \uac80\uc99d\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c\ub294 Reviewer\uc758 \uac80\uc99d \uacb0\uacfc\uc5d0 \ub530\ub77c TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative) \ub124 \uac00\uc9c0 \uacbd\uc6b0\ub97c \uc608\uc2dc\ub85c \uc81c\uc2dc\ud558\uc5ec, \uac01\uac01\uc758 \uacbd\uc6b0\uc5d0 \ud574\ub2f9\ud558\ub294 \ube44\uc8fc\uc5bc \ub370\uc774\ud130\uc640 \uc124\uba85\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. TP\ub294 Reviewer\uac00 \uc815\ud655\ud558\uac8c \uc2dd\ubcc4\ud558\uace0 \ud3c9\uac00\ud55c \ud56d\ubaa9\uc774\uace0, TN\uc740 Reviewer\uac00 \uc798\ubabb\ub41c \uac83\uc73c\ub85c \uc815\ud655\ud558\uac8c \uc81c\uac70\ud55c \ud56d\ubaa9\uc785\ub2c8\ub2e4. FP\ub294 Reviewer\uac00 \uc62c\ubc14\ub974\ub2e4\uace0 \ud310\ub2e8\ud588\uc9c0\ub9cc \uc2e4\uc81c\ub85c\ub294 \uc798\ubabb\ub41c \ud56d\ubaa9\uc774\uace0, FN\uc740 Reviewer\uac00 \uc798\ubabb\ub41c \uac83\uc73c\ub85c \ud310\ub2e8\ud588\uc9c0\ub9cc \uc2e4\uc81c\ub85c\ub294 \uc62c\ubc14\ub978 \ud56d\ubaa9\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 Reviewer\uc758 \uc131\ub2a5 \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \uc9c0\ud45c\uc640 \uadf8\uc5d0 \ub530\ub978 \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ud1b5\ud574, \ub370\uc774\ud130 \ud488\uc9c8 \uad00\ub9ac \uacfc\uc815\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub192\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K Dataset"}, {"figure_path": "https://arxiv.org/html/2501.00599/x13.png", "caption": "Figure 11: A detailed illustrative example of the construction pipeline in our multi-agent data engine.", "description": "\uadf8\ub9bc 11\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \ub370\uc774\ud130 \uc5d4\uc9c4\uc758 \uad6c\uc131 \uacfc\uc815\uc744 \uc790\uc138\ud558\uac8c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.  \ub2e8\uacc4\ubcc4\ub85c \uc124\uba85\ud558\uc790\uba74, \uba3c\uc800 \ubd84\uc11d\uae30(Analyzer)\ub97c \ud1b5\ud574 \ube44\ub514\uc624 \ucea1\uc158\uc5d0\uc11c \uba85\uc0ac(\uc8fc\uc5b4)\ub97c \ucd94\ucd9c\ud558\uace0, \uc8fc\uc11d\uae30(Annotator)\ub97c \ud1b5\ud574 \uac1d\uccb4\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc124\uba85(\ub3d9\uc791 \ubc0f \uc678\ud615)\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \ub2e4\uc74c\uc73c\ub85c, \ubd84\ud560\uae30(Segmentor)\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac1d\uccb4\uc5d0 \ub300\ud55c \ud53d\uc140 \ub2e8\uc704 \ub9c8\uc2a4\ud06c\ub97c \uc0dd\uc131\ud558\uace0, \uac80\ud1a0\uc790(Reviewer)\uac00 \ub9c8\uc2a4\ud06c\uc640 \uc124\uba85\uc758 \uc77c\uad00\uc131\uc744 \uac80\uc99d\ud569\ub2c8\ub2e4. \ucd5c\uc885\uc801\uc73c\ub85c, \ub2e4\ub4ec\ub294 \uacfc\uc815(Refiner)\uc744 \ud1b5\ud574 \uc77c\uad00\uc131 \uc788\ub294 \uac1d\uccb4 \uc218\uc900\uc758 \ube44\ub514\uc624 \uc124\uba85 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc911 \uc5d0\uc774\uc804\ud2b8 \uae30\ubc18 \ub370\uc774\ud130 \uc0dd\uc131 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uc0c1\uc138\ud55c \uc608\uc2dc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K Dataset"}, {"figure_path": "https://arxiv.org/html/2501.00599/x14.png", "caption": "Figure 12: Visualization results of VideoRefer across various tasks, including single-object referring, video relationship analysis, complex reasoning, future prediction, video object retrieval, as well as general video understanding and image object understanding.", "description": "\uadf8\ub9bc 12\ub294 VideoRefer \ubaa8\ub378\uc774 \uc218\ud589\ud558\ub294 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0 \ub300\ud55c \uc2dc\uac01\ud654 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 \ub2e8\uc77c \uac1d\uccb4 \uc5b8\uae09, \ube44\ub514\uc624 \uad00\uacc4 \ubd84\uc11d, \ubcf5\uc7a1\ud55c \ucd94\ub860, \ubbf8\ub798 \uc608\uce21, \ube44\ub514\uc624 \uac1d\uccb4 \uac80\uc0c9\ubfd0\ub9cc \uc544\ub2c8\ub77c \uc77c\ubc18\uc801\uc778 \ube44\ub514\uc624 \uc774\ud574 \ubc0f \uc774\ubbf8\uc9c0 \uac1d\uccb4 \uc774\ud574\ub3c4 \ud3ec\ud568\ub429\ub2c8\ub2e4.  \uac01 \uc791\uc5c5 \uc720\ud615\uc5d0 \ub300\ud574 VideoRefer \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uacb0\uacfc\uc758 \uc608\uc2dc \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \uc9c8\ubb38\uacfc \ub2f5\ubcc0\uc774 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 VideoRefer \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \ub2a5\ub825\uacfc \uc815\ud655\ub3c4\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.3 VideoRefer-Bench"}, {"figure_path": "https://arxiv.org/html/2501.00599/x15.png", "caption": "Figure 13: Visual samples from our VideoRefer-700 dataset, typical including short descriptions, detailed descriptions, and QA pairs.", "description": "\uadf8\ub9bc 13\uc740 VideoRefer-700K \ub370\uc774\ud130\uc14b\uc758 \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac04\ub7b5\ud55c \uc124\uba85, \uc790\uc138\ud55c \uc124\uba85, \uadf8\ub9ac\uace0 \uc9c8\ubb38\uacfc \ub2f5\ubcc0(QA) \uc30d\uc744 \ud3ec\ud568\ud558\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ub370\uc774\ud130\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uc608\uc2dc\ub294 \ube44\ub514\uc624 \ud074\ub9bd\uc758 \ud2b9\uc815 \uc601\uc5ed\uc744 \uac00\ub9ac\ud0a4\ub294 \uc9c8\ubb38\uacfc \uadf8\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc744 \ubcf4\uc5ec\uc8fc\uba70, \ube44\ub514\uc624\uc5d0 \ub300\ud55c \ub2e4\uc591\ud55c \uc218\uc900\uc758 \uc774\ud574\ub3c4\ub97c \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc608\uc2dc\ub294 \ub2e8\uc21c\ud55c \uac1d\uccb4 \uc124\uba85\uc5d0\uc11c\ubd80\ud130 \ubcf5\uc7a1\ud55c \uad00\uacc4 \ucd94\ub860, \ubbf8\ub798 \uc608\uce21\uae4c\uc9c0 \ub2e4\uc591\ud55c \uc9c8\ubb38 \uc720\ud615\uc744 \ub2e4\ub8f9\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 VideoRefer \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ube44\ub514\uc624 \uc774\ud574 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1 VideoRefer-700K \ub370\uc774\ud130\uc14b"}, {"figure_path": "https://arxiv.org/html/2501.00599/x16.png", "caption": "Figure 14: Visual examples of our VideoRefer-Bench, including VideoRefer-BenchDD{}^{\\text{D}}start_FLOATSUPERSCRIPT D end_FLOATSUPERSCRIPT and VideoRefer-BenchQQ{}^{\\text{Q}}start_FLOATSUPERSCRIPT Q end_FLOATSUPERSCRIPT.", "description": "\uadf8\ub9bc 14\ub294 VideoRefer-Bench\uc758 \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoRefer-Bench\ub294 \uc124\uba85 \uc0dd\uc131 \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\ub294 VideoRefer-BenchD\uc640 \ub2e4\uc911 \uc120\ud0dd \uc9c8\uc758\uc751\ub2f5 \uc791\uc5c5\uc744 \ud3c9\uac00\ud558\ub294 VideoRefer-BenchQ\uc758 \ub450 \uac00\uc9c0 \ud558\uc704 \ubca4\uce58\ub9c8\ud06c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  VideoRefer-BenchD\ub294 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc608\uc2dc\uc640 \ud568\uaed8 \uac1d\uccb4\uc5d0 \ub300\ud55c \uc138\ubd80\uc801\uc778 \uc124\uba85\uc744 \uc0dd\uc131\ud558\ub294 \ubaa8\ub378\uc758 \ub2a5\ub825\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. VideoRefer-BenchQ\ub294 \ube44\ub514\uc624\uc5d0\uc11c \ub2e4\uc591\ud55c \uac1d\uccb4\uc758 \ud2b9\uc9d5\uacfc \ud589\ub3d9\uc5d0 \ub300\ud55c \uc774\ud574\ub3c4\ub97c \ud3c9\uac00\ud558\ub294 \ub2e4\uc911 \uc120\ud0dd \uc9c8\ubb38\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.  \uac01 \ud558\uc704 \ubca4\uce58\ub9c8\ud06c\ub294 \uc2dc\uac01\uc801 \uc608\uc2dc\uc640 \ud568\uaed8, \ubaa8\ub378\uc774 \uc5b4\ub5bb\uac8c \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\uc5d0 \ub2f5\ubcc0\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ube44\ub514\uc624 \uac1d\uccb4 \ucc38\uc870, \uc2dc\uacc4\uc5f4 \uc774\ud574 \ubc0f \ucd94\ub860\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc774\ud574 \uacfc\uc81c\uc5d0\uc11c VideoRefer \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc885\ud569\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.3 VideoRefer-Bench"}]