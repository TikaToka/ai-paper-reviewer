{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models", "publication_date": "2022-01-01", "reason": "This paper introduced Latent Diffusion Models (LDMs), a foundational architecture for high-quality image generation that is core to the current work."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation", "publication_date": "2023-01-01", "reason": "DreamBooth introduced a method for personalizing text-to-image models, enabling subject-driven generation and establishing a key benchmark for the task."}, {"fullname_first_author": "Alex Nichol", "paper_title": "Glide: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models", "publication_date": "2021-12-21", "reason": "Glide introduced a text-guided diffusion model, laying the groundwork for text-conditioned image editing and generation, highly relevant to the proposed method."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning Transferable Visual Models From Natural Language Supervision", "publication_date": "2021-01-01", "reason": "This paper introduced CLIP, a model that connects images and text, making it possible to condition image generation on natural language prompts."}, {"fullname_first_author": "Daniel Winter", "paper_title": "ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion", "publication_date": "2024-01-01", "reason": "This work enables high-quality background extraction, essential for the object insertion task, and uses a dataset collection technique related to the presented approach."}]}