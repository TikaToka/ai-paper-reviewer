[{"figure_path": "https://arxiv.org/html/2412.08645/x2.png", "caption": "Figure 1: Our method composes objects into scenes with photorealistic pose and lighting, while preserving their identity. The scene can be specified via an image or text. We do not use test-time tuning.", "description": "ObjectMate\ub294 \uac1d\uccb4 \ud569\uc131\uc744 \uc704\ud55c \ud29c\ub2dd \uc5c6\ub294 \uc0c8\ub85c\uc6b4 \ubc29\ubc95\uc785\ub2c8\ub2e4. \uac1d\uccb4 \uc0bd\uc785\uacfc \uc8fc\uc81c \uae30\ubc18 \uc0dd\uc131\uc774\ub77c\ub294 \ub450 \uac00\uc9c0 \ud558\uc704 \uc791\uc5c5\uc744 \ubcd1\ud569\ud569\ub2c8\ub2e4. \uadf8\ub9bc 1\uc740 ObjectMate\uac00 \uc0ac\uc9c4\ucc98\ub7fc \uc0ac\uc2e4\uc801\uc778 \ud3ec\uc988\uc640 \uc870\uba85\uc73c\ub85c \uc7a5\uba74\uc5d0 \uac1d\uccb4\ub97c \ud569\uc131\ud558\uba74\uc11c \uac1d\uccb4\uc758 \uc815\uccb4\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc7a5\uba74\uc740 \uc774\ubbf8\uc9c0\ub098 \ud14d\uc2a4\ud2b8\ub97c \ud1b5\ud574 \uc9c0\uc815\ud560 \uc218 \uc788\uc73c\uba70 \ud14c\uc2a4\ud2b8 \uc2dc\uc810 \ud29c\ub2dd\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. ObjectMate\ub294 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \ubc30\uacbd \uc774\ubbf8\uc9c0\uc758 \uc870\uba85, \ud3ec\uc988, \uad6c\uc131\uc744 \uc870\ud654\uc2dc\ud0a4\ub294 \ub370 \ud0c1\uc6d4\ud569\ub2c8\ub2e4.", "section": "\uc18c\uac1c"}, {"figure_path": "https://arxiv.org/html/2412.08645/x3.png", "caption": "Figure 2: Retrieval feature comparison. Retrieval with DINO features (right) produces semantic matches, while instance retrieval features [51] (middle) find identical objects.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc11c\ub85c \ub2e4\ub978 \ud2b9\uc9d5 \ucd94\ucd9c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc774\ubbf8\uc9c0 \uac80\uc0c9 \uacb0\uacfc\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. \uc624\ub978\ucabd\uc758 DINO \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud55c \uac80\uc0c9\uc740 \uc758\ubbf8\uc801\uc73c\ub85c \uc720\uc0ac\ud55c \uac1d\uccb4\ub4e4\uc744 \ucc3e\uc544\ub0b4\uc9c0\ub9cc(\uc608: \ucd95\uad6c\uacf5, \ub18d\uad6c\uacf5), \uac00\uc6b4\ub370\uc758 \uc778\uc2a4\ud134\uc2a4 \uac80\uc0c9(IR) \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud55c \uac80\uc0c9\uc740 \ub3d9\uc77c\ud55c \uac1d\uccb4\uc758 \ub2e4\ub978 \uc774\ubbf8\uc9c0\ub4e4\uc744 \ucc3e\uc544\ub0c5\ub2c8\ub2e4. \uc989, IR \ud2b9\uc9d5\uc740 \uac1d\uccb4\uc758 \uc885\ub958\uac00 \uc544\ub2cc \uac1d\uccb4\uc758 \uac1c\ubcc4\uc801\uc778 identity\ub97c \uad6c\ubd84\ud558\uc5ec \uac80\uc0c9\ud569\ub2c8\ub2e4. \ub17c\ubb38\uc5d0\uc11c\ub294 \uac1d\uccb4 \uc0bd\uc785 \uacfc\uc81c\uc5d0\uc11c identity \ubcf4\uc874\uc744 \uc704\ud574 IR \ud2b9\uc9d5\uc774 \uc911\uc694\ud558\ub2e4\uace0 \uc8fc\uc7a5\ud569\ub2c8\ub2e4.", "section": "4. The object recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x4.png", "caption": "(a)", "description": "(a) \uac80\uc0c9 \uc815\ubc00\ub3c4 \ub300 \uc720\uc0ac\uc131 \uc784\uacc4\uac12. 0.93\uc758 \uc784\uacc4\uac12\uc740 70%\uc758 \uc815\ubc00\ub3c4\ub97c \uc0b0\ucd9c\ud569\ub2c8\ub2e4. \uac80\uc0c9 \uc815\ubc00\ub3c4\ub294 \uac80\uc0c9\ub41c \uc774\uc6c3 \uc911 \uc2e4\uc81c\ub85c \ub3d9\uc77c\ud55c \uac1d\uccb4\uc778 \uc774\uc6c3\uc758 \ube44\uc728\uc785\ub2c8\ub2e4. \uc720\uc0ac\ub3c4 \uc810\uc218\ub294 \uac1d\uccb4\uc758 IR \uc784\ubca0\ub529 \uac04\uc758 \ucf54\uc0ac\uc778 \uc720\uc0ac\ub3c4\uc785\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 0.93\uc758 \uc784\uacc4\uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac80\uc0c9\ub41c \uac1d\uccb4\uc640 \uc8fc\uc5b4\uc9c4 \uac1d\uccb4 \uc0ac\uc774\uc758 \ucd5c\uc18c \uc720\uc0ac\ub3c4\ub97c \ubcf4\uc7a5\ud569\ub2c8\ub2e4. 0.93\ubcf4\ub2e4 \ub0ae\uc740 \uac12\uc740 \uc77c\ubc18\uc801\uc73c\ub85c \uc11c\ub85c \ub2e4\ub978 \uac1d\uccb4\ub97c \ub098\ud0c0\ub0b4\ub294 \ubc18\uba74, 0.975\ubcf4\ub2e4 \ub192\uc740 \uac12\uc740 \uc885\uc885 \uac70\uc758 \uc911\ubcf5\ub41c \uac1d\uccb4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc720\uc0ac\ub3c4 \uac12\uc774 0.93\uc5d0\uc11c 0.975 \uc0ac\uc774\uc778 \uac1d\uccb4 \uc30d\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4.", "section": "4. \uac1d\uccb4 \ubc18\ubcf5 \uc0ac\uc804"}, {"figure_path": "https://arxiv.org/html/2412.08645/x5.png", "caption": "(b)", "description": "\uc774 \uadf8\ub9bc\uc740 \uac1d\uccb4\uc640 \uadf8 3\uac1c\uc758 \ucd5c\uadfc\uc811 \uc774\uc6c3 \uac04\uc758 \uc720\uc0ac\uc131 \uc810\uc218 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\uace0, \ubc94\ub840\ub294 [0.93, 0.975] \ubc94\uc704 \ub0b4\uc5d0 \uc788\ub294 \uac1d\uccb4\uc758 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 WebLI, COCO, Open Images \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac80\uc0c9\ub41c \uac1d\uccb4\ub4e4\uc5d0 \ub300\ud55c \uc720\uc0ac\uc131 \uc810\uc218 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \uac1d\uccb4\uac00 \ub192\uc740 \uc720\uc0ac\uc131 \uc810\uc218\ub97c \uac00\uc9c0\uace0 \uc788\uc5b4 \uac1d\uccb4 \ubc18\ubcf5 \uc0ac\uc804\uc758 \ud0c0\ub2f9\uc131\uc744 \ub4b7\ubc1b\uce68\ud569\ub2c8\ub2e4. \uc989, \ub9ce\uc740 \uc77c\uc0c1\uc801\uc778 \uac1d\uccb4\ub4e4\uc774 \ub2e4\uc591\ud55c \uc7a5\uba74, \ud3ec\uc988, \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ub300\uaddc\ubaa8 \uc778\ud130\ub137 \uae30\ubc18 \ub370\uc774\ud130\uc14b\uc5d0 \uac78\uccd0 \ubc18\ubcf5\uc801\uc73c\ub85c \ub098\ud0c0\ub0a9\ub2c8\ub2e4.", "section": "4. The object recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x6.png", "caption": "(c)", "description": "WebLI \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc7ac\ubc1c\uc0dd \uac1d\uccb4\uc758 \ube44\uc728\ub3c4 \ucd08\uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \ub370\uc774\ud130\uc14b \ud06c\uae30\uac00 \ud074\uc218\ub85d \uac1d\uccb4 \uc7ac\ubc1c\uc0dd \ube44\uc728\uc774 \ub192\uc544\uc9c4\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4. \uac1d\uccb4 \uc7ac\ubc1c\uc0dd \uc0ac\uc804"}, {"figure_path": "https://arxiv.org/html/2412.08645/x7.png", "caption": "Figure 3: Object recurrence analysis: (a) Retrieval precision vs. similarity threshold. A threshold of 0.930.930.930.93 yields 70%percent70~{}70\\%70 % precision. (b) Similarity score distribution for 3 datasets between an object and its 3 nearest neighbors. The legend shows the percentage of objects within the range of [0.93,0.975]0.930.975[0.93,0.975][ 0.93 , 0.975 ]. (c) The percentage of objects in this range grows super-linearly as we use larger subsets of WebLI.", "description": "\uc774 \uadf8\ub9bc\uc740 \uac1d\uccb4 \ubc18\ubcf5 \ubc1c\uc0dd \uc0ac\uc804\uc5d0 \ub300\ud55c \ubd84\uc11d\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc720\uc0ac\ub3c4 \uc784\uacc4\uac12\uc5d0 \ub530\ub978 \uac80\uc0c9 \uc815\ubc00\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc784\uacc4\uac12 0.93\uc5d0\uc11c \uc815\ubc00\ub3c4 70%\ub97c \ub2ec\uc131\ud569\ub2c8\ub2e4. (b)\ub294 3\uac1c\uc758 \ub370\uc774\ud130\uc14b(COCO, Open Images, WebLI)\uc5d0\uc11c \uac1d\uccb4\uc640 3\uac1c\uc758 \ucd5c\uadfc\uc811 \uc774\uc6c3 \uac04\uc758 \uc720\uc0ac\ub3c4 \uc810\uc218 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\uba70, \ubc94\ub840\ub294 [0.93, 0.975] \ubc94\uc704 \ub0b4 \uac1d\uccb4\uc758 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. (c)\ub294 WebLI\uc758 \uc11c\ube0c\uc14b \ud06c\uae30\uac00 \ucee4\uc9d0\uc5d0 \ub530\ub77c \uc774 \ubc94\uc704 \ub0b4 \uac1d\uccb4\uc758 \ube44\uc728\uc774 \ucd08\uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30\uac00 \ud074\uc218\ub85d \ub3d9\uc77c\ud55c \uac1d\uccb4\uc758 \ub2e4\uc591\ud55c \ubcf4\uae30\ub97c \ub354 \ub9ce\uc774 \ucc3e\uc744 \uc218 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4. The object recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x8.png", "caption": "Figure 4: Recurring mass-produced objects. Percentage of instances within classes of everyday objects with at least 3 retrieved recurrences in WebLI.", "description": "\uc774 \uadf8\ub9bc\uc740 WebLI \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ucd5c\uc18c 3\ubc88 \uc774\uc0c1 \uac80\uc0c9\ub41c \uc77c\uc0c1\uc801\uc778 \ubb3c\uccb4\ub4e4\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub0c9\uc7a5\uace0, \ube44\ud589\uae30, \ub18d\uad6c\uacf5, \ucd95\uad6c\uacf5, \ucc9c\uc7a5 \uc120\ud48d\uae30, \ud5ec\uba67, \uc790\ub3d9\ucc28, \uc624\ud1a0\ubc14\uc774, \ud48d\uc120, \uc640\uc778 \uc794, \ub178\ud2b8\ubd81, \ub9c8\uc2a4\ud06c\uc640 \uac19\uc740 \ub300\ub7c9 \uc0dd\uc0b0\ub418\ub294 \ubb3c\uccb4\ub4e4\uc774 \ub192\uc740 \uc7ac\ubc1c\uc0dd\ub960\uc744 \ubcf4\uc774\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc774\ub7ec\ud55c \ubb3c\uccb4\ub4e4\uc774 \ub2e4\uc591\ud55c \uc7a5\uba74, \ud3ec\uc988, \uc870\uba85 \uc870\uac74\uc5d0\uc11c \uc5ec\ub7ec \uc774\ubbf8\uc9c0\uc5d0 \uac78\uccd0 \ubc18\ubcf5\uc801\uc73c\ub85c \ub098\ud0c0\ub098\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uba70, \uc774\ub7ec\ud55c \ud2b9\uc9d5\uc744 \uac1d\uccb4 \uc7ac\ubc1c\uc0dd \uc0ac\uc804 \uc9c0\uc2dd\uc73c\ub85c \ud65c\uc6a9\ud558\uc5ec \uac1d\uccb4 \uc0bd\uc785 \ubc0f \uc8fc\uccb4 \uae30\ubc18 \uc0dd\uc131\uc744 \uc704\ud55c \ub300\uaddc\ubaa8 \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. The object recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x9.png", "caption": "Figure 5: Creating a supervised dataset. For each unlabeled image, we detect and crop objects with high detection confidence. Next, we extract the kNN of these objects based on IR feature similarity. To generate the background image, we apply an object removal model.", "description": "\ub300\uaddc\ubaa8 \ub808\uc774\ube14\uc774 \uc5c6\ub294 \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac1d\uccb4 \uac10\uc9c0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub192\uc740 \uc2e0\ub8b0\ub3c4\ub85c \uac10\uc9c0\ub41c \uac1d\uccb4\ub4e4\uc744 \uc798\ub77c\ub0c5\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c, \uc778\uc2a4\ud134\uc2a4 \uac80\uc0c9(IR) \ud2b9\uc9d5 \uc720\uc0ac\ub3c4\ub97c \uae30\ubc18\uc73c\ub85c kNN\uc744 \ucd94\ucd9c\ud558\uace0, \uac1d\uccb4 \uc81c\uac70 \ubaa8\ub378\uc744 \uc801\uc6a9\ud558\uc5ec \ubc30\uacbd \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacfc\uc815\uc744 \ud1b5\ud574 \uc9c0\ub3c4 \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc744 \uad6c\ucd95\ud569\ub2c8\ub2e4.", "section": "5. ObjectMate: Leveraging object recurrence"}, {"figure_path": "https://arxiv.org/html/2412.08645/x10.png", "caption": "Figure 6: Architecture. We use an unmodified standard UNet. The input is a 2\u00d72222\\times 22 \u00d7 2 grid of 3 reference images and a noisy target image. We calculate the loss only for the target image pixels. In object insertion, we concatenate the mask and background along the channel axis.", "description": "ObjectMate\ub294 \uc218\uc815\ub418\uc9c0 \uc54a\uc740 \ud45c\uc900 UNet \uc544\ud0a4\ud14d\ucc98\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc785\ub825\uc740 3\uac1c\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \ub178\uc774\uc988\uac00 \uc788\ub294 \ub300\uc0c1 \uc774\ubbf8\uc9c0\ub85c \uad6c\uc131\ub41c 2x2 \uadf8\ub9ac\ub4dc\uc785\ub2c8\ub2e4. \uc190\uc2e4\uc740 \ub300\uc0c1 \uc774\ubbf8\uc9c0 \ud53d\uc140\uc5d0 \ub300\ud574\uc11c\ub9cc \uacc4\uc0b0\ub429\ub2c8\ub2e4. \uac1d\uccb4 \uc0bd\uc785\uc758 \uacbd\uc6b0 \ub9c8\uc2a4\ud06c\uc640 \ubc30\uacbd\uc744 \ucc44\ub110 \ucd95\uc744 \ub530\ub77c \uc5f0\uacb0\ud569\ub2c8\ub2e4. \ub2e4\uc2dc \ub9d0\ud574, \uc774\ubbf8\uc9c0 \ud569\uc131\uc744 \uc704\ud55c ObjectMate\uc758 \uc544\ud0a4\ud14d\ucc98\ub294 2x2 \uc785\ub825 \uadf8\ub9ac\ub4dc\uac00 \uc788\ub294 UNet\uc73c\ub85c \uad6c\uc131\ub418\uba70, \uc5ec\uae30\uc11c 3\uac1c\uc758 \uc140\uc5d0\ub294 \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 \ud3ec\ud568\ub418\uace0 \ub098\uba38\uc9c0 \uc140\uc5d0\ub294 \ub178\uc774\uc988\uac00 \uc788\ub294 \ub300\uc0c1 \uc774\ubbf8\uc9c0\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc190\uc2e4 \ud568\uc218\ub294 \ub300\uc0c1 \uc774\ubbf8\uc9c0\uc758 \ud53d\uc140 \uac12\uacfc \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \ud53d\uc140 \uac12 \ucc28\uc774\ub97c \uacc4\uc0b0\ud558\ub294 L2 \uc190\uc2e4\uc785\ub2c8\ub2e4. \uac1d\uccb4 \uc0bd\uc785 \uc791\uc5c5\uc758 \uacbd\uc6b0, \uc7a5\uba74 \uc124\uba85 S\uc5d0\ub294 \ubc30\uacbd \uc774\ubbf8\uc9c0\uc640 \ub9c8\uc2a4\ud06c\uac00 \ud3ec\ud568\ub429\ub2c8\ub2e4. \ubc30\uacbd \uc774\ubbf8\uc9c0\ub294 \uac1d\uccb4\uac00 \uc81c\uac70\ub41c \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc774\uace0, \ub9c8\uc2a4\ud06c\ub294 \uc0bd\uc785\ub420 \uac1d\uccb4\uc758 \uc704\uce58\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc785\ub825\uc740 \ub178\uc774\uc988\uac00 \uc788\ub294 \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 UNet\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4.", "section": "5.2. Training"}, {"figure_path": "https://arxiv.org/html/2412.08645/x11.png", "caption": "Figure 7: Object insertion results. Our method better harmonizes the pose and lighting with the scene while preserving object identity.", "description": "ObjectMate \uac1d\uccb4 \uc0bd\uc785 \uacb0\uacfc\ub294 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \uac1d\uccb4\ub97c \ub2e4\uc591\ud55c \ubc30\uacbd\uc5d0 \ud569\uc131\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  ObjectMate\ub294 \uac1d\uccb4\uc758 \uace0\uc720\ud55c \ud2b9\uc9d5(\uc608: \ubaa8\uc591, \uc0c9\uc0c1)\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ubc30\uacbd\uc758 \uc870\uba85\uacfc \ud3ec\uc988\uc5d0 \ub9de\ucdb0 \uc790\uc5f0\uc2a4\ub7fd\uac8c \ud569\uc131\ud569\ub2c8\ub2e4. \ube44\uad50 \ubaa8\ub378\ub4e4(PbE, ObjectStich, AnyDoor)\uc740 \uac1d\uccb4\uc758 \ud2b9\uc9d5\uc744 \uc720\uc9c0\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uac70\ub098, \ubc30\uacbd\uacfc\uc758 \uc870\ud654\uac00 \ubd80\uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 ObjectMate\ub294 \uc5ec\ub7ec \uc7a5\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0(3 Refs)\ub97c \uc0ac\uc6a9\ud560 \uacbd\uc6b0 \ub354\uc6b1 \uc815\ud655\ud558\uace0 \uc0ac\uc2e4\uc801\uc778 \ud569\uc131 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \uc5f4\uc758 \"Ground Truth\"\ub294 \uc0ac\uc9c4 \ucd2c\uc601\uc744 \ud1b5\ud574 \uc9c1\uc811 \ub9cc\ub4e0 \uc2e4\uc81c \ud569\uc131 \uc774\ubbf8\uc9c0\ub85c, ObjectMate \uacb0\uacfc\uc758 \uc0ac\uc2e4\uc131\uc744 \uc785\uc99d\ud569\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8 (6. Experiments)"}, {"figure_path": "https://arxiv.org/html/2412.08645/x12.png", "caption": "Figure 8: Subject-driven generation results. ObjectMate can composite the object into the scene given 3 reference views and a prompt describing the scene. Our method does not require test-time tuning.", "description": "ObjectMate\ub294 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 3\uac1c\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac1d\uccb4\ub97c \uc0c8\ub85c\uc6b4 \uc7a5\uba74\uc5d0 \ud569\uc131\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \"\ubc00\ubc2d\uc744 \ubc30\uacbd\uc73c\ub85c \ud55c \uc624\ub9ac \uc778\ud615\", \"\uc790\uac08\uae38 \uc704\uc758 \uc624\ub9ac \uc778\ud615\", \"\uc232 \uc18d \ubcf4\ub77c\uc0c9 \uae54\uac1c \uc704\uc758 \uc624\ub9ac \uc778\ud615\", \"\ubb3c \uc704\uc5d0 \ub5a0 \uc788\ub294 \uc624\ub9ac \uc778\ud615\", \"\uc815\uae00 \uc18d \uc624\ub9ac \uc778\ud615\"\uacfc \uac19\uc740 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc624\ub9ac \uc778\ud615\uc744 \ub2e4\uc591\ud55c \uc7a5\uba74\uc5d0 \ud569\uc131\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ObjectMate\ub294 \ud14c\uc2a4\ud2b8 \ud0c0\uc784 \ud29c\ub2dd \uc5c6\uc774\ub3c4 \uace0\ud488\uc9c8\uc758 \uacb0\uacfc\ubb3c\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "6.3. Subject-driven generation"}, {"figure_path": "https://arxiv.org/html/2412.08645/x13.png", "caption": "Figure 9: Open features and data. Using data based on IR features outperforms CLIP and DINO. Public datasets and feature encoders achieve strong performance.", "description": "\uc774 \uadf8\ub9bc\uc740 ObjectMate \ubaa8\ub378\uc774 \uacf5\uac1c\uc801\uc73c\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub370\uc774\ud130\uc14b\uacfc \ud2b9\uc9d5 \ucd94\ucd9c\uae30\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ub418\uc5c8\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IR \ud2b9\uc9d5\uc744 \uae30\ubc18\uc73c\ub85c \ud55c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacb0\uacfc, CLIP \ubc0f DINO\ub97c \uc0ac\uc6a9\ud55c \uac83\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uacf5\uac1c\uc801\uc73c\ub85c \uc774\uc6a9 \uac00\ub2a5\ud55c \ub370\uc774\ud130\uc14b\uacfc \ud2b9\uc9d5 \ucd94\ucd9c\uae30\ub97c \uc0ac\uc6a9\ud558\ub354\ub77c\ub3c4 \uac15\ub825\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "6.4. Ablation study"}, {"figure_path": "https://arxiv.org/html/2412.08645/x14.png", "caption": "Figure 10: Effect of dataset size on object insertion metrics. Larger unsupervised datasets yield better results.", "description": "\uc774 \uadf8\ub798\ud504\ub294 \ube44\uc9c0\ub3c4 \ud559\uc2b5 \ub370\uc774\ud130\uc14b \ud06c\uae30\uac00 \uac1d\uccb4 \uc0bd\uc785 \uba54\ud2b8\ub9ad\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac1d\uccb4\uc758 ID \ubcf4\uc874\uacfc \ud569\uc131\uc758 \uc0ac\uc2e4\uc131 \ubaa8\ub450 \ub370\uc774\ud130\uc14b \ud06c\uae30\uac00 \ucee4\uc9d0\uc5d0 \ub530\ub77c \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 WebLI\uc640 \uac19\uc774 \uc218\uc2ed\uc5b5 \uac1c\uc758 \uc774\ubbf8\uc9c0\ub97c \ud3ec\ud568\ud558\ub294 \ub300\uaddc\ubaa8 \ub370\uc774\ud130\uc14b\uc740 \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub97c \uac00\uc838\uc635\ub2c8\ub2e4. \uc774\ub294 \uac1d\uccb4 \ubc18\ubcf5 \uc0ac\uc804\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc73c\ub85c, \ub354 \ud070 \ub370\uc774\ud130\uc14b\uc5d0\ub294 \ub354 \ub2e4\uc591\ud55c \uc7a5\uba74, \ud3ec\uc988, \uc870\uba85 \uc870\uac74\uc5d0\uc11c \ub3d9\uc77c\ud55c \uac1d\uccb4\uc758 \uc5ec\ub7ec \ubdf0\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.08645/x15.png", "caption": "Figure 11: Subject-driven generation model\u2019s architecture.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc8fc\uc81c \uae30\ubc18 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8 \uc778\ucf54\ub354\ub294 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \ucc98\ub9ac\ud558\uace0 \uad50\ucc28 \uc8fc\uc758 \ub808\uc774\uc5b4\ub97c \ud1b5\ud574 UNet \uc544\ud0a4\ud14d\ucc98\uc5d0 \ud1b5\ud569\ud569\ub2c8\ub2e4. UNet\uc740 \ub178\uc774\uc988\uac00 \uc788\ub294 \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \ub178\uc774\uc988 \uc81c\uac70\ub41c \ub300\uc0c1 \uc774\ubbf8\uc9c0\ub97c \ucd9c\ub825\ud569\ub2c8\ub2e4. \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ucc38\uc870 \uc774\ubbf8\uc9c0\ub294 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.", "section": "A. Implementation details"}, {"figure_path": "https://arxiv.org/html/2412.08645/x16.png", "caption": "Figure 12: A screenshot of the user study questionnaire.", "description": "\uc0ac\uc6a9\uc790 \uc5f0\uad6c \uc124\ubb38\uc9c0\uc758 \uc2a4\ud06c\ub9b0\uc0f7\uc785\ub2c8\ub2e4. \ucc38\uac00\uc790\uc5d0\uac8c\ub294 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \ud504\ub86c\ud504\ud2b8\uac00 \uc8fc\uc5b4\uc9c0\uba70, \ub450 \uc774\ubbf8\uc9c0 \uc911 \uc5b4\ub5a4 \uc774\ubbf8\uc9c0\uac00 \ucc38\uc870\uc640 \ub354 \uc720\uc0ac\ud558\uace0 \ud504\ub86c\ud504\ud2b8\uc640 \ub354 \uc77c\uce58\ud558\ub294\uc9c0 \uc9c8\ubb38\ud569\ub2c8\ub2e4.", "section": "C. User study"}, {"figure_path": "https://arxiv.org/html/2412.08645/x17.png", "caption": "Figure 13: Example of a quadruplet from out test set. From each quadruplet we extract 4 samples, where one object is used as the ground truth and the remaining 3 serve as the reference condition.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \uac1d\uccb4 \uc0bd\uc785 \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4. 4\uac1c\uc758 \uc774\ubbf8\uc9c0\ub85c \uad6c\uc131\ub41c \ucffc\ub4dc\ud50c\ub81b\uc5d0\uc11c \ud558\ub098\uc758 \uc774\ubbf8\uc9c0\ub294 \uc815\ub2f5 \uc774\ubbf8\uc9c0(ground truth)\ub85c \uc0ac\uc6a9\ub418\uace0, \ub098\uba38\uc9c0 3\uac1c\uc758 \uc774\ubbf8\uc9c0\ub294 \ucc38\uc870 \uc774\ubbf8\uc9c0(reference images)\ub85c \ud65c\uc6a9\ub429\ub2c8\ub2e4. \uc815\ub2f5 \uc774\ubbf8\uc9c0\ub294 \uac1d\uccb4\uac00 \ubc30\uacbd\uc5d0 \ud569\uc131\ub41c \ucd5c\uc885 \uacb0\uacfc\ubb3c\uc774\uba70, \ucc38\uc870 \uc774\ubbf8\uc9c0\ub294 \ud569\uc131\ud560 \uac1d\uccb4\uc758 \ub2e4\uc591\ud55c \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uad6c\uc131\uc744 \ud1b5\ud574 \uac1d\uccb4 \uc0bd\uc785 \ubaa8\ub378\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uae30\ubc18\uc73c\ub85c \ub2e4\uc591\ud55c \ubc30\uacbd\uc5d0 \uac1d\uccb4\ub97c \uc0ac\uc2e4\uc801\uc73c\ub85c \ud569\uc131\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.1. Dataset creation with the recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x18.png", "caption": "Figure 14: Ablation study on the importance of IR features for object insertion. Using CLIP or DINO features for instance retrieval during object insertion training is insufficient to achieve identity preservation. Using specialized instance-retrieval (IR) features achieve much stronger results. In addition, the publicly available IR model from [51] is comparable to our internal model.", "description": "\uac1d\uccb4 \uc0bd\uc785 \uc791\uc5c5\uc5d0\uc11c \uc778\uc2a4\ud134\uc2a4 \uac80\uc0c9(IR) \uae30\ub2a5\uc758 \uc911\uc694\uc131\uc5d0 \ub300\ud55c \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. CLIP \ub610\ub294 DINO \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0 \uac1d\uccb4 ID\ub97c \uc720\uc9c0\ud558\uae30 \uc5b4\ub835\uc9c0\ub9cc \ud2b9\uc218\ud654\ub41c IR \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\uba74 \ud6e8\uc52c \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc73c\uba70 \uacf5\uac1c\uc801\uc73c\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud55c IR \ubaa8\ub378 [51]\uc740 \ub0b4\ubd80 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "6.4. Ablation study"}, {"figure_path": "https://arxiv.org/html/2412.08645/x19.png", "caption": "Figure 15: Ablation study on the importance of IR features for subject generation. Our subject generation model, denoted as IR, demonstrates superior identity preservation compared to a model trained using DINO-based retrievals.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc8fc\uc81c \uae30\ubc18 \uc0dd\uc131\uc5d0\uc11c IR \uae30\ub2a5\uc758 \uc911\uc694\uc131\uc5d0 \ub300\ud55c \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. IR\ub85c \ud45c\uc2dc\ub41c \uc8fc\uc81c \uc0dd\uc131 \ubaa8\ub378\uc740 DINO \uae30\ubc18 \uac80\uc0c9\uc73c\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc5d0 \ube44\ud574 \uc6b0\uc218\ud55c ID \ubcf4\uc874\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, IR \uae30\ubc18 \ubaa8\ub378\uc740 \ubb3c\uccb4\uc758 \uc138\ubd80\uc801\uc778 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \ub354 \uc798 \uc720\uc9c0\ud569\ub2c8\ub2e4. DINO \uae30\ubc18 \uac80\uc0c9 \ubaa8\ub378\uc740 \uc2dc\ub9e8\ud2f1 \uc720\uc0ac\uc131\uc5d0 \ub530\ub77c \uac80\uc0c9\ud558\ubbc0\ub85c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \uac1d\uccb4\uac00 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \uc2dc\uac01\uc801\uc73c\ub85c \ub2e4\ub97c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubc18\uba74, IR \uae30\ubc18 \ubaa8\ub378\uc740 \ub3d9\uc77c\ud55c \uac1d\uccb4\uc758 \uc5ec\ub7ec \ubcf4\uae30\ub97c \uac80\uc0c9\ud558\ubbc0\ub85c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uac00 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \uc2dc\uac01\uc801\uc73c\ub85c \uc77c\uce58\ud560 \uac00\ub2a5\uc131\uc774 \ub192\uc2b5\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.08645/x20.png", "caption": "Figure 16: Ablation study on data sources. We compare the effectiveness of different data sources for training.\nTraining on Open Images with publicly available IR features and on a web-scraped dataset using our internal IR model both outperform the current state-of-the-art insertion model, AnyDoor.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \ub370\uc774\ud130 \uc18c\uc2a4\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud6c8\ub828\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uacf5\uac1c\uc801\uc73c\ub85c \uc0ac\uc6a9 \uac00\ub2a5\ud55c IR \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud558\uc5ec Open Images \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uacfc \uc6f9\uc5d0\uc11c \uc218\uc9d1\ud55c \ub370\uc774\ud130\uc14b\uc744 \ub0b4\ubd80 IR \ubaa8\ub378\ub85c \ud6c8\ub828\ud55c \ubaa8\ub378 \ubaa8\ub450 \ucd5c\uc2e0 \uac1d\uccb4 \uc0bd\uc785 \ubaa8\ub378\uc778 AnyDoor\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0ac\uc2b5\ub2c8\ub2e4.", "section": "6.4. Ablation study"}, {"figure_path": "https://arxiv.org/html/2412.08645/x21.png", "caption": "Figure 17: Comparison with counterfactual object insertion. We compare to a model similar ObjectDrop. Our model is able to realistically harmonize the object\u2019s pose and lighting, while the counterfactual model pastes the object without adjustments.", "description": "ObjectMate\ub294 \uac1d\uccb4 \uc0bd\uc785\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \uc811\uadfc \ubc29\uc2dd\uc73c\ub85c, ObjectDrop\uacfc \uc720\uc0ac\ud55c \ubaa8\ub378\uacfc \ube44\uad50\ub429\ub2c8\ub2e4. ObjectDrop\uc740 \uac1d\uccb4\ub97c \uc0c8 \uc7a5\uba74\uc5d0 \ubd99\uc5ec\ub123\uae30\ub9cc \ud558\uace0 \uadf8\ub9bc\uc790\uc640 \ubc18\uc0ac\ub9cc \uc0dd\uc131\ud558\uc9c0\ub9cc \uac1d\uccb4\uc758 \ud3ec\uc988\ub098 \uc870\uba85\uc744 \uc870\uc815\ud558\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4. \ubc18\uba74, ObjectMate\ub294 \uac1d\uccb4\uc758 \ud3ec\uc988\uc640 \uc870\uba85\uc744 \uc7a5\uba74\uc5d0 \ub9de\ucdb0 \uc0ac\uc2e4\uc801\uc73c\ub85c \uc870\ud654\uc2dc\ud0a4\ub294 \uae30\ub2a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c ObjectMate\ub294 \uce74\uc6b4\ud130\ud329\uce04\uc5bc \ubaa8\ub378\uacfc \ub2ec\ub9ac \uac1d\uccb4\ub97c \uc7a5\uba74\uc5d0 \uc790\uc5f0\uc2a4\ub7fd\uac8c \ud1b5\ud569\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.08645/x22.png", "caption": "Figure 18: Additional in-the-wild object insertion results.", "description": "ObjectMate\uc758 \uac1d\uccb4 \uc0bd\uc785 \uacb0\uacfc\ub97c \uc57c\uc0dd \uc774\ubbf8\uc9c0\uc5d0\uc11c \ucd94\uac00\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ObjectMate\ub294 \ub2e4\uc591\ud55c \uac1d\uccb4\uc640 \ubc30\uacbd \uc7a5\uba74\uc5d0 \ub300\ud574 \uc0ac\uc2e4\uc801\uc774\uace0 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \ud569\uc131 \uacb0\uacfc\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ucc38\uc870 \uac1d\uccb4\uc758 \ud3ec\uc988\uc640 \uc870\uba85\uc774 \ubc30\uacbd\uacfc \uc798 \uc5b4\uc6b8\ub9ac\ub3c4\ub85d \uc870\uc815\ub429\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8 (6. Experiments)"}, {"figure_path": "https://arxiv.org/html/2412.08645/x23.png", "caption": "Figure 19: Comparison with SuTI. Our method better preserves the fine details of the subjects. SuTI uses semantic features (CLIP) for retrieval, while we use specialized instance-retrieval features. This makes our paired data more suitable for identity preservation. Results of SuTI are taken from their manuscript. Here, SuTI uses 5 references, while we use 3.", "description": "ObjectMate\uac00 SuTI\uc640 \ube44\uad50\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. ObjectMate\ub294 \ud53c\uc0ac\uccb4\uc758 \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uc744 \ub354 \uc798 \ubcf4\uc874\ud569\ub2c8\ub2e4. SuTI\ub294 \uac80\uc0c9\uc5d0 CLIP\uc758 \uc758\ubbf8\ub860\uc801 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud558\ub294 \ubc18\uba74, ObjectMate\ub294 \ud2b9\uc218\ud654\ub41c \uc778\uc2a4\ud134\uc2a4 \uac80\uc0c9 \ud2b9\uc9d5\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub85c \uc778\ud574 ObjectMate\uc758 \uc30d \ub370\uc774\ud130\uac00 \ub3d9\uc77c\uc131 \ubcf4\uc874\uc5d0 \ub354 \uc801\ud569\ud569\ub2c8\ub2e4. SuTI\uc758 \uacb0\uacfc\ub294 SuTI\uc758 \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c SuTI\ub294 5\uac1c\uc758 \ucc38\uc870\ub97c \uc0ac\uc6a9\ud558\uace0 ObjectMate\ub294 3\uac1c\uc758 \ucc38\uc870\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8 (6.3. \uc8fc\uc81c \uae30\ubc18 \uc0dd\uc131)"}, {"figure_path": "https://arxiv.org/html/2412.08645/x24.png", "caption": "Figure 20: Comparison with SuTI. Our model demonstrates superior capability in preserving fine details of the object, regardless of whether 1 or 3 reference images are provided by the user. Results of SuTI are taken from their manuscript.", "description": "ObjectMate \ubaa8\ub378\uacfc SuTI \ubaa8\ub378\uc744 \ube44\uad50\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. ObjectMate \ubaa8\ub378\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 1\uc7a5\uc77c \ub54c\uc640 3\uc7a5\uc77c \ub54c \ubaa8\ub450 \uac1d\uccb4\uc758 \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uc744 \ub354 \uc798 \ubcf4\uc874\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SuTI\uc758 \uacb0\uacfc\ub294 \ud574\ub2f9 \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8 (6. Experiments)"}, {"figure_path": "https://arxiv.org/html/2412.08645/x25.png", "caption": "Figure 21: Comparison with Instruct-Imagen. Our method better preserves the fine details of the bowl (e.g., text decoration). Instruct-Imagen uses similar data to SuTI, which is based on semantic clustering. Results of Instruct-Imagen are taken from their manuscript.", "description": "ObjectMate\uc640 Instruct-Imagen\uc744 \ube44\uad50\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4. ObjectMate\ub294 \uadf8\ub987\uc758 \ud14d\uc2a4\ud2b8 \uc7a5\uc2dd\uacfc \uac19\uc740 \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uc744 \ub354 \uc798 \ubcf4\uc874\ud569\ub2c8\ub2e4. Instruct-Imagen\uc740 SuTI\uc640 \uc720\uc0ac\ud55c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uba70, \uc758\ubbf8\ub860\uc801 \ud074\ub7ec\uc2a4\ud130\ub9c1\uc744 \uae30\ubc18\uc73c\ub85c \ud569\ub2c8\ub2e4. Instruct-Imagen\uc758 \uacb0\uacfc\ub294 \ud574\ub2f9 \ub17c\ubb38\uc5d0\uc11c \uac00\uc838\uc654\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c ObjectMate\ub294 \uadf8\ub987\uc5d0 \uc4f0\uc778 \"Bon Appetit\"\uc774\ub77c\ub294 \ubb38\uad6c\ub97c \uc798 \ubcf4\uc874\ud558\ub294 \ubc18\uba74, Instruct-Imagen\uc740 \ud14d\uc2a4\ud2b8 \uc7a5\uc2dd\uc744 \uc81c\ub300\ub85c \uc0dd\uc131\ud558\uc9c0 \ubabb\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8 (Experiments)"}, {"figure_path": "https://arxiv.org/html/2412.08645/x26.png", "caption": "Figure 22: Creative application. We test the model\u2019s generalization by providing it with three references of different objects. This setup represents a significant deviation from the training distribution, where the model received three references of the same object. Remarkably, the model demonstrates an ability to generalize beyond its training data by either synthesizing the references into a single unified object or generating the three objects separately.", "description": "ObjectMate\ub294 \uc77c\ubc18\uc801\uc73c\ub85c \ub3d9\uc77c\ud55c \uac1d\uccb4\uc758 \uc138 \uac00\uc9c0 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub85c \ud6c8\ub828\ub418\uc9c0\ub9cc, \uc774 \uadf8\ub9bc\uc5d0\uc11c\ub294 \uc11c\ub85c \ub2e4\ub978 \uc138 \uac1d\uccb4\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc785\ub825\uc73c\ub85c \uc81c\uacf5\ud558\uc5ec \ubaa8\ub378\uc758 \uc77c\ubc18\ud654 \ub2a5\ub825\uc744 \ud14c\uc2a4\ud2b8\ud569\ub2c8\ub2e4. \ubaa8\ub378\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \ub2e8\uc77c \uac1d\uccb4\ub85c \ud569\uc131\ud558\uac70\ub098 \uc138 \uac1d\uccb4\ub97c \uac1c\ubcc4\uc801\uc73c\ub85c \uc0dd\uc131\ud558\uc5ec \ud6c8\ub828 \ub370\uc774\ud130\ub97c \ub118\uc5b4 \uc77c\ubc18\ud654\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "6. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.08645/x27.png", "caption": "(a)", "description": "(a) \uac80\uc0c9 \uc815\ubc00\ub3c4 \ub300 \uc720\uc0ac\uc131 \uc784\uacc4\uac12. \uc784\uacc4\uac12 0.93\uc740 70%\uc758 \uc815\ubc00\ub3c4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uac80\uc0c9 \uc815\ubc00\ub3c4\ub294 \uc720\uc0ac\uc131 \uc784\uacc4\uac12\uc5d0 \ub530\ub77c \ub2ec\ub77c\uc9c0\uba70, \uac80\uc0c9\ub41c \uac1d\uccb4\uc758 \ube44\uc728\uc740 \uc784\uacc4\uac12\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uac10\uc18c\ud569\ub2c8\ub2e4. \ud68c\uc0c9 \uc810\uc120\uc740 \ub17c\ubb38\uc5d0\uc11c \uc120\ud0dd\ud55c \ucd5c\uc885 \uc784\uacc4\uac12\uacfc \uadf8\uc5d0 \uc0c1\uc751\ud558\ub294 \uc815\ubc00\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 \uac1d\uccb4 \ubc18\ubcf5 \ubd84\uc11d\uc744 \ubcf4\uc5ec\uc8fc\uace0, 0.93\uc758 \uc784\uacc4\uac12\uc774 70%\uc758 \uc815\ubc00\ub3c4\ub97c \uc0b0\ucd9c\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uac1d\uccb4 \ubc18\ubcf5 \uc0ac\uc804"}, {"figure_path": "https://arxiv.org/html/2412.08645/x28.png", "caption": "(b)", "description": "\uc774 \uadf8\ub9bc\uc740 \uac1d\uccb4\uc640 \uadf8 3\uac1c\uc758 \ucd5c\uadfc\uc811 \uc774\uc6c3 \uac04\uc758 \uc720\uc0ac\uc131 \uc810\uc218 \ubd84\ud3ec\ub97c \uc138 \uac00\uc9c0 \ub370\uc774\ud130\uc14b(COCO, Open Images, WebLI)\uc5d0 \ub300\ud574 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc94\ub840\ub294 [0.93, 0.975] \ubc94\uc704 \ub0b4\uc5d0 \uc788\ub294 \uac1d\uccb4\uc758 \ubc31\ubd84\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. The object recurrence prior"}, {"figure_path": "https://arxiv.org/html/2412.08645/x29.png", "caption": "Figure 23: Limitations. (a) This study primarily focuses on preserving subject identity, which may result in quality variability in scenarios that require changing some of the subject\u2019s properties, such as changes in color or shape. (b) Given that the training data is predominantly composed of real photographs, the model occasionally generates photos of paintings when the prompt specifies an artistic style.", "description": "\uc774 \uadf8\ub9bc\uc740 ObjectMate \ubaa8\ub378\uc758 \ud55c\uacc4\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 \uc0c9\uc0c1\uc774\ub098 \ubaa8\uc591\uacfc \uac19\uc740 \ud53c\uc0ac\uccb4\uc758 \uc18d\uc131\uc744 \ubcc0\uacbd\ud574\uc57c \ud558\ub294 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \ud488\uc9c8 \ubcc0\ub3d9\uc774 \ubc1c\uc0dd\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b)\ub294 \ud6c8\ub828 \ub370\uc774\ud130\uac00 \uc8fc\ub85c \uc2e4\uc81c \uc0ac\uc9c4\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \ud504\ub86c\ud504\ud2b8\uac00 \uc608\uc220\uc801 \uc2a4\ud0c0\uc77c\uc744 \uc9c0\uc815\ud560 \ub54c \ubaa8\ub378\uc774 \uac00\ub054 \uadf8\ub9bc \uc0ac\uc9c4\uc744 \uc0dd\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, ObjectMate\ub294 \ud53c\uc0ac\uccb4\uc758 \uc815\uccb4\uc131 \ubcf4\uc874\uc5d0 \uc911\uc810\uc744 \ub450\uae30 \ub54c\ubb38\uc5d0 \uc0c9\uc0c1\uc774\ub098 \ubaa8\uc591 \ubcc0\uacbd\uacfc \uac19\uc740 \uc18d\uc131 \ud3b8\uc9d1\uc740 \ud488\uc9c8\uc774 \ub5a8\uc5b4\uc9c8 \uc218 \uc788\uc73c\uba70, \ub610\ud55c \ud559\uc2b5 \ub370\uc774\ud130\uc758 \ud2b9\uc131\uc0c1 \uadf8\ub9bc\uacfc \uac19\uc740 \uc2a4\ud0c0\uc77c\uc758 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc5d0 \uc5b4\ub824\uc6c0\uc744 \uacaa\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "7. Discussion and Limitations"}, {"figure_path": "https://arxiv.org/html/2412.08645/x30.png", "caption": "Figure 24: Additional object insertion comparisons on our benchmark with the provided ground truth.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud55c \uac1d\uccb4 \uc0bd\uc785 \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uac1d\uccb4 \uc0bd\uc785 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub2e4\ub978 \uac1d\uccb4\uc640 \ubc30\uacbd \uc7a5\uba74\uc744 \ub098\ud0c0\ub0b4\uba70, \uac01 \uc5f4\uc740 PbE, ObjectStitch, AnyDoor\uc640 \uac19\uc740 \uae30\uc874 \ubc29\ubc95\uacfc ObjectMate\uc758 1\uac1c \ub808\ud37c\ub7f0\uc2a4 \uc774\ubbf8\uc9c0, 3\uac1c \ub808\ud37c\ub7f0\uc2a4 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud55c \uacb0\uacfc, \uadf8\ub9ac\uace0 Ground Truth \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc744 \ud1b5\ud574 ObjectMate\uac00 \ub2e4\uc591\ud55c \uac1d\uccb4\uc640 \ubc30\uacbd\uc5d0\uc11c \uc0ac\uc2e4\uc801\uc778 \uac1d\uccb4 \uc0bd\uc785 \uacb0\uacfc\ub97c \uc0dd\uc131\ud558\uace0 \uae30\uc874 \ubc29\ubc95\ubcf4\ub2e4 Ground Truth\uc5d0 \ub354 \uac00\uae4c\uc6b4 \uacb0\uacfc\ub97c \uc0dd\uc131\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "6. \uc2e4\ud5d8"}]