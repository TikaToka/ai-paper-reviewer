[{"content": "| Block Size | Block Shape (T\u00d7H\u00d7W) | FVD\u2193 |\n|---|---|---|\n| 16 | 1\u00d74\u00d74 | 33.4 |\n| 16 | 2\u00d71\u00d78 | 29.2 |\n| 16 | 1\u00d71\u00d716 | 25.5 |\n| 8 | 2\u00d72\u00d72 | 32.7 |\n| 8 | 1\u00d71\u00d78 | 25.7 |", "caption": "Table 1: Comparison of next-token prediction (NTP) and next-block prediction (NBP) models in terms of performance and speed, evaluated on the K600 dataset (5-frame condition, 12 frames (768 tokens) to predict). Inference time was measured on a single A100 Nvidia GPU. All models are implemented by us under the same setting and trained for 20 epochs. FPS denotes \u201cframe per second\u201d. The measurement of inference speed includes tokenization and de-tokenization processes. KV-cache is used for both models.", "description": "\ud45c 1\uc740 K600 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc218\ud589\ub41c \ub2e4\uc74c \ud1a0\ud070 \uc608\uce21(NTP) \ubc0f \ub2e4\uc74c \ube14\ub85d \uc608\uce21(NBP) \ubaa8\ub378\uc758 \uc131\ub2a5 \ubc0f \uc18d\ub3c4 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 5\ud504\ub808\uc784 \uc870\uac74\uc5d0\uc11c 12\ud504\ub808\uc784(768\uac1c \ud1a0\ud070)\uc744 \uc608\uce21\ud558\ub294 \uc2e4\ud5d8\uc744 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4. \ub2e8\uc77c A100 Nvidia GPU\uc5d0\uc11c \ucd94\ub860 \uc2dc\uac04\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \ubaa8\ub4e0 \ubaa8\ub378\uc740 \ub3d9\uc77c\ud55c \uc124\uc815\ud558\uc5d0 \uad6c\ud604\ub418\uc5c8\uace0 20 \uc5d0\ud3ec\ud06c \ub3d9\uc548 \ud559\uc2b5\ub418\uc5c8\uc2b5\ub2c8\ub2e4. FPS\ub294 \ucd08\ub2f9 \ud504\ub808\uc784 \uc218\ub97c \ub098\ud0c0\ub0b4\uba70, \ucd94\ub860 \uc18d\ub3c4 \uce21\uc815\uc5d0\ub294 \ud1a0\ud070\ud654 \ubc0f \uc5ed\ud1a0\ud070\ud654 \uacfc\uc815\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \ub450 \ubaa8\ub378 \ubaa8\ub450 KV-\uce90\uc2dc\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Model | Parameters | Layers | Hidden Size | Heads |\n|---|---|---|---|---|\n| NBP-XL | 700M | 24 | 1536 | 16 |\n| NBP-XXL | 1.2B | 24 | 2048 | 32 |\n| NBP-3B | 3B | 32 | 3072 | 32 |", "caption": "Table 2: Comparions of class-conditional generation results on UCF-101 and frame prediction results on K600. MTM indicates mask token modeling. Our model on K600 is trained for 77 epochs, we gray out models that use significantly more training computation (e.g., those trained for over 300 epochs) for a fair comparison.", "description": "\ud45c 2\ub294 UCF-101 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \ud074\ub798\uc2a4 \uc870\uac74\ubd80 \ube44\ub514\uc624 \uc0dd\uc131 \uacb0\uacfc\uc640 K600 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\uc758 \ud504\ub808\uc784 \uc608\uce21 \uacb0\uacfc\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  MTM\uc740 \ub9c8\uc2a4\ud06c \ud1a0\ud070 \ubaa8\ub378\ub9c1\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. K600 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ubcf8 \ub17c\ubb38\uc758 \ubaa8\ub378\uc740 77 \uc5d0\ud3ed \ub3d9\uc548 \ud559\uc2b5\ub418\uc5c8\uc73c\uba70, 300 \uc5d0\ud3ed \uc774\uc0c1\uc758 \uc0c1\ub2f9\ud788 \ub9ce\uc740 \uacc4\uc0b0\ub7c9\uc744 \ud544\uc694\ub85c \ud558\ub294 \ubaa8\ub378\ub4e4\uc740 \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \ud68c\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc218, FVD(Fr\u00e9chet Video Distance) \uc810\uc218, \ud1a0\ud070 \uc218, \ud559\uc2b5 \ub2e8\uacc4 \ub4f1\uc758 \uc815\ubcf4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4, \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uacfc \ud6a8\uc728\uc131\uc744 \ube44\uad50\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Hyper-parameters | UCF101 | K600 |\n|---|---|---|\n| Video FPS | 8 | 8 |\n| Latent shape | 5x16x16 | 5x16x16 |\n| Vocabulary size | 64K | 64K |\n| Embedding dimension | 6 | 6 |\n| Initialization | Random | Random |\n| Peak learning rate | 5e-5 | 1e-4 |\n| Learning rate schedule | linear | linear |\n| Warmup ratio | 0.01 | 0.01 |\n| Perceptual loss weight | 0.1 | 0.1 |\n| Generator adversarial loss weight | 0.1 | 0.1 |\n| Optimizer | Adam | Adam |\n| Batch size | 256 | 256 |\n| Epoch | 2000 | 100 |", "caption": "Table 3: Generation quality (FVD) of various block shape.", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \ube14\ub85d \ud615\ud0dc\uc5d0 \ub530\ub978 \ube44\ub514\uc624 \uc0dd\uc131 \ud488\uc9c8(FVD)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube14\ub85d\uc758 \ud06c\uae30\uc640 \ud615\ud0dc\uac00 \ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uae30 \uc704\ud574 \uc218\ud589\ub41c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ube14\ub85d \ud06c\uae30\uc640 \ud615\ud0dc(\uc608: 1x4x4, 2x1x8, 1x1x16 \ub4f1)\uc5d0 \ub530\ub978 FVD \uac12\uc744 \uc81c\uc2dc\ud558\uc5ec \uc5b4\ub5a4 \ube14\ub85d \ud615\ud0dc\uac00 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \uac00\uc7a5 \ud6a8\uacfc\uc801\uc778\uc9c0 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub2e8\uc21c\ud788 FVD \uc218\uce58\ub9cc \uc81c\uc2dc\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c,  \ube14\ub85d \ud615\ud0dc\uac00 \uc0dd\uc131 \uc131\ub2a5\uc5d0 \uc5b4\ub5bb\uac8c \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0\uc5d0 \ub300\ud55c \uc2ec\uce35\uc801\uc778 \ubd84\uc11d\uacfc \uadf8 \uc774\uc720\ub97c \uc124\uba85\ud558\ub294 \ub0b4\uc6a9\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.", "section": "4.5. Ablation Study and Analysis"}, {"content": "| Hyper-parameters | UCF101 | K600 |\n|---|---|---|\n| Video FPS | 8 | 16 |\n| Latent shape | 5 \\times 16 \\times 16 | 5 \\times 16 \\times 16 |\n| Vocabulary size | 96K (including 32K text tokens) | 64K |\n| Initialization | Random | Random |\n| Peak learning rate | 6e-4 | 1e-3 |\n| Learning rate schedule | linear | linear |\n| Warmup steps | 5,000 | 10,000 |\n| Weight decay | 0.01 | 0.01 |\n| Optimizer | Adam (0.9, 0.98) | Adam (0.9, 0.98) |\n| Dropout | 0.1 | 0.1 |\n| Batch size | 256 | 64 |\n| Epoch | 2560 | 77 |", "caption": "Table 4: Model sizes and architecture configurations of our generation model. The configurations are following LLaMA\u00a0(Touvron et\u00a0al., 2023).", "description": "\ud45c 4\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ud06c\uae30\uc640 \uc544\ud0a4\ud14d\ucc98 \uad6c\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLaMA (Touvron et al., 2023)\uc758 \uc124\uc815\uc744 \uae30\ubc18\uc73c\ub85c \ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ubaa8\ub378 \uc774\ub984(NBP-XL, NBP-XXL, NBP-3B), \ud30c\ub77c\ubbf8\ud130 \uc218, \ub808\uc774\uc5b4 \uc218, \ud788\ub4e0 \uc0c1\ud0dc \ud06c\uae30, \ud5e4\ub4dc \uc218 \ub4f1\uc758 \uc815\ubcf4\uac00 \ud3ec\ud568\ub418\uc5b4 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uaddc\ubaa8\uc640 \uad6c\uc870\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc \ud6a8\uc728\uc131\uc744 \uc774\ud574\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | Backbone | Quantizer | Param. | # bits | rFVD<binary data, 1 bytes><binary data, 1 bytes> (UCF-101) | PSNR<binary data, 1 bytes><binary data, 1 bytes> (UCF-101) | SSIM<binary data, 1 bytes><binary data, 1 bytes> (UCF-101) | LPIPS<binary data, 1 bytes><binary data, 1 bytes> (UCF-101) | rFVD<binary data, 1 bytes><binary data, 1 bytes> (K600) | PSNR<binary data, 1 bytes><binary data, 1 bytes> (K600) | SSIM<binary data, 1 bytes><binary data, 1 bytes> (K600) | LPIPS<binary data, 1 bytes><binary data, 1 bytes> (K600) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| MaskGIT [Chang et al., 2022] | 2D CNN | VQ | 53M | 10 | 216 | 21.5 | .685 | .1140 | - | - | - | - |\n| TATS [Ge et al., 2022] | 3D CNN | VQ | 32M | 14 | 162 | - | - | - | - | - | - | - |\n| OmniTokenizer [Wang et al., 2024a] | ViT | VQ | 78M | 13 | 42 | 30.3 | .910 | .0733 | 27 | 28.5 | .883 | .0945 |\n| MAGVIT-v1 [Yu et al., 2023a] | 3D CNN | VQ | 158M | 10 | 25 | 22.0 | .701 | .0990 | - | - | - | - |\n| MAGVIT-v2 [Yu et al., 2024] | C.-3D CNN | LFQ | 158M | 18 | 16.12 | - | - | .0694 | - | - | - | - |\n| MAGVIT-v2 [Yu et al., 2024] | C.-3D CNN | LFQ | 370M | 18 | 8.62 | - | - | .0537 | - | - | - | - |\n| NBP-Tokenizer (Ours) | C.-3D CNN | FSQ | 370M | 16 | 15.50 | 29.3 | .893 | .0648 | 6.73 | 31.3 | .944 | .0828 |", "caption": "Table 5: Training configurations of video tokenizer.", "description": "\ud45c 5\ub294 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uc124\uc815 \ubd80\ubd84\uc5d0\uc11c \ube44\ub514\uc624 \ud1a0\ud06c\ub098\uc774\uc800(video tokenizer)\uc758 \ud559\uc2b5 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  UCF101\uacfc K600 \ub450 \uac1c\uc758 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574, \ube44\ub514\uc624 FPS, \uc7a0\uc7ac \ubca1\ud130\uc758 \ud615\ud0dc(latent shape), \uc5b4\ud718 \uc0ac\uc804 \ud06c\uae30(vocabulary size), \uc784\ubca0\ub529 \ucc28\uc6d0(embedding dimension), \ucd08\uae30\ud654 \ubc29\ubc95(initialization), \ucd5c\ub300 \ud559\uc2b5\ub960(peak learning rate), \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904(learning rate schedule), \uc6dc\uc5c5 \ube44\uc728(warmup ratio), \uc190\uc2e4 \ud568\uc218 \uac00\uc911\uce58(loss function weights), \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998(optimizer), \ubc30\uce58 \ud06c\uae30(batch size), \uc5d0\ud3ed \uc218(epoch) \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac12\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ube44\ub514\uc624 \ud1a0\ud06c\ub098\uc774\uc800 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \uc8fc\uc694 \uc124\uc815\ub4e4\uc744 \ud55c\ub208\uc5d0 \ud30c\uc545\ud560 \uc218 \uc788\ub3c4\ub85d \uc790\uc138\ud788 \uc81c\uc2dc\ud558\uc5ec, \uc2e4\ud5d8\uc758 \uc7ac\ud604\uc131\uacfc \uc774\ud574\ub3c4\ub97c \ub192\uc774\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}]