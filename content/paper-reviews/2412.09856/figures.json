[{"figure_path": "https://arxiv.org/html/2412.09856/x1.png", "caption": "Figure 1: LinGen generates photorealistic high-resolution long videos with linear computational complexity.\n(a) High-quality videos generated using our LinGen model. (b) The computational cost scaling curves across different video resolutions and lengths. LinGen achieves 15\u00d7\\times\u00d7 speed-up compared to the standard DiT when generating 68s-length videos at 512p resolution.", "description": "LinGen\uc740 \uc120\ud615 \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc2e4\uc801\uc778 \uace0\ud574\uc0c1\ub3c4 \uc7a5\uc2dc\uac04 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. (a) LinGen \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uace0\ud488\uc9c8 \ube44\ub514\uc624\uc785\ub2c8\ub2e4. (b) \ub2e4\uc591\ud55c \ube44\ub514\uc624 \ud574\uc0c1\ub3c4\uc640 \uae38\uc774\uc5d0 \ub530\ub978 \uacc4\uc0b0 \ube44\uc6a9 \uc99d\uac00 \uace1\uc120\uc785\ub2c8\ub2e4. LinGen\uc740 512p \ud574\uc0c1\ub3c4\uc5d0\uc11c 68\ucd08 \uae38\uc774\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \ub54c \ud45c\uc900 DiT\uc5d0 \ube44\ud574 \ucd5c\ub300 15\ubc30\uc758 \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.09856/x2.png", "caption": "Figure 2: Overview of the LinGen denoising module.\nLinGen replaces self-attention layers with a MATE block, which inherits linear complexity from its two branches: MA-branch and TE-branch. The MA-branch consists of a bidirectional Mamba2 block, RMS, and review tokens to cover short-to-long-range correlations. The TE-branch is a TEmporal Swin Attention block that addresses the adjacency preservation issue and improves the consistency of generated videos significantly.", "description": "LinGen denoising \ubaa8\ub4c8\uc740 self-attention \ub808\uc774\uc5b4\ub97c MATE \ube14\ub85d\uc73c\ub85c \ub300\uccb4\ud558\uc5ec \uc120\ud615 \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\ub97c \ub2ec\uc131\ud569\ub2c8\ub2e4. MATE \ube14\ub85d\uc740 MA-branch(\uc591\ubc29\ud5a5 Mamba2 \ube14\ub85d, RMS, review \ud1a0\ud070)\uc640 TE-branch(Temporal Swin Attention \ube14\ub85d)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. MA-branch\ub294 \ub2e8-\uc911-\uc7a5\uac70\ub9ac \uc0c1\uad00\uad00\uacc4\ub97c \ucc98\ub9ac\ud558\uace0, TE-branch\ub294 \uc778\uc811\uc131 \ubcf4\uc874 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uc77c\uad00\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2412.09856/x3.png", "caption": "Figure 3: The bidirectional Mamba2 module. \nNative Mamba2 only generates the lower triangular part of the attention map due to its causal characteristic. Thus, we deploy bidirectional Mamba2 to obtain the complete attention map for vision tasks.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc591\ubc29\ud5a5 Mamba2 \ubaa8\ub4c8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 Mamba2\ub294 \uc778\uacfc\uc801 \ud2b9\uc131\uc73c\ub85c \uc778\ud574 \uc8fc\uc758 \ub9f5\uc758 \uc544\ub798\ucabd \uc0bc\uac01\ud615 \ubd80\ubd84\ub9cc \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c, \ube44\uc804 \uc791\uc5c5\uc744 \uc704\ud574 \uc644\uc804\ud55c \uc8fc\uc758 \ub9f5\uc744 \uc5bb\uae30 \uc704\ud574 \uc591\ubc29\ud5a5 Mamba2\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc989, Mamba2\ub294 SSM(State Space Model)\uc758 \ubcc0\ud615\uc73c\ub85c, SSM\uacfc \ub9c8\uc2a4\ud06c \ud6a8\uc728\uc801 \uc8fc\uc758\ub97c \ud1b5\ud569\ud558\ub294 \ud2b9\uc218\ud55c SSM\uc785\ub2c8\ub2e4. Mamba2\ub294 Mamba\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \uc21c\ucc28\uc801 \uc120\ud615 \ud22c\uc601\uc744 \uc81c\uac70\ud558\uace0 SSM \ub9e4\uac1c\ubcc0\uc218 A, B, C\ub97c \ubcd1\ub82c\ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub610\ud55c Mamba2\uc758 \uc815\uaddc\ud654 \uacc4\uce35\uc740 [51]\uacfc \ub3d9\uc77c\ud558\uba70, \uc548\uc815\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3.2. MA-Branch: Targets Short-to-Long Range"}, {"figure_path": "https://arxiv.org/html/2412.09856/x4.png", "caption": "Figure 4: Rotary-Major Scan (RMS). We apply different scan schedules across layers to preserve adjacency along various dimensions. Note that scan is bidirectional in practice, but for clarity, only one direction is illustrated for each scan schedule.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 Rotary-Major Scan(RMS) \uae30\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. RMS\ub294 3\ucc28\uc6d0 \ube44\ub514\uc624 \ud1a0\ud070 \ud150\uc11c\ub97c 4\uac00\uc9c0 \ub2e4\ub978 \ubc29\uc2dd(\uacf5\uac04 \ud589 \uc6b0\uc120, \uacf5\uac04 \uc5f4 \uc6b0\uc120, \uc2dc\uac04 \ud589 \uc6b0\uc120, \uc2dc\uac04 \uc5f4 \uc6b0\uc120)\uc73c\ub85c \uc7ac\ubc30\uc5f4\ud558\uc5ec \uc778\uc811\ud55c \ud1a0\ud070 \uac04\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1\ud569\ub2c8\ub2e4. \uac01 \ub808\uc774\uc5b4\ub9c8\ub2e4 \ub2e4\ub978 \uc2a4\uce94 \ubc29\uc2dd\uc744 \ubc88\uac08\uc544 \uc0ac\uc6a9\ud558\uba70, \uc2e4\uc81c\ub85c\ub294 \uc591\ubc29\ud5a5 \uc2a4\uce94\uc744 \ud558\uc9c0\ub9cc \uadf8\ub9bc\uc5d0\uc11c\ub294 \uac01 \uc2a4\uce94 \ubc29\ud5a5\uc744 \uba85\ud655\ud788 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574 \ud55c \ubc29\ud5a5\ub9cc \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4. \uc774 \uae30\ubc95\uc744 \ud1b5\ud574 Mamba2 \ube14\ub85d\uc758 \uc778\uc811\uc131 \ubcf4\uc874 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uace0, \ucd94\uac00\uc801\uc778 \uc9c0\uc5f0 \uc2dc\uac04 \uc5c6\uc774 \ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3.2. MA-Branch: Targets Short-to-Long Range"}, {"figure_path": "https://arxiv.org/html/2412.09856/x5.png", "caption": "Figure 5: TEmporal Swin Attention (TESA). We divide the token tensor into small windows and calculate self-attention within each window. The windows are alternately shifted across layers to cross the boundaries of local windows. The window size remains fixed across different resolutions, hence maintaining linear complexity.", "description": "TESA(Temporal Swin Attention)\ub294 \ud1a0\ud070 \ud150\uc11c\ub97c \uc791\uc740 \uc708\ub3c4\uc6b0\ub85c \ub098\ub204\uace0 \uac01 \uc708\ub3c4\uc6b0 \ub0b4\uc5d0\uc11c \uc790\uae30 \uc8fc\uc758(self-attention)\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc708\ub3c4\uc6b0\ub294 \ub808\uc774\uc5b4\ub9c8\ub2e4 \ubc88\uac08\uc544 \uac00\uba70 \uc774\ub3d9\ud558\uc5ec \ub85c\uceec \uc708\ub3c4\uc6b0\uc758 \uacbd\uacc4\ub97c \ub118\uc5b4 \uc5f0\uacb0\uc744 \ud615\uc131\ud569\ub2c8\ub2e4. \uc708\ub3c4\uc6b0 \ud06c\uae30\ub294 \ub2e4\uc591\ud55c \ud574\uc0c1\ub3c4\uc5d0\uc11c \uace0\uc815\ub418\uc5b4 \uc120\ud615 \ubcf5\uc7a1\ub3c4\ub97c \uc720\uc9c0\ud569\ub2c8\ub2e4. \uc774\ub294 \uc708\ub3c4\uc6b0 \ud06c\uae30\uac00 \uace0\uc815\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \ud1a0\ud070 \uc218\uc5d0 \ub530\ub77c \uacc4\uc0b0 \ubcf5\uc7a1\ub3c4\uac00 \uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uace0\ud574\uc0c1\ub3c4, \uae34 \uc601\uc0c1 \uc0dd\uc131\uc5d0 \ud6a8\uc728\uc801\uc785\ub2c8\ub2e4. \ub610\ud55c, \uc708\ub3c4\uc6b0\ub97c \uc774\ub3d9\uc2dc\ud0a4\ub294 \ubc29\uc2dd\uc740 Swin Transformer\uc5d0\uc11c \uc601\uac10\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4. \uac01 \ub808\uc774\uc5b4\ub9c8\ub2e4 \uc708\ub3c4\uc6b0\ub97c \uc774\ub3d9\uc2dc\ucf1c \uc774\uc804 \ub808\uc774\uc5b4\uc758 \uc708\ub3c4\uc6b0 \uacbd\uacc4\ub97c \ub118\uc5b4 \uc0c1\ud638 \uc791\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc774\ub294 \uc778\uc811\ud55c \ud1a0\ud070 \uac04\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \uc798 \ud3ec\ucc29\ud558\uace0 \uc601\uc0c1\uc758 \uc77c\uad00\uc131\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.3. TE-Branch: TEmporal Swin Attention"}, {"figure_path": "https://arxiv.org/html/2412.09856/x6.png", "caption": "Figure 6: Computational cost comparison between DiT-4B and LinGen-4B. (a) Latency. (b) FLOPs. The cost of LinGen scales significantly slower with both video length and video resolution than DiT. Latency is measured on a single H100 GPU.", "description": "\uc774 \uadf8\ub9bc\uc740 DiT-4B\uc640 LinGen-4B\uc758 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. LinGen\uc758 \ube44\uc6a9\uc740 \ube44\ub514\uc624 \uae38\uc774\uc640 \ud574\uc0c1\ub3c4 \ubaa8\ub450\uc5d0\uc11c DiT\ubcf4\ub2e4 \ud6e8\uc52c \ub290\ub9ac\uac8c \uc99d\uac00\ud569\ub2c8\ub2e4. 68\ucd08 \uae38\uc774\uc758 512p \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \ub54c LinGen\uc740 DiT\uc5d0 \ube44\ud574 \ucd5c\ub300 15\ubc30\uc758 FLOPs \uac10\uc18c \ubc0f 11.5\ubc30\uc758 \uc9c0\uc5f0 \uc2dc\uac04 \ub2e8\ucd95\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4. \uc9c0\uc5f0 \uc2dc\uac04\uc740 \ub2e8\uc77c H100 GPU\uc5d0\uc11c \uce21\uc815\ub429\ub2c8\ub2e4.", "section": "4.2. Efficiency: Linear Computational Complexity"}, {"figure_path": "https://arxiv.org/html/2412.09856/x7.png", "caption": "Figure 7: Visual examples of videos generated from different models. LinGen-4B generates videos that have similar quality to state-of-the-art commercial video generative models, including Gen-3, LumaLabs, and Kling, while achieving linear complexity and significant speed-up relative to the standard DiT architecture.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen-4B, Gen-3, LumaLabs, Kling\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \ubaa8\ub378\uc5d0\uc11c \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LinGen-4B\ub294 \ud45c\uc900 DiT \uc544\ud0a4\ud14d\ucc98\uc5d0 \ube44\ud574 \uc120\ud615 \ubcf5\uc7a1\ub3c4\uc640 \uc0c1\ub2f9\ud55c \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ub2ec\uc131\ud558\uba74\uc11c Gen-3, LumaLabs, Kling\uc744 \ud3ec\ud568\ud55c \ucd5c\ucca8\ub2e8 \uc0c1\uc6a9 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uacfc \uc720\uc0ac\ud55c \ud488\uc9c8\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \"A fish swimming into a coffee shop and trying to order\"\ub77c\ub294 \ud504\ub86c\ud504\ud2b8\ub97c \uae30\ubc18\uc73c\ub85c \uac01 \ubaa8\ub378\uc740 \ubb3c\uace0\uae30\uac00 \ucee4\ud53c\uc20d\uc5d0 \ub4e4\uc5b4\uac00 \uc8fc\ubb38\uc744 \uc2dc\ub3c4\ud558\ub294 \ub3c5\ud2b9\ud55c \ud574\uc11d\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. LinGen-4B\uac00 \uc0dd\uc131\ud55c \ube44\ub514\uc624\ub294 \ucd5c\ucca8\ub2e8 \ubaa8\ub378\uacfc \ube44\uad50\ud560 \ub9cc\ud55c \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3. Comparing Quality to State-of-the-Art Models"}, {"figure_path": "https://arxiv.org/html/2412.09856/x8.png", "caption": "Figure 8: Human evaluation on the quality and text-video alignment of videos generated by DiT-4B and LinGen-4B. LinGen outperforms DiT due to it faster adapation to longer token sequences.", "description": "LinGen-4B\uc640 DiT-4B\uac00 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \ud488\uc9c8 \ubc0f \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc815\ub82c\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00 \uacb0\uacfc\uc785\ub2c8\ub2e4. LinGen\uc740 \ub354 \uae34 \ud1a0\ud070 \uc2dc\ud000\uc2a4\uc5d0 \ub354 \ube60\ub974\uac8c \uc801\uc751\ud558\uae30 \ub54c\ubb38\uc5d0 DiT\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ud488\uc9c8, \ud504\ub808\uc784 \uc77c\uad00\uc131, \ubaa8\uc158 \uc790\uc5f0\uc2a4\ub7ec\uc6c0, \ubaa8\uc158 \uc77c\uce58, \uc8fc\uc81c \uc77c\uce58, \uc804\ubc18\uc801\uc778 \uc815\ub82c \ub4f1 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c \ub450 \ubaa8\ub378\uc758 \uc2b9\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.3. Comparing Quality to State-of-the-Art Models"}, {"figure_path": "https://arxiv.org/html/2412.09856/x9.png", "caption": "Figure 9: Win rates of human evaluation on the quality and text-video alignment of videos generated by LinGen and state-of-the-art video generative models. LinGen has comparable performance to them, given that the variance of human evaluation is 3%.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen\uacfc \ucd5c\uc2e0 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\ub4e4(Gen-3, LumaLabs, Kling)\uc774 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \ud488\uc9c8 \ubc0f \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc815\ub82c\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LinGen\uc740 \uc778\uac04 \ud3c9\uac00\uc758 \ubd84\uc0b0\uc774 3%\ub77c\ub294 \uc810\uc744 \uace0\ub824\ud588\uc744 \ub54c, \ucd5c\uc2e0 \uc0c1\uc6a9 \ubaa8\ub378\ub4e4\uacfc \ube44\uc2b7\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4.3. Comparing Quality to State-of-the-Art Models"}, {"figure_path": "https://arxiv.org/html/2412.09856/x10.png", "caption": "Figure 10: LinGen adapts much faster to the new task than DiT. (a) Loss curves when transferring the model trained on 256p video generation to 512p. (b) Win rates of human evaluation on quality and text-video faithfulness comparison between LinGen-4B and DiT-4B. Checkpoints are selected after 1K pre-training steps.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen\uc774 DiT\ubcf4\ub2e4 \uc0c8\ub85c\uc6b4 \uc791\uc5c5\uc5d0 \ub354 \ube68\ub9ac \uc801\uc751\ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 256p \ube44\ub514\uc624 \uc0dd\uc131\uc5d0\uc11c \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 512p \uc0dd\uc131\uc73c\ub85c \uc804\ud658\ud560 \ub54c\uc758 \uc190\uc2e4 \uace1\uc120\uc744, (b)\ub294 LinGen-4B\uc640 DiT-4B \uac04\uc758 \ud488\uc9c8 \ubc0f \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \ucda9\uc2e4\ub3c4 \ube44\uad50\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00 \uc2b9\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 1K \uc0ac\uc804 \ud6c8\ub828 \ub2e8\uacc4 \ud6c4 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc120\ud0dd\ud569\ub2c8\ub2e4. LinGen\uc758 \uc190\uc2e4\uc774 DiT\ubcf4\ub2e4 \ud6e8\uc52c \ube60\ub974\uac8c \uac10\uc18c\ud558\uace0, \ud6c8\ub828 \ucd08\uae30\uc5d0 \ub354 \ub192\uc740 \ud488\uc9c8\uacfc \ud14d\uc2a4\ud2b8 \uc815\ub82c \uc810\uc218\ub97c \ub2ec\uc131\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 LinGen\uc774 \ub354 \uae34 \ud1a0\ud070 \uc2dc\ud000\uc2a4\uc640 \ub354 \ub192\uc740 \ud574\uc0c1\ub3c4\uc5d0 \ub354 \ube68\ub9ac \uc801\uc751\ud558\uc5ec \ud655\uc7a5\uc131\uc774 \ub6f0\uc5b4\ub098\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4. Adaptation to Longer Token Sequences"}, {"figure_path": "https://arxiv.org/html/2412.09856/x11.png", "caption": "Figure 11: Loss curves of 256p text-to-video pre-training under different settings. (a) Ablation on the TESA block and RMS. (b) Ablation on different scan methods.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen \ubaa8\ub378\uc758 256p \ud574\uc0c1\ub3c4 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0ac\uc804 \ud6c8\ub828 \uc911 \uc190\uc2e4 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 TESA \ube14\ub85d\uacfc RMS\uc5d0 \ub300\ud55c \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c, (b)\ub294 \ub2e4\uc591\ud55c \uc2a4\uce94 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc808\uc81c \uc5f0\uad6c \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. TESA \ube14\ub85d\uacfc RMS\ub97c \ubaa8\ub450 \uc81c\uac70\ud558\uba74 \uc190\uc2e4\uc774 \uac00\uc7a5 \ub192\uc73c\uba70, \uc774\ub294 \ub450 \uc694\uc18c\uac00 \ubaa8\ub450 \ube44\ub514\uc624 \uc0dd\uc131 \ud488\uc9c8\uc5d0 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. RMS\ub294 \uc9c0\uadf8\uc7ac\uadf8 \uc2a4\uce94\uacfc \uc720\uc0ac\ud55c \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0\ub9cc \ucd94\uac00 \uc9c0\uc5f0 \uc2dc\uac04\uc774 \ud6e8\uc52c \uc801\uc2b5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 (Experiments)"}, {"figure_path": "https://arxiv.org/html/2412.09856/x12.png", "caption": "Figure 12: Win rates of human evaluation on quality comparison between the LinGen default setting and corresponding variants.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen\uc758 \uae30\ubcf8 \uc124\uc815\uacfc \uc5ec\ub7ec \ubcc0\ud615 \uc124\uc815 \uac04\uc758 \ud488\uc9c8 \ube44\uad50\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00\uc758 \uc2b9\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubcc0\ud615 \uc124\uc815\uc5d0\ub294 TESA \ube14\ub85d \uc81c\uac70, RMS \uc81c\uac70, \uac80\ud1a0 \ud1a0\ud070 \uc81c\uac70, \ud558\uc774\ube0c\ub9ac\ub4dc \ud559\uc2b5 \uc81c\uac70, \ud488\uc9c8 \uc870\uc815 \uc81c\uac70 \ub4f1\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. LinGen\uc758 \uae30\ubcf8 \uc124\uc815\uc740 \ub300\ubd80\ubd84\uc758 \ubcc0\ud615 \uc124\uc815\ubcf4\ub2e4 \ud6e8\uc52c \ub354 \ub098\uc740 \ud488\uc9c8\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub294 TESA \ube14\ub85d, RMS, \uac80\ud1a0 \ud1a0\ud070, \ud558\uc774\ube0c\ub9ac\ub4dc \ud559\uc2b5 \ubc0f \ud488\uc9c8 \uc870\uc815\uc774 \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x13.png", "caption": "Figure 13: Examples of 17-second and 68-second videos generated by LinGen.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen \ubaa8\ub378\ub85c \uc0dd\uc131\ub41c 17\ucd08 \ubc0f 68\ucd08 \uae38\uc774\uc758 \ube44\ub514\uc624 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 17\ucd08 \ube44\ub514\uc624\uc758 \ud504\ub86c\ud504\ud2b8\ub294 \"\ucef5\uc5d0 \uc6b0\uc720\ub97c \uc870\uc2ec\uc2a4\ub7fd\uac8c \ubd93\ub294\", \"\uac8c\uac00 \uad74 \uc8fc\uc704\ub97c \ub3cc\uc544\ub2e4\ub2c8\ub294\", \"\ub538\uae30\uc640 \ube14\ub8e8\ubca0\ub9ac\uac00 \ubb3c\uc5d0 \ub5a8\uc5b4\uc9c0\ub294\"\uc785\ub2c8\ub2e4. 68\ucd08 \ube44\ub514\uc624\uc758 \ud504\ub86c\ud504\ud2b8\ub294 \"\ub09c\ud30c\uc120 \uadfc\ucc98\uc5d0\uc11c \ud5e4\uc5c4\uce58\ub294 \ubc14\ub2e4\uac70\ubd81\"\uc785\ub2c8\ub2e4. LinGen\uc740 \uae34 \uc601\uc0c1\uc5d0\uc11c\ub3c4 \uc77c\uad00\uc131\uacfc \uc0ac\uc2e4\uc801\uc778 \ub514\ud14c\uc77c\uc744 \uc720\uc9c0\ud558\uba74\uc11c \uace0\ud488\uc9c8 \uc601\uc0c1\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "A. Visual Examples"}, {"figure_path": "https://arxiv.org/html/2412.09856/x14.png", "caption": "Figure 14: Comparisons with typical open-source video generative models.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc77c\ubc18\uc801\uc778 \uc624\ud508 \uc18c\uc2a4 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uacfc LinGen\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LinGen\uc774 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \ud488\uc9c8\uc774 \ub2e4\ub978 \uc624\ud508 \uc18c\uc2a4 \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ube44\ub514\uc624\uc5d0\ub294 \ud504\ub86c\ud504\ud2b8\uac00 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70 LinGen\uc740 \ud504\ub86c\ud504\ud2b8\ub97c \ub354 \uc798 \ub530\ub974\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x15.png", "caption": "Figure 15: Comparisons with state-of-the-art accessible commercial models.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen-4B \ubaa8\ub378\uacfc \ub2e4\ub978 \ucd5c\ucca8\ub2e8 \uc0c1\uc6a9 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378(Gen-3, LumaLabs, Kling)\uc5d0\uc11c \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LinGen-4B\ub294 \ub2e4\ub978 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \ud488\uc9c8\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\uba74\uc11c \uc120\ud615 \uacc4\uc0b0 \ubcf5\uc7a1\uc131\uacfc \ud45c\uc900 DiT \uc544\ud0a4\ud14d\ucc98\uc5d0 \ube44\ud574 \uc0c1\ub2f9\ud55c \uc18d\ub3c4 \ud5a5\uc0c1\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x16.png", "caption": "Figure 16: Comparisons with existing trials on generating minute-length videos.", "description": "\uc774 \uadf8\ub9bc\uc740 1\ubd84 \uae38\uc774\uc758 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \ub300\ud55c \uae30\uc874 \uc5f0\uad6c \uacb0\uacfc\uc640\uc758 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, Loong\uacfc PA-VDM\uc785\ub2c8\ub2e4. PA-VDM\uc740 \ud504\ub86c\ud504\ud2b8\ub97c \uc81c\uacf5\ud558\uc9c0 \uc54a\uc73c\ubbc0\ub85c LinGen\uc5d0\uc11c \uc0dd\uc131\ub41c \uc720\uc0ac\ud55c \ube44\ub514\uc624\ub97c \ucc3e\uc558\uc2b5\ub2c8\ub2e4. LinGen\uc758 \uacb0\uacfc\ub294 \ucd5c\ucca8\ub2e8 \uc0c1\uc5c5\uc6a9 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ubc18\uba74 Loong\uc758 \uacb0\uacfc\ub294 \ud488\uc9c8\uc774 \ub0ae\uc2b5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2412.09856/x17.png", "caption": "Figure 17: Visual examples of ablation experiments on the TESA block, RMS, and review tokens.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen \ubaa8\ub378\uc5d0\uc11c TESA \ube14\ub85d, RMS, \ub9ac\ubdf0 \ud1a0\ud070\uc758 \ud6a8\uacfc\ub97c \uac80\uc99d\ud558\uae30 \uc704\ud55c ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \ud589\uc740 256p \ud574\uc0c1\ub3c4, 17\ucd08 \uae38\uc774\uc758 \ube44\ub514\uc624\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\uc774\uace0 \ub450 \ubc88\uc9f8 \ud589\uc740 512p \ud574\uc0c1\ub3c4, 68\ucd08 \uae38\uc774\uc758 \ube44\ub514\uc624\uc5d0 \ub300\ud55c ablation study \uacb0\uacfc\uc785\ub2c8\ub2e4. \uac01 \ud589\uc5d0\uc11c \uc67c\ucabd\uc740 TESA \ube14\ub85d\uacfc RMS\ub97c \uc81c\uac70\ud55c \uacb0\uacfc, \uc911\uac04\uc740 \ub9ac\ubdf0 \ud1a0\ud070\uc744 \uc81c\uac70\ud55c \uacb0\uacfc, \uc624\ub978\ucabd\uc740 LinGen\uc758 \ucd5c\uc885 \uacb0\uacfc\uc785\ub2c8\ub2e4. \uc774 ablation study\ub97c \ud1b5\ud574 TESA \ube14\ub85d, RMS, \ub9ac\ubdf0 \ud1a0\ud070\uc774 \uc0dd\uc131\ub418\ub294 \ube44\ub514\uc624\uc758 \ud488\uc9c8\uacfc \uc77c\uad00\uc131\uc5d0 \uae0d\uc815\uc801\uc778 \uc601\ud5a5\uc744 \ubbf8\uce5c\ub2e4\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.5. Ablation Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x18.png", "caption": "Figure 18: Visual examples of ablation experiments on hybrid training and quality-tuning.", "description": "\uc774 \uadf8\ub9bc\uc740 \ud558\uc774\ube0c\ub9ac\ub4dc \ud559\uc2b5\uacfc \ud488\uc9c8 \ud29c\ub2dd\uc5d0 \ub300\ud55c \uc808\uc81c \uc2e4\ud5d8\uc758 \uc2dc\uac01\uc801 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. 256p \ud574\uc0c1\ub3c4\uc5d0\uc11c \uc77c\uad00\uc131\uc774 \ube44\uc815\uc0c1\uc801\uc73c\ub85c \ub098\uc05c \uc2e4\ud328 \uc0ac\ub840\uc640 512p \ud574\uc0c1\ub3c4\uc5d0\uc11c \ud488\uc9c8\uc774 \ube44\uc815\uc0c1\uc801\uc73c\ub85c \ub098\uc05c \uc2e4\ud328 \uc0ac\ub840\ub97c \uac01\uac01 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud558\uc774\ube0c\ub9ac\ub4dc \ud559\uc2b5\uc740 \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc640 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \ub370\uc774\ud130\ub97c \ubaa8\ub450 \uc0ac\uc6a9\ud558\uc5ec \ud559\uc2b5\ud558\ub294 \uac83\uc744 \ub9d0\ud558\uba70, \ud488\uc9c8 \ud29c\ub2dd\uc740 \uace0\ud488\uc9c8 \ube44\ub514\uc624 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubaa8\ub378\uc744 \ubbf8\uc138 \uc870\uc815\ud558\ub294 \uac83\uc744 \ub9d0\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x19.png", "caption": "Figure 19: Win rates of human evaluation of quality and text-video alignment of videos generated by LinGen and typical open-source video generative models.", "description": "\uc774 \uadf8\ub9bc\uc740 LinGen\uacfc \ub2e4\ub978 \uc624\ud508 \uc18c\uc2a4 \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ube44\ub514\uc624\uc758 \ud488\uc9c8 \ubc0f \ud14d\uc2a4\ud2b8-\ube44\ub514\uc624 \uc815\ub82c\uc5d0 \ub300\ud55c \uc778\uac04 \ud3c9\uac00 \uacb0\uacfc\ub97c \ub9c9\ub300 \uadf8\ub798\ud504\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. LinGen\uc740 \ub2e4\ub978 \ubaa8\ub378\ubcf4\ub2e4 \ud488\uc9c8 \ubc0f \uc815\ub82c \uce21\uba74\uc5d0\uc11c \ub354 \ub192\uc740 \uc810\uc218\ub97c \ubc1b\uc558\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.09856/x20.png", "caption": "Figure 20: Latency of generating 512p 17s videos with different model designs. The latency of LinGen models scales more slowly with model size than self-attention-based standard DiT models. Note that we perform 100 inference steps to measure average latency. This is different from the default setting of 50 steps employed in our main paper.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378 \ub514\uc790\uc778\uc73c\ub85c 512p \ud574\uc0c1\ub3c4, 17\ucd08 \uae38\uc774\uc758 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uac78\ub9ac\ub294 \uc9c0\uc5f0 \uc2dc\uac04\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. LinGen \ubaa8\ub378\uc758 \uc9c0\uc5f0 \uc2dc\uac04\uc740 \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub530\ub77c self-attention \uae30\ubc18\uc758 \ud45c\uc900 DiT \ubaa8\ub378\ubcf4\ub2e4 \ub354 \ub290\ub9ac\uac8c \uc99d\uac00\ud569\ub2c8\ub2e4. \ud3c9\uade0 \uc9c0\uc5f0 \uc2dc\uac04\uc744 \uce21\uc815\ud558\uae30 \uc704\ud574 100\ud68c\uc758 \ucd94\ub860 \ub2e8\uacc4\ub97c \uc218\ud589\ud588\uc73c\uba70, \uc774\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uae30\ubcf8 \uc124\uc815\uc778 50\ub2e8\uacc4\uc640 \ub2e4\ub985\ub2c8\ub2e4.", "section": "Supplementary Material"}]