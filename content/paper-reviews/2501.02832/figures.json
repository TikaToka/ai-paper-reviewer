[{"figure_path": "https://arxiv.org/html/2501.02832/extracted/6115352/MAMBA-ASR.drawio_V1.png", "caption": "Figure 1: Architecture diagram (original) of the Samba-ASR model, illustrating the key components including the Mamba encoder, which processes raw audio features using Mamba blocks, and the Mamba decoder along with the Mamba-Cross-Connection bridge, which generates transcriptions by integrating audio context with text representations. The model\u2019s design focuses on efficient long-range dependency capture for accurate automatic speech recognition.", "description": "\uadf8\ub9bc 1\uc740 Samba-ASR \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98 \ub2e4\uc774\uc5b4\uadf8\ub7a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\ub294 \ub9d8\ubc14 \ube14\ub85d(Mamba blocks)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc6d0\uc2dc \uc624\ub514\uc624 \ud2b9\uc9d5\uc744 \ucc98\ub9ac\ud558\ub294 \ub9d8\ubc14 \uc778\ucf54\ub354(Mamba encoder)\uc640 \ub9d8\ubc14-\ud06c\ub85c\uc2a4-\ucee4\ub125\uc158(Mamba-Cross-Connection) \ube0c\ub9ac\uc9c0\ub97c \ud1b5\ud574 \uc624\ub514\uc624 \ucee8\ud14d\uc2a4\ud2b8\uc640 \ud14d\uc2a4\ud2b8 \ud45c\ud604\uc744 \ud1b5\ud569\ud558\uc5ec \uc804\uc0ac\ub97c \uc0dd\uc131\ud558\ub294 \ub9d8\ubc14 \ub514\ucf54\ub354(Mamba decoder)\uc785\ub2c8\ub2e4. \ubaa8\ub378\uc758 \uc124\uacc4\ub294 \uc815\ud655\ud55c \uc790\ub3d9 \uc74c\uc131 \uc778\uc2dd\uc744 \uc704\ud55c \ud6a8\uc728\uc801\uc778 \uc7a5\uae30 \uc758\uc874\uc131 \ud3ec\ucc29\uc5d0 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4. \ub9d8\ubc14 \uc778\ucf54\ub354\ub294 \ucee8\ubcfc\ub8e8\uc158 \ub808\uc774\uc5b4\ub97c \ud1b5\ud574 \uc624\ub514\uc624 \uc2e0\ud638\uc758 \uad6d\uc18c\uc801 \ud328\ud134\uc744 \ucea1\ucc98\ud558\uace0, \ub9d8\ubc14 \ube14\ub85d\uc740 \uc7a5\uae30 \uc758\uc874\uc131\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1\ud569\ub2c8\ub2e4. \ub9d8\ubc14 \ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354\uc758 \ucd9c\ub825\uacfc \uc774\uc804\uc5d0 \uc0dd\uc131\ub41c \ud1a0\ud070\uc744 \uc870\uac74\uc73c\ub85c \ud558\uc5ec \ud14d\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \ub9d8\ubc14-\ud06c\ub85c\uc2a4-\ucee4\ub125\uc158 \ube0c\ub9ac\uc9c0\ub294 \uc624\ub514\uc624\uc640 \ud14d\uc2a4\ud2b8 \uc0ac\uc774\uc758 \uad00\uacc4\ub97c \uba85\ud655\ud788 \ud574\uc8fc\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4. \uc774 \ub2e4\uc774\uc5b4\uadf8\ub7a8\uc740 Samba-ASR\uc774 \uc624\ub514\uc624 \uc2e0\ud638\uc758 \uc7a5\uae30 \uc758\uc874\uc131\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\ub294 \ubc29\ubc95\uc744 \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 Samba-ASR: Architecture"}, {"figure_path": "https://arxiv.org/html/2501.02832/extracted/6115352/EpochvsLoss.png", "caption": "Figure 2: This graph shows the correlation of training and validation loss across epochs, with both losses steadily decreasing and converging around the 72nd epoch.", "description": "\uadf8\ub9bc 2\ub294 \uc5d0\ud3ed\uc5d0 \ub530\ub978 \ud559\uc2b5 \ubc0f \uac80\uc99d \uc190\uc2e4\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub450 \uc190\uc2e4 \ubaa8\ub450 \uafb8\uc900\ud788 \uac10\uc18c\ud558\uc5ec 72\ubc88\uc9f8 \uc5d0\ud3ed\uc5d0\uc11c \uc218\ub834\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uc548\uc815\uc801\uc73c\ub85c \ud559\uc2b5\ub418\uc5c8\uace0 \uacfc\uc801\ud569 \uc5c6\uc774 \uc77c\ubc18\ud654\ub420 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.  x\ucd95\uc740 \uc5d0\ud3ed(\ud559\uc2b5 \ubc18\ubcf5 \ud69f\uc218), y\ucd95\uc740 \uc190\uc2e4 \uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "7 \ud3c9\uac00 \ubc0f \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.02832/extracted/6115352/EpochvsWER.png", "caption": "Figure 3: This graph demonstrates a significant reduction in Word Error Rate (WER) throughout the training process, indicating improved model performance and accuracy.", "description": "\uadf8\ub9bc 3\uc740 \ud559\uc2b5 \uacfc\uc815 \uc804\ubc18\uc5d0 \uac78\uccd0 \ub2e8\uc5b4 \uc624\ub958\uc728(WER)\uc774 \ud06c\uac8c \uac10\uc18c\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378 \uc131\ub2a5\uacfc \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\uc5c8\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. WER\uc740 \uc74c\uc131 \uc778\uc2dd \uc2dc\uc2a4\ud15c\uc758 \uc131\ub2a5\uc744 \uce21\uc815\ud558\ub294 \uc8fc\uc694 \uc9c0\ud45c\ub85c, WER \uac12\uc774 \ub0ae\uc744\uc218\ub85d \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\uac00 \ub192\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \uc5d0\ud3ec\ud06c(epoch)\ubcc4 WER \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294\ub370, \uc5d0\ud3ec\ud06c\uac00 \uc99d\uac00\ud560\uc218\ub85d WER\uc774 \uafb8\uc900\ud788 \uac10\uc18c\ud558\ub294 \ucd94\uc138\ub97c \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \ud559\uc2b5 \ub370\uc774\ud130\uc5d0 \uc798 \uc801\uc751\ud558\uace0, \uc74c\uc131 \uc778\uc2dd \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "7 Evaluation and Results"}]