[{"content": "| Model | Train/Claimed |  | En.Sum | En.QA | En.MC | AVG. |  | NIAH | VT | QA | AVG. |  | LongBench-Chat (EN) |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| GPT-4-128K | 128K |  | 14.73 | 22.44 | 67.25 | 34.81 |  | 95.4 | 99.9 | 70.3 | 88.53 |  | 8.40 |\n| Qwen2-72B | 128K |  | 24.32<sup>\u266d</sup> | 7.03<sup>\u266d</sup> | 72.05<sup>\u266d</sup> | 34.47<sup>\u266d</sup> |  | 88.6 | 95.7 | 66.7 | 83.67 |  | 7.72<sup>\u266d</sup> |\n| LLaMA 3.1-70B | 128K |  | 33.55<sup>\u266d</sup> | 36.08<sup>\u266d</sup> | 69.00<sup>\u266d</sup> | 46.21<sup>\u266d</sup> |  | 96.1 | 93.2 | 67.8 | 85.7 |  | 6.67<sup>\u266d</sup> |\n| LLaMA 3.1-8B | 128K |  | 28.06<sup>\u266d</sup> | 30.47<sup>\u266d</sup> | 58.08<sup>\u266d</sup> | 38.87<sup>\u266d</sup> |  | 97.93 | 91.4 | 64.7 | 84.68 |  | 6.22<sup>\u266d</sup> |\n| GLM-4-9B | 128K |  | 14.84<sup>\u266d</sup> | 9.51<sup>\u266d</sup> | 67.25<sup>\u266d</sup> | 30.53<sup>\u266d</sup> |  | 96.51<sup>\u266d</sup> | 97.3<sup>\u266d</sup> | 64.8<sup>\u266d</sup>0 | 86.20<sup>\u266d</sup> |  | 5.67<sup>\u266d</sup> |\n| GLM-4-9B-1M | 1M |  | 28.3 | 9.7 | 68.6 | 35.53 |  | 98.2 | 99.4 | 69.4 | 89.0 |  | 5.03<sup>\u266d</sup> |\n| LWM-7B-1M | 1M |  | 4.33<sup>\u266d</sup> | 0.0<sup>\u266d</sup> | 3.06<sup>\u266d</sup> | 2.46<sup>\u266d</sup> |  | 87.20 | 57.5 | 56.4 | 67.03 |  | 1.25<sup>\u266d</sup> |\n| YaRN-Mistral-7B | 128K |  | 9.09 | 9.55 | 27.95 | 15.53 |  | 63.4 | 36.1 | 25.9 | 41.8 |  | - |\n| \\hdashlineMistral-7B | 32K |  | 22.13 | 4.93 | 14.41 | 13.82 |  | 72.60 | 74.40 | 52.2 | 66.4 |  | 4.10 |\n| - SFT | 128K |  | 23.44 | 13.45 | 53.21 | 30.03 |  | 88.73 | 79.64 | 51.08 | 73.15 |  | 4.25 |\n| - DPO | 128K |  | 15.21 | 10.34 | 48.14 | 25.56 |  | 74.25 | 72.36 | 50.24 | 65.62 |  | 4.08 |\n| - LongPO (iter1) | 128K |  | 27.05 | 23.51 | 67.25 | 39.27 |  | 96.88 | 96.49 | 64.81 | 86.06 |  | 5.42 |\n| - LongPO (iter2) | 256K |  | 28.16 | 24.43 | 66.35 | 39.65 |  | 96.80 | 97.0 | 64.87 | 86.22 |  | 5.48 |\n| - LongPO (iter3) | 512K |  | 29.10 | 27.85 | 66.67 | 41.21 |  | 97.28 | 97.48 | 64.92 | 86.56 |  | 5.80 |\n| \\hdashlineQwen2.5-7B | 128K |  | 22.89 | 6.08 | 52.4 | 27.12 |  | 82.1 | 80.09 | 54.30 | 72.16 |  | 5.80 |\n| - LongPO (iter1) | 128K |  | 32.06 | 17.32 | 72.05 | 40.48 |  | 95.81 | 89.71 | 59.4 | 81.64 |  | 5.75 |", "caption": "Table 1: Long-Context Performance of our LongPO compared with baselines. Higher is better for all metrics. Results marked with \u266d\u266d\\flat\u266d are evaluated by ourselves, while other results of baselines are sourced from the original benchmarks. Full results on RULER are listed in\u00a0Table\u00a02.", "description": "\ud45c 1\uc740 LongPO\uc758 \uc7a5\uc810\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  LongPO \ubaa8\ub378\uacfc \uae30\uc900 \ubaa8\ub378\ub4e4\uc758 \uae34 \ucee8\ud14d\uc2a4\ud2b8 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec LongPO\uc758 \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub4e0 \uc9c0\ud45c\uc5d0\uc11c \ub192\uc744\uc218\ub85d \uc131\ub2a5\uc774 \uc88b\uc73c\uba70, \u266d\u266d \uae30\ud638\uac00 \ubd99\uc740 \uacb0\uacfc\ub294 \uc5f0\uad6c\ud300\uc774 \uc9c1\uc811 \ud3c9\uac00\ud55c \uac83\uc774\uace0, \ub098\uba38\uc9c0\ub294 \uc6d0 \ub17c\ubb38\uc758 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uac00\uc838\uc628 \uac83\uc785\ub2c8\ub2e4.  RULER \ubca4\uce58\ub9c8\ud06c\uc758 \uc790\uc138\ud55c \uacb0\uacfc\ub294 \ud45c 2\uc5d0 \ub098\uc640\uc788\uc2b5\ub2c8\ub2e4.  LongPO\ub294 \ub2e4\uc591\ud55c \uae34 \ucee8\ud14d\uc2a4\ud2b8 \uc791\uc5c5\uc5d0\uc11c \uae30\uc900 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Model | Category | 4k | 8k | 16k | 32k | 64k | 128k | AVG |\n|---|---|---|---|---|---|---|---|---|\n| Qwen2.5-7B-Instruct | NIAH | 99.69 | 98.45 | 97.82 | 95.24 | 74.56 | 26.86 | 82.10 |\n|  | VT | 99.88 | 99.72 | 96.24 | 96.44 | 81.44 | 6.84 | 80.09 |\n|  | AGG | 92.52 | 89.78 | 92.08 | 81.93 | 62.48 | 28.23 | 74.50 |\n|  | QA | 71.00 | 65.30 | 64.00 | 58.70 | 46.80 | 19.99 | 54.30 |\n|  | AVG (13 tasks) | 94.19 | 92.11 | 91.61 | 87.66 | 68.96 | 24.47 | **76.50** |\n| Qwen2.5-7B-LongPO-128K | NIAH | 99.64 | 98.97 | 97.80 | 95.54 | 94.80 | 88.15 | 95.82 |\n|  | VT | 99.96 | 99.92 | 96.12 | 86.24 | 78.20 | 77.80 | 89.71 |\n|  | AGG | 95.50 | 86.12 | 91.75 | 82.56 | 66.31 | 49.81 | 78.67 |\n|  | QA | 70.00 | 64.00 | 62.70 | 57.70 | 53.00 | 49.00 | 59.40 |\n|  | AVG (13 tasks) | 94.47 | 91.69 | 91.34 | 87.00 | 82.71 | 75.43 | **87.11** |\n| Mistral-7B-LongPO-128K | NIAH | 99.43 | 98.64 | 98.09 | 97.84 | 95.82 | 91.44 | 96.88 |\n|  | VT | 99.40 | 99.16 | 98.08 | 96.36 | 92.80 | 93.12 | 96.49 |\n|  | AGG | 88.31 | 82.91 | 92.23 | 72.775 | 46.305 | 46.79 | 71.55 |\n|  | QA | 71.10 | 70.15 | 66.60 | 65.80 | 61.00 | 54.20 | 64.81 |\n|  | AVG (13 tasks) | 93.36 | 91.88 | 92.35 | 88.94 | 82.61 | 78.97 | **88.02** |\n| Mistral-7B-LongPO-256K | NIAH | 99.16 | 97.79 | 98.02 | 97.76 | 96.53 | 91.54 | 96.80 |\n|  | VT | 99.40 | 99.20 | 97.96 | 97.72 | 94.21 | 93.52 | 97.00 |\n|  | AGG | 87.40 | 76.59 | 89.03 | 72.20 | 45.17 | 44.47 | 69.14 |\n|  | QA | 71.50 | 69.50 | 66.70 | 64.30 | 60.80 | 56.40 | 64.87 |\n|  | AVG (13 tasks) | 93.11 | 90.28 | 91.81 | 88.68 | 82.95 | 79.04 | **87.65** |\n| Mistral-7B-LongPO-512K | NIAH | 99.19 | 97.78 | 98.06 | 97.69 | 96.62 | 94.36 | 97.28 |\n|  | VT | 99.44 | 99.16 | 98.04 | 97.80 | 95.92 | 94.52 | 97.48 |\n|  | AGG | 87.56 | 76.71 | 88.95 | 72.70 | 44.93 | 44.51 | 69.22 |\n|  | QA | 71.40 | 69.50 | 66.40 | 64.50 | 60.60 | 57.10 | 64.92 |\n|  | AVG (13 tasks) | 93.14 | 90.29 | 91.78 | 88.75 | 83.07 | 80.97 | **88.00** |", "caption": "Table 2: Full results on 13 tasks of RULER benchmark. The bold values denote the average score of 13 tasks in RULER over various context lengths.", "description": "\ud45c 2\ub294 RULER \ubca4\uce58\ub9c8\ud06c\uc758 13\uac00\uc9c0 \uacfc\uc81c\uc5d0 \ub300\ud55c \uc804\uccb4 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubb38\ub9e5 \uae38\uc774\uc5d0\uc11c \uc218\ud589\ub41c 13\uac00\uc9c0 \uacfc\uc81c\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc810\uc218\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uad75\uc740 \uac12\uc740 \ub2e4\uc591\ud55c \ubb38\ub9e5 \uae38\uc774\uc5d0 \uac78\uccd0 13\uac00\uc9c0 \uacfc\uc81c\uc758 \ud3c9\uade0 \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  RULER \ubca4\uce58\ub9c8\ud06c\ub294 \ub2e4\uc591\ud55c \uae38\uc774(4K, 8K, 16K, 32K, 64K, 128K)\uc758 \ubb38\ub9e5\uc744 \uc0ac\uc6a9\ud558\ub294 \ub124 \uac00\uc9c0 \uc885\ub958\uc758 \ud569\uc131 \uacfc\uc81c (Needle-in-a-haystack \uac80\uc0c9, \uac00\ubcc0 \ucd94\uc801 \ub2e4\ub2e8\uacc4 \ucd94\uc801, \uc9d1\uacc4 \ubc0f \uc9c8\uc758\uc751\ub2f5)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \ud45c\ub294 \uac01 \ubaa8\ub378(Qwen2.5-7B-Instruct, Qwen2.5-7B-LongPO-128K, Mistral-7B-LongPO-128K, Mistral-7B-LongPO-256K, Mistral-7B-LongPO-512K)\uc758 \uac01 \uacfc\uc81c \ubc0f \ubb38\ub9e5 \uae38\uc774\uc5d0 \ub300\ud55c \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c"}, {"content": "| Model | MMLU | ARC-C | Hellaswag | Winogrande | MT-Bench |\n|---|---|---|---|---|---| \n| Mistral-7B-Instruct-v0.2 | 59.15 | 59.26 | 83.2 | 78.4 | 6.34 |\n| Mistral-7B-LongPO-128K | 59.99 | 59.34 | 82.99 | 78.53 | 6.35 |\n| Mistral-7B-LongPO-256K | 59.47 | 60.28 | 83.14 | 78.14 | 6.38 |\n| Mistral-7B-LongPO-512K | 59.51 | 60.58 | 82.87 | 77.66 | 6.34 |\n| Qwen2.5-7B-Instruct | 74.28 | 67.15 | 81.41 | 74.66 | 7.30 |\n| Qwen2.5-7B-LongPO-128K | 73.64 | 65.70 | 80.82 | 74.98 | 7.62 |", "caption": "Table 3: Performance on short-context tasks.", "description": "\ud45c 3\uc740 \ub2e8\uc77c \ub9e5\ub77d(short-context) \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ub2e4\uc591\ud55c \ub2e8\uc77c \ub9e5\ub77d \uc5b8\uc5b4 \uc774\ud574 \ubc0f \ucd94\ub860 \ubca4\uce58\ub9c8\ud06c(MMLU, ARC-C, Hellaswag, Winogrande)\uc640 \uc9c0\uce68 \ub530\ub974\uae30 \ubca4\uce58\ub9c8\ud06c(MT-Bench)\uc5d0\uc11c Mistral-7B \uae30\ubcf8 \ubaa8\ub378\uacfc LongPO\ub85c \uc870\uc815\ub41c Mistral-7B \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec LongPO\uac00 \ub2e8\uc77c \ub9e5\ub77d \uc131\ub2a5\uc744 \uc720\uc9c0\ud558\uba74\uc11c \uc7a5\ubb38 \ub9e5\ub77d(long-context) \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.2 \ud3c9\uac00 \ubca4\uce58\ub9c8\ud06c"}]