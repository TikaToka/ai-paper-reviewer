{"references": [{"fullname_first_author": "Fran\u00e7ois Chollet", "paper_title": "On the Measure of Intelligence", "publication_date": "2019-11-00", "reason": "This paper proposes a benchmark for evaluating AI systems' reasoning and abstraction abilities, providing a relevant comparison to the proposed benchmark in this paper."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training Verifiers to Solve Math Word Problems", "publication_date": "2021-11-00", "reason": "This paper introduces a benchmark focusing on mathematical problem-solving, which is a key area of reasoning that the authors compare their results to."}, {"fullname_first_author": "DeepSeek-AI", "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", "publication_date": "2025-01-00", "reason": "This paper presents a state-of-the-art reasoning model that the current paper directly benchmarks against and analyzes."}, {"fullname_first_author": "Google", "paper_title": "Gemini 2.0 Flash Thinking Experimental", "publication_date": "2024-12-00", "reason": "This paper introduces another state-of-the-art reasoning model used for comparison in the current paper's benchmark."}, {"fullname_first_author": "Aryan Gulati", "paper_title": "Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning", "publication_date": "2024-10-00", "reason": "This paper introduces a challenging mathematical reasoning benchmark, useful for comparative analysis with the proposed benchmark in this paper."}]}