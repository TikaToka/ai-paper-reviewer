[{"figure_path": "https://arxiv.org/html/2412.14233/x1.png", "caption": "Figure 1: (a) We present a comparison of captions from DCE, human, and generalist LMM models annotations, including InternVL2-26B, LLaVA-NeXT, and GPT-4V. (b) visualizes the extent to which the captions in (a) describe multiple objects and various attributes, including Objects 1-8, Object Attributes, OCR, HOI, 2D spatial relations and 3D spatial relations.", "description": "\uadf8\ub9bc 1\uc740 \uc774\ubbf8\uc9c0 \ucea1\uc158 \uc0dd\uc131 \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\ub294 DCE(Descriptive Caption Enhancement Engine), \uc0ac\ub78c, \uadf8\ub9ac\uace0 InternVL2-26B, LLaVA-NeXT, GPT-4V\uc640 \uac19\uc740 \uc77c\ubc18\uc801\uc778 LMM(Large Multimodality Model) \uc138 \uac00\uc9c0 \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0 \ucea1\uc158\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. (b)\ub294 (a)\uc5d0\uc11c \uc0dd\uc131\ub41c \ucea1\uc158\ub4e4\uc774 \uc5bc\ub9c8\ub098 \ub2e4\uc591\ud55c \uac1d\uccb4\uc640 \uc18d\uc131\ub4e4\uc744 \uae30\uc220\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\uae30\uc5d0\ub294 \uac1d\uccb4 1~8, \uac1d\uccb4 \uc18d\uc131, OCR \uc815\ubcf4, HOI(Human-Object Interaction), 2D \ubc0f 3D \uacf5\uac04 \uad00\uacc4 \ub4f1\uc774 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uadf8\ub9bc\uc744 \ud1b5\ud574 \uac01 \ubc29\ubc95\uc774 \uc774\ubbf8\uc9c0\uc758 \ub2e4\uc591\ud55c \uce21\uba74\uc744 \uc5bc\ub9c8\ub098 \uc798 \ud3ec\ucc29\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 DCE\uac00 \ub2e4\ub978 \ubc29\ubc95\uc5d0 \ube44\ud574 \uc5bc\ub9c8\ub098 \ub354 \ud48d\ubd80\ud558\uace0 \uc815\ud655\ud55c \ucea1\uc158\uc744 \uc0dd\uc131\ud558\ub294\uc9c0\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.14233/x2.png", "caption": "Figure 2: Comparisons of caption quality. (a) and (b) show the downstream task performance of LLaVA-v1.5 and LLaVA-NeXT after pretraining with different image captions.", "description": "\uadf8\ub9bc 2\ub294 \uc11c\ub85c \ub2e4\ub978 \uc774\ubbf8\uc9c0 \ucea1\uc158\uc73c\ub85c \uc0ac\uc804 \ud6c8\ub828\ud55c \ud6c4 LLaVA-v1.5 \ubc0f LLaVA-NeXT\uc758 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\uc640 (b)\ub294 \uac01\uac01 LLaVA-v1.5\uc640 LLaVA-NeXT \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \ucea1\uc158\uc73c\ub85c \ud6c8\ub828\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ube44\uad50 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \ucea1\uc158 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc0ac\uc804 \ud6c8\ub828\uc774 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uac01 \uadf8\ub798\ud504\ub294 \uc5ec\ub7ec \uac00\uc9c0 \ubca4\uce58\ub9c8\ud06c \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5 \uc810\uc218\ub97c \ub098\ud0c0\ub0b4\uba70,  \uc778\uac04\uc774 \uc791\uc131\ud55c \ucea1\uc158,  \uae30\uc874\uc758 LMM(Large Multimodality Model)\uc5d0\uc11c \uc0dd\uc131\ud55c \ucea1\uc158, \uadf8\ub9ac\uace0 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 DCE(Descriptive Caption Enhancement) \uae30\ubc95\uc744 \ud1b5\ud574 \uac1c\uc120\ub41c \ucea1\uc158\uc744 \uc0ac\uc6a9\ud55c \uacbd\uc6b0\uc758 \uacb0\uacfc\ub97c \ube44\uad50\ud569\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 DCE\uac00 \uc774\ubbf8\uc9c0 \ucea1\uc158\uc758 \uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uace0, \uadf8 \uacb0\uacfc \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc758 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2. \uad00\ub828 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2412.14233/x3.png", "caption": "Figure 3: The DCE pipeline first utilizes various visual specialists to extract both Object and Relation attributes. Then, it uses an LLM to integrate the object attributes into detailed region captions, followed by combining the region captions with relational attributes to generate a comprehensive image caption.", "description": "\uadf8\ub9bc 3\uc740 DCE \ud30c\uc774\ud504\ub77c\uc778\uc758 \uc804\uccb4 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc804\ubb38\uac00 \ubaa8\ub378(Visual Specialists)\uc744 \ud65c\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac1d\uccb4(Object)\uc640 \uad00\uacc4(Relation) \uc18d\uc131\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4.  \ucd94\ucd9c\ub41c \uac1d\uccb4 \uc18d\uc131\uc740 \ub300\ud615 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc744 \uc774\uc6a9\ud558\uc5ec \uc0c1\uc138\ud55c \uc601\uc5ed\ubcc4 \ucea1\uc158(detailed region captions)\uc73c\ub85c \ud1b5\ud569\ub429\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc601\uc5ed\ubcc4 \ucea1\uc158\uacfc \uad00\uacc4 \uc18d\uc131\uc744 \uacb0\ud569\ud558\uc5ec \ud3ec\uad04\uc801\uc778 \uc774\ubbf8\uc9c0 \ucea1\uc158\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uc989, \uc2dc\uac01\uc801 \uc804\ubb38\uac00 \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0\uc758 \uc138\ubd80 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uace0, LLM\uc774 \uc774 \uc815\ubcf4\ub4e4\uc744 \uc885\ud569\ud558\uc5ec \ud48d\ubd80\ud558\uace0 \uc815\ud655\ud55c \uc124\uba85\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "3. Approach"}, {"figure_path": "https://arxiv.org/html/2412.14233/x4.png", "caption": "Figure 4: The prompt for using LLM\nto generate an region caption\nby considering object attributes and\nreference captions.", "description": "\uadf8\ub9bc 4\ub294 LLM(Large Language Model)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac1d\uccb4 \uc18d\uc131\uacfc \ucc38\uc870 \ucea1\uc158\uc744 \uace0\ub824\ud558\uc5ec \uc138\ubd80\uc801\uc778 \uc601\uc5ed \ucea1\uc158\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ud504\ub86c\ud504\ud2b8(\uba85\ub839\uc5b4)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLM\uc5d0\uac8c \uc804\ub2ec\ub418\ub294 \ud504\ub86c\ud504\ud2b8\ub294 \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0\uc640 \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0 \ub450 \ubd80\ubd84\uc73c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc2dc\uc2a4\ud15c \uba54\uc2dc\uc9c0\ub294 LLM\uc5d0\uac8c \uc5ec\ub7ec \uc2dc\uac01\uc801 \uc18d\uc131\uc744 \uacb0\ud569\ud558\uc5ec \uc0c1\uc138\ud55c \uc601\uc5ed \ucea1\uc158\uc744 \uc0dd\uc131\ud558\ub294 AI \uc2dc\uac01 \ubcf4\uc870 \uc5ed\ud560\uc744 \ubd80\uc5ec\ud569\ub2c8\ub2e4. \ucc38\uc870 \ucea1\uc158\uacfc \ub2e4\uc591\ud55c \uc2dc\uac01 \uc804\ubb38\uac00(visual specialists)\uac00 \uc81c\uacf5\ud558\ub294 \uac1d\uccb4 \uc18d\uc131\uc744 \ud1b5\ud569\ud558\uc5ec \ud3ec\uad04\uc801\uc774\uace0 \uc77c\uad00\uc131 \uc788\ub294 \uc124\uba85\uc744 \uc0dd\uc131\ud558\ub3c4\ub85d \uc9c0\uc2dc\ud569\ub2c8\ub2e4.  \uc0ac\uc6a9\uc790 \uba54\uc2dc\uc9c0\ub294 \uc2e4\uc81c\ub85c LLM\uc5d0\uac8c \uc804\ub2ec\ub418\ub294 \ud504\ub86c\ud504\ud2b8\ub85c, \ucc38\uc870 \ucea1\uc158\uacfc \uac1d\uccb4\uc758 \uc18d\uc131(\uac1d\uccb4 \uc885\ub958, \uac10\uc815, OCR \uc815\ubcf4, \uc138\ubd80 \ubd84\ub958\ub41c \ud56d\uacf5\uae30, \ub3d9\ubb3c, \uc2dd\ubb3c, \ub85c\uace0 \ub4f1)\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ud504\ub86c\ud504\ud2b8\ub294 LLM\uc774 \uc774\ubbf8\uc9c0\uc758 \uac01 \uc601\uc5ed\uc5d0 \ub300\ud55c \ud48d\ubd80\ud558\uace0 \uc815\ud655\ud55c \uc124\uba85\uc744 \uc0dd\uc131\ud558\ub294 \ub370 \ud544\uc694\ud55c \ubaa8\ub4e0 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3. \uc811\uadfc \ubc29\uc2dd"}, {"figure_path": "https://arxiv.org/html/2412.14233/x5.png", "caption": "Figure 5: The prompt for LLM\nto generate an image caption\nby considering relation attributes, region location information and captions.", "description": "\uadf8\ub9bc 5\ub294 LLM(Large Language Model)\uc774 \uc774\ubbf8\uc9c0 \ucea1\uc158\uc744 \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLM\uc740 \uc774\ubbf8\uc9c0\uc758 \uc804\uccb4\uc801\uc778 \uc124\uba85\uacfc \uc5ec\ub7ec \uac1c\uc758 \uc9c0\uc5ed\uc801 \uc124\uba85\uc744 \uc785\ub825\ubc1b\uc2b5\ub2c8\ub2e4. \uc9c0\uc5ed\uc801 \uc124\uba85\uc740 \uc774\ubbf8\uc9c0 \uc601\uc5ed\uc758 \uc704\uce58 \uc815\ubcf4(\uc88c\ud45c)\uc640 \ud574\ub2f9 \uc601\uc5ed\uc758 \uc0c1\uc138 \uc124\uba85\uc73c\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. LLM\uc740 \uc804\uccb4 \uc124\uba85\uacfc \uc9c0\uc5ed\ubcc4 \uc124\uba85\uc758 \uac1d\uccb4\ub4e4\uc744 \uc5f0\uacb0\ud558\uc5ec \uc911\ubcf5 \uc5c6\uc774 \ubaa8\ub4e0 \uad00\ub828 \uc815\ubcf4\ub97c \ud1b5\ud569\ud55c \uc644\uc131\ub3c4 \ub192\uc740 \uc774\ubbf8\uc9c0 \ucea1\uc158\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \uac01 \uc9c0\uc5ed \uc124\uba85\uc740 \uc774\ubbf8\uc9c0\uc758 \uc77c\ubd80\ub9cc\uc744 \ubcf4\uc5ec\uc8fc\ubbc0\ub85c \ucd08\uc810\uc774 \ub2e4\ub97c \uc218 \uc788\uc74c\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0, LLM\uc740 \ubaa8\uc21c\ub418\ub294 \ubd80\ubd84 \uc5c6\uc774 \uc720\uc6a9\ud55c \uc815\ubcf4\ub4e4\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\ub294 \ucea1\uc158\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \ud2b9\ud788, OCR \uc815\ubcf4, \uc774\ubbf8\uc9c0 \ub0b4 \uc0c1\ub300\uc801 \uc704\uce58 \uc815\ubcf4, \uac1d\uccb4 \uac04 \uacf5\uac04\uc801 \uad00\uacc4 \uc815\ubcf4\ub97c \ucd5c\ub300\ud55c \uc720\uc9c0\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4.", "section": "3. \uc811\uadfc \ubc29\uc2dd"}, {"figure_path": "https://arxiv.org/html/2412.14233/x6.png", "caption": "Figure 6: Visualization of DCE\u2019s Attribute Fusion: DCE combines object and relational attributes to generate detailed and comprehensive captions.", "description": "\uadf8\ub9bc 6\uc740 DCE(Descriptive Caption Enhancement)\uc758 \uc18d\uc131 \uc735\ud569\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. DCE\ub294 \uac1c\uccb4 \uc18d\uc131(\ud06c\uae30, \uae4a\uc774, \uac10\uc815, OCR \uc815\ubcf4, \ubbf8\uc138 \uc785\uc790 \uc18d\uc131 \ub4f1)\uacfc \uad00\uacc4 \uc18d\uc131(\uc778\uac04-\uac1c\uccb4 \uc0c1\ud638\uc791\uc6a9, 2D \ubc0f 3D \uc0c1\ub300 \uc704\uce58 \ub4f1)\uc744 \uacb0\ud569\ud558\uc5ec \uc0c1\uc138\ud558\uace0 \uc885\ud569\uc801\uc778 \ucea1\uc158\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \ub450 \uac00\uc9c0 \uc608\uc2dc \uc774\ubbf8\uc9c0\ub97c \ud1b5\ud574, \uae30\uc874\uc758 \uc77c\ubc18\uc801\uc778 LMM(Large Multimodality Model) \uae30\ubc18 \ucea1\uc158 \uc0dd\uc131 \ubc29\uc2dd\ubcf4\ub2e4 DCE\uac00 \ud6e8\uc52c \ub354 \ud48d\ubd80\ud558\uace0 \uc815\ud655\ud55c \ubb18\uc0ac\ub97c \uc81c\uacf5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \uc608\uc2dc\ub294 \uad70\uc6a9 \uc81c\ud2b8\uae30\ub97c, \ub450 \ubc88\uc9f8\ub294 \uafc0\ubcd1\ub4e4\uc744 \ubb18\uc0ac\ud558\ub294\ub370, DCE\ub294 \uac01 \uac1c\uccb4\uc758 \uc138\ubd80 \uc815\ubcf4\uc640 \uac1c\uccb4 \uac04\uc758 \uacf5\uac04\uc801 \uad00\uacc4\ub97c \uba85\ud655\ud558\uac8c \uc124\uba85\ud569\ub2c8\ub2e4. \uc774\ub294 DCE\uac00 \ub2e8\uc21c\ud788 \uac1c\uccb4\ub97c \ub098\uc5f4\ud558\ub294 \uc218\uc900\uc744 \ub118\uc5b4, \uc774\ubbf8\uc9c0\uc758 \uc2dc\uac01\uc801, \uc758\ubbf8\uc801 \ub9e5\ub77d\uc744 \uc815\ud655\ud558\uac8c \ud3ec\ucc29\ud558\uc5ec \uace0\ud488\uc9c8 \ucea1\uc158\uc744 \uc0dd\uc131\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. Approach"}]