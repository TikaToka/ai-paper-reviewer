[{"figure_path": "https://arxiv.org/html/2501.16273/extracted/6155161/figures/IntroFigure.png", "caption": "Figure 1: Architectural Efficiency in SLMs. Left: Comparison of architectures where encoder-decoder creates a fixed input representation with KV cache only for output, while decoder-only requires growing KV caches for both input and output. Top right: Inference time scaling with input length, showing encoder-decoder\u2019s efficient fixed-representation approach versus decoder-only\u2019s steeper computational growth. Bottom right: Performance across tasks showing encoder-decoder\u2019s advantages at fixed compute budget, further enhanced by KD.", "description": " \uadf8\ub9bc 1\uc740 \uc18c\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(SLM)\uc5d0\uc11c\uc758 \uc544\ud0a4\ud14d\ucc98 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ud328\ub110\uc740 \uc778\ucf54\ub354-\ub514\ucf54\ub354 \ubaa8\ub378\uacfc \ub514\ucf54\ub354 \uc804\uc6a9 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. \uc778\ucf54\ub354-\ub514\ucf54\ub354 \ubaa8\ub378\uc740 \uc785\ub825 \uc2dc\ud000\uc2a4\uc5d0 \ub300\ud574 \ud55c \ubc88\ub9cc \ucc98\ub9ac\ud558\uc5ec \uace0\uc815\ub41c \uc7a0\uc7ac \ud45c\ud604\uc744 \uc0dd\uc131\ud558\uace0, \ucd9c\ub825\uc5d0 \ub300\ud574\uc11c\ub9cc KV \uce90\uc2dc\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ubc18\uba74\uc5d0 \ub514\ucf54\ub354 \uc804\uc6a9 \ubaa8\ub378\uc740 \uc785\ub825\uacfc \ucd9c\ub825 \ubaa8\ub450\uc5d0 \ub300\ud574 \uc99d\uac00\ud558\ub294 KV \uce90\uc2dc\ub97c \ud544\uc694\ub85c \ud569\ub2c8\ub2e4. \uc624\ub978\ucabd \uc0c1\ub2e8 \ud328\ub110\uc740 \uc785\ub825 \uc2dc\ud000\uc2a4 \uae38\uc774\uc5d0 \ub530\ub978 \ucd94\ub860 \uc2dc\uac04\uc744 \ube44\uad50\ud558\uc5ec \uc778\ucf54\ub354-\ub514\ucf54\ub354 \ubaa8\ub378\uc758 \ud6a8\uc728\uc801\uc778 \uace0\uc815 \ud45c\ud604 \ubc29\uc2dd\uacfc \ub514\ucf54\ub354 \uc804\uc6a9 \ubaa8\ub378\uc758 \uac00\ud30c\ub978 \uacc4\uc0b0 \uc131\uc7a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd \ud558\ub2e8 \ud328\ub110\uc740 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \uace0\uc815\ub41c \uacc4\uc0b0 \uc608\uc0b0\uc5d0\uc11c \uc778\ucf54\ub354-\ub514\ucf54\ub354 \ubaa8\ub378\uc758 \uc774\uc810\uacfc \uc9c0\uc2dd \uc99d\ub958(KD)\ub97c \ud1b5\ud55c \ucd94\uac00\uc801\uc778 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.16273/extracted/6155161/figures/Scaling.png", "caption": "Figure 2: Performance across various model scales across top two architectures (2/3-1/3 enc-dec vs dec-only).", "description": "\uadf8\ub9bc 2\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub450 \uac00\uc9c0 \uc8fc\uc694 \uc544\ud0a4\ud14d\ucc98(2/3-1/3 \uc778\ucf54\ub354-\ub514\ucf54\ub354\uc640 \ub514\ucf54\ub354 \uc804\uc6a9)\uc5d0 \ub300\ud574 \ub2e4\uc591\ud55c \ubaa8\ub378 \ud06c\uae30(\ub9e4\uac1c\ubcc0\uc218 \uc218)\ubcc4 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  x\ucd95\uc740 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc218(3\uc5b5, 5\uc5b5, 10\uc5b5)\ub97c \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \ucd94\ub860 \ubc0f \uc694\uc57d \uc791\uc5c5\uc5d0\uc11c\uc758 \ud3c9\uade0 Rouge \uc131\ub2a5 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 \ubaa8\ub378 \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ub450 \uc544\ud0a4\ud14d\ucc98 \ubaa8\ub450 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc9c0\ub9cc, \ud2b9\ud788 2/3-1/3 \uc778\ucf54\ub354-\ub514\ucf54\ub354 \uc544\ud0a4\ud14d\ucc98\uac00 \ub354 \ud070 \uc131\ub2a5 \uac1c\uc120\uc744 \ubcf4\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub514\ucf54\ub354 \uc804\uc6a9 \uc544\ud0a4\ud14d\ucc98\ub294 \ud2b9\uc815 \ud06c\uae30 \uc774\uc0c1\ubd80\ud130\ub294 \uc778\ucf54\ub354-\ub514\ucf54\ub354 \uc544\ud0a4\ud14d\ucc98\uc5d0 \ube44\ud574 \uc131\ub2a5 \ud5a5\uc0c1 \ud3ed\uc774 \ub454\ud654\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Parameter Efficient SLMs"}, {"figure_path": "https://arxiv.org/html/2501.16273/x1.png", "caption": "Figure 3: Vision Language Encoder-Decoder Architecture.", "description": "\uadf8\ub9bc 3\uc740 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \ube44\uc804-\uc5b8\uc5b4 \uc5d4\ucf54\ub354-\ub514\ucf54\ub354 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874\uc758 \ud14d\uc2a4\ud2b8 \uae30\ubc18 \uc5d4\ucf54\ub354-\ub514\ucf54\ub354 \uad6c\uc870\ub97c \ud655\uc7a5\ud558\uc5ec \uc774\ubbf8\uc9c0 \ucc98\ub9ac \uae30\ub2a5\uc744 \ud1b5\ud569\ud55c \uad6c\uc870\uc785\ub2c8\ub2e4.  CLIP\uc758 ViT-L-336px \ubaa8\ub378\uc744 \ube44\uc804 \uc778\ucf54\ub354\ub85c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \ucc98\ub9ac\ud558\uace0, 2-layer MLP \ud22c\uc601 \ub808\uc774\uc5b4\ub97c \ud1b5\ud574 \ud14d\uc2a4\ud2b8 \uc784\ubca0\ub529 \uacf5\uac04\uacfc \uc815\ub82c\ud569\ub2c8\ub2e4. \uace0\ud574\uc0c1\ub3c4 \uc774\ubbf8\uc9c0 \ucc98\ub9ac\ub97c \uc704\ud574 \uc774\ubbf8\uc9c0\ub97c \uc5ec\ub7ec \uc11c\ube0c \uc774\ubbf8\uc9c0\ub85c \ub098\ub204\uc5b4 \ucc98\ub9ac\ud558\uace0, \uc804\uccb4\uc801\uc778 \ub9e5\ub77d\uc744 \uc704\ud574 \uc800\ud574\uc0c1\ub3c4 \uc378\ub124\uc77c \uc774\ubbf8\uc9c0\ub3c4 \ud568\uaed8 \ucc98\ub9ac\ud569\ub2c8\ub2e4.  \uc774\ub807\uac8c \uc0dd\uc131\ub41c \ube44\uc804 \ud1a0\ud070\uacfc \ud14d\uc2a4\ud2b8 \ud1a0\ud070\uc744 \uacb0\ud569\ud558\uc5ec \ud14d\uc2a4\ud2b8 \uc5d4\ucf54\ub354-\ub514\ucf54\ub354\uc5d0 \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.  \ud14d\uc2a4\ud2b8 \ub514\ucf54\ub354\ub294 \ucd5c\uc885 \ud14d\uc2a4\ud2b8 \ucd9c\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.  \ube44\uad50\ub97c \uc704\ud574 \ud14d\uc2a4\ud2b8 \uc778\ucf54\ub354 \ubd80\ubd84\uc744 \uc81c\uac70\ud55c \ub514\ucf54\ub354 \uc804\uc6a9 \ubcc0\ud615 \ubaa8\ub378\ub3c4 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc544\ud0a4\ud14d\ucc98 \uc120\ud0dd\uc758 \uc601\ud5a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4. Vision-Language Architecture"}, {"figure_path": "https://arxiv.org/html/2501.16273/extracted/6155161/figures/vision_model_comparison.png", "caption": "Figure 4: Performance comparison across vision-language tasks. Despite equal parameter constraints (800M), our encoder-decoder architecture consistently outperforms the decoder-only baseline.", "description": "\uadf8\ub9bc 4\ub294 \ube44\uc804-\uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \uacfc\uc81c\uc5d0 \uac78\uccd0 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub9e4\uac1c\ubcc0\uc218 \uc218\uac00 \ub3d9\uc77c(8\uc5b5 \uac1c)\ud568\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0, \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 \uc778\ucf54\ub354-\ub514\ucf54\ub354 \uad6c\uc870\uac00 \ub514\ucf54\ub354 \uc804\uc6a9 \uae30\ubc18 \ubaa8\ub378\ubcf4\ub2e4 \uc77c\uad00\ub418\uac8c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c4\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc778\ucf54\ub354-\ub514\ucf54\ub354 \uc544\ud0a4\ud14d\ucc98\uac00 \ube44\uc804-\uc5b8\uc5b4 \uacfc\uc81c\uc5d0 \ub354 \uc801\ud569\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. Vision-Language Tasks"}]