[{"figure_path": "https://arxiv.org/html/2502.05176/x2.png", "caption": "Figure 1: \nOverview of our reference-based 360\u00b0 unbounded scene inpainting method. Given input images with camera parameters, object masks, and a reference image, our AuraFusion360 approach generates an object-masked Gaussian Splatting representation. This representation can then render novel views of the inpainted scene, effectively removing the masked objects while maintaining consistency with the reference image.", "description": "\uc774 \uadf8\ub9bc\uc740 AuraFusion360 \ubc29\ubc95\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uce74\uba54\ub77c \ud30c\ub77c\ubbf8\ud130, \uac1d\uccb4 \ub9c8\uc2a4\ud06c, \uadf8\ub9ac\uace0 \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 \uc8fc\uc5b4\uc9c0\uba74, AuraFusion360\uc740 \uac1d\uccb4 \ub9c8\uc2a4\ud06c\uac00 \uc801\uc6a9\ub41c Gaussian Splatting \ud45c\ud604\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 \ud45c\ud604\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc640 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ub9c8\uc2a4\ud06c\ub41c \uac1d\uccb4\ub97c \uc81c\uac70\ud558\uace0 \uc0c8\ub85c\uc6b4 \ubdf0\uc758 \ud569\uc131 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uc785\ub825 \uc774\ubbf8\uc9c0\ub294 \uc5ec\ub7ec \uac01\ub3c4\uc5d0\uc11c \ucd2c\uc601\ub41c \uc774\ubbf8\uc9c0\ub4e4\uc774\uace0, \uac1d\uccb4 \ub9c8\uc2a4\ud06c\ub294 \uc81c\uac70\ud560 \uac1d\uccb4\uc758 \uc601\uc5ed\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ucc38\uc870 \uc774\ubbf8\uc9c0\ub294 \ubc30\uacbd\uacfc \uc8fc\ubcc0 \ud658\uacbd \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.  AuraFusion360\uc740 \uc774\ub7ec\ud55c \uc815\ubcf4\ub4e4\uc744 \ud65c\uc6a9\ud558\uc5ec  360\ub3c4 \uc804\ubc29\uc704\uc758 \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc77c\uad00\uc131 \uc788\ub294 \ud569\uc131 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2502.05176/x3.png", "caption": "Figure 2: Comparison with different 3D inpainting approaches. Previous methods, such as SPin-NeRF\u00a0[34] and GScream\u00a0[60], are tailored for forward-facing scenes and tend to underperform in 360\u00b0 unbounded scenarios. Reference-based methods, such as Infusion\u00a0[27], whose depth completion model struggles to accurately project the reference view back into the 3D scene, leading to fine-tuning artifacts. Gaussian Grouping\u00a0[65] often misidentifies the unseen region during mask generation, which can degrade inpainting quality. Our method, AuraFusion360, achieves a more accurate unseen mask and enhanced depth alignment through Adaptive Guided Depth Diffusion, with SDEdit\u00a0[30] applied to the initial points to leverage diffusion prior while also maintaining multi-view consistency in RGB guidance.", "description": "\uadf8\ub9bc 2\ub294 \ub2e4\uc591\ud55c 3D \uc774\ubbf8\uc9c0 \ucc44\uc0c9 \uae30\ubc95\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uae30\uc874\uc758 SPIn-NeRF [34]\ub098 GScream [60]\uacfc \uac19\uc740 \ubc29\ubc95\ub4e4\uc740 \uc815\uba74\uc744 \ud5a5\ud558\ub294 \uc7a5\uba74\uc5d0 \ub9de\ucdb0 \uc124\uacc4\ub418\uc5c8\uae30 \ub54c\ubb38\uc5d0 360\ub3c4 \uc804\ubc29\uc704 \uc7a5\uba74\uc5d0\uc11c\ub294 \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4.  Infusion [27]\uacfc \uac19\uc740 \ucc38\uc870 \uae30\ubc18 \ubc29\ubc95\ub4e4\uc740 \uae4a\uc774 \uc644\uc131 \ubaa8\ub378\uc758 \ubd80\uc815\ud655\uc131\uc73c\ub85c \uc778\ud574 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c 3D \uc7a5\uba74\uc5d0 \uc815\ud655\ud558\uac8c \ud22c\uc601\ud558\uc9c0 \ubabb\ud558\uc5ec \ubbf8\uc138 \uc870\uc815 \uacfc\uc815\uc5d0\uc11c \uc778\uacf5\ubb3c\uc774 \ubc1c\uc0dd\ud558\ub294 \ubb38\uc81c\uac00 \uc788\uc2b5\ub2c8\ub2e4. Gaussian Grouping [65]\uc740 \ub9c8\uc2a4\ud06c \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc744 \uc798\ubabb \uc778\uc2dd\ud558\uc5ec \ucc44\uc0c9 \ud488\uc9c8\uc774 \uc800\ud558\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ubc18\uba74 AuraFusion360\uc740 \uc801\uc751\uc801 \uc720\ub3c4 \uae4a\uc774 \ud655\uc0b0\uc744 \ud1b5\ud574 \ubcf4\ub2e4 \uc815\ud655\ud55c \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \uc0dd\uc131\ud558\uace0, \ucd08\uae30 \uc810\uc5d0 SDEdit [30]\uc744 \uc801\uc6a9\ud558\uc5ec \ud655\uc0b0 \uc0ac\uc804 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uba74\uc11c RGB \uc548\ub0b4\uc758 \ub2e4\uc911 \ubcf4\uae30 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud568\uc73c\ub85c\uc368 \uc774\ub7ec\ud55c \ubb38\uc81c\uc810\ub4e4\uc744 \ud574\uacb0\ud569\ub2c8\ub2e4.", "section": "2. \uad00\ub828 \uc5f0\uad6c"}, {"figure_path": "https://arxiv.org/html/2502.05176/x4.png", "caption": "Figure 3: Overview of our method. Our approach takes multi-view RGB images and corresponding object masks as input and outputs a Gaussian representation with the masked objects removed. The pipeline consists of three main stages: (a) Depth-Aware Unseen Masks Generation to identify truly occluded areas, referred to as the \u201cunseen region\u201d, (b) Depth-Aligned Gaussian Initialization on Reference View to fill unseen regions with initialized Gaussian containing reference RGB information after object removal, and (c) SDEdit-Based RGB Guidance for Detail Enhancement, which enhances fine details using an inpainting model while preserving reference view information. Instead of applying SDEdit with random noise, we use DDIM Inversion on the rendered initial Gaussians to generate noise that retains the structure of the reference view, ensuring multi-view consistency across all RGB Guidance.", "description": "\uadf8\ub9bc 3\uc740 AuraFusion360 \ubc29\ubc95\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ubc29\ubc95\uc740 \ub2e4\uc911 \ubdf0 RGB \uc774\ubbf8\uc9c0\uc640 \ud574\ub2f9 \uac1d\uccb4 \ub9c8\uc2a4\ud06c\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc544 \ub9c8\uc2a4\ud06c\ub41c \uac1d\uccb4\uac00 \uc81c\uac70\ub41c \uac00\uc6b0\uc2dc\uc548 \ud45c\ud604\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4. \uc774 \ud30c\uc774\ud504\ub77c\uc778\uc740 \uc138 \uac00\uc9c0 \uc8fc\uc694 \ub2e8\uacc4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. (a) \uae4a\uc774 \uc778\uc2dd\uc774 \ub418\ub294 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c \uc0dd\uc131\uc740 \uc2e4\uc81c\ub85c \uac00\ub824\uc9c4 \uc601\uc5ed(\ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc774\ub77c\uace0 \ud568)\uc744 \uc2dd\ubcc4\ud569\ub2c8\ub2e4. (b) \ucc38\uc870 \ubdf0\uc5d0 \ub300\ud55c \uae4a\uc774 \uc815\ub82c\ub41c \uac00\uc6b0\uc2dc\uc548 \ucd08\uae30\ud654\ub294 \uac1d\uccb4 \uc81c\uac70 \ud6c4 \ucc38\uc870 RGB \uc815\ubcf4\uac00 \ud3ec\ud568\ub41c \ucd08\uae30\ud654\ub41c \uac00\uc6b0\uc2dc\uc548\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc744 \ucc44\uc6c1\ub2c8\ub2e4. (c) SDEdit \uae30\ubc18 RGB \uc548\ub0b4 \uac1c\uc120\uc740 \ucc38\uc870 \ubdf0 \uc815\ubcf4\ub97c \uc720\uc9c0\ud558\uba74\uc11c \uc778\ud398\uc778\ud305 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc138\ubd80\uc801\uc778 \ubd80\ubd84\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4. \ubb34\uc791\uc704 \ub178\uc774\uc988\ub97c \uc0ac\uc6a9\ud558\uc5ec SDEdit\uc744 \uc801\uc6a9\ud558\ub294 \ub300\uc2e0, \ub80c\ub354\ub9c1\ub41c \ucd08\uae30 \uac00\uc6b0\uc2dc\uc548\uc5d0 DDIM \ubc18\uc804\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucc38\uc870 \ubdf0\uc758 \uad6c\uc870\ub97c \uc720\uc9c0\ud558\ub294 \ub178\uc774\uc988\ub97c \uc0dd\uc131\ud558\uc5ec \ubaa8\ub4e0 RGB \uc548\ub0b4\uc5d0 \uac78\uccd0 \ub2e4\uc911 \ubdf0 \uc77c\uad00\uc131\uc744 \ubcf4\uc7a5\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.05176/x5.png", "caption": "Figure 4: Overview of the Unseen Mask Generation Process using Depth Warping. To obtain the unseen mask for view n\ud835\udc5bnitalic_n, we calculate the pixel correspondences between the view n\ud835\udc5bnitalic_n and all other views i\ud835\udc56iitalic_i by using the rendered incomplete depth Dnincompletesuperscriptsubscript\ud835\udc37\ud835\udc5bincompleteD_{n}^{\\text{incomplete}}italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT incomplete end_POSTSUPERSCRIPT. For each view i\ud835\udc56iitalic_i, the removal region Risubscript\ud835\udc45\ud835\udc56R_{i}italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is backward traversal to view n\ud835\udc5bnitalic_n to align occlusions. We then aggregate the results from multiple views, averaging and applying a threshold to produce the initial contour of the unseen mask. This contour is subsequently converted into a bounding box prompt for SAM2\u00a0[44], which refines the unseen mask to its final version for view n\ud835\udc5bnitalic_n.", "description": "\uadf8\ub9bc 4\ub294 \uae4a\uc774 \uc6cc\ud551\uc744 \uc0ac\uc6a9\ud55c \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c \uc0dd\uc131 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\uc815 \ubdf0 n\uc5d0 \ub300\ud55c \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \uc5bb\uae30 \uc704\ud574, \uba3c\uc800 \ub80c\ub354\ub9c1\ub41c \ubd88\uc644\uc804\ud55c \uae4a\uc774 \uc815\ubcf4 D\ud835\udc5bincomplete\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubdf0 n\uacfc \ub2e4\ub978 \ubaa8\ub4e0 \ubdf0 i \uac04\uc758 \ud53d\uc140 \ub300\uc751 \uad00\uacc4\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4. \uac01 \ubdf0 i\uc5d0 \ub300\ud574, \uc81c\uac70 \uc601\uc5ed Ri\ub97c \ubdf0 n\uc5d0 \ub9de\ucdb0 \uc5ed\ubcc0\ud658\ud558\uc5ec \ud3d0\uc0c9\uc744 \uc815\ub82c\ud569\ub2c8\ub2e4. \uc5ec\ub7ec \ubdf0\uc758 \uacb0\uacfc\ub97c \ud3c9\uade0\ud654\ud558\uace0 \uc784\uacc4\uac12\uc744 \uc801\uc6a9\ud558\uc5ec \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\uc758 \ucd08\uae30 \uc724\uacfd\uc120\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774 \uc724\uacfd\uc120\uc740 SAM2 [44]\uc5d0 \ub300\ud55c \uacbd\uacc4 \uc0c1\uc790 \ud504\ub86c\ud504\ud2b8\ub85c \ubcc0\ud658\ub418\uc5b4 \ubdf0 n\uc5d0 \ub300\ud55c \ucd5c\uc885 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.05176/x6.png", "caption": "Figure 5: \nOverview of Adaptive Guided Depth Diffusion (AGDD).\nThe framework takes image latent, incomplete depth, and unseen mask as inputs to generate aligned depth estimates. (a) The guided region is identified by dilating the unseen mask and subtracting the original mask. (b) At each denoising timestep t\ud835\udc61titalic_t, an adaptive loss \u2112adaptivesubscript\u2112adaptive\\mathcal{L}_{\\text{adaptive}}caligraphic_L start_POSTSUBSCRIPT adaptive end_POSTSUBSCRIPT is computed between the pre-decoded and incomplete depth to update the noise input \u03f5^tsubscript^italic-\u03f5\ud835\udc61\\hat{\\epsilon}_{t}over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This process repeats N\ud835\udc41Nitalic_N times before advancing to the next denoising step, ensuring the estimated depth aligns with the incomplete depth distribution in the guided region.", "description": "\uadf8\ub9bc 5\ub294 \uc801\uc751\uc801 \uc720\ub3c4 \uc2ec\ub3c4 \ud655\uc0b0(AGDD)\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  AGDD\ub294 \uc774\ubbf8\uc9c0 \uc7a0\uc7ac \ubca1\ud130, \ubd88\uc644\uc804\ud55c \uc2ec\ub3c4, \uadf8\ub9ac\uace0 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \uc785\ub825\ubc1b\uc544 \uc815\ub82c\ub41c \uc2ec\ub3c4 \ucd94\uc815\uac12\uc744 \uc0dd\uc131\ud558\ub294 \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4.  (a) \ubd80\ubd84\uc740 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \ud655\uc7a5\ud558\uace0 \uc6d0\ubcf8 \ub9c8\uc2a4\ud06c\ub97c \ube7c\uc11c \uc720\ub3c4 \uc601\uc5ed\uc744 \uc2dd\ubcc4\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (b) \ubd80\ubd84\uc740 \uac01 \ub514\ub178\uc774\uc9d5 \uc2dc\uac04 \ub2e8\uacc4 t\uc5d0\uc11c \ubbf8\ub9ac \ub514\ucf54\ub529\ub41c \uc2ec\ub3c4\uc640 \ubd88\uc644\uc804\ud55c \uc2ec\ub3c4 \uac04\uc758 \uc801\uc751\uc801 \uc190\uc2e4(\u2112adaptive)\uc744 \uacc4\uc0b0\ud558\uc5ec \uc7a1\uc74c \uc785\ub825 (\u03f5\u0302t)\uc744 \uc5c5\ub370\uc774\ud2b8\ud558\ub294 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc740 \ub2e4\uc74c \ub514\ub178\uc774\uc9d5 \ub2e8\uacc4\ub85c \ub118\uc5b4\uac00\uae30 \uc804\uc5d0 N\ubc88 \ubc18\ubcf5\ub418\uba70, \ucd94\uc815\ub41c \uc2ec\ub3c4\uac00 \uc720\ub3c4 \uc601\uc5ed \ub0b4\uc758 \ubd88\uc644\uc804\ud55c \uc2ec\ub3c4 \ubd84\ud3ec\uc640 \uc77c\uce58\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.05176/x7.png", "caption": "Figure 6: Overview of the 360-USID dataset. Sample images from each scene, including five outdoor scenes (Carton, Cone, Newcone, Skateboard, Plant) and two indoor scenes (Cookie, Sunflower). (Bottom right) The table shows statistics for each scene, including the number of training views and ground truth (GT) novel views. The dataset provides a diverse range of environments for evaluating 3D inpainting methods in both indoor and outdoor settings.", "description": "\uadf8\ub9bc 6\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \uc0c8\ub85c\uc6b4 360\ub3c4 \ubb34\uc81c\ud55c \uc7a5\uba74 \uc778\ud398\uc778\ud305 \ub370\uc774\ud130\uc14b\uc778 360-USID\uc758 \uac1c\uc694\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \ud658\uacbd\uc5d0\uc11c 3D \uc778\ud398\uc778\ud305 \uae30\ubc95\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc2e4\ub0b4\uc678 \ud658\uacbd\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\ub294 7\uac1c\uc758 \uc7a5\uba74(\uc0c1\uc790, \uc6d0\ubfd4, \uc0c8\ub85c\uc6b4 \uc6d0\ubfd4, \uc2a4\ucf00\uc774\ud2b8\ubcf4\ub4dc, \uc2dd\ubb3c, \ucfe0\ud0a4, \ud574\ubc14\ub77c\uae30)\uc758 \uc0d8\ud50c \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd \ud558\ub2e8\uc758 \ud45c\ub294 \uac01 \uc7a5\uba74\uc5d0 \ub300\ud55c \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc8fc\ub294\ub370, \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ubdf0\uc758 \uc218\uc640 \uc2e4\uc81c\uac12(GT) \uc0c8\ub85c\uc6b4 \ubdf0\uc758 \uc218\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc774 \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc591\ud55c \uc2e4\ub0b4\uc678 \ud658\uacbd\uc744 \uc81c\uacf5\ud558\uc5ec 3D \uc778\ud398\uc778\ud305 \ubc29\ubc95\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "4. 360\u00b0 Unbounded Scenes Inpainting Dataset"}, {"figure_path": "https://arxiv.org/html/2502.05176/x8.png", "caption": "Figure 7: Illustration of the data capture process for the 360-USID dataset. (a) Capturing training views: Multiple images are taken around the object in the scene. (b) Capturing the reference view: A camera is mounted on a tripod to capture a fixed reference view (with an object). (c) Capturing novel views: After removing the object, additional images are taken from various viewpoints, including one from the same tripod position as the reference image.", "description": "\uadf8\ub9bc 7\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c 360-USID \ub370\uc774\ud130\uc14b\uc744 \uad6c\ucd95\ud558\uae30 \uc704\ud55c \ub370\uc774\ud130 \uc218\uc9d1 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  (a)\ub294 \ud6c8\ub828 \ub370\uc774\ud130\ub97c \uc218\uc9d1\ud558\ub294 \uacfc\uc815\uc73c\ub85c, \uc7a5\uba74 \ub0b4\uc758 \ubb3c\uccb4 \uc8fc\ubcc0\uc5d0\uc11c \uc5ec\ub7ec \uac01\ub3c4\ub85c \uc774\ubbf8\uc9c0\ub97c \ucd2c\uc601\ud569\ub2c8\ub2e4.  (b)\ub294 \uae30\uc900 \uc774\ubbf8\uc9c0\ub97c \uc5bb\ub294 \uacfc\uc815\uc73c\ub85c, \uc0bc\uac01\ub300\uc5d0 \uce74\uba54\ub77c\ub97c \uace0\uc815\ud558\uc5ec \ubb3c\uccb4\uac00 \uc788\ub294 \uc7a5\uba74\uc758 \uace0\uc815\ub41c \uae30\uc900 \uc774\ubbf8\uc9c0\ub97c \ucd2c\uc601\ud569\ub2c8\ub2e4. (c)\ub294 \uc0c8\ub85c\uc6b4 \ubdf0\ub97c \uc218\uc9d1\ud558\ub294 \uacfc\uc815\uc73c\ub85c, \ubb3c\uccb4\ub97c \uc81c\uac70\ud55c \ud6c4 \ub2e4\uc591\ud55c \uc2dc\uc810\uc5d0\uc11c \ucd94\uac00\uc801\uc778 \uc774\ubbf8\uc9c0\ub97c \ucd2c\uc601\ud558\uba70, \uc5ec\uae30\uc5d0\ub294 \uae30\uc900 \uc774\ubbf8\uc9c0\uc640 \ub3d9\uc77c\ud55c \uc0bc\uac01\ub300 \uc704\uce58\uc5d0\uc11c \ucd2c\uc601\ud55c \uc774\ubbf8\uc9c0\ub3c4 \ud3ec\ud568\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 360\ub3c4 \ud658\uacbd\uc5d0\uc11c\uc758 \ubb3c\uccb4 \uc81c\uac70 \ubc0f \ubc30\uacbd \ubcf5\uc6d0 \uc791\uc5c5\uc5d0 \ud544\uc694\ud55c \ub370\uc774\ud130\uc14b \uad6c\ucd95 \uacfc\uc815\uc744 \uc790\uc138\ud788 \uc124\uba85\ud569\ub2c8\ub2e4.", "section": "4. 360\u00b0 Unbounded Scenes Inpainting Dataset"}, {"figure_path": "https://arxiv.org/html/2502.05176/x9.png", "caption": "Figure 8: Visual Comparison on our 360-USID dataset. We compare our method against state-of-the-art approaches including Gaussian Grouping\u00a0[65], 2DGS + LeftRefill, and Infusion\u00a0[27]. While Gaussian Grouping struggles with misidentifying unseen regions, leading to floating artifacts, and 2DGS + LeftRefill faces view consistency issues, our method successfully maintains geometric consistency and preserves fine details across different viewpoints. Ground truth (GT) is shown for reference, and the original scene with an object is provided in the first row for comparison.", "description": "\uadf8\ub9bc 8\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c 360-USID \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \ucd5c\ucca8\ub2e8 \ubc29\ubc95\ub4e4\uacfc \uc81c\uc548\ub41c \ubc29\ubc95\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\uad50 \ub300\uc0c1 \ubc29\ubc95\uc740 Gaussian Grouping [65], 2DGS + LeftRefill, Infusion [27]\uc785\ub2c8\ub2e4. Gaussian Grouping\uc740 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc744 \uc798\ubabb \uc2dd\ubcc4\ud558\uc5ec \ubd80\uc720\ud558\ub294 \uc778\uacf5\ubb3c\uc774 \ubc1c\uc0dd\ud558\ub294 \ubc18\uba74, 2DGS + LeftRefill\uc740 \ubdf0 \uc77c\uad00\uc131 \ubb38\uc81c\ub97c \ubcf4\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc81c\uc548\ub41c \ubc29\ubc95\uc740 \uae30\ud558\ud559\uc801 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uace0 \ub2e4\uc591\ud55c \uad00\uc810\uc5d0\uc11c \ubbf8\uc138\ud55c \ub514\ud14c\uc77c\uc744 \ubcf4\uc874\ud558\ub294 \ub370 \uc131\uacf5\ud569\ub2c8\ub2e4. \ucc38\uc870\uc6a9\uc73c\ub85c \uc2e4\uc81c \uc815\ub2f5(GT) \uc774\ubbf8\uc9c0\uac00 \ud45c\uc2dc\ub418\uba70, \ube44\uad50\ub97c \uc704\ud574 \ubb3c\uccb4\uac00 \uc788\ub294 \uc6d0\ubcf8 \uc7a5\uba74 \uc774\ubbf8\uc9c0\ub3c4 \uccab \ubc88\uc9f8 \ud589\uc5d0 \ud568\uaed8 \uc81c\uacf5\ub429\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2502.05176/x10.png", "caption": "Figure 9: Visual comparison of unseen mask generation method. Our method enables SAM2\u00a0[44] to generate more accurate predictions for each view without the need for manually provided prompts, as the bounding box prompts are automatically generated through depth warping.", "description": "\uadf8\ub9bc 9\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \uae30\uc874\uc758 SAM2 [44] \ubc29\ubc95\ubcf4\ub2e4 \uac01 \ubdf0\uc5d0 \ub300\ud574 \ub354 \uc815\ud655\ud55c \uc608\uce21\uc744 \uc0dd\uc131\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc218\ub3d9\uc73c\ub85c \ud504\ub86c\ud504\ud2b8\ub97c \uc81c\uacf5\ud560 \ud544\uc694 \uc5c6\uc774 \uae4a\uc774 \uc65c\uace1\uc744 \ud1b5\ud574 \uacbd\uacc4 \uc0c1\uc790 \ud504\ub86c\ud504\ud2b8\ub97c \uc790\ub3d9\uc73c\ub85c \uc0dd\uc131\ud558\uc5ec SAM2 [44]\uac00 \ub354\uc6b1 \uc815\ud655\ud55c \uc608\uce21\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \uc989, \uae30\uc874 \ubc29\ubc95\uc740 \uc218\ub3d9\uc73c\ub85c \ud504\ub86c\ud504\ud2b8\ub97c \uc9c0\uc815\ud574\uc57c \ud558\uc9c0\ub9cc, \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \ubc29\ubc95\uc740 \uae4a\uc774 \uc65c\uace1 \uae30\ubc95\uc744 \uc774\uc6a9\ud558\uc5ec \uacbd\uacc4 \uc0c1\uc790 \ud504\ub86c\ud504\ud2b8\ub97c \uc790\ub3d9\uc73c\ub85c \uc0dd\uc131\ud568\uc73c\ub85c\uc368 \ub354\uc6b1 \uc815\ud655\ud55c \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1 Depth-Aware Unseen Mask Generation"}, {"figure_path": "https://arxiv.org/html/2502.05176/x11.png", "caption": "Figure 10: Compared Unseen Mask w/ Gaussian Grouping. Gaussian Grouping\u00a0[65] uses a video tracker\u00a0[9] and the \u201cblack blurry hole\u201d prompt for the DEVA\u00a0[9] method to track the unseen region. However, this can result in tracking errors, affecting inpainting. In contrast, our geometry-based approach uses depth warping to estimate the unseen region\u2019s contour, reducing segmentation errors.", "description": "\uadf8\ub9bc 10\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uacfc Gaussian Grouping [65]\uc758 Unseen Mask \uc0dd\uc131 \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Gaussian Grouping\uc740 \ube44\ub514\uc624 \ucd94\uc801\uae30 [9]\uc640 DEVA [9] \uba54\uc11c\ub4dc\uc758 \"\uac80\uc740 \ud750\ub9bf\ud55c \uad6c\uba4d\" \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec Unseen \uc601\uc5ed\uc744 \ucd94\uc801\ud558\uc9c0\ub9cc, \uc774\ub294 \ucd94\uc801 \uc624\ub958\ub97c \ubc1c\uc0dd\uc2dc\ucf1c \uc778\ud398\uc778\ud305 \uacb0\uacfc\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce60 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubc18\uba74\uc5d0, \uc81c\uc548\ub41c \uae30\ud558 \uae30\ubc18 \uc811\uadfc \ubc29\uc2dd\uc740 \uae4a\uc774 \uc65c\uace1\uc744 \uc0ac\uc6a9\ud558\uc5ec Unseen \uc601\uc5ed\uc758 \uc724\uacfd\uc120\uc744 \ucd94\uc815\ud558\uc5ec \ubd84\ud560 \uc624\ub958\ub97c \uc904\uc785\ub2c8\ub2e4. \uc989, Gaussian Grouping\uc740 \uc601\uc0c1 \uae30\ubc18 \ucd94\uc801\uc5d0 \uc758\uc874\ud558\uc5ec Unseen \uc601\uc5ed\uc744 \uc2dd\ubcc4\ud558\ub294 \ubc18\uba74, \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95\uc740 \uae30\ud558\ud559\uc801 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\uc5ec \ub354\uc6b1 \uc815\ud655\ud558\uac8c Unseen \uc601\uc5ed\uc744 \uc2dd\ubcc4\ud569\ub2c8\ub2e4. \uc774\ub294 \ubcf5\uc7a1\ud55c \uc7a5\uba74\uc5d0\uc11c \ud2b9\ud788 \uc720\uc6a9\ud558\uba70, \uc778\ud398\uc778\ud305 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0b5\ub2c8\ub2e4.", "section": "3.1 Depth-Aware Unseen Mask Generation"}, {"figure_path": "https://arxiv.org/html/2502.05176/x12.png", "caption": "Figure 11: Compared to other depth completion methods. The depth completion model in Infusion\u00a0[27] (a) performs better at depth alignment compared to traditional methods (b) and (c), but it lacks generalization. Similarly, (d) Guided Depth Diffusion\u00a0[68] struggles to achieve precise alignment, as the background regions amplify the loss, leading to misalignment. In contrast, (e) Our AGDD effectively addresses these issues.", "description": "\uadf8\ub9bc 11\uc740 \ub2e4\uc591\ud55c \ubc29\ubc95\uc73c\ub85c \uae4a\uc774 \uc644\uc131\uc744 \uc218\ud589\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874\uc758 \ubc29\ubc95 (b, c)\ub4e4\uacfc \ube44\uad50\ud588\uc744 \ub54c, Infusion [27] (a)\ub294 \uae4a\uc774 \uc815\ub82c\uc5d0 \uc788\uc5b4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0\ub9cc \uc77c\ubc18\ud654\uc5d0\ub294 \ucde8\uc57d\uc810\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ub9c8\ucc2c\uac00\uc9c0\ub85c, Guided Depth Diffusion [68] (d) \ub610\ud55c \ubc30\uacbd \uc601\uc5ed\uc5d0\uc11c \uc190\uc2e4\uc774 \uc99d\ud3ed\ub418\uc5b4 \uc815\ubc00\ud55c \uc815\ub82c\uc744 \ub2ec\uc131\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\uc2b5\ub2c8\ub2e4. \ubc18\uba74\uc5d0, \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 AGDD (e)\ub294 \uc774\ub7ec\ud55c \ubb38\uc81c\uc810\ub4e4\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud569\ub2c8\ub2e4.", "section": "3.2 Reference View Initial Gaussians Alignment"}, {"figure_path": "https://arxiv.org/html/2502.05176/x13.png", "caption": "Figure 12: Intermediate Results of Depth Warping for Unseen Region Detection. This figure illustrates the intermediate results generated during the depth warping process. (a) and (b) show the RGB image and the corresponding removal region at view n\ud835\udc5bnitalic_n, respectively. (c) displays the removal regions obtained from view i\ud835\udc56iitalic_i (i\u2260n\ud835\udc56\ud835\udc5bi\\neq nitalic_i \u2260 italic_n). (d) shows the unseen region obtained from view i\ud835\udc56iitalic_i through backward traversal. The intersections are concentrated near the unseen region. Note that the pixels within the unseen region, but with a value of zero, are due to the absence of Gaussians in that area, preventing depth rendering and thus making it impossible to establish pixel correspondences between view n\ud835\udc5bnitalic_n and view i\ud835\udc56iitalic_i. (e) presents the aggregation of all unseen regions obtained from view i\ud835\udc56iitalic_i at view n\ud835\udc5bnitalic_n. A threshold is applied to this result, and it is then intersected with the removal region at view n\ud835\udc5bnitalic_n to obtain the final result in (f).", "description": "\uadf8\ub9bc 12\ub294 \uae4a\uc774 \uc65c\uace1 \uacfc\uc815\uc5d0\uc11c \uc0dd\uc131\ub41c \uc911\uac04 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\uc640 (b)\ub294 \uac01\uac01 \ubdf0 n\uc758 RGB \uc774\ubbf8\uc9c0\uc640 \ud574\ub2f9 \uc81c\uac70 \uc601\uc5ed\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (c)\ub294 \ubdf0 i(i\u2260n)\uc5d0\uc11c \uc5bb\uc740 \uc81c\uac70 \uc601\uc5ed\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (d)\ub294 \uc5ed\ubc29\ud5a5 \ucd94\uc801\uc744 \ud1b5\ud574 \ubdf0 i\uc5d0\uc11c \uc5bb\uc740 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uad50\ucc28\uc810\uc740 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \uadfc\ucc98\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub0b4\uc5d0 \ud53d\uc140\uc774 \uc788\uc9c0\ub9cc \uac12\uc774 0\uc778 \uac83\uc740 \ud574\ub2f9 \uc601\uc5ed\uc5d0 \uac00\uc6b0\uc2dc\uc548\uc774 \uc5c6\uae30 \ub54c\ubb38\uc774\uba70, \uc774\ub85c \uc778\ud574 \uae4a\uc774 \ub80c\ub354\ub9c1\uc774 \ubd88\uac00\ub2a5\ud558\uace0 \ub530\ub77c\uc11c \ubdf0 n\uacfc \ubdf0 i \uac04\uc758 \ud53d\uc140 \ub300\uc751 \uad00\uacc4\ub97c \uc124\uc815\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4. (e)\ub294 \ubdf0 i\uc5d0\uc11c \ubdf0 n\uc5d0\uc11c \uc5bb\uc740 \ubaa8\ub4e0 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed\uc758 \uc9d1\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uacb0\uacfc\uc5d0 \uc784\uacc4\uac12\uc744 \uc801\uc6a9\ud55c \ub2e4\uc74c \ubdf0 n\uc758 \uc81c\uac70 \uc601\uc5ed\uacfc \uad50\ucc28\uc2dc\ucf1c (f)\uc758 \ucd5c\uc885 \uacb0\uacfc\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.05176/x14.png", "caption": "Figure 13: Ablation Study on Removal Region Definition. Comparison of (a) object masks vs. (b) depth difference for defining removal regions. Object masks fail to capture geometric changes, leading to less accurate unseen masks. Depth difference better preserves scene structure, improving SAM2 prompts and unseen region segmentation.", "description": "\uadf8\ub9bc 13\uc740 \uc81c\uac70 \uc601\uc5ed \uc815\uc758\uc5d0 \ub300\ud55c ablation \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a) \uac1d\uccb4 \ub9c8\uc2a4\ud06c\uc640 (b) \uae4a\uc774 \ucc28\uc774\ub97c \uc81c\uac70 \uc601\uc5ed\uc744 \uc815\uc758\ud558\ub294 \ubc29\ubc95\uc73c\ub85c \ube44\uad50\ud569\ub2c8\ub2e4. \uac1d\uccb4 \ub9c8\uc2a4\ud06c\ub294 \uae30\ud558\ud559\uc801 \ubcc0\ud654\ub97c \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\uc5ec \ubd80\uc815\ud655\ud55c \ubcf4\uc774\uc9c0 \uc54a\ub294 \ub9c8\uc2a4\ud06c\ub85c \uc774\uc5b4\uc9d1\ub2c8\ub2e4. \ubc18\uba74\uc5d0 \uae4a\uc774 \ucc28\uc774\ub294 \uc7a5\uba74 \uad6c\uc870\ub97c \ub354 \uc798 \ubcf4\uc874\ud558\uc5ec SAM2 \ud504\ub86c\ud504\ud2b8\uc640 \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ubd84\ud560\uc744 \uac1c\uc120\ud569\ub2c8\ub2e4. \uc989, \uac1d\uccb4\uc758 \uae30\ud558\ud559\uc801 \ubaa8\uc591 \ubcc0\ud654\ub97c \ub354 \uc798 \ubc18\uc601\ud558\ub294 \uae4a\uc774 \ucc28\uc774 \uc815\ubcf4\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubcf4\uc774\uc9c0 \uc54a\ub294 \uc601\uc5ed \ub9c8\uc2a4\ud06c\ub97c \uc0dd\uc131\ud558\ub294 \uac83\uc774 \ub354 \uc815\ud655\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2502.05176/x15.png", "caption": "Figure 14: Failure Cases. The figure illustrates failure cases of inpainting results. These examples highlight the challenges of 3D inpainting when significant occlusions are present near the regions requiring inpainting. For instance, (b) and (c) demonstrate difficulties in achieving satisfactory guided inpainted RGB images in the training views, while (d) and (e) show errors resulting from incorrect pixel unprojections. These observations indicate that this issue is not effectively addressed by any of the compared methods, suggesting a potential avenue for further exploration and improvement.", "description": "\uadf8\ub9bc 14\ub294 3D \uc774\ubbf8\uc9c0 \uc778\ud398\uc778\ud305\uc758 \uc5b4\ub824\uc6c0\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc2e4\ud328 \uc0ac\ub840\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, \uc778\ud398\uc778\ud305\uc774 \ud544\uc694\ud55c \uc601\uc5ed \uadfc\ucc98\uc5d0 \uc0c1\ub2f9\ud55c \ud3d0\uc0c9\uc774 \uc874\uc7ac\ud560 \ub54c \uc5b4\ub824\uc6c0\uc774 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. (b)\uc640 (c)\ub294 \uae30\uc874 \ubc29\ubc95\ub4e4\uc774 \ud6c8\ub828 \ubdf0\uc5d0\uc11c \ub9cc\uc871\uc2a4\ub7ec\uc6b4 RGB \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \ubc18\uba74, (d)\uc640 (e)\ub294 \uc798\ubabb\ub41c \ud53d\uc140 \ud22c\uc601\uc73c\ub85c \uc778\ud55c \uc624\ub958\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uad00\ucc30 \uacb0\uacfc\ub294 \ube44\uad50\ub41c \ubc29\ubc95\ub4e4 \uc911 \uc5b4\ub5a4 \uac83\ub3c4 \uc774 \ubb38\uc81c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud558\uc9c0 \ubabb\ud55c\ub2e4\ub294 \uac83\uc744 \uc2dc\uc0ac\ud558\uba70, \ucd94\uac00\uc801\uc778 \uc5f0\uad6c\uc640 \uac1c\uc120\uc758 \uc5ec\uc9c0\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "5.2. \ucd5c\ucca8\ub2e8 \uae30\ubc95\uacfc\uc758 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2502.05176/x16.png", "caption": "Figure 15: Visual Comparison on our 360-USID dataset.", "description": "\uadf8\ub9bc 15\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c 360-USID \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c 360\ub3c4 \ubb34\uc81c\ud55c \uc7a5\uba74 \uc778\ud398\uc778\ud305 \ubc29\ubc95\ub4e4\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubcf8 \ub17c\ubb38\uc758 \ubc29\ubc95(Ours)\uc744 \ud3ec\ud568\ud558\uc5ec,  2DGS + LeftRefill, Gaussian Grouping, Infusion \ub4f1 \uae30\uc874 \ubc29\ubc95\ub4e4\uc758 \uacb0\uacfc\ub97c  Ground Truth(GT)\uc640 \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec, \uac01 \ubc29\ubc95\ub4e4\uc758 \uc7a5\uc810\uacfc \ub2e8\uc810, \ud2b9\ud788 \uc5ec\ub7ec \uad00\uc810\uc5d0\uc11c\uc758 \uc77c\uad00\uc131 \ubc0f \uae30\ud558\ud559\uc801 \uc815\ud655\uc131\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uba85\ud655\ud558\uac8c \ube44\uad50\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud658\uacbd\uacfc \uc81c\uac70 \ub300\uc0c1 \ubb3c\uccb4\uc758 \ubcf5\uc7a1\ub3c4\uc5d0 \ub530\ub978 \uac01 \ubc29\ubc95\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \uc9c1\uad00\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}]