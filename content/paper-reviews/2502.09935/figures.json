[{"figure_path": "https://arxiv.org/html/2502.09935/x1.png", "caption": "Figure 1: Overview of the localization process. Our goal is to edit the image generated from the source prompt pSsubscript\ud835\udc5d\ud835\udc46p_{S}italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT using the target prompt pTsubscript\ud835\udc5d\ud835\udc47p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. To find which cross and joint attention layers should be modified, we pass the target prompt pTsubscript\ud835\udc5d\ud835\udc47p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT through the DM, caching the keys and values. Then, while generating the image from pSsubscript\ud835\udc5d\ud835\udc46p_{S}italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT we substitute the keys and values with the cached ones. We select the layers which yield the highest image and text alignment.\n(A) Localizing by Patching is applied to SD3, and (B) Localizing by Injection is used for SDXL and DeepFloyd IF.", "description": "\uadf8\ub9bc 1\uc740 \ub17c\ubb38\uc758 \ud575\uc2ec \uae30\ubc95\uc778 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998 \uacc4\uce35\uc758 \uc704\uce58 \ud30c\uc545 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa9\ud45c\ub294 \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8(pS)\ub85c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \ud14d\uc2a4\ud2b8\ub97c \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8(pT)\uc758 \ub0b4\uc6a9\uc73c\ub85c \uc218\uc815\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.  \uc774\ub97c \uc704\ud574 \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8(pT)\ub97c \ud655\uc0b0 \ubaa8\ub378(DM)\uc5d0 \ud1b5\uacfc\uc2dc\ucf1c \uac01 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998 \uacc4\uce35\uc758 \ud0a4(key)\uc640 \uac12(value)\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8(pS)\ub85c \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc5d0\uc11c \uc800\uc7a5\ub41c \ud0a4\uc640 \uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec \uae30\uc874 \ud0a4\uc640 \uac12\uc744 \ub300\uccb4\ud569\ub2c8\ub2e4.  \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8 \uc815\ub82c\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \uacc4\uce35\uc744 \uc120\ud0dd\ud558\uc5ec \ud574\ub2f9 \uacc4\uce35\uc744 \uc218\uc815\ud569\ub2c8\ub2e4. (A)\ub294 SD3 \ubaa8\ub378\uc5d0 \uc801\uc6a9\ub418\ub294 \ud328\uce58 \uae30\ubc95\uc744, (B)\ub294 SDXL\uacfc DeepFloyd IF \ubaa8\ub378\uc5d0 \uc801\uc6a9\ub418\ub294 \uc8fc\uc785 \uae30\ubc95\uc744 \uac01\uac01 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \uc5b4\ub5a4 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998 \uacc4\uce35\uc774 \uc774\ubbf8\uc9c0 \ub0b4 \ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294\uc9c0 \ucc3e\uc544\ub0b4\ub294 \ubc29\ubc95\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \uc124\uba85\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "4. LOCALIZATION OF ATTENTION LAYERS RESPONSIBLE FOR TEXTUAL CONTENT GENERATION"}, {"figure_path": "https://arxiv.org/html/2502.09935/x2.png", "caption": "Figure 2: Localized attention layers responsible for the content of the generated text. We selectively patch individual cross and joint attention layers with computations for the target prompt and measure the responses with OCR F1 Score. We identify three layers with the highest responses in SDXL (55, 56, and 57), one layer in DeepFloyd IF (17), and one layer in SD3 (10).", "description": "\uc774 \uadf8\ub9bc\uc740 \ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc5d0 \uad00\uc5ec\ud558\ub294 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc758 \uc704\uce58\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \uac00\uc9c0 \ucd5c\uc2e0 \ud655\uc0b0 \ubaa8\ub378(SDXL, DeepFloyd IF, SD3)\uc5d0\uc11c \uac01 \ub808\uc774\uc5b4\uc758 \ud06c\ub85c\uc2a4 \ubc0f \uc870\uc778\ud2b8 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub97c \uc120\ud0dd\uc801\uc73c\ub85c \ud328\uce58\ud558\uc5ec \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\ub97c \uacc4\uc0b0\ud558\uace0 OCR F1 \uc810\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc751\ub2f5\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \uadf8 \uacb0\uacfc SDXL\uc5d0\uc11c\ub294 55, 56, 57\ubc88 \ub808\uc774\uc5b4, DeepFloyd IF\uc5d0\uc11c\ub294 17\ubc88 \ub808\uc774\uc5b4, SD3\uc5d0\uc11c\ub294 10\ubc88 \ub808\uc774\uc5b4\uac00 \ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc5d0 \uac00\uc7a5 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ub808\uc774\uc5b4\ub85c \ud655\uc778\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uac01 \ubaa8\ub378\uc758 \ud30c\ub77c\ubbf8\ud130 \uc911 1% \ubbf8\ub9cc\ub9cc\uc774 \uc774\ubbf8\uc9c0 \ub0b4 \ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce5c\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. LOCALIZATION OF ATTENTION LAYERS RESPONSIBLE FOR TEXTUAL CONTENT GENERATION"}, {"figure_path": "https://arxiv.org/html/2502.09935/extracted/6198226/figs/lora_generations5.jpg", "caption": "Figure 3: The localized layers effectively balance the text alignment with the target prompt pTsubscript\ud835\udc5d\ud835\udc47p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT and the image alignment with the source prompt pSsubscript\ud835\udc5d\ud835\udc46p_{S}italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT. For ease of exposition, we measure the text alignment with OCR F1 and the image alignment with SSIM. We observe that injecting the target prompt pTsubscript\ud835\udc5d\ud835\udc47p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT to too many layers decreases the image alignment and introduces undesirable artifacts, e.g., the Japanese text on the robot\u2019s chest in 2nd image from the right and the lack of fish in the 1st image from the right. Conversely, injecting pTsubscript\ud835\udc5d\ud835\udc47p_{T}italic_p start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT to too few layers does not edit the generated text.\nWe present more details about the experiment in Appendix\u00a0E.", "description": "\uadf8\ub9bc 3\uc740 \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8(p<sub>S</sub>)\uc640\uc758 \uc774\ubbf8\uc9c0 \uc815\ub82c\uacfc \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8(p<sub>T</sub>)\uc640\uc758 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uac04\uc758 \uade0\ud615\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ub9de\ucd94\ub294 \uc9c0\uc5ed\ud654\ub41c \ub808\uc774\uc5b4\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc124\uba85\uc744 \uac04\uc18c\ud654\ud558\uae30 \uc704\ud574 \ud14d\uc2a4\ud2b8 \uc815\ub82c\uc740 OCR F1 \uc810\uc218\ub85c, \uc774\ubbf8\uc9c0 \uc815\ub82c\uc740 SSIM\uc73c\ub85c \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4. \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8(p<sub>T</sub>)\ub97c \ub108\ubb34 \ub9ce\uc740 \ub808\uc774\uc5b4\uc5d0 \uc8fc\uc785\ud558\uba74 \uc774\ubbf8\uc9c0 \uc815\ub82c\uc774 \uc800\ud558\ub418\uace0(\uc608: \uc624\ub978\ucabd\uc5d0\uc11c \ub450 \ubc88\uc9f8 \uc774\ubbf8\uc9c0\uc758 \ub85c\ubd07 \uac00\uc2b4\uc5d0 \uc788\ub294 \uc77c\ubcf8\uc5b4 \ud14d\uc2a4\ud2b8, \uc624\ub978\ucabd \uccab \ubc88\uc9f8 \uc774\ubbf8\uc9c0\uc5d0 \uc5c6\ub294 \ubb3c\uace0\uae30 \ub4f1) \uc6d0\uce58 \uc54a\ub294 \uc544\ud2f0\ud329\ud2b8\uac00 \ubc1c\uc0dd\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubc18\ub300\ub85c, p<sub>T</sub>\ub97c \ub108\ubb34 \uc801\uc740 \ub808\uc774\uc5b4\uc5d0 \uc8fc\uc785\ud558\uba74 \uc0dd\uc131\ub41c \ud14d\uc2a4\ud2b8\uac00 \uc218\uc815\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \ubd80\ub85d E\uc5d0 \uc2e4\ud5d8\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. CROSS-ATTENTION LAYER LOCALIZATION"}, {"figure_path": "https://arxiv.org/html/2502.09935/x10.png", "caption": "Figure 4: Patching preserves visual components from the source prompt, taking only the textual information from the injected target prompt. In all the combinations of templates and texts that we inject to localized layers of diffusion models (with other layers receiving both source template and source text), the final visual components of the image are always closer to the original template, while the textual content is always aligned with the one from an injected prompt. The source prompt is always defined as pSsubscript\ud835\udc5d\ud835\udc46p_{S}italic_p start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT=TemplateS:TextS, while we change the target prompts to TemplateS:TextS, TemplateS:TextT, and TemplateT:TextT (from left to right for the images).", "description": "\uadf8\ub9bc 4\ub294 \uc81c\uc548\ub41c \ud328\uce58 \uae30\ubc95\uc774 \uc5b4\ub5bb\uac8c \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8\uc758 \uc2dc\uac01\uc801 \uc694\uc18c\ub294 \uc720\uc9c0\ud558\uba74\uc11c \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\uc758 \ud14d\uc2a4\ud2b8 \uc815\ubcf4\ub9cc\uc744 \uc120\ud0dd\uc801\uc73c\ub85c \ud1b5\ud569\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc2e4\ud5d8\uc740 \ub2e4\uc591\ud55c \ud15c\ud50c\ub9bf\uacfc \ud14d\uc2a4\ud2b8 \uc870\ud569\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc218\ud589\ub418\uc5c8\uc73c\uba70, \uad6d\uc18c\ud654\ub41c \ud655\uc0b0 \ubaa8\ub378 \ub808\uc774\uc5b4\uc5d0 \uc8fc\uc785\ub41c \uc815\ubcf4\ub294 \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\uc758 \ud14d\uc2a4\ud2b8\uc640 \uc77c\uce58\ud558\ub294 \ubc18\uba74, \ub2e4\ub978 \ub808\uc774\uc5b4\ub4e4\uc740 \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8\uc758 \uc2dc\uac01\uc801 \uad6c\uc131\uc694\uc18c\ub97c \uc720\uc9c0\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \uc2dc\uac01\uc801 \uc694\uc18c\ub294 \uc18c\uc2a4 \ud15c\ud50c\ub9bf\uacfc \uc720\uc0ac\ud558\uba70, \ud14d\uc2a4\ud2b8 \ub0b4\uc6a9\uc740 \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\uc640 \uc77c\uce58\ud569\ub2c8\ub2e4.  \uc18c\uc2a4 \ud504\ub86c\ud504\ud2b8\ub294 'TemplateS:TextS'\ub85c \uc815\uc758\ub418\uace0, \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\ub294 'TemplateS:TextS', 'TemplateS:TextT', \uadf8\ub9ac\uace0 'TemplateT:TextT'\ub85c \ubcc0\uacbd\ud558\uc5ec \uc2e4\ud5d8\uc774 \uc9c4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4 (\uc774\ubbf8\uc9c0 \uc67c\ucabd\uc5d0\uc11c \uc624\ub978\ucabd \uc21c\uc11c).", "section": "4.1 \ud328\uce58 \uae30\ubc95"}, {"figure_path": "https://arxiv.org/html/2502.09935/x11.png", "caption": "Figure 5: Fine-tuning LoRA on localized layers improves text generation quality without compromising overall generation capabilities.\nWe apply LoRA fine-tuning to the SDXL model to enhance its text generation capabilities.\n(top left) The LoRA fine-tuning on the localized layers converges to a higher quality of the generated text (as measured by OCR F1 and CLIP-T metrics).\n(bottom left) When fine-tuning LoRA on all cross-attention layers (denoted as C-A), the model quickly collapses, losing its ability to generate examples that match the prompt. The diversity is significantly reduced, as indicated by a recall. In contrast, fine-tuning LoRA only on our localized cross-attention layers prevents model overfitting while improving text generation quality. It preserves diversity while achieving higher fidelity measured by precision.\n(right) We also present this effect on sample generations. Longer LoRA fine-tuning (measured in epochs) on localized layers improves text quality while preserving visual content, however, applying LoRA to all layers results in significant degradation of the image quality and diversity.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \uad6d\uc18c\ud654\ub41c \ub808\uc774\uc5b4\uc5d0 LoRA \ubbf8\uc138 \uc870\uc815\uc744 \uc801\uc6a9\ud558\uc5ec SDXL \ubaa8\ub378\uc758 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uae30\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc758 \uc67c\ucabd \uc0c1\ub2e8\uc740 \uad6d\uc18c\ud654\ub41c \ub808\uc774\uc5b4\uc5d0 LoRA \ubbf8\uc138 \uc870\uc815\uc744 \uc801\uc6a9\ud588\uc744 \ub54c OCR F1 \ubc0f CLIP-T \uc9c0\ud45c\ub85c \uce21\uc815\ud588\uc744 \ub54c \uc0dd\uc131\ub41c \ud14d\uc2a4\ud2b8\uc758 \ud488\uc9c8\uc774 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ud558\ub2e8\uc740 \ubaa8\ub4e0 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 LoRA \ubbf8\uc138 \uc870\uc815\uc744 \uc801\uc6a9\ud558\uba74 \ubaa8\ub378\uc774 \ubd95\uad34\ub418\uc5b4 \ud504\ub86c\ud504\ud2b8\uc640 \uc77c\uce58\ud558\ub294 \uc608\uc2dc\ub97c \uc0dd\uc131\ud558\uc9c0 \ubabb\ud558\uace0 \ub2e4\uc591\uc131\uc774 \ud06c\uac8c \uac10\uc18c\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubc18\uba74\uc5d0 \uad6d\uc18c\ud654\ub41c \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0\ub9cc LoRA \ubbf8\uc138 \uc870\uc815\uc744 \uc801\uc6a9\ud558\uba74 \ubaa8\ub378 \uacfc\uc801\ud569\uc744 \ubc29\uc9c0\ud558\uba74\uc11c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\uace0 \uc815\ubc00\ub3c4\ub97c \ub192\uc774\uba70 \ub2e4\uc591\uc131\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc758 \uc624\ub978\ucabd\uc5d0\ub294 \uc0d8\ud50c \uc0dd\uc131 \uacb0\uacfc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uad6d\uc18c\ud654\ub41c \ub808\uc774\uc5b4\uc5d0 \ub300\ud55c \uc7a5\uae30\uac04 LoRA \ubbf8\uc138 \uc870\uc815(\uc5d0\ud3ec\ud06c \ub2e8\uc704)\uc744 \ud1b5\ud574 \uc2dc\uac01\uc801 \ucf58\ud150\uce20\ub97c \uc720\uc9c0\ud558\uba74\uc11c \ud14d\uc2a4\ud2b8 \ud488\uc9c8\uc774 \ud5a5\uc0c1\ub418\ub294 \ubc18\uba74, \ubaa8\ub4e0 \ub808\uc774\uc5b4\uc5d0 \uc801\uc6a9\ud558\uba74 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uacfc \ub2e4\uc591\uc131\uc774 \ud06c\uac8c \uc800\ud558\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.1 LoRA\ub97c \ud1b5\ud55c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uac1c\uc120"}, {"figure_path": "https://arxiv.org/html/2502.09935/x12.png", "caption": "(a) Image alignment vs Diffusion Patching Timestep SD3.", "description": "\uadf8\ub9bc 6(a)\ub294 Stable Diffusion 3 \ubaa8\ub378\uc5d0\uc11c \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc5d0 \ub530\ub978 \uc774\ubbf8\uc9c0 \uc815\ub82c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc744 \ub2e4\ub974\uac8c \ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc640 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0 \uac04\uc758 MSE(Mean Squared Error), SSIM(Structural Similarity Index), PSNR(Peak Signal-to-Noise Ratio) \uac12\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ucd5c\uc801\uc758 \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc744 \ucc3e\uc544 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uc744 \uac1c\uc120\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4.1 \ud328\uce58 \uae30\ubc95"}, {"figure_path": "https://arxiv.org/html/2502.09935/x13.png", "caption": "(b) Text alignment vs Diffusion Patching Timestep SD3.", "description": "\uadf8\ub9bc (b)\ub294 Stable Diffusion 3 \ubaa8\ub378\uc5d0\uc11c \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc5d0 \ub530\ub978 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc138\ub85c\ucd95\uc740 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uc131\ub2a5 \uc9c0\ud45c (OCR F1, CLIP-T, LD)\uc774\uba70, \uac00\ub85c\ucd95\uc740 \ud328\uce58\ub97c \uc2dc\uc791\ud558\ub294 \ub514\ud4e8\uc804(denoising) \ub2e8\uacc4(timestep)\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 \ub2e4\uc591\ud55c \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ud328\uce58\ub97c \uc801\uc6a9\ud588\uc744 \ub54c, \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \ud14d\uc2a4\ud2b8\uac00 \ud0c0\uac9f \ud504\ub86c\ud504\ud2b8\uc640 \uc5bc\ub9c8\ub098 \uc798 \uc77c\uce58\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \ud328\uce58 \uc2dc\uc791 \uc2dc\uc810\uc744 \uc5b4\ub5bb\uac8c \uc870\uc808\ud558\ub290\ub0d0\uc5d0 \ub530\ub77c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uc815\ud655\ub3c4\uac00 \ub2ec\ub77c\uc9d0\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.", "section": "4.1 \ud328\uce58 \uae30\ubc95"}, {"figure_path": "https://arxiv.org/html/2502.09935/x14.png", "caption": "(c) Image alignment vs Diffusion Patching Timestep DeepFloyd IF.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepFloyd IF \ubaa8\ub378\uc5d0\uc11c \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc5d0 \ub530\ub978 \uc774\ubbf8\uc9c0 \uc815\ub82c(alignment)\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc2dc \ub9d0\ud574, \ud14d\uc2a4\ud2b8 \ud3b8\uc9d1\uc744 \uc704\ud574 \ud655\uc0b0 \ubaa8\ub378\uc758 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 \ud328\uce58\ub97c \uc801\uc6a9\ud558\ub294 \uc2dc\uc791 \ub2e8\uacc4(timestep)\ub97c \ubc14\uafd4\uac00\uba74\uc11c \uc774\ubbf8\uc9c0\uc758 \ub2e4\ub978 \ubd80\ubd84(\ud14d\uc2a4\ud2b8\uac00 \uc544\ub2cc \ubd80\ubd84)\uc774 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc640 \uc5bc\ub9c8\ub098 \uc720\uc0ac\ud55c\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uc785\ub2c8\ub2e4.  MSE(Mean Squared Error), SSIM(Structural Similarity Index), PSNR(Peak Signal-to-Noise Ratio) \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \uc720\uc0ac\uc131\uc744 \uce21\uc815\ud569\ub2c8\ub2e4. x\ucd95\uc740 \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04, y\ucd95\uc740 \uc774\ubbf8\uc9c0 \uc815\ub82c \ucc99\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub294 \ud14d\uc2a4\ud2b8 \ud3b8\uc9d1 \uc2dc \uc774\ubbf8\uc9c0 \ud488\uc9c8 \ubcf4\uc874\uc5d0 \ucd5c\uc801\uc758 \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04\uc744 \ucc3e\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4.1 PATCHING TECHNIQUE"}, {"figure_path": "https://arxiv.org/html/2502.09935/x15.png", "caption": "(d) Text alignment vs Diffusion Patching Timestep DeepFloyd IF.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepFloyd IF \ubaa8\ub378\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \uc815\ub82c\uacfc \ud655\uc0b0 \ud328\uce58\uc758 \uc2dc\uac04 \ub2e8\uacc4 \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ud328\uce58\ub97c \uc2dc\uc791\ud588\uc744 \ub54c\uc758 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc758 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ub2a5\ub825\uc5d0 \ub300\ud55c \uc2dc\uac04 \ub2e8\uacc4\uc758 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uae30 \uc704\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ub098\ud0c0\ub0b8 \uac83\uc785\ub2c8\ub2e4.  x\ucd95\uc740 \ud328\uce58 \uc2dc\uc791 \uc2dc\uac04 \ub2e8\uacc4, y\ucd95\uc740 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uc9c0\ud45c(\uc608: OCR F1 \uc810\uc218, CLIP-T \uc810\uc218, LD)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4.1 PATCHING TECHNIQUE"}, {"figure_path": "https://arxiv.org/html/2502.09935/x16.png", "caption": "(e) Image alignment vs Diffusion Patching Timestep SDXL.", "description": "\uadf8\ub9bc (e)\ub294 SDXL \ud655\uc0b0 \ubaa8\ub378\uc5d0\uc11c \ud328\uce58\ub97c \uc2dc\uc791\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ub294 \ud655\uc0b0 \ub2e8\uacc4(denoising timestep)\uac00 \uc774\ubbf8\uc9c0 \uc815\ub82c\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\ub978 \ub2e8\uacc4\uc5d0\uc11c \ud328\uce58\ub97c \uc2dc\uc791\ud558\ub294 \uac83\uc774 \uc774\ubbf8\uc9c0\uc758 \uc2dc\uac01\uc801 \ud2b9\uc9d5\uc744 \uc5bc\ub9c8\ub098 \uc798 \ubcf4\uc874\ud558\ub294\uc9c0, \uc989 \uc6d0\ubcf8 \ud504\ub86c\ud504\ud2b8\uc640 \uc5bc\ub9c8\ub098 \uc720\uc0ac\ud55c \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\ub294\uc9c0\uc5d0 \ub300\ud55c \ube44\uad50 \ubd84\uc11d \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. x\ucd95\uc740 \ud328\uce58 \uc2dc\uc791 \ub2e8\uacc4\ub97c, y\ucd95\uc740 MSE(Mean Squared Error), SSIM(Structural Similarity Index), PSNR(Peak Signal-to-Noise Ratio) \uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. MSE\ub294 \uc774\ubbf8\uc9c0 \ucc28\uc774\ub97c, SSIM\uacfc PSNR\uc740 \uc774\ubbf8\uc9c0 \uc720\uc0ac\ub3c4\ub97c \uce21\uc815\ud558\ub294 \uc9c0\ud45c\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub798\ud504\ub97c \ud1b5\ud574 \uc5b4\ub5a4 \ub2e8\uacc4\uc5d0\uc11c \ud328\uce58\ub97c \uc2dc\uc791\ud558\ub294 \uac83\uc774 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uc5d0 \uac00\uc7a5 \uc801\ud569\ud55c\uc9c0 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 \ud328\uce58 \uae30\ubc95"}, {"figure_path": "https://arxiv.org/html/2502.09935/x17.png", "caption": "(f) Text alignment vs Diffusion Patching Timestep SDXL.", "description": "\uc774 \uadf8\ub9bc\uc740 SDXL \ubaa8\ub378\uc5d0\uc11c \ud14d\uc2a4\ud2b8 \uc815\ub82c\uc5d0 \ub300\ud55c \ud655\uc0b0 \ud328\uce58\uc758 \uc2dc\uc810 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \uc2dc\uc791 \uc2dc\uc810\uc5d0\uc11c \ud655\uc0b0 \ud328\uce58\ub97c \uc801\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uacb0\uacfc(OCR F1 \uc810\uc218, CLIP-T \uc810\uc218, Levenshtein \uac70\ub9ac)\ub97c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ucd5c\uc801\uc758 \ud328\uce58 \uc2dc\uc791 \uc2dc\uc810\uc744 \ucc3e\uc544 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uadf8\ub9bc\uc740 SDXL \ubaa8\ub378\uc758 \uc5ec\ub7ec \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 \ud328\uce58\ub97c \uc801\uc6a9\ud588\uc744 \ub54c \uc2dc\uac04 \uacbd\uacfc\uc5d0 \ub530\ub978 \ud14d\uc2a4\ud2b8 \uc815\ub82c \uc9c0\ud45c\uc758 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub798\ud504\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.", "section": "4.1 \ud328\uce58 \uae30\ubc95"}, {"figure_path": "https://arxiv.org/html/2502.09935/x18.png", "caption": "Figure 6: Starting the text edition from a later diffusion timestep improves both image and text alignment.\nWe analyze the impact of the diffusion timestep from which we start the patching on the image and text alignment. We observe that we can find an optimum diffusion timestep that can simultaneously improve image and text quality.", "description": "\uadf8\ub9bc 6\uc740 \ud14d\uc2a4\ud2b8 \ud3b8\uc9d1\uc744 \uc2dc\uc791\ud558\ub294 \ud655\uc0b0(diffusion) \ub2e8\uacc4\uc758 \uc2dc\uc810\uc774 \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8 \uc815\ub82c \ubaa8\ub450\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud55c \uac83\uc785\ub2c8\ub2e4. \ubd84\uc11d \uacb0\uacfc, \ud328\uce58(patching)\ub97c \uc2dc\uc791\ud558\ub294 \ucd5c\uc801\uc758 \ud655\uc0b0 \ub2e8\uacc4\ub97c \ucc3e\uc73c\uba74 \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8 \ud488\uc9c8\uc744 \ub3d9\uc2dc\uc5d0 \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \ub108\ubb34 \uc774\ub978 \ub2e8\uacc4\uc5d0\uc11c \ud328\uce58\ub97c \uc2dc\uc791\ud558\uba74 \uc774\ubbf8\uc9c0 \ud488\uc9c8\uc774 \uc800\ud558\ub418\uace0, \ub108\ubb34 \ub2a6\uc740 \ub2e8\uacc4\uc5d0\uc11c \uc2dc\uc791\ud558\uba74 \ud14d\uc2a4\ud2b8 \ud488\uc9c8\uc774 \ub5a8\uc5b4\uc9c8 \uc218 \uc788\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ucd5c\uc801\uc758 \ud0c0\uc774\ubc0d\uc744 \ucc3e\uc544 \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8 \ubaa8\ub450\uc758 \ud488\uc9c8\uc744 \uac1c\uc120\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\uc744 \uc81c\uc2dc\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 PATCHING TECHNIQUE"}, {"figure_path": "https://arxiv.org/html/2502.09935/x19.png", "caption": "Figure 7: \nLoRA SDXL Fine-Tuning Across Different Setups. We fine-tune LoRA applied to the SDXL model to improve the text generation capabilities of the base model. When we fine-tune LoRA on all cross-attention layers, the model quickly collapses and loses its ability to generate examples that match the prompt. In contrast, when we fine-tune LoRA only on our localized three cross-attention layers, we successfully prevent model overfitting while also improving text generation quality. This trend is not observed when we apply LoRA to other sets of three layers.", "description": "\ubcf8 \uadf8\ub9bc\uc740 LoRA\ub97c \uc0ac\uc6a9\ud558\uc5ec SDXL \ubaa8\ub378\uc758 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub4e0 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 LoRA\ub97c \uc801\uc6a9\ud588\uc744 \ub54c \ubaa8\ub378\uc774 \uacfc\uc801\ud569\ub418\uc5b4 \ud504\ub86c\ud504\ud2b8\uc640 \uc77c\uce58\ud558\ub294 \uc608\uc81c\ub97c \uc0dd\uc131\ud558\uc9c0 \ubabb\ud558\ub294 \ubc18\uba74, \uc5f0\uad6c\uc5d0\uc11c \uc2dd\ubcc4\ub41c \uc138 \uac1c\uc758 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0\ub9cc LoRA\ub97c \uc801\uc6a9\ud588\uc744 \ub54c \uacfc\uc801\ud569\uc744 \ubc29\uc9c0\ud558\uba74\uc11c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ud488\uc9c8\uc744 \ud5a5\uc0c1\uc2dc\ucf30\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\ub978 \uc138 \uac1c\uc758 \ub808\uc774\uc5b4 \uc9d1\ud569\uc5d0 LoRA\ub97c \uc801\uc6a9\ud588\uc744 \ub54c\ub294 \uc774\ub7ec\ud55c \ucd94\uc138\uac00 \uad00\ucc30\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.", "section": "5.1 LoRA\ub97c \ud1b5\ud55c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uac1c\uc120"}, {"figure_path": "https://arxiv.org/html/2502.09935/x20.png", "caption": "Figure 8: Scaling up training size when fine-tuning all cross-attention layers does not prevent model collapse. Increasing the training dataset size fails to mitigate model collapse, as evidenced by the significant drop in Recall and Precision metrics. In contrast, our approach, which fine-tunes only localized cross-attention layers, demonstrates consistent performance regardless of training set size.", "description": "\uadf8\ub9bc 8\uc740 \ubaa8\ub4e0 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub97c \ubbf8\uc138 \uc870\uc815\ud560 \ub54c \ud2b8\ub808\uc774\ub2dd \ub370\uc774\ud130\uc14b \ud06c\uae30\ub97c \ub298\ub824\ub3c4 \ubaa8\ub378 \ubd95\uad34\ub97c \ub9c9\uc744 \uc218 \uc5c6\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Recall \ubc0f Precision \uc9c0\ud45c\uc758 \uc0c1\ub2f9\ud55c \uac10\uc18c\uc5d0\uc11c \uc54c \uc218 \uc788\ub4ef\uc774, \ud2b8\ub808\uc774\ub2dd \ub370\uc774\ud130\uc14b \ud06c\uae30 \uc99d\uac00\ub294 \ubaa8\ub378 \ubd95\uad34\ub97c \uc644\ud654\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4. \ubc18\uba74\uc5d0, \uad6d\uc18c \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub9cc \ubbf8\uc138 \uc870\uc815\ud558\ub294 \uc5f0\uad6c\ud300\uc758 \ubc29\ubc95\uc740 \ud2b8\ub808\uc774\ub2dd \ub370\uc774\ud130\uc14b \ud06c\uae30\uc5d0 \uad00\uacc4\uc5c6\uc774 \uc77c\uad00\ub41c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \uc81c\ud55c\ub41c \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub9cc \uc870\uc815\ud558\ub294 \uac83\uc774 \ubaa8\ub378 \uc548\uc815\uc131\uc744 \uc720\uc9c0\ud558\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "5.1 LoRA\ub97c \ud1b5\ud55c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uac1c\uc120"}, {"figure_path": "https://arxiv.org/html/2502.09935/x21.png", "caption": "Figure 9: LoRA fine-tuning of localized layers outperforms fine-tuning of all cross-attention layers, even with smaller datasets. LoRA fine-tuning of localized layers achieves consistent performance across all evaluated training set sizes, from 20k to 200k samples. While increasing the dataset size slightly improves the performance of the model when all cross-attention layers are fine-tuned, a noticeable performance gap remains compared to localized fine-tuning.", "description": "\uadf8\ub9bc 9\ub294 \uad6d\uc18c\ud654\ub41c \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 \ub300\ud55c LoRA \ubbf8\uc138 \uc870\uc815\uc774 \ubaa8\ub4e0 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\uc5d0 \ub300\ud55c \ubbf8\uc138 \uc870\uc815\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 2\ub9cc\uac1c\uc5d0\uc11c 20\ub9cc\uac1c\uae4c\uc9c0 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc5d0\uc11c\ub3c4 \uc77c\uad00\ub41c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.  \ubaa8\ub4e0 \ud06c\ub85c\uc2a4 \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\ub97c \ubbf8\uc138 \uc870\uc815\ud560 \ub54c \ub370\uc774\ud130\uc14b \ud06c\uae30\uac00 \uc99d\uac00\ud558\uba74 \ubaa8\ub378 \uc131\ub2a5\uc774 \uc57d\uac04 \ud5a5\uc0c1\ub418\uc9c0\ub9cc, \uad6d\uc18c\ud654\ub41c \ubbf8\uc138 \uc870\uc815\uacfc \ube44\uad50\ud588\uc744 \ub54c \uc0c1\ub2f9\ud55c \uc131\ub2a5 \ucc28\uc774\uac00 \ub0a8\uc544\uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc989, \ub354 \uc801\uc740 \ub9e4\uac1c\ubcc0\uc218\ub9cc \ubbf8\uc138 \uc870\uc815\ud558\ub354\ub77c\ub3c4 \uc804\uccb4 \ubaa8\ub378 \uc131\ub2a5\uc744 \ud06c\uac8c \uac1c\uc120\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "5.1 LoRA\ub97c \uc0ac\uc6a9\ud55c \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \uac1c\uc120"}, {"figure_path": "https://arxiv.org/html/2502.09935/x24.png", "caption": "Figure 10: \nComparison of facial expression scores (average), extracted from generations of a man holding a sign with toxic texts. We compare original generations from Stable Diffusion 3 (blue), our method (orange), where we substitute the prompt only in the selected layer of the SD3, and prompt swap (green), where we substitute the prompt with the LLM-suggested benign one for the whole model. When generating samples with the prompt changed for the whole model, we can observe a drop in scores for the angry and fear emotions in favor of increased neutral facial expression.", "description": "\uadf8\ub9bc 10\uc740 \ub3c5\uc131\uc774 \uc788\ub294 \ubb38\uad6c\uac00 \uc801\ud78c \ud45c\uc9c0\ub97c \ub4e4\uace0 \uc788\ub294 \ub0a8\uc131\uc758 \uc5bc\uad74 \ud45c\uc815 \uc810\uc218(\ud3c9\uade0)\ub97c \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. Stable Diffusion 3(\ud30c\ub780\uc0c9)\uc758 \uc6d0\ubcf8 \uc774\ubbf8\uc9c0 \uc0dd\uc131, \uc120\ud0dd\ub41c SD3 \ub808\uc774\uc5b4\uc5d0\uc11c \ud504\ub86c\ud504\ud2b8\ub97c \ub300\uccb4\ud55c \uc800\ud76c \ubc29\ubc95(\uc8fc\ud669\uc0c9), \uadf8\ub9ac\uace0 \uc804\uccb4 \ubaa8\ub378\uc758 \ud504\ub86c\ud504\ud2b8\ub97c LLM\uc774 \uc81c\uc548\ud55c \ubb34\ud574\ud55c \ubb38\uad6c\ub85c \ub300\uccb4\ud55c \ud504\ub86c\ud504\ud2b8 \uad50\uccb4(\ub179\uc0c9)\ub97c \ube44\uad50 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4. \ud504\ub86c\ud504\ud2b8\uac00 \uc804\uccb4 \ubaa8\ub378\uc5d0 \ubcc0\uacbd\ub41c \uacbd\uc6b0, \ubd84\ub178\uc640 \uacf5\ud3ec \ud45c\ud604 \uc810\uc218\ub294 \uac10\uc18c\ud558\uace0, \uc911\ub9bd\uc801\uc778 \ud45c\uc815 \uc810\uc218\ub294 \uc99d\uac00\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "5.3 \ub3c5\uc131 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ubc29\uc9c0"}, {"figure_path": "https://arxiv.org/html/2502.09935/x25.png", "caption": "Figure 11: \nInfluence of generated text on the final generation. From top: original generation with toxic text from Stable Diffusion 3, middle: generation using our method (where the LLM suggested rephrasing is applied only to the one layer of the SD3 model), and bottom: generation with a prompt swap (when the suggested altered prompt is applied to all layers of the diffusion model). Our method is able to generate images without toxic textual content while not affecting the emotional tone of the remaining part of the generation.", "description": "\uadf8\ub9bc 11\uc740 \ub3c5\uc131\uc774 \uc788\ub294 \ud14d\uc2a4\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc138 \uac00\uc9c0 \ub2e4\ub978 \ubc29\ubc95\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0c1\ub2e8\uc740 Stable Diffusion 3\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uc6d0\ubcf8 \uc774\ubbf8\uc9c0, \uc911\uac04\uc740 \uc81c\uc548\ub41c \ubc29\ubc95(LLM\uc5d0\uc11c \uc81c\uc548\ud55c \uc218\uc815\ub41c \ud14d\uc2a4\ud2b8\uac00 SD3 \ubaa8\ub378\uc758 \ud55c \ub808\uc774\uc5b4\uc5d0\ub9cc \uc801\uc6a9\ub428), \ud558\ub2e8\uc740 \ud504\ub86c\ud504\ud2b8 \uad50\uccb4(\uc218\uc815\ub41c \ud504\ub86c\ud504\ud2b8\uac00 \ubaa8\ub378\uc758 \ubaa8\ub4e0 \ub808\uc774\uc5b4\uc5d0 \uc801\uc6a9\ub428)\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc81c\uc548\ub41c \ubc29\ubc95\uc774 \ub3c5\uc131\uc774 \uc788\ub294 \ud14d\uc2a4\ud2b8 \ub0b4\uc6a9 \uc5c6\uc774 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uba74\uc11c\ub3c4 \ub098\uba38\uc9c0 \ubd80\ubd84\uc758 \uac10\uc815\uc801 \uc5b4\uc870\ub294 \uc720\uc9c0\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.3 \ub3c5\uc131 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ubc29\uc9c0"}, {"figure_path": "https://arxiv.org/html/2502.09935/x26.png", "caption": "Figure 12: Example results for methods for preventing toxic text in generated images. Negative Prompt and Safe Diffusion methods are incapable of removing foul words from the images. In Prompt Swap, the background of generated images is highly influenced by the suggested word. We show that our method successfully changes foul words yet ensures minimal changes to the other visual aspects of the image. Orange bounding boxes were added by the authors to cover four words.", "description": "\uadf8\ub9bc 12\ub294 \ub3c5\uc131\uc774 \uc788\ub294 \ud14d\uc2a4\ud2b8 \uc0dd\uc131\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud55c \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Negative Prompt\uc640 Safe Diffusion \ubc29\ubc95\uc740 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ubd80\uc801\uc808\ud55c \ub2e8\uc5b4\ub97c \uc81c\uac70\ud558\ub294 \ub370 \uc2e4\ud328\ud588\uc2b5\ub2c8\ub2e4. Prompt Swap\uc5d0\uc11c\ub294 \uc81c\uc548\ub41c \ub2e8\uc5b4\uc5d0 \uc758\ud574 \uc0dd\uc131\ub41c \uc774\ubbf8\uc9c0\uc758 \ubc30\uacbd\uc774 \ud06c\uac8c \uc601\ud5a5\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ubc29\ubc95\uc740 \ubd80\uc801\uc808\ud55c \ub2e8\uc5b4\ub97c \uc131\uacf5\uc801\uc73c\ub85c \ubcc0\uacbd\ud558\uba74\uc11c \uc774\ubbf8\uc9c0\uc758 \ub2e4\ub978 \uc2dc\uac01\uc801 \uce21\uba74\uc5d0\ub294 \ucd5c\uc18c\ud55c\uc758 \ubcc0\uacbd\ub9cc\uc744 \uc720\uc9c0\ud569\ub2c8\ub2e4. \uc8fc\ud669\uc0c9 \ud14c\ub450\ub9ac\ub294 \uc800\uc790\ub4e4\uc774 \ub124 \ub2e8\uc5b4\ub97c \ubb36\uae30 \uc704\ud574 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "5.3 \ub3c5\uc131 \ud14d\uc2a4\ud2b8 \uc0dd\uc131 \ubc29\uc9c0"}]