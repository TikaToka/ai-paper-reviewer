{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces the foundational latent diffusion model that VideoGrain builds upon for video editing, providing the core framework for the advancements made in VideoGrain."}, {"fullname_first_author": "Jiaming Song", "paper_title": "Denoising diffusion implicit models", "publication_date": "2021-00-00", "reason": "This paper presents the fundamental denoising diffusion process used in VideoGrain for video generation and editing, providing the underlying mechanism for many aspects of VideoGrain's functionality."}, {"fullname_first_author": "Omri Avrahami", "paper_title": "Blended diffusion for text-driven editing of natural images", "publication_date": "2022-00-00", "reason": "This paper introduces a key technique used in VideoGrain, the latent blending method, which enables seamless integration of edits while preserving the background context of the video."}, {"fullname_first_author": "Zachary Teed", "paper_title": "RAFT: Recurrent all-pairs field transforms for optical flow", "publication_date": "2020-00-00", "reason": "The RAFT model, for accurate optical flow estimation, is leveraged in VideoGrain to maintain temporal consistency during video editing, ensuring smooth and realistic transitions between frames."}, {"fullname_first_author": "Yoni Kasten", "paper_title": "Layered neural atlases for consistent video editing", "publication_date": "2021-00-00", "reason": "This paper introduces techniques for consistent video editing, which are incorporated into VideoGrain's methodology for handling temporal coherence in video editing tasks."}]}