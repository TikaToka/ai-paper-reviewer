<table id='10' style='font-size:18px'><tr><td>Parameter</td><td>Llama3-8B</td><td>Mistral-7B</td></tr><tr><td>Train BS</td><td>128</td><td>128</td></tr><tr><td>Micro Train BS</td><td>1</td><td>1</td></tr><tr><td>Max Length</td><td>4096</td><td>4096</td></tr><tr><td>Learning Rate</td><td>3e-7</td><td>3e-7</td></tr><tr><td>Beta</td><td>0.01</td><td>0.01</td></tr><tr><td>Weight Decay</td><td>0.0</td><td>0.0</td></tr><tr><td>LR Scheduler</td><td>cosine_with_min_lr</td><td>cosine_with_min_lr</td></tr><tr><td>Warmup Ratio</td><td>0.03</td><td>0.03</td></tr><tr><td>Optimizer</td><td>Adam</td><td>Adam</td></tr><tr><td>Epoch</td><td>1</td><td>1</td></tr><tr><td>Zero Stage</td><td>3</td><td>2</td></tr><tr><td>Adam Offload</td><td>True</td><td>False</td></tr><tr><td>w (scaling coefficient)</td><td>1.0</td><td>0.5</td></tr></table>