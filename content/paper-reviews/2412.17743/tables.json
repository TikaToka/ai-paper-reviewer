[{"content": "| Model | n<sub>layers</sub> | d<sub>model</sub> | r<sub>ffn</sub> | n<sub>heads</sub> | n<sub>kv_heads</sub> |\n|---|---|---|---|---|---| \n| LLaMA-3.2-3B | 28 | 3,072 | 2.7 | 24 | 8 |\n| Phi-3-mini-4k-instruct | 32 | 3,072 | 2.7 | 32 | 32 |\n| MiniCPM-2B | 40 | 2,304 | 2.5 | 36 | 36 |\n| MiniCPM3-4B | 62 | 2,560 | 2.5 | 40 | 40 |\n| Qwen2.5-1.5B | 28 | 1,536 | 5.8 | 12 | 2 |\n| MobileLLM-1B | 54 | 1,280 | 2.8 | 20 | 5 |\n| YuLan-Mini | 56 | 1,920 | 2.5 | 30 | 6 |", "caption": "Table 1: Hyperparameter settings of diffrent models. rffnsubscript\ud835\udc5fffnr_{\\text{ffn}}italic_r start_POSTSUBSCRIPT ffn end_POSTSUBSCRIPT is the ratio of the feed-forward network\u2019s hidden size to the model\u2019s hidden size. The definition of the symbols is available at Table\u00a08", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubaa8\ub378\uc758 \ucd08\ub9e4\uac1c\ubcc0\uc218 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  `rffnsubscript\ud835\udc5fffnr_{ffn}`\uc740 \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub124\ud2b8\uc6cc\ud06c\uc758 \ud788\ub4e0 \uc0ac\uc774\uc988\uc640 \ubaa8\ub378\uc758 \ud788\ub4e0 \uc0ac\uc774\uc988\uc758 \ube44\uc728\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \ub808\uc774\uc5b4 \uc218, \uc784\ubca0\ub529 \ucc28\uc6d0, \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub124\ud2b8\uc6cc\ud06c\uc758 \ud788\ub4e0 \uc0ac\uc774\uc988, \ud5e4\ub4dc \uc218, KV \ud5e4\ub4dc \uc218 \ub4f1\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c 8\uc5d0 \ub098\uba38\uc9c0 \uae30\ud638\uc5d0 \ub300\ud55c \uc815\uc758\uac00 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ucd08\ub9e4\uac1c\ubcc0\uc218 \uc124\uc815\uc744 \ube44\uad50\ud558\uc5ec \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98\uc758 \ucc28\uc774\ub97c \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "2.1 \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98"}, {"content": "| Tokenizer | Vocabulary Size | Web | Chinese | Math | Code |\n|---|---|---|---|---|---| \n| Gemma2-2B | 256,000 | 4.928 | 3.808 | 2.865 | 3.309 |\n| Qwen2.5 | 151,936 | 4.935 | 3.956 | 2.890 | 3.881 |\n| LLaMA-3.1 | 128,000 | 4.994 | 3.263 | 3.326 | 3.911 |\n| MiniCPM-2.4B | 122,753 | 4.753 | 4.273 | 2.739 | 3.052 |\n| Phi-3.5-mini | 100,352 | 4.311 | 1.914 | 2.654 | 3.110 |\n| MiniCPM-1.2B | 73,440 | 4.631 | 4.042 | 2.696 | 3.017 |\n| YuLan-Mini | 99,000 | 4.687 | 4.147 | 2.716 | 3.033 |\n| YuLan-Mini + Dropout | 99,000 | 4.687 | 4.146 | 2.715 | 3.031 |", "caption": "Table 2: Compression rate of different tokenizers. Higher values indicate more effective compression.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \ud1a0\ud06c\ub098\uc774\uc800\uc758 \uc555\ucd95\ub960\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc555\ucd95\ub960\uc740 \ud1a0\ud06c\ub098\uc774\uc800\uac00 \uc785\ub825 \ud14d\uc2a4\ud2b8\ub97c \ud1a0\ud070\uc73c\ub85c \ubcc0\ud658\ud560 \ub54c \uc5bc\ub9c8\ub098 \ud6a8\uc728\uc801\uc73c\ub85c \uacf5\uac04\uc744 \uc808\uc57d\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac12\uc774 \ud074\uc218\ub85d \ub354 \ud6a8\uacfc\uc801\uc778 \uc555\ucd95\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc5b4\ud718 \ud06c\uae30, \uc6f9 \ub370\uc774\ud130, \uc911\uad6d\uc5b4 \ub370\uc774\ud130, \uc218\ud559 \ub370\uc774\ud130 \ubc0f \ucf54\ub4dc \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uac01 \ud1a0\ud06c\ub098\uc774\uc800\uc758 \uc555\ucd95\ub960\uc744 \ube44\uad50\ud558\uc5ec \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uacfc \uc131\ub2a5\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "2 Overall Pre-Training Configuration"}, {"content": "Method | SI | MiniCPM | CerebrasGPT | YuLan-Mini\n---|---|---|---|---\nScale Embedding Output | 1 | 12 | 10 | 10\nScale MHA equation | $1/\\sqrt{d_{head}}$ | $1/\\sqrt{d_{head}}$ | $1/d_{head}$ | $1/\\sqrt{d_{head}}$\nScale Residual Connection | 1 | $\\frac{1.4}{\\sqrt{n_{layers}}}$ | 1 | $\\frac{1.4}{\\sqrt{n_{layers}}}$\nQKV Weights LR | $\\eta_{base}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$\nQKV $\\sigma$ Init | $\\sigma_{base}^{2}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$\nO Weights LR | $\\eta_{base}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$\nO $\\sigma$ Init | $\\frac{\\sigma_{base}^{2}}{2n_{layers}}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\frac{\\sigma_{base}^{2}}{2m_{width}\\cdot n_{layers}}$\nFFN1 Weights LR | $\\eta_{base}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$\nFFN1 $\\sigma$ Init | $\\sigma_{base}^{2}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$\nFFN2 Weights LR | $\\eta_{base}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$ | $\\eta_{base}/m_{width}$\nFFN2 $\\sigma$ Init | $\\frac{\\sigma_{base}^{2}}{2n_{layers}}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\sigma_{base}^{2}/m_{width}$ | $\\frac{\\sigma_{base}^{2}}{2m_{width}\\cdot n_{layers}}$\nScale Output logits | 1 | $1/m_{width}$ | $1/m_{width}$ | 1", "caption": "Table 3: Comparison of the used hyperparameter settings for training stability, where the detailed explanation for the variables are in Table\u00a08.\nWe include SI\u00a0(Takase et\u00a0al., 2023) for comparison, MiniCPM\u00a0(Hu et\u00a0al., 2024), CerebrasGPT\u00a0(Dey et\u00a0al., 2023a). The definition of the symbols is available at Table\u00a08 .", "description": "\ud45c 3\uc740 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c \uc0ac\uc6a9\ub418\ub294 \ucd08\ubaa8\uc218 \uc124\uc815\uc744 \ube44\uad50\ud558\uc5ec \ubaa8\ub378 \ud559\uc2b5 \uc548\uc815\uc131\uc5d0 \ub300\ud55c \uc774\ud574\ub97c \ub3d5\ub294 \ud45c\uc785\ub2c8\ub2e4.  Takase et al.(2023)\uc758 SI \ubaa8\ub378, Hu et al.(2024)\uc758 MiniCPM \ubaa8\ub378, Dey et al.(2023a)\uc758 CerebrasGPT \ubaa8\ub378\uc744 \ube44\uad50 \ub300\uc0c1\uc73c\ub85c \ud3ec\ud568\ud558\uc5ec YuLan-Mini \ubaa8\ub378\uc758 \ucd08\ubaa8\uc218 \uc124\uc815\uc744 \ubcf4\ub2e4 \uc790\uc138\ud788 \uc0b4\ud3b4\ubd05\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc758 \uc784\ubca0\ub529 \ud06c\uae30 \uc870\uc815, \uc794\ucc28 \uc5f0\uacb0, \uadf8\ub9ac\uace0 \ub2e4\uc591\ud55c \uac00\uc911\uce58 \ud589\ub82c\uc5d0 \ub300\ud55c \ud559\uc2b5\ub960 \ubc0f \ucd08\uae30\ud654 \ubc29\uc2dd\uc5d0 \ub300\ud55c \uc138\ubd80\uc801\uc778 \uc124\uc815\uc744 \ube44\uad50\ud558\uc5ec YuLan-Mini \ubaa8\ub378\uc758 \ud559\uc2b5 \uc548\uc815\uc131\uc744 \uc704\ud55c \ucd08\ubaa8\uc218 \uc124\uc815 \uc804\ub7b5\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.  \ud45c\uc5d0 \uc0ac\uc6a9\ub41c \ubcc0\uc218\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc124\uba85\uc740 \ubcf8 \ub17c\ubb38\uc758 \ud45c 8\uc5d0 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3.2 \uc548\uc815\uc131 \ud5a5\uc0c1 \uae30\ubc95"}, {"content": "| Type | Source | Volume |\n|---|---|---|\n| Web Pages | FineWeb-Edu, DCLM, Chinese-FineWeb-Edu | 559.76B |\n| Math (Pretrain) | AutoMathText, Proof-Pile-2, OpenWebMath Pro | 85.00B |\n| Code (Pretrain) | the-stack-v2, StarCoder | 202.44B |\n| General Knowledge | arXiv, StackExchange, English News | 121.87B |\n| Books | CBook, Gutenberg, LoC-PD-Books | 52.13B |\n| Encyclopedia | Wikipedia, Baidu-Baike | 14.80B |\n| Open-Source Instruction | SlimOrca, OpenMathInstruct-1, JiuZhang3.0 | 11.64B |\n| Synthetic Pretrain Data (Ours) | Synthetic document (seed: AutoMathText, LeetCode) | 8.76B |\n| Synthetic Instruction (Ours) | Reasoning (seed: MetaMathQA, DeepMind Math, \u2026) | 23.52B |\n| Total | - | 1,080B |", "caption": "Table 4: Statistical information of the entire pre-training corpus for YuLan-Mini. The data during the annealing process is detailed in Table\u00a05. For model reproducibility, all curated datasets are placed in Appendix\u00a0D, and the remaining synthetic data we generated is open-sourced.", "description": "\ubcf8 \ud45c\ub294 YuLan-Mini \uc0ac\uc804 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \uc804\uccb4 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\uc801 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd1d 1.08\uc870 \ud1a0\ud070 \uaddc\ubaa8\uc774\uba70, \uc6f9 \ud398\uc774\uc9c0, \uc218\ud559, \ucf54\ub4dc, \uc77c\ubc18 \uc9c0\uc2dd, \ub3c4\uc11c, \ubc31\uacfc\uc0ac\uc804, \uc624\ud508\uc18c\uc2a4 \uc9c0\uc2dc \ub370\uc774\ud130 \ub4f1 \ub2e4\uc591\ud55c \ucd9c\ucc98\uc758 \ub370\uc774\ud130\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc5b4\ub2d0\ub9c1 \ub2e8\uacc4\uc758 \ub370\uc774\ud130\ub294 \ud45c 5\uc5d0 \uc790\uc138\ud788 \uc124\uba85\ub418\uc5b4 \uc788\uc73c\uba70, \uc7ac\ud604\uc131\uc744 \uc704\ud574 \ubaa8\ub4e0 \uae30\uc874 \ub370\uc774\ud130\uc14b\uc740 \ubd80\ub85d D\uc5d0, \uc0dd\uc131\ub41c \ud569\uc131 \ub370\uc774\ud130\ub294 \uacf5\uac1c\uc801\uc73c\ub85c \uc81c\uacf5\ub429\ub2c8\ub2e4.", "section": "2.3 Training Data Preparation"}, {"content": "| Domain | Type | Dataset | Volume |\n|---|---|---|---| \n| Mix | Pretrain | FineWeb-Edu, CBook, arXiv | 64.65B |\n| Math | (1) CoT | Deepmind-Math, MathInstruct | 3.07B |\n|  | (2) Long CoT | Numina, AMPS, Platypus | 0.61B |\n|  | (3) Formal math | Lean-GitHub, Lean-WorkBook, DeepSeek-Prover-V1 | 0.10B |\n|  | (4) Curated | Tulu v3, MathInstruct | 1.42B |\n| Code | (1) CoT | OSS-Instruct (seed: the-Stack-v2), OpenCoder-LLM | 6.66B |\n|  | (2) Curated | LeetCode, XCoder-80K | 2.39B |\n| Science | (1) Long CoT | Camel-ai | 0.04B |\n|  | (2) Curated | EvolKit-20k, Celestia, Supernova | 1.06B |\n| Total | - | - | 80B |", "caption": "Table 5: Detailed information of the training data in the annealing stage.", "description": "\ud45c 5\ub294 YuLan-Mini \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc5b4\ub2d0\ub9c1 \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud559\uc2b5 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc0c1\uc138 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub370\uc774\ud130 \uc720\ud615, \ub3c4\uba54\uc778, \ub370\uc774\ud130\uc14b, \uadf8\ub9ac\uace0 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud06c\uae30(\ubcfc\ub968)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5b4\ub2d0\ub9c1 \ub2e8\uacc4\ub294 \ubaa8\ub378 \ud559\uc2b5\uc758 \ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\ub85c, \uace0\ud488\uc9c8 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5\uc744 \ud5a5\uc0c1\uc2dc\ud0a4\ub294 \ub370 \uc911\uc810\uc744 \ub461\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc5b4\ub2d0\ub9c1 \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc758 \ubd84\ud3ec\ub97c \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "2 Overall Pre-Training Configuration"}, {"content": "| Models | Model | Size | # Train Tokens | Context Length | MATH | GSM | Human Eval | MBPP | RACE Middle | RACE High | RULER |\n|---|---|---|---|---|---|---|---|---|---|---|---| \n| MiniCPM | 2.6B | 1.06T | 4K | 15.00 | 53.83 | 50.00* | 47.31 | 56.61 | 44.27 | N/A |\n| Qwen-2 | 1.5B | 7T | 128K | 22.60 | 46.90* | 34.80* | 46.90* | 55.77 | 43.69 | 60.16 |\n| Qwen2.5 | 0.5B | 18T | 128K | 23.60 | 41.60* | 30.50* | 39.30* | 52.36 | 40.31 | 49.23 |\n| Qwen2.5 | 1.5B | 18T | 128K | 45.40 | 68.50* | 37.20* | 60.20* | 58.77 | 44.33 | 68.26 |\n| Gemma2 | 2.6B | 2T | 8K | 18.30* | 30.30* | 19.50* | 42.10* | - | - | N/A |\n| StableLM2 | 1.7B | 2T | 4K | - | 20.62 | 8.50 | 17.50 | 56.33 | 45.06 | N/A |\n| SmolLM2 | 1.7B | 11T | 8K | 11.80 | - | 23.35 | 45.00 | 55.77 | 43.06 | N/A |\n| Llama3.2 | 3.2B | 9T | 128K | 7.40 | - | 29.30 | 49.70 | 55.29 | 43.34 | 77.06 |\n| YuLan-Mini | 2.4B | 1.04T | 4K | 32.60 | 66.65 | 61.60 | 66.70 | 55.71 | 43.58 | N/A |\n| YuLan-Mini | 2.4B | 1.08T | 28K | 37.80 | 68.46 | 64.00 | 65.90 | 57.18 | 44.57 | 51.48 |", "caption": "Table 6: Performance on math, code, and long context benchmarks. Results marked with * are cited from their official paper or report. The best and second best results are bold and underlined, respectively.", "description": "\ud45c 6\uc740 \uc218\ud559, \ucf54\ub4dc \ubc0f \uc7a5\ubb38 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. * \ud45c\uc2dc\ub41c \uacb0\uacfc\ub294 \ud574\ub2f9 \ubaa8\ub378\uc758 \uacf5\uc2dd \ub17c\ubb38\uc774\ub098 \ubcf4\uace0\uc11c\uc5d0\uc11c \uc778\uc6a9\ud55c \uac83\uc785\ub2c8\ub2e4. \uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\uc640 \ub450 \ubc88\uc9f8\ub85c \uc88b\uc740 \uacb0\uacfc\ub294 \uac01\uac01 \uad75\uc740 \uae00\uc528\uccb4\uc640 \ubc11\uc904\ub85c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 YuLan-Mini \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\ub978 \uc5ec\ub7ec \uae30\uc900 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 \uc218\ud559\uc801 \ucd94\ub860, \ucf54\ub4dc \uc0dd\uc131 \ubc0f \uc7a5\ubb38 \uc774\ud574\uc640 \uad00\ub828\ub41c \ubca4\uce58\ub9c8\ud06c \uc791\uc5c5\uc5d0 \ub300\ud55c YuLan-Mini\uc758 \uc131\ub2a5\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| Model | Size |\n|---|---|", "caption": "Table 7: Performance on commonsense reasoning benchmarks. Results marked with * are cited from their official paper or report.", "description": "\ud45c 7\uc740 commonsense \ucd94\ub860 \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c commonsense \ucd94\ub860 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c YuLan-Mini \ubaa8\ub378\uacfc \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \ud45c\uc5d0 \uc81c\uc2dc\ub41c \uacb0\uacfc\ub294 \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \uc810\uc218\ub97c \ub098\ud0c0\ub0b4\uba70, \ud2b9\ud788 \uc5f0\uad6c \ub17c\ubb38\uc774\ub098 \ubcf4\uace0\uc11c\uc5d0\uc11c \ubc1c\ucdcc\ud55c \uacb0\uacfc\ub294 * \ud45c\uc2dc\ub85c \uad6c\ubd84\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "6.1 \uc2e4\ud5d8 \uc124\uc815"}, {"content": "| # Train |\n|---|---| \n| Tokens |", "caption": "Table 8: Definition of the variables for computing the hyperparameters.", "description": "\uc774 \ud45c\ub294 \ucd08\ub9e4\uac1c\ubcc0\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \ubcc0\uc218\ub4e4\uc758 \uc815\uc758\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubcc0\uc218\ub294 \ubaa8\ub378\uc758 \uacc4\uce35 \uc218, \uc5b4\ud150\uc158 \ud5e4\ub4dc \uc218, \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub124\ud2b8\uc6cc\ud06c\uc758 \ud788\ub4e0 \uc0ac\uc774\uc988, \uc784\ubca0\ub529 \ucc28\uc6d0, \ucd08\uae30\ud654 \ud45c\uc900\ud3b8\ucc28, \ud559\uc2b5\ub960 \ub4f1 \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98\uc640 \ud6c8\ub828 \uc124\uc815\uc5d0 \ub300\ud55c \uc911\uc694\ud55c \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \ubcc0\uc218\ub4e4\uc758 \uc815\ud655\ud55c \uc815\uc758\ub294 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ucd5c\uc801\ud654 \ubc0f \ubaa8\ub378 \uc131\ub2a5\uc5d0 \uc9c1\uc811\uc801\uc778 \uc601\ud5a5\uc744 \ubbf8\uce69\ub2c8\ub2e4.", "section": "2.1 \ubaa8\ub378 \uc544\ud0a4\ud14d\ucc98"}, {"content": "| Context | Length |\n|---|---|", "caption": "Table 9: Small proxy models used to explore the training dynamics.", "description": "\ud45c 9\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \ud6c8\ub828 \uc5ed\ub3d9\uc131\uc744 \ud0d0\uad6c\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub41c \uc18c\uaddc\ubaa8 \ud504\ub85d\uc2dc \ubaa8\ub378\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud504\ub85d\uc2dc \ubaa8\ub378\uc740 \uacc4\uc0b0 \ube44\uc6a9\uc744 \uc904\uc774\uae30 \uc704\ud574 \uc2e4\uc81c \ubaa8\ub378\ubcf4\ub2e4 \uc791\uc740 \ud06c\uae30\ub85c \ub9cc\ub4e4\uc5b4\uc84c\uc73c\uba70, \uc8fc\uc694 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(\ub808\uc774\uc5b4 \uc218, \ubaa8\ub378 \ucc28\uc6d0, \ud53c\ub4dc\ud3ec\uc6cc\ub4dc \ub124\ud2b8\uc6cc\ud06c \ud06c\uae30, \ud5e4\ub4dc \uc218)\ub97c \ube44\uad50\ud558\uc5ec \uc2e4\uc81c \ubaa8\ub378\uacfc\uc758 \ucc28\uc774\uc810\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc2e4\uc81c \ubaa8\ub378 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ubc1c\uc0dd\ud560 \uc218 \uc788\ub294 \ubd88\uc548\uc815\uc131\uc744 \uc18c\uaddc\ubaa8 \ubaa8\ub378\uc5d0\uc11c \uba3c\uc800 \uad00\ucc30\ud558\uace0 \ubd84\uc11d\ud568\uc73c\ub85c\uc368 \ud6a8\uc728\uc801\uc778 \ud6c8\ub828 \uc804\ub7b5\uc744 \uc218\ub9bd\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3.1.1 Indicator"}, {"content": "| MATH |\n|---|---| \n| 500 |", "caption": "Table 10: Comprehensive list of all open-source datasets used. For datasets that are only available via links, we also offer additional guidance on our project website\u00a0https://github.com/RUC-GSAI/YuLan-Mini.", "description": "\ud45c 10\uc740 YuLan-Mini \ubaa8\ub378 \uc0ac\uc804 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ubaa8\ub4e0 \uc624\ud508\uc18c\uc2a4 \ub370\uc774\ud130\uc14b\uc758 \ubaa9\ub85d\uc785\ub2c8\ub2e4. \ub9c1\ud06c\ub85c\ub9cc \uc81c\uacf5\ub418\ub294 \ub370\uc774\ud130\uc14b\uc758 \uacbd\uc6b0, \ud504\ub85c\uc81d\ud2b8 \uc6f9\uc0ac\uc774\ud2b8(https://github.com/RUC-GSAI/YuLan-Mini)\uc5d0\uc11c \ucd94\uac00\uc801\uc778 \uc548\ub0b4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub370\uc774\ud130\uc14b\uc758 \uc885\ub958, \ucd9c\ucc98, \ud06c\uae30 \ub4f1\uc758 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc73c\uba70, YuLan-Mini \ubaa8\ub378\uc758 \ub370\uc774\ud130 \uae30\ubc18\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "4 \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778"}, {"content": "| GSM | 8K |\n|---|---|", "caption": "Table 12: Detailed data composition by training curriculum phases.", "description": "\ud45c 12\ub294 YuLan-Mini \ubaa8\ub378\uc758 \uc0ac\uc804 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uc138\ubd80 \uad6c\uc131\uc744 \ud6c8\ub828 \ucee4\ub9ac\ud058\ub7fc \ub2e8\uacc4\ubcc4\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub2e8\uacc4(warmup, stable training, annealing)\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \ube44\uc728\uc744  \uc6f9 \ud398\uc774\uc9c0 \ub370\uc774\ud130, \ucf54\ub4dc \ub370\uc774\ud130, \uc218\ud559 \ub370\uc774\ud130, \uadf8\ub9ac\uace0 \uc911\uad6d\uc5b4 \ub370\uc774\ud130\ub85c \uad6c\ubd84\ud558\uc5ec \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \ub2e8\uacc4\ub294 \uc5ec\ub7ec \uac1c\uc758 \uc138\ubd80 \ub2e8\uacc4\ub85c \ub098\ub258\uba70, \uac01 \uc138\ubd80 \ub2e8\uacc4\ub9c8\ub2e4 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc14b\uc758 \ube44\uc728\uc774 \uc790\uc138\ud558\uac8c \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 YuLan-Mini \ubaa8\ub378\uc758 \ub370\uc774\ud130 \ud6a8\uc728\uc801\uc778 \uc0ac\uc804 \ud6c8\ub828 \uacfc\uc815\uc744 \uc7ac\ud604\ud558\ub294 \ub370 \ud544\uc694\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "4 \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778"}]