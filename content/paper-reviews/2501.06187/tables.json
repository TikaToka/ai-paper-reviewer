[{"content": "| Method | Test-time Optimization | Reference Images: Subject | Reference Images: Background | Text-S\u2191 | Vid-S\u2191 | Subj-S\u2191 | Dync-D\u2191 |\n|---|---|---|---|---|---|---|---| \n| ELITE<sup>\u2020</sup> [74] | \u2717 | single | \u2717 | 0.245 | 0.620 | 0.359 | - |\n| VideoBooth [28] | \u2717 | single | \u2717 | 0.222 | 0.612 | 0.395 | 0.448 |\n| DreamVideo [75] | \u2713 | single | \u2717 | 0.261 | 0.611 | 0.310 | 0.311 |\n| *Video Alchemist* | \u2717 | single | \u2717 | 0.269 | 0.732 | 0.617 | 0.466 |\n| DreamVideo [75] | \u2713 | multiple | \u2717 | 0.253 | 0.604 | 0.256 | 0.303 |\n| *Video Alchemist* | \u2717 | multiple | \u2717 | 0.268 | 0.743 | 0.626 | 0.473 |\n| *Video Alchemist* | \u2717 | multiple | \u2713 | 0.254 | 0.780 | 0.570 | 0.506 |", "caption": "Table 1: Quantitative comparison on MSRVTT-Personalization.\u00a0\nWe compare Video Alchemist with state-of-the-art personalization methods across multiple metrics, including text similarity (Text-S), video similarity (Vid-S), subject similarity (Subj-S), face similarity (Face-S), and dynamic degree (Dync-D). The top and bottom tables show the evaluations for subject and face modes, respectively. \u2020For text-to-image models, outputs are treated as single-frame videos without evaluating temporal quality. We evaluate Video Alchemist with the videos at 512\u2062p\u2062x\u00d7288\u2062p\u2062x512px288px512\\mathrm{px}\\times 288\\mathrm{px}512 roman_p roman_x \u00d7 288 roman_p roman_x resolution. We highlight the top two models for the single reference image setting.", "description": "\ud45c 1\uc740 MSRVTT-Personalization \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uc815\ub7c9\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ube44\ub514\uc624 \uc54c\ucf00\ubbf8\uc2a4\ud2b8(Video Alchemist) \ubaa8\ub378\uc744 \ucd5c\ucca8\ub2e8 \uac1c\uc778\ud654 \ubaa8\ub378\ub4e4\uacfc \ud14d\uc2a4\ud2b8 \uc720\uc0ac\ub3c4(Text-S), \ube44\ub514\uc624 \uc720\uc0ac\ub3c4(Vid-S), \uac1d\uccb4 \uc720\uc0ac\ub3c4(Subj-S), \uc5bc\uad74 \uc720\uc0ac\ub3c4(Face-S), \ub3d9\uc801 \uc815\ub3c4(Dync-D) \ub4f1 \uc5ec\ub7ec \uc9c0\ud45c\ub97c \ud1b5\ud574 \ube44\uad50 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4. \uc0c1\ub2e8 \ud45c\ub294 \uac1d\uccb4 \ubaa8\ub4dc, \ud558\ub2e8 \ud45c\ub294 \uc5bc\uad74 \ubaa8\ub4dc \ud3c9\uac00 \uacb0\uacfc\ub97c \uac01\uac01 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \ubaa8\ub378\uc758 \uacbd\uc6b0 \uc2dc\uac04\uc801 \ud488\uc9c8 \ud3c9\uac00 \uc5c6\uc774 \ub2e8\uc77c \ud504\ub808\uc784 \ube44\ub514\uc624\ub85c \ucc98\ub9ac\ub418\uc5c8\uc73c\uba70, \ube44\ub514\uc624 \uc54c\ucf00\ubbf8\uc2a4\ud2b8 \ubaa8\ub378\uc740 512x288 \ud574\uc0c1\ub3c4 \ube44\ub514\uc624\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4. \ub2e8\uc77c \ucc38\uc870 \uc774\ubbf8\uc9c0 \uc124\uc815\uc5d0\uc11c \uc0c1\uc704 2\uac1c \ubaa8\ub378\uc744 \uac15\uc870 \ud45c\uc2dc\ud588\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"content": "| Method | Test-time Optimization | Reference Images | Text-S\u2191 | Vid-S\u2191 | Face-S\u2191 | Dync-D\u2191 |\n|---|---|---|---|---|---|---|\n| IP-Adapter<sup>\u2020</sup> [82] | \u2717 | single | 0.251 | 0.648 | 0.269 | - |\n| PhotoMaker<sup>\u2020</sup> [34] | \u2717 | single | 0.278 | 0.569 | 0.189 | - |\n| Magic-Me [42] | \u2713 | single | 0.251 | 0.602 | 0.135 | 0.418 |\n| *Video Alchemist* | \u2717 | single | 0.273 | 0.687 | 0.382 | 0.424 |\n| PhotoMaker<sup>\u2020</sup> [34] | \u2717 | multiple | 0.275 | 0.582 | 0.216 | - |\n| Magic-Me [42] | \u2713 | multiple | 0.248 | 0.618 | 0.153 | 0.385 |\n| *Video Alchemist* | \u2717 | multiple | 0.272 | 0.694 | 0.411 | 0.402 |", "caption": "Table 2: User preference study.\u00a0\nWe show the user preference percentage for subject (left) and face modes (right), respectively.", "description": "\ud45c 2\ub294 \uc0ac\uc6a9\uc790 \uc120\ud638\ub3c4 \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd\uc5d0\ub294 \uac1d\uccb4 \ubaa8\ub4dc\uc5d0 \ub300\ud55c \uc0ac\uc6a9\uc790 \uc120\ud638\ub3c4 \ube44\uc728\uc744, \uc624\ub978\ucabd\uc5d0\ub294 \uc5bc\uad74 \ubaa8\ub4dc\uc5d0 \ub300\ud55c \uc0ac\uc6a9\uc790 \uc120\ud638\ub3c4 \ube44\uc728\uc744 \uac01\uac01 \ubc31\ubd84\uc728\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc0ac\uc6a9\uc790\ub4e4\uc774 \uc81c\uc2dc\ub41c \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uac1c\uc778\ud654 \ubc29\ubc95\ub4e4 \uc911 \uc5b4\ub5a4 \ubc29\ubc95\uc744 \ub354 \uc120\ud638\ud558\ub294\uc9c0 \uc815\ub7c9\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc120\ud638\ub3c4 \ube44\uc728\uc744 \ud1b5\ud574, \uc8fc\uc5b4\uc9c4 \uc870\uac74\uc5d0\uc11c \uc5b4\ub5a4 \ubaa8\ub378\uc774 \uc2dc\uac01\uc801 \ud488\uc9c8\uacfc \uc8fc\uc81c \ucda9\uc2e4\ub3c4 \uce21\uba74\uc5d0\uc11c \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uc9c0 \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2. \ucd5c\ucca8\ub2e8 \uae30\uc220\uacfc\uc758 \ube44\uad50"}, {"content": "| Method | Preference Ratio \u2191 | Quality | Fidelity |\n|---|---|---|---|\n| ELITE [74] | 2.7% | 0.6% |\n| VideoBooth [28] | 0.3% | 0.8% |\n| DreamVideo [75] | 0.5% | 0.5% |\n| Video Alchemist | 96.5% | 98.1% |", "caption": "Table 3: Ablation study for the subject mode.\u00a0\nWe use a single reference image for each model and examine three control factors. The experiments are conducted on the videos at 256\u2062p\u2062x\u00d7144\u2062p\u2062x256px144px256\\mathrm{px}\\times 144\\mathrm{px}256 roman_p roman_x \u00d7 144 roman_p roman_x resolution.", "description": "\ud45c 3\uc740 \uc8fc\uc81c \ubaa8\ub4dc\uc5d0 \ub300\ud55c ablation \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \ub2e8\uc77c \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uace0 \uc138 \uac00\uc9c0 \uc81c\uc5b4 \uc694\uc18c(\uc774\ubbf8\uc9c0 \uc778\ucf54\ub354, \ub2e8\uc5b4 \ud1a0\ud070 \uc0ac\uc6a9 \uc5ec\ubd80, \uc774\ubbf8\uc9c0 \uc99d\uac15 \uc0ac\uc6a9 \uc5ec\ubd80)\ub97c \uc870\uc0ac\ud588\uc2b5\ub2c8\ub2e4. \uc2e4\ud5d8\uc740 256px \u00d7 144px \ud574\uc0c1\ub3c4\uc758 \ube44\ub514\uc624\uc5d0\uc11c \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uc81c\uc548\ub41c \ubc29\ubc95\uc758 \ub2e4\uc591\ud55c \uad6c\uc131 \uc694\uc18c\uc758 \ud6a8\uacfc\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "4.3. Ablation Study"}, {"content": "| Method | Preference Ratio \u2191 | Quality | Fidelity |\n|---|---|---|---|\n| IP-Adapter [82] | 10.4% | 20.2% | \n| PhotoMaker [34] | 37.5% | 7.4% | \n| Magic-Me [42] | 4.4% | 4.0% | \n| Video Alchemist | 47.6% | 68.4% | ", "caption": "Table 4: Training augmentations.\u00a0\nWe denote the height and width of the reference image as h\u210ehitalic_h and w\ud835\udc64witalic_w.", "description": "\ud45c 4\ub294 \ube44\ub514\uc624 \uac1c\uc778\ud654 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130 \uc99d\uac15 \uae30\ubc95\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \uc99d\uac15 \uae30\ubc95\uc758 \uc801\uc6a9 \ud655\ub960\uacfc, \uc99d\uac15 \uae30\ubc95\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130,  \uc99d\uac15 \uae30\ubc95\uc758 \uc720\ud615, \uadf8\ub9ac\uace0 \uac01 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc758 \uc0d8\ud50c\ub9c1 \ubc94\uc704\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  'Downscale', 'Gaussian blur', 'Color jitter', 'Brightness', 'Horizontal flip', 'Shearing (x-axis)', 'Shearing (y-axis)', 'Rotation', 'Random crop' \uacfc \uac19\uc740 \uc5ec\ub7ec \uac00\uc9c0 \uc99d\uac15 \uae30\ubc95\ub4e4\uc774 \uc0ac\uc6a9\ub418\uc5c8\uc73c\uba70,  \uac01 \uae30\ubc95\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \ub192\uc774(h)\uc640 \ub108\ube44(w)\ub97c \uae30\uc900\uc73c\ub85c \uc0d8\ud50c\ub9c1 \ubc94\uc704\uac00 \uc815\ud574\uc9d1\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, 'Downscale'\uc758 \uacbd\uc6b0,  \uc0d8\ud50c\ub9c1 \ubc94\uc704\ub294 [112/max(h, w), 1.0]\ub85c,  \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \ucd5c\ub300 \ud06c\uae30(h, w \uc911 \ud070 \uac12)\uc5d0 \ub530\ub77c \uc2a4\ucf00\uc77c\ub9c1 \ube44\uc728\uc774 \uc870\uc815\ub429\ub2c8\ub2e4.", "section": "3.3. Reducing Model Overfitting"}, {"content": "| Method | Image Encoder | Use Word Token | Image Augmentations | Text-S\u2191 | Vid-S\u2191 | Subj-S\u2191 | Dync-D\u2191 |\n|---|---|---|---|---|---|---|---| \n| Use CLIP | CLIP [52] | \u2713 | \u2713 | 0.269 | 0.768 | 0.569 | 0.552 |\n| No word token | DINOv2 [47] | \u2717 | \u2713 | 0.256 | 0.790 | 0.566 | 0.569 |\n| No augmentation | DINOv2 [47] | \u2713 | \u2717 | 0.251 | 0.781 | 0.609 | 0.506 |\n| *Video Alchemist* | DINOv2 [47] | \u2713 | \u2713 | 0.257 | 0.790 | 0.600 | 0.570 |", "caption": "Table 5: Architecture details of video generation backbone and image encoders.", "description": "\ud45c 5\ub294 \ube44\ub514\uc624 \uc0dd\uc131 \ubc31\ubcf8\uacfc \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\uc758 \uad6c\uc870\uc801 \uc138\ubd80 \uc815\ubcf4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\ub514\uc624 \ubc31\ubcf8\uc740 DiT(Diffusion Transformer) \uc544\ud0a4\ud14d\ucc98\ub97c \uae30\ubc18\uc73c\ub85c \ud558\uba70, \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\ub294 CLIP(Contrastive Language\u2013Image Pre-training)\uacfc DINOv2(self-supervised vision transformer) \ub450 \uac00\uc9c0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uc785\ub825 \ucc44\ub110 \uc218, \ud328\uce58 \ud06c\uae30, \ud1a0\ud070 \uc218, \uc5b4\ud150\uc158 \ud5e4\ub4dc \uc218, \uc0ac\uc6a9\ub41c \ucd94\uac00 \ubaa8\ub4c8(\uc608: \ud50c\ub798\uc2dc \uc5b4\ud150\uc158, \ud4e8\uc988\ub4dc \ub808\uc774\uc5b4 \uc815\uaddc\ud654) \ub4f1\uc758 \uc815\ubcf4\uac00 \uc790\uc138\ud788 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \uc774\ud574\ud558\ub294 \ub370 \ud544\uc218\uc801\uc778 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "3. \ubc29\ubc95\ub860"}, {"content": "| Apply | Probability | Hyperparameters |\n|---|---|---|\n|  |  | Type | Sampling Range |\n| Downscale | 1.0 | scale | [112/max(h,w),1.0] |\n| Gaussian blur | 1.0 | kernel size (px) | [1,max(h,w)/50] |\n| Color jitter | 1.0 | scale | [-0.05,0.05] |\n| Brightness | 1.0 | scale | [0.9,1.1] |\n| Horizontal flip | 0.5 | - | - |\n| Shearing (x-axis) | 1.0 | value (px) | [-0.05,0.05]x w |\n| Shearing (y-axis) | 1.0 | value (px) | [-0.05,0.05]x h |\n| Rotation | 1.0 | value (\u00b0)| [-20,20] |\n| Random crop | 1.0 | scale | [0.67,1.0] |", "caption": "Table 6: Training hyperparameters.\u00a0\nThe right table is for stage II training.", "description": "\ud45c 6\uc740 \ub17c\ubb38\uc758 3. Methodology \uc139\uc158\uc5d0 \uc788\ub294 \ubaa8\ub378 \ud559\uc2b5 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc67c\ucabd \ud45c\ub294 1\ub2e8\uacc4 \ud559\uc2b5, \uc624\ub978\ucabd \ud45c\ub294 2\ub2e8\uacc4 \ud559\uc2b5\uc5d0 \ub300\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \uac01\uac01 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uac01 \ub2e8\uacc4\ubcc4\ub85c \ud559\uc2b5 \uc2a4\ud15d \uc218, \uc0d8\ud50c \uc218, \ubc30\uce58 \ud06c\uae30, \ud559\uc2b5\ub960, \ucd5c\uc801\ud654 \uc54c\uace0\ub9ac\uc998, \uac00\uc911\uce58 \uac10\uc18c, \uadf8\ub798\ub514\uc5b8\ud2b8 \ud074\ub9ac\ud551 \ub4f1\uc758 \uc815\ubcf4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, 2\ub2e8\uacc4 \ud559\uc2b5\uc5d0\uc11c\ub294 \uc774\ubbf8\uc9c0 \uc870\uac74\ud654 \uc5ec\ubd80 \ubc0f \ucd94\uac00\uc801\uc778 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\uc774 \ub2e4\ub974\uac8c \uc801\uc6a9\ub428\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Methodology"}]