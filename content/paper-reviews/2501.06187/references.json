{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduced the foundation of denoising diffusion probabilistic models, a crucial concept underlying the video generation model in the main paper."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper significantly improved the resolution of images generated by diffusion models, a key advancement that the main paper leverages for its video generation approach."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-12-01", "reason": "This paper demonstrated the state-of-the-art in text-to-image generation using diffusion models, which directly inspired the text conditioning component of the video generation model."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable diffusion models with transformers", "publication_date": "2023-10-01", "reason": "This paper introduced the Diffusion Transformer architecture, which forms the backbone of the video generation model in the main paper, enabling efficient multi-subject and open-set personalization."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "DreamBooth: Fine-tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-06-01", "reason": "This paper presented a method for personalizing text-to-image diffusion models, which is directly relevant to the multi-subject personalization capability of the video generation model."}]}