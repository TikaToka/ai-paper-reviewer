[{"figure_path": "https://arxiv.org/html/2501.06187/x2.png", "caption": "Figure 1: \nGiven a text prompt as well as reference images for each subject (i.e., man, dog) and background images (i.e., bridge, desert, sea ice, Moon\u2019s surface), Video Alchemist synthesizes natural motions while preserving subject identity and background fidelity.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ube44\ub514\uc624 \uc54c\ucf00\ubbf8\uc2a4\ud2b8(Video Alchemist) \ubaa8\ub378\uc758 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8(\"A man pets a dog on...\")\uc640 \uac01 \uac1d\uccb4(\uc0ac\ub78c, \uac15\uc544\uc9c0) \ubc0f \ubc30\uacbd(\ub2e4\ub9ac, \uc0ac\ub9c9, \ubc14\ub2e4 \uc5bc\uc74c, \ub2ec \ud45c\uba74)\uc5d0 \ub300\ud55c \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 \uc8fc\uc5b4\uc9c0\uba74, \ubaa8\ub378\uc740 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \ub3d9\uc791\uc744 \ud569\uc131\ud558\uba74\uc11c \ub3d9\uc2dc\uc5d0 \uac1d\uccb4\uc758 \uc815\uccb4\uc131\uacfc \ubc30\uacbd\uc758 \ucda9\uc2e4\ub3c4\ub97c \uc720\uc9c0\ud569\ub2c8\ub2e4.  \uc989, \uc785\ub825\ub41c \ud14d\uc2a4\ud2b8\uc640 \uc774\ubbf8\uc9c0\ub4e4\uc744 \ubc14\ud0d5\uc73c\ub85c \uc0ac\ub78c\uacfc \uac15\uc544\uc9c0\uac00 \uc790\uc5f0\uc2a4\ub7fd\uac8c \uc0c1\ud638\uc791\uc6a9\ud558\ub294 \uc601\uc0c1\uc744 \uc0dd\uc131\ud558\uace0, \ubc30\uacbd \ub610\ud55c \ud504\ub86c\ud504\ud2b8\uc5d0 \ub9de\ucdb0 \uc77c\uad00\uc131 \uc788\uac8c \ud45c\ud604\ud558\ub294 \ubaa8\ub378\uc758 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.06187/x3.png", "caption": "Figure 2: Dataset collection pipeline for video personalization.\u00a0\nWe construct our training dataset using video and caption pairs through three steps. First, we identify three categories of entity words from the caption: subject, object, and background. Next, we use these entity words to localize and segment the target subjects and objects in three selected video frames. Finally, we extract a clean background image by removing the subjects and objects from the middle frame.", "description": "\uadf8\ub9bc 2\ub294 \ube44\ub514\uc624 \uac1c\uc778\ud654\ub97c \uc704\ud55c \ub370\uc774\ud130\uc14b \uc218\uc9d1 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc138 \ub2e8\uacc4\ub97c \uac70\uccd0 \ube44\ub514\uc624\uc640 \ucea1\uc158 \uc30d\uc744 \uc774\uc6a9\ud558\uc5ec \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc744 \uad6c\uc131\ud569\ub2c8\ub2e4. \uccab\uc9f8, \ucea1\uc158\uc5d0\uc11c \uc138 \uac00\uc9c0 \uc885\ub958\uc758 \uc5d4\ud2f0\ud2f0 \ub2e8\uc5b4(\uc8fc\uc81c, \uac1c\uccb4, \ubc30\uacbd)\ub97c \uc2dd\ubcc4\ud569\ub2c8\ub2e4. \ub2e4\uc74c\uc73c\ub85c, \uc774\ub7ec\ud55c \uc5d4\ud2f0\ud2f0 \ub2e8\uc5b4\ub4e4\uc744 \uc774\uc6a9\ud558\uc5ec \uc120\ud0dd\ub41c \uc138 \uac1c\uc758 \ube44\ub514\uc624 \ud504\ub808\uc784\uc5d0\uc11c \uc8fc\uc81c\uc640 \uac1c\uccb4\ub97c \ucc3e\uc544 \ubd84\ud560\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc911\uac04 \ud504\ub808\uc784\uc5d0\uc11c \uc8fc\uc81c\uc640 \uac1c\uccb4\ub97c \uc81c\uac70\ud558\uc5ec \uae68\ub057\ud55c \ubc30\uacbd \uc774\ubbf8\uc9c0\ub97c \ucd94\ucd9c\ud569\ub2c8\ub2e4.", "section": "3.1. \ub370\uc774\ud130\uc14b \uc218\uc9d1"}, {"figure_path": "https://arxiv.org/html/2501.06187/x4.png", "caption": "Figure 3: Model architecture.\u00a0\nOur model is a latent DiT\u00a0[50], where we first encode a video into video tokens and denoise them with a deep cascade of DiT blocks in the latent space. Each DiT block includes an additional cross-attention operation with personalization embeddings f=Concat\u2062(f1,\u2026,fn,\u2026,fN)\ud835\udc53Concatsubscript\ud835\udc531\u2026subscript\ud835\udc53\ud835\udc5b\u2026subscript\ud835\udc53\ud835\udc41f=\\textrm{Concat}(f_{1},\\dots,f_{n},\\dots,f_{N})italic_f = Concat ( italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u2026 , italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , \u2026 , italic_f start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ), where fnsubscript\ud835\udc53\ud835\udc5bf_{n}italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT fuses the embeddings of both the reference image xnsubscript\ud835\udc65\ud835\udc5bx_{n}italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and the corresponding entity word cnsubscript\ud835\udc50\ud835\udc5bc_{n}italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Each square in the figure represents a 1-D token.", "description": "\uadf8\ub9bc 3\uc740 Video Alchemist \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc740 latent Diffusion Transformer (DiT) [50] \uae30\ubc18\uc73c\ub85c, \ube44\ub514\uc624\ub97c video tokens\uc73c\ub85c \uc778\ucf54\ub529\ud55c \ud6c4, latent space\uc5d0\uc11c DiT blocks\uc758 \uc5f0\uc18d\uc801\uc778 denoising\uc744 \ud1b5\ud574 \ubcf5\uc6d0\ud569\ub2c8\ub2e4. \uac01 DiT block\uc740 \uac1c\ubcc4 reference image\uc640 \ud574\ub2f9\ud558\ub294 entity word\uc758 embedding\uc744 \uacb0\ud569\ud55c personalization embedding (f=Concat(f1,\u2026,fn,\u2026,fN))\uacfc\uc758 \ucd94\uac00\uc801\uc778 cross-attention \uc5f0\uc0b0\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc11c, fn\uc740 reference image xn\uacfc entity word cn\uc758 embedding\uc744 \uc735\ud569\ud55c \uac83\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \uac01 \uc0ac\uac01\ud615\uc740 1-D \ud1a0\ud070\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "3. Methodology"}, {"figure_path": "https://arxiv.org/html/2501.06187/x5.png", "caption": "Figure 4: Test sample in MSRVTT-Personalization.\u00a0\nWe present a comprehensive video personalization benchmark. Our benchmark supports various modes, including face conditioning, single or multiple subjects conditioning, and foreground and background conditioning.", "description": "\uadf8\ub9bc 4\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 MSRVTT-Personalization \ubca4\uce58\ub9c8\ud06c\uc758 \ud14c\uc2a4\ud2b8 \uc0d8\ud50c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ubca4\uce58\ub9c8\ud06c\ub294 \uc5bc\uad74 \uc870\uac74\ud654, \ub2e8\uc77c \ub610\ub294 \ub2e4\uc911 \uc8fc\uc81c \uc870\uac74\ud654, \uc804\uacbd \ubc0f \ubc30\uacbd \uc870\uac74\ud654\ub97c \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \ubaa8\ub4dc\ub97c \uc9c0\uc6d0\ud558\ub294 \uc885\ud569\uc801\uc778 \ube44\ub514\uc624 \uac1c\uc778\ud654 \ud3c9\uac00 \uae30\uc900\uc785\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc870\uac74\ud654 \ubaa8\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \ube44\ub514\uc624\ub97c \uac1c\uc778\ud654\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uc989, \uc5bc\uad74\ub9cc\uc744 \uc0ac\uc6a9\ud558\uac70\ub098, \uc5ec\ub7ec \uba85\uc758 \uc0ac\ub78c \ub610\ub294 \uc0ac\ubb3c\uc744 \uc870\uac74\ud654\ud558\uac70\ub098, \uc804\uacbd\uacfc \ubc30\uacbd\uc744 \ubaa8\ub450 \uc870\uac74\ud654\ud558\ub294 \ub4f1 \ub2e4\uc591\ud55c \ubc29\uc2dd\uc73c\ub85c \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uac1c\uc778\ud654 \uae30\ubc95\uc758 \uc131\ub2a5\uc744 \ubcf4\ub2e4 \uc815\ud655\ud558\uace0 \ud3ec\uad04\uc801\uc73c\ub85c \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.1 MSRVTT-Personalization \ubca4\uce58\ub9c8\ud06c"}, {"figure_path": "https://arxiv.org/html/2501.06187/x6.png", "caption": "Figure 5: Qualitative comparison on MSRVTT-Personalization.\u00a0\nWe use a single reference image to each model for a fair comparison. Compared to existing methods, our results closely match the input text prompt and reference subjects while exhibiting natural motion and pose variations.", "description": "\uadf8\ub9bc 5\ub294 MSRVTT-Personalization \uae30\uc900\uc73c\ub85c \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uac1c\uc778\ud654 \ubaa8\ub378\uc758 \uc9c8\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uacf5\uc815\ud55c \ube44\uad50\ub97c \uc704\ud574 \uac01 \ubaa8\ub378\uc5d0 \ub2e8\uc77c \ucc38\uc870 \uc774\ubbf8\uc9c0\ub9cc\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uae30\uc874 \ubc29\ubc95\uacfc \ube44\uad50\ud558\uc5ec, \ubcf8 \ub17c\ubb38\uc758 \uacb0\uacfc\ub294 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 \ucc38\uc870 \ud53c\uc0ac\uccb4\ub97c \ucda9\uc2e4\ud788 \ubc18\uc601\ud558\uba74\uc11c \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \ub3d9\uc791\uacfc \uc790\uc138 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378\uc774 \ud14d\uc2a4\ud2b8\uc640 \uc774\ubbf8\uc9c0 \uc815\ubcf4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uacb0\ud569\ud558\uc5ec \uc2e4\uc81c\uc640 \uc720\uc0ac\ud55c \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.06187/x7.png", "caption": "Figure 6: Qualitative results of the ablation study.\u00a0\nFrom top to bottom, we show that 1) Video Alchemist achieves better subject fidelity using DINOv2\u00a0[47] as the image encoder; 2) it correctly binds the conditional image and entity word with the usage of word tokens; 3) it mitigates the copy-and-paste effect and synthesizes text-aligned videos via the proposed data augmentation. The reference image is synthesized by DALL\u00b7E 3\u00a0[3].", "description": "\uadf8\ub9bc 6\uc740 ablation study\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc0c1\ub2e8\ubd80\ud130 \uc21c\uc11c\ub300\ub85c, 1) Video Alchemist\ub294 DINOv2 [47]\ub97c \uc774\ubbf8\uc9c0 \uc778\ucf54\ub354\ub85c \uc0ac\uc6a9\ud588\uc744 \ub54c \ub354 \ub098\uc740 \uc8fc\uc81c \ucda9\uc2e4\ub3c4\ub97c \ub2ec\uc131\ud569\ub2c8\ub2e4. 2) \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc640 \ub2e8\uc5b4 \ud1a0\ud070\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc870\uac74\ubd80 \uc774\ubbf8\uc9c0\uc640 \uac1c\uccb4 \ub2e8\uc5b4\ub97c \uc62c\ubc14\ub974\uac8c \uc5f0\uacb0\ud569\ub2c8\ub2e4. 3) \uc81c\uc548\ub41c \ub370\uc774\ud130 \uc99d\uac15\uc744 \ud1b5\ud574 \ubcf5\uc0ac-\ubd99\uc5ec\ub123\uae30 \ud6a8\uacfc\ub97c \uc644\ud654\ud558\uace0 \ud14d\uc2a4\ud2b8\uc640 \uc77c\uce58\ud558\ub294 \ube44\ub514\uc624\ub97c \ud569\uc131\ud569\ub2c8\ub2e4. \ucc38\uace0 \uc774\ubbf8\uc9c0\ub294 DALL-E 3 [3]\uc5d0 \uc758\ud574 \ud569\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "3.3. Reducing Model Overfitting"}, {"figure_path": "https://arxiv.org/html/2501.06187/extracted/6124560/figures/sources/word_cloud.png", "caption": "Figure 7: Prompt template for retrieving the entity words.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 \ub370\uc774\ud130\uc14b \uc0dd\uc131 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud504\ub86c\ud504\ud2b8 \ud15c\ud50c\ub9bf\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LLM(\ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378)\uc744 \uc774\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \ucea1\uc158\uc5d0\uc11c \ubc30\uacbd, \uc8fc\uc81c, \uc2dc\uac01\uc801\uc73c\ub85c \ubd84\ub9ac \uac00\ub2a5\ud55c \uac1c\uccb4 \ub4f1 \uc138 \uac00\uc9c0 \uc720\ud615\uc758 \uc5d4\ud2f0\ud2f0 \ub2e8\uc5b4\ub97c \ucd94\ucd9c\ud558\ub294 \ubc29\ubc95\uc744 \uc124\uba85\ud558\uae30 \uc704\ud55c \ud15c\ud50c\ub9bf\uc785\ub2c8\ub2e4.  \uac01 \uc5d4\ud2f0\ud2f0 \uc720\ud615\uc5d0 \ub300\ud55c \uc815\uc758\uc640 \ud568\uaed8,  LLM\uc774 \uc62c\ubc14\ub978 \uacb0\uacfc\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ud615\uc2dd\uacfc \uaddc\uce59(\uba85\uc0ac\ub9cc \uc0ac\uc6a9, \ucea1\uc158\uc758 \ubd80\ubd84\uc9d1\ud569\uc774\uc5b4\uc57c \ud568 \ub4f1)\uc744 \uc81c\uc2dc\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \uc5ec\ub7ec \uc608\uc2dc\ub97c \ud1b5\ud574 LLM\uc774 \uc5b4\ub5bb\uac8c \uc5d4\ud2f0\ud2f0 \ub2e8\uc5b4\ub97c \ucd94\ucd9c\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.1. Dataset Collection"}, {"figure_path": "https://arxiv.org/html/2501.06187/x8.png", "caption": "Figure 8: Word cloud of the entity words.\u00a0\nWe randomly sample 10k videos from our training dataset and plot the word cloud of the retrieved subject and object entity words.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ubb34\uc791\uc704\ub85c 1\ub9cc \uac1c\uc758 \ube44\ub514\uc624\ub97c \ucd94\ucd9c\ud558\uc5ec, \uac01 \ube44\ub514\uc624\uc758 \ucea1\uc158\uc5d0\uc11c \ucd94\ucd9c\ub41c \uc8fc\uc694 \uac1d\uccb4(subject)\uc640 \uc0ac\ubb3c(object)\uc5d0 \ub300\ud55c \ub2e8\uc5b4\ub4e4\uc744 \uc6cc\ub4dc \ud074\ub77c\uc6b0\ub4dc\ub85c \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4. \ub2e8\uc5b4 \ud06c\uae30\ub294 \ud574\ub2f9 \ub2e8\uc5b4\uac00 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc790\uc8fc \ub4f1\uc7a5\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc790\uc8fc \ub4f1\uc7a5\ud558\ub294 \ub2e8\uc5b4\uc77c\uc218\ub85d \ud06c\uac8c \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud6c8\ub828 \ub370\uc774\ud130\uc14b\uc758 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\uc640  \ub2e4\uc591\uc131\uc744 \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "A. Details of Training Datasets and Augmentations"}, {"figure_path": "https://arxiv.org/html/2501.06187/x9.png", "caption": "Figure 9: Additional results of multi-subject open-set personalization.", "description": "\uadf8\ub9bc 9\ub294 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \ub2e4\uc911 \uc8fc\uccb4 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654\uc758 \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uc870\ud569\uc758 \uc8fc\uccb4\uc640 \ubc30\uacbd\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uac1c\uc758 \uc608\uc2dc\ub97c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uac01 \uc608\uc2dc\ub294 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 \ucc38\uc870 \uc774\ubbf8\uc9c0, \uadf8\ub9ac\uace0 \uc0dd\uc131\ub41c \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574, \uc81c\uc548\ub41c \ubaa8\ub378\uc774 \ub2e4\uc911 \uc8fc\uccb4\uc640 \ubc30\uacbd\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uace0 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \ub0b4\uc6a9\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06187/x10.png", "caption": "Figure 10: Additional results of multi-subject open-set personalization.", "description": "\uadf8\ub9bc 10\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c \ub2e4\uc911 \uc8fc\uccb4 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc5ec\ub7ec \uba85\uc758 \uc0ac\ub78c\uc774 \ub4f1\uc7a5\ud558\ub294 \ub2e4\uc591\ud55c \ubc30\uacbd\uacfc \uc0c1\ud669\uc5d0\uc11c,  \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub4e4\uc744 \uc870\ud569\ud558\uc5ec  \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud55c \uacb0\uacfc\ub4e4\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ud2b9\uc815 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud55c \uacb0\uacfc\ubb3c\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\uba70,  \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \uc218\uac00 \uc99d\uac00\ud560\uc218\ub85d (P1, P2, P3)  \uc0dd\uc131\ub41c \ube44\ub514\uc624\uc758 \uc815\ud655\ub3c4\uc640 \ub514\ud14c\uc77c\uc774 \ub192\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \uc5f4 ([P3] with no reference image) \uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0 \uc5c6\uc774 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub9cc\uc73c\ub85c \uc0dd\uc131\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc5b4 \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 \uc0dd\uc131 \uacb0\uacfc\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ube44\uad50\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2501.06187/x11.png", "caption": "Figure 11: Additional results of multi-subject open-set personalization.", "description": "\uadf8\ub9bc 11\uc740 \uc81c\uc2dc\ub41c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 \uc5ec\ub7ec \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ub2e4\uc911 \uc8fc\uccb4 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654\uc758 \ucd94\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub2e4\ub978 \uc218\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ub41c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uba70, \ud504\ub86c\ud504\ud2b8\uc5d0 \ub530\ub77c \ubc30\uacbd\uacfc \uc8fc\uccb4\uac00 \uc5b4\ub5bb\uac8c \ubcc0\uacbd\ub418\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \ub2e4\uc911 \uc8fc\uccb4\uc640 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654 \uae30\ub2a5\uc744 \ub354 \uc798 \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06187/x12.png", "caption": "Figure 12: Additional results of multi-subject open-set personalization.", "description": "\uadf8\ub9bc 12\ub294 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 \ub2e4\uc911 \uc8fc\uccb4 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \ucd94\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud589\uc740 \ub3d9\uc77c\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc9c0\ub9cc, \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \uc218\uac00 \ub2ec\ub77c\uc9c0\ub294 \ub2e4\uc591\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uccab \ubc88\uc9f8 \uc5f4([P1])\uc740 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub530\ub978 \uae30\ubcf8 \uacb0\uacfc\ub97c, \ub450 \ubc88\uc9f8 \uc5f4([P2])\uc740 \ud558\ub098\uc758 \ucd94\uac00 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud55c \uacb0\uacfc\ub97c, \uc138 \ubc88\uc9f8 \uc5f4([P3])\uc740 \ub450 \uac1c\uc758 \ucd94\uac00 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud55c \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \uc5f4([P3] with no reference image)\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0 \uc5c6\uc774 \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub9cc \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc758 \uc218\uac00 \uacb0\uacfc\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uacfc \ubaa8\ub378\uc758 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654 \ub2a5\ub825\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \ud2b9\ud788, \ub85c\ucf13 \ubc1c\uc0ac \uc7a5\uba74\uc744 \ub2e4\uc591\ud55c \ubc30\uacbd\uacfc \ud568\uaed8 \uc0dd\uc131\ud558\uc5ec \ubaa8\ub378\uc758 \uc720\uc5f0\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06187/x13.png", "caption": "Figure 13: Same text prompt with different reference images of person.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 \ud575\uc2ec \ub0b4\uc6a9\uc778 \ub2e4\uc911 \uac1d\uccb4 \uac1c\ubc29\ud615 \uc9d1\ud569 \uac1c\uc778\ud654 \ube44\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub3d9\uc77c\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \ub2e4\ub978 \uc0ac\ub78c\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud588\uc744 \ub54c \uc0dd\uc131\ub41c \ube44\ub514\uc624 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ube44\uad50 \uacb0\uacfc\uc785\ub2c8\ub2e4.  \uac01\uac01 \ub2e4\ub978 \uc0ac\ub78c\uc758 \uc774\ubbf8\uc9c0\ub97c \ucc38\uc870 \uc774\ubbf8\uc9c0\ub85c \uc0ac\uc6a9\ud558\uc5ec \ub3d9\uc77c\ud55c \ud504\ub86c\ud504\ud2b8\uc5d0 \ub300\ud574 \uc5b4\ub5bb\uac8c \uacb0\uacfc\uac00 \ub2ec\ub77c\uc9c0\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \uc785\ub825 \uc774\ubbf8\uc9c0\uc5d0 \uacfc\ub3c4\ud558\uac8c \uc758\uc874\ud558\uc9c0 \uc54a\uace0, \ud504\ub86c\ud504\ud2b8\uc758 \ub0b4\uc6a9\uc744 \ucda9\uc2e4\ud788 \ubc18\uc601\ud558\uc5ec \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \ubd80\ubd84\uc785\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc (Experiments)"}, {"figure_path": "https://arxiv.org/html/2501.06187/x14.png", "caption": "Figure 14: Same text prompt with different reference images of dog.", "description": "\uadf8\ub9bc 14\ub294 \ub3d9\uc77c\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac15\uc544\uc9c0\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \ub2e4\ub974\uac8c \ud588\uc744 \ub54c \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ud589\uc740 \ub2e4\ub978 \uac15\uc544\uc9c0\uc758 \ucc38\uc870 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0dd\uc131\ud55c \ub3d9\uc77c\ud55c \ud504\ub86c\ud504\ud2b8\uc758 \ube44\ub514\uc624 \uc2dc\ud000\uc2a4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \uac15\uc544\uc9c0\uc758 \uc678\ud615\uc744 \uc720\uc9c0\ud558\uba74\uc11c\ub3c4 \ub3d9\uc77c\ud55c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc5d0 \ub530\ub978 \ube44\ub514\uc624 \uc0dd\uc131\uc758 \uc77c\uad00\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uccab \ubc88\uc9f8 \uc5f4\uc740 \ucc38\uc870 \uc774\ubbf8\uc9c0 \uc5c6\uc774 \uc0dd\uc131\ub41c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.06187/x15.png", "caption": "Figure 15: Qualitative comparison on the conditional subject of dog.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \ub17c\ubb38\uc758 \uc2e4\ud5d8 \uacb0\uacfc \ubd80\ubd84\uc5d0 \uc788\ub294 \uac83\uc73c\ub85c, \uac15\uc544\uc9c0\ub97c \uc870\uac74\uc73c\ub85c \ud558\ub294 \ube44\ub514\uc624 \uc0dd\uc131\uc5d0 \ub300\ud55c \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Video Alchemist\ub97c \ud3ec\ud568\ud55c \uc5ec\ub7ec \ube44\ub514\uc624 \uac1c\uc778\ud654 \ubaa8\ub378\ub4e4\uc774 \uc0dd\uc131\ud55c \ube44\ub514\uc624 \uc601\uc0c1\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\uba70, \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \uc601\uc0c1\ub4e4\uc740 \uc785\ub825\ub41c \ud14d\uc2a4\ud2b8 \ud504\ub86c\ud504\ud2b8\uc640 \ucc38\uc870 \uc774\ubbf8\uc9c0\uc5d0 \uc5bc\ub9c8\ub098 \ucda9\uc2e4\ud558\uac8c \uac15\uc544\uc9c0\uc758 \ubaa8\uc2b5\uacfc \uc6c0\uc9c1\uc784\uc744 \uc7ac\ud604\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc9c0\ud45c\uac00 \ub429\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810, \uadf8\ub9ac\uace0 \uac1c\uc778\ud654 \uc131\ub2a5\uc758 \ucc28\uc774\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ube44\uad50\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2. Comparisons with the State-of-the-Arts"}, {"figure_path": "https://arxiv.org/html/2501.06187/x16.png", "caption": "Figure 16: Qualitative comparison on the conditional subject of cat.", "description": "\uadf8\ub9bc 16\uc740 \uace0\uc591\uc774\ub97c \uc870\uac74\ubd80 \ud53c\uc0ac\uccb4\ub85c \uc0ac\uc6a9\ud55c \uc815\uc131\uc801 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ube44\ub514\uc624 \uac1c\uc778\ud654 \ubaa8\ub378(Video Alchemist, DreamVideo [75], VideoBooth [28], ELITE [74])\uc774 \uc0dd\uc131\ud55c \uacb0\uacfc\uc640 \uc2e4\uc81c \uc601\uc0c1\uc744 \ub098\ub780\ud788 \ubc30\uce58\ud558\uc5ec \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc774 \uace0\uc591\uc774\uc758 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uc6c0\uc9c1\uc784\uacfc \uc678\ud615\uc744 \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc7ac\ud604\ud558\ub294\uc9c0,  \uc870\uac74\ubd80 \uc815\ubcf4(\ud14d\uc2a4\ud2b8, \ucc38\uc870 \uc774\ubbf8\uc9c0)\ub97c \uc5bc\ub9c8\ub098 \ucda9\uc2e4\ud788 \ubc18\uc601\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 \uc804\uccb4\uc801\uc778 \ube44\ub514\uc624 \ud488\uc9c8\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \ubaa8\ub378 \uc131\ub2a5 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uac1c\uc778\ud654 \uc131\ub2a5\uc744 \uc815\uc131\uc801\uc73c\ub85c \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4.2. \ucd5c\ucca8\ub2e8 \uae30\uc220\uacfc\uc758 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2501.06187/x17.png", "caption": "Figure 17: Qualitative comparison on the conditional subject of car.", "description": "\uadf8\ub9bc 17\uc740 \uc790\ub3d9\ucc28\ub97c \uc870\uac74\ubd80 \uc8fc\uc81c\ub85c \ud558\ub294 \uc815\uc131\uc801 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\ub514\uc624 \uc54c\ucf00\ubbf8\uc2a4\ud2b8(Video Alchemist)\ub97c \ube44\ub86f\ud55c \ucd5c\ucca8\ub2e8 \uac1c\uc778\ud654 \ubaa8\ub378\uc758 \uacb0\uacfc\uc640 \uc2e4\uc81c \uc601\uc0c1\uc744 \ub098\ub780\ud788 \ubcf4\uc5ec\uc8fc\uc5b4, \uac01 \ubaa8\ub378\uc758 \uc790\ub3d9\ucc28 \ubb18\uc0ac \ub2a5\ub825\uacfc \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uc6c0\uc9c1\uc784 \uc0dd\uc131 \ub2a5\ub825\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \ud2b9\ud788, \ub2e4\uc591\ud55c \uac01\ub3c4\uc640 \uc870\uba85 \uc544\ub798\uc5d0\uc11c \uc790\ub3d9\ucc28\uc758 \uc678\uad00 \ubc0f \uc8fc\ubcc0 \ud658\uacbd\uc744 \uc5bc\ub9c8\ub098 \uc815\ud655\ud558\uac8c \uc7ac\ud604\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 \uc790\ub3d9\ucc28\uc758 \uc6c0\uc9c1\uc784\uc774 \uc5bc\ub9c8\ub098 \uc790\uc5f0\uc2a4\ub7fd\uace0 \ud604\uc2e4\uc801\uc778\uc9c0\ub97c \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "4.2. \ucd5c\ucca8\ub2e8 \uae30\uc220\uacfc\uc758 \ube44\uad50"}]