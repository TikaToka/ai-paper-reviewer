[{"content": "| Method | C (\u2191) | M<sub>1</sub> | M<sub>2</sub> | M<sub>3</sub> | M<sub>4</sub> | Avg (\u2193) |\n|---|---|---|---|---|---|---|\n| Human | 4.59 | 33.4 | 35.2 | 46.0 | 52.4 | 41.8 |\n| Naive | 4.59 | 34.2 | 40.6 | 50.2 | 59.0 | 46.0 |\n| w/o Concept | 4.66 | 33.6 | 37.8 | 46.4 | 57.4 | 43.8 |\n| w/o Reason | 4.69 | 30.0 | 40.2 | 47.8 | 56.2 | 43.5 |\n| w/o Vision | 4.68 | 29.0 | 39.2 | 45.8 | 57.2 | 42.8 |\n| w/o Data | 4.66 | 29.4 | 36.6 | 47.0 | 57.8 | 42.7 |\n| w/o Bias | 4.65 | 30.6 | 37.6 | 48.6 | 60.2 | 44.2 |\n| w/o Reviewer | 4.64 | 30.2 | 38.2 | 45.4 | 57.2 | 42.7 |\n| w/o Refiner | 4.28 | 25.0 | 34.2 | 42.0 | 50.0 | 37.8 |\n| *AutoConverter* | 4.69 | 27.8 | 37.2 | 44.2 | 53.6 | 40.7 |", "caption": "Table 1: Performance of 33 VLMs on VMCBench test set.", "description": "\ud45c 1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc2dc\ub41c VMCBench \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0 \ub300\ud574 33\uac1c\uc758 \ucd5c\ucca8\ub2e8 VLMs(Vision Language Models)\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \uc77c\ubc18 \ucd94\ub860, OCR, \ubb38\uc11c \ubc0f \ucc28\ud2b8 \uc774\ud574 \uc138 \uac00\uc9c0 \ud558\uc704 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4 \uc810\uc218\uc640 \uc774 \uc138 \uac00\uc9c0 \uc791\uc5c5\uc5d0 \ub300\ud55c \uac00\uc911 \ud3c9\uade0 \uc810\uc218\ub97c \ud3ec\ud568\ud558\uc5ec \ubaa8\ub378\uc758 \uc804\ubc18\uc801\uc778 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c VLMs\uc758 \uc0c1\ub300\uc801\uc778 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ube44\uad50\ud558\uc5ec VLM \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud55c VMCBench\uc758 \uc720\uc6a9\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5.2 \ud3c9\uac00 \uacb0\uacfc"}, {"content": "| Model | General | Reasoning | OCR | Doc&Chart | Avg. |\n|---|---|---|---|---|---| \n| Qwen2-VL-72B | 88.5 | 72.6 | 96.8 | 90.1 | 85.0 |\n| GPT-4o | 85.2 | 66.9 | 96.4 | 83.1 | 80.3 |\n| Molmo-72B | 82.9 | 66.6 | 94.7 | 81.1 | 78.7 |\n| Qwen2-VL-7B | 84.5 | 62.7 | 96.4 | 80.1 | 78.1 |\n| Claude-3.5-Sonnet | 81.3 | 62.8 | 93.4 | 84.6 | 77.8 |\n| Cambrian-34B | 83.7 | 65.9 | 95.7 | 73.3 | 77.0 |\n| Gemini-1.5-Pro | 79.6 | 64.7 | 92.6 | 72.6 | 74.7 |\n| VILA1.5-40B | 82.5 | 65.3 | 93.2 | 67.4 | 74.7 |\n| GPT-4o-Mini | 80.9 | 58.8 | 93.8 | 74.8 | 74.0 |\n| Qwen2-VL-2B | 77.9 | 55.8 | 93.1 | 72.5 | 71.5 |\n| CogVLM2-19B | 78.1 | 55.6 | 92.3 | 72.6 | 71.4 |\n| Phi-3-Vision | 74.1 | 56.4 | 90.6 | 73.8 | 70.3 |\n| Cambrian-13B | 79.3 | 54.6 | 92.3 | 66.6 | 70.0 |\n| Cambrian-8B | 77.9 | 56.4 | 91.0 | 65.4 | 69.6 |\n| Molmo-7B-D | 73.2 | 55.5 | 91.7 | 72.1 | 69.5 |\n| Idefics2-8B | 77.8 | 55.8 | 92.7 | 61.8 | 68.7 |\n| Molmo-7B-O | 72.6 | 54.3 | 88.5 | 68.9 | 67.8 |\n| Phi-3.5-Vision | 71.4 | 55.3 | 87.2 | 68.6 | 67.4 |\n| VILA1.5-13B | 74.6 | 54.1 | 85.3 | 50.2 | 63.4 |\n| DeepSeek-VL-7B | 73.2 | 52.6 | 85.8 | 52.9 | 63.2 |\n| Molmo-1B | 69.4 | 50.1 | 87.4 | 60.2 | 63.1 |\n| CogVLM-17B | 72.3 | 48.8 | 77.8 | 54.6 | 61.3 |\n| VILA1.5-8B | 72.4 | 51.8 | 81.8 | 46.5 | 60.7 |\n| Gemini-1.5-Flash | 59.7 | 53.8 | 79.9 | 56.3 | 59.1 |\n| PaliGemma-3B | 71.7 | 51.3 | 53.1 | 53.0 | 59.0 |\n| VILA1.5-3B | 70.3 | 48.0 | 78.9 | 42.3 | 57.5 |\n| DeepSeek-VL-1.3B | 68.9 | 43.6 | 79.5 | 43.8 | 56.1 |\n| LLaVA1.5-13B | 66.4 | 46.2 | 75.8 | 37.0 | 53.9 |\n| LLaVA1.5-7B | 63.6 | 44.7 | 74.0 | 35.0 | 51.8 |\n| Chameleon-30B | 53.1 | 41.2 | 48.0 | 33.9 | 44.2 |\n| InstructBLIP-7B | 55.1 | 35.2 | 47.7 | 29.9 | 42.1 |\n| InstructBLIP-13B | 54.8 | 34.7 | 48.7 | 26.5 | 41.1 |\n| Chameleon-7B | 41.0 | 34.7 | 42.3 | 29.6 | 36.4 |", "caption": "Table 2: Examples of rule-based evaluation failures of open-ended questions. Rule-based methods fail to account for semantic similarity and penalize formatting errors, resulting in highly inaccurate evaluation results.", "description": "\ubcf8 \ud45c\ub294 \uac1c\ubc29\ud615 \uc9c8\ubb38\uc5d0 \ub300\ud55c \uaddc\uce59 \uae30\ubc18 \ud3c9\uac00 \ubc29\uc2dd\uc758 \ud55c\uacc4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4. \uaddc\uce59 \uae30\ubc18 \ubc29\uc2dd\uc740 \uc758\ubbf8\uc801 \uc720\uc0ac\uc131\uc744 \uace0\ub824\ud558\uc9c0 \uc54a\uace0 \ud615\uc2dd\uc801 \uc624\ub958\uc5d0 \ub300\ud574 \ubd88\uc774\uc775\uc744 \uc8fc\uae30 \ub54c\ubb38\uc5d0, \ud3c9\uac00 \uacb0\uacfc\uac00 \ub9e4\uc6b0 \ubd80\uc815\ud655\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uc774\ubbf8\uc9c0\uc640 \uc9c8\ubb38, \uc815\ub2f5, \ubaa8\ub378\uc758 \uc608\uce21\uac12, \uadf8\ub9ac\uace0 \uae30\uc874 VQA \uc810\uc218\uc640 \ubaa8\ub378 \uc810\uc218\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uc608\uc2dc\ub294 \uaddc\uce59 \uae30\ubc18 \ud3c9\uac00 \ubc29\uc2dd\uc774 \uc758\ubbf8\uc801 \ucc28\uc774\ub97c \uc81c\ub300\ub85c \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\uace0 \ud615\uc2dd\uc5d0\ub9cc \uc9d1\uc911\ud558\uc5ec \ubd80\uc815\ud655\ud55c \ud3c9\uac00 \uacb0\uacfc\ub97c \ucd08\ub798\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. Open-Ended Question Evaluation Challenge"}, {"content": "| Image | Question | Answer | Prediction | VQAScore | ModelScore |\n|---|---|---|---|---|---| \n| <img src=\"https://arxiv.org/html/2501.03225/rule1.png\" width=63 height=63> | Where is the man\u2019s left hand holding? | chin | On his chin. | 0 | 1 |\n| <img src=\"https://arxiv.org/html/2501.03225/rule2.png\" width=63 height=63> | How many sinks are there? | 2 | Two sinks. | 0 | 1 |\n| <img src=\"https://arxiv.org/html/2501.03225/rule3.png\" width=63 height=63> | What is the light source? | street lights | Streetlights | 0 | 1 |\n| <img src=\"https://arxiv.org/html/2501.03225/rule4.png\" width=63 height=63> | What is the horse jumping over? | log | Log fence | 0 | 1 |\n| <img src=\"https://arxiv.org/html/2501.03225/rule5.png\" width=63 height=63> | Where is the train going? | svanemollen | Svanem\u00f8llen | 0 | 1 |\n| <img src=\"https://arxiv.org/html/2501.03225/rule6.png\" width=63 height=63> | What colors are on this train? | blue and yellow and silver | Blue, yellow, and silver. | 0 | 1 |", "caption": "Table 3: Examples of model-based evaluation failures of open-ended questions. GPT-4o-0806 often assigns a perfect score of for similar predictions and answers, whereas GPT-4o-0513 tends to assign a score of 0.9. This behavior variation introduces significant differences in evaluation results and raises concerns about reproducibility in future research.", "description": "\ubcf8 \ud45c\ub294 \uc624\ud508\uc5d4\ub4dc\ud615 \uc9c8\ubb38\uc5d0 \ub300\ud55c \ubaa8\ub378 \uae30\ubc18 \ud3c9\uac00\uc758 \uc5b4\ub824\uc6c0\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  GPT-4 0806 \ubaa8\ub378\uc740 \uc720\uc0ac\ud55c \uc608\uce21\uacfc \ub2f5\ubcc0\uc5d0 \ub300\ud574 \uc644\ubcbd\ud55c \uc810\uc218(1.0)\ub97c \ubd80\uc5ec\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\ub294 \ubc18\uba74, GPT-4 0513 \ubaa8\ub378\uc740 0.9\uc810\uc744 \ubd80\uc5ec\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ucc28\uc774\ub294 \ud3c9\uac00 \uacb0\uacfc\uc5d0 \uc0c1\ub2f9\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\uba70, \uc5f0\uad6c\uc758 \uc7ac\ud604\uc131\uc5d0 \ub300\ud55c \uc6b0\ub824\ub97c \uc81c\uae30\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \ubaa8\ub378\uc758 \ubc84\uc804\uc5d0 \ub530\ub978 \ubd88\uc77c\uce58 \uc0ac\ub840 \uc5ec\uc12f \uac00\uc9c0\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3. Open-Ended Question Evaluation Challenge"}, {"content": "| Image | Question | Answer | Prediction | GPT-4o-0513 Score | GPT-4o-0806 Score |\n|---|---|---|---|---|---| \n| ![model1](https://arxiv.org/html/2501.03225/images/model1.png) | Does the giraffe appear dangerous? | no | The giraffe in the image does not appear to be dangerous. It seems to be calm and at ease with the person\u2019s presence, indicating a level of trust and familiarity between them. | 0.9 | 1.0 |\n| ![model2](https://arxiv.org/html/2501.03225/images/model2.png) | Is the man happy? | yes | The man in the image appears to be happy. His facial expression, characterized by a broad smile and eyes that seem to be crinkling at the corners, typically indicates joy or amusement\u2026 | 0.9 | 1.0 |\n| ![model3](https://arxiv.org/html/2501.03225/images/model3.png) | Is that wine in the background? | no | No, there is no wine in the background. The image shows a pizza and a can of Coca-Cola on a desk, with a laptop and some other items in the background. | 0.9 | 1.0 |\n| ![model4](https://arxiv.org/html/2501.03225/images/model4.png) | What are all the scene text in the image? | S3302CD | The scene text in the image reads \u2019S 3302 CD\u2019. | 0.9 | 1.0 |\n| ![model5](https://arxiv.org/html/2501.03225/images/model5.png) | What is this banknote? | ten pound or 10 pound or British pound | This is a ten-pound banknote from the United Kingdom, featuring the portrait of Queen Elizabeth II. | 0.9 | 1.0 |\n| ![model6](https://arxiv.org/html/2501.03225/images/model6.png) | How many birds are there? | 6 | There are six birds perched on the branch, each displaying a unique coloration and size, which suggests they may belong to different species. | 0.9 | 1.0 |", "caption": "Table 4: Performance of 33 vision language models on 20 subsets of VMCBench test set.", "description": "\ubcf8 \ud45c\ub294 VMCBench \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc758 20\uac1c \ud558\uc704 \uc9d1\ud569\uc5d0 \ub300\ud574 33\uac1c\uc758 \ucd5c\ucca8\ub2e8 \ube44\uc804 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud558\uc704 \uc9d1\ud569\uc740 \ud2b9\uc815\ud55c \ube44\uc804 \uc5b8\uc5b4 \uc791\uc5c5(\uc608: \uc77c\ubc18 \ucd94\ub860, OCR, \ubb38\uc11c \ubc0f \ucc28\ud2b8 \uc774\ud574)\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 \uc788\uc73c\uba70, \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ud574\ub2f9 \ud558\uc704 \uc9d1\ud569\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub85c \uce21\uc815\ub429\ub2c8\ub2e4.", "section": "5.2 \ud3c9\uac00 \uacb0\uacfc"}, {"content": "Model|SEEDBench|MMStar|A-OKVQA|VizWiz|MMVet|VQAv2|OKVQA|MMMU|MathVista|ScienceQA|\n---|---|---|---|---|---|---|---|---|---|---|\nQwen2-VL-72B|84.2|71.5|93.4|94.9|88.5|92.4|94.8|70.2|70.3|87.1|\nGPT-4o|84.2|62.2|92.0|94.4|80.6|88.7|94.1|70.0|51.0|86.9|\nMolmo-72B|82.0|62.5|88.5|88.5|79.1|85.6|94.1|59.4|60.9|89.4|\nQwen2-VL-7B|82.7|60.3|90.1|92.4|82.0|91.4|92.6|54.1|48.0|86.9|\nClaude-3.5-Sonnet|78.3|53.7|86.4|87.2|87.8|84.7|91.1|59.6|56.9|79.9|\nCambrian-34B|83.5|59.4|91.1|90.7|81.3|88.4|91.9|55.0|60.9|83.5|\nGemini-1.5-Pro|77.3|52.0|88.0|89.0|79.9|80.8|90.4|59.6|56.9|83.0|\nVILA1.5-40B|81.2|58.0|90.8|90.2|77.0|87.3|93.3|58.2|65.3|83.3|\nGPT-4o-Mini|79.3|47.7|86.1|92.2|80.6|88.2|92.1|56.5|43.1|78.7|\nQwen2-VL-2B|77.8|44.7|86.6|88.2|70.5|88.7|88.6|46.2|39.1|76.0|\nCogVLM2-19B|77.3|48.2|87.8|87.3|73.4|85.2|87.4|39.7|35.6|90.5|\nPhi-3-Vision|78.3|46.8|81.6|79.9|67.6|79.2|85.2|44.7|38.6|92.1|\nCambrian-13B|79.3|48.5|86.4|87.3|76.3|87.0|90.6|41.3|39.6|77.4|\nCambrian-8B|78.3|53.0|84.5|88.0|68.3|85.6|87.9|43.3|45.5|77.4|\nMolmo-7B-D|74.1|46.8|82.4|81.9|63.3|80.3|83.5|43.0|37.6|91.9|\nIdefics2-8B|77.8|49.4|85.4|84.8|69.8|86.8|90.4|38.5|41.6|91.9|\nMolmo-7B-O|75.1|45.8|80.5|78.9|66.2|78.2|83.2|44.0|35.6|90.0|\nPhi-3.5-Vision|74.8|45.8|76.5|75.7|64.0|79.4|83.5|45.2|39.1|87.3|\nVILA1.5-13B|77.5|44.9|81.9|83.3|63.3|82.4|88.6|42.8|48.5|72.6|\nDeepSeek-VL-7B|75.6|39.9|80.5|82.1|63.3|83.6|87.7|41.1|33.2|86.7|\nMolmo-1B|70.9|43.0|77.9|80.9|54.7|75.7|83.0|36.3|27.7|89.1|\nCogVLM-17B|70.9|42.8|80.7|85.0|59.7|80.1|86.7|37.5|36.1|66.7|\nVILA1.5-8B|74.3|40.9|77.9|79.4|64.7|80.8|88.6|38.0|49.0|71.5|\nGemini-1.5-Flash|56.3|38.0|67.0|68.5|53.2|64.1|70.6|48.1|57.9|66.3|\nPaliGemma-3B|74.6|39.9|87.3|77.0|50.4|87.7|85.2|29.1|30.7|94.3|\nVILA1.5-3B|74.3|38.5|76.9|80.9|57.6|78.5|85.4|34.4|39.6|64.9|\nDeepSeek-VL-1.3B|70.9|37.5|74.4|82.1|52.5|80.3|84.7|31.0|22.3|63.8|\nLLaVA1.5-13B|66.2|37.3|76.5|76.0|59.7|64.1|85.2|37.5|31.7|66.3|\nLLaVA1.5-7B|62.2|34.2|72.5|73.8|54.0|66.7|82.2|35.6|31.2|68.6|\nChameleon-30B|53.6|33.0|57.2|52.2|48.9|58.3|68.6|34.4|32.7|57.9|\nInstructBLIP-7B|52.8|34.7|61.9|65.4|39.6|59.7|71.9|31.0|22.8|46.8|\nInstructBLIP-13B|48.4|29.0|63.3|64.2|43.2|64.1|71.6|25.7|19.8|50.0|\nChameleon-7B|44.9|31.6|46.4|40.4|29.5|41.4|53.1|32.7|22.3|53.6|", "caption": "Table 5: Examples of VMCBench (1/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\uc774 \ud45c\ub294 \ub17c\ubb38\uc758 VMCBench \ubca4\uce58\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VMCBench\ub294 \ub2e4\uc591\ud55c \uae30\uc874 VQA \ub370\uc774\ud130\uc14b\uc744 \uc5ec\ub7ec \uc120\ud0dd\uc9c0\uac00 \uc788\ub294 \uc9c8\ubb38 \ud615\uc2dd\uc73c\ub85c \ud1b5\ud569\ud55c \uac83\uc785\ub2c8\ub2e4. \uac01 \ud589\uc740 \ud2b9\uc815 \ub370\uc774\ud130\uc14b\uc758 \ucd9c\ucc98, \uad00\ub828 \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc815\ub2f5\uc740 \uc8fc\ud669\uc0c9\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench\uc758 \ub2e4\uc591\ud55c \uc9c8\ubb38 \uc720\ud615\uacfc \ub370\uc774\ud130\uc14b\uc758 \ubc94\uc704\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ucd08\uc810\uc744 \ub9de\ucd94\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ucd1d 7\uac1c\uc758 \ud45c\ub85c \ub098\ub220\uc838 \uc788\uc73c\uba70, \uc774 \ud45c\ub294 \uadf8 \uc911 \uccab \ubc88\uc9f8 \ud45c\uc785\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| A-OKVQA | https://arxiv.org/html/2501.03225/images/8255.png | What season of the year is shown here? | A. late summer with green leaves <br> B. early spring with blooming flowers <br> C. fall <br> D. early winter with snow | \n| A-OKVQA | https://arxiv.org/html/2501.03225/images/7998.png | What occasion are the bears probably sitting at the table enjoying? | A. Thanksgiving <br> B. Easter <br> C. New Year\u2019s Eve <br> D. Christmas | \n| A-OKVQA | https://arxiv.org/html/2501.03225/images/8430.png | What kind of beverage is the red sign advertising? | A. Dr Pepper <br> B. Coca Cola <br> C. Red Bull <br> D. Pepsi | \n| AI2D | https://arxiv.org/html/2501.03225/images/1667.png | Which shows the first stage? | A. b <br> B. a <br> C. d <br> D. c | \n| AI2D | https://arxiv.org/html/2501.03225/images/1293.png | What part of plants the diagram depicts? | A. Leaf <br> B. Stem <br> C. Root <br> D. Flower petal | \n| AI2D | https://arxiv.org/html/2501.03225/images/1275.png | Which is the exterior portion of the earth? | A. A <br> B. D <br> C. C <br> D. B | \n| ChartQA | https://arxiv.org/html/2501.03225/images/7120.jpg | What percentage of respondents own lots of vinyl records? | A. 35 <br> B. 24 <br> C. 30 <br> D. 28 | \n| ChartQA | https://arxiv.org/html/2501.03225/images/7076.jpg | In which year is the ACSI score is lowest? | A. 2015 <br> B. 2017 <br> C. 2018 <br> D. 2010 | \n| ChartQA | https://arxiv.org/html/2501.03225/images/7073.jpg | What is the total ratio of 2014 through 2017? | A. 5.36 <br> B. 5.11 <br> C. 4.57 <br> D. 5.25 |", "caption": "Table 6: Examples of VMCBench (2/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 6\uc740 VMCBench\uc758 \uc77c\ubd80 \uc608\uc2dc (\uc804\uccb4 7\uac1c \uc911 2\ubc88\uc9f8)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc608\uc2dc\ub294 \ub370\uc774\ud130\uc14b \ucd9c\ucc98, \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0 (\uc815\ub2f5\uc740 \uc8fc\ud669\uc0c9\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench \ub370\uc774\ud130\uc14b\uc758 \ub2e4\uc591\ud55c \uc720\ud615\uacfc \ubcf5\uc7a1\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc608\uc2dc\ub4e4\uc744 \uc81c\uc2dc\ud558\uc5ec \ub3c5\uc790\uc758 \uc774\ud574\ub97c \ub3d5\uace0\uc790 \ud569\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| DocVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/5929.png | What is the table number? | A. 7<br>B. 8<br>C. 10<br>D. 9 | \n| DocVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/5663.png | In the plot, what is the value of \u201dr\u201d? | A. 0.994<br>B. 0.949<br>C. 1.004<br>D. 0.980 | \n| DocVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/5758.jpg | Which category item\u2019s advertisement is this? | A. health supplements <br>B. foods<br>C. home appliances <br>D. clothing | \n| GQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/7896.jpg | What food is to the left of the table? | A. can of soup <br>B. bag of flour <br>C. cereal box <br>D. dog food | \n| GQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/7537.jpg | Who is looking at the cell phone? | A. man<br>B. tourist <br>C. child <br>D. nobody | \n| GQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/7776.jpg | What does the woman hold? | A. cell phone<br>B. digital camera <br>C. remote control <br>D. compact mirror | \n| InfoVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/5343.jpg | Which states/UT has been included under \u201cCertain\u201d risk of community transmission? | A. manipur, tamil nadu <br>B. maharashtra, gujarat <br>C. rajasthan, karnataka <br>D. telangana, delhi | \n| InfoVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/4993.jpg | What percentage of Canadian still go to brick and mortar stores to buy items? | A. 30% <br>B. 70%<br>C. 80% <br>D. 60% | \n| InfoVQA | https://arxiv.org/html/2501.03225/extracted/6113068/images/5165.jpg | How many women out of every 4 women are domestic violence survivors? | A. 4 <br>B. 3<br>C. 1.5 <br>D. 2 |", "caption": "Table 7: Examples of VMCBench (3/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 7\uc740 VMCBench\uc758 \uc77c\ubd80 \uc9c8\ubb38\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4. VMCBench\ub294 20\uac1c\uc758 \uae30\uc874 VQA \ub370\uc774\ud130\uc14b\uc744 \ud1b5\ud569\ud558\uc5ec \ub9cc\ub4e0 \ubca4\uce58\ub9c8\ud06c\uc774\uba70, \uac01 \uc608\uc2dc\ub294 \ub370\uc774\ud130\uc14b \ucd9c\ucc98, \uc774\ubbf8\uc9c0, \uc9c8\ubb38\uacfc \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0(\uc815\ub2f5\uc740 \uc8fc\ud669\uc0c9\uc73c\ub85c \ud45c\uc2dc)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench\uc758 \ub2e4\uc591\ud55c \uc9c8\ubb38 \uc720\ud615\uacfc \ub09c\uc774\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc608\uc2dc\ub4e4\uc744 \uc81c\uc2dc\ud558\uba70, \uc804\uccb4 \ubca4\uce58\ub9c8\ud06c\uc758 \uaddc\ubaa8\uc640 \ub2e4\uc591\uc131\uc744 \uac04\ub7b5\ud788 \uc18c\uac1c\ud558\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| MMMU | https://arxiv.org/html/2501.03225/images/343.png | The average wave velocity value of the bored pile body at a certain site is 3555.6m/s, and the low strain reflected wave dynamic test curve of a certain column is shown in Figure 10-3, corresponding to the values of time t1, t2, and t3 in the figure, which of the following options is the closest value to the length of the pile? | A. 22.0m <br> B. 24.0m <br> C. 26.0m <br> D. 23.0m |\n| MMMU | https://arxiv.org/html/2501.03225/images/284.png | How many molecules of the sweetener saccharin can be prepared from 30 $C$ atoms, 25 $H$ atoms, 12 $O$ atoms, 8 $S$ atoms, and 14 $N$ atoms? | A. 6 <br> B. 4 <br> C. 2 <br> D. 5 |\n| MMMU | https://arxiv.org/html/2501.03225/images/333.png | The accompanying sketch shows the schematic arrangement for measuring the thermal conductivity by the guarded hot plate method. Two similar 1 cm thick specimens receive heat from a 6.5 cm by 6.5 cm guard heater. When the power dissipation by the wattmeter was 15 W, the thermocouples inserted at the hot and cold surfaces indicated temperatures as 325 K and 300 K. What is the thermal conductivity of the test specimen material? | A. 0.86 W/m K <br> B. 0.5 W/m K <br> C. 0.68 W/m K <br> D. 0.71 W/m K |\n| MMStar | https://arxiv.org/html/2501.03225/images/1194.jpg | What color is the ribbon that the man on the right is holding? | A. Red <br> B. Blue <br> C. Yellow <br> D. Green |\n| MMStar | https://arxiv.org/html/2501.03225/images/1202.jpg | What is the main feature of the building in the image? | A. The colorful facade <br> B. The large stained glass windows <br> C. The marble columns <br> D. The stone wall |\n| MMStar | https://arxiv.org/html/2501.03225/images/916.jpg | who is this person? | A. Awkwafina <br> B. Sandra Oh <br> C. Ali Wong <br> D. Lucy Liu |\n| MMVet | https://arxiv.org/html/2501.03225/images/2784.jpg | What is the original price for pork belly before discount? | A. 10 <br> B. 12 <br> C. 14 <br> D. 15 |\n| MMVet | https://arxiv.org/html/2501.03225/images/2773.jpg | What is the answer to the second equation on the right? | A. 11 <br> B. 5 <br> C. 7 <br> D. 9 |\n| MMVet | https://arxiv.org/html/2501.03225/images/2902.jpg | What occasions would someone use this meme? | A. Sharing relatable humor about feeling sleepy or having conflicting desires, especially during the day. <br> B. Expressing excitement about a new bedtime routine <br> C. Celebrating an all-nighter successfully pulled off <br> D. Promoting productivity in the workplace |", "caption": "Table 8: Examples of VMCBench (4/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 8\uc740 VMCBench \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80(4/7)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub370\uc774\ud130\uc14b \ucd9c\ucc98, \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \uc815\ub2f5\uc774 \uc8fc\ud669\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub41c \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench\uc758 \ub2e4\uc591\ud55c \uc9c8\ubb38 \uc720\ud615\uacfc \ub09c\uc774\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ub300\ud45c\uc801\uc778 \uc608\uc2dc\ub4e4\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| MathVision | https://arxiv.org/html/2501.03225/images/3460.png | In the grid, how many grey squares have to be coloured white, so that in each row and each column there is exactly one grey square? | A. 5 <br> B. 8 <br> C. 6 <br> D. 7 | \n| MathVision | https://arxiv.org/html/2501.03225/images/3221.png | Tom, John and Lily each shot six arrows at a target. Arrows hitting anywhere within the same ring scored the same number of points. Tom scored 46 points and John scored 34 points, as shown. How many points did Lily score? | A. 42 <br> B. 40 <br> C. 44 <br> D. 38 | \n| MathVision | https://arxiv.org/html/2501.03225/images/3270.png | A point  \ud835\udc43  is chosen in the interior of  \u25b3ABC  so that when lines are drawn through  \ud835\udc43  parallel to the sides of  \u25b3ABC , the resulting smaller triangles,  \ud835\udc61\u2081, \ud835\udc61\u2082, and  \ud835\udc61\u2083  in the figure, have areas 4, 9, and 49, respectively. Find the area of  \u25b3ABC . | A. 81 <br> B. 128 <br> C. 144 <br> D. 72 | \n| MathVista | https://arxiv.org/html/2501.03225/images/755.jpg | In the figure, \u22209=75. Find the measure of \u22206. | A. 120 <br> B. 135 <br> C. 150 <br> D. 105 | \n| MathVista | https://arxiv.org/html/2501.03225/images/766.jpg | (Original in Chinese) As shown in the figure, in \u25b3ABC, AD is the angle bisector, and AE is the altitude. If \u2220B=40\u00b0 and \u2220C=70\u00b0, then the measure of \u2220EAD is (). | A. 25\u00b0 <br> B. 20\u00b0 <br> C. 30\u00b0 <br> D. 15\u00b0 | \n| MathVista | https://arxiv.org/html/2501.03225/images/583.jpg | What is the green curve? | A. a cubic function <br> B. a trigonometric function <br> C. an exponential function <br> D. a logarithmic function | \n| OCRVQA | https://arxiv.org/html/2501.03225/images/6164.jpg | Who wrote this book? | A. John D. Smith <br> B. Ruth E. McCall BS MT(ASCP) <br> C. Michael A. Johnson <br> D. Emily J. Brown | \n| OCRVQA | https://arxiv.org/html/2501.03225/images/6102.jpg | What is the title of this book? | A. Climate Change and Urban Adaptation Strategies <br> B. Building a Sustainable Future: Climate Change Adaptation <br> C. Adapting Urban Spaces: Sustainability in the 21st Century <br> D. Adapting Buildings and Cities for Climate Change | \n| OCRVQA | https://arxiv.org/html/2501.03225/images/6145.jpg | What is the title of this book? | A. Cracking the PSAT/NMSQT, 2013 Edition (College Test Preparation) <br> B. Cracking the SAT, 2013 Edition (College Test Preparation) <br> C. Crushing the PSAT/NMSQT, 2013 Edition <br> D. Cracking the PSAT, 2014 Edition (College Test Preparation) |", "caption": "Table 9: Examples of VMCBench (5/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 9\ub294 VMCBench \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80(5/7)\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ud589\uc740 \ub370\uc774\ud130\uc14b \ucd9c\ucc98, \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \ub124 \uac00\uc9c0 \ubcf4\uae30(\uc815\ub2f5\uc740 \uc8fc\ud669\uc0c9\uc73c\ub85c \ud45c\uc2dc)\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench\uc758 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc9c8\ubb38\uacfc \uc774\ubbf8\uc9c0\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\ub4e4\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| OKVQA | https://arxiv.org/html/2501.03225/images/8935.png | What food is being sold? | A. hamburger <br> B. sandwich <br> C. hot dog <br> D. kebab | \n| OKVQA | https://arxiv.org/html/2501.03225/images/8827.png | What is the proper response when traveling in a vehicle and seeing a red traffic light? | A. proceed with caution <br> B. speed up to clear the intersection <br> C. stop <br> D. yield only if necessary | \n| OKVQA | https://arxiv.org/html/2501.03225/images/8885.png | How long does this animal usually live? | A. 25 years <br> B. 10 years <br> C. 20 years <br> D. 8 years | \n| RealWorldQA | https://arxiv.org/html/2501.03225/images/4406.jpg | How many oncoming vehicles are there? | A. 4 <br> B. 3 <br> C. 1 <br> D. 2 | \n| RealWorldQA | https://arxiv.org/html/2501.03225/images/4389.jpg | Which way does this door open? | A. The door opens outward, swinging to the right. <br> B. The door is a sliding door, moving to the right. <br> C. The door opens inward, swinging to the right. <br> D. The door opens outward, swinging to the left. | \n| RealWorldQA | https://arxiv.org/html/2501.03225/images/4311.jpg | Which object is bigger than the other? | A. Both objects are the same size. <br> B. The right object is bigger. <br> C. The left object has more volume. <br> D. The left object is bigger. | \n| SEEDBench | https://arxiv.org/html/2501.03225/images/2720.jpg | What can be found in the image? | A. A group of people sitting down and a young boy with a basketball player. <br> B. A basketball player signing autographs for a line of fans. <br> C. A group of musicians playing instruments <br> D. Several students in a classroom setting | \n| SEEDBench | https://arxiv.org/html/2501.03225/images/2551.jpg | Which object is emitting smoke in the image? | A. Factory smokestack in the background <br> B. House chimney <br> C. Chimney of a nearby house <br> D. Train | \n| SEEDBench | https://arxiv.org/html/2501.03225/images/2614.jpg | What is the boy doing in the image? | A. Jumping <br> B. Smiling <br> C. Reading a book <br> D. Waving |", "caption": "Table 10: Examples of VMCBench (6/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 10\uc740 VMCBench \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4. VMCBench\ub294 \ub2e4\uc591\ud55c \uae30\uc874 VQA \ub370\uc774\ud130\uc14b\ub4e4\uc744 \ud558\ub098\uc758 \ub2e4\uc911 \uc120\ud0dd \uc9c8\ubb38 \ud615\uc2dd\uc73c\ub85c \ud1b5\ud569\ud55c \ubca4\uce58\ub9c8\ud06c\uc785\ub2c8\ub2e4. \uc774 \ud45c\uc5d0\ub294 \uac01 \uc608\uc2dc\uc5d0 \ub300\ud574 \ub370\uc774\ud130\uc14b \ucd9c\ucc98, \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0 (\uc815\ub2f5\uc740 \uc8fc\ud669\uc0c9\uc73c\ub85c \ud45c\uc2dc)\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc758 \ub2e4\uc591\ud55c \ube44\uc804 \uc5b8\uc5b4 \uc774\ud574 \ub2a5\ub825\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}, {"content": "| Source | Image | Question | Choices |\n|---|---|---|---| \n| ScienceQA | https://arxiv.org/html/2501.03225/images/2139.png | What is the name of the colony shown? | A. Rhode Island<br>B. Connecticut<br>C. New Hampshire<br>D. Massachusetts | \n| ScienceQA | https://arxiv.org/html/2501.03225/images/2001.png | Which continent is highlighted? | A. Australia<br>B. Arctic<br>C. South America<br>D. Antarctica | \n| ScienceQA | https://arxiv.org/html/2501.03225/images/1815.png | What can Turner and Mona trade to each get what they want? | A. Turner can trade his tomatoes for Mona\u2019s broccoli.<br>B. Turner can trade his oranges for Mona\u2019s water. <br>C. Turner can trade his water for Mona\u2019s almonds. <br>D. Turner can trade his sandwich for Mona\u2019s hot dog. | \n| TableVQA-Bench | https://arxiv.org/html/2501.03225/images/3799.png | What is the total amount of Purchase Obligations due after 2021? | A. $6.5<br>B. $80.7<br>C. $0.0<br>D. $214.9 | \n| TableVQA-Bench | https://arxiv.org/html/2501.03225/images/3764.png | what other name did asian cougar have? | A. Gamma<br>B. Kooga<br>C. Kuuga<br>D. Black Buffalo | \n| TableVQA-Bench | https://arxiv.org/html/2501.03225/images/3504.png | how many metals did netherlands and the us win together? | A. 18<br>B. 20<br>C. 22<br>D. 19 | \n| TextVQA | https://arxiv.org/html/2501.03225/images/4635.jpg | what number is shown? | A. 21<br>B. 25<br>C. 22<br>D. 20 | \n| TextVQA | https://arxiv.org/html/2501.03225/images/4515.jpg | what male name is written on the white book? | A. mike<br>B. sean<br>C. dave<br>D. steve | \n| TextVQA | https://arxiv.org/html/2501.03225/images/4865.jpg | which company is giving the presentation? | A. ibm<br>B. sap<br>C. google<br>D. oracle |", "caption": "Table 11: Examples of VMCBench (7/7). Each example has a dataset source, image, question, and four choices (correct choice highlighted in orange).", "description": "\ud45c 11\uc740 VMCBench \ub370\uc774\ud130\uc14b\uc758 \uc77c\ubd80 \uc608\uc2dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd1d 20\uac1c\uc758 \uae30\uc874 VQA \ub370\uc774\ud130\uc14b\uc744 \ud558\ub098\ub85c \ud1b5\ud569\ud55c VMCBench\ub294 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \uc2dc\uac01\uc801 \uc9c8\ubb38\uacfc \ub2f5\ubcc0\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4. \uac01 \ud589\uc740 \ud558\ub098\uc758 \ub370\uc774\ud130\uc14b \uc18c\uc2a4, \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \uadf8\ub9ac\uace0 \uc815\ub2f5\uc774 \uc8fc\ud669\uc0c9\uc73c\ub85c \uac15\uc870\ub41c \ub124 \uac00\uc9c0 \uc120\ud0dd\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 VMCBench\uc758 \ub2e4\uc591\uc131\uacfc \ub09c\uc774\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. VMCBench: A Unified Multiple-Choice Visual Question Answering Benchmark"}]