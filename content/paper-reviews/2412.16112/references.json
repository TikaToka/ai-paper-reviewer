{"references": [{"fullname_first_author": "Fan Bao", "paper_title": "All are worth words: A vit backbone for diffusion models", "publication_date": "2023-00-00", "reason": "This paper is foundational to the understanding of using vision transformer backbones within diffusion models, a core topic of the current paper."}, {"fullname_first_author": "Omer Bar-Tal", "paper_title": "Multidiffusion: Fusing diffusion paths for controlled image generation", "publication_date": "2023-00-00", "reason": "This paper is important for its exploration of controlled image generation, a key aspect for evaluating the effectiveness of the techniques described in the current work."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-00-00", "reason": "This paper is highly influential due to its demonstration of the superiority of diffusion models over GANs in image generation, a key point of comparison in the current paper."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-00-00", "reason": "This paper is a significant contribution due to its focus on high-resolution image synthesis using diffusion transformers, which is directly addressed and improved upon in the current paper."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "Laion-5b: An open large-scale dataset for training next generation image-text models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant for providing a key dataset for training and evaluating large-scale image-text models, which is essential to the current work."}]}