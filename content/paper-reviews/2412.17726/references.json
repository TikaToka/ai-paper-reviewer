{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces the foundation for diffusion models, a key concept in the field of generative AI that the current paper builds upon."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces a high-resolution image synthesis method using latent diffusion models, which is highly relevant to the video generation task addressed in the current paper."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This paper shows how transformers can be used for high-resolution image synthesis, which is a crucial component used in the current paper's proposed model."}, {"fullname_first_author": "Diederik P Kingma", "paper_title": "Auto-encoding variational bayes", "publication_date": "2022-00-00", "reason": "This paper introduces variational autoencoders (VAEs), a fundamental concept in the current paper, and forms the basis for the video autoencoder architecture used."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2023-00-00", "reason": "This paper introduces the Transformer architecture, which is a crucial part of the current paper's model and a cornerstone of modern deep learning."}]}