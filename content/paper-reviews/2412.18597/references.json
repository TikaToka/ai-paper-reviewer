{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen Video: High definition video generation with diffusion models", "publication_date": "2022-10-02", "reason": "This paper is foundational to the current work as it introduces Imagen Video, a high-definition video generation model using diffusion models, which is the base architecture for DiTCtrl's multi-prompt video generation."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Scaling rectified flow transformers for high-resolution image synthesis", "publication_date": "2024-07-21", "reason": "This paper introduces the Multi-Modal Diffusion Transformer (MM-DiT) architecture, which DiTCtrl utilizes and analyzes to enable training-free multi-prompt video generation."}, {"fullname_first_author": "Mingdeng Cao", "paper_title": "MasaCtrl: Tuning-free mutual self-attention control for consistent image synthesis and editing", "publication_date": "2023-10-01", "reason": "This paper introduces the concept of attention control in diffusion models, which DiTCtrl adapts to enable precise semantic control across different prompts in video generation."}, {"fullname_first_author": "Amir Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2022-08-01", "reason": "This paper introduces the prompt-to-prompt image editing technique using cross-attention, a concept that DiTCtrl leverages and extends to the video domain for multi-prompt video generation."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter1: Open diffusion models for high-quality video generation", "publication_date": "2023-01-01", "reason": "This paper introduces Videocrafter, a high-quality video generation model using diffusion transformers, which serves as a baseline and comparison model for DiTCtrl's multi-prompt video generation capabilities."}]}