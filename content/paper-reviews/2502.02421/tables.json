[{"content": "| Method | Model(s) | AIM | HumanEval | MBPP | MMLU | MATH | GSM8K | IFEval | HV Gain |\n|---|---|---|---|---|---|---|---|---|---| \n| **Base Models** |  |  |  |  |  |  |  |  |  |\n| - | Base | - | 17.07 | 27.80 | 52.18 | 0.70 | 4.20 | 25.10 | - |\n| - | Code | - | 17.07 | 31.60 | 52.91 | 6.00 | 24.10 | 26.25 | - |\n| - | Instruction Tuned | - | 26.83 | 34.80 | 53.41 | 7.50 | 43.40 | 35.67 | - |\n| - | Math | - | 15.24 | 27.60 | 51.89 | 13.10 | 59.10 | 21.58 | - |\n| **Merged Models** |  |  |  |  |  |  |  |  |  |\n| DARE Task Arithmetic | Code + Instruction Tuned | No | 26.83 | 34.40 | 53.53 | 8.40 | 45.80 | 33.42 | 0.27 |\n|  |  | Yes | 29.27 (+9.09%) | 36.00 (+4.65%) | 54.18 (+1.21%) | 8.30 (-1.19%) | 46.20 (+0.87%) | 32.00 (-4.25%) | 0.28 (+2.49%) |\n| DARE Task Arithmetic | Code + Math | No | 16.46 | 28.60 | 51.96 | 15.10 | 64.70 | 22.02 | 0.23 |\n|  |  | Yes | 15.85 (-3.71%) | 29.60 (+3.50%) | 52.50 (+1.04%) | 14.80 (-1.99%) | 64.10 (-0.93%) | 21.91 (-0.50%) | 0.23 (-1.65%) |\n| DARE Task Arithmetic | Instruction Tuned + Math | No | 5.49 | 19.00 | 51.08 | 9.80 | 54.30 | 32.35 | 0.18 |\n|  |  | Yes | 12.20 (+122.22%) | 28.20 (+48.42%) | 52.72 (+3.21%) | 12.90 (+31.63%) | 62.20 (+14.55%) | 31.96 (-1.21%) | 0.26 (+40.71%) |\n| DARE Task Arithmetic | Code + Instruction Tuned + Math | No | 11.59 | 19.60 | 50.89 | 9.10 | 49.70 | 33.20 | 0.16 |\n|  |  | Yes | 15.85 (+36.76%) | 27.00 (+37.76%) | 52.59 (+3.34%) | 12.20 (+34.07%) | 60.70 (+22.13%) | 33.59 (+1.17%) | 0.23 (+40.59%) |\n| DARE Ties | Code + Instruction Tuned | No | 30.49 | 35.20 | 53.40 | 8.60 | 46.20 | 33.28 | 0.28 |\n|  |  | Yes | 30.49 | 36.80 (+4.55%) | 54.02 (+1.16%) | 8.60 | 47.20 (+2.16%) | 33.16 (-0.36%) | 0.29 (+1.63%) |\n| DARE Ties | Code + Math | No | 17.07 | 27.40 | 51.92 | 14.90 | 63.60 | 22.53 | 0.23 |\n|  |  | Yes | 17.68 (+3.57%) | 29.00 (+5.84%) | 52.61 (+1.33%) | 15.20 (+2.01%) | 63.90 (+0.47%) | 21.10 (-6.35%) | 0.24 (+4.00%) |\n| DARE Ties | Instruction Tuned + Math | No | 8.54 | 23.80 | 51.39 | 9.20 | 54.10 | 33.89 | 0.20 |\n|  |  | Yes | 15.85 (+85.60%) | 30.20 (+26.89%) | 52.89 (+2.92%) | 11.60 (+26.09%) | 57.80 (+6.84%) | 35.63 (+5.13%) | 0.26 (+31.22%) |\n| DARE Ties | Code + Instruction Tuned + Math | No | 13.41 | 21.20 | 51.15 | 8.70 | 51.50 | 35.75 | 0.17 |\n|  |  | Yes | 19.51 (+45.49%) | 28.60 (+34.91%) | 52.63 (+2.89%) | 11.60 (+33.33%) | 57.00 (+10.68%) | 36.20 (+1.26%) | 0.24 (+41.28%) |\n| Task Arithmetic | Code + Instruction Tuned | No | 29.27 | 33.80 | 53.44 | 8.60 | 47.10 | 31.60 | 0.28 |\n|  |  | Yes | 29.88 (+2.08%) | 35.80 (+5.92%) | 54.12 (+1.27%) | 7.80 (-9.30%) | 46.60 (-1.06%) | 32.01 (+1.30%) | 0.28 (+0.61%) |\n| Task Arithmetic | Code + Math | No | 18.29 | 28.60 | 52.10 | 15.00 | 64.70 | 21.92 | 0.24 |\n|  |  | Yes | 17.68 (-3.34%) | 29.20 (+2.10%) | 52.52 (+0.81%) | 14.60 (-2.67%) | 64.50 (-0.31%) | 21.54 (-1.73%) | 0.24 (-2.65%) |\n| Task Arithmetic | Instruction Tuned + Math | No | 4.27 | 20.20 | 51.50 | 10.00 | 54.20 | 31.31 | 0.18 |\n|  |  | Yes | 8.54 (+100.00%) | 26.40 (+30.69%) | 52.83 (+2.58%) | 12.80 (+28.00%) | 61.30 (+13.10%) | 32.62 (+4.18%) | 0.24 (+34.52%) |\n| Task Arithmetic | Code + Instruction Tuned + Math | No | 11.59 | 19.60 | 51.20 | 9.00 | 52.70 | 32.87 | 0.16 |\n|  |  | Yes | 15.24 (+31.49%) | 27.40 (+39.80%) | 52.63 (+2.79%) | 12.00 (+33.33%) | 58.10 (+10.25%) | 33.91 (+3.16%) | 0.22 (+31.97%) |\n| Ties Merging | Code + Instruction Tuned | No | 16.46 | 23.60 | 52.70 | 2.70 | 5.40 | 24.48 | 0.00 |\n|  |  | Yes | 15.24 (-7.41%) | 24.20 (+2.54%) | 53.15 (+0.85%) | 2.60 (-3.70%) | 5.20 (-3.70%) | 22.87 (-6.58%) | 0.05 (+inf%) |\n| Ties Merging | Code + Math | No | 15.85 | 26.80 | 51.86 | 14.30 | 62.60 | 21.63 | 0.20 |\n|  |  | Yes | 15.85 | 28.60 (+6.72%) | 52.29 (+0.83%) | 15.30 (+6.99%) | 63.80 (+1.92%) | 22.64 (+4.67%) | 0.23 (+13.55%) |\n| Ties Merging | Instruction Tuned + Math | No | 28.05 | 34.60 | 54.45 | 8.70 | 44.70 | 34.04 | 0.23 |\n|  |  | Yes | 27.44 (-2.17%) | 35.00 (+1.16%) | 54.74 (+0.53%) | 9.30 (+6.90%) | 46.10 (+3.13%) | 34.51 (+1.38%) | 0.25 (+6.38%) |\n| Ties Merging | Code + Instruction Tuned + Math | No | 21.34 | 29.20 | 53.97 | 6.30 | 29.20 | 26.95 | 0.11 |\n|  |  | Yes | 20.73 (-2.86%) | 29.20 | 54.46 (+0.91%) | 5.70 (-9.52%) | 23.70 (-18.84%) | 25.98 (-3.60%) | 0.11 (+4.33%) |\n| WIDEN | Code + Instruction Tuned | No | 26.22 | 35.60 | 54.90 | 8.30 | 45.00 | 30.42 | 0.27 |\n|  |  | Yes | 25.61 (-2.33%) | 34.60 (-2.81%) | 54.97 (+0.13%) | 8.20 (-1.20%) | 44.10 (-2.00%) | 31.60 (+3.88%) | 0.26 (-0.93%) |\n| WIDEN | Code + Math | No | 17.07 | 29.40 | 53.35 | 14.20 | 64.40 | 24.02 | 0.24 |\n|  |  | Yes | 17.07 | 29.60 (+0.68%) | 53.36 (+0.02%) | 14.30 (+0.70%) | 62.20 (-3.42%) | 23.95 (-0.29%) | 0.24 (-1.22%) |\n| WIDEN | Instruction Tuned + Math | No | 24.39 | 30.40 | 54.20 | 14.60 | 66.00 | 30.82 | 0.30 |\n|  |  | Yes | 23.78 (-2.50%) | 32.00 (+5.26%) | 54.69 (+0.90%) | 15.10 (+3.42%) | 68.20 (+3.33%) | 31.23 (+1.33%) | 0.31 (+2.54%) |\n| WIDEN | Code + Instruction Tuned + Math | No | 25.00 | 33.20 | 54.58 | 13.50 | 64.20 | 31.44 | 0.29 |\n|  |  | Yes | 26.83 (+7.32%) | 32.80 (-1.20%) | 54.98 (+0.73%) | 14.40 (+6.67%) | 64.00 (-0.31%) | 32.82 (+4.39%) | 0.30 (+4.70%) |", "caption": "Table 1: \nBenchmark Results Across Various Merging Scenarios and Methods. Percentage changes are shown relative to models merged without AIM, with these differences highlighted for each metric. The highest-performing fine-tuned large language models and base models are highlighted in yellow, while the best-performing merged models are marked in blue. The results demonstrate that, in most cases, applying AIM significantly enhances the performance of merged models across all benchmarks, often increasing HV Gain.", "description": "\ud45c 1\uc740 \ub2e4\uc591\ud55c \ubaa8\ub378 \ubcd1\ud569 \uc2dc\ub098\ub9ac\uc624\uc640 \ubc29\ubc95\uc5d0 \ub530\ub978 \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  AIM(Activation-Informed Merging)\uc744 \uc801\uc6a9\ud558\uc9c0 \uc54a\uc740 \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec \ubc31\ubd84\uc728 \ubcc0\ud654\ub97c \uac15\uc870\ud558\uc5ec \uac01 \uc9c0\ud45c\uc5d0 \ub300\ud55c \uc0c1\ub300\uc801 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ucd5c\uace0 \uc131\ub2a5\uc758 \ubbf8\uc138 \uc870\uc815\ub41c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378\uacfc \uae30\ubcf8 \ubaa8\ub378\uc740 \ub178\ub780\uc0c9\uc73c\ub85c \uac15\uc870 \ud45c\uc2dc\ub418\uace0, \ucd5c\uace0 \uc131\ub2a5\uc758 \ubcd1\ud569 \ubaa8\ub378\uc740 \ud30c\ub780\uc0c9\uc73c\ub85c \ud45c\uc2dc\ub429\ub2c8\ub2e4.  \uacb0\uacfc\ub294 AIM\uc744 \uc801\uc6a9\ud558\uba74 \ub300\ubd80\ubd84\uc758 \uacbd\uc6b0 \ubaa8\ub4e0 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ubcd1\ud569 \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \ud06c\uac8c \ud5a5\uc0c1\ub418\uace0, \uc885\uc885 HV Gain\uc774 \uc99d\uac00\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uc124\uc815 \ubc0f \ud3c9\uac00 \uc9c0\ud45c"}, {"content": "| Method | \u03c9 | HumanEval | MBPP | MMLU | MATH | GSM8K | IFEval | HV Gain |\n|---|---|---|---|---|---|---|---|---|\n| Ties Merging | 0.0 | 19.51 | 29.0 | 54.32 | 4.6 | 17.6 | 26.24 | 0.1015 |\n|  | 0.2 | 19.51 | 28.6 | 54.35 | 5.3 | 21.2 | 25.37 | 0.1069 |\n|  | 0.4 | 20.73 | 29.2 | 54.46 | 5.7 | 23.7 | 25.98 | 0.1143 |\n|  | 0.6 | 20.12 | 27.8 | 54.25 | 6.6 | 32.1 | 23.9 | 0.1155 |\n|  | 0.8 | 20.73 | 27.8 | 54.09 | 6.6 | 33.7 | 24.07 | 0.1131 |\n|  | 1.0 | 21.34 | 29.2 | 53.97 | 6.3 | 29.2 | 26.95 | 0.1096 |\n| DARE Task Arithmetic | 0.0 | 18.90 | 29.4 | 53.42 | 13.8 | 60.5 | 35.49 | 0.2623 |\n|  | 0.2 | 16.46 | 29.0 | 52.98 | 12.9 | 61.5 | 34.97 | 0.2434 |\n|  | 0.4 | 15.85 | 27.0 | 52.59 | 12.2 | 60.7 | 33.67 | 0.2257 |\n|  | 0.6 | 15.24 | 27.0 | 52.18 | 11.8 | 58.1 | 33.95 | 0.2142 |\n|  | 0.8 | 14.02 | 22.2 | 51.53 | 9.9 | 54.0 | 32.69 | 0.1828 |\n|  | 1.0 | 11.59 | 19.6 | 50.89 | 9.1 | 49.7 | 33.2 | 0.1604 |\n| DARE Ties | 0.0 | 25.61 | 29.6 | 53.31 | 12.0 | 59.4 | 34.64 | 0.2669 |\n|  | 0.2 | 21.34 | 29.4 | 53.11 | 12.1 | 58.7 | 36.76 | 0.2590 |\n|  | 0.4 | 19.51 | 28.6 | 52.63 | 11.6 | 57.0 | 36.2 | 0.2426 |\n|  | 0.6 | 15.85 | 26.0 | 52.22 | 10.1 | 54.2 | 34.82 | 0.2019 |\n|  | 0.8 | 14.02 | 24.0 | 51.6 | 10.0 | 53.1 | 35.51 | 0.1917 |\n|  | 1.0 | 13.41 | 21.2 | 51.15 | 8.7 | 51.5 | 35.75 | 0.1717 |\n| Task Arithmetic | 0.0 | 18.90 | 29.4 | 53.42 | 13.8 | 60.5 | 35.49 | 0.2623 |\n|  | 0.2 | 15.24 | 27.6 | 52.97 | 13.0 | 59.8 | 35.27 | 0.2296 |\n|  | 0.4 | 15.24 | 27.4 | 52.63 | 12.0 | 58.1 | 33.88 | 0.2165 |\n|  | 0.6 | 15.24 | 25.4 | 52.13 | 11.4 | 57.4 | 33.29 | 0.2069 |\n|  | 0.8 | 13.41 | 21.8 | 51.61 | 10.2 | 56.2 | 32.74 | 0.1862 |\n|  | 1.0 | 11.59 | 19.6 | 51.20 | 9.0 | 52.7 | 32.95 | 0.1643 |\n| WIDEN | 0.0 | 27.44 | 33.2 | 55.26 | 14.0 | 64.9 | 32.39 | 0.3027 |\n|  | 0.2 | 28.05 | 33.0 | 55.16 | 14.2 | 65.6 | 32.39 | 0.3066 |\n|  | 0.4 | 26.83 | 32.8 | 54.98 | 14.4 | 64.0 | 32.76 | 0.3013 |\n|  | 0.6 | 25.61 | 33.4 | 54.77 | 14.2 | 63.0 | 32.06 | 0.2947 |\n|  | 0.8 | 26.22 | 32.6 | 54.64 | 14.0 | 64.1 | 31.74 | 0.2941 |\n|  | 1.0 | 25.00 | 33.2 | 54.58 | 13.5 | 64.2 | 31.44 | 0.2879 |", "caption": "Table 2: Performance metrics for different methods with varying \u03c9\ud835\udf14\\omegaitalic_\u03c9 values.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \u03c9 \uac12\uc744 \uc0ac\uc6a9\ud558\ub294 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378 \ubcd1\ud569 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc131\ub2a5 \uc9c0\ud45c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ubc29\ubc95\uc5d0 \ub300\ud574 \ub2e4\uc591\ud55c \u03c9 \uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec HumanEval, MBPP, MMLU, MATH, GSM8K, IFEval \ubc0f HV Gain \ub4f1 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 AIM \uc54c\uace0\ub9ac\uc998\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\uc778 \u03c9 \uac12\uc758 \ubcc0\ud654\uc5d0 \ub530\ub77c \ubaa8\ub378 \ubcd1\ud569 \uc131\ub2a5\uc774 \uc5b4\ub5bb\uac8c \ub2ec\ub77c\uc9c0\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uc138\ubd80\uc801\uc778 \ubd84\uc11d \uacb0\uacfc\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5.2 Ablation study"}]