<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>🏢 Tencent AI Lab on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-tencent-ai-lab/</link><description>Recent content in 🏢 Tencent AI Lab on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2025 AI Paper Reviews by AI</copyright><lastBuildDate>Mon, 30 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-tencent-ai-lab/index.xml" rel="self" type="application/rss+xml"/><item><title>Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21187/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21187/</guid><description>대규모 언어 모델의 과도한 연산 문제 해결: 효율적인 추론을 위한 새로운 지표 및 자기 학습 전략 제시</description></item><item><title>HUNYUANPROVER: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/</guid><description>HunyuanProver: 대규모 언어 모델 기반의 확장 가능한 데이터 합성 프레임워크와 안내 트리 탐색을 통해 최첨단 자동 정리 증명 성능 달성!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/cover.png"/></item><item><title>VideoMaker: Zero-shot Customized Video Generation with the Inherent Force of Video Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/</guid><description>VideoMaker: 영상 확산 모델의 고유한 힘을 이용한 제로샷 맞춤형 영상 생성</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/cover.png"/></item><item><title>DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</guid><description>DiTCtrl: 튜닝 없이 다중 프롬프트로 매끄러운 장시간 비디오 생성</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/cover.png"/></item><item><title>DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</guid><description>DRT-01 모델은 장문의 사고 과정을 활용하여 문학 번역의 정확도와 유창성을 크게 향상시켰습니다.</description></item></channel></rss>