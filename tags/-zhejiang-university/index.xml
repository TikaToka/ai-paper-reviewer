<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>🏢 Zhejiang University on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/tags/-zhejiang-university/</link><description>Recent content in 🏢 Zhejiang University on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2025 AI Paper Reviews by AI</copyright><lastBuildDate>Tue, 31 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/tags/-zhejiang-university/index.xml" rel="self" type="application/rss+xml"/><item><title>VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/</guid><description>VideoRefer Suite는 &lt;strong>정교한 공간-시간적 개체 이해를 위한 새로운 비디오 LLM(VideoRefer)과 대규모 고품질 데이터셋(VideoRefer-700K), 종합적인 벤치마크(VideoRefer-Bench)를 제시&lt;/strong>합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/cover.png"/></item><item><title>OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/</link><pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/</guid><description>OneKE: 도커 기반, 다중 에이전트 LLM 지식 추출 시스템으로 웹, PDF에서 다양한 도메인 지식 추출 가능</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/cover.png"/></item><item><title>Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/</guid><description>단일 이미지에서 객체 방향 추정의 정확도를 크게 높이는 &amp;lsquo;Orient Anything&amp;rsquo; 모델 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/cover.png"/></item><item><title>Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</guid><description>저렴한 라이다 프롬프트를 사용한 4K 고해상도 정확한 계량적 깊이 추정을 위한 새로운 패러다임, Prompt Depth Anything 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/cover.png"/></item></channel></rss>