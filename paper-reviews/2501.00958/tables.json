[{"content": "| Dataset | #Image |  |  | #Text Token |  |  | *L*=4 | *L*=5 | *L*=6 | *L*=7 | *L*=8 | Avg. | Source |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| Min. | Max. | Avg. | Min. | Max. | Avg. |  |  |  |  |  |  |  |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| *Image-text Paired Dataset* |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| COYO-700M | 1 | 1 | 1 | 1 | 811 | 16 | - | - | - | - | - | - | Common Crawl |\n| LAION-5B | 1 | 1 | 1 | 6 | 683 | 27 | - | - | - | - | - | - | Common Crawl |\n| *Image-text Interleaved Dataset* |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| MMC4 | 0 | 117 | 5.7 | 4 | 16715 | 417 | 0.363 | 0.348 | 0.310 | 0.298 | 0.276 | 0.319 | Common Crawl |\n| MMC4-core-ff | 0 | 15 | 4.1 | 15 | 16715 | 329 | 0.431 | 0.406 | 0.404 | 0.403 | 0.396 | 0.407 | Common Crawl |\n| OBELICS | 1 | 30 | 2.5 | 12 | 10717 | 816 | 0.366 | 0.351 | 0.339 | 0.337 | 0.336 | 0.345 | Common Crawl |\n| OmniCorpus* | 1 | 16 | 3.9 | 14 | 6893 | 574 | 0.358 | 0.329 | 0.310 | 0.305 | 0.301 | 0.321 | Multi-sources |\n| **Ours** | **2** | **45** | **10.7** | **11** | **34174** | **1297** | **0.687** | **0.697** | **0.698** | **0.688** | **0.662** | **0.686** | Video Website |", "caption": "Table 1: We compare our multimodal textbook with image-text paired datasets and webpage-centric interleaved datasets in terms of image and text distributions. In-sample Image SIMLsuperscriptSIM\ud835\udc3f\\text{SIM}^{L}SIM start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT measures the semantic and structural correlation between multiple images within an interleaved sample. OmniCorpus\u2217superscriptOmniCorpus\\text{OmniCorpus}^{*}OmniCorpus start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT: Due to the extensive size of the dataset, we perform statistical analysis on a randomly sampled subset.", "description": "\ud45c 1\uc740 \uc81c\uc2dc\ub41c \ub17c\ubb38\uc5d0\uc11c \ub2e4\ub8e8\ub294 \ub2e4\uc911 \ubaa8\ub4dc \uad50\uacfc\uc11c \ub370\uc774\ud130\uc14b\uc744 \uae30\uc874\uc758 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \uc30d \ub370\uc774\ud130\uc14b \ubc0f \uc6f9 \ud398\uc774\uc9c0 \uc911\uc2ec\uc758 \ud63c\ud569 \ub370\uc774\ud130\uc14b\uacfc \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc774\ubbf8\uc9c0\uc640 \ud14d\uc2a4\ud2b8\uc758 \ubd84\ud3ec \uce21\uba74\uc5d0\uc11c \ube44\uad50 \ubd84\uc11d\ud558\uba70, \ud2b9\ud788 \ud63c\ud569 \uc0d8\ud50c \ub0b4 \uc5ec\ub7ec \uc774\ubbf8\uc9c0 \uac04\uc758 \uc758\ubbf8 \ubc0f \uad6c\uc870\uc801 \uc0c1\uad00\uad00\uacc4\ub97c \uce21\uc815\ud558\ub294 \uc9c0\ud45c\uc778 In-sample Image SIML(SIML\uc740 \uc774\ubbf8\uc9c0 \uc218\ub97c \ub098\ud0c0\ub0b4\ub294 \uc0c1\uc218)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \ubcf4\ub2e4 \uc790\uc138\ud558\uac8c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4. OmniCorpus \ub370\uc774\ud130\uc14b\uc758 \uacbd\uc6b0 \ub370\uc774\ud130\uc14b \ud06c\uae30\uac00 \ub9e4\uc6b0 \ud06c\uae30 \ub54c\ubb38\uc5d0 \ubb34\uc791\uc704\ub85c \uc0d8\ud50c\ub9c1\ub41c \ud558\uc704 \uc9d1\ud569\uc5d0 \ub300\ud55c \ud1b5\uacc4 \ubd84\uc11d \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uc694\uc57d\ud558\uc790\uba74, \ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ub2e4\uc911 \ubaa8\ub4dc \ub370\uc774\ud130\uc14b\ub4e4\uc758 \uc774\ubbf8\uc9c0-\ud14d\uc2a4\ud2b8 \ubd84\ud3ec \ubc0f \uc774\ubbf8\uc9c0 \uac04\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50 \ubd84\uc11d\ud558\uc5ec \uc81c\uc548\ub41c \ub2e4\uc911 \ubaa8\ub4dc \uad50\uacfc\uc11c \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uacfc \uc6b0\uc218\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Analysis of Multimodal Textbook"}, {"content": "| #Shot | 0 | 1 | 2 | 4 | 0 | 1 | 2 | 4 | 0 | 1 | 2 | 4 | 0 | 1 | 2 | 4 |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| **Dataset** | ScienceQA<sup>IMG</sup> |  |  |  | OKVQA |  |  |  | TextVQA |  |  |  | TextVQA<sup>ocr</sup> |  |  |  |\n| MMC4 | - | 1.6 | 3.9 | 11.6 | 8.6 | 23.6 | 21.5 | 28.7 | 12.1 | 16.2 | 16.8 | 20.9 | 14.5 | 23.9 | 29.9 | 34.7 |\n| MMC4-Core-ff | - | 2.1 | 10.1 | 10.2 | 11.8 | 21.2 | 25.3 | 30.4 | 13.6 | 18.7 | 18.8 | 22.1 | 16.1 | 26.6 | 28.7 | 33.1 |\n| OBELICS | - | 2.8 | 3.0 | 16.4 | 13.0 | 31.7 | 35.7 | 37.5 | 9.2 | 26.5 | 30.2 | 32.2 | 11 | 30.7 | 36.3 | 41 |\n| **Textbook-6.5M** | 26.3 | 29.4 | 25.1 | 37.3 | 10.2 | 31.2 | 36.8 | 39.9 | 11.8 | 26.7 | 32.1 | 33.5 | 14.1 | 33.1 | 36.4 | 42.8 |\n| **Dataset** | MathVista |  |  |  | MathVision |  |  |  | MathVerse |  |  |  | Avg. |  |  |  |\n| MMC4 | 20.4 | 30 | 27.9 | 26 | 12.2 | 21.3 | 15.5 | 16.1 | 8.6 | 19.4 | 21.2 | 15.9 | 10.9 | 19.4 | 19.5 | 21.9 |\n| MMC4-Core-ff | 22.5 | 33.0 | 29.2 | 27.8 | 13.7 | 23.4 | 16.3 | 17.7 | 8.6 | 19.9 | 21.8 | 15.2 | 12.3 | 20.7 | 21.4 | 22.3 |\n| OBELICS | 21.6 | 28.5 | 31.1 | 27.6 | 13.4 | 20.1 | 16.8 | 14.9 | 6.9 | 19.4 | 20.7 | 14 | 10.7 | 22.8 | 24.8 | 26.2 |\n| **Textbook-6.5M** | 24.3 | 43.4 | 33.2 | 29.2 | 14.5 | 25.6 | 18.2 | 18.1 | 7.7 | 28.5 | 19.8 | 14.6 | 15.5 | 31.1 | 28.8 | 30.8 |", "caption": "Table 2: We continued pre-training the base model of LLaVA-1.5-7B using different interleaved datasets. The results are evaluated on 4 common VQA and 3 math-related benchmarks under few-shot settings.", "description": "\ud45c 2\ub294 \ub2e4\uc591\ud55c \uc0bd\uc785\ud615 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud558\uc5ec LLaVA-1.5-7B \uae30\ubcf8 \ubaa8\ub378\uc744 \ucd94\uac00\ub85c \uc0ac\uc804 \ud6c8\ub828\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc131\ub2a5 \ud3c9\uac00\ub294 4\uac00\uc9c0 \uc77c\ubc18\uc801\uc778 VQA \ubca4\uce58\ub9c8\ud06c\uc640 3\uac00\uc9c0 \uc218\ud559 \uad00\ub828 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uba87 \ubc88\uc758 \uc2dc\ub3c4\ub9cc\uc73c\ub85c \uc218\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \uac01 \ub370\uc774\ud130\uc14b\uc73c\ub85c \uc0ac\uc804 \ud6c8\ub828\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 0-shot, 1-shot, 2-shot, 4-shot \uc124\uc815\uc5d0\uc11c \ube44\uad50\ud558\uc5ec, \ub2e4\uc591\ud55c \uc0bd\uc785\ud615 \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud55c \uc0ac\uc804 \ud6c8\ub828\uc774 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "|                       | OKVQA | TextVQA | MathVista | MathVison | MathVerse | OKVQA | TextVQA | MathVista | MathVison | MathVerse |\n|-----------------------|-------|---------|-----------|-----------|----------|-------|---------|-----------|-----------|----------|\n| **Continual Pre-training from Idefics2-8B-base** |       |         |           |           |          |       |         |           |           |          |\n| Dataset                 |       |         |           |           |          |       |         |           |           |          |\n| MMC4-cf                 | 54.1  | 57.7    | 27.8      | 14.0      | 17.3     | 9.4   | 25.1    | 24        | 13.3      | 18.3     |\n| OBELICS                 | 54.6  | 57.5    | 27.6      | 14.3      | 17.5     | 10.5  | 25.7    | 24.2      | 13.6      | 17.7     |\n| Textbook-6.5M          | 55.1  | 58.2    | 29.7      | 16.2      | 19.4     | 10.1  | 26.8    | 26.1      | 14.4      | 19.8     |\n| **Pre-training Idefics2-8B from scratch** |       |         |           |           |          |       |         |           |           |          |", "caption": "Table 3: Except for LLaVA, we also pre-train advanced VLMs with multi-image ability (Idefics): continual pretraining from Idefics-8B-base or pre-training from scratch. The evaluations are extended to an 8-shot using randomly selected examples as previous works\u00a0[16].", "description": "\ud45c 3\uc740 LLaVA \ubaa8\ub378 \uc678\uc5d0\ub3c4, \ub2e4\uc911 \uc774\ubbf8\uc9c0 \ucc98\ub9ac \ub2a5\ub825\uc744 \uac16\ucd98 \uace0\uae09 VLM\uc778 Idefics \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Idefics-8B \uae30\ubc18 \ubaa8\ub378\uc744 \uc9c0\uc18d\uc801\uc73c\ub85c \ud559\uc2b5\uc2dc\ud0a4\uac70\ub098 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\uc2dc\ud0a4\ub294 \ub450 \uac00\uc9c0 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uae30\uc874 \uc5f0\uad6c[16]\ub97c \ubc14\ud0d5\uc73c\ub85c \ud3c9\uac00\ub294 8-shot \uc124\uc815\uc73c\ub85c \ud655\uc7a5\ub418\uc5c8\uc73c\uba70, \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ub41c \uc608\uc2dc\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\ub294 TextVQA, OKVQA, MathVista, MathVision, MathVerse\uc640 \uac19\uc740 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc720\uc6a9\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Dataset | OKVQA | TextVQA | Mathvista | Mathvision | Mathverse |\n|---|---|---|---|---|---| \n| *1-shot Cheat: Example:* {$I_t$, $q_t$, $a_t$} + Test-case: $I_t$, $q_t$ |  |  |  |  |  |\n| MMC4-cf | 69.0 | 41.0 | 72.6 | 69.3 | 55.7 |\n| OBELICS | 71.5 | 43.8 | 67.7 | 66.5 | 62.8 |\n| Ours | **79.2** | **51.9** | **94.1** | **98.4** | **76.8** |\n| *2-shot Cheat: Example:* {$I_t$, $q_t$, $a_t$}, {$I_e$, $q_e$, $a_e$} + Test-case: $I_t$, $q_t$|  |  |  |  |  |\n| MMC4-Cf | 53.5 | 39.2 | 55.7 | 51.9 | 40.8 |\n| OBELICS | 71.3 | 42.8 | 56.7 | 39.9 | 39.5 |\n| Ours | **84.3** | **49.4** | **77.1** | **70.7** | **63.1** |", "caption": "Table 4: We design \u201cCheat Test\u201d to observe whether VLMs can attend to their interleaved context. We replace a few-shot example with the test sample itself and observe whether VLM notice this identical <<<image,question,answer>>> within their prompt. Itsubscript\ud835\udc3c\ud835\udc61I_{t}italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, qtsubscript\ud835\udc5e\ud835\udc61q_{t}italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, atsubscript\ud835\udc4e\ud835\udc61a_{t}italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denote the test case, Iesubscript\ud835\udc3c\ud835\udc52I_{e}italic_I start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT, qesubscript\ud835\udc5e\ud835\udc52q_{e}italic_q start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT, aesubscript\ud835\udc4e\ud835\udc52a_{e}italic_a start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT denote a random selected example.", "description": "\ud45c 4\ub294 VLMs\uc774 \ubb38\ub9e5 \ub0b4 \uc815\ubcf4\ub97c \uc5bc\ub9c8\ub098 \uc798 \ud65c\uc6a9\ud558\ub294\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud55c \"\uc18d\uc784\uc218 \ud14c\uc2a4\ud2b8\" \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud14c\uc2a4\ud2b8\ub294 \uae30\uc874\uc758 \uba87\uba87 \uc0f7 \uc608\uc81c \uc911 \ud558\ub098\ub97c \ud14c\uc2a4\ud2b8 \uc0d8\ud50c \uc790\uccb4\ub85c \ubc14\uafd4\uc11c \uc9c4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  VLMs\uc774 \ub3d9\uc77c\ud55c \uc774\ubbf8\uc9c0, \uc9c8\ubb38, \ub2f5\ubcc0\uc774 \uc774\ubbf8 \ubb38\ub9e5 \ub0b4\uc5d0 \uc874\uc7ac\ud558\ub294 \uac83\uc744 \uc778\uc2dd\ud558\uace0 \uc27d\uac8c \ub2f5\ubcc0\ud558\ub294\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4.  I<sub>t</sub>, q<sub>t</sub>, a<sub>t</sub>\ub294 \ud14c\uc2a4\ud2b8 \ucf00\uc774\uc2a4\ub97c \ub098\ud0c0\ub0b4\uace0, I<sub>e</sub>, q<sub>e</sub>, a<sub>e</sub>\ub294 \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ub41c \uc608\uc81c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc989, \ud14c\uc2a4\ud2b8 \uc0d8\ud50c\uacfc \ub3d9\uc77c\ud55c \uc608\uc81c\uac00 \uba87\uba87 \uc0f7 \uc608\uc81c\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \uc0c1\ud669\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud3c9\uac00\ud55c \uac83\uc785\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc \ubd84\uc11d"}, {"content": "| Pretraining | Continual Pretraining | SFT | OKVQA | MathVista |\n|---|---|---|---|---|\n| \u2713 | - | \u2713 | 61.1 | 23.2 |\n| \u2713 | MMC4-Core-ff | \u2713 | 61.5 \u21910.4 | 24.8 \u21911.6 |\n| \u2713 | OBELICS | \u2713 | 61.8 \u21910.7 | 25.6 \u21912.4 |\n| \u2713 | Textbook-6.5M | \u2713 | **62.2 \u21911.1** | **28.7 \u21915.5** |", "caption": "Table 5: We also evaluated the zero-shot result after instruction fine-tuning using the 665K data from LLaVA-1.5.", "description": "\ud45c 5\ub294 LLaVA-1.5\uc758 665K \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec instruction fine-tuning \ud6c4 zero-shot \uacb0\uacfc\ub97c \ud3c9\uac00\ud55c \uac83\uc785\ub2c8\ub2e4.  LLaVA-1.5 \ubaa8\ub378\uc5d0 \ub300\ud574 MMC4-Core-ff, OBELICS, \uadf8\ub9ac\uace0 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 Multimodal Textbook \ub370\uc774\ud130\uc14b\uc73c\ub85c \uc0ac\uc804 \ud559\uc2b5 \ud6c4 instruction fine-tuning\uc744 \uc9c4\ud589\ud55c zero-shot \uc131\ub2a5\uc744 OKVQA\uc640 MathVista \uc9c0\ud45c\ub97c \ud1b5\ud574 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  \uac01 \ub370\uc774\ud130\uc14b\uc758 zero-shot \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uba70, Multimodal Textbook \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c \uc131\ub2a5 \ud5a5\uc0c1\uc774 \ub208\uc5d0 \ub744\uac8c \ub098\ud0c0\ub0a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8"}, {"content": "| Dataset | Perplexity \u2193 | 1-shot Acc. |\n|---|---|---|\n| MMC4-Core-ff | 12.56 | 20.7 |\n| OBELICS | 11.27 | 22.8 |\n| Ours (ASR Refine, OCR, SSIM) | 13.92 | 31.1 |\n| - w/o ASR Refine | 16.86 | 26.2 (\u21934.9) |\n| - w/o OCR | 12.7 | 28.8 (\u21932.3) |\n| Keyframe Extraction algorithms | #Keyframe | 1-shot Acc. |\n| - SSIM\u2192Pixel-level extractor | 6.5M \u2192 18M | 22.1 (\u21939) |\n| - SSIM\u2192CLIP-based extractor | 6.5M \u2192 1.7M | 24.6 (\u21936.5) |", "caption": "Table 6: We perform an ablation study on video-to-textbook pipeline, including the impact of ASR refinement, the necessity of incorporating OCR, and the algorithms for extracting keyframes.", "description": "\ud45c 6\uc740 \ube44\ub514\uc624-\uad50\uc7ac \ud30c\uc774\ud504\ub77c\uc778\uc5d0 \ub300\ud55c ablation \uc5f0\uad6c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. ASR \uac1c\uc120\uc758 \uc601\ud5a5, OCR \ud1b5\ud569\uc758 \ud544\uc694\uc131, \uadf8\ub9ac\uace0 \ud0a4\ud504\ub808\uc784 \ucd94\ucd9c \uc54c\uace0\ub9ac\uc998\uc758 \ube44\uad50\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.  \uad6c\uccb4\uc801\uc73c\ub85c, ASR \uac1c\uc120\uc744 \ud558\uc9c0 \uc54a\uc558\uc744 \ub54c, OCR\uc744 \ud1b5\ud569\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c, \uadf8\ub9ac\uace0 \uc11c\ub85c \ub2e4\ub978 \ud0a4\ud504\ub808\uc784 \ucd94\ucd9c \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \uc815\ub7c9\uc801\uc73c\ub85c \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uc774\ub294 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ub300\ud55c \uac01 \uad6c\uc131 \uc694\uc18c\uc758 \uae30\uc5ec\ub3c4\ub97c \ud30c\uc545\ud558\uace0, \ube44\ub514\uc624-\uad50\uc7ac \ud30c\uc774\ud504\ub77c\uc778\uc758 \ucd5c\uc801\ud654 \ubc29\ud5a5\uc744 \uc81c\uc2dc\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "5.4. Ablation of Video-to-Textbook\u2019s Design"}, {"content": "| Subject | #Video | Duration (h) | #Topic | #Video Clip | #Keyframe | #ASR Token | #OCR Token | #Sample |\n|---|---|---|---|---|---|---|---|---|\n| Mathematics | 21.7k | 4,423 | 725 | 809k | 1.67M | 72.5M | 145M | 123k |\n| Physics | 11k | 3,511 | 530 | 822k | 0.95M | 36.7M | 73.4M | 119k |\n| Chemistry | 4.5k | 2,643 | 410 | 234k | 0.49M | 15M | 30M | 32k |\n| Earth Science | 12k | 3,670 | 520 | 640k | 1.03M | 40M | 80M | 88k |\n| Engineering | 13k | 4,096 | 810 | 713k | 1.15M | 43.3M | 86.6M | 98k |\n| Computer Science | 12.8k | 4,354 | 820 | 782k | 1.21M | 42.8M | 85.5M | 150k |\n| **All** | **75k** | **22,697** | **3,915** | **4M** | **6.58M** | **258M** | **500M** | **610k** |", "caption": "Table 7: The statistics of our multimodal textbook. Topic denotes the knowledge points covered by each category of videos, which are sourced from our knowledge taxonomy.", "description": "\ud45c 7\uc740 \uc81c\uc2dc\ub41c \ub17c\ubb38\uc758 \ub2e4\uc911 \ubaa8\ub4dc \uad50\uacfc\uc11c \ud1b5\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ube44\ub514\uc624 \ubc94\uc8fc\uc5d0 \ud3ec\ud568\ub41c \uc9c0\uc2dd \ud3ec\uc778\ud2b8\uc758 \uc218\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc911 \ubaa8\ub4dc \uad50\uacfc\uc11c\uc758 \uaddc\ubaa8\uc640 \ub2e4\uc591\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4. \uac01 \uc5f4\uc740 \ube44\ub514\uc624 \uc218, \ube44\ub514\uc624\uc758 \ucd1d \uc9c0\uc18d \uc2dc\uac04, \uc8fc\uc81c \uc218, \ube44\ub514\uc624 \ud074\ub9bd \uc218, \ud0a4\ud504\ub808\uc784 \uc218, ASR \ud1a0\ud070 \uc218, OCR \ud1a0\ud070 \uc218, \uc0d8\ud50c \uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uac01 \ud589\uc740 \uc218\ud559, \ubb3c\ub9ac, \ud654\ud559, \uc9c0\uad6c \uacfc\ud559, \uacf5\ud559, \ucef4\ud4e8\ud130 \uacfc\ud559\uc758 6\uac00\uc9c0 \uc8fc\uc81c\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4. Analysis of Multimodal Textbook"}]