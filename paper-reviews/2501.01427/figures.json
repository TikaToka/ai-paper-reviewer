[{"figure_path": "https://arxiv.org/html/2501.01427/x2.png", "caption": "Figure 1: \nDemonstrations for video object insertion.\nVideoAnydoor preserves the fine-grained object details and enables users to control the motion with boxes or point trajectories.\nBased on the robust insertion, users could further add multiple objects iteratively or swap objects in the same video.\nCompared with the previous works, VideoAnydoor demonstrates significant superiority.", "description": "\ubcf8 \uadf8\ub9bc\uc740 VideoAnydoor\uc758 \ube44\ub514\uc624 \uac1d\uccb4 \uc0bd\uc785 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uae30\uc874 \ubc29\ubc95\ub4e4\uacfc \ub2ec\ub9ac VideoAnydoor\ub294 \uac1d\uccb4\uc758 \uc138\uc138\ud55c \ubd80\ubd84\uae4c\uc9c0 \ubcf4\uc874\ud558\uba74\uc11c, \uc0ac\uc6a9\uc790\uac00 \ubc15\uc2a4\ub098 \uc810 \uada4\uc801\uc744 \uc774\uc6a9\ud558\uc5ec \uac1d\uccb4\uc758 \uc6c0\uc9c1\uc784\uc744 \uc815\ubc00\ud558\uac8c \uc81c\uc5b4\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4. \ub610\ud55c, VideoAnydoor\ub294 \uc5ec\ub7ec \uac1d\uccb4\ub97c \ubc18\ubcf5\uc801\uc73c\ub85c \ucd94\uac00\ud558\uac70\ub098 \ub3d9\uc77c\ud55c \ube44\ub514\uc624 \ub0b4\uc5d0\uc11c \uac1d\uccb4\ub97c \ubc14\uafd4\uce58\uae30 \ud560 \uc218 \uc788\uc744 \ub9cc\ud07c \uac15\ub825\ud55c \uc0bd\uc785 \uae30\ub2a5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uae30\uc874 \uc5f0\uad6c\ub4e4\uacfc \ube44\uad50\ud588\uc744 \ub54c VideoAnydoor\uac00 \ud6e8\uc52c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2501.01427/x3.png", "caption": "Figure 2: \nThe pipelines of our VideoAnydoor. First, we input the concatenation of the original video, object masks, and masked video into the 3D U-Net. Meanwhile, the background-removed reference image is fed into the ID extractor, and the obtained features are injected into the 3D U-Net. In our pixel warper, the reference image marked with key points and the trajectories are utilized as inputs for the content and motion encoders. Then, the extracted embeddings are input into cross-attentions for further fusion. The fused results serve as the input of a ControlNet, which extracts multi-scale features for fine-grained injection of motion and identity. The framework is trained with reweight reconstruction losses. We use a blend of real videos and image-simulated videos for training to compensate for the data scarcity.", "description": "\uadf8\ub9bc 2\ub294 VideoAnydoor\uc758 \uad6c\uc870\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc6d0\ubcf8 \ube44\ub514\uc624, \uac1d\uccb4 \ub9c8\uc2a4\ud06c, \ub9c8\uc2a4\ud06c\ub41c \ube44\ub514\uc624\uc758 \uacb0\ud569\uc774 3D U-Net\uc5d0 \uc785\ub825\ub429\ub2c8\ub2e4. \ub3d9\uc2dc\uc5d0 \ubc30\uacbd\uc774 \uc81c\uac70\ub41c \ucc38\uc870 \uc774\ubbf8\uc9c0\ub294 ID \ucd94\ucd9c\uae30\uc5d0 \uc785\ub825\ub418\uace0, \uc5bb\uc5b4\uc9c4 \ud2b9\uc9d5\ub4e4\uc740 3D U-Net\uc5d0 \uc8fc\uc785\ub429\ub2c8\ub2e4. \ud53d\uc140 \uc6cc\ud37c\uc5d0\uc11c\ub294 \ud0a4\ud3ec\uc778\ud2b8\uc640 \uada4\uc801\uc774 \ud45c\uc2dc\ub41c \ucc38\uc870 \uc774\ubbf8\uc9c0\uac00 \ub0b4\uc6a9\uacfc \ub3d9\uc791 \uc778\ucf54\ub354\uc758 \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \ucd94\ucd9c\ub41c \uc784\ubca0\ub529\uc740 \uad50\ucc28 \uc5b4\ud150\uc158\uc744 \ud1b5\ud574 \ucd94\uac00\uc801\uc778 \uc735\ud569\uc744 \uac70\uce69\ub2c8\ub2e4. \uc735\ud569\ub41c \uacb0\uacfc\ub294 ControlNet\uc758 \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ub418\uba70, \uc774\ub294 \ub3d9\uc791\uacfc ID\uc758 \ubbf8\uc138 \uc870\uc815 \uc8fc\uc785\uc744 \uc704\ud55c \ub2e4\uc911 \uc2a4\ucf00\uc77c \ud2b9\uc9d5\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4. \uc774 \ud504\ub808\uc784\uc6cc\ud06c\ub294 \uac00\uc911\uce58 \uc7ac\uad6c\uc131 \uc190\uc2e4\uc744 \ud1b5\ud574 \ud559\uc2b5\ub418\uba70, \ub370\uc774\ud130 \ubd80\uc871\uc744 \ubcf4\uc644\ud558\uae30 \uc704\ud574 \uc2e4\uc81c \ube44\ub514\uc624\uc640 \uc774\ubbf8\uc9c0\ub85c \uc0dd\uc131\ub41c \ube44\ub514\uc624\ub97c \ud63c\ud569\ud558\uc5ec \uc0ac\uc6a9\ud569\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2501.01427/x4.png", "caption": "Figure 3: Pipeline of trajectory generation for training data. We first perform NMS to filter out densely-distributed points and then select points with larger motion. The retained ones can be sparsely distributed in each part of the target and contain more motion information, thus inducing more precise control.", "description": "\uc774 \uadf8\ub9bc\uc740 \ube44\ub514\uc624 \uac1d\uccb4 \uc0bd\uc785\uc744 \uc704\ud55c \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uada4\uc801 \uc0dd\uc131 \uacfc\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uba3c\uc800, \ubc00\uc9d1\ub41c \uc810\ub4e4\uc744 \uc81c\uac70\ud558\uae30 \uc704\ud574 NMS(Non-Maximum Suppression)\ub97c \uc218\ud589\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c, \ub354 \ud070 \uc6c0\uc9c1\uc784\uc744 \uac00\uc9c4 \uc810\ub4e4\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4.  \uc120\ud0dd\ub41c \uc810\ub4e4\uc740 \ubaa9\ud45c \ub300\uc0c1\uc758 \uac01 \ubd80\ubd84\uc5d0 \ub4dc\ubb3c\uac8c \ubd84\ud3ec\ub418\uc5b4 \ub354 \ub9ce\uc740 \uc6c0\uc9c1\uc784 \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\uac8c \ub418\ubbc0\ub85c, \ubcf4\ub2e4 \uc815\ud655\ud55c \uc81c\uc5b4\ub97c \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4.  \uc27d\uac8c \ub9d0\ud574, \ud6a8\uc728\uc801\uc778 \ud6c8\ub828 \ub370\uc774\ud130 \uc0dd\uc131\uc744 \uc704\ud574 \ubd88\ud544\uc694\ud55c \uc810\ub4e4\uc744 \uc81c\uac70\ud558\uace0 \uc6c0\uc9c1\uc784\uc774 \ud070 \uc911\uc694\ud55c \uc810\ub4e4\ub9cc \ucd94\ucd9c\ud558\ub294 \uacfc\uc815\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.", "section": "3.2 Pixel Warper"}, {"figure_path": "https://arxiv.org/html/2501.01427/x5.png", "caption": "Figure 4: Comparison results between VideoAnydoor and existing state-of-the-art video editing works. Our VideoAnydoor can achieve superior performance on precise control of both motion and content.", "description": "\uadf8\ub9bc 4\ub294 VideoAnydoor\uc640 \uae30\uc874 \ucd5c\ucca8\ub2e8 \ube44\ub514\uc624 \ud3b8\uc9d1 \ubc29\ubc95\ub4e4\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. VideoAnydoor\ub294 \ub3d9\uc791\uacfc \ucf58\ud150\uce20\uc758 \uc815\ubc00\ud55c \uc81c\uc5b4 \uce21\uba74\uc5d0\uc11c \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.  VideoAnydoor\ub294 \uae30\uc874 \ubc29\ubc95\ub4e4\ubcf4\ub2e4 \ub354\uc6b1 \uc815\ud655\ud558\uace0 \uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uac1d\uccb4 \uc0bd\uc785 \ubc0f \ub3d9\uc791 \uc81c\uc5b4\uac00 \uac00\ub2a5\ud568\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \ube44\ub514\uc624 \ud3b8\uc9d1 \uc0ac\ub840\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01\uac01\uc758 \ube44\ub514\uc624 \ud3b8\uc9d1 \uacb0\uacfc\ub294 \uc6d0\ubcf8 \ube44\ub514\uc624\uc640 \ube44\uad50\ub418\uc5b4 VideoAnydoor\uc758 \uc6b0\uc218\uc131\uc744 \uba85\ud655\ud558\uac8c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788,  \uc138\ubc00\ud55c \ubd80\ubd84\uae4c\uc9c0 \uc720\uc9c0\ud558\uba74\uc11c \uc6d0\ud558\ub294 \ub300\ub85c \uac1d\uccb4\uc758 \uc6c0\uc9c1\uc784\uc744 \uc81c\uc5b4\ud560 \uc218 \uc788\ub294 \ub2a5\ub825\uc774 \uac15\uc870\ub429\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8"}, {"figure_path": "https://arxiv.org/html/2501.01427/x6.png", "caption": "Figure 5: Demonstrations for precise motion control. VideoAnydoor can achieve precise alignment with the given trajectories and objects when using a pair of reference images marked with key-points and corresponding trajectory maps as input.", "description": "\uc774 \uadf8\ub9bc\uc740 VideoAnydoor \ubaa8\ub378\uc758 \uc815\ubc00\ud55c \ubaa8\uc158 \uc81c\uc5b4 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc0ac\uc6a9\uc790\uac00 \ud0a4\ud3ec\uc778\ud2b8\uac00 \ud45c\uc2dc\ub41c \ucc38\uc870 \uc774\ubbf8\uc9c0 \ud55c \uc30d\uacfc \ud574\ub2f9\ud558\ub294 \uada4\uc801 \uc9c0\ub3c4\ub97c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ub54c, VideoAnydoor\ub294 \uc8fc\uc5b4\uc9c4 \uada4\uc801\uacfc \uac1d\uccb4\uc5d0 \uc815\ud655\ud558\uac8c \uc815\ub82c\ub420 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc5ec\ub7ec \uc608\uc2dc\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \ub2e8\uc21c\ud788 \uac1d\uccb4\ub97c \uc0bd\uc785\ud558\ub294 \uac83\uc744 \ub118\uc5b4, \uc0ac\uc6a9\uc790\uac00 \uc6d0\ud558\ub294 \uc815\ud655\ud55c \uc6c0\uc9c1\uc784\uc744 \uad6c\ud604\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2501.01427/x7.png", "caption": "Figure 6: More visual examples of VideoAnydoor. It preserves fine-grained details (e.g., logos on the car) and achieves smooth motion control (e.g., the tail of the cat) with our pixel warper.", "description": "\uadf8\ub9bc 6\uc740 VideoAnydoor\uc758 \ucd94\uac00\uc801\uc778 \uc2dc\uac01\uc801 \uc608\uc2dc\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 VideoAnydoor\uac00 \uc790\ub3d9\ucc28\uc758 \ub85c\uace0\uc640 \uac19\uc774 \uc138\ubc00\ud55c \ubd80\ubd84\uae4c\uc9c0\ub3c4 \ubcf4\uc874\ud558\uba74\uc11c \uace0\uc591\uc774\uc758 \uaf2c\ub9ac\ucc98\ub7fc \ubd80\ub4dc\ub7ec\uc6b4 \uc6c0\uc9c1\uc784\uc744 \uc81c\uc5b4\ud558\ub294 \ub2a5\ub825\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud53d\uc140 \uc6cc\ud37c(Pixel Warper) \ub355\ubd84\uc5d0 \uace0\ud574\uc0c1\ub3c4\uc758 \ub514\ud14c\uc77c\uc744 \uc720\uc9c0\ud558\uba74\uc11c \ub3d9\uc2dc\uc5d0 \uc815\ubc00\ud55c \ubaa8\uc158 \uc81c\uc5b4\uac00 \uac00\ub2a5\ud568\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub2e8\uc21c\ud788 \uac1d\uccb4\ub97c \uc0bd\uc785\ud558\ub294 \uac83\uc744 \ub118\uc5b4,  \uc2e4\uc81c \ube44\ub514\uc624\ucc98\ub7fc \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc0ac\uc2e4\uc801\uc778 \uacb0\uacfc\ubb3c\uc744 \uc0dd\uc131\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "4.2. \uc815\uc131\uc801 \ube44\uad50"}, {"figure_path": "https://arxiv.org/html/2501.01427/x8.png", "caption": "Figure 7: Qualitative ablation studies on the core components of VideoAnydoor. When removing the pixel warper, it suffers from poor motion consistency due to the undesired posture. And it can be observed that all the components contribute to the best performance.", "description": "\uadf8\ub9bc 7\uc740 VideoAnydoor\uc758 \ud575\uc2ec \uad6c\uc131 \uc694\uc18c\ub4e4\uc5d0 \ub300\ud55c \uc815\uc131\uc801 ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Pixel Warper\ub97c \uc81c\uac70\ud558\uba74 \uc6d0\uce58 \uc54a\ub294 \uc790\uc138\ub85c \uc778\ud574 \ubaa8\uc158 \uc77c\uad00\uc131\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \ubaa8\ub4e0 \uad6c\uc131 \uc694\uc18c\uac00 \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc5d0 \uae30\uc5ec\ud55c\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 VideoAnydoor\uc758 \uc131\ub2a5\uc5d0 \uac01 \uad6c\uc131\uc694\uc18c(3D U-Net, ID \ucd94\ucd9c\uae30, Pixel Warper, \uc7ac\uac00\uc911\ud654\ub41c \uc7ac\uad6c\uc131 \uc190\uc2e4)\ub4e4\uc774 \uc5bc\ub9c8\ub098 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Pixel Warper\ub294 \ud2b9\ud788 \uac1d\uccb4\uc758 \ub514\ud14c\uc77c\ud55c \ubaa8\uc591\uacfc \uc815\ud655\ud55c \uc6c0\uc9c1\uc784\uc744 \uc720\uc9c0\ud558\ub294 \ub370 \ud544\uc218\uc801\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \uad6c\uc131\uc694\uc18c\ub97c \uc81c\uac70\ud588\uc744 \ub54c \uc131\ub2a5\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \ud1b5\ud574, VideoAnydoor\uc758 \uc131\ub2a5\uc740 \uc5ec\ub7ec \uad6c\uc131\uc694\uc18c\uac00 \uc0c1\ud638\uc791\uc6a9\ud558\uc5ec \ub9cc\ub4e4\uc5b4\ub0b8 \uacb0\uacfc\uc784\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4.4 Ablation Studies"}]