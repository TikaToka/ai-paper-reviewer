[{"figure_path": "https://arxiv.org/html/2412.14689/x1.png", "caption": "Figure 1: Model collapse of synthetic data.\u00a0\u2460 The model continuously trains on its previously generated data, leading to a gradual decline in model performance, i.e., model collapse. Starting from real data (xo,yo)subscript\ud835\udc65\ud835\udc5csubscript\ud835\udc66\ud835\udc5c(x_{o},y_{o})( italic_x start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ), the test error Et\u2062e\u2062s\u2062tsubscript\ud835\udc38\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61E_{test}italic_E start_POSTSUBSCRIPT italic_t italic_e italic_s italic_t end_POSTSUBSCRIPT increases as f0subscript\ud835\udc530f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT undergoes iterative training on synthetic data (y1,y2,\u2026,yn)subscript\ud835\udc661subscript\ud835\udc662\u2026subscript\ud835\udc66\ud835\udc5b(y_{1},y_{2},\\dots,y_{n})( italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u2026 , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ).\n\u2461 ToEdit\u00a0(ours), we use a trained model for token-level editing rather than purely synthesizing data.\nLeveraging f0subscript\ud835\udc530f_{0}italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and an operation matrix misubscript\ud835\udc5a\ud835\udc56m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to edit the data, the test error is constrained within a fixed upper bound. Therefore, we can preserve the distribution coverage to avoid model collapse.", "description": "\uadf8\ub9bc 1\uc740 \ud569\uc131 \ub370\uc774\ud130\uc758 \ubaa8\ub378 \ubd95\uad34 \ud604\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \u2460 \uae30\uc874 \ubaa8\ub378\uc740 \uc774\uc804\uc5d0 \uc0dd\uc131\ud55c \ub370\uc774\ud130\ub85c \uc9c0\uc18d\uc801\uc73c\ub85c \ud559\uc2b5\ud558\uba70, \ubaa8\ub378 \uc131\ub2a5\uc774 \uc810\ucc28 \uc800\ud558\ub418\ub294 \ubaa8\ub378 \ubd95\uad34 \ud604\uc0c1\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc2e4\uc81c \ub370\uc774\ud130 (xo, yo)\uc5d0\uc11c \uc2dc\uc791\ud558\uc5ec, \ubaa8\ub378 f0\uac00 \ud569\uc131 \ub370\uc774\ud130 (y1, y2,\u2026, yn)\ub85c \ubc18\ubcf5 \ud559\uc2b5\ud568\uc5d0 \ub530\ub77c, \ud14c\uc2a4\ud2b8 \uc624\ub958 Et\u2062e\u2062s\u2062t\uac00 \uc99d\uac00\ud569\ub2c8\ub2e4. \u2461 \ubcf8 \ub17c\ubb38\uc5d0\uc11c \uc81c\uc548\ud558\ub294 ToEdit \ubc29\ubc95\uc740 \uc21c\uc218\ud558\uac8c \ud569\uc131 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\ub294 \ub300\uc2e0, \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud1a0\ud070 \uc218\uc900\uc5d0\uc11c \ub370\uc774\ud130\ub97c \uc218\uc815\ud569\ub2c8\ub2e4. \ud6c8\ub828\ub41c \ubaa8\ub378 f0\uc640 \uc5f0\uc0b0 \ud589\ub82c mi\ub97c \ud65c\uc6a9\ud558\uc5ec \ub370\uc774\ud130\ub97c \uc218\uc815\ud568\uc73c\ub85c\uc368, \ud14c\uc2a4\ud2b8 \uc624\ub958\uac00 \uace0\uc815\ub41c \uc0c1\ud55c\uc120 \ub0b4\uc5d0 \uc81c\ud55c\ub429\ub2c8\ub2e4. \ub530\ub77c\uc11c, \ubd84\ud3ec \ubc94\uc704\ub97c \uc720\uc9c0\ud558\uc5ec \ubaa8\ub378 \ubd95\uad34\ub97c \ubc29\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 NON-ITERATIVE MODEL COLLAPSE"}, {"figure_path": "https://arxiv.org/html/2412.14689/x2.png", "caption": "Figure 2: Non-iterative model collapse. Training language models from scratch on AI-synthesized data or a mixture of human and synthetic data leads to performance degradation. This degradation is negatively correlated with the proportion of synthetic data used in training.\nA. We pre-train GPT-2 Small (124M) on human (Dolma\u00a0(Soldaini et\u00a0al., 2024)) and synthetic (Cosmopedia\u00a0(Ben\u00a0Allal et\u00a0al., 2024)) data. As the proportion of synthetic data increases, the model\u2019s loss decreases. B. As the proportion of synthetic data increases, the PPL also rises. This trend remains consistent across different validation sets. More results on downstream tasks are presented in\u00a010 and \u00a011.", "description": "\uadf8\ub9bc 2\ub294 \uc778\uacf5\uc9c0\ub2a5 \ud569\uc131 \ub370\uc774\ud130 \ub610\ub294 \uc778\uac04 \ubc0f \ud569\uc131 \ub370\uc774\ud130\uc758 \ud63c\ud569\ubb3c\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\uc2dc\ud0ac \ub54c \uc131\ub2a5 \uc800\ud558\uac00 \ubc1c\uc0dd\ud558\ub294 \ube44\ubc18\ubcf5\uc801 \ubaa8\ub378 \ubd95\uad34 \ud604\uc0c1\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5 \uc800\ud558\uac00 \uc2ec\ud574\uc9c0\ub294 \uc74c\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ubcf4\uc785\ub2c8\ub2e4. A\ub294 \uc778\uac04 \ub370\uc774\ud130(Dolma (Soldaini et al., 2024))\uc640 \ud569\uc131 \ub370\uc774\ud130(Cosmopedia (Ben Allal et al., 2024))\ub97c \uc0ac\uc6a9\ud558\uc5ec GPT-2 Small (124M)\uc744 \uc0ac\uc804 \ud6c8\ub828\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud569\uc131 \ub370\uc774\ud130 \ube44\uc728\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \ubaa8\ub378 \uc190\uc2e4\uc740 \uac10\uc18c\ud558\uc9c0\ub9cc, B\uc5d0\uc11c \ubcf4\ub294 \uac83\ucc98\ub7fc \uac80\uc99d \uc138\ud2b8\uc5d0\uc11c\uc758 PPL(\ud37c\ud50c\ub809\uc11c\ud2f0)\uc740 \uc99d\uac00\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacbd\ud5a5\uc740 \ub2e4\uc591\ud55c \uac80\uc99d \uc138\ud2b8\uc5d0\uc11c \uc77c\uad00\ub418\uac8c \ub098\ud0c0\ub0a9\ub2c8\ub2e4. \ud558\uc704 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uacb0\uacfc\ub294 \uadf8\ub9bc 10\uacfc 11\uc5d0 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 \ube44\ubc18\ubcf5\uc801 \ubaa8\ub378 \ubd95\uad34"}, {"figure_path": "https://arxiv.org/html/2412.14689/x3.png", "caption": "Figure 3: PPL distribution of human and synthetic data estimated by Llama-3-8B. The synthetic data lacks the long tail of the human-produced data and is also concentrated within the first 25%percent2525\\%25 % of the human-produced data distribution. A. Distribution of human-produced data is sharp with a long tail, spanning a wide range from 0 to over 100. B. The values are concentrated within a much narrower range, mostly between 0 and 12.\nThe experiment uses Dolma v6 and Cosmopedia as human and synthetic data, each with sampled 6B tokens. More results in Figure\u00a09.", "description": "\uadf8\ub9bc 3\uc740 Llama-3-8B\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd94\uc815\ud55c \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc640 \ud569\uc131 \ub370\uc774\ud130\uc758 PPL \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud569\uc131 \ub370\uc774\ud130\ub294 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc758 \uae34 \uaf2c\ub9ac\ub97c \uac16\uc9c0 \uc54a\uace0, \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130 \ubd84\ud3ec\uc758 \ucc98\uc74c 25% \ub0b4\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. (A) \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc758 \ubd84\ud3ec\ub294 \uae34 \uaf2c\ub9ac\ub97c \uac00\uc9c4 \ubfb0\uc871\ud55c \ubd84\ud3ec\ub85c 0\uc5d0\uc11c 100 \uc774\uc0c1\uc758 \ub113\uc740 \ubc94\uc704\uc5d0 \uac78\uccd0 \uc788\uc2b5\ub2c8\ub2e4. (B) \ud569\uc131 \ub370\uc774\ud130\uc758 \uac12\uc740 \ud6e8\uc52c \ub354 \uc881\uc740 \ubc94\uc704\uc778 0\uc5d0\uc11c 12 \uc0ac\uc774\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uc2e4\ud5d8\uc5d0\uc11c\ub294 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\ub85c Dolma v6\uc744, \ud569\uc131 \ub370\uc774\ud130\ub85c Cosmopedia\ub97c \uc0ac\uc6a9\ud588\uc73c\uba70, \uac01\uac01 60\uc5b5 \uac1c\uc758 \ud1a0\ud070\uc744 \uc0d8\ud50c\ub9c1\ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc 9\uc5d0 \ucd94\uac00 \uacb0\uacfc\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.2 WHY DOES SYNTHETIC DATA FAIL IN LANGUAGE MODEL PRE-TRAINING?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x4.png", "caption": "Figure 4: A. Embedding visualization using t-SNE and sentence-transformers. B. pre-training results for selected synthetic data and other data mixtures.", "description": "\uadf8\ub9bc 4\ub294 \ub450 \uac00\uc9c0 \ud558\uc704 \uadf8\ub9bc\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub9bc 4A\ub294 t-SNE\uc640 sentence-transformer\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc778\uac04\uc774 \uc791\uc131\ud55c \ub370\uc774\ud130, \ud569\uc131 \ub370\uc774\ud130, DSIR(Data Selection via Importance Resampling) \uae30\ubc95\uc73c\ub85c \uc120\ud0dd\ub41c \ud569\uc131 \ub370\uc774\ud130\uc758 \uc784\ubca0\ub529\uc744 \uc2dc\uac01\ud654\ud55c \uac83\uc785\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uac01 \ub370\uc774\ud130 \uc720\ud615 \uac04\uc758 \ubd84\ud3ec \ucc28\uc774\ub97c \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc 4B\ub294 \uc120\ud0dd\ub41c \ud569\uc131 \ub370\uc774\ud130\uc640 \ub2e4\ub978 \ub370\uc774\ud130 \ud63c\ud569\ubb3c\uc744 \uc0ac\uc6a9\ud558\uc5ec OLMo-237M \ubaa8\ub378\uc744 \uc0ac\uc804 \ud6c8\ub828\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud569\uc131 \ub370\uc774\ud130 \ube44\uc728\uc5d0 \ub530\ub978 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\uc5b4, \ud569\uc131 \ub370\uc774\ud130 \uc0ac\uc6a9\uc758 \uc601\ud5a5\uacfc \ucd5c\uc801 \ud63c\ud569 \ube44\uc728\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "2.2 WHY DOES SYNTHETIC DATA FAIL IN LANGUAGE MODEL PRE-TRAINING?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x5.png", "caption": "Figure 5: Uni/Bi-gram feature distribution across 10,000 hash buckets.", "description": "\uadf8\ub9bc 5\ub294 10,000\uac1c\uc758 \ud574\uc2dc \ubc84\ud0b7\uc5d0 \uac78\uccd0 \ub2e8\uc77c\uad6c \ubc0f \uc774\uc911\uad6c \ud2b9\uc9d5\uc758 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\ub294 \ub113\uc740 \ubc94\uc704\uc5d0 \uac78\uccd0 \ubd84\ud3ec\ub418\uc5b4 \uc788\uc9c0\ub9cc, \ud569\uc131 \ub370\uc774\ud130\ub294 \uba87\uba87 \ud2b9\uc815 \ubc84\ud0b7\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ud569\uc131 \ub370\uc774\ud130\uac00 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc758 \ub2e4\uc591\uc131\uc744 \ucda9\ubd84\ud788 \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\uace0, \ud2b9\uc815 \ud2b9\uc9d5\uc5d0 \uacfc\ub3c4\ud558\uac8c \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ud604\uc0c1\uc740 \ubaa8\ub378 \ubd95\uad34 \ud604\uc0c1\uacfc \ubc00\uc811\ud55c \uad00\ub828\uc774 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.2 \ud569\uc131 \ub370\uc774\ud130\uac00 \uc5b8\uc5b4 \ubaa8\ub378 \uc0ac\uc804 \ud6c8\ub828\uc5d0\uc11c \uc2e4\ud328\ud558\ub294 \uc774\uc720\ub294 \ubb34\uc5c7\uc77c\uae4c\uc694?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x6.png", "caption": "Figure 6: U-shape token probability distribution of Dolma-sampled V6 estimated by Qwen-0.5B-Instruct\u00a0(qwe, 2024).", "description": "\uadf8\ub9bc 6\uc740 Qwen-0.5B-Instruct \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec Dolma-sampled V6 \ub370\uc774\ud130\uc14b\uc758 \ud1a0\ud070 \ud655\ub960 \ubd84\ud3ec\ub97c \ub098\ud0c0\ub0b8 \uadf8\ub9bc\uc785\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub2e8\uc21c\ud788 U\uc790\ud615 \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uac83 \uc774\uc0c1\uc73c\ub85c,  \uc5b8\uc5b4 \ubaa8\ub378\uc774 \ud559\uc2b5\ud55c \ub370\uc774\ud130\uc758 \ud1a0\ud070\uc5d0 \ub300\ud55c \ud655\ub960 \ubd84\ud3ec\uac00 \uc591 \ub05d\ub2e8(\ud655\ub960\uc774 \ub9e4\uc6b0 \ub192\uac70\ub098 \ub9e4\uc6b0 \ub0ae\uc740 \ud1a0\ud070)\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \uc911\uac04 \uc601\uc5ed\uc758 \ud1a0\ud070\ub4e4\uc774 \uc0c1\ub300\uc801\uc73c\ub85c \ub0ae\uc740 \ud655\ub960\uc744 \uac00\uc9c0\uba70,  \ubaa8\ub378\uc774 \uc77c\ubd80 \ud1a0\ud070 \ud328\ud134\uc5d0 \uacfc\ub3c4\ud558\uac8c \uc9d1\uc911\ud558\ub294 \ud604\uc0c1\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub7ec\ud55c U\uc790\ud615 \ubd84\ud3ec\ub294 \ud6c4\uc18d \uc808\uc5d0\uc11c \uc124\uba85\ud558\ub294 \ud1a0\ud070 \ud3b8\uc9d1 \uae30\ubc95(Token-level Editing)\uc758 \uc774\ub860\uc801 \uadfc\uac70\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uc989,  \ubaa8\ub378\uc774 \ud655\ub960\uc774 \ub192\uc740 \ud1a0\ud070\uc5d0 \uacfc\ub3c4\ud558\uac8c \uc758\uc874\ud558\ub294 \uacbd\ud5a5\uc744 \uc218\uc815\ud558\uc5ec,  \ub354\uc6b1 \ub2e4\uc591\ud558\uace0 \uade0\ud615\uc7a1\ud78c \ub370\uc774\ud130\uc14b\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ud1a0\ub300\uac00 \ub429\ub2c8\ub2e4.", "section": "3 TOKEN-LEVEL EDITING"}, {"figure_path": "https://arxiv.org/html/2412.14689/x7.png", "caption": "Figure 7: OLMo-237M pretraining with mixed human and synthetic data proportions. We pretrain the OLMo-237M model using a mixture of human data (Dolma\u00a0(Soldaini et\u00a0al., 2024)) and synthetic data (Cosmopedia\u00a0(Ben\u00a0Allal et\u00a0al., 2024)).", "description": "\uadf8\ub9bc 7\uc740 OLMo-237M \uc5b8\uc5b4 \ubaa8\ub378\uc744 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130(Dolma)\uc640 \ud569\uc131 \ub370\uc774\ud130(Cosmopedia)\ub97c \uc11e\uc5b4\uc11c \uc0ac\uc804 \ud6c8\ub828\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ube44\uc728\ub85c \uc778\uac04 \ub370\uc774\ud130\uc640 \ud569\uc131 \ub370\uc774\ud130\ub97c \uc11e\uc5b4\uc11c \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ucf30\uace0, \uadf8 \uacb0\uacfc\ub97c \uadf8\ub798\ud504\ub85c \ub098\ud0c0\ub0c8\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc774 \ub192\uc544\uc9d0\uc5d0 \ub530\ub77c \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud569\ub2c8\ub2e4.  x\ucd95\uc740 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ub370\uc774\ud130\uc758 \uc591(\ud1a0\ud070 \uc218)\uc744 \ub098\ud0c0\ub0b4\uace0, y\ucd95\uc740 \uc190\uc2e4(loss) \uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc774 \ub192\uc744\uc218\ub85d \uc190\uc2e4 \uac12\uc774 \uac10\uc18c\ud558\uc9c0\ub9cc, \uc2e4\uc81c \uc131\ub2a5\uc740 \uc624\ud788\ub824 \ub5a8\uc5b4\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2 Non-iterative Model Collapse"}, {"figure_path": "https://arxiv.org/html/2412.14689/x8.png", "caption": "Figure 8: GPT-2 perplexity (PPL) on validation sets, trained from scratch.", "description": "\uadf8\ub9bc 8\uc740 GPT-2 \uc5b8\uc5b4 \ubaa8\ub378\uc744 \ucc98\uc74c\ubd80\ud130 \ud559\uc2b5\uc2dc\ud0ac \ub54c, \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc744 \ub2ec\ub9ac\ud558\uc5ec \ud559\uc2b5\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \ud1a0\ud070\uc758 \uc218 (\uc2ed\uc5b5 \ub2e8\uc704)\uc774\uace0, y\ucd95\uc740 \ub2e4\uc591\ud55c \uac80\uc99d \ub370\uc774\ud130\uc14b(Wikitext-103, RedPajama, Falcon-RefinedWeb, c4-en)\uc5d0 \ub300\ud55c GPT-2\uc758 perplexity(PPL) \uac12\uc785\ub2c8\ub2e4.  PPL\uc740 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\ub294 \uc9c0\ud45c\ub85c, \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc131\ub2a5\uc774 \uc88b\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uac01 \uc120\uc740 \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc774 \ub2e4\ub978 \uacbd\uc6b0(0%, 25%, 50%, 75%, 100%)\uc758 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ud569\uc131 \ub370\uc774\ud130\uc758 \ube44\uc728\uc774 \ub192\uc544\uc9c8\uc218\ub85d \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc800\ud558\ub428\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ubaa9\uc801\uc73c\ub85c \ud569\ub2c8\ub2e4.  \uc989, \uc21c\uc218 \ud569\uc131 \ub370\uc774\ud130\ub85c\ub9cc \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uac00\uc7a5 \ub0ae\uace0, \uc2e4\uc81c \ub370\uc774\ud130\ub9cc\uc73c\ub85c \ud559\uc2b5\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uac00\uc7a5 \ub192\ub2e4\ub294 \uac83\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2 NON-ITERATIVE MODEL COLLAPSE"}, {"figure_path": "https://arxiv.org/html/2412.14689/x9.png", "caption": "Figure 9: PPL distribution of human and synthetic data estimated by StabLM-Zephyr-3B. This indicates that different prior distributions yielded the same result, which is consistent with Figure\u00a03. The synthetic data lacks a long tail and is concentrated within a narrow portion of the distribution.", "description": "\uadf8\ub9bc 9\ub294 StabLM-Zephyr-3B\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd94\uc815\ub41c \uc778\uac04 \ub370\uc774\ud130\uc640 \ud569\uc131 \ub370\uc774\ud130\uc758 PPL \ubd84\ud3ec\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc11c\ub85c \ub2e4\ub978 \uc0ac\uc804 \ubd84\ud3ec\ub97c \uc0ac\uc6a9\ud558\ub354\ub77c\ub3c4 \ub3d9\uc77c\ud55c \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 Figure 3\uacfc \uc77c\uce58\ud569\ub2c8\ub2e4. \ud569\uc131 \ub370\uc774\ud130\ub294 \uae34 \uaf2c\ub9ac\ub97c \uac00\uc9c0\uc9c0 \uc54a\uace0 \ubd84\ud3ec\uc758 \uc881\uc740 \uc601\uc5ed\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub2e4\uc2dc \ub9d0\ud574, \ud569\uc131 \ub370\uc774\ud130\ub294 \uc778\uac04 \ub370\uc774\ud130\uc758 \ub2e4\uc591\uc131\uacfc \ubcf5\uc7a1\uc131\uc744 \ucda9\ubd84\ud788 \ud3ec\ucc29\ud558\uc9c0 \ubabb\ud558\uace0, \uc778\uac04 \ub370\uc774\ud130 \ubd84\ud3ec\uc758 \ud558\uc704 25%\uc5d0\ub9cc \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774\ub7ec\ud55c \uacb0\uacfc\ub294 \ud569\uc131 \ub370\uc774\ud130\uac00 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc758 \ubcf5\uc7a1\uc131\uc744 \ucda9\ubd84\ud788 \ubc18\uc601\ud558\uc9c0 \ubabb\ud55c\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uba70, \uc774\ub85c \uc778\ud574 \ubaa8\ub378 \ubd95\uad34\uac00 \ubc1c\uc0dd\ud560 \uac00\ub2a5\uc131\uc744 \ub192\uc785\ub2c8\ub2e4.", "section": "2.2 WHY DOES SYNTHETIC DATA FAIL IN LANGUAGE MODEL PRE-TRAINING?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x10.png", "caption": "Figure 10: The top 40 bi-grams from separately sampled 1M subsets of Dolma, Cosmopedia, and DSIR-selected datasets.", "description": "\uadf8\ub9bc 10\uc740 Dolma, Cosmopedia \ubc0f DSIR\ub85c \uc120\ud0dd\ub41c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac1c\ubcc4\uc801\uc73c\ub85c \uc0d8\ud50c\ub9c1\ub41c 1M\uac1c\uc758 \ud558\uc704 \uc9d1\ud569\uc5d0\uc11c \uc0c1\uc704 40\uac1c\uc758 \uc774\uc911 \uadf8\ub7a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uac01 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uac00\uc7a5 \ube48\ubc88\ud558\uac8c \ub098\ud0c0\ub098\ub294 \uc774\uc911 \uadf8\ub7a8\ub4e4\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \uc138 \ub370\uc774\ud130\uc14b\uc758 \uc5b8\uc5b4\uc801 \ud2b9\uc9d5\uacfc \ubd84\ud3ec\uc758 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Dolma\ub294 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc14b, Cosmopedia\ub294 \ud569\uc131 \ub370\uc774\ud130\uc14b, DSIR\uc740 \uc120\ud0dd\ub41c \ub370\uc774\ud130\uc14b\uc73c\ub85c, \uc774\ub4e4\uc758 \uc774\uc911 \uadf8\ub7a8 \ubd84\ud3ec\ub97c \ube44\uad50\ud568\uc73c\ub85c\uc368 \uac01 \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uacfc \ud55c\uacc4\ub97c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc14b\uacfc \ud569\uc131 \ub370\uc774\ud130\uc14b \uac04\uc758 \uc774\uc911 \uadf8\ub7a8 \ubd84\ud3ec \ucc28\uc774\ub97c \ud1b5\ud574 \ud569\uc131 \ub370\uc774\ud130\uc14b\uc758 \ud55c\uacc4\uc810\uc744 \ubcf4\uc5ec\uc8fc\uace0, DSIR\uc744 \ud1b5\ud574 \uc120\ud0dd\ub41c \ub370\uc774\ud130\uc14b\uc774 \ub450 \ub370\uc774\ud130\uc14b\uc758 \ud2b9\uc9d5\uc744 \uc5b4\ub5bb\uac8c \ubc18\uc601\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2.2 WHY DOES SYNTHETIC DATA FAIL IN LANGUAGE MODEL PRE-TRAINING?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x11.png", "caption": "Figure 11: The top 64 bi-grams from separately sampled 1M subsets of Dolma, Cosmopedia, and DSIR-selected datasets.", "description": "\uadf8\ub9bc 11\uc740 Dolma, Cosmopedia \ubc0f DSIR \uc120\ud0dd \ub370\uc774\ud130 \uc138\ud2b8\uc758 \uac1c\ubcc4\uc801\uc73c\ub85c \uc0d8\ud50c\ub9c1\ub41c 1M \ud558\uc704 \uc9d1\ud569\uc5d0\uc11c \uc0c1\uc704 64\uac1c\uc758 \uc774\uc911 \uadf8\ub7a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uac01 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \uac00\uc7a5 \uc790\uc8fc \ub098\ud0c0\ub098\ub294 2\uac1c\uc758 \ub2e8\uc5b4 \uc870\ud569\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec, \ub370\uc774\ud130 \uc138\ud2b8 \uac04\uc758 \ucc28\uc774\uc810\uacfc \uc720\uc0ac\uc810\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ud2b9\ud788, \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ud14d\uc2a4\ud2b8(Dolma)\uc640 \ud569\uc131 \ud14d\uc2a4\ud2b8(Cosmopedia) \uc0ac\uc774\uc758 n-gram \ud2b9\uc9d5\uc758 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. DSIR \uc120\ud0dd \ub370\uc774\ud130 \uc138\ud2b8\ub294 \uc778\uac04\uc774 \uc0dd\uc131\ud55c \ub370\uc774\ud130\uc640 \ud569\uc131 \ub370\uc774\ud130\uc758 \ud2b9\uc9d5\uc744 \ubaa8\ub450 \ud3ec\ud568\ud558\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc73c\ubbc0\ub85c, \uc138 \ub370\uc774\ud130 \uc138\ud2b8 \ubaa8\ub450\uc5d0\uc11c \uc0c1\uc704 n-gram \ud2b9\uc9d5\uc758 \ubd84\ud3ec\uac00 \uc5b4\ub5bb\uac8c \ub2e4\ub978\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4. \uc774 \ube44\uad50\ub97c \ud1b5\ud574 \ud569\uc131 \ub370\uc774\ud130 \uc0dd\uc131 \uc2dc \ubc1c\uc0dd\ud560 \uc218 \uc788\ub294 \ubb38\uc81c\uc810(\uc608: \ud2b9\uc9d5 \uacfc\uc789 \uc9d1\uc911)\uc744 \uc774\ud574\ud558\uace0 \uac1c\uc120\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "2.2 WHY DOES SYNTHETIC DATA FAIL IN LANGUAGE MODEL PRE-TRAINING?"}, {"figure_path": "https://arxiv.org/html/2412.14689/x12.png", "caption": "Figure 12: Density sampling response values. This result further confirms the issue of feature collapse in synthetic data.", "description": "\uadf8\ub9bc 12\ub294 \ud569\uc131 \ub370\uc774\ud130\uc5d0\uc11c \ud2b9\uc9d5\ub4e4\uc758 \ubd95\uad34 \ubb38\uc81c\ub97c \ub354 \uc790\uc138\ud788 \ubcf4\uc5ec\uc8fc\ub294 \ubc00\ub3c4 \uc0d8\ud50c\ub9c1 \uc751\ub2f5 \uac12\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  x\ucd95\uc740 \ud574\uc2dc \ud568\uc218\uc758 \uc778\ub371\uc2a4\ub97c \ub098\ud0c0\ub0b4\uace0 y\ucd95\uc740 \ud574\ub2f9 \ud574\uc2dc \ubc84\ud0b7\uc5d0 \uc788\ub294 \ud2b9\uc9d5\ub4e4\uc758 \ube48\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774 \ud788\ud2b8\ub9f5\uc740 \ud569\uc131 \ub370\uc774\ud130\uc758 \ud2b9\uc9d5\ub4e4\uc774 \uc18c\uc218\uc758 \ud2b9\uc9d5 \ubc84\ud0b7\uc5d0 \uacfc\ub3c4\ud558\uac8c \uc9d1\uc911\ub418\uc5b4 \uc788\uc74c\uc744 \uc2dc\uac01\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 \ud569\uc131 \ub370\uc774\ud130\uac00 \uc2e4\uc81c \ub370\uc774\ud130\uc758 \ub2e4\uc591\ud55c \ud2b9\uc9d5\ub4e4\uc744 \uc81c\ub300\ub85c \ubc18\uc601\ud558\uc9c0 \ubabb\ud558\uace0 \uc788\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud558\uba70, \ubaa8\ub378 \ubd95\uad34 \ubb38\uc81c\uc758 \uc6d0\uc778\uc774 \ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc00\ub3c4 \uc0d8\ud50c\ub9c1 \uc751\ub2f5 \uac12\uc740 \uc55e\uc11c \uc5b8\uae09\ub41c \ubd84\ud3ec \ubc0f \ud2b9\uc9d5 \ubd84\uc11d \uacb0\uacfc\ub97c \ub354\uc6b1 \uac15\ud654\ud558\uba70, \ud569\uc131 \ub370\uc774\ud130\uc758 \ud55c\uacc4\ub97c \uba85\ud655\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "2.2 \ud569\uc131 \ub370\uc774\ud130\uac00 \uc5b8\uc5b4 \ubaa8\ub378 \uc0ac\uc804 \ud6c8\ub828\uc5d0\uc11c \uc2e4\ud328\ud558\ub294 \uc774\uc720\ub294 \ubb34\uc5c7\uc77c\uae4c\uc694?"}]