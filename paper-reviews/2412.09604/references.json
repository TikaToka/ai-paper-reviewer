{"references": [{"fullname_first_author": "Jinze Bai", "paper_title": "Qwen technical report", "publication_date": "2023-09-16", "reason": "This reference introduces Qwen, a large language model (LLM) that SynerGen-VL builds upon and initializes from."}, {"fullname_first_author": "Rohan Bavishi", "paper_title": "Introducing our multimodal models", "publication_date": "2023-00-00", "reason": "This reference introduces Fuyu-8B (HD), an important encoder-free unified MLLM that SynerGen-VL is compared against."}, {"fullname_first_author": "Zheng Cai", "paper_title": "InternLM2 technical report", "publication_date": "2024-03-17", "reason": "This reference introduces InternLM2, a pretrained LLM that SynerGen-VL is built upon, sharing the same text tokenizer and conversation format."}, {"fullname_first_author": "ChameleonTeam", "paper_title": "Chameleon: Mixed-modal early-fusion foundation models", "publication_date": "2024-05-09", "reason": "This reference introduces Chameleon, an encoder-free unified MLLM for synergizing image understanding and generation, that SynerGen-VL is compared to."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-00-00", "reason": "This reference introduces VQGAN, which serves as the basis for discrete visual tokenizers used by SynerGen-VL and other encoder-free MLLMs."}]}