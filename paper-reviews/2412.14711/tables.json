[{"content": "| Size | #Parameters | hidden_size | num_layers | num_heads | num_groups | GFLOPs |\n|---|---|---|---|---|---|---|\n| Small | 182M | 768 | 12 | 12 | 4 | 995 |\n| Medium | 469M | 1024 | 24 | 16 | 4 | 2873 |\n| Large | 978M | 1536 | 24 | 16 | 4 | 5991 |", "caption": "Table 1: Configurations for the dense backbones. FLOPs are calculated with a single sequence according to\u00a0Narayanan et\u00a0al. (2021).", "description": "\ud45c 1\uc740 \ub17c\ubb38\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uc138 \uac00\uc9c0 \ud06c\uae30\uc758 \uae30\ubcf8 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378(Small, Medium, Large)\uc758 \uc124\uc815\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubaa8\ub378\uc740 \ub9e4\uac1c\ubcc0\uc218\uc758 \uc218, \uc740\ub2c9\uce35 \ud06c\uae30, \ub808\uc774\uc5b4 \uc218, \ud5e4\ub4dc \uc218, \uadf8\ub8f9 \uc218, \uadf8\ub9ac\uace0 \ub2e8\uc77c \uc2dc\ud000\uc2a4\uc5d0 \ub300\ud55c FLOP(\ubd80\ub3d9 \uc18c\uc218\uc810 \uc5f0\uc0b0 \uc218)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. FLOP\ub294 Narayanan et al.(2021)\uc758 \ubc29\ubc95\uc5d0 \ub530\ub77c \uacc4\uc0b0\ub429\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ubaa8\ub378\uc758 \uaddc\ubaa8\uc640 \uacc4\uc0b0 \ube44\uc6a9\uc744 \ube44\uad50\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4.1 \uc124\uc815"}, {"content": "| Model | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|\n| Dense | 19.45 | 43.35 | 54.40 | 28.61 | 31.09 | 61.97 | 28.52 | 38.20 |\n| Hash | 19.28 | 45.45 | 54.95 | 29.68 | 31.44 | 63.06 | 27.66 | 38.79 |\n| Lory | 20.31 | 42.97 | 49.54 | 28.75 | 32.35 | 62.24 | 27.75 | 37.70 |\n| SparseMixer-v2 | 19.80 | 46.72 | 45.96 | 30.24 | 34.12 | 62.89 | 29.00 | 38.39 |\n| EC | 18.86 | 42.97 | 60.21 | 29.14 | 29.26 | 61.92 | 27.37 | 38.53 |\n| dMoE | 20.05 | 45.16 | 57.83 | 29.83 | 32.97 | 63.55 | 28.33 | 39.67 |\n| ReMoE | 20.22 | 46.68 | 54.16 | 30.26 | 35.94 | 63.55 | 29.38 | 40.03 |", "caption": "Table 2: Zero-shot accuracy of different routing methods on downstream tasks.", "description": "\ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ub77c\uc6b0\ud305 \ubc29\ubc95(TopK, ReLU, Lory, SparseMixer-v2, EC, dMoE \ub4f1)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5(ARC, BoolQ, HellaSwag, LAMBADA, PIQA, RACE)\uc5d0 \ub300\ud55c \uc81c\ub85c\uc0f7 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uac01 \ub77c\uc6b0\ud305 \ubc29\ubc95\uc758 \uc131\ub2a5\uc744 \uc5ec\ub7ec \uac00\uc9c0 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc5d0 \uac78\uccd0 \uce21\uc815\ud558\uc5ec \ube44\uad50\ud568\uc73c\ub85c\uc368 \ub2e4\uc591\ud55c \ubaa8\ub378 \uaddc\ubaa8\uc640 \uc804\ubb38\uac00 \uc218\uc5d0 \ub530\ub978 \uc131\ub2a5\uc758 \ucc28\uc774\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ub77c\uc6b0\ud305 \uae30\ubc95\ub4e4\uc758 \uc0c1\ub300\uc801\uc778 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "4.2 \ub2e4\ub978 \ub77c\uc6b0\ud305 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"content": "| \u03bb\u2080 | 1e\u207b\u00b9\u2076 | 1e\u207b\u00b9\u00b2 | 1e\u207b\u2078 | 1e\u207b\u2074 | 1 |\n|---|---|---|---|---|---| \n| Valid Loss | 2.031 | 2.029 | 2.032 | 2.036 | 2.032 |\n| Settling time | 138 | 136 | 110 | 55 | 92\u2020 |", "caption": "Table 5: Performance of training N=\ud835\udc41absentN=italic_N =469M, E=8\ud835\udc388E=8italic_E = 8, k=1\ud835\udc581k=1italic_k = 1 models for 120B tokens.", "description": "\ud45c 5\ub294 469M\uac1c\uc758 \ub9e4\uac1c\ubcc0\uc218, 8\uac1c\uc758 \uc804\ubb38\uac00, \uadf8\ub9ac\uace0 \ud65c\uc131 \uc804\ubb38\uac00 \uc218 k=1\uc744 \uac16\ub294 \ubaa8\ub378\uc744 1200\uc5b5 \uac1c\uc758 \ud1a0\ud070\uc73c\ub85c \ud559\uc2b5\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud558\ub958 \uc791\uc5c5(ARC-C, ARC-e, BoolQ, HellaSwag, LAMBADA, PIQA, RACE)\uc5d0 \ub300\ud55c \uac80\uc99d \uc190\uc2e4 \ubc0f \uc815\ud655\ub3c4 \uc810\uc218\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, ReMoE \ubaa8\ub378\uc758 \uc131\ub2a5 \uc6b0\uc218\uc131\uc744 \ub354 \uae34 \ud559\uc2b5 \uc2dc\uac04 \ud6c4\uc5d0\ub3c4 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| \n\u03b1 | 1.05 | 1.1 | 1.2 | 1.3 | 1.5 |\n|---|---|---|---|---|---| \n| Valid Loss | 2.033 | 2.028 | 2.032 | 2.029 | 2.057* |\n| Settling time | 414 | 211 | 110 | 80 | 52 |\n", "caption": "Table 6: End-to-end training time comparison across stages (in hours). The time is measured on N=\ud835\udc41absentN=italic_N = 469M, E=8\ud835\udc388E=8italic_E = 8, k=1\ud835\udc581k=1italic_k = 1 models training over 120B tokens.", "description": "\ud45c 6\uc740 4\uc5b5 6900\ub9cc\uac1c\uc758 \ub9e4\uac1c\ubcc0\uc218(N=469M), 8\uac1c\uc758 \uc804\ubb38\uac00(E=8), \ud65c\uc131\ud654\ub41c \uc804\ubb38\uac00 \uc218 1\uac1c(k=1)\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uc744 1200\uc5b5\uac1c\uc758 \ud1a0\ud070\uc73c\ub85c \ud559\uc2b5\uc2dc\ud0a8 \uacb0\uacfc\uc5d0 \ub300\ud55c \uac01 \ub2e8\uacc4\ubcc4(Stage I, II, III) \ud559\uc2b5 \uc2dc\uac04\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  \ucd1d \ud559\uc2b5 \uc2dc\uac04\uacfc \uac01 \ub2e8\uacc4\ubcc4 \uc2dc\uac04\uc744 \uc2dc\uac04(hour) \ub2e8\uc704\ub85c \ub098\ud0c0\ub0b4\uc5b4, ReMoE\uc640 \uae30\uc874 MoE\uc758 \ud559\uc2b5 \uc2dc\uac04 \ud6a8\uc728\uc131\uc744 \ube44\uad50 \ubd84\uc11d\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  Stage I\uacfc II\ub294 ReMoE\uc758 \ucd08\uae30 \ub2e8\uacc4\ub85c, \ub300\ubd80\ubd84\uc758 \uc804\ubb38\uac00\uac00 \ud65c\uc131\ud654\ub418\ub294 \ub2e8\uacc4\uc785\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"content": "| Model | Valid Loss | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| MoE | 1.716 | 23.62 | 52.40 | 53.94 | 35.43 | 43.64 | 68.34 | **31.48** | 44.12 |\n| ReMoE | **1.689** | **25.34** | **55.22** | **55.96** | **36.76** | **45.82** | **68.93** | 30.43 | **45.49** |", "caption": "Table 7: Throughput comparison between TopK-routed MoE and ReLU-routed ReMoE models. TP indicates the tensor parallel size. Train Diff. and Infer Diff. indicate the relative TFLOPS difference of ReMoE compared to MoE, where \u2191 denotes ReMoE is faster, and \u2193 denotes it is slower.", "description": "\ud45c 7\uc740 TopK \ub77c\uc6b0\ud305 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub294 \uae30\uc874 MoE \ubaa8\ub378\uacfc ReLU \ub77c\uc6b0\ud305 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub294 ReMoE \ubaa8\ub378\uc758 \ucc98\ub9ac\ub7c9\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. TP\ub294 \ud150\uc11c \ubcd1\ub82c \ucc98\ub9ac \ud06c\uae30\ub97c \ub098\ud0c0\ub0b4\uace0, Train Diff.\uc640 Infer Diff.\ub294 ReMoE\uc640 MoE \uac04\uc758 \uc0c1\ub300\uc801\uc778 TFLOPS \ucc28\uc774\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \u2191\ub294 ReMoE\uac00 \ub354 \ube60\ub974\ub2e4\ub294 \uac83\uc744, \u2193\ub294 ReMoE\uac00 \ub354 \ub290\ub9ac\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc989, \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378\uacfc \ud150\uc11c \ubcd1\ub82c \ucc98\ub9ac \ud06c\uae30\uc5d0 \ub300\ud574 ReMoE\uc758 \uc131\ub2a5\uc744 \uae30\uc874 MoE\uc640 \ube44\uad50\ud558\uc5ec ReMoE\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ubaa8\ub378 \ud06c\uae30\uc640 \ud150\uc11c \ubcd1\ub82c \ucc98\ub9ac \ud06c\uae30\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c ReMoE\uc758 \uc18d\ub3c4 \ubcc0\ud654\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.2 \ub2e4\ub978 \ub77c\uc6b0\ud305 \ubc29\ubc95\uacfc\uc758 \ube44\uad50"}, {"content": "| Model | Stage I | Stage II | Stage III | Total |\n|---|---|---|---|---|\n| MoE | 0.12 | 0.41 | 119.12 | 119.65 |\n| ReMoE | 0.32 | 0.91 | 119.25 | 120.48 |", "caption": "Table 8: Downstream results of scaling in active parameters N\ud835\udc41Nitalic_N.", "description": "\ud45c 8\uc740 \ud65c\uc131 \ub9e4\uac1c\ubcc0\uc218 N\uc758 \ud06c\uae30\uc5d0 \ub530\ub978 \ubaa8\ub378 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378(182M, 469M, 978M \ub9e4\uac1c\ubcc0\uc218)\uc5d0 \ub300\ud574,  \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5(ARC, ARC-e, BoolQ, HellaSwag, LAMBADA, PIQA, RACE)\uc5d0\uc11c\uc758 \uc815\ud655\ub3c4\ub97c \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 \ud65c\uc131 \ub9e4\uac1c\ubcc0\uc218 \uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\ub294 \uc591\uc0c1\uc744 \ubcf4\uc5ec\uc8fc\uba70, ReMoE \ubaa8\ub378\uc774 \uae30\uc874 MoE \ubaa8\ub378\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 REMOE\uc758 \ud655\uc7a5\uc131"}, {"content": "| # Parameters | TP | Model | Train TFLOPS | Train Diff. | Infer TFLOPS | Infer Diff. |\n|---|---|---|---|---|---|---|\n| 182M | 1 | MoE | 103.49 | \u21911.82% | 78.47 | \u21912.19% |\n|  |  | ReMoE | 105.38 |  | 80.19 |  |\n| 469M | 1 | MoE | 138.58 | \u21931.37% | 107.52 | \u21913.89% |\n|  |  | ReMoE | 136.69 |  | 111.71 |  |\n| 978M | 1 | MoE | 160.46 | \u21931.77% | 153.11 | \u21930.23% |\n|  |  | ReMoE | 157.61 |  | 152.76 |  |\n| 978M | 2 | MoE | 133.40 | \u21930.68% | 118.55 | \u21931.08% |\n|  |  | ReMoE | 132.49 |  | 117.27 |  |\n| 978M | 4 | MoE | 103.61 | \u21932.29% | 85.96 | \u21912.33% |\n|  |  | ReMoE | 101.23 |  | 87.96 |  |", "caption": "Table 9: Downstream results of scaling in expert count E\ud835\udc38Eitalic_E.", "description": "\ud45c 9\ub294 \uc804\ubb38\uac00 \uc218(E)\ub97c \ud655\uc7a5\ud560 \ub54c\uc758 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378\uacfc \ub2e4\uc591\ud55c \uc218\uc758 \uc804\ubb38\uac00\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \uac00\uc9c0 \ud558\ub958 \uc791\uc5c5(ARC, ARC-e, BoolQ, HellaSwag, LAMBADA, PIQA, RACE)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc804\ubb38\uac00 \uc218\ub97c \ub298\ub9ac\ub294 \uac83\uc774 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uacfc ReMoE\uac00 \uc774\ub7ec\ud55c \ud655\uc7a5\uc131 \uce21\uba74\uc5d0\uc11c \uc5b4\ub5bb\uac8c \ub3d9\uc791\ud558\ub294\uc9c0\uc5d0 \ub300\ud55c \ud1b5\ucc30\ub825\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.  \ub2e4\ub978 \ub9d0\ub85c \ud558\uba74, \uc774 \ud45c\ub294 \ubaa8\ub378 \ud06c\uae30\uc640 \uc804\ubb38\uac00 \uc218\uc758 \uc870\ud569\uc5d0 \ub530\ub978 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uc5b4, ReMoE\uc758 \ud655\uc7a5\uc131\uc744 \ud3c9\uac00\ud558\ub294 \ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4.", "section": "4.3 ReMoE\uc758 \ud655\uc7a5\uc131"}, {"content": "| Model | N | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| Dense | 182M | 19.45 | 43.35 | 54.40 | 28.61 | 31.09 | 61.97 | 28.52 | 38.20 |\n|  | 469M | 21.50 | 49.12 | 56.88 | 31.12 | 36.74 | 64.47 | 30.53 | 41.48 |\n|  | 978M | 21.93 | 50.88 | 60.24 | 32.42 | 41.06 | 67.46 | 31.77 | 43.68 |\n| MoE | 182M | 20.82 | 45.03 | 57.55 | 29.84 | 31.81 | 63.28 | 28.42 | 39.53 |\n|  | 469M | 23.63 | 52.40 | 53.94 | 32.43 | 43.64 | 68.34 | 31.48 | 43.69 |\n|  | 978M | 23.81 | 52.90 | 58.90 | 35.01 | 44.42 | 67.90 | 31.48 | 44.91 |\n| ReMoE | 182M | 20.22 | 46.68 | 54.16 | 30.26 | 35.94 | 63.55 | 29.38 | 40.03 |\n|  | 469M | 21.67 | 53.16 | 58.75 | 33.80 | 40.66 | 67.95 | 31.20 | 43.88 |\n|  | 978M | 24.06 | 55.26 | 57.28 | 35.93 | 44.42 | 68.99 | 30.43 | 45.20 |", "caption": "Table 10: Downstream results of scaling in granularity G\ud835\udc3aGitalic_G.", "description": "\ud45c 10\uc740 \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \uc138\ubd84\ud654(granularity) \uc218\uc900\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub2e4\uc591\ud55c \ud06c\uae30\uc758 \ubaa8\ub378(\ub9e4\uac1c\ubcc0\uc218 \uc218)\uc5d0\uc11c \uc138\ubd84\ud654 \uc218\uc900\uc744 \ubcc0\uacbd\ud558\uba74\uc11c \uc5ec\ub7ec \uac00\uc9c0 \ud558\ub958 \uc791\uc5c5(downstream tasks)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \uce21\uc815\ud569\ub2c8\ub2e4.  \uc774 \ud45c\ub294 ReMoE \ubaa8\ub378\uc774 \uc138\ubd84\ud654 \uc218\uc900\uc774 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294  \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc81c\uc2dc\ud569\ub2c8\ub2e4. \ud2b9\ud788 \uae30\uc874 MoE \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec ReMoE \ubaa8\ub378\uc758 \ud655\uc7a5\uc131(scalability)\uc744 \uac15\uc870\ud569\ub2c8\ub2e4.", "section": "4.3 ReMoE\uc758 \ud655\uc7a5\uc131"}, {"content": "| Model | E | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| Dense | - | 19.45 | 43.35 | 54.40 | 28.61 | 31.09 | 61.97 | 28.52 | 38.20 |\n| MoE |  |  |  |  |  |  |  |  |  |\n| 4 | 20.73 | 44.49 | 59.63 | 29.14 | 31.40 | 63.33 | 29.19 | 39.70 |\n| 8 | 20.82 | 45.03 | 57.55 | 29.84 | 31.81 | 63.28 | 28.42 | 39.53 |\n| 16 | 20.90 | 45.29 | 46.36 | 30.50 | 33.22 | 64.96 | 28.33 | 38.50 |\n| 32 | 19.54 | 47.35 | 52.29 | 31.12 | 35.63 | 64.25 | 28.23 | 39.77 |\n| 64 | 19.88 | 46.63 | 60.06 | 31.47 | 36.33 | 65.07 | 28.04 | 41.06 |\n| 128 | 20.99 | 47.69 | 56.73 | 32.00 | 36.62 | 65.67 | 28.04 | 41.10 |\n| ReMoE |  |  |  |  |  |  |  |  |  |\n| 4 | 19.88 | 46.46 | 57.43 | 29.64 | 33.57 | 62.95 | 27.66 | 39.66 |\n| 8 | 20.22 | 46.68 | 54.16 | 30.26 | 35.94 | 63.55 | 29.38 | 40.03 |\n| 16 | 20.90 | 49.28 | 53.36 | 30.85 | 37.09 | 65.83 | 30.05 | 41.05 |\n| 32 | 20.56 | 48.11 | 59.54 | 31.42 | 37.84 | 65.18 | 28.42 | 41.58 |\n| 64 | 20.82 | 50.51 | 57.80 | 32.17 | 36.74 | 65.78 | 27.46 | 41.61 |\n| 128 | 19.97 | 51.05 | 56.97 | 32.40 | 37.92 | 66.70 | 29.86 | 42.12 |", "caption": "Table 11: Downstream results of training with or without load balancing.", "description": "\ud45c 11\uc740 \ub85c\ub4dc \ubc38\ub7f0\uc2f1\uc744 \uc801\uc6a9\ud588\uc744 \ub54c\uc640 \uc801\uc6a9\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c\uc758 \uc131\ub2a5 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ub85c\ub4dc \ubc38\ub7f0\uc2f1\uc740 Mixture-of-Experts (MoE) \ubaa8\ub378\uc5d0\uc11c \ud2b9\uc815 \uc804\ubb38\uac00\uc5d0\uac8c \uacfc\ub3c4\ud55c \uacc4\uc0b0 \ubd80\ud558\uac00 \uc9d1\uc911\ub418\ub294 \uac83\uc744 \ubc29\uc9c0\ud558\ub294 \uae30\ubc95\uc785\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 \ub2e4\uc591\ud55c \ud558\uc704 \uc791\uc5c5(downstream tasks)\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\ub97c \ube44\uad50\ud558\uc5ec \ub85c\ub4dc \ubc38\ub7f0\uc2f1\uc758 \ud6a8\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub85c\ub4dc \ubc38\ub7f0\uc2f1\uc744 \uc801\uc6a9\ud55c MoE\uc640 ReMoE \ubaa8\ub378\uc774 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \ubcf4\uc774\ub294\uc9c0, \uadf8\ub9ac\uace0 \ub85c\ub4dc \ubc38\ub7f0\uc2f1\uc758 \uc720\ubb34\uc5d0 \ub530\ub77c \uc131\ub2a5 \ucc28\uc774\uac00 \uc5bc\ub9c8\ub098 \ub098\ub294\uc9c0\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.4 Load Balancing Ablations"}, {"content": "| Model | G | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---|\n| Dense | - | 19.45 | 43.35 | 54.40 | 28.61 | 31.09 | 61.97 | 28.52 | 38.20 |\n| Dense \u00d7 8 | - | 22.78 | 48.11 | 59.66 | 31.11 | 35.65 | 65.02 | 29.57 | 41.70 |\n| MoE 1 | 1 | 20.82 | 45.03 | 57.55 | 29.84 | 31.81 | 63.28 | 28.42 | 39.53 |\n| MoE 2 | 2 | 21.42 | 46.55 | 54.25 | 29.95 | 32.52 | 64.09 | 28.61 | 39.62 |\n| MoE 4 | 4 | 20.99 | 46.09 | 55.90 | 30.52 | 35.16 | 63.98 | 29.28 | 40.27 |\n| MoE 8 | 8 | 21.59 | 47.73 | 60.70 | 30.83 | 36.41 | 64.69 | 28.04 | 41.42 |\n| MoE 16 | 16 | 19.80 | 48.82 | 57.34 | 30.64 | 36.00 | 64.74 | 28.71 | 40.86 |\n| MoE 32 | 32 | 21.67 | 48.78 | 57.85 | 31.27 | 37.10 | 64.69 | 28.52 | 41.41 |\n| MoE 64 | 64 | 20.14 | 48.74 | 61.50 | 31.03 | 36.31 | 63.93 | 27.85 | 41.35 |\n| ReMoE 1 | 1 | 20.22 | 46.68 | 54.16 | 30.26 | 35.94 | 63.55 | 29.38 | 40.03 |\n| ReMoE 2 | 2 | 20.14 | 47.39 | 57.95 | 30.60 | 34.52 | 63.71 | 28.52 | 40.40 |\n| ReMoE 4 | 4 | 20.39 | 47.94 | 55.35 | 31.04 | 36.11 | 64.64 | 29.00 | 40.64 |\n| ReMoE 8 | 8 | 20.82 | 48.36 | 60.49 | 30.90 | 36.06 | 63.87 | 28.90 | 41.34 |\n| ReMoE 16 | 16 | 21.25 | 49.41 | 56.06 | 30.91 | 36.23 | 64.91 | 29.95 | 41.25 |\n| ReMoE 32 | 32 | 20.90 | 48.86 | 55.81 | 31.14 | 36.58 | 64.69 | 30.05 | 41.15 |\n| ReMoE 64 | 64 | 20.65 | 48.74 | 60.06 | 31.56 | 36.43 | 65.40 | 29.00 | 41.69 |", "caption": "Table 12: Routed tokens with high probability for experts in Layer 5 of ReMoE", "description": "\ubcf8 \ud45c\ub294 ReMoE \ubaa8\ub378\uc758 5\ubc88\uc9f8 \ub808\uc774\uc5b4\uc5d0\uc11c \ud2b9\uc815 \uc804\ubb38\uac00(expert)\uc5d0 \ub192\uc740 \ud655\ub960\ub85c \ub77c\uc6b0\ud305(routing)\ub418\ub294 \ud1a0\ud070\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc804\ubb38\uac00\ub294 \ud2b9\uc815 \ub3c4\uba54\uc778(\uc608: Arxiv, Books, C4, Github, StackExchange, Wikipedia)\uacfc \uad00\ub828\ub41c \ub2e8\uc5b4\ub4e4\uc744 \uc8fc\ub85c \ucc98\ub9ac\ud558\ub294 \uacbd\ud5a5\uc744 \ubcf4\uc774\uba70, \uc774\ub294 ReMoE \ubaa8\ub378\uc774 \uc804\ubb38\uac00\ub4e4\uc744 \ub3c4\uba54\uc778\ubcc4\ub85c \ud2b9\ud654\uc2dc\ucf1c \ud559\uc2b5\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\ub294 \uc804\ubb38\uac00 ID\uc640 \ud568\uaed8 \ud574\ub2f9 \uc804\ubb38\uac00\uc5d0 \ub192\uc740 \ud655\ub960\ub85c \ub77c\uc6b0\ud305\ub418\ub294 \ud1a0\ud070\ub4e4\uc758 \ubaa9\ub85d\uc744 \uc81c\uc2dc\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \uc804\ubb38\uac00 1\uc740 'husband', 'wife', 'baby' \uc640 \uac19\uc740 \ub2e8\uc5b4\ub4e4\uc744 \uc8fc\ub85c \ucc98\ub9ac\ud558\uba70, \uc804\ubb38\uac00 6\uc740 'variable', 'env', 'HEAD' \uc640 \uac19\uc740 \ub2e8\uc5b4\ub4e4\uc744 \uc8fc\ub85c \ucc98\ub9ac\ud569\ub2c8\ub2e4. \uc774\ub294 ReMoE\uc758 \ub3c4\uba54\uc778 \ud2b9\ud654 \uae30\ub2a5\uc744 \uc798 \ubcf4\uc5ec\uc8fc\ub294 \uc0ac\ub840\uc785\ub2c8\ub2e4.", "section": "5.3 \ub3c4\uba54\uc778 \ud2b9\ud654 ReMoE\uc5d0\uc11c"}, {"content": "| Model | LB | ARC-c | ARC-e | BoolQ | HellaSwag | LAMBADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| Dense | - | 19.45 | 43.35 | 54.40 | 28.61 | 31.09 | 61.97 | 28.52 | 38.20 |\n| MoE | \u00d7 | 19.20 | 44.74 | 50.80 | 28.60 | 30.18 | 62.24 | 27.94 | 37.67 |\n| MoE | \u2713 | 20.05 | 45.16 | **57.83** | 29.83 | 32.97 | **63.55** | 28.33 | 39.67 |\n| ReMoE | \u00d7 | 19.45 | 46.34 | 56.94 | 30.19 | 31.79 | 63.33 | 28.61 | 39.52 |\n| ReMoE | \u2713 | **20.22** | **46.68** | 54.16 | **30.26** | **35.94** | **63.55** | **29.38** | **40.03** |", "caption": "Table 13: Performance of MoE with near-dense warmup", "description": "\uc774 \ud45c\ub294 \uadfc-\uc870\ubc00(near-dense) \uc6cc\ubc0d\uc5c5\uc744 \uc0ac\uc6a9\ud55c MoE \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'MoE with warmup' \uc5f4\uc740 \ud6c8\ub828 \ucd08\uae30\uc5d0 \ub300\ubd80\ubd84\uc758 \uc804\ubb38\uac00(expert)\uac00 \ud65c\uc131\ud654\ub418\ub3c4\ub85d \ud558\uc5ec MoE \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0a8 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc774\ub294 ReMoE\uc758 \ud6c8\ub828 \uacfc\uc815\uc5d0\uc11c \ucc98\uc74c \ub450 \ub2e8\uacc4\uc640 \uc720\uc0ac\ud569\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uc6cc\ubc0d\uc5c5 \uae30\ubc95\uc744 \uc801\uc6a9\ud55c MoE\uc640 \uae30\ubcf8 MoE, ReMoE\uc758 \uac80\uc99d \uc190\uc2e4(validation loss) \ubc0f \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \uc791\uc5c5\uc758 \uc815\ud655\ub3c4\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70, ReMoE\uac00 \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc6b0\uc218\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. EXPERIMENTS > H TRAINING MOE WITH NEAR-DENSE WARMUP"}, {"content": "| Expert ID | Routed Tokens With High Probability |\n|---|---| \n| 0 | `End`(100%); `folding`(100%); `Fill`(100%); `FILE`(100%); `NULL`(100%); `byte`(100%); `Release`(99.36%); `Del`(99.80%) |\n| 1 | `husband`(100%); `ife`(100%); `baby`(100%); `human`(100%); `lover`(99.60%); `.`(99.86%); `),`(99.71%); `)...`(98.425%) |\n| 2 | `invest`(100%); `Fortune`(100%); `exec` (100%); `0000`(100%); `Sorry`(100%); `bye`(97.82%); `If`(97.74%); `\u00ae`(97.63%) |\n| 3 | `Conversely`(100%); `Methods`(100%); `flower`(100%); `Blossom`(99.93%); `Argentina`(100%); `Georgian`(100%); `Uruguay`(98.90%); `African` (100%) |\n| 4 | `Spring`(100%); `Summer`(100%) `Autumn`(100%); `Winter`(100%); `seasons`(99.02%); `Temperature` (100%); `hot`(97.98%); `cold`(100%) |\n| 5 | `\u00e8`(100%); `\u00e6`(99.80%); `\u00e5`(98.59%); `\u00c6`(97.67%) |\n| 6 | `]);`(100%); `gif`(100%); `size`(100%); `variable`(100%); `env`(100%); `begin`(97.95%); `HEAD`(97.94%); `|`(97.83%) |\n| 7 | `Kuala`(100%); `Tus`(100%); `Lama`(100%); `Riley`(98.94%) |", "caption": "Table 14: Results for MoE with warmup under different expert count E\ud835\udc38Eitalic_E", "description": "\ud45c 14\ub294 \ub2e4\uc591\ud55c \uc804\ubb38\uac00 \uc218(E)\uc5d0 \ub530\ub978 \uc6cc\ubc0d\uc5c5 \uacfc\uc815\uc744 \uac70\uce5c MoE \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\uc5d0\uc11c \ud65c\uc131\ud654\ub418\ub294 \uc804\ubb38\uac00 \uc218\ub97c \uc870\uc815\ud558\uc5ec MoE \ubaa8\ub378\uc758 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c \ubc1c\uc0dd\ud558\ub294 \uacc4\uc0b0 \ube44\uc6a9\uc744 ReMoE \ubaa8\ub378\uacfc \uc720\uc0ac\ud558\uac8c \ub9de\ucd94\uc5c8\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 MoE \ubaa8\ub378\uc758 \uac80\uc99d \uc190\uc2e4\uacfc \uc815\ud655\ub3c4\uac00 E \uac12\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud558\ub294\uc9c0, \uadf8\ub9ac\uace0 ReMoE \ubaa8\ub378\uacfc\uc758 \uc131\ub2a5 \ucc28\uc774\uac00 \uc5b4\ub5bb\uac8c \ub098\ud0c0\ub098\ub294\uc9c0\uac00 \uc694\uc57d\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\ub97c \ud1b5\ud574 MoE \ubaa8\ub378\uc758 \uc131\ub2a5\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc9c0\ub9cc, ReMoE \ubaa8\ub378\uc740 \uc5ec\uc804\ud788 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uc804\ubb38\uac00 \uc218\uac00 \uc99d\uac00\ud560\uc218\ub85d ReMoE\uc758 \uc6b0\uc218\uc131\uc774 \ub354\uc6b1 \ub450\ub4dc\ub7ec\uc9d1\ub2c8\ub2e4.", "section": "4.3 ReMoE\uc758 \ud655\uc7a5\uc131"}, {"content": "| Model | Valid Loss | ARC-c | ARC-e | BoolQ | HellaSwag | LAM-BADA | PIQA | RACE | Avg. |\n|---|---|---|---|---|---|---|---|---|---| \n| MoE | 1.936 | 20.82 | 45.03 | 57.55 | 29.84 | 31.81 | 63.28 | 28.42 | 39.53 |\n| MoE with warmup | 1.928 | 20.73 | 46.38 | 52.35 | 30.28 | 33.90 | 63.76 | 27.66 | 39.29 |\n| ReMoE | 1.921 | 20.22 | 46.68 | 54.16 | 30.26 | 35.94 | 63.55 | 29.38 | 40.03 |", "caption": "Table 15: Final validation loss of MoE with different warmup steps", "description": "\ud45c 15\ub294 \ub2e4\uc591\ud55c \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\ub97c \uc0ac\uc6a9\ud55c MoE\uc758 \ucd5c\uc885 \uac80\uc99d \uc190\uc2e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc774 \ud45c\ub294  MoE \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0ac \ub54c, \ucc98\uc74c\uc5d0 \ub300\ubd80\ubd84\uc758 \uc804\ubb38\uac00\ub97c \ud65c\uc131\ud654\ud558\ub294 '\uac70\uc758 \uc870\ubc00\ud55c' \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\ub97c \ucd94\uac00\ud558\ub294 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774\ub294 ReMoE\uc758 3\ub2e8\uacc4 \ud6c8\ub828 \uacfc\uc815\uacfc \ube44\uc2b7\ud558\uac8c, \ud6c8\ub828 \ucd08\uae30\uc5d0 \ubaa8\ub378\uc774 \ub354 \uc870\ubc00\ud55c \uc0c1\ud0dc\ub85c \uc2dc\uc791\ud558\ub3c4\ub85d \ud558\uc5ec \uc131\ub2a5\uc744 \uac1c\uc120\ud558\ub294\uc9c0 \ud655\uc778\ud558\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4. \ud45c\uc5d0\ub294 \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\uc758 \uc218(0, 50, 100, 500, 1000)\uc5d0 \ub530\ub978 MoE \ubaa8\ub378\uc758 \ucd5c\uc885 \uac80\uc99d \uc190\uc2e4\uc774 \ub098\uc640 \uc788\uc73c\uba70, ReMoE \ubaa8\ub378\uc758 \ucd5c\uc885 \uac80\uc99d \uc190\uc2e4\ub3c4 \ube44\uad50\ub97c \uc704\ud574 \ud568\uaed8 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc6cc\ubc0d\uc5c5 \ub2e8\uacc4\uc758 \uae38\uc774\uac00 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 \ubd84\uc11d\ud558\uace0, ReMoE\uc758 \ud6c8\ub828 \uc804\ub7b5\uc758 \ud6a8\uc728\uc131\uc744 \ud3c9\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "H. NEAR-DENSE WARMUP\uc744 \uc0ac\uc6a9\ud55c MoE \ud6c8\ub828"}]