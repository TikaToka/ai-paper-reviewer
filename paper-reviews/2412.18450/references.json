{"references": [{"fullname_first_author": "Ziqin Wang", "paper_title": "VL-SAT: Visual-linguistic semantics assisted training for 3d semantic scene graph prediction in point cloud", "publication_date": "2023-00-00", "reason": "This paper proposes VL-SAT, a method for generating 3D semantic scene graphs from point clouds, which is a key component of the proposed 3DGraphLLM model."}, {"fullname_first_author": "Justin Johnson", "paper_title": "Image retrieval using scene graphs", "publication_date": "2015-00-00", "reason": "This foundational paper introduces the concept of scene graphs for image understanding, providing a basis for extending the concept to 3D scenes."}, {"fullname_first_author": "Dave Zhenyu Chen", "paper_title": "ScanRefer: 3d object localization in rgb-d scans using natural language", "publication_date": "2020-00-00", "reason": "This paper introduces the ScanRefer dataset, a benchmark dataset used in the paper's experiments for evaluating 3D vision-language tasks."}, {"fullname_first_author": "Zhenyu Chen", "paper_title": "Scan2Cap: Context-aware dense captioning in rgb-d scans", "publication_date": "2021-00-00", "reason": "This paper introduces the Scan2Cap dataset, another benchmark dataset used for evaluating 3D scene captioning performance."}, {"fullname_first_author": "Daichi Azuma", "paper_title": "ScanQA: 3d question answering for spatial scene understanding", "publication_date": "2022-00-00", "reason": "This paper introduces the ScanQA dataset, which is used for evaluating 3D visual question answering capabilities, a key task in 3D scene understanding."}]}