[{"figure_path": "https://arxiv.org/html/2412.15191/x2.png", "caption": "Figure 1: Compared to current Video-to-Audio and Audio-to-Video methods, AV-Link provides a unified framework for these two tasks. Rather than relying on feature extractors pretrained for other tasks (e.g.\u00a0CLIP\u00a0[63], CLAP\u00a0[16]), we directly leverage the activations from pretrained frozen Flow Matching models using a Fusion Block to achieve precise time alignment between modalities. Our approach offers competitive semantic alignment and improved temporal alignment in a self-contained framework for both modalities.", "description": "\ubcf8 \uadf8\ub9bc\uc740 \uae30\uc874\uc758 Video-to-Audio \ubc0f Audio-to-Video \ubc29\uc2dd\uacfc \ube44\uad50\ud558\uc5ec AV-Link\uac00 \ub450 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud1b5\ud569 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uacf5\ud558\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  AV-Link\ub294 CLIP\uc774\ub098 CLAP\uacfc \uac19\uc740 \ub2e4\ub978 \uc791\uc5c5\uc744 \uc704\ud574 \ubbf8\ub9ac \ud559\uc2b5\ub41c \ud2b9\uc9d5 \ucd94\ucd9c\uae30\ub97c \uc0ac\uc6a9\ud558\ub294 \ub300\uc2e0, \ubbf8\ub9ac \ud559\uc2b5\ub41c \uace0\uc815\ub41c Flow Matching \ubaa8\ub378\uc758 \ud65c\uc131\ud654\ub97c Fusion Block\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud65c\uc6a9\ud568\uc73c\ub85c\uc368 \ubaa8\ub2ec \uac04\uc758 \uc815\ud655\ud55c \uc2dc\uac04 \uc815\ub82c\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uacbd\uc7c1\ub825 \uc788\ub294 \uc758\ubbf8\uc801 \uc815\ub82c\uacfc \ud5a5\uc0c1\ub41c \uc2dc\uac04\uc801 \uc815\ub82c\uc744 \uc790\uccb4\uc801\uc73c\ub85c \ud3ec\ud568\ud558\ub294 \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.15191/x3.png", "caption": "Figure 2: Design of the proposed Fusion Block connecting the frozen video and audio backbones. A RoPE-based temporal alignment mechanism establishes correspondences between modalities that are leveraged by self attention. Video and audio features are symmetrically reinjected into the frozen generators. The block is regularly applied multiple times throughout the backbones.", "description": "\uadf8\ub9bc 2\ub294 \ub3d9\uacb0\ub41c \ube44\ub514\uc624 \ubc0f \uc624\ub514\uc624 \ubc31\ubcf8\uc744 \uc5f0\uacb0\ud558\ub294 \uc81c\uc548\ub41c \uc735\ud569 \ube14\ub85d\uc758 \uc124\uacc4\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. RoPE \uae30\ubc18 \uc2dc\uac04 \uc815\ub82c \uba54\ucee4\ub2c8\uc998\uc740 \uc5ec\ub7ec \ubaa8\ub2ec\ub9ac\ud2f0 \uac04\uc758 \ub300\uc751 \uad00\uacc4\ub97c \uc124\uc815\ud558\uace0, \uc774\ub294 \uc790\uae30 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998\uc5d0 \uc758\ud574 \ud65c\uc6a9\ub429\ub2c8\ub2e4. \ube44\ub514\uc624 \ubc0f \uc624\ub514\uc624 \uae30\ub2a5\uc740 \ub300\uce6d\uc801\uc73c\ub85c \ub3d9\uacb0\ub41c \uc0dd\uc131\uae30\uc5d0 \uc7ac\uc8fc\uc785\ub429\ub2c8\ub2e4. \uc774 \ube14\ub85d\uc740 \ubc31\ubcf8 \uc804\uccb4\uc5d0 \uac78\uccd0 \uc5ec\ub7ec \ubc88 \uc815\uae30\uc801\uc73c\ub85c \uc801\uc6a9\ub429\ub2c8\ub2e4.  \uc774 \uadf8\ub9bc\uc740 \ub2e8\uc21c\ud788 \ub450 \ubaa8\ub2ec\ub9ac\ud2f0\uc758 \ud2b9\uc9d5\uc744 \uacb0\ud569\ud558\ub294 \uac83\uc774 \uc544\ub2c8\ub77c, RoPE \uae30\ubc18 \uc2dc\uac04 \uc815\ub82c \uba54\ucee4\ub2c8\uc998\uc744 \ud1b5\ud574 \uc2dc\uac04\uc801 \uc77c\uad00\uc131\uc744 \uc720\uc9c0\ud558\uba74\uc11c, \uc790\uae30 \uc8fc\uc758 \uba54\ucee4\ub2c8\uc998\uc744 \uc774\uc6a9\ud558\uc5ec \uc11c\ub85c \uc0c1\ud638 \uc791\uc6a9\ud558\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ub300\uce6d\uc801\uc778 \uc7ac\uc8fc\uc785\uc740 \ub450 \ubaa8\ub2ec\ub9ac\ud2f0 \uac04\uc758 \uc815\ubcf4 \ud750\ub984\uc744 \uade0\ud615 \uc788\uac8c \uc720\uc9c0\ud558\ub294 \ub370 \uae30\uc5ec\ud569\ub2c8\ub2e4.", "section": "3.3. Multimodal Fusion Block"}, {"figure_path": "https://arxiv.org/html/2412.15191/x4.png", "caption": "Figure 3: Visualization of Audio-to-Video and Video-to-Audio generation performance for various value of flow timesteps t\ud835\udc61titalic_t for conditioning features. Best performance is achieved when conditioning features are close to be fully denoised, i.e. t\u2208[0.8,0.98]\ud835\udc610.80.98t\\in[0.8,0.98]italic_t \u2208 [ 0.8 , 0.98 ].", "description": "\uadf8\ub9bc 3\uc740 \uc624\ub514\uc624-\ube44\ub514\uc624 \uc0dd\uc131\uc5d0\uc11c \uc870\uac74 \uc124\uc815 \ud2b9\uc9d5\uc744 \uc704\ud55c \ub2e4\uc591\ud55c \ud750\ub984 \uc2dc\uac04 \ub2e8\uacc4(t)\uc5d0 \ub530\ub978 \uc624\ub514\uc624-\ube44\ub514\uc624 \uc0dd\uc131 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uacb0\uacfc\uc801\uc73c\ub85c, \uc870\uac74 \uc124\uc815 \ud2b9\uc9d5\uc774 \uc644\uc804\ud788 \uc7a1\uc74c\uc774 \uc81c\uac70\ub41c \uc0c1\ud0dc\uc5d0 \uac00\uae4c\uc6b8 \ub54c(\uc989, t\uac00 0.8\uc5d0\uc11c 0.98 \uc0ac\uc774\uc77c \ub54c) \ucd5c\uc0c1\uc758 \uc131\ub2a5\uc744 \ub2ec\uc131\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc7a1\uc74c \uc81c\uac70 \uacfc\uc815\uc774 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c \uc0dd\uc131 \ubaa8\ub378\uc774 \ub354\uc6b1 \uc815\ud655\ud558\uace0 \ud6a8\uacfc\uc801\uc778 \uc870\uac74 \uc124\uc815 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.15191/x5.png", "caption": "Figure 4: Qualitative V2A results. Our model achieved the best temporal alignment, matching closely the \u201cbouncing\u201d and \u201cdrumming\u201d sounds entailed by the video modality. See the Appendix and Website for additional results.", "description": "\uadf8\ub9bc 4\ub294 \uc81c\uc548\ub41c AV-Link \ubaa8\ub378\uacfc \uae30\uc874 \ube44\ub514\uc624-\uc624\ub514\uc624 \uc0dd\uc131 \ubaa8\ub378\ub4e4\uc758 \ube44\uad50 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uc815\uc131\uc801 \ubd84\uc11d \uacb0\uacfc\uc785\ub2c8\ub2e4.  AV-Link \ubaa8\ub378\uc740 \"\uacf5\ub180\uc774\"\uc640 \"\ubd81\uc18c\ub9ac\"\uc640 \uac19\uc740 \ube44\ub514\uc624\uc758 \uc2dc\uac01\uc801 \uc694\uc18c\uc5d0 \ub530\ub978 \uc18c\ub9ac\uc758 \ubc1c\uc0dd \uc2dc\uc810\uc744 \uc815\ud655\ud558\uac8c \ub9de\ucdb0 \ucd5c\uace0 \uc218\uc900\uc758 \uc2dc\uac04\uc801 \uc815\ud569\uc131\uc744 \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4.  \uae30\uc874 \ubaa8\ub378\ub4e4\uc740 \uc2dc\uac01\uc801 \uc694\uc18c\uc640 \uc18c\ub9ac\uc758 \uc2dc\uac04\uc801 \uc815\ud569\uc131\uc774 \ub5a8\uc5b4\uc9c0\ub294 \ubaa8\uc2b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubd80\ub85d\uacfc \uc6f9\uc0ac\uc774\ud2b8\uc5d0\uc11c \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. \uc2e4\ud5d8 \uacb0\uacfc"}, {"figure_path": "https://arxiv.org/html/2412.15191/x6.png", "caption": "Figure 5: Qualitative A2V results. Our model generates semantically and temporally aligned content showing to the \u201cexplosions\u201d and \u201cdrumming\u2192\u2192\\rightarrow\u2192silence\u2192\u2192\\rightarrow\u2192drumming\u201d events implied by the audio modality. We show 3.3s of our samples at 3 FPS while only 2s of TempoTokens samples, hence the difference in frame count. See the Appendix and Website for additional results.", "description": "\uadf8\ub9bc 5\ub294 \uc81c\uc548\ub41c AV-Link \ubaa8\ub378\uacfc TempoTokens \ubaa8\ub378\uc758 A2V(Audio-to-Video) \uc131\ub2a5\uc744 \ube44\uad50\ud55c \uc815\uc131\uc801 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. AV-Link \ubaa8\ub378\uc740 \uc785\ub825 \uc624\ub514\uc624 \uc2e0\ud638\uc5d0 \ub2f4\uae34 \uc758\ubbf8(\ud3ed\ubc1c, \ubd81\uc18c\ub9ac-\uc815\uc801-\ubd81\uc18c\ub9ac)\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \uc798 \ud45c\ud604\ud558\uace0 \uc788\uc73c\uba70, \uc2dc\uac04\uc801 \uc815\ub82c \ub610\ud55c \ub9e4\uc6b0 \uc815\ud655\ud569\ub2c8\ub2e4.  TempoTokens \uacb0\uacfc\uc640 \ube44\uad50\ud588\uc744 \ub54c, AV-Link\ub294 \ub354\uc6b1 \uc790\uc5f0\uc2a4\ub7fd\uace0 \uc77c\uad00\uc131 \uc788\ub294 \ube44\ub514\uc624\ub97c \uc0dd\uc131\ud558\uba70, \uc2dc\uac04\uc801 \uc77c\uce58\uc131\uc774 \ud6e8\uc52c \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4.  AV-Link\uc758 \uc0d8\ud50c\uc740 3FPS\ub85c 3.3\ucd08 \ubd84\ub7c9\uc744 \ubcf4\uc5ec\uc8fc\uc9c0\ub9cc, TempoTokens\ub294 2\ucd08 \ubd84\ub7c9\ub9cc \ud45c\uc2dc\ub418\uc5b4 \ud504\ub808\uc784 \uc218 \ucc28\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4. \ubd80\ub85d\uacfc \uc6f9\uc0ac\uc774\ud2b8\uc5d0\uc11c \ucd94\uac00\uc801\uc778 \uacb0\uacfc\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4.3 Results"}, {"figure_path": "https://arxiv.org/html/2412.15191/x7.png", "caption": "Figure 6: Comparison between different parametrizations for the Logit-Normal training distributions ptsubscript\ud835\udc5d\ud835\udc61p_{t}italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT for the flow timestep t\ud835\udc61titalic_t. When the location (i.e. the mean of the normal distribution) is shifted towards higher noise levels, we observe faster model convergence.", "description": "\uc774 \uadf8\ub9bc\uc740 \ud750\ub984 \uc2dc\uac04 \ub2e8\uacc4(t)\uc5d0 \ub300\ud55c \ub85c\uadf8-\uc815\uaddc \ubd84\ud3ec(Logit-Normal distribution) \ud835\udc5d\ud835\udc61(pt)\uc758 \ub9e4\uac1c\ubcc0\uc218\ud654\uc5d0 \ub530\ub978 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub85c\uadf8-\uc815\uaddc \ubd84\ud3ec\uc758 \uc704\uce58(\uc989, \uc815\uaddc \ubd84\ud3ec\uc758 \ud3c9\uade0)\uac00 \ub354 \ub192\uc740 \ub178\uc774\uc988 \uc218\uc900\uc73c\ub85c \uc774\ub3d9\ud568\uc5d0 \ub530\ub77c \ubaa8\ub378\uc758 \uc218\ub834 \uc18d\ub3c4\uac00 \ube68\ub77c\uc9c0\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc989, \ub178\uc774\uc988\uac00 \ub9ce\uc740 \uc0d8\ud50c\uc5d0\uc11c \ud559\uc2b5\uc744 \uc2dc\uc791\ud558\ub294 \uac83\uc774 \ubaa8\ub378\uc758 \ud559\uc2b5 \uc18d\ub3c4\ub97c \ub192\uc774\ub294 \ub370 \ud6a8\uacfc\uc801\uc784\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "D.1 \ub178\uc774\uc988 \uc0d8\ud50c\ub9c1 \uc2a4\ucf00\uc904\ub7ec"}, {"figure_path": "https://arxiv.org/html/2412.15191/x8.png", "caption": "Figure 7: Qualitative V2A results comparing our method to baselines on in-the-wild videos captured by the authors that require precise temporal alignment. AV-Link produces audio signals that closely align to the visual modalities, while baselines often produce audio that is unrelated or not correctly synchronized with the visual content. See the Website for more results.", "description": "\uadf8\ub9bc 7\uc740 \uc5f0\uad6c\uc9c4\uc774 \uc9c1\uc811 \ucd2c\uc601\ud55c \uc2e4\uc81c \uc601\uc0c1\uc744 \uc0ac\uc6a9\ud558\uc5ec, \uc815\ud655\ud55c \uc2dc\uac04\uc801 \uc815\ub82c\uc774 \ud544\uc694\ud55c \ube44\ub514\uc624-\uc624\ub514\uc624 \uc0dd\uc131 \uc791\uc5c5\uc5d0\uc11c \uc81c\uc548\ub41c \ubc29\ubc95\uacfc \uae30\uc874 \ubc29\ubc95\ub4e4\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  AV-Link\ub294 \uc2dc\uac01\uc801 \ubaa8\ub4dc\uc640 \ubc00\uc811\ud558\uac8c \uc77c\uce58\ud558\ub294 \uc624\ub514\uc624 \uc2e0\ud638\ub97c \uc0dd\uc131\ud558\uc9c0\ub9cc, \uae30\uc874 \ubc29\ubc95\ub4e4\uc740 \uad00\ub828\uc774 \uc5c6\ub294 \uc624\ub514\uc624\ub098 \uc2dc\uac01\uc801 \ucf58\ud150\uce20\uc640 \ub3d9\uae30\ud654\ub418\uc9c0 \uc54a\uc740 \uc624\ub514\uc624\ub97c \uc0dd\uc131\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc2b5\ub2c8\ub2e4.  \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc6f9\uc0ac\uc774\ud2b8\ub97c \ucc38\uc870\ud558\uc2ed\uc2dc\uc624.", "section": "4.3. \uacb0\uacfc"}]