<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs &#183; AI Paper Reviews by AI</title>
<meta name=title content="GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs &#183; AI Paper Reviews by AI"><meta name=description content="GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다."><meta name=keywords content="Computer Vision,3D Vision,🏢 Hong Kong University of Science and Technology,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs"><meta property="og:description" content="GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2024-12-15T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-15T00:00:00+00:00"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="3D Vision"><meta property="article:tag" content="🏢 Hong Kong University of Science and Technology"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"><meta name=twitter:title content="GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs"><meta name=twitter:description content="GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs","headline":"GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs","abstract":"GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2412.11258\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2024","dateCreated":"2024-12-15T00:00:00\u002b00:00","datePublished":"2024-12-15T00:00:00\u002b00:00","dateModified":"2024-12-15T00:00:00\u002b00:00","keywords":["Computer Vision","3D Vision","🏢 Hong Kong University of Science and Technology"],"mainEntityOfPage":"true","wordCount":"2657"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About This Project">About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Paper Reviews by AI">Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About This Project">About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Paper Reviews by AI">Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2412.11258/cover_hu8886631986264939136.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2412.11258/>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-12-15T00:00:00+00:00>15 December 2024</time><span class="px-2 text-primary-500">&#183;</span><span>2657 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">13 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2412.11258/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2412.11258/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🤗 Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/computer-vision/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Computer Vision
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/3d-vision/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">3D Vision
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-hong-kong-university-of-science-and-technology/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🏢 Hong Kong University of Science and Technology</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#3d-gaussian-properties>3D Gaussian Properties</a></li><li><a href=#llm-driven-physics>LLM-Driven Physics</a></li><li><a href=#robotic-grasping>Robotic Grasping</a></li><li><a href=#dynamic-simulation>Dynamic Simulation</a></li><li><a href=#ambiguity-limits>Ambiguity Limits</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#3d-gaussian-properties>3D Gaussian Properties</a></li><li><a href=#llm-driven-physics>LLM-Driven Physics</a></li><li><a href=#robotic-grasping>Robotic Grasping</a></li><li><a href=#dynamic-simulation>Dynamic Simulation</a></li><li><a href=#ambiguity-limits>Ambiguity Limits</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2412.11258</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Xinli Xu et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>🤗 2024-12-17</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2412.11258 target=_self role=button>↗ arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2412.11258 target=_self role=button>↗ Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/gaussianproperty-integrating-physical target=_self role=button>↗ Papers with Code</a></p><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>시각 데이터에서 물리적 속성을 추정하는 것은 컴퓨터 비전, 그래픽 및 로봇 공학에서 중요한 작업으로, 증강 현실, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다양한 분야의 토대를 마련합니다. 그러나 레이블이 지정된 Ground-truth 데이터를 얻는 어려움, 예측 작업의 모호성 및 관찰 가능한 표면의 제한된 수로 인해 물리적 속성 추정은 여전히 어려운 과제입니다.</p><p>이 논문에서는 **LMM(Large Multimodal Models)**과 **SAM(Segment Anything)**을 사용하여 3D 가우시안에 물리적 속성을 할당하는 <strong>훈련 없는 프레임워크인 GaussianProperty</strong>를 제안합니다. <strong>GPT-4V(ision)의 인식 기능을 활용하여 2D 이미지에서 물리적 속성을 추정하고, 전역-지역 물리적 속성 추론 모듈을 사용하여 다양한 구성 요소의 속성을 정확하게 식별</strong>합니다. 그런 다음 다중 뷰 재구성 접근 방식과 투표 전략을 사용하여 이러한 속성을 3D 가우시안에 투영합니다. 이러한 주석이 달린 3D 가우시안은 물리 기반 동적 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 용이하게 합니다. <strong>이 방법은 재료 분할, 물리 기반 동적 시뮬레이션 및 로봇 쥐기를 포함한 광범위한 실험을 통해 검증</strong>되었으며, 최첨단 성능과 다운스트림 작업에 대한 이점을 보여줍니다.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-d22e927f37c9100344cc8f0034042cce></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-d22e927f37c9100344cc8f0034042cce",{strings:[" GaussianProperty는 LMM과 SAM을 활용하여 3D 가우시안에 물리적 속성을 할당하는 훈련 없는 프레임워크입니다. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-cbde87d7b3ab01837096a95fb27c1abc></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-cbde87d7b3ab01837096a95fb27c1abc",{strings:[" 물리적 속성 주석이 달린 3D 가우시안은 물리 기반 동적 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업에 사용할 수 있습니다. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-1389178fe1baf05ff34c91122914dd71></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-1389178fe1baf05ff34c91122914dd71",{strings:[" 이 프레임워크는 다양한 재료, 동적 시뮬레이션 및 실제 로봇 쥐기 실험에서 효과적임이 입증되었습니다. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p><strong>3D 모델에 물리적 속성을 통합하는 것은 AR, 로봇 공학, 시뮬레이션과 같은 다양한 분야에서 중요하지만, 본질적인 모호성으로 인해 어려움을 겪고 있습니다.</strong> 이 논문은 이러한 문제를 해결하는 훈련 없이 3D 가우시안에 물리적 속성을 할당하는 새로운 프레임워크인 GaussianProperty를 제시합니다. <strong>이 연구는 대규모 다중 모드 모델(LMM)을 활용하여 물리적 속성 추정을 위한 새로운 길을 열어줍니다.</strong> 또한 물리 기반 동적 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 위한 잠재적 응용 프로그램을 강조하여 추가 연구 및 개발을 위한 길을 열었습니다.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x1.png alt></figure></p><blockquote><p>🔼 GaussianProperty는 LMM의 도움을 받아 3D 가우시안에 물리적 속성을 추가하는 학습 없는 프레임워크입니다. 3D 가우시안에 물리적 속성을 할당함으로써 물리 기반 생성 역학 및 로봇 파지와 같은 여러 다운스트림 작업을 촉진합니다. 그림은 입력으로 다중 뷰 이미지를 사용하고 SAM을 사용하여 분할 맵을 생성한 다음 LMM을 사용하여 물리적 속성을 예측하는 방법을 보여줍니다. 그런 다음 이러한 속성이 3D 가우시안에 투영되어 물리 기반 시뮬레이션 및 로봇 파지와 같은 애플리케이션에 사용됩니다.</p><details><summary>read the caption</summary>Figure 1: GaussianProperty is a training-free framework, aiming at adding physical properties to 3D Gaussians with the assistance of LMMs. By assigning physical properties to 3D Gaussians, it promotes several downstream tasks such as physical-based generative dynamics and robot grasping in this work.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th style=text-align:left>· Method</th><th style=text-align:left>ABO dataset</th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left>MVImgNet</th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th><th style=text-align:left></th></tr></thead><tbody><tr><td style=text-align:left></td><td style=text-align:left>Wood</td><td style=text-align:left>Metal</td><td style=text-align:left>Plastic</td><td style=text-align:left>Fabric</td><td style=text-align:left>Ceramic</td><td style=text-align:left>Average</td><td style=text-align:left>Wood</td><td style=text-align:left>Metal</td><td style=text-align:left>Plastic</td><td style=text-align:left>Glass</td><td style=text-align:left>Fabric</td><td style=text-align:left>Foam</td><td style=text-align:left>Food</td><td style=text-align:left>Ceramic</td><td style=text-align:left>Paper</td><td style=text-align:left>Leather</td><td style=text-align:left>Average</td></tr><tr><td style=text-align:left>Nerf2phycics</td><td style=text-align:left>27.87</td><td style=text-align:left>13.01</td><td style=text-align:left>8.38</td><td style=text-align:left>40.26</td><td style=text-align:left>38.44</td><td style=text-align:left>25.59</td><td style=text-align:left>6.39</td><td style=text-align:left>3.63</td><td style=text-align:left>6.70</td><td style=text-align:left>1.15</td><td style=text-align:left>1.11</td><td style=text-align:left>0.38</td><td style=text-align:left>2.40</td><td style=text-align:left>6.54</td><td style=text-align:left>6.73</td><td style=text-align:left>5.20</td><td style=text-align:left>4.02</td></tr><tr><td style=text-align:left>Ours</td><td style=text-align:left><strong>61.53</strong></td><td style=text-align:left><strong>33.41</strong></td><td style=text-align:left><strong>38.26</strong></td><td style=text-align:left><strong>67.57</strong></td><td style=text-align:left><strong>78.40</strong></td><td style=text-align:left><strong>55.83</strong></td><td style=text-align:left><strong>41.96</strong></td><td style=text-align:left><strong>38.85</strong></td><td style=text-align:left><strong>39.50</strong></td><td style=text-align:left><strong>18.87</strong></td><td style=text-align:left><strong>27.12</strong></td><td style=text-align:left><strong>23.18</strong></td><td style=text-align:left><strong>84.89</strong></td><td style=text-align:left><strong>19.74</strong></td><td style=text-align:left><strong>30.23</strong></td><td style=text-align:left><strong>23.96</strong></td><td style=text-align:left><strong>34.83</strong></td></tr></tbody></table></table></figure><blockquote><p>🔼 NeRF2Physics [46] 와 ABO 및 MVImgNet 데이터 세트의 다양한 범주에서 재료 분할 비교. 저희 방법은 객체를 더욱 포괄적이고 정확하게 이해하고 더욱 정밀한 재료 분할을 달성합니다.</p><details><summary>read the caption</summary>Table 1: Comparison of material segmentation with NeRF2Physics [46] across different categories on ABO and MVImgNet dataset. Our method achieves a more comprehensive and accurate understanding of the object and achieve more precise material segmentation.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">3D Gaussian Properties<div id=3d-gaussian-properties class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3d-gaussian-properties aria-label=Anchor>#</a></span></h4><p><strong>3D 가우시안 속성</strong>은 3D 장면을 나타내는 강력한 방법으로, 각 가우시안은 중심, 공분산, 모양과 외관에 대한 추가 정보를 인코딩합니다. 이러한 속성은 <strong>물리 기반 시뮬레이션</strong>과 같은 다운스트림 작업에 매우 중요합니다. 예를 들어, <strong>강성</strong> 및 <strong>밀도</strong>와 같은 재료 속성을 3D 가우시안에 할당하면 사실적인 물리적 상호 작용을 시뮬레이션할 수 있습니다. 또한, <strong>질량</strong>, <strong>부피</strong>, <strong>마찰 계수</strong>와 같은 속성은 <strong>로봇 파지</strong>에 유용하여 로봇이 다양한 재료와 모양의 물체를 효과적으로 파지하는 데 필요한 힘을 추정할 수 있습니다. 또한 3D 가우시안을 사용하여 물체의 <strong>표면 속성</strong>(예: <strong>거칠기</strong>, <strong>질감</strong>)을 나타낼 수 있어 햅틱 피드백과 같은 응용 분야에 유용할 수 있습니다. <strong>3D 가우시안의 속성을 풍부하게 하면</strong> 장면 이해가 향상되고 로봇 공학 및 시뮬레이션과 같은 다양한 응용 분야에 대한 새로운 가능성이 열립니다.</p><h4 class="relative group">LLM-Driven Physics<div id=llm-driven-physics class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#llm-driven-physics aria-label=Anchor>#</a></span></h4><p><strong>LLM 기반 물리 엔진</strong>은 3D 모델에 물리적 속성을 부여하여 시뮬레이션과 로봇 조작을 향상시키는 새로운 패러다임입니다. 이는 전통적인 방법과 달리 데이터 기반 접근법을 사용하여 사전 지식 없이도 다양한 재료의 물리적 특성을 예측합니다. <strong>SAM과 GPT-4V</strong>의 조합은 객체의 부분별 분할 및 속성 매칭을 가능하게 하여 복잡한 장면에서도 정확한 물리적 속성 추정을 가능하게 합니다. <strong>멀티뷰 투영 및 투표 전략</strong>을 통해 2D 이미지에서 추출된 정보를 3D 가우시안으로 통합하여 일관성 있는 3D 표현을 생성합니다. 이러한 통합된 물리적 속성은 <strong>물리 기반 동적 시뮬레이션과 로봇 grasping</strong>에서 그 효과를 발휘합니다. 특히, 로봇 grasping에서는 LLM 기반 물리 엔진을 통해 재료에 따른 최적의 grasping force를 예측하여 안정적인 grasping을 가능하게 합니다. 하지만, 모호한 표면 질감을 가진 객체의 경우 정확한 재료 분류가 어려울 수 있다는 한계점이 있습니다. 향후 연구에서는 이러한 한계점을 해결하고 다양한 재료와 물리적 특성을 포괄하는 보다 포괄적인 물리 엔진 개발이 기대됩니다.</p><h4 class="relative group">Robotic Grasping<div id=robotic-grasping class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#robotic-grasping aria-label=Anchor>#</a></span></h4><p><strong>로봇 파지</strong>는 시각적 입력만으로 물체의 구성 재료를 예측하고 그에 따른 물리적 특성을 추정하여 물체에 맞는 파지력을 적용하는 기술입니다. 이는 <strong>재료에 따라 파지력을 조정해야 하는</strong> 어려움을 해결하여 <strong>다양한 재료의 물체를 효과적으로 파지</strong>할 수 있게 합니다. 기존의 고정된 파지력 접근 방식은 <strong>다양한 재료와 특성을 가진 물체에 대한 일반적인 적용에 한계</strong>가 있었습니다. GaussianProperty는 <strong>SAM의 분할 기능과 GPT-4V의 인식 기능을 결합</strong>하여 물체의 재료와 물리적 특성을 <strong>정확히 예측</strong>하고, <strong>MPM을 활용하여 물리 기반 동역학 시뮬레이션을 통해 현실적인 파지 과정을 구현</strong>합니다. 또한, 파지력 예측 모듈을 통해 물체의 변형을 방지하고 안정적인 파지를 위한 <strong>최적의 힘 범위를 추정</strong>합니다. 이러한 접근 방식은 <strong>로봇 및 산업 응용 분야 전반에 폭넓게 적용</strong>될 수 있는 <strong>잠재력</strong>을 가지고 있습니다.</p><h4 class="relative group">Dynamic Simulation<div id=dynamic-simulation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#dynamic-simulation aria-label=Anchor>#</a></span></h4><p><strong>동적 시뮬레이션</strong>은 물리적 속성을 3D 모델에 통합하여 사실적인 움직임과 상호 작용을 생성하는 핵심 기술입니다. 이 연구에서는 <strong>가우시안 속성</strong>이라는 새로운 방법을 통해 멀티뷰 2D 이미지에서 추정된 물리적 속성을 3D 가우시안에 할당하여 동적 시뮬레이션을 향상시킵니다. 기존 방법은 물리적 속성을 수동으로 할당해야 하는 비효율성이 있었지만, 가우시안 속성은 이러한 과정을 자동화하여 시뮬레이션 시간을 단축하고 복잡한 환경에서의 확장 가능한 응용을 가능하게 합니다. **물질점법(MPM)**을 활용하여 사실적인 물리적 상호작용을 구현하고, 예측된 속성을 시뮬레이션에 직접 적용하여 <strong>생성적 다이내믹스</strong>라는 새로운 가능성을 제시합니다. 이는 힘에 따른 물체의 움직임과 변형을 사실적으로 시뮬레이션하는 데 기여하며, 다양한 분야에서의 응용 가능성을 보여줍니다.</p><h4 class="relative group">Ambiguity Limits<div id=ambiguity-limits class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ambiguity-limits aria-label=Anchor>#</a></span></h4><p><strong>모호성 제한</strong>은 물리적 특성 추정의 주요 과제입니다. 시각적 정보만으로는 물체의 고유한 물리적 특성을 확실하게 파악하기 어려운 경우가 많습니다. 예를 들어, 같은 모양과 색상의 물체라도 재질이 다르면 무게나 밀도가 다를 수 있습니다. 또한, 물체의 표면이 제한적으로 보이는 경우, 가려진 부분의 특성을 추정하기가 더욱 어려워집니다. 이러한 모호성은 <strong>학습 데이터 부족과 결합</strong>되어 문제를 더욱 악화시킵니다. 물리적 특성에 대한 정확한 레이블이 지정된 데이터를 수집하는 것은 어렵고 비용이 많이 들기 때문에, 기존의 지도 학습 방법을 적용하기가 어렵습니다. 따라서 <strong>모호성을 해결</strong>하고 <strong>데이터 부족을 완화</strong>하는 효과적인 방법을 개발하는 것이 물리적 특성 추정의 핵심입니다. 이를 위해 다양한 시각적 단서와 사전 지식을 활용하고, 멀티모달 정보를 통합하는 방법 등이 연구되고 있습니다.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x2.png alt></figure></p><blockquote><p>🔼 GaussianProperty의 전체 파이프라인은 먼저 SAM을 사용하여 객체의 분할 맵을 얻습니다. 그런 다음 원본 이미지와 마스크를 GPT-4V(ision)과 같은 파운데이션 모델로 보내 재료 후보를 질의하여 해당 물리적 속성을 얻습니다. 2D 이미지에서 물리적 속성을 획득한 후 다중 뷰 접근 방식과 투표 전략을 사용하여 재구성된 3D 가우시안에 물리적 속성을 추가합니다.</p><details><summary>read the caption</summary>Figure 2: Overall pipeline. Our Gausssian-Property initially leverages SAM to get the segmentation map of the object. Then the original images and the masks are sent to the foundation models like GPT-4V(ision) to get the corresponding physical properties by inquiring the material candidates. After acquiring physical properties from 2D images, we using a multi-view approach and a voting strategy to add physical properties to the reconstruction 3D Gaussians.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x3.png alt></figure></p><blockquote><p>🔼 이 그림은 GPT-4V(ision)이 전역 및 부분 이미지 입력만으로 재질을 인식하는 데 어려움을 겪는다는 것을 보여줍니다(왼쪽). 그러나 전역-지역 정보와 연계를 결합하면 구성 요소의 속성을 정확하게 특징짓습니다(오른쪽). 왼쪽 이미지에서는 덤벨 전체 이미지와 손잡이 부분 이미지를 입력으로 제공했을 때 GPT-4V가 재질을 제대로 인식하지 못합니다. 오른쪽 이미지에서는 덤벨 전체 이미지, 손잡이 부분이 빨간색으로 강조된 분할 이미지, 손잡이 부분 이미지를 함께 입력으로 제공했을 때 GPT-4V가 손잡이 재질을 금속으로 정확하게 인식하는 것을 보여줍니다. 이는 전역-지역 정보와 연계를 활용하여 LMM의 인식 능력을 향상시키는 방법을 보여주는 예시입니다.</p><details><summary>read the caption</summary>Figure 3: Left: GPT-4V(ision) struggles to recognize the material when directly provided with both global and partial image inputs. Right: Enhanced with combined global-local information and association, the agent accurately characterizes the component’s properties.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x4.png alt></figure></p><blockquote><p>🔼 이 그림은 GaussianProperty가 다양한 객체에 대해 재료 분할을 수행한 결과를 보여줍니다. 각 객체의 부분별로 어떤 재료로 구성되어 있는지 예측한 결과를 시각적으로 표현하고 있습니다. 예측된 재료는 색상으로 구분되어 있으며, 경계가 명확하게 표시되어 높은 정확도를 보여줍니다. 제시된 예시들은 나무, 금속, 플라스틱, 고무, 천 등 다양한 재료를 포함하고 있으며, GaussianProperty가 복잡한 형태의 객체도 정확하게 분할할 수 있음을 나타냅니다.</p><details><summary>read the caption</summary>Figure 4: Qualitative results of Material Segmentation. Our model makes boundary-accurate physical material predictions.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x5.png alt></figure></p><blockquote><p>🔼 이 그림은 물리적 속성을 가진 3D 가우시안의 다운스트림 작업인 생성 역학을 보여줍니다. 힘을 가하면 3D 가우시안은 그에 상응하는 움직임을 생성합니다. 예를 들어 첫 번째 행에서 의자에 위에서 아래로 힘을 가했을 때 가해진 힘에 따라 의자가 움직이는 것을 보여줍니다. 의자, 베개, 쓰레기통과 같은 다양한 물체에 대한 시뮬레이션 결과가 표시됩니다. 정적 상태의 물체에 힘을 가하면 물리 기반 시뮬레이션을 통해 물체가 움직이거나 변형됩니다.</p><details><summary>read the caption</summary>Figure 5: Generative Dynamics. We present a potential downstream task of 3D Gaussians with physical property, i.e., the generative dynamics. By imposing force, the 3D Gaussians generate corresponding motion. For example, in the first row, we applied a top-down force, the chair exhibited a movement corresponding to the applied force.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x6.png alt></figure></p><blockquote><p>🔼 이 그림은 GaussianProperty를 로봇 파지 작업에 적용한 결과를 보여줍니다. 여러 물체에 대한 로봇 파지 실험의 샘플 결과가 제시되어 있으며, 제안된 방법(오른쪽 열)을 세 가지 기준선(중간 열)과 비교하고 초기 구성(왼쪽 열)을 보여줍니다. 기준선에는 최소 파지력(MinGF), 중간 파지력(MidGF), 최대 파지력(MaxGF)을 사용한 파지 전략이 포함됩니다. 제안된 방법은 물체의 재질 특성을 고려하여 파지력을 조정하는 반면, 기준선은 고정된 파지력을 사용합니다.</p><details><summary>read the caption</summary>Figure 6: Robot Grasping is a downstream application of GaussianProperty. Several sample cases from robot grasping experiments are presented, where we compare our proposed method (right) against three baselines (middle columns), starting from initial configurations (left).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x7.png alt></figure></p><blockquote><p>🔼 이 그림은 로봇 파지 실험에 사용된 로봇 플랫폼(왼쪽)과 로봇 그리퍼(오른쪽)를 보여줍니다. 로봇 플랫폼은 Jacobi.ai JSR-1 로봇 플랫폼이고, 로봇 그리퍼는 최대 40N의 파지력을 가진 TEK CTAG2F90-C 로봇 그리퍼입니다. 그리퍼 끝 부분의 힘 전달 면적은 0.00011m²이고, 최대 허용 굽힘 곡률은 0.5입니다.</p><details><summary>read the caption</summary>Figure 7: The robot platform (left) and the robotic gripper (right) utilized in robot grasping experiments.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x8.png alt></figure></p><blockquote><p>🔼 로봇 그리퍼의 파지력과 정규화된 입력값 간의 관계를 보여주는 그래프입니다. 왼쪽 그래프는 실제 측정값을, 가운데와 오른쪽 그래프는 각각 5차 다항식으로 부드럽게 처리한 결과를 나타냅니다. 최소 활성화 정규화 입력값이 존재하며, 로봇 그리퍼는 정규화 입력값 NGF가 15 이상일 때만 활성화됩니다.</p><details><summary>read the caption</summary>Figure 8: Calibration curve of robotic gripper grasping force (left) and its 5th-order polynomial smoothings (middle and right).</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x9.png alt></figure></p><blockquote><p>🔼 로봇 grasping 실험을 위해 선택된 16개의 물체 목록입니다. 이 컬렉션은 플라스틱, 세라믹, 종이, 강철, 나무, 유리 등 다양한 무게와 재질의 물체들을 포함합니다. 이러한 물체들은 일상생활에서 흔히 볼 수 있으며, 각 부분의 재질 특성도 매우 다양합니다. 따라서 재질 적응성을 고려하지 않은 단순한 grasping 전략은 이러한 모든 항목을 효과적이고 안전하게 파지하는 데 어려움을 겪을 수 있습니다.</p><details><summary>read the caption</summary>Figure 9: List of selected objects for robot grasping experiments.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x10.png alt></figure></p><blockquote><p>🔼 이 그림은 16개의 실제 물체에 대한 로봇 grasping 실험 결과를 보여줍니다. 제안된 방법(오른쪽 열)을 초기 구성(왼쪽 열)에서 시작하여 세 가지 기준선(중간 열)과 비교합니다. 성공적인 grasping은 물체를 미끄러지거나 손상시키거나 원치 않는 변형을 일으키지 않고 집어 올리는 것을 의미합니다. 프로젝트 페이지에서 실험 비디오를 볼 수 있습니다.</p><details><summary>read the caption</summary>Figure 10: Complete robot grasping experiment results. The 16 test cases along with results in robot grasping experiments are listed. We compare our proposed method (right) against three baselines (middle columns), starting from initial configurations (left). You can view the MP4 videos of the experiments in our project page.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x11.png alt></figure></p><blockquote><p>🔼 NeRF2Physics는 경계가 모호한 예측을 생성하는 반면 제안된 방법은 명확한 경계를 생성합니다. 즉, 제안된 방법은 경도 예측 정확도가 더 높습니다.</p><details><summary>read the caption</summary>Figure 11: Qualitative comparison of hardness prediction. Compared to NeRF2Physics, our method provides more accurate hardness prediction with clear boundaries.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x12.png alt></figure></p><blockquote><p>🔼 이 그림은 SAM(Segment Anything Model)을 사용하여 다양한 세분화 수준에서 이미지를 분할하는 과정을 보여줍니다. 왼쪽에서 오른쪽으로 입력 이미지, 큰 수준 분할, 중간 수준 분할, 작은 수준 분할이 표시됩니다. 큰 수준 분할은 객체 그룹화를 단순화하지만 세부 정보가 부족한 반면, 작은 수준 분할은 계산 복잡성을 높이면서 미세한 세부 정보를 캡처합니다. 객체 이해와 효율성 사이의 균형을 맞추기 위해 모델에서는 의미 있는 부분 수준 세부 정보를 유지하면서 과도한 조각화를 방지하는 중간 수준 분할을 선택했습니다.</p><details><summary>read the caption</summary>Figure 12: Segmentation process using SAM at different levels of granularity. From left to right: the input image, large-level segmentation, middle-level segmentation, and small-level segmentation. For our model, we selected the middle-level of SAM prediction to balance part-level object understanding and computational efficiency.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x13.png alt></figure></p><blockquote><p>🔼 이 그림은 ABO-500 데이터셋에서 가져온 객체들의 데이터 레이블링 예시를 보여줍니다. 의자, 탁자, 서랍장 등의 객체 일부분을 대화형 분할 도구를 사용하여 라벨링한 결과를 시각적으로 표현하고 있습니다. 각 객체 부분은 나무, 금속, 가죽 등의 재질에 따라 다른 색상으로 표시되어 있습니다.</p><details><summary>read the caption</summary>Figure 13: Examples of data labeling. These objects are sourced from the ABO-500 dataset.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x14.png alt></figure></p><blockquote><p>🔼 이 그림은 GPT-4V(ision)에 입력으로 제공되는 프롬프트의 예시를 보여줍니다. 이 프롬프트는 객체의 재질과 기타 물리적 특성(경도, 밀도, 영률, 푸아송 비 등)을 제안하는 데 사용됩니다. 프롬프트는 왼쪽 이미지(원본 이미지), 중간 이미지(부분 분할 다이어그램, 빨간색 마스크), 오른쪽 이미지(객체의 일부) 세 부분으로 구성됩니다. 먼저 객체의 일부에 대한 간략한 캡션을 제공하고, 객체의 재질을 설명하며, 마지막으로 객체의 재질과 물리적 특성을 예측합니다. 답변 형식은 (캡션, 재질, 경도 최소-최대, &lt;쇼어 A 또는 쇼어 D>, 밀도, 영률, 푸아송 비) 쌍으로 제공되어야 합니다. 재질 유형은 &lsquo;일반 재질 라이브러리&rsquo;에서 선택해야 합니다.</p><details><summary>read the caption</summary>Figure 14: Prompt used for proposing materials and other physical properties.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x15.png alt></figure></p><blockquote><p>🔼 이 그림은 빈도 기반 투표 전략의 효과를 보여주는 예시입니다. 투표 전략이 없으면 &lsquo;알루미늄&rsquo;과 &lsquo;나무&rsquo;가 각각 &lsquo;플라스틱&rsquo;과 &lsquo;강철&rsquo;로 잘못 분류됩니다. 빈도 기반 투표 전략을 사용하면 여러 시점에서 얻은 정보를 집계하여 일관성 있고 안정적인 예측을 보장합니다.</p><details><summary>read the caption</summary>Figure 15: Effects of Frequency-based Voting Strategy. We provide an example to demonstrate the effectiveness of the frequency-based voting strategy. The result misclassified the “aluminum” and “wood” into “plastic” and “’steel’ without voting strategy.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x16.png alt></figure></p><blockquote><p>🔼 이 그림은 ABO-500 데이터셋에서 가져온 객체들의 재질 분할 결과를 NeRF2Physics와 제안된 방법을 비교하여 보여줍니다. 제안된 방법이 NeRF2Physics보다 더 정확한 재질 분할 결과를 보여주고, 경계도 더 명확하게 구분하는 것을 확인할 수 있습니다. 예시로 제시된 객체들은 사다리, 의자, 소파, 화분, 벤치 등 다양한 재질로 이루어진 객체들입니다.</p><details><summary>read the caption</summary>Figure 16: Qualitative comparison of Material Segmentation. These objects are sourced from the ABO-500 dataset.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2412.11258/x17.png alt></figure></p><blockquote><p>🔼 MVImgNet 데이터셋에서 객체 재질 분할에 대한 정성적 결과입니다. 모델은 단일 또는 여러 재질로 구성된 객체에 대해 합리적이고 경계가 정확한 재질 예측을 수행합니다.</p><details><summary>read the caption</summary>Figure 17: Qualitative results of object material segmentation on MVImgNet. Our model makes reasonable and boundary-accurate material predictions for objects with multiple or single materials.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Global-to-local</th><th>Voting</th><th>Average mIoU (%) (↑)</th></tr></thead><tbody><tr><td></td><td>✓</td><td>22.17</td></tr><tr><td>✓</td><td></td><td>51.28</td></tr><tr><td>✓</td><td>✓</td><td><strong>55.83</strong></td></tr></tbody></table></table></figure><blockquote><p>🔼 이 표는 전역-지역 지식 통합과 빈도 기반 투표 전략을 사용하지 않았을 때와 사용했을 때의 재료 분할 성능을 비교하여 두 가지 기술의 효과를 보여줍니다. 전역-지역 지식 통합은 객체의 전역적 구조와 세부 정보를 더 잘 이해하여 재료 예측의 정확도를 향상시키는 반면, 빈도 기반 투표는 여러 시점에서 정보를 집계하여 예측의 일관성과 신뢰성을 보장합니다.</p><details><summary>read the caption</summary>Table 2: Ablation study of Global-to-Local Knowledge Integration and Frequency-Based Voting.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Method</th><th>PUR (%)↑</th><th>NDR (%)↑</th><th>SR (%)↑</th></tr></thead><tbody><tr><td>MinGF</td><td>50.00</td><td><strong>100.00</strong></td><td>50.00</td></tr><tr><td>MidGF</td><td>87.50</td><td>81.25</td><td>68.75</td></tr><tr><td>MaxGF</td><td><strong>100.00</strong></td><td>75.00</td><td>75.00</td></tr><tr><td>Ours*</td><td><strong>100.00</strong></td><td><strong>100.00</strong></td><td><strong>100.00</strong></td></tr></tbody></table></table></figure><blockquote><p>🔼 로봇 그리핑 실험 결과를 요약한 표입니다. 최소, 중간, 최대 그리핑 힘을 사용하는 베이스라인과 제안된 GaussianProperty 방법을 비교하여 성공률을 보여줍니다.</p><details><summary>read the caption</summary>Table 3: Results of robot grasping experiments on 16 objects. MinGF, MidGF and MaxGF are baselines with minimum (NG⁢F=15subscript𝑁𝐺𝐹15N_{GF}=15italic_N start_POSTSUBSCRIPT italic_G italic_F end_POSTSUBSCRIPT = 15), medium (NG⁢F=60subscript𝑁𝐺𝐹60N_{GF}=60italic_N start_POSTSUBSCRIPT italic_G italic_F end_POSTSUBSCRIPT = 60) and maximum (NG⁢F=100subscript𝑁𝐺𝐹100N_{GF}=100italic_N start_POSTSUBSCRIPT italic_G italic_F end_POSTSUBSCRIPT = 100) grasping forces applied by the robotic gripper. Bold: best results.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Method</th><th>ADE (↓)</th><th>ALDE (↓)</th><th>APE (↓)</th><th>MnRE (↑)</th><th>PRA (↑)</th></tr></thead><tbody><tr><td>NeRF2Physics</td><td>35.917</td><td>0.328</td><td>0.294</td><td>0.748</td><td>0.575</td></tr><tr><td>Ours*</td><td><strong>28.583</strong></td><td><strong>0.220</strong></td><td><strong>0.198</strong></td><td><strong>0.820</strong></td><td><strong>0.686</strong></td></tr></tbody></table></table></figure><blockquote><p>🔼 이 표는 실제 촬영된 자체 수집 데이터셋(10개 객체, 100개 지점)에서 지점별 Shore 경도 추정 결과를 비교한 것입니다. NeRF2Physics와 제한된 방법과 비교하여 제안된 방법이 더 정확한 경도 추정 결과를 보여줍니다.</p><details><summary>read the caption</summary>Table 4: Estimation of per-point Shore hardness on the real-captured in-house collected dataset (10 objects, 100 points). Bold: best model.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Method</th><th>ADE (↓)</th><th>ALDE (↓)</th><th>APE (↓)</th><th>MnRE (↑)</th></tr></thead><tbody><tr><td>NeRF2Physics</td><td>12.761</td><td>0.803</td><td><strong>0.589</strong></td><td>0.498</td></tr><tr><td>Ours*</td><td><strong>5.960</strong></td><td><strong>0.744</strong></td><td>1.609</td><td><strong>0.559</strong></td></tr></tbody></table></table></figure><blockquote><p>🔼 ABO 데이터셋에서의 질량 추정 결과 비교. 다양한 평가 지표에서 NeRF2Physics보다 본 연구의 방법이 더 나은 성능을 보임.</p><details><summary>read the caption</summary>Table 5: Mass estimation on ABO dataset. Bold: best results.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-6c556962ca71995a35654dcb7b6bec1f class=gallery><img src=paper_images/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/17.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/&amp;title=GaussianProperty:%20Integrating%20Physical%20Properties%20to%203D%20Gaussians%20with%20LMMs" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/&amp;text=GaussianProperty:%20Integrating%20Physical%20Properties%20to%203D%20Gaussians%20with%20LMMs" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/&amp;subject=GaussianProperty:%20Integrating%20Physical%20Properties%20to%203D%20Gaussians%20with%20LMMs" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2412.11258/index.md",oid_likes="likes_paper-reviews/2412.11258/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2412.11314/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Reliable, Reproducible, and Really Fast Leaderboards with Evalica</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-15T00:00:00+00:00>15 December 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2412.11100/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-15T00:00:00+00:00>15 December 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title=Tags>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>