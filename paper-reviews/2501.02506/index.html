<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use &#183; AI Paper Reviews by AI</title>
<meta name=title content="ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use &#183; AI Paper Reviews by AI"><meta name=description content="ToolHop: 대규모 언어 모델의 다중 단계 도구 사용 능력을 엄격히 평가하는 새로운 벤치마크"><meta name=keywords content="Natural Language Processing,Large Language Models,🏢 ByteDance,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use"><meta property="og:description" content="ToolHop: 대규모 언어 모델의 다중 단계 도구 사용 능력을 엄격히 평가하는 새로운 벤치마크"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-01-05T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-05T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="🏢 ByteDance"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/cover.png"><meta name=twitter:title content="ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use"><meta name=twitter:description content="ToolHop: 대규모 언어 모델의 다중 단계 도구 사용 능력을 엄격히 평가하는 새로운 벤치마크"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use","headline":"ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use","abstract":"ToolHop: 대규모 언어 모델의 다중 단계 도구 사용 능력을 엄격히 평가하는 새로운 벤치마크","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2501.02506\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2025","dateCreated":"2025-01-05T00:00:00\u002b00:00","datePublished":"2025-01-05T00:00:00\u002b00:00","dateModified":"2025-01-05T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","🏢 ByteDance"],"mainEntityOfPage":"true","wordCount":"3178"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About This Project">About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Paper Reviews by AI">Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About This Project">About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Paper Reviews by AI">Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2501.02506/cover_hu14651807694880768002.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2501.02506/>ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-01-05T00:00:00+00:00>5 January 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3178 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">15 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2501.02506/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2501.02506/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🤗 Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-bytedance/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🏢 ByteDance</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#multi-hop-tool-use>Multi-hop Tool Use</a></li><li><a href=#query-driven-dataset>Query-Driven Dataset</a></li><li><a href=#llm-tool-evaluation>LLM Tool Evaluation</a></li><li><a href=#model-family-analysis>Model Family Analysis</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#multi-hop-tool-use>Multi-hop Tool Use</a></li><li><a href=#query-driven-dataset>Query-Driven Dataset</a></li><li><a href=#llm-tool-evaluation>LLM Tool Evaluation</a></li><li><a href=#model-family-analysis>Model Family Analysis</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2501.02506</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Junjie Ye et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>🤗 2025-01-07</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2501.02506 target=_self role=button>↗ arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2501.02506 target=_self role=button>↗ Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/toolhop-a-query-driven-benchmark-for target=_self role=button>↗ Papers with Code</a></p><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>대규모 언어 모델(LLM)은 인간처럼 다양한 도구를 활용하여 복잡한 문제를 해결해야 실용적인 수준에 도달할 수 있습니다. 하지만, 기존 평가 방식은 LLM이 <strong>실제 환경에서 여러 도구를 활용하여 문제를 해결하는 능력</strong>을 제대로 평가하지 못한다는 한계가 있었습니다.</p><p>본 연구는 이러한 문제를 해결하고자 <strong>새로운 벤치마크 데이터셋인 ToolHop</strong>을 제시합니다. ToolHop은 다양한 종류의 <strong>실제 사용자 질의</strong>와 이에 해당하는 여러 도구를 포함하고 있으며, <strong>LLM의 다중 단계 도구 사용 능력</strong>을 엄밀하게 평가할 수 있도록 설계되었습니다. 연구진은 ToolHop을 사용하여 여러 LLM 모델을 평가하고, 그 결과를 분석하여 각 모델의 강점과 약점을 파악하고 개선 방향을 제시했습니다.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-15589eca88f79eccc71267259d846b4a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-15589eca88f79eccc71267259d846b4a",{strings:[" 새로운 벤치마크 ToolHop을 통해 다양한 LLM의 다중 단계 도구 사용 능력을 종합적으로 평가 "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-affa024e362481ff96421742312c8b20></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-affa024e362481ff96421742312c8b20",{strings:[" LLM의 다중 단계 도구 사용 능력에 대한 심층 분석 및 개선 방향 제시 "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-9fbe44edc1160423a3a424590989a398></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-9fbe44edc1160423a3a424590989a398",{strings:[" 실제 사용자 질의 기반의 혁신적인 데이터 구축 방법 제시 "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>본 논문은 <strong>다중 단계 도구 사용 능력 평가를 위한 새로운 벤치마크인 ToolHop</strong>을 제시하여, 대규모 언어 모델(LLM)의 도구 사용 능력을 엄격하게 평가하고 향상시키는 데 중요한 기여를 합니다. <strong>다양한 LLM의 성능을 비교 분석하고, 향후 연구 방향을 제시함으로써 LLM의 도구 사용 능력 향상에 대한 새로운 가능성을 제시</strong>합니다. 특히, <strong>실제 사용자 질의를 기반으로 데이터를 구축한 점</strong>과 <strong>모델의 성능 차이를 분석하여 개선 방향을 제시</strong>한 점이 높이 평가됩니다. 이는 <strong>LLM의 실제 응용 분야에서의 성능 향상</strong>을 위한 중요한 발걸음이 될 것입니다.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x1.png alt></figure></p><blockquote><p>🔼 그림 1은 다단계 도구 사용의 과정을 보여줍니다. 복잡한 다단계 질의는 여러 개의 원자적 하위 질의로 분해되고, 적절한 도구가 순차적으로 호출되며, 도구 피드백에서 결과를 가져와 최종 답변이 도출될 때까지 반복됩니다. 이 과정은 이해, 추론 및 함수 호출 기능의 통합을 보여줍니다. 다단계 질의를 해결하기 위해 모델이 여러 도구를 순차적으로 사용하여 하위 질의를 처리하고, 각 도구의 결과를 다음 단계의 입력으로 사용하는 과정을 시각적으로 나타냅니다. 각 단계의 하위 질의, 도구 호출, 피드백, 그리고 최종 답변이 명확하게 표시되어 있습니다.</p><details><summary>read the caption</summary>Figure 1: An illustration of multi-hop tool use. The process entails decomposing a complex multi-hop query into multiple atomic sub-queries, sequentially invoking the appropriate tools, retrieving results from the tool feedback, and iterating until the final answer is derived. This demonstrates the integration of comprehension, reasoning, and function-calling capabilities.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th># Tools</th><th>Three</th><th>Four</th><th>Five</th><th>Six</th><th>Seven</th></tr></thead><tbody><tr><td><strong># Data</strong></td><td>428</td><td>353</td><td>136</td><td>10</td><td>68</td></tr></tbody></table></table></figure><blockquote><p>🔼 ToolHop 데이터셋에서 각 쿼리를 해결하는 데 필요한 도구의 수 분포를 보여줍니다. 세 개에서 일곱 개의 도구가 필요한 쿼리가 있으며, 이는 쿼리의 다양한 복잡성 수준을 반영합니다. 즉, 단순한 쿼리부터 여러 단계의 추론이 필요한 복잡한 쿼리까지 다양한 유형의 쿼리를 포함하고 있음을 보여줍니다.</p><details><summary>read the caption</summary>Table 1: Distribution of the number of tools required to solve each query in ToolHop.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Multi-hop Tool Use<div id=multi-hop-tool-use class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#multi-hop-tool-use aria-label=Anchor>#</a></span></h4><p>연구 논문에서 &lsquo;다단계 도구 사용(Multi-hop Tool Use)&lsquo;에 대한 심층적인 분석은 **대규모 언어 모델(LLM)**의 <strong>이해, 추론 및 함수 호출 능력</strong>을 평가하는 데 매우 중요함을 시사합니다. <strong>복잡한 질문을 해결하기 위해 여러 도구를 순차적으로 사용하는 능력</strong>은 진정한 인공 지능으로 가는 중요한 단계이며, 이를 효과적으로 평가하기 위한 벤치마크의 필요성을 강조합니다. 기존 연구들은 단순한 시뮬레이션 환경이나 단일 도구 사용에 초점을 맞추었지만, 이는 실제 세계의 복잡한 문제 해결에는 부족합니다. <strong>ToolHop과 같은 새로운 벤치마크</strong>는 다양하고 상호 의존적인 도구들과 검증 가능한 답변을 포함하여 이러한 문제점을 해결하고자 노력합니다. <strong>질의 중심 데이터 구축 방식</strong>은 도구의 상호 의존성을 보장하고, <strong>다단계 추론을 필요로 하는 진정한 질의</strong>를 생성하는 데 도움이 됩니다. <strong>LLM의 다단계 도구 사용 능력 평가</strong>를 위한 체계적인 접근 방식을 제시하며, 향후 연구 방향을 제시하는 데 기여합니다.</p><h4 class="relative group">Query-Driven Dataset<div id=query-driven-dataset class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#query-driven-dataset aria-label=Anchor>#</a></span></h4><p>본 논문에서 제시된 &lsquo;질의 중심 데이터셋(Query-Driven Dataset)&lsquo;은 기존의 도구 중심 접근 방식과 차별화되는 혁신적인 방법론을 제시합니다. <strong>기존 도구 중심 방식은 도구를 먼저 수집하고 그에 맞는 질의를 생성하는 반면,</strong> <strong>본 논문의 방법론은 사용자의 다양한 질의를 먼저 고려하여 필요한 도구를 생성하는 역 접근 방식</strong>을 취합니다. 이는 <strong>실제 사용자의 요구를 더욱 정확하게 반영하고, 도구 간의 의미있는 상호 의존성을 보장</strong>하는데 큰 장점이 있습니다. <strong>다양한 질의를 통해 도구의 기능과 상호작용을 다각적으로 평가</strong>할 수 있으며, <strong>실제 현실 세계 문제 해결에 더욱 가까운 시나리오</strong>를 만들 수 있다는 점도 주목할 만합니다. <strong>검증 가능한 답변과 상세한 피드백을 제공</strong>하여 모델의 성능 평가를 더욱 엄격하고 신뢰할 수 있도록 합니다. 결과적으로, 이러한 <strong>질의 중심 접근 방식은 대규모 언어 모델의 다중 도구 활용 능력 평가를 위한 보다 효과적이고 실용적인 데이터셋 구축</strong>에 기여할 수 있습니다. <strong>데이터셋의 질적 향상</strong>은 모델의 성능 개선과 더 나아가 인공지능 기술 전반의 발전에 큰 영향을 미칠 것입니다.</p><h4 class="relative group">LLM Tool Evaluation<div id=llm-tool-evaluation class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#llm-tool-evaluation aria-label=Anchor>#</a></span></h4><p>LLM 도구 평가는 대규모 언어 모델(LLM)이 다양한 도구를 얼마나 효과적으로 사용하는지 측정하는 데 중점을 둡니다. 이는 단순히 정확한 답변을 생성하는 것을 넘어 <strong>도구 선택, 호출, 결과 해석</strong>의 전 과정을 평가해야 하므로 복잡한 과제입니다. <strong>다양한 벤치마크</strong>가 제시되고 있지만, 각 벤치마크는 고유한 강점과 약점을 가지고 있으며, <strong>다차원적 평가 지표</strong> 개발이 필요합니다. 예를 들어, 단일 도구 사용 성공률 뿐 아니라, 도구 사용 전략, 오류 처리 방식 등을 분석해야 LLM의 도구 활용 능력을 종합적으로 이해할 수 있습니다. 또한, <strong>실제 사용 시나리오</strong>를 반영한 평가가 중요하며, <strong>데이터셋의 질</strong>이 평가 결과의 신뢰성에 큰 영향을 미친다는 점을 고려해야 합니다. 궁극적으로, LLM 도구 평가는 LLM의 지능 수준 향상과 실제 응용 가능성 확대에 중요한 역할을 합니다. <strong>지속적인 연구 개발</strong>을 통해, 보다 객관적이고 포괄적인 평가 체계를 구축하는 것이 필요합니다.</p><h4 class="relative group">Model Family Analysis<div id=model-family-analysis class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#model-family-analysis aria-label=Anchor>#</a></span></h4><p>본 논문에서 제시된 다양한 모델들을 모델 패밀리별로 분석하는 것은 <strong>상당히 중요한 의미</strong>를 지닌다. 각 모델 패밀리는 고유한 설계 철학과 강점, 약점을 가지고 있기 때문이다. LLaMA3.1 패밀리는 자연어 처리와 코드 생성 능력에 초점을 맞춘 반면, Qwen2.5 패밀리는 수리 능력과 지식 표현에 강점을 보였다. Gemini1.5 패밀리는 혼합 전문가(MoE) 아키텍처를 활용하여 복잡한 추론 과제에서 뛰어난 성능을 보였고, Claude3.5 패밀리는 지시 사항 따르기와 미묘한 추론 능력이 뛰어났다. 마지막으로 GPT 패밀리는 텍스트 생성과 다중 모드 이해, 도구 사용 능력에서 우수한 성능을 보였다. 이러한 <strong>상호 비교 분석을 통해 각 모델 패밀리의 강점과 약점을 명확히 파악</strong>할 수 있으며, 향후 모델 개발 방향을 설정하는 데 귀중한 정보를 제공한다. 특히, <strong>다양한 도구 사용 전략</strong>과 <strong>성능 차이</strong>를 분석하여 효과적인 모델 개발을 위한 구체적인 방향을 제시할 수 있다는 점에서 가치가 크다. <strong>단순한 성능 비교를 넘어 각 모델의 내부 작동 방식과 설계 특징을 고려</strong>하여 심층적인 분석을 수행하는 것이 중요하다.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>본 논문에서 제시된 ToolHop 데이터셋은 다양한 도메인과 복잡한 멀티-홉 질의를 포함하여 LLM의 툴 사용 능력을 평가하는 데 유용한 기반을 제공합니다. 하지만, <strong>LLM의 툴 사용 능력 향상을 위한 구체적인 방법론은 제시하지 못하고 있다는 점이 한계</strong>입니다. 따라서, 향후 연구는 ToolHop을 활용하여 <strong>다양한 LLM 아키텍처와 학습 전략에 따른 성능 차이를 분석</strong>하고, <strong>멀티-홉 툴 사용에서의 어려움을 극복할 수 있는 새로운 모델 아키텍처 또는 학습 기법을 제안</strong>하는 데 초점을 맞춰야 합니다. 특히, <strong>오류 처리 및 피드백 메커니즘 개선</strong>을 통해 모델의 견고성을 높이고, <strong>실제 세계 문제 해결에 효과적인 툴 사용 전략을 개발</strong>하는 것이 중요합니다. 더불어, <strong>다양한 유형의 툴과 멀티모달 데이터를 포함하는 확장된 데이터셋 구축</strong>은 LLM의 일반화 능력 향상에 기여할 것입니다. <strong>ToolHop의 범용성을 높이기 위한 추가적인 연구</strong>도 필요하며, 특히 다양한 언어 및 문화적 배경을 고려한 다국어 지원 및 편향성 해소 연구는 중요한 과제입니다. 궁극적으로, 이러한 노력들을 통해 LLM의 지능적인 툴 사용 능력을 한층 더 발전시킬 수 있을 것입니다.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x2.png alt></figure></p><blockquote><p>🔼 그림 2는 논문에서 제안하는 질의 중심 데이터 구성 방식을 보여줍니다. 이 방식은 도구 생성, 문서 개선, 코드 생성의 세 가지 주요 단계로 구성됩니다. 각각의 다단계 질의 내에 있는 원자적 하위 질의에 대해 자세한 도구 문서와 코드 구현을 점진적으로 개발하는 접근 방식입니다. 그림은 각 단계의 과정과 그 결과물을 시각적으로 보여주어, 다단계 질의를 처리하기 위한 도구 사용에 대한 이해를 돕습니다.</p><details><summary>read the caption</summary>Figure 2: An illustration of our proposed query-driven data construction scheme, comprising three key processes: tool creation, document refinement, and code generation. This approach incrementally develops detailed tool document and code implementation for each atomic subquery within a multi-hop query.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x3.png alt></figure></p><blockquote><p>🔼 ToolHop 데이터셋에 있는 995개의 멀티홉 질의가 47개의 도메인에 걸쳐 얼마나 다양하게 분포되어 있는지 보여주는 그림입니다. 각 도메인별 질의 수를 막대 그래프로 나타내어, 데이터셋의 다양성과 실제 사용자 질의의 다양성을 반영하고 있음을 시각적으로 보여줍니다. 이는 ToolHop 데이터셋이 다양한 종류의 질의를 잘 포괄하고 있음을 보여주는 중요한 지표입니다.</p><details><summary>read the caption</summary>Figure 3: Distribution of user queries across 47 domains in the ToolHop dataset.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x4.png alt></figure></p><blockquote><p>🔼 이 그림은 문서 개선 전후의 도구 매개변수 수의 분포를 보여줍니다. 문서 개선 전에는 매개변수의 수가 적게 분포되어 있지만, 문서 개선 후에는 더 많은 수의 매개변수가 사용되는 것을 보여줍니다. 이는 문서 개선 과정을 통해 도구의 기능이 향상되고 복잡성이 증가했음을 시사합니다.</p><details><summary>read the caption</summary>Figure 4: Distribution of the number of tool parameters before and after document refinement.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x5.png alt></figure></p><blockquote><p>🔼 그림 5는 도구 매개변수의 자료형 분포를 도구 문서 개선 전과 후로 나누어 보여줍니다. 도구 문서 개선 전에는 문자열 자료형 매개변수가 대부분이었으나, 개선 후에는 배열, 정수, 객체 자료형 매개변수의 비중이 증가한 것을 보여줍니다. 이는 도구의 기능이 더욱 복잡해지고 다양한 입력을 처리할 수 있도록 개선되었음을 시각적으로 보여주는 것입니다. 개선 전과 후의 자료형 분포 차이를 통해 도구 문서 개선 과정의 효과를 명확하게 파악할 수 있습니다.</p><details><summary>read the caption</summary>Figure 5: Distribution of tool parameter types before and after document refinement.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x6.png alt></figure></p><blockquote><p>🔼 ToolHop 데이터셋의 두 번째 원자적 하위 질문과 최종 답변에 대한 답변 유형 분포를 보여주는 그림입니다. 그림은 다양한 유형의 답변(예: 숫자, 날짜, 문자열, 개체 등)이 ToolHop 데이터셋에 얼마나 다양하게 포함되어 있는지를 시각적으로 보여줍니다. 이는 ToolHop 데이터셋이 다양한 유형의 질문과 답변을 포괄함으로써, 다양한 종류의 멀티홉 툴 사용 시나리오를 평가하는 데 적합함을 나타냅니다.</p><details><summary>read the caption</summary>Figure 6: Distribution of answer types for the second atomic subquery and final answers in ToolHop.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x7.png alt></figure></p><blockquote><p>🔼 그림 7은 Qwen2.5 계열의 대규모 언어 모델(LLM)이 필수 도구 사용 시나리오에서 병렬 도구 호출을 사용하는 경향이 있음을 보여줍니다. 이는 잘못된 답변을 초래할 수 있는 환각(hallucination)으로 이어질 수 있습니다. 이 그림은 Qwen2.5-Instruct-32B 모델이 하나의 질문에 여러 도구를 동시에 호출하려고 시도하는 과정을 보여줍니다. 각 도구 호출은 서로 의존적이며, 하나의 도구 결과가 다른 도구의 입력으로 사용됩니다. 그러나 병렬 처리로 인해 각 도구가 독립적으로 실행되어 예상치 못한 결과와 부정확한 최종 답변이 발생할 수 있습니다. 이를 통해 병렬 도구 호출 전략의 한계를 보여주며, LLM이 다단계 도구 사용 시나리오에서 효율성과 정확성 사이의 균형을 맞추는 데 어려움을 겪는다는 것을 시사합니다.</p><details><summary>read the caption</summary>Figure 7: The Qwen2.5 family of LLMs emphasizes parallel tool calls in the mandatory tool use scenario, which can lead to hallucinations and incorrect answers.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x8.png alt></figure></p><blockquote><p>🔼 그림 8은 Claude 3.5 계열의 대규모 언어 모델(LLM)이 직접적인 답변 시나리오에서 사고 연쇄(CoT) 추론을 최적화하여 분석 및 문제 해결 능력을 향상시키는 것을 보여줍니다. 즉, 도구를 사용하지 않고 주어진 질문에 대해 모델이 스스로 추론하고 답을 도출하는 능력을 평가하는 것입니다. 이 그림은 Claude 3.5 모델이 단계별 추론 과정을 통해 복잡한 문제를 효과적으로 해결하는 능력을 시각적으로 보여주는 예시를 포함하고 있을 것으로 예상됩니다. 이를 통해 CoT 추론 전략이 모델의 성능 향상에 미치는 영향을 효과적으로 보여줍니다.</p><details><summary>read the caption</summary>Figure 8: The Claude 3.5 family of LLMs optimizes CoT reasoning in the direct answer scenario, enhancing their analytical and problem-solving capabilities.'</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x9.png alt></figure></p><blockquote><p>🔼 그림 9는 GPT 계열의 대규모 언어 모델(LLM)이 상세한 도구 피드백을 사용하여 도구 호출 동작을 개선함으로써 성능을 향상시키는 과정을 보여줍니다. LLM이 도구를 사용하는 방식을 단계별로 보여주는 예시로, 도구 호출 시 발생하는 에러를 상세한 피드백을 통해 수정하고, 결과적으로 질의에 대한 정확한 답변을 도출하는 과정을 시각적으로 제시합니다. 이는 단순히 도구를 사용하는 것 이상으로, LLM이 피드백을 통해 학습하고 오류를 수정하며 더욱 정교한 작업을 수행할 수 있음을 보여주는 중요한 예시입니다.</p><details><summary>read the caption</summary>Figure 9: The GPT family of LLMs improves performance by refining calling behavior through the use of detailed tool feedback.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.02506/x10.png alt></figure></p><blockquote><p>🔼 그림 10은 GPT 계열의 대규모 언어 모델(LLM)이 최소한의 피드백만 제공받았을 때, 잘못된 툴 호출 동작을 수정하는 데 어려움을 겪는다는 것을 보여줍니다. GPT 모델은 툴을 호출하는 과정에서 오류가 발생했을 때, 자세한 피드백이 없으면 올바른 결과를 얻기 위한 호출 동작을 수정하지 못하고, 잘못된 답변을 생성하는 경향을 보입니다. 이는 LLM이 툴 사용에 대한 충분한 이해와 적절한 오류 처리 능력을 갖추지 못했음을 시사합니다.</p><details><summary>read the caption</summary>Figure 10: The GPT fmaily of LLMs struggles to correct their calling behavior when provided with minimal feedback.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Refinement</th><th>Zero</th><th>One</th><th>Two</th><th>Three</th><th>Four</th></tr></thead><tbody><tr><td>Before</td><td>2</td><td>2433</td><td>1250</td><td>202</td><td>25</td></tr><tr><td>After</td><td>2</td><td>2490</td><td>1198</td><td>200</td><td>22</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 2는 문서 개선 전후에 필요한 매개변수의 수 분포를 보여줍니다. 문서 개선 과정을 거치면서 각 도구에 필요한 매개변수의 수가 어떻게 변화하는지 보여주는 표입니다. &lsquo;Refinement&rsquo; 열은 문서 개선 단계를 나타내고, &lsquo;Zero&rsquo;, &lsquo;One&rsquo;, &lsquo;Two&rsquo;, &lsquo;Three&rsquo;, &lsquo;Four&rsquo; 열은 각각 매개변수 개수가 0개, 1개, 2개, 3개, 4개 이상인 도구의 수를 나타냅니다. &lsquo;Before&rsquo; 행은 문서 개선 전의 분포를, &lsquo;After&rsquo; 행은 문서 개선 후의 분포를 보여줍니다. 이 표를 통해 문서 개선이 도구의 복잡성과 세련성을 높이는 데 어떤 영향을 미치는지 확인할 수 있습니다.</p><details><summary>read the caption</summary>Table 2: Distribution of the number of required parameters before and after document refinement.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Refinement</th><th>string</th><th>boolean</th><th>array</th><th>integer</th><th>object</th><th>number</th></tr></thead><tbody><tr><td>Before</td><td>4758</td><td>2</td><td>404</td><td>333</td><td>24</td><td>114</td></tr><tr><td>After</td><td>4473</td><td>2</td><td>755</td><td>241</td><td>44</td><td>102</td></tr></tbody></table></table></figure><blockquote><p>🔼 본 표는 도구 매개변수 유형의 분포를 세분화하여 보여줍니다. 도구 개선 전과 후의 필수 매개변수의 유형별 개수를 비교 분석하여 도구 개선 과정에서 매개변수의 유형과 수에 어떤 변화가 있었는지 보여줍니다. 이는 모델의 도구 사용 능력 평가에 있어서 도구의 복잡성 변화를 이해하는 데 도움이 됩니다.</p><details><summary>read the caption</summary>Table 3: Distribution of required tool parameter types before and after refinement.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Source</th><th>Family</th><th>Version</th><th>Direct</th><th>Mandatory</th><th>Free</th><th>Query</th><th>Instance</th><th></th></tr></thead><tbody><tr><td></td><td></td><td><em>Avg.</em></td><td><em>19.83</em></td><td><em>32.12</em></td><td><em>32.84</em></td><td><em>18.72</em></td><td><em>8.68</em></td><td></td></tr><tr><td>Open-Source</td><td>LLaMA3.1</td><td>Instruct-8B</td><td>13.17</td><td>12.76</td><td>13.47</td><td>41.61</td><td>21.10</td><td></td></tr><tr><td></td><td></td><td>Instruct-70B</td><td>18.79</td><td>19.10</td><td>12.76</td><td>35.08</td><td>14.24</td><td></td></tr><tr><td></td><td>Qwen2.5</td><td>Instruct-7B</td><td>11.46</td><td>9.85</td><td>16.18</td><td>28.84</td><td>7.09</td><td></td></tr><tr><td></td><td></td><td>Instruct-14B</td><td>17.39</td><td>26.38</td><td>26.13</td><td>15.78</td><td>6.82</td><td></td></tr><tr><td></td><td></td><td>Instruct-32B</td><td>20.00</td><td>25.03</td><td>22.61</td><td>12.46</td><td>3.46</td><td></td></tr><tr><td></td><td></td><td>Instruct-72B</td><td>17.89</td><td>45.43</td><td>38.29</td><td>13.27</td><td>4.93</td><td></td></tr><tr><td>Closed-Source</td><td>Gemini1.5</td><td>flash-002</td><td>18.59</td><td>29.35</td><td>32.76</td><td>13.59</td><td>6.69</td><td></td></tr><tr><td></td><td></td><td>pro-002</td><td>18.89</td><td>31.16</td><td>33.07</td><td>14.57</td><td>6.61</td><td></td></tr><tr><td></td><td>Claude3.5</td><td>Haiku</td><td>36.08</td><td>38.09</td><td>44.72</td><td>23.48</td><td>15.81</td><td></td></tr><tr><td></td><td></td><td>Sonnet</td><td>27.14</td><td>39.90</td><td>45.23</td><td>19.60</td><td>15.83</td><td></td></tr><tr><td></td><td>GPT</td><td>3.5-Turbo</td><td>17.09</td><td>35.38</td><td>36.58</td><td>11.76</td><td>6.03</td><td></td></tr><tr><td></td><td></td><td>4o-mini</td><td>19.40</td><td>40.20</td><td>43.42</td><td>11.66</td><td>3.58</td><td></td></tr><tr><td></td><td></td><td>4-Turbo</td><td>18.59</td><td>47.94</td><td>46.83</td><td>10.95</td><td>4.97</td><td></td></tr><tr><td></td><td></td><td>4o</td><td>23.12</td><td>49.04</td><td>47.74</td><td>9.45</td><td>4.31</td><td></td></tr></tbody></table></table></figure><blockquote><p>🔼 표 4는 다양한 대규모 언어 모델(LLM)의 ToolHop 데이터셋 성능을 보여줍니다. 세 가지 시나리오(직접 답변, 필수 도구 사용, 자유 선택)에서 모델의 정답률과 도구 호출 오류율을 비교 분석합니다. &lsquo;쿼리&rsquo;와 &lsquo;인스턴스&rsquo;는 각각 오류가 발생한 쿼리와 도구 호출의 비율을 나타냅니다. 평균값보다 높은 값은 청록색으로, 낮은 값은 갈색으로 강조 표시되어 있으며, 음영의 농도는 평균값과의 차이를 나타냅니다.</p><details><summary>read the caption</summary>Table 4: Performance of various LLMs on ToolHop, including answer correctness and invocation error. ‘Direct,’ ‘Mandatory,’ and ‘Free’ denote the direct answer, mandatory tool use, and free choice scenarios, respectively. ‘Query’ and ‘Instance’ refer to the percentage of queries and tool invocation instances with errors, respectively. ‘Avg.’ represents the average across all LLMs. Values above the average are highlighted in teal, and those below are highlighted in maroon, with darker shades indicating larger deviations.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Version</th><th>w/ Feedback</th><th>w/o Feedback</th></tr></thead><tbody><tr><td>3.5-Turbo</td><td>36.75</td><td>21.37</td></tr><tr><td>4o-mini</td><td>38.53</td><td>11.93</td></tr><tr><td>4-Turbo</td><td>29.31</td><td>12.07</td></tr><tr><td>4o</td><td>47.87</td><td>24.47</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 5는 GPT 계열 모델의 호출 오류가 포함된 질문에 대한 답변 정확도를 보여줍니다. &lsquo;피드백 있음&rsquo;과 &lsquo;피드백 없음&rsquo;은 각각 자세한 피드백 또는 간단한 오류 보고서가 제공된 경우를 나타냅니다. ΔC→I는 자세한 피드백에서 간단한 오류 보고서로 전환할 때 정답이 오답으로 변하는 비율을 나타내고, ΔI→C는 오답이 정답으로 변하는 비율을 나타냅니다.</p><details><summary>read the caption</summary>Table 5: Answer correctness of the GPT family of models in queries containing invocation error. ‘w/ Feedback’ and ‘w/o Feedback’ represent cases where detailed feedback or only simple error reporting is provided, respectively. ‘𝚫𝐂→𝐈subscript𝚫→𝐂𝐈\mathbf{\Delta_{C\to I}}bold_Δ start_POSTSUBSCRIPT bold_C → bold_I end_POSTSUBSCRIPT’ denotes the proportion of correct answers that become incorrect, while ‘𝚫𝐈→𝐂subscript𝚫→𝐈𝐂\mathbf{\Delta_{I\to C}}bold_Δ start_POSTSUBSCRIPT bold_I → bold_C end_POSTSUBSCRIPT’ represents the proportion of incorrect answers that become correct, when transitioning from detailed feedback to simple error reporting.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Steps</th><th>Description</th></tr></thead><tbody><tr><td>1. Analyze the Problem</td><td>Understand the question and determine the type of information required to answer it.</td></tr><tr><td>2. Tool Design</td><td>Design a tool that can solve the problem, considering the complexity and additional functionalities it might need.</td></tr><tr><td>3. Parameter Specification</td><td>Define the parameters for the tool, ensuring they are comprehensive and flexible for various use cases.</td></tr><tr><td>4. Output Construction</td><td>Format the output in JSON, including both the analysis and the tool schema.</td></tr><tr><td>Notes</td><td>- Ensure the tool is versatile enough to handle similar queries for different sports figures.<br>- Consider edge cases.</td></tr><tr><td>Output Format</td><td>The output should be a JSON object with the following structure <strong>without any other contents</strong>:<br>- &ldquo;analysis&rdquo;: A detailed analysis of the ideas behind the tool design.<br>- &ldquo;tool&rdquo;: A JSON schema characterizing the tool, including its name, description, and parameters.</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 6는 툴 생성을 위한 프롬프트를 보여줍니다. &lsquo;{Example}&lsquo;은 예시를, &lsquo;{Question}&lsquo;은 하위 질의를 각각 나타냅니다. 본질적으로 이 표는 대규모 언어 모델(LLM)이 다중 단계 툴 사용 과제를 수행하기 위해 필요한 툴을 생성하는 데 사용된 지침을 설명합니다. 이 지침에는 문제 분석, 툴 설계, 매개변수 명세, 출력 구성 등의 단계가 포함됩니다. 각 단계는 LLM이 툴을 효과적으로 설계하고 생성하는 데 필요한 구체적인 지침을 제공합니다.</p><details><summary>read the caption</summary>Table 6: The prompt for tool creation, where ‘{Example}’ and ‘{Question}’ represent the example and subquery, respectively.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption>{&ldquo;analysis&rdquo;: &ldquo;Analysis of ideas about refining the tool.&rdquo;, &ldquo;refined_version&rdquo;: {}}</table></figure><blockquote><p>🔼 표 7은 논문의 2.2절인 &lsquo;Query-Driven Data Construction&rsquo; 섹션에 포함된 표입니다. 이 표는 쿼리 기반 데이터 구성 방식에서 도구 문서를 개선하는 과정에 사용되는 프롬프트(지시어)를 보여줍니다. 프롬프트는 초기 단계에서 생성된 도구 문서({Tool})를 입력으로 받아, 도구의 설명을 개선하고, 매개변수의 복잡성을 높이는 것을 목표로 합니다. 즉, 초기 도구의 기능과 호환성을 유지하면서 더욱 세련되고, 다양한 상황에 적용 가능한 도구 문서를 만들기 위한 지시사항을 담고 있습니다.</p><details><summary>read the caption</summary>Table 7: The prompt for document refinement, where ‘{Tool}’ represents the preliminary document.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Steps</th><th>Description</th></tr></thead><tbody><tr><td>1. <strong>Understand the Tool Document</strong></td><td>Review the tool document to identify the function name, parameter names, and types.</td></tr><tr><td>2. <strong>Analyze the Question and Answer</strong></td><td>Determine how the function should be used to answer the question.</td></tr><tr><td>3. <strong>Implement the Function</strong></td><td>Use the tool name as the function name. Define parameters exactly as specified in the tool document. Implement the function logic to produce the correct answer for the given question. Simulate additional return values as specified in the tool document.</td></tr><tr><td>4. <strong>Error Handling</strong></td><td>Develop a robust error handling mechanism to return valid error messages for incorrect inputs or other issues.</td></tr><tr><td>Notes</td><td>Description</td></tr><tr><td>&mdash;</td><td>&mdash;</td></tr><tr><td>-</td><td>Ensure parameter types and names match exactly with the tool document.</td></tr><tr><td>-</td><td>Simulate additional return values as needed based on the tool’s documentation.</td></tr><tr><td>-</td><td>Implement comprehensive error handling to cover potential issues.</td></tr><tr><td>Output format</td><td>Description</td></tr><tr><td>&mdash;</td><td>&mdash;</td></tr><tr><td></td><td>Output the result in JSON format with the following structure <strong>without any other contents</strong>: {</td></tr><tr><td>&ldquo;analysis&rdquo;: &ldquo;Detailed analysis of how the function was designed, including reasoning for parameter choices and exception handling.&rdquo;,</td><td></td></tr><tr><td>&ldquo;function&rdquo;: &ldquo;The specific function design, including code and comments explaining each part.&rdquo;</td><td></td></tr><tr><td>}</td><td></td></tr><tr><td><em>Tool Document</em></td><td>{document}</td></tr><tr><td><em>Question</em></td><td>{question}</td></tr><tr><td><em>Answer</em></td><td>{answer}</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 8은 코드 생성을 위한 프롬프트를 보여줍니다. 여기서 {document}는 다듬어진 문서, {question}은 하위 질문, {answer}는 해당하는 답변을 각각 나타냅니다. 이 표는 논문의 2.2절 &lsquo;Query-Driven Data Construction&rsquo; 에서 다루어지는 질의 중심 데이터 생성 과정에서 사용되는 프롬프트를 설명합니다. GPT-40과 같은 대규모 언어모델이 질문과 다듬어진 문서, 그리고 정답을 바탕으로 실제 실행 가능한 코드를 생성할 수 있도록 안내하는 프롬프트의 구조와 내용을 보여줍니다.</p><details><summary>read the caption</summary>Table 8: The prompt for code generation, where ‘{document}’, ‘{question}’ and ‘{answer}’ represent the refined document, the subquery and the corresponding answer, respectively.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Steps</th><th>Description</th></tr></thead><tbody><tr><td>1. <strong>Analyze the Sentence</strong></td><td>Break down the sentence to understand its components and context.</td></tr><tr><td>2. <strong>Identify Key Elements</strong></td><td>Look for specific terms or phrases that indicate the subject matter, such as names, dates, or specific topics.</td></tr><tr><td>3. <strong>Determine the Domain</strong></td><td>Based on the analysis, select the most appropriate domain that encapsulates the main focus of the sentence.</td></tr><tr><td>Output Format</td><td>```json</td></tr><tr><td>{</td><td></td></tr><tr><td>&ldquo;analysis&rdquo;: &ldquo;Analysis of the given sentence.&rdquo;,</td><td></td></tr><tr><td>&ldquo;domain&rdquo;: &ldquo;The domain of the sentence, as short as possible&rdquo;</td><td></td></tr><tr><td>}</td><td></td></tr></tbody></table><pre tabindex=0><code class=language-| data-lang=|>| Notes | - Ensure the domain is specific and directly related to the main subject of the sentence. &lt;br&gt; - Consider the broader context if the sentence includes specific names or events. |
| Sentence | {sentence} |
</code></pre></table></figure><blockquote><p>🔼 표 9는 도메인 분류를 위한 프롬프트를 보여줍니다. 여기서 <code>{sentence}</code>는 다단계 질의를 나타냅니다. 이 프롬프트는 GPT-40을 사용하여 ToolHop 데이터셋 내 질의의 도메인을 분류하기 위해 사용됩니다. 프롬프트는 문장의 내용과 문맥을 분석하고, 주요 요소를 파악하여, 문장의 주제를 가장 잘 나타내는 단일 도메인을 식별하는 단계들을 포함합니다. 출력 형식은 분석 결과와 도메인을 포함하는 JSON 객체입니다.</p><details><summary>read the caption</summary>Table 9: The prompt for domain classification, where ‘{sentence}’ represents the multi-hop query.</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-ad827fd2bebd4c39745d7fbc5b6a3baa class=gallery><img src=paper_images/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/&amp;title=ToolHop:%20A%20Query-Driven%20Benchmark%20for%20Evaluating%20Large%20Language%20Models%20in%20Multi-Hop%20Tool%20Use" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/&amp;text=ToolHop:%20A%20Query-Driven%20Benchmark%20for%20Evaluating%20Large%20Language%20Models%20in%20Multi-Hop%20Tool%20Use" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/&amp;subject=ToolHop:%20A%20Query-Driven%20Benchmark%20for%20Evaluating%20Large%20Language%20Models%20in%20Multi-Hop%20Tool%20Use" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2501.02506/index.md",oid_likes="likes_paper-reviews/2501.02506/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2501.02157/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Personalized Graph-Based Retrieval for Large Language Models</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-01-04T00:00:00+00:00>4 January 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2501.02497/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Test-time Computing: from System-1 Thinking to System-2 Thinking</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-01-05T00:00:00+00:00>5 January 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title=Tags>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>