[{"content": "| Model | Instruction Following (IFEval) | | Math Reasoning | | Code Generation | \n|---|---|---|---|---|---|---|---|---|---| \n| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n|  Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | |\n| Mistral-7B-v0.3 | 19.59 | 31.77 | 22.74 | 34.65 | | 33.89 | **3.16** | | 24.39 | 6.00 |\n| DeepSeek-7B | 36.23 | **48.20** | 41.04 | 52.52 | | **48.07** | 2.96 | | 28.66 | 33.00 |\n| Llama-3.2-3B | 40.11 | 50.84 | 43.81 | 54.43 | | 53.75 | 6.60 | | 35.98 | **36.00** |\n| Llama-3-8B | 33.83 | 46.28 | 36.41 | 49.28 | | 63.00 | 7.62 | | 43.90 | 36.20 |\n| Llama-3.1-8B | 34.57 | 46.04 | 38.81 | 50.48 | | 64.22 | 11.32 | | **51.22** | 40.60 |\n| InternLM-2-7B | 40.85 | 53.48 | 44.54 | 56.95 | | **68.31** | 19.50 | | 56.10 | 40.40 |\n| Supervised Model: Llama-3.1-8B-Instruct||||| | | | | |\n| Mistral-7B-v0.3 | **24.40** | **35.01** | **26.25** | **37.53** | | **40.18** | 2.84 | | **29.27** | **19.60** |\n| DeepSeek-7B | **36.60** | 48.08 | **41.77** | **53.12** | | 47.92 | **3.56** | | **34.76** | **33.80** |\n| Llama-3.2-3B | **41.59** | **53.48** | **45.66** | **57.07** | | **55.12** | **7.32** | | **39.02** | 32.80 |\n| Llama-3-8B | **35.49** | **47.00** | **39.56** | **50.72** | | **63.38** | **11.44** | | **48.17** | **37.60** |\n| Llama-3.1-8B | **38.45** | **50.96** | **43.81** | **55.28** | | **67.10** | **13.12** | | 48.78 | **41.60** |\n| InternLM-2-7B | **43.07** | **54.80** | **47.32** | **58.39** | | 68.08 | **20.32** | | **57.93** | **40.80** |", "caption": "Table 1: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under Evol-Instruct scenario.", "description": "Llama-3.1-8B-Instruct \ubc0f Llama-3.1-70B-Instruct\ub97c Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uac01\uac01 \uad50\uc0ac \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud558\uc5ec \uc9c0\uc2dc \uc9c4\ud654 \uc131\ub2a5\uc744 \uc5ec\ub7ec \ubaa8\ub378\uc5d0 \ub300\ud574 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \uc9c0\uc2dc \ub530\ub974\uae30(IFEval), \uc218\ud559\uc801 \ucd94\ub860(GSM8K, MATH), \ucf54\ub4dc \uc0dd\uc131(HumanEval, MBPP)\uacfc \uac19\uc740 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0\uc11c \uc131\ub2a5\uc744 \uce21\uc815\ud569\ub2c8\ub2e4. \ud45c\uc5d0\uc11c Pr.(S)\ub294 \uc791\uc740 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ud504\ub86c\ud504\ud2b8 \uc810\uc218\ub97c, In.(S)\ub294 \uc791\uc740 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc9c0\uc2dc \uc810\uc218\ub97c, Pr.(L)\ub294 \ud070 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ud504\ub86c\ud504\ud2b8 \uc810\uc218\ub97c, In.(L)\ub294 \ud070 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \uc9c0\uc2dc \uc810\uc218\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |\n|---|---|---|---|---|---|---|---|\n|       | Pr.(S) | In.(S) | Pr.(L) | In.(L) |   | GSM8K | MATH |   | HumanEval | MBPP |\n|---|---|---|---|---|---|---|---|---|---|---| \n| **Supervised Model: Qwen-2-72B-Instruct** | | | | | | | | | |\n| Mistral-7B-v0.3 | 20.15 | 30.94 | 23.84 | 34.41 |   | 46.93 | **3.26** |   | 32.32 | 1.80 |\n| DeepSeek-7B | 35.67 | 47.12 | **39.56** | 50.84 |   | 44.81 | 2.76 |   | **36.59** | **34.00** |\n| Llama-3.2-3B | 39.74 | 51.44 | 43.99 | 55.40 |   | 53.83 | **7.40** |   | 38.41 | 31.00 |\n| Llama-3-8B | 34.75 | 45.80 | 37.71 | 48.92 |   | 63.76 | **10.06** |   | 43.90 | 35.40 |\n| Llama-3.1-8B | **36.41** | **47.60** | 39.00 | 50.60 |   | 65.43 | 10.84 |   | **48.17** | 38.40 |\n| InternLM-2-7B | 41.96 | 53.60 | 43.99 | 55.64 |   | 65.28 | 17.96 |   | 56.71 | 40.60 |\n| **Supervised Model: Qwen-2-7B-Instruct** | | | | | | | | | |\n| Mistral-7B-v0.3 | **25.32** | **37.17** | **29.76** | **41.01** |   | **47.31** | 2.20 |   | **32.93** | **12.00** |\n| DeepSeek-7B | **36.41** | **48.56** | 39.37 | **51.32** |   | **48.07** | **3.82** |   | 35.37 | 33.20 |\n| Llama-3.2-3B | **43.81** | **55.16** | **47.87** | **58.27** |   | **56.56** | 7.18 |   | **39.63** | **31.40** |\n| Llama-3-8B | **38.92** | **48.33** | **43.81** | **52.19** |   | **63.91** | 8.66 |   | **45.73** | **38.40** |\n| Llama-3.1-8B | 34.75 | 45.80 | **39.93** | **51.08** |   | **68.76** | **14.02** |   | 46.34 | **38.60** |\n| InternLM-2-7B | **44.12** | **55.16** | **48.62** | **58.73** |   | **66.87** | **19.60** |   | **58.54** | **41.40** |", "caption": "Table 2: Comparison of performance with Qwen-2-7B-Instruct and Qwen-2-72B-Instruct as supervised models under Evol-Instruct scenario.", "description": "Qwen-2-7B-Instruct(SLM)\uc640 Qwen-2-72B-Instruct(LLM)\ub97c Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc9c0\ub3c4 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud558\uc5ec \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4.  IFEval, FollowBench, GSM8K, MATH, HumanEval, MBPP \ub4f1 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc131\ub2a5\uc744 \uce21\uc815\ud588\uc2b5\ub2c8\ub2e4.  Pr.(S)\uc640 In.(S)\ub294 \uac01\uac01 \uc791\uc740 \ubaa8\ub378\ub85c \uc0dd\uc131\ud55c \uba85\ub839\uacfc \uc9c0\uc2dc\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ub098\ud0c0\ub0b4\uba70, Pr.(L)\uacfc In.(L)\ub294 \ud070 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc131\ub2a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "3 RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "| Model | IFEval | | | | FollowBench (HSR) | | | | | Common Abilities | |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | Level 1 | Level 2 | Level 3 | Level 4 | Level 5 | Avg. | | C-Eval | MMLU | HumanEval | GSM8K |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---| \n| *Supervision Model: Llama-3.1-70B-Instruct* | | | | | | | | | | | | | | | |\n| Llama-3.2-3B | 40.85 | 51.92 | 42.33 | 53.84 | | **61.17** | 57.59 | **50.55** | 33.09 | 26.74 | 45.83 | | **41.37** | **52.65** | **29.88** | 27.07 |\n| Llama-3-8B | 37.71 | 50.00 | 39.19 | 52.04 | | 49.64 | 46.60 | 41.56 | 27.05 | 22.37 | 37.44 | | 41.87 | 51.14 | 26.83 | 37.76 |\n| Llama-3.1-8B | 41.96 | 53.36 | 42.70 | 54.20 | | 51.77 | 45.60 | 45.04 | 34.85 | 26.61 | 40.78 | | **44.50** | 56.39 | 31.10 | 38.21 |\n| Qwen-2-7B | 41.96 | 53.60 | 43.62 | 55.64 | | 72.18 | 62.45 | **56.43** | 41.31 | 35.42 | 53.56 | | **81.08** | 55.71 | 57.32 | **79.68** |\n| Qwen-2.5-7B | 49.17 | **60.31** | 50.46 | 61.51 | | **78.88** | **73.78** | **61.50** | 51.99 | 45.42 | **62.31** | | **80.46** | 58.39 | 67.68 | **85.90** |\n| InternLM-2-7B | 46.21 | 56.71 | 48.06 | 58.63 | | 68.89 | 62.23 | 54.17 | 44.27 | 42.06 | 54.33 | | 60.11 | 60.59 | 65.35 | 50.00 |\n| *Supervision Model: Llama-3.1-8B-Instruct* | | | | | | | | | | | | | | | |\n| Llama-3.2-3B | **43.62** | **54.20** | **46.95** | **57.07** | | 56.95 | **61.46** | 50.20 | **37.65** | **34.16** | **48.08** | | 40.56 | 49.08 | 25.00 | **29.87** |\n| Llama-3-8B | **41.04** | **51.32** | **42.88** | **53.11** | | **62.99** | **54.38** | **49.29** | **32.21** | **32.21** | **46.21** | | **43.49** | **55.63** | **37.20** | **45.26** |\n| Llama-3.1-8B | **42.51** | **54.92** | **44.73** | **56.71** | | **63.99** | **58.15** | **53.29** | **39.49** | **36.02** | **50.19** | | 43.77 | **58.32** | **32.32** | **47.92** |\n| Qwen-2-7B | **44.92** | **55.76** | **47.50** | **58.39** | | **78.75** | **63.30** | 52.31 | **50.28** | **43.08** | **57.54** | | 80.11 | **56.84** | **65.24** | 79.53 |\n| Qwen-2.5-7B | **50.09** | 59.59 | **52.50** | **61.75** | | 77.86 | 70.22 | 59.86 | **53.35** | **47.18** | 61.69 | | 79.74 | **60.17** | **72.56** | 84.69 |\n| InternLM-2-7B | **47.50** | **57.67** | **50.83** | **61.15** | | **74.73** | **66.16** | **61.94** | **54.10** | **46.28** | **60.64** | | **63.03** | **63.16** | **70.96** | **54.27** |", "caption": "Table 3: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under AutoIF scenario.", "description": "\uc774 \ud45c\ub294 AutoIF \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c Llama-3.1-8B-Instruct\uc640 Llama-3.1-70B-Instruct\ub97c \uc9c0\ub3c4 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud588\uc744 \ub54c\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. AutoIF\ub294 \uc18c\uc218\uc758 \ucd08\uae30 \uc9c0\uce68\uc5d0\uc11c \ub300\uaddc\ubaa8\uc758 \uc548\uc815\uc801\uc778 \uc9c0\uce68\uc744 \uc790\ub3d9\uc73c\ub85c \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c \ud569\ub2c8\ub2e4. \ud45c\uc5d0\uc11c Pr.(S) \ubc0f In.(S)\ub294 \uac01\uac01 \uc791\uc740 \ubaa8\ub378(Llama-3.1-8B-Instruct)\ub85c \uc9c0\ub3c4 \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \ud504\ub86c\ud504\ud2b8 \ubc0f \uc9c0\uce68 \uc218\uc900\uc5d0\uc11c\uc758 IFEval \uc815\ud655\ub3c4\ub97c \ub098\ud0c0\ub0b4\uace0, Pr.(L) \ubc0f In.(L)\uc740 \ud070 \ubaa8\ub378(Llama-3.1-70B-Instruct)\ub85c \uc9c0\ub3c4 \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 IFEval \uc815\ud655\ub3c4\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. FollowBench(HSR) \uc5f4\uc740 \ub2e4\uc12f \uac00\uc9c0 \ub09c\uc774\ub3c4 \uc218\uc900(1-5)\uacfc \ud3c9\uade0 HSR(Hard Satisfaction Rate)\uc744 \ubcf4\uc5ec\uc8fc\uba70, Common Abilities \uc5f4\uc740 C-Eval, MMLU, HumanEval, GSM8K\uc5d0\uc11c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ub2e4\uc591\ud55c \uce21\uba74\uc5d0\uc11c SLM\uacfc LLM\uc758 \uc131\ub2a5 \ucc28\uc774\ub97c \ube44\uad50\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "| Model | Instruction Following (IFEval) | | | | | Math Reasoning | | | Code Generation | |\n|---|---|---|---|---|---|---|---|---|---|---| \n| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP | \n|---|---|---|---|---|---|---|---|---|---|---| \n| Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | | \n| Llama-3.2-3B | 36.60 | 48.68 | 39.00 | 51.08 | | 53.60 | 7.56 | | 35.37 | 33.00 | \n| Llama-3-8B | 35.86 | 47.60 | 38.63 | 50.24 | | 63.91 | 9.18 | | 38.41 | 32.40 | \n| Llama-3.1-8B | 36.97 | 47.60 | 40.30 | 51.08 | | 66.11 | 11.68 | | 40.85 | **40.40** | \n| Supervised Model: Llama-3.1-8B-Instruct | | | | | | | | | | | \n| Llama-3.2-3B | **45.47** | **57.43** | **50.28** | **61.27** | | **56.48** | **8.42** | | **38.41** | **34.40** | \n| Llama-3-8B | **37.34** | **49.64** | **39.74** | **51.56** | | **67.40** | **12.26** | | **43.90** | **34.80** | \n| Llama-3.1-8B | **38.08** | **49.76** | **40.48** | **52.40** | | **69.52** | **15.62** | | **51.22** | 38.80 |", "caption": "Table 4: Comparison of performance with Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models under Auto Evol-Instruct scenario.", "description": "\uc774 \ud45c\ub294 Auto Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c Llama-3.1-8B-Instruct\uc640 Llama-3.1-70B-Instruct\ub97c \uc9c0\ub3c4 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud55c \uc131\ub2a5 \ube44\uad50\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Auto Evol-Instruct\ub294 \uc8fc\uc5b4\uc9c4 \uba85\ub839\uc744 \ub354 \ubcf5\uc7a1\ud55c \ubc84\uc804\uc73c\ub85c \ub2e4\uc2dc \uc791\uc131\ud558\ub294 \uba85\ub839 \uc7ac\uc791\uc131\uae30\uc785\ub2c8\ub2e4. \ud45c\uc5d0\uc11c SLM(Llama-3.1-8B-Instruct)\uc740 LLM(Llama-3.1-70B-Instruct)\ubcf4\ub2e4 \ub354 \ud6a8\uacfc\uc801\uc778 \uba85\ub839\uc744 \uc790\ub3d9\uc73c\ub85c \uc9c4\ud654\uc2dc\ud0ac \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.3 Auto Evol-Instruct Scenario"}, {"content": "| Metrics | IFEval | | | |\n|---|---|---|---|---| \n| | Pr.(S) | In.(S) | Pr.(L) | In.(L) |\n| Original | 33.09 | 44.72 | 36.41 | 48.32 |\n| Instruction Len. | 29.94 | 39.69 | 33.83 | 43.53 |\n| Instruction PPL | 27.91 | 39.69 | 32.35 | 44.36 |\n| IFD | 30.87 | 43.53 | 36.04 | 47.60 |\n| IC-IFD | **34.01** | **46.16** | **38.82** | **50.72** |", "caption": "Table 5: Comparison of different metrics under 25% of Alpaca-iter3 evolved by SLMs on Llama-3-8B.", "description": "\uc774 \ud45c\ub294 Llama-3-8B \ubaa8\ub378\uc5d0\uc11c SLM\uc73c\ub85c \uc0dd\uc131\ub41c Alpaca-iter3 \ub370\uc774\ud130\uc758 25%\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc591\ud55c \uba54\ud2b8\ub9ad\uc744 \ube44\uad50\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc73c\ub85c, \uba85\ub839 \uae38\uc774, \uba85\ub839 PPL, IFD \ubc0f IC-IFD\uc640 \uac19\uc740 \uba54\ud2b8\ub9ad\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub370\uc774\ud130\ub97c \ud544\ud130\ub9c1\ud558\uace0 Llama-3-8B\uc5d0\uc11c IFEval \uc131\ub2a5\uc744 \uce21\uc815\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 IC-IFD\uac00 \uba85\ub839 \ubcf5\uc7a1\ub3c4\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \uace0\ub824\ud558\uc5ec \ub2e4\ub978 \uba54\ud2b8\ub9ad\ubcf4\ub2e4 \ub354 \uc815\ud655\ud55c \ub370\uc774\ud130 \ud488\uc9c8 \ud3c9\uac00\ub97c \uc81c\uacf5\ud568\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "5. RQ3: How Do We Determine Whether An Instruction is Effective without Instruction Tuning?"}, {"content": "| Hyperparameter | Value |\n|---|---| \n| Learning Rate | 2 \u00d7 10\u207b\u2075 |\n| Number of Epochs | 3 |\n| Number of Devices | 8 |\n| Per-device Batch Size | 1 |\n| Gradient Accumulation Steps | 8 |\n| Learning Rate Scheduler | cosine |\n| Warmup Ratio | 0.03 |\n| Max Sequence Length | 2048 |", "caption": "Table 6: Hyperparameters utilized in Evol-Instruct, AutoIF and Auto Evol-Instruct scenarios.", "description": "\uc774 \ud45c\ub294 Evol-Instruct, AutoIF, Auto Evol-Instruct \uc138 \uac00\uc9c0 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc778 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub85c\ub294 epoch \uc218, \ub514\ubc14\uc774\uc2a4 \uc218, \ubc30\uce58 \ud06c\uae30, \uadf8\ub798\ub514\uc5b8\ud2b8 \ub204\uc801 \ub2e8\uacc4, \ud559\uc2b5\ub960 \uc2a4\ucf00\uc904\ub7ec, \uc6dc\uc5c5 \ube44\uc728, \ucd5c\ub300 \uc2dc\ud000\uc2a4 \uae38\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4. LoRA \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub85c\ub294 LoRA Rank, LoRA Alpha, LoRA Target, LoRA Dropout\uc774 \uc788\uc2b5\ub2c8\ub2e4.", "section": "A.1 Experimental Details"}, {"content": "| Hyperparameter | Value |\n|---|---| \n| **General Hyperparameters** | |\n| Number of Epochs | 2 |\n| Number of Devices | 8 |\n| Per-device Batch Size | 1 |\n| Gradient Accumulation Steps | 8 |\n| Learning Rate Scheduler | cosine |\n| Warmup Ratio | 0.03 |\n| Max Sequence Length | 2048 |\n| **LoRA Hyperparameters** |  |\n| LoRA Rank | 8 |\n| LoRA Alpha | 8 |\n| LoRA Target | all module |\n| LoRA Dropout | 0.0 |\n| **Qwen-2.5-0.5B and 1.5B** | |\n| Learning Rate | 1e-5 |\n| **Qwen-2.5-3B and 7B** | |\n| Learning Rate | 7e-6 |\n| **Qwen-2.5-14B, 32B and 72B** | |\n| Learning Rate | 5e-5 |", "caption": "Table 7: Hyperparameters utilized for fine-tuning Qwen-2.5 series models.", "description": "\uc774 \ud45c\ub294 Qwen-2.5 \uc2dc\ub9ac\uc988 \ubaa8\ub378\uc758 \ubbf8\uc138 \uc870\uc815\uc5d0 \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ubaa8\ub378 \ud06c\uae30\uc5d0 \ub530\ub77c \ud559\uc2b5\ub960\uacfc LoRA \uc801\uc6a9 \uc5ec\ubd80\uac00 \ub2e4\ub985\ub2c8\ub2e4.", "section": "RQ1: SLM\uc774 \uc9c0\uc2dc \uc9c4\ud654\uc5d0\uc11c LLM\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uac00?"}, {"content": "| | Seed Data | | \n| --- | ---: | ---: |\n|  | **Dataset** | **Datasize** |\n| Instruction Following | Alpaca | 51,983 |\n| Mathematical Reasoning | GSM8K Train | 7,473 |\n| Code Generation | Code Alpaca | 20,022 |", "caption": "Table 8: Statistics of seed instruction data used in the Evol-Instruct and Auto-Evol-Instruct scenarios.", "description": "\uc774 \ud45c\ub294 Evol-Instruct \ubc0f Auto-Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0 \uc0ac\uc6a9\ub41c \uc2dc\ub4dc \uba85\ub839 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130 \uc138\ud2b8\uc758 \uc774\ub984\uacfc \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130 \ud06c\uae30\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.", "section": "3 RQ1: SLM\uc774 \uc9c0\uce68 \ubc1c\uc804\uc5d0\uc11c LLM\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub354 \uc6b0\uc218\ud569\ub2c8\uae4c?"}, {"content": "| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |\n|---|---|---|---|---|---|---|---|\n|       | Pr.(S) | In.(S) | Pr.(L) | In.(L) |   | GSM8K | MATH |   | HumanEval | MBPP |\n|---|---|---|---|---|---|---|---|---|---|\n|       |       |       |       |       |       |       |       |       |       |       |\n| Mistral-7B-v0.3 | 17.01 | 26.86 | 19.04 | 29.14 |   | 27.07 | 0.12 |   | 10.20 | 8.80 |\n| DeepSeek-7B | 22.00 | 34.05 | 23.48 | 35.73 |   | 44.05 | 0.56 |   | 25.61 | 33.80 |\n| Llama-3.2-3B | 22.55 | 34.17 | 25.88 | 37.65 |   | 46.40 | 0.56 |   | 28.05 | 32.20 |\n| Llama-3-8B | 23.11 | 32.97 | 24.77 | 35.13 |   | 53.68 | 0.22 |   | 25.00 | 28.60 |\n| Llama-3.1-8B | 27.54 | 38.13 | 28.65 | 39.21 |   | 56.41 | 7.56 |   | 29.88 | 31.80 |\n| InternLM-2-7B | 32.72 | 45.08 | 35.30 | 48.08 |   | 61.87 | 10.28 |   | 42.07 | 40.00 |", "caption": "Table 9: Results of seed instruction data.", "description": "\uc774 \ud45c\ub294 Evol-Instruct \ubc0f Auto Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \uc2dc\ub4dc \uba85\ub839 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Llama-3.2-3B, Llama-3-8B, Llama-3.1-8B, DeepSeek-7B, Mistral-7B-v0.3, InternLM-2-7B \ub4f1 \ub2e4\uc591\ud55c \ubaa8\ub378\uc5d0 \ub300\ud55c IFEval(\uba85\ub839\uc5b4 \uc218\ud589), \uc218\ud559\uc801 \ucd94\ub860(GSM8K, MATH), \ucf54\ub4dc \uc0dd\uc131(HumanEval, MBPP) \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud45c\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \uc774\ub7ec\ud55c \uc2dc\ub4dc \ub370\uc774\ud130\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ucd5c\uc801\uc774 \uc544\ub2d9\ub2c8\ub2e4. \uc774\ub294 \ud604\uc7ac \ucd5c\uc2e0 \uae30\ubcf8 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub354\uc6b1 \ud5a5\uc0c1\uc2dc\ud0a4\uae30\uc5d0\ub294 \uc774\ub7ec\ud55c \uc2dc\ub4dc \ub370\uc774\ud130\uc758 \ud488\uc9c8\uc774 \ucda9\ubd84\ud558\uc9c0 \uc54a\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "RQ1: SLM\uc774 \uba85\ub839\uc5b4 \ubc1c\uc804\uc5d0\uc11c LLM\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uac00?"}, {"content": "| Model | Instruction Following (IFEval) |   | Math Reasoning |   | Code Generation |   |\n|---|---|---|---|---|---|---| \n|  | Pr.(S) | In.(S) | Pr.(L) | In.(L) | GSM8K | MATH | HumanEval | MBPP |\n|---|---|---|---|---|---|---|---|---| \n| *Supervised Model: Llama-3.1-70B-Instruct* |  |  |  |  |  |  |  |  |\n| Iteration 1 | 33.83 | 46.28 | 36.41 | 49.28 | 63.00 | 7.62 | 43.90 | 36.20 |\n| Iteration 2 | 32.53 | 43.76 | 34.20 | 46.16 | 64.59 | 10.04 | 42.07 | 36.60 |\n| Iteration 3 | 35.12 | 47.36 | 36.97 | 49.28 | 64.75 | 11.82 | 43.29 | 37.20 |\n| *Supervised Model: Llama-3.1-8B-Instruct* |  |  |  |  |  |  |  |  |\n| Iteration 1 | 35.49 | 47.00 | 39.56 | 50.72 | 63.38 | 11.44 | 48.17 | 37.60 |\n| Iteration 2 | 36.78 | 48.20 | 40.30 | 50.84 | 64.82 | 11.48 | 48.78 | 39.40 |\n| Iteration 3 | 33.09 | 44.72 | 36.41 | 48.32 | 65.88 | 14.12 | 44.51 | 40.80 |", "caption": "Table 10: Detailed performance of different evolved iterations on Llama-3-8B refer to Figure\u00a01.", "description": "\uc774 \ud45c\ub294 Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c Llama-3-8B \ubaa8\ub378\uc5d0 \ub300\ud574 \uc11c\ub85c \ub2e4\ub978 \uc9c4\ud654 \ubc18\ubcf5(Iteration 1, 2, 3)\uc744 \uc801\uc6a9\ud55c \ud6c4\uc758 \uc131\ub2a5\uc744 \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Llama-3.1-70B-Instruct\uc640 Llama-3.1-8B-Instruct\ub97c \uac01\uac01 \uc9c0\ub3c4 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud558\uc5ec \ube44\uad50\ud569\ub2c8\ub2e4. \uc131\ub2a5 \uc9c0\ud45c\ub294 IFEval(Instruction Following), GSM8K, MATH(Math Reasoning), HumanEval, MBPP(Code Generation)\ub97c \ud3ec\ud568\ud569\ub2c8\ub2e4.", "section": "RQ1: SLM\uc774 \uc9c0\uc2dc\ubb38 \uc9c4\ud654\uc5d0\uc11c LLM\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294\uac00?"}, {"content": "| Model | Instruction Following (IFEval) | | | | | Math Reasoning | | | Code Generation | |\n|---|---|---|---|---|---|---|---|---|---|---|\n| | Pr.(S) | In.(S) | Pr.(L) | In.(L) | | GSM8K | MATH | | HumanEval | MBPP |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Supervised Model: Llama-3.1-70B-Instruct | | | | | | | | | | |\n| Qwen-2.5-0.5B | 18.48 | 32.73 | 22.00 | 35.85 | | 40.26 | 16.32 | | 30.49 | 27.60 |\n| Qwen-2.5-1.5B | 28.84 | 42.67 | 31.98 | 46.04 | | 62.32 | 24.06 | | 50.00 | 43.20 |\n| Qwen-2.5-3B | 37.89 | 48.56 | 42.70 | 53.60 | | 76.12 | 26.44 | | 63.41 | 55.40 |\n| Qwen-2.5-7B | 46.21 | 56.83 | 50.64 | 60.79 | | 76.12 | 38.14 | | 70.73 | 61.60 |\n| Qwen-2.5-14B (LoRA) | 40.11 | 54.43 | 48.24 | 61.99 | | 87.79 | 49.94 | | 75.00 | 67.20 |\n| Qwen-2.5-32B (LoRA) | 42.88 | 57.31 | 51.20 | 64.15 | | 87.79 | 55.02 | | 80.49 | 71.20 |\n| Qwen-2.5-72B (LoRA) | 50.63 | 68.43 | 57.12 | 70.98 | | 91.05 | 58.83 | | 82.93 | 76.00 |\n| Supervised Model: Llama-3.1-8B-Instruct | | | | | | | | | | |\n| Qwen-2.5-0.5B | 17.38 | 29.38 | 19.78 | 32.01 | | 40.71 | 16.26 | | 34.76 | 28.00 |\n| Qwen-2.5-1.5B | 28.47 | 41.73 | 31.98 | 44.96 | | 65.35 | 27.84 | | 52.44 | 49.94 |\n| Qwen-2.5-3B | 38.82 | 49.76 | 42.51 | 53.96 | | 76.57 | 30.92 | | 64.02 | 55.80 |\n| Qwen-2.5-7B | 47.32 | 58.39 | 51.39 | 62.35 | | 82.03 | 43.78 | | 71.95 | 61.80 |\n| Qwen-2.5-14B (LoRA) | 42.51 | 55.16 | 51.02 | 62.47 | | 88.17 | 52.22 | | 75.61 | 67.20 |\n| Qwen-2.5-32B (LoRA) | 45.84 | 58.75 | 54.71 | 66.31 | | 89.61 | 55.28 | | 81.71 | 73.20 |\n| Qwen-2.5-72B (LoRA) | 52.79 | 72.56 | 61.25 | 73.27 | | 91.36 | 60.75 | | 84.67 | 76.80 |", "caption": "Table 11: Detailed performance among Qwen-2.5 series models refer to Figure\u00a03.", "description": "Qwen-2.5 \uc2dc\ub9ac\uc988 \ubaa8\ub378\uc758 \uc131\ub2a5 \ube44\uad50\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4. Figure 3\uc5d0\uc11c \uc5b8\uae09\ub41c \ubaa8\ub378 \ud06c\uae30 \uc870\uc815 \uc2e4\ud5d8\uc758 \uacb0\uacfc\ub97c \uc790\uc138\ud788 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Llama-3.1-70B-Instruct \ubc0f Llama-3.1-8B-Instruct\ub97c \uac10\ub3c5 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud55c \ub450 \uac00\uc9c0 \uc124\uc815\uc5d0\uc11c Qwen-2.5-0.5B, Qwen-2.5-1.5B, Qwen-2.5-3B, Qwen-2.5-7B, Qwen-2.5-14B (LORA), Qwen-2.5-32B (LORA), Qwen-2.5-72B (LORA) \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 IFEval (Pr.(S), In.(S), Pr.(L), In.(L)), GSM8K, MATH, HumanEval, MBPP \ub4f1\uc758 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "RQ1: SLM\uc774 \uc9c0\uce68 \ubc1c\uc804\uc5d0\uc11c LLM\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub354 \uc6b0\uc218\ud569\ub2c8\uae4c?"}, {"content": "| Temperature | HumanEval | MBPP | HumanEval | MBPP |\n|---|---|---|---|---| \n| | *Supervised Model: Llama-3.1-70B-Instruct* | | *Supervised Model: Llama-3.1-8B-Instruct* | |\n| greedy | 37.20 | 33.40 | **39.63** | **36.40** |\n| 0.1 | 36.59 | 36.40 | **37.80** | **37.60** |\n| 0.3 | 38.41 | 35.20 | **39.63** | **37.80** |\n| 0.5 | 35.98 | 33.40 | **37.80** | **35.80** |\n| 0.7 | 35.98 | **36.00** | **39.02** | 32.80 |\n| 0.9 | 34.76 | 33.00 | **40.24** | **35.80** |", "caption": "Table 12: Performance among different temperatures on Llama-3.2-3B under code generation scenario.", "description": "\uc774 \ud45c\ub294 \ucf54\ub4dc \uc0dd\uc131 \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \ub2e4\uc591\ud55c \uc628\ub3c4 \uc124\uc815\uc5d0 \ub530\ub978 Llama-3.2-3B \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, greedy decoding (\uc628\ub3c4 0)\uacfc 0.1\uc5d0\uc11c 0.9\uae4c\uc9c0 \ub2e4\uc12f \uac00\uc9c0 \uc628\ub3c4 \uc124\uc815\uc5d0\uc11c Code Alpaca \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc9c4\ud654 \uacfc\uc815\uc744 \uac70\uce69\ub2c8\ub2e4. \ubaa8\ub4e0 \uc751\ub2f5 \uc0dd\uc131\uc5d0\ub294 Qwen-2.5-72B-Instruct\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ud45c\ub294 HumanEval \ubc0f MBPP \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud55c pass@1 \uc9c0\ud45c\ub97c \ubcf4\uc5ec\uc8fc\uba70, Llama-3.1-70B-Instruct \ubc0f Llama-3.1-8B-Instruct\ub77c\ub294 \ub450 \uac00\uc9c0 supervised model\uc744 \uc0ac\uc6a9\ud558\uc5ec fine-tuning\ud55c \uacb0\uacfc\ub97c \ube44\uad50\ud569\ub2c8\ub2e4.", "section": "RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "|                       | Alpaca | GSM8K Train | Code Alpaca |\n| :-------------------- | :----: | :---------: | :--------: |\n| Seed Instruction     | 27.63 |    34.05    |   26.01    |\n| LLM-Inst Iter1      | 52.89 |    39.88    |   46.75    |\n| **SLM-Inst Iter1** | **66.35** |  **48.85**  |  **58.86**  |\n| LLM-Inst Iter2      | 68.16 |    47.14    |   65.02    |\n| **SLM-Inst Iter2** | **77.62** |  **63.48**  |  **73.37**  |\n| LLM-Inst Iter3      | 75.73 |    54.00    |   72.85    |\n| **SLM-Inst Iter3** | **82.44** |  **72.12**  |  **79.19**  |", "caption": "Table 13: Scores of difficulty levels for instructions evolved during three iterations, using Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct as supervised models for each round under Evol-Instruct scenario.", "description": "\uc774 \ud45c\ub294 Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c Llama-3.1-8B-Instruct(SLM)\uc640 Llama-3.1-70B-Instruct(LLM)\ub97c \uc0ac\uc6a9\ud558\uc5ec 3\ubc88\uc758 \ubc18\ubcf5 \ub3d9\uc548 \uc9c4\ud654\ub41c \uba85\ub839\uc5b4\uc758 \ub09c\uc774\ub3c4 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ubc18\ubcf5\uc5d0\uc11c SLM\uacfc LLM\uc73c\ub85c \uc0dd\uc131\ub41c \uba85\ub839\uc5b4 \ub370\uc774\ud130\uc14b(SLM-INST, LLM-INST)\uc5d0 \ub300\ud574 Alpaca, GSM8K Train, Code Alpaca \ub370\uc774\ud130\uc14b\uc758 \ub09c\uc774\ub3c4 \uc810\uc218\ub97c \ube44\uad50\ud569\ub2c8\ub2e4. \ub09c\uc774\ub3c4 \uc810\uc218\ub294 Qwen-2.5-72B-Instruct \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud3c9\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "| Iteration | Average Reward | Average Reward | Average Reward |\n|---|---|---|---| \n| | Alpaca | GSM8K | Code Alpaca |\n|---|---|---|---| \n| *Supervised Model: Llama-3.1-70B-Instruct* | | | | \n| Iteration 1 | 1.54 | 0.74 | 1.10 |\n| Iteration 2 | **1.68** | 0.73 | **1.19** |\n| Iteration 3 | **1.56** | 0.69 | **1.14** |\n| *Supervised Model: Llama-3.1-8B-Instruct* | | | |\n| Iteration 1 | **1.59** | **1.01** | **1.23** |\n| Iteration 2 | 1.54 | **0.79** | 0.96 |\n| Iteration 3 | 1.42 | **0.97** | 1.03 |", "caption": "Table 14: Comparison of average rewards among different iteration evolution instruction data.", "description": "\uc774 \ud45c\ub294 Evol-Instruct \uc2dc\ub098\ub9ac\uc624\uc5d0\uc11c \uc11c\ub85c \ub2e4\ub978 \ubc18\ubcf5 \uc9c4\ud589 \ud6c4 \uc9c4\ud654\ub41c \uba85\ub839 \ub370\uc774\ud130\uc758 \ud3c9\uade0 \ubcf4\uc0c1\uc744 \ube44\uad50\ud558\uc5ec SLM\uacfc LLM \uc911 \uc5b4\ub5a4 \uac83\uc774 \ub354 \ub098\uc740 \uba85\ub839\uc744 \uc0dd\uc131\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Llama-3.1-70B-Instruct\uc640 Llama-3.1-8B-Instruct\ub97c \uac10\ub3c5 \ubaa8\ub378\ub85c \uc0ac\uc6a9\ud558\uace0, \uc138 \uac00\uc9c0 \ub370\uc774\ud130\uc14b(Alpaca, GSM8K, Code Alpaca)\uc5d0 \ub300\ud574 \ubc18\ubcf5 1, 2, 3\uc758 \ud3c9\uade0 \ubcf4\uc0c1 \uc810\uc218\ub97c \ube44\uad50\ud569\ub2c8\ub2e4.", "section": "RQ1: Do SLMs Perform Better than LLMs in Evolving Instructions?"}, {"content": "| Datasets | IFD (%) | IC-IFD (%) | Performance |\n|---|---|---|---| \n| SLMs (Alpaca iter 3) | **83.04** | 35.89 | 40.64 |\n| LLMs (Alpaca iter 3) | 82.03 | **37.05** | **42.18** |", "caption": "Table 15: Comparison of IFD and IC-IFD on third-round evolved Alpaca datasets from SLMs and LLMs.", "description": "\uc774 \ud45c\ub294 \uc138 \ubc88\uc9f8 \uc9c4\ud654 \uacfc\uc815\uc744 \uac70\uce5c Alpaca \ub370\uc774\ud130\uc14b\uc5d0\uc11c SLM\uacfc LLM\uc73c\ub85c \uc0dd\uc131\ub41c \uc9c0\uc2dc\ubb38\uc758 IFD \ubc0f IC-IFD \uc810\uc218\ub97c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc9c0\uc2dc\ubb38\uc758 \ub09c\uc774\ub3c4\uac00 \ub9e4\uc6b0 \ub192\uc740 \uacbd\uc6b0, IFD \uc810\uc218\uac00 \uc99d\uac00\ud558\ub294 \uacbd\ud5a5\uc774 \uc788\uc9c0\ub9cc \ubbf8\uc138 \uc870\uc815\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \uae30\ub300\uc5d0 \ubbf8\uce58\uc9c0 \ubabb\ud558\ub294 \uacbd\uc6b0\uac00 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\uc640 \ubc18\ub300\ub85c, IC-IFD \uc810\uc218\ub294 \uc9c0\uc2dc\ubb38 \ubcf5\uc7a1\uc131\uc758 \uc601\ud5a5\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \ud3ec\ucc29\ud558\uc5ec \ubcf4\ub2e4 \uc815\ud655\ud55c \ub370\uc774\ud130 \ud488\uc9c8 \ud3c9\uac00\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. Llama-3-8B \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub450 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c IFEval\uc758 \ud3c9\uade0 \uc131\ub2a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.", "section": "RQ3: How Do We Determine Whether An Instruction is Effective without Instruction Tuning?"}]