[{"figure_path": "https://arxiv.org/html/2412.12098/x1.png", "caption": "(a) Normalized average performance of MaxInfoRL across several deep RL benchmarks on state-based tasks.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0c1\ud0dc \uae30\ubc18 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc5ec\ub7ec \ub525 \uac15\ud654 \ud559\uc2b5 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c MaxInfoRL\uc758 \uc815\uaddc\ud654\ub41c \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MaxInfoRL\uc740 \uc77c\uad00\ub418\uac8c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uba70 \ub300\ubd80\ubd84\uc758 \ud658\uacbd\uc5d0\uc11c \ub2e4\ub978 \uae30\uc900\uc120\ubcf4\ub2e4 \uc6b0\uc218\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x2.png", "caption": "(b) Normalized average performance of MaxInfoDrQv2 on the humanoid visual control tasks (stand, walk, and run).", "description": "\uc774 \uadf8\ub9bc\uc740 HumanoidBench \ubca4\uce58\ub9c8\ud06c\uc758 \uc138 \uac00\uc9c0 \uc791\uc5c5(\uc11c\uae30, \uac77\uae30, \ub2ec\ub9ac\uae30)\uc5d0 \ub300\ud55c MAXINFODRQV2\uc758 \uc815\uaddc\ud654\ub41c \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MAXINFODRQV2\ub294 \uc2dc\uac01\uc801 \uc81c\uc5b4 \uc791\uc5c5\uc744 \uc704\ud574 MAXINFORL\uc744 DrQv2\uc640 \uacb0\ud569\ud55c \uac83\uc785\ub2c8\ub2e4. \uacb0\uacfc\ub294 5\uac1c\uc758 \uc2dc\ub4dc\uc5d0 \ub300\ud574 \ud3c9\uade0\uc774 \uacc4\uc0b0\ub418\uc5c8\uc73c\uba70 \ud45c\uc900 \uc624\ucc28\uac00 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70 MAXINFODRQV2\uac00 \ubaa8\ub4e0 \uc791\uc5c5\uc5d0\uc11c DrQv2\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc11c\uae30 \uc791\uc5c5\uc5d0\uc11c \uc57d\uac04\uc758 \uc218\ub834 \uc9c0\uc5f0\uc774 \uc788\uc9c0\ub9cc \uc804\ubc18\uc801\uc73c\ub85c \ub354 \ub192\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud569\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x3.png", "caption": "Figure 1: We summarize the normalized performance of different variants of MaxInfoRL; MaxInfoSAC for state-based control and MaxInfoDrQv2 for visual control (cf.,\u00a0Section\u00a04 for more details). We report the mean performance across five seeds with one standard error.", "description": "\uc774 \uadf8\ub9bc\uc740 MaxInfoRL\uc758 \uc5ec\ub7ec \ubcc0\ud615\uc758 \uc815\uaddc\ud654\ub41c \uc131\ub2a5\uc744 \uc694\uc57d\ud55c \uac83\uc785\ub2c8\ub2e4. \uc0c1\ud0dc \uae30\ubc18 \uc81c\uc5b4\uc5d0\ub294 MaxInfoSAC\ub97c, \uc2dc\uac01\uc801 \uc81c\uc5b4\uc5d0\ub294 MaxInfoDrQv2\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4(\uc790\uc138\ud55c \ub0b4\uc6a9\uc740 4\uc7a5 \ucc38\uc870). 5\uac1c\uc758 \uc2dc\ub4dc\uc5d0 \ub300\ud55c \ud3c9\uade0 \uc131\ub2a5\uacfc \ud45c\uc900 \uc624\ucc28\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc67c\ucabd \uadf8\ub798\ud504(a)\ub294 \uc0c1\ud0dc \uae30\ubc18 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc5ec\ub7ec \ub525 \uac15\ud654 \ud559\uc2b5 \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c MaxInfoRL\uc758 \uc815\uaddc\ud654\ub41c \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc624\ub978\ucabd \uadf8\ub798\ud504(b)\ub294 \ud734\uba38\ub178\uc774\ub4dc \uc2dc\uac01 \uc81c\uc5b4 \uc791\uc5c5(\uc11c\uae30, \uac77\uae30, \ub2ec\ub9ac\uae30)\uc5d0 \ub300\ud55c MaxInfoDrQv2\uc758 \uc815\uaddc\ud654\ub41c \ud3c9\uade0 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "\uc18c\uac1c(Introduction)"}, {"figure_path": "https://arxiv.org/html/2412.12098/x4.png", "caption": "Figure 2: Learning curves of all methods on several environments from the OpenAI gym and DMC suite benchmarks.", "description": "\uc774 \uadf8\ub9bc\uc740 OpenAI Gym\uacfc DeepMind Control Suite \ubca4\uce58\ub9c8\ud06c\uc758 \uc5ec\ub7ec \ud658\uacbd\uc5d0\uc11c MAXINFORL(\ub179\uc0c9)\uc744 \ud3ec\ud568\ud55c \ub2e4\uc591\ud55c \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MAXINFORL\uc740 \ub300\ubd80\ubd84\uc758 \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \ubc29\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098 \uc77c\uad00\ub418\uac8c \ub354 \ub192\uc740 \ubcf4\uc0c1\uc5d0 \ub3c4\ub2ec\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x5.png", "caption": "Figure 3: Performance of MaxInfoSAC and SAC on the HumanoidBench benchmark.", "description": "\uc774 \uadf8\ub9bc\uc740 HumanoidBench \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c MaxInfoSAC\uc640 SAC\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MaxInfoSAC\ub294 stand \ud0dc\uc2a4\ud06c\ub97c \uc81c\uc678\ud55c \ubaa8\ub4e0 \ud0dc\uc2a4\ud06c\uc5d0\uc11c SAC\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud588\uc2b5\ub2c8\ub2e4. stand \ud0dc\uc2a4\ud06c\ub294 exploration\uc774 \ud544\uc694\uc5c6\ub294 \uc548\uc815\ud654 \ud0dc\uc2a4\ud06c\uc774\uae30 \ub54c\ubb38\uc5d0, \ub450 \uc54c\uace0\ub9ac\uc998\uc758 \uc131\ub2a5\uc774 \ube44\uc2b7\ud569\ub2c8\ub2e4. \uc804\ubc18\uc801\uc73c\ub85c MaxInfoSAC\ub294 SAC\uc5d0 \ube44\ud574 \uc0d8\ud50c \ud6a8\uc728\uc131\uacfc \ucd5c\uc885 \uc131\ub2a5 \ubaa8\ub450\uc5d0\uc11c \ud5a5\uc0c1\ub41c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x6.png", "caption": "Figure 4: Phase plots during learning of MaxInfoRL and SAC on the Pendulum environment. MaxInfoSAC covers the state space much faster and effectively solves the swing-up task within 10101010K environment interactions.", "description": "\uc774 \uadf8\ub9bc\uc740 MaxInfoRL\uacfc SAC \uc54c\uace0\ub9ac\uc998\uc744 Pendulum \ud658\uacbd\uc5d0\uc11c \ud559\uc2b5\uc2dc\ud0a4\ub294 \ub3d9\uc548\uc758 \uc704\uc0c1 \ud50c\ub86f\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MaxInfoSAC\uc740 \uc0c1\ud0dc \uacf5\uac04\uc744 SAC\ubcf4\ub2e4 \ud6e8\uc52c \ube60\ub974\uac8c \ucee4\ubc84\ud558\uba70, 10K \ud658\uacbd interaction \ub0b4\uc5d0 \uc2a4\uc719\uc5c5 \uacfc\uc81c(\ubaa9\ud45c \uc9c0\uc810: (0,0))\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud574\uacb0\ud569\ub2c8\ub2e4. SAC\ub294 exploration\uc774 \ub290\ub9ac\uae30 \ub54c\ubb38\uc5d0 \ud559\uc2b5 \ucd08\uae30 \ub2e8\uacc4\uc5d0\uc11c \uc0c1\ud0dc \uacf5\uac04\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ucee4\ubc84\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4. \ubc18\uba74, MaxInfoSAC\uc740 information gain\uc744 \ud1b5\ud574 directed exploration\uc744 \uc218\ud589\ud558\uc5ec \uc0c1\ud0dc \uacf5\uac04\uc744 \ube60\ub974\uac8c \ud0d0\uc0c9\ud558\uace0 \uc870\uae30\uc5d0 \ucd5c\uc801 \uc815\ucc45\uc73c\ub85c \uc218\ub834\ud569\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x7.png", "caption": "Figure 5: \n\nLearning curves for state-based tasks for different values of the action cost parameter K\ud835\udc3eKitalic_K.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc561\uc158 \ube44\uc6a9 \ub9e4\uac1c\ubcc0\uc218 \\(K\\)\uc758 \uc5ec\ub7ec \uac12\uc5d0 \ub300\ud574 \uc0c1\ud0dc \uae30\ubc18 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc561\uc158 \ube44\uc6a9\uc740 \uc5d0\uc774\uc804\ud2b8\uac00 \ud070 \uc561\uc158\uc744 \ucde8\ud560 \ub54c \ud328\ub110\ud2f0\ub97c \ubd80\uacfc\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 MAXINFORL\uc774 \uc5b4\ub824\uc6b4 \ud0d0\uc0c9 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ub370 \uc788\uc5b4\uc11c \uae30\uc900\uc120\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \ud2b9\ud788, MAXINFORL\uc740 CartPole \ubc0f Walker \uc791\uc5c5\uc5d0\uc11c \uc561\uc158 \ube44\uc6a9\uc774 \uc788\ub294 \uacbd\uc6b0 \uae30\uc900\uc120\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4. \ub610\ud55c \uadf8\ub9bc\uc740 \ud39c\ub4c8\ub7fc \ud658\uacbd\uc5d0\uc11c\uc758 \ud0d0\uc0c9 \ub2e8\uacc4\uc758 \uc704\uc0c1 \ub3c4\ud45c\ub97c \ubcf4\uc5ec\uc8fc\uba70, \uc5ec\uae30\uc11c MAXINFORL\uc740 SAC\ubcf4\ub2e4 \ud6e8\uc52c \ube60\ub974\uac8c \uc0c1\ud0dc \uacf5\uac04\uc744 \ucee4\ubc84\ud569\ub2c8\ub2e4. \uc774\uac83\uc740 MAXINFORL\uc774 \uc8fc\ub85c \uc815\ubcf4 \ud68d\ub4dd\uc744 \ud1b5\ud574 \ud0d0\uc0c9\uc744 \uc720\ub3c4\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x8.png", "caption": "Figure 6: Learning curves from visual control tasks of the DMC suite.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepMind Control Suite\uc758 \ub2e4\uc591\ud55c \uc2dc\uac01\uc801 \uc81c\uc5b4 \uc791\uc5c5\uc5d0 \ub300\ud55c \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MAXINFODRQ(\uc81c\uc548\ub41c \ubc29\ubc95)\ub294 DrQ \ubc0f DrQv2\uc640 \ube44\uad50\ub429\ub2c8\ub2e4. MAXINFODRQ\uac00 \ubaa8\ub4e0 \uc791\uc5c5\uc5d0\uc11c \ub354 \ub192\uc740 \ubcf4\uc0c1\uc5d0 \ub3c4\ub2ec\ud558\uace0 \uae30\uc900\uc120\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc0d8\ud50c \ud6a8\uc728\uc131\uc744 \ub2ec\uc131\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x9.png", "caption": "Figure 7: Learning curves from the visual control humanoid tasks of the DMC suite.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepMind Control Suite\uc758 Humanoid Stand, Walk, Run \ud0dc\uc2a4\ud06c\uc5d0 \ub300\ud55c \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MAXINFODRQV2\ub294 DrQv2\uc5d0 \ube44\ud574 \ubaa8\ub4e0 \ud0dc\uc2a4\ud06c\uc5d0\uc11c \ub354 \ub192\uc740 \ubcf4\uc0c1\uacfc \ub354 \ub098\uc740 \uc0d8\ud50c \ud6a8\uc728\uc131\uc5d0 \ub3c4\ub2ec\ud55c\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc815\ubcf4 \uc774\ub4dd\uc744 \ud1b5\ud55c \uc9c0\uc2dc\uc801 \ud0d0\uc0c9\uc758 \uc774\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x10.png", "caption": "Figure 8: Evolution of the intrinsic reward coefficient \u03bb\ud835\udf06\\lambdaitalic_\u03bb of SACEipo and MaxInfoSAC over environment interaction.", "description": "\uc774 \uadf8\ub9bc\uc740 SACEipo\uc640 MaxInfoSAC\uc758 \ub0b4\uc7a5 \ubcf4\uc0c1 \uacc4\uc218 \u03bb\uc758 \ubcc0\ud654\ub97c \ud658\uacbd \uc0c1\ud638 \uc791\uc6a9\uc5d0 \ub530\ub77c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. SACEipo\uc758 \uacbd\uc6b0, \u03bb \uac12\uc774 0\uc73c\ub85c \ube60\ub974\uac8c \uac10\uc18c\ud558\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\ub294\ub370, \uc774\ub294 \uc5d0\uc774\uc804\ud2b8\uac00 \ud0d0\uc0c9\uc744 \uba48\ucd94\uace0 \ud0d0\uc695\uc801\uc778 \ud589\ub3d9\uc744 \ud558\uac8c \ub418\uc5b4 \uc9c0\uc5ed \ucd5c\uc801\uc810\uc5d0 \uc218\ub834\ud558\uac8c \ub428\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ubc18\uba74, MaxInfoSAC\uc758 \uacbd\uc6b0, \u03bb \uac12\uc774 0\uc73c\ub85c \uac10\uc18c\ud558\uc9c0 \uc54a\uace0, \ub0b4\uc7a5 \ubcf4\uc0c1\uacfc \uc678\uc801 \ubcf4\uc0c1 \uc0ac\uc774\uc758 \uade0\ud615\uc744 \uc720\uc9c0\ud568\uc73c\ub85c\uc368 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 MaxInfoSAC\uc774 SACEipo\ubcf4\ub2e4 \ud0d0\uc0c9\uacfc \ud65c\uc6a9 \uc0ac\uc774\uc758 \uade0\ud615\uc744 \ub354 \ud6a8\uacfc\uc801\uc73c\ub85c \uc870\uc815\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x11.png", "caption": "Figure 9: We combine MaxInfoRL with REDQ (MaxInfoREDQ) and report the learning curves of SAC, REDQ, MaxInfoSAC, and MaxInfoREDQ.", "description": "\uc774 \uadf8\ub9bc\uc740 MaxInfoRL\uc744 REDQ\uc640 \uacb0\ud569\ud55c MaxInfoREDQ\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. Hopper, Walker, Humanoid \ud658\uacbd\uc5d0\uc11c SAC, REDQ, MaxInfoSAC\uc640 MaxInfoREDQ\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ube44\uad50\ud558\uc5ec MaxInfoREDQ\uac00 \ud5a5\uc0c1\ub41c \uc131\ub2a5\uacfc \uc0d8\ud50c \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x12.png", "caption": "Figure 10: Learning curves of MaxInfoDrQv2 with different noise levels \u03c3\u2208{0.0,0.2}\ud835\udf0e0.00.2\\sigma\\in\\{0.0,0.2\\}italic_\u03c3 \u2208 { 0.0 , 0.2 } compared to DrQv2 and MaxInfoDrQ.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepMind Control Suite\uc758 \uc5ec\ub7ec \uc2dc\uac01\uc801 \uc81c\uc5b4 \uc791\uc5c5\uc5d0 \ub300\ud55c MaxInfoDrQv2, DrQv2, MaxInfoDrQ\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MaxInfoDrQv2\ub294 \ub2e4\uc591\ud55c \ub178\uc774\uc988 \ub808\ubca8(\ud835\udf0e=0.0 \ubc0f \ud835\udf0e=0.2)\uc5d0\uc11c \ud3c9\uac00\ub429\ub2c8\ub2e4. \uc804\ubc18\uc801\uc73c\ub85c MaxInfoDrQv2\ub294 \ubaa8\ub4e0 \uc791\uc5c5\uc5d0\uc11c \ub2e4\ub978 \uae30\uc900\uc120\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uacfc \uc0d8\ud50c \ud6a8\uc728\uc131\uc5d0 \ub3c4\ub2ec\ud569\ub2c8\ub2e4. \ud765\ubbf8\ub86d\uac8c\ub3c4 MaxInfoDrQv2\ub294 \ud0d0\uc0c9\uc744 \uc704\ud55c \ub178\uc774\uc988\uac00 \ucd94\uac00\ub418\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uc5d0\ub3c4(\ud835\udf0e=0.0) \uc5ec\uc804\ud788 DrQv2\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub0a9\ub2c8\ub2e4. \uc774\ub294 \uc815\ubcf4 \uc774\ub4dd\uc744 \ud1b5\ud574 \uc9c0\uc2dc\ub41c \ud0d0\uc0c9\ub9cc\uc73c\ub85c\ub3c4 \ud6a8\uacfc\uc801\uc778 \ud0d0\uc0c9\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x13.png", "caption": "Figure 11: MaxInfoDrQv2 evaluated on the humanoid walk task with no action noise.", "description": "\uc774 \uadf8\ub9bc\uc740 DeepMind Control Suite\uc758 Humanoid-Walk \ud0dc\uc2a4\ud06c\uc5d0 \ub300\ud55c MAXINFODRQV2\uc758 \uc131\ub2a5\uc744 DrQv2\uc640 \ube44\uad50\ud569\ub2c8\ub2e4. MAXINFODRQV2\ub294 action noise \uc5c6\uc774 \ud559\uc2b5\ub418\uace0 \ud3c9\uac00\ub429\ub2c8\ub2e4. action noise\uac00 \uc5c6\ub294 DrQv2\ub294 \ub192\uc740 reward\ub97c \uc5bb\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \ubc18\uba74, action noise\uac00 \uc5c6\ub294 MAXINFODRQV2\ub294 \uc5ec\uc804\ud788 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub294 MAXINFODRQV2\uac00 \uc815\ubcf4 \uc774\ub4dd\uc744 \ud1b5\ud574 exploration\uc744 \ud6a8\uacfc\uc801\uc73c\ub85c \uc218\ud589\ud568\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "4 EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x14.png", "caption": "Figure 12: Learning curves of MaxInfoSAC with RND as the intrinsic reward, instead of the information gain, compared to SAC and standard MaxInfoSAC.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc138 \uac00\uc9c0 \ub2e4\ub978 \uac15\ud654 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc778 MaxInfoSAC(\uc815\ubcf4 \uc774\ub4dd\uc744 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \uc0ac\uc6a9), MaxInfoSAC[RND](RND\ub97c \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \uc0ac\uc6a9), \uadf8\ub9ac\uace0 SAC(\ub0b4\uc7ac\uc801 \ubcf4\uc0c1 \uc5c6\uc74c)\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MaxInfoSAC[RND]\ub294 \uc815\ubcf4 \uc774\ub4dd \ub300\uc2e0 RND\ub97c \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 MaxInfoSAC\uc758 \ubcc0\ud615\uc785\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uba87 \uac00\uc9c0 OpenAI Gym \ubc0f DeepMind Control Suite \ud658\uacbd\uc5d0\uc11c\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. action cost \ub9e4\uac1c\ubcc0\uc218 K\uc758 \uac12\uc774 \ub2e4\ub978 \uc138 \uac00\uc9c0 state-based \uc791\uc5c5\uc5d0 \ub300\ud55c \ud559\uc2b5 \uace1\uc120\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x15.png", "caption": "Figure 13: Learning curves of \u03f5italic-\u03f5\\epsilonitalic_\u03f5\u2013MaxInfoRL with disagreement as the intrinsic reward, SAC and MaxInfoSAC.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc0c1\ud0dc \uae30\ubc18 \uc791\uc5c5\uc5d0 \ub300\ud55c \u03f5-MaxInfoRL, SAC \ubc0f MaxInfoSAC\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \u03f5-MaxInfoRL\uc740 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \ubd88\uc77c\uce58\ub97c \uc0ac\uc6a9\ud558\uba70, \uc774\ub294 \ub3d9\uc801 \ubaa8\ub378 \uc559\uc0c1\ube14\uc758 \uc608\uce21 \uac04\uc758 \ucc28\uc774\ub85c \uacc4\uc0b0\ub429\ub2c8\ub2e4. SAC\ub294 \uc21c\uc218\ud55c \uc678\ubd80 \ubcf4\uc0c1\uc744 \uc0ac\uc6a9\ud558\ub294 \ubc18\uba74, MaxInfoSAC\ub294 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uacfc \uc678\ubd80 \ubcf4\uc0c1\uc744 \ubaa8\ub450 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \u03f5-MaxInfoRL\uc740 SAC\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\uace0 MaxInfoSAC\uc640 \uac70\uc758 \ub3d9\ub4f1\ud55c \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc744 \uc0ac\uc6a9\ud558\uc5ec \ud0d0\uc0c9\uc744 \uc548\ub0b4\ud558\uba74 \uc21c\uc218\ud55c \uc678\ubd80 \ubcf4\uc0c1\ub9cc \uc0ac\uc6a9\ud558\ub294 \uac83\ubcf4\ub2e4 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \uc5bb\uc744 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "Experiments with \u2208\u2013MaxInfoRL"}, {"figure_path": "https://arxiv.org/html/2412.12098/x16.png", "caption": "Figure 14: Learning curves of \u03f5italic-\u03f5\\epsilonitalic_\u03f5\u2013MaxInfoRL with disagreement as the intrinsic reward, SAC and MaxInfoSAC for varying levels of action costs K\ud835\udc3eKitalic_K.", "description": "\uc774 \uadf8\ub9bc\uc740 \u03f5-MaxInfoRL, SAC, MaxInfoSAC \uc54c\uace0\ub9ac\uc998\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \uc561\uc158 \ube44\uc6a9 K\uc758 \uc5ec\ub7ec \uac12\uc5d0 \ub300\ud574 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \u03f5-MaxInfoRL\uc740 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \ubd88\uc77c\uce58\ub97c \uc0ac\uc6a9\ud558\uace0 \uae30\ubcf8 \uc54c\uace0\ub9ac\uc998\uc73c\ub85c SAC\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\ub294 Pendulum, CartPole[Swingup sparse], Walker[Run] \ud658\uacbd\uc5d0 \ub300\ud55c \uacb0\uacfc\uac00 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \uc139\uc158 4(\uc2e4\ud5d8)\uc5d0 \uc788\uc2b5\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}, {"figure_path": "https://arxiv.org/html/2412.12098/x17.png", "caption": "Figure 15: Learning curves of \u03f5italic-\u03f5\\epsilonitalic_\u03f5\u2013MaxInfoRL with disagreement and curiosity as the intrinsic reward compared with SAC.", "description": "\uc774 \uadf8\ub9bc\uc740 OpenAI Gym\uacfc DeepMind Control Suite \ubca4\uce58\ub9c8\ud06c\uc758 \uc5ec\ub7ec \ud658\uacbd\uc5d0\uc11c \u03f5-MaxInfoRL(\ubd88\uc77c\uce58 \ubc0f \ud638\uae30\uc2ec\uc744 \ub0b4\uc7ac\uc801 \ubcf4\uc0c1\uc73c\ub85c \uc0ac\uc6a9)\uc758 \ud559\uc2b5 \uace1\uc120\uacfc SAC\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc804\ubc18\uc801\uc73c\ub85c \ubd88\uc77c\uce58\uc640 \ud638\uae30\uc2ec \ubaa8\ub450 SAC\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\uba70 \ubd88\uc77c\uce58\uac00 \ud638\uae30\uc2ec\ubcf4\ub2e4 \uc57d\uac04 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4.", "section": "Experiments"}, {"figure_path": "https://arxiv.org/html/2412.12098/x18.png", "caption": "Figure 16: Learning curves of \u03f5italic-\u03f5\\epsilonitalic_\u03f5\u2013MaxInfoRL with disagreement. We compare a version of \u03f5italic-\u03f5\\epsilonitalic_\u03f5\u2013MaxInfoRL which switches between extrinsic and intrinsic policy every step with one which switches every 32 steps.", "description": "\uc774 \uadf8\ub9bc\uc740 \u03f5-MaxInfoRL\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \u03f5-MaxInfoRL\uc774 extrinsic \uc815\ucc45\uacfc intrinsic \uc815\ucc45 \uac04\uc5d0 \uc804\ud658\ud558\ub294 \ube48\ub3c4\ub97c \ubcc0\uacbd\ud558\uc5ec \ube44\uad50\ud569\ub2c8\ub2e4. extrinsic \ubc0f intrinsic \uc815\ucc45 \uac04\uc5d0 \ub9e4 \uc2a4\ud15d\ub9c8\ub2e4 \uc804\ud658\ud558\ub294 \u03f5-MaxInfoRL \ubc84\uc804\uacfc 32 \uc2a4\ud15d\ub9c8\ub2e4 \uc804\ud658\ud558\ub294 \ubc84\uc804\uc744 \ube44\uad50\ud569\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c 32 \uc2a4\ud15d\ub9c8\ub2e4 \uc804\ud658\ud558\ub294 \ubc84\uc804\uc774 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc785\ub2c8\ub2e4. \uc774\ub294 \ub354 \uae34 \ud0d0\uc0c9 \ub370\uc774\ud130 trajectory\ub97c \uc218\uc9d1\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c, \ub354 \ub098\uc740 \ud0d0\uc0c9\uc744 \uc704\ud574\uc11c\ub294 exploration\uacfc exploitation policy\ub97c \ub108\ubb34 \uc790\uc8fc \uc804\ud658\ud558\uc9c0 \uc54a\ub294 \uac83\uc774 \ub354 \uc88b\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "E. Experiments with \n\u03f5\u2013MaxInfoRL"}, {"figure_path": "https://arxiv.org/html/2412.12098/x19.png", "caption": "Figure 17: Learning curves of OAC compared with MaxInfoSAC and a MaxInfoRL version of OAC (MaxInfoOAC).", "description": "\uc774 \uadf8\ub9bc\uc740 OpenAI Gym \ubc0f DeepMind Control Suite \ubca4\uce58\ub9c8\ud06c\uc758 \uc5ec\ub7ec \ud658\uacbd\uc5d0\uc11c Optimistic Actor Critic(OAC), MaxInfoSAC(\ubcf8 \uc5f0\uad6c\uc5d0\uc11c \uc81c\uc548), MaxInfoRL \ubc84\uc804\uc758 OAC(MaxInfoOAC)\uc758 \ud559\uc2b5 \uace1\uc120\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OAC\uac00 SAC\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\uc9c0\ub9cc MaxInfoRL \uc54c\uace0\ub9ac\uc998, \ud2b9\ud788 MaxInfoSAC\uc640 MaxInfoOAC\ub294 \ub2e4\ub978 \ubaa8\ub4e0 \ubc29\ubc95\ubcf4\ub2e4 \uc131\ub2a5\uc774 \ub6f0\uc5b4\ub098\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \uc815\ubcf4 \uc774\ub4dd\uc744 \ud1b5\ud55c \uc9c0\uc2dc\ub41c \ud0d0\uc0c9\uc758 \uc774\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. EXPERIMENTS"}]