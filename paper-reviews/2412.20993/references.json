{"references": [{"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "publication_date": "2022-03-17", "reason": "This paper introduces self-consistency, a fundamental LLM reasoning algorithm that Dynasor builds upon and optimizes."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-26", "reason": "This paper introduces GSM8K, a benchmark dataset heavily used in Dynasor's evaluations, demonstrating the effectiveness of the proposed system."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces chain-of-thought prompting, a key concept influencing LLM reasoning algorithms and the foundation for Dynasor's approach."}, {"fullname_first_author": "Lianmin Zheng", "paper_title": "Sglang: Efficient execution of structured language model programs", "publication_date": "2024-01-01", "reason": "SGLang serves as a baseline system in Dynasor's experimental comparisons, enabling performance improvements to be measured against existing state-of-the-art systems."}, {"fullname_first_author": "Woosuk Kwon", "paper_title": "Efficient memory management for large language model serving with pagedattention", "publication_date": "2023-01-01", "reason": "This paper details memory management optimizations for LLM serving that Dynasor incorporates and improves upon for reasoning workloads."}]}