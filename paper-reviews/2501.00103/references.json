{"references": [{"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-00-00", "reason": "This paper introduces Sora, a foundational model for text-to-video generation, establishing a key benchmark for subsequent models."}, {"fullname_first_author": "Adam Polyak", "paper_title": "MovieGen: A cast of media foundation models", "publication_date": "2024-10-24", "reason": "MovieGen significantly advanced text-to-video generation capabilities, setting a high bar for visual quality and coherence, and introducing the concept of a 3D VAE."}, {"fullname_first_author": "Zhuoyi Yang", "paper_title": "CogVideoX: Text-to-video diffusion models with an expert transformer", "publication_date": "2024-08-04", "reason": "CogVideoX demonstrated the effectiveness of combining spatiotemporal transformers with VAEs for high-quality video generation, representing a substantial improvement over previous methods."}, {"fullname_first_author": "Yang Jin", "paper_title": "Pyramidal flow matching for efficient video generative modeling", "publication_date": "2024-10-24", "reason": "PyramidFlow offered a highly efficient method for video generation by optimizing interactions between the transformer and the VAE, thus improving generation speed and reducing computational costs."}, {"fullname_first_author": "Junsong Chen", "paper_title": "Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis", "publication_date": "2023-10-00", "reason": "Pixart-alpha improved upon the DiT architecture, enhancing the effectiveness of transformers for conditional image generation; its approach informed the architecture of the Video Transformer in LTX-Video."}]}