[{"figure_path": "https://arxiv.org/html/2412.11457/x2.png", "caption": "Figure 1: \\Aclnvs and cross-view image matching. The first row shows that MOVIS generalizes to different datasets on NVS. We also show visualizations of cross-view consistency compared with Zero-1-to-3\u00a0[31] and ground truth by applying image-matching. MOVIS can match a significantly greater number of points, closely aligned with the ground truth.", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS(\uc81c\uc548\ub41c \ubc29\ubc95)\uac00 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b(Objaverse, 3D-FRONT, SUNRGB-D)\uc5d0\uc11c \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \ud569\uc131(NVS) \uc791\uc5c5\uc744 \uc5b4\ub5bb\uac8c \uc218\ud589\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud574 \uc785\ub825 \uc774\ubbf8\uc9c0, \ud0c0\uac9f \uc774\ubbf8\uc9c0(Ground Truth), MOVIS\uc758 \ucd9c\ub825, Zero-1-to-3\uc758 \ucd9c\ub825, Zero-1-to-3+\uc758 \ucd9c\ub825, ZeroNVS\uc758 \ucd9c\ub825\uc744 \uc2dc\uac01\ud654\ud588\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 Ground Truth \ubc0f \uac01 \ubaa8\ub378\uc758 \uc608\uce21 \uc774\ubbf8\uc9c0 \uac04\uc758 \uad50\ucc28 \uc2dc\uc810 \uc77c\uce58 \uc2dc\uac01\ud654\ub97c \ud1b5\ud574 \uad50\ucc28 \uc2dc\uc810 \uc77c\uad00\uc131\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. MOVIS\ub294 Ground Truth\uc640 \ub9e4\uc6b0 \uc720\uc0ac\ud558\uac8c \uc815\ud655\ud55c \uac1d\uccb4 \ubc30\uce58, \ubaa8\uc591 \ubc0f \uc678\uad00\uc744 \uac00\uc9c4 \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uba70, Zero-1-to-3 \ubc0f \ub2e4\ub978 \uae30\uc900\uc120\ubcf4\ub2e4 Ground Truth\uc5d0 \ub354 \uac00\uae5d\uac8c \uc77c\uce58\ud558\ub294 \ub9ce\uc740 \uc810\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.", "section": "1. Introduction"}, {"figure_path": "https://arxiv.org/html/2412.11457/x3.png", "caption": "Figure 2: Overview of MOVIS. Our model performs NVS from the input image and relative camera change. We introduce structure-aware features as additional inputs and employ mask prediction as an auxiliary task\u00a0(Sec.\u00a03.2). The model is trained with a structure-guided timestep sampling scheduler (Fig.\u00a03) to balance the learning of global object placement and local detail recovery.", "description": "MOVIS\ub294 \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uc0c1\ub300\uc801\uc778 \uce74\uba54\ub77c \ubcc0\ud654\ub97c \uae30\ubc18\uc73c\ub85c \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \ud569\uc131(NVS)\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uae4a\uc774 \ubc0f \uac1d\uccb4 \ub9c8\uc2a4\ud06c\uc640 \uac19\uc740 \uad6c\uc870 \uc778\uc2dd \uae30\ub2a5\uc774 \ucd94\uac00 \uc785\ub825\uc73c\ub85c \ud65c\uc6a9\ub418\uba70, \uac1d\uccb4 \ubc30\uce58 \ud559\uc2b5\uc744 \ubcf4\uc870\ud558\uae30 \uc704\ud574 \ubcf4\uc870 \uc791\uc5c5\uc73c\ub85c \ub9c8\uc2a4\ud06c \uc608\uce21\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uad6c\uc870 \uae30\ubc18 \ud0c0\uc784\uc2a4\ud15d \uc0d8\ud50c\ub9c1 \uc2a4\ucf00\uc904\ub7ec\ub97c \ud1b5\ud574 \uc804\uc5ed \uac1d\uccb4 \ubc30\uce58\uc640 \uad6d\ubd80\uc801 \uc138\ubd80 \uc0ac\ud56d \ubcf5\uad6c \uac04\uc758 \ud559\uc2b5 \uade0\ud615\uc744 \ub9de\ucda5\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \uc785\ub825 \uc774\ubbf8\uc9c0, \ubdf0, \uae4a\uc774, \ub9c8\uc2a4\ud06c, VAE, \ub178\uc774\uc988 \ucd94\uac00, UNet \ub514\ub178\uc774\uc800, \ud22c\uc601, \uc608\uce21\ub41c \ubdf0, \uc608\uce21\ub41c \ub9c8\uc2a4\ud06c \ubc0f \ud655\uc0b0 \ud6c8\ub828 \ubaa9\ud45c\ub97c \ud3ec\ud568\ud55c MOVIS\uc758 \uc804\uccb4 \uc544\ud0a4\ud14d\ucc98\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.11457/x4.png", "caption": "Figure 3: Visualization of inference. The early stage of the denoising process focuses on restoring global object placements, while the prediction of object masks requires a relatively noiseless image to recover fine-grained geometry. This motivates us to seek a balanced timestep sampling scheduler during training. The model trained w/ shift yields better mask prediction and thus recovers an image with more details and sharp object boundary. The w/o shift here refers to not shifting the \u03bc\ud835\udf07\\muitalic_\u03bc value.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub178\uc774\uc988 \uc81c\uac70 \uacfc\uc815 \uc911 \ub2e4\uc591\ud55c timestep\uc5d0\uc11c \uc608\uce21\ub41c \uc774\ubbf8\uc9c0\uc640 \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\ub97c \uc2dc\uac01\ud654\ud558\uc5ec timestep t\uac00 \uc804\uc5ed \ubc30\uce58 \uc815\ubcf4\uc640 \uad6d\ubd80\uc801 \uc138\ubd80 \uc815\ubcf4 \ud559\uc2b5\uc758 \uade0\ud615\uc744 \ub9de\ucd94\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud55c\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. w/ shift\ub85c \ud6c8\ub828\ub41c \ubaa8\ub378\uc740 \ub9c8\uc2a4\ud06c \uc608\uce21 \uc131\ub2a5\uc774 \ub354 \ub6f0\uc5b4\ub098\ubbc0\ub85c \ub354 \uc790\uc138\ud558\uace0 \uc120\uba85\ud55c \uac1d\uccb4 \uacbd\uacc4\ub97c \uac00\uc9c4 \uc774\ubbf8\uc9c0\ub97c \ubcf5\uad6c\ud569\ub2c8\ub2e4. \uc774\ub294 \ub178\uc774\uc988 \uc81c\uac70\uc758 \ucd08\uae30 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uc804\uc5ed \uac1d\uccb4 \ubc30\uce58 \ubcf5\uc6d0\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\uace0, \ud6c4\uae30 \ub2e8\uacc4\uc5d0\uc11c\ub294 \uac1d\uccb4 \ub9c8\uc2a4\ud06c \uc608\uce21 \ubc0f \uc138\ubd80\uc801\uc778 \uae30\ud558\ud559\uc801 \uad6c\uc870\uc640 \uc678\uad00 \ubcf5\uad6c\uc5d0 \ucd08\uc810\uc744 \ub9de\ucd94\ub294, \uade0\ud615 \uc7a1\ud78c timestep \uc0d8\ud50c\ub9c1 \uc2a4\ucf00\uc904\ub7ec\ub97c \uc0ac\uc6a9\ud574\uc57c \ud560 \ud544\uc694\uc131\uc744 \uac15\uc870\ud569\ub2c8\ub2e4. w/o shift\ub294 \u03bc \uac12\uc744 \uc774\ub3d9\ud558\uc9c0 \uc54a\ub294\ub2e4\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4.", "section": "3. Method"}, {"figure_path": "https://arxiv.org/html/2412.11457/x5.png", "caption": "Figure 4: Qualitative results of NVS and cross-view matching. Our method generates plausible novel-view images across various datasets, surpassing baselines regarding object placement, shape, and appearance. In cross-view matching, points of the same color indicate correspondences between the input and target views. We achieve a higher number of matched points with more precise locations.", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS\uac00 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc758 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uace0, \uc785\ub825 \uc2dc\uc810 \uc774\ubbf8\uc9c0\uc640 \ube44\uad50\ud558\uc5ec \uc815\ud655\ud55c \uac1d\uccb4 \ubc30\uce58, \ud615\ud0dc, \uc678\uad00\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uac83\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub610\ud55c, \uad50\ucc28 \uc2dc\uc810 \ub9e4\uce6d\uc5d0\uc11c \uc815\ud655\ud55c \uc704\uce58\ub97c \uac00\uc9c4 \ub354 \ub9ce\uc740 \ub9e4\uce6d \ud3ec\uc778\ud2b8\ub97c \ub2ec\uc131\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11457/x6.png", "caption": "Figure 5: Qualitative comparison for ablation study. Excluding mask predictions or the scheduler reduces the model\u2019s ability to learn object placement, as shown by the brown cabinet example.", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS \ubaa8\ub378\uc758 ablation study \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. mask \uc608\uce21\uc774\ub098 timestep scheduler\ub97c \uc81c\uac70\ud558\uba74 \ubaa8\ub378\uc774 \ubb3c\uccb4\uc758 \uc704\uce58\ub97c \ud559\uc2b5\ud558\ub294 \ub2a5\ub825\uc774 \uc800\ud558\ub418\ub294 \uac83\uc744 \uac08\uc0c9 \uce90\ube44\ub2db\uc744 \ud1b5\ud574 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. scheduler\uac00 \uc5c6\uc73c\uba74 \ubb3c\uccb4\uc758 \uc704\uce58\uac00 \ubd80\uc815\ud655\ud574\uc9c0\uace0, \uae4a\uc774 \ub610\ub294 \ub9c8\uc2a4\ud06c \uc785\ub825\uc744 \uc81c\uac70\ud558\uba74 \uacf5\uac04 \uad00\uacc4\uc640 \ubb3c\uccb4 \uc874\uc7ac\uc5d0 \ub300\ud55c \ubaa8\ub378\uc758 \uc774\ud574\ub3c4\uac00 \ub5a8\uc5b4\uc9d1\ub2c8\ub2e4. \ud2b9\ud788, \ub9c8\uc2a4\ud06c \uc608\uce21\uc744 \uc81c\uc678\ud558\uac70\ub098 scheduler \uc5c6\uc774 \ud559\uc2b5\ud558\uba74 \uac08\uc0c9 \uce90\ube44\ub2db\uc758 \ubc29\ud5a5\uc774 \uc798\ubabb \ud45c\ud604\ub418\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub294\ub370, \uc774\ub294 scheduler \uc5c6\uc774\ub294 \ubaa8\ub378\uc774 \ucd08\uae30 timestep\uc758 denoising\uc5d0 \uc9d1\uc911\ud558\uc5ec \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0 \ubcf5\uad6c\uc640 \uc138\ubc00\ud55c \uae30\ud558\ud559\uc801 \ud615\ud0dc \ubc0f \uc678\uad00 \uac1c\uc120\uc5d0 \ub300\ud55c \ud559\uc2b5\uc774 \ubd80\uc871\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c \ub9c8\uc2a4\ud06c \uc608\uce21\uacfc timestep scheduler\ub294 \uac1d\uccb4 \ubc30\uce58, \ubaa8\uc591, \uc678\uad00\uacfc \uac19\uc740 \uad6c\uc131\uc801 \uad6c\uc870 \uc815\ubcf4\ub97c \ud559\uc2b5\ud558\ub294 \ub370 \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.", "section": "4. Experiments"}, {"figure_path": "https://arxiv.org/html/2412.11457/x7.png", "caption": "Figure S.6: Illustration of different timestep sampling strategies.", "description": "\uc774 \uadf8\ub9bc\uc740 \uc11c\ub85c \ub2e4\ub978 \uc138 \uac00\uc9c0 \ud0c0\uc784\uc2a4\ud15d \uc0d8\ud50c\ub9c1 \uc804\ub7b5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. KMS\ub294 \ud3c9\uade0\uac12\uc744 \uc0c1\uc218\ub85c \uc720\uc9c0\ud558\uace0, LIND\ub294 \uae09\uaca9\ud788 \uac10\uc18c\ud55c \ud6c4 \uc120\ud615\uc801\uc73c\ub85c \uc99d\uac00\ud558\uba70, LDC\ub294 \uc120\ud615\uc801\uc73c\ub85c \uac10\uc18c\ud569\ub2c8\ub2e4. x\ucd95\uc740 \ud559\uc2b5 \ub2e8\uacc4\ub97c, y\ucd95\uc740 \ud3c9\uade0\uac12\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "A.4. Timestep scheduler"}, {"figure_path": "https://arxiv.org/html/2412.11457/x8.png", "caption": "Figure S.7: Comparison of different strategies. The predicted images and mask images under novel views using different strategies are visualized. We can observe that images predicted by the KMS strategy possess weird and blurry color while LDC strategy seems to be slightly better than LIND.", "description": "\uc774 \uadf8\ub9bc\uc740 \ub178\uc774\uc988 \ud0c0\uc784\uc2a4\ud15d \uc0d8\ud50c\ub9c1 \uc2a4\ucf00\uc904\ub7ec \uc804\ub7b5(KMS, LIND, LDC)\uc744 \ubcc0\uacbd\ud558\uba74\uc11c \uc608\uce21\ub41c \uc774\ubbf8\uc9c0\uc640 \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. KMS \uc804\ub7b5\uc73c\ub85c \uc608\uce21\ub41c \uc774\ubbf8\uc9c0\ub294 \uc774\uc0c1\ud558\uace0 \ud750\ub9bf\ud55c \uc0c9\uc0c1\uc744 \ub098\ud0c0\ub0b4\ub294 \ubc18\uba74 LDC \uc804\ub7b5\uc774 LIND\ubcf4\ub2e4 \uc57d\uac04 \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \uc804\ub7b5\uc5d0 \ub300\ud55c \uc815\ub7c9\uc801 \ud3c9\uac00 \uacb0\uacfc\ub294 \ud45c S.3\uc5d0 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc73c\uba70, \uc774 \uadf8\ub9bc\uc740 \uadf8 \uacb0\uacfc\ub97c \ubcf4\uc644\ud558\ub294 \uc2dc\uac01\uc801 \ube44\uad50\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.", "section": "B.4. Results"}, {"figure_path": "https://arxiv.org/html/2412.11457/x9.png", "caption": "Figure S.8: Visualized comparison on Room-Texture\u00a0[35], SUNRGB-D\u00a0[49], and 3D-FRONT\u00a0[14].", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS \ubaa8\ub378\uacfc \uae30\uc900 \ubaa8\ub378(Zero-1-to-3, Zero-1-to-3+, ZeroNVS)\uc758 \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \ud569\uc131(NVS) \uacb0\uacfc\ub97c Room-Texture, SUNRGB-D, 3D-FRONT \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc2dc\uac01\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uac01 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc785\ub825 \uc774\ubbf8\uc9c0, \ud0c0\uac9f \uc774\ubbf8\uc9c0, \uac01 \ubaa8\ub378\uc774 \uc608\uce21\ud55c \uc774\ubbf8\uc9c0, \uadf8\ub9ac\uace0 \uc608\uce21\ub41c \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\uac00 \ud568\uaed8 \uc81c\uc2dc\ub429\ub2c8\ub2e4. \uadf8\ub9bc\uc5d0\uc11c 'N/A'\ub85c \ud45c\uc2dc\ub41c \ubd80\ubd84\uc740 \ud574\ub2f9 \ub370\uc774\ud130\uc14b\uc5d0 \ub9c8\uc2a4\ud06c \uc815\ubcf4\uac00 \uc5c6\uc5b4\uc11c \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uc9c0 \ubabb\ud588\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 MOVIS \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uae30\uc900 \ubaa8\ub378\ubcf4\ub2e4 \ub354 \uc0ac\uc2e4\uc801\uc774\uace0 \uc77c\uad00\ub41c \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "B.4. Results"}, {"figure_path": "https://arxiv.org/html/2412.11457/x10.png", "caption": "Figure S.9: Continuous rotation examples on SUNRGB-D and 3D-FRONT. We rotate the camera around the multi-object composites, successfully synthesizing plausible novel-view images across a wide range of camera pose variations. This first five examples are from SUNRGB-D, and the last three examples are from 3D-FRONT.", "description": "\uc774 \uadf8\ub9bc\uc740 SUNRGB-D\uc640 3D-FRONT \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc5ec\ub7ec \uac1d\uccb4\ub85c \uad6c\uc131\ub41c \uc7a5\uba74\uc5d0 \ub300\ud55c \uc5f0\uc18d\uc801\uc778 \ud68c\uc804\uc73c\ub85c \uc0dd\uc131\ub41c \uc0c8\ub85c\uc6b4 \uc2dc\uc810 \uc774\ubbf8\uc9c0\ub4e4\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uce74\uba54\ub77c\uc758 \uc704\uce58\uc640 \uac01\ub3c4\ub97c \ub2e4\uc591\ud558\uac8c \ubc14\uafb8\uba74\uc11c \uc0ac\uc2e4\uc801\uc778 \uc774\ubbf8\uc9c0\ub4e4\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc8fc\uace0, \uc0c1\uc704 5\uac1c\uc758 \uc608\uc2dc\ub294 SUNRGB-D, \ud558\uc704 3\uac1c\uc758 \uc608\uc2dc\ub294 3D-FRONT \ub370\uc774\ud130\uc14b\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.", "section": "B.4. Results"}, {"figure_path": "https://arxiv.org/html/2412.11457/x11.png", "caption": "Figure S.10: Visualized cross-view matching results. Since we do not have ground truth image for 3D-FRONT and SUNRGB-D, we only visualize cross-view matching results using our predicted images. But we can still observe a strong cross-view consistency from the accurate matching results.", "description": "\uc774 \uadf8\ub9bc\uc740 3D-FRONT \ubc0f SUNRGB-D \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uad50\ucc28 \ubdf0 \ub9e4\uce6d \uacb0\uacfc\ub97c \uc2dc\uac01\ud654\ud558\uc5ec \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc2e4\uc81c \uc774\ubbf8\uc9c0\uc640 \uc608\uce21\ub41c \uc774\ubbf8\uc9c0 \uac04\uc758 \ub9e4\uce6d \ud3ec\uc778\ud2b8\ub97c \uc2dc\uac01\ud654\ud588\uc73c\uba70, \uc815\ud655\ud55c \ub9e4\uce6d \uacb0\uacfc\ub97c \ud1b5\ud574 \uac15\ub825\ud55c \uad50\ucc28 \ubdf0 \uc77c\uad00\uc131\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. 3D-FRONT\uc640 SUNRGB-D\uc758 \uacbd\uc6b0 \uc815\ub2f5 \uc774\ubbf8\uc9c0\uac00 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \uc608\uce21\ub41c \uc774\ubbf8\uc9c0\ub9cc \uc0ac\uc6a9\ud558\uc5ec \uad50\ucc28 \ubdf0 \ub9e4\uce6d \uacb0\uacfc\ub97c \uc2dc\uac01\ud654\ud588\uc2b5\ub2c8\ub2e4.", "section": "B.4. Results"}, {"figure_path": "https://arxiv.org/html/2412.11457/x12.png", "caption": "Figure S.11: Failure Cases. It is hard for our model to learn extremely fine-grained consistency on objects with delicate structure and texture.", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS \ubaa8\ub378\uc774 \uc12c\uc138\ud55c \uad6c\uc870\ub098 \uc9c8\uac10\uc744 \uac00\uc9c4 \ubb3c\uccb4\uc5d0 \ub300\ud574\uc11c\ub294 \uc138\ubc00\ud55c \uc77c\uad00\uc131\uc744 \ud559\uc2b5\ud558\ub294 \ub370 \uc5b4\ub824\uc6c0\uc744 \uacaa\ub294 \uc2e4\ud328 \uc0ac\ub840\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \uc18c\ud30c\uc758 \ud654\ub824\ud55c \ucfe0\uc158\uc774\ub098 \uc758\uc790\uc758 \uac00\ub290\ub2e4\ub780 \ub2e4\ub9ac\uc640 \uac19\uc740 \ubd80\ubd84\uc740 \ubaa8\ub378\uc774 \ud559\uc2b5\ud558\uae30 \uc5b4\ub824\uc6cc\ud569\ub2c8\ub2e4. \ubb3c\uccb4 \ubc30\uce58\ub294 \ub300\ub7b5\uc801\uc73c\ub85c \uc815\ud655\ud558\uc9c0\ub9cc, \uc774\ub7ec\ud55c \uacbd\uc6b0 \uc138\ubc00\ud55c \ubd80\ubd84\uc758 \uc77c\uad00\uc131\uc740 \uc774\uc0c1\uc801\uc774\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uace0\ud574\uc0c1\ub3c4 \ud559\uc2b5\uacfc \uc5d0\ud53c\ud3f4\ub77c \uc81c\uc57d \uc870\uac74\uc744 \ud1b5\ud569\ud558\uba74 \uc774 \ubb38\uc81c\uac00 \uc644\ud654\ub420 \uac83\uc73c\ub85c \uc608\uc0c1\ub429\ub2c8\ub2e4.", "section": "C. Failure Cases and Limitations"}, {"figure_path": "https://arxiv.org/html/2412.11457/x13.png", "caption": "Figure S.12: Occlusion Synthesis Capability. Our proposed method can synthesize new occlusion relationship under novel views as shown in the highlighted area of sofa or cabinet in (a). Our method can also hallucinate occluded parts as shown in the highlighted area of chairs in (b).", "description": "\uc774 \uadf8\ub9bc\uc740 MOVIS \ubaa8\ub378\uc758 \ud3d0\uc0c9 \ud569\uc131 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. (a)\uc5d0\uc11c\ub294 \uc18c\ud30c\uc640 \uce90\ube44\ub2db\uc758 \uac15\uc870\ub41c \uc601\uc5ed\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc5d0\uc11c \uac00\ub824\uc9c4 \ubd80\ubd84\uc744 \ud569\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc989, \uc785\ub825 \uc2dc\uc810\uc5d0\uc11c\ub294 \uac00\ub824\uc838 \ubcf4\uc774\uc9c0 \uc54a\ub358 \ubd80\ubd84\uc774 \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc5d0\uc11c\ub294 \ubcf4\uc774\ub3c4\ub85d \ud569\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (b)\uc5d0\uc11c\ub294 \uc758\uc790\uc758 \uac15\uc870\ub41c \uc601\uc5ed\uc5d0\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc5d0\uc11c \uac00\ub824\uc9c4 \ubb3c\uccb4\uc758 \ubd80\ubd84\uc744 \ubcf5\uc6d0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc989, \uc785\ub825 \uc2dc\uc810\uc5d0\uc11c\ub294 \uc644\uc804\ud788 \ubcf4\uc774\ub358 \ubb3c\uccb4\uac00 \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc5d0\uc11c\ub294 \uc77c\ubd80\ubd84\uc774 \uac00\ub824\uc9c0\ub294 \uacbd\uc6b0, \uac00\ub824\uc9c4 \ubd80\ubd84\uc744 \ucd94\ub860\ud558\uc5ec \ud569\uc131\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub378\uc774 \ub2e4\uc911 \uac1d\uccb4\uc758 \ubc30\uce58 \ubc0f \uc0c1\ud638 \uc791\uc6a9\uc744 \uc5b4\ub290 \uc815\ub3c4 \uc774\ud574\ud558\uace0 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.", "section": "B.6. Mutual Occlusion"}, {"figure_path": "https://arxiv.org/html/2412.11457/x16.png", "caption": "Figure S.13: Object Removal Example. We can remove an object under novel views by setting a threshold to the predicted mask image and delete corresponding pixels.", "description": "\uc774 \uadf8\ub9bc\uc740 \uac1d\uccb4 \uc81c\uac70 \uae30\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc608\uce21\ub41c \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\uc5d0 \uc784\uacc4\uac12\uc744 \uc124\uc815\ud558\uc5ec \ud2b9\uc815 \uac1d\uccb4\ub97c \uc81c\uac70\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0\uc640 \uc608\uce21\ub41c \uc774\ubbf8\uc9c0, \uadf8\ub9ac\uace0 \uac1d\uccb4\uac00 \uc81c\uac70\ub41c \uc774\ubbf8\uc9c0\ub97c \ube44\uad50\ud558\uc5ec \uc81c\uac70 \uae30\ub2a5\uc774 \uc5b4\ub5bb\uac8c \uc791\ub3d9\ud558\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uce68\ub300\uc640 \ud0c1\uc790\ub97c \uac01\uac01 \uc81c\uac70\ud558\ub294 \ub450 \uac00\uc9c0 \uc608\uc2dc\uac00 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.", "section": "B.5. Applications"}, {"figure_path": "https://arxiv.org/html/2412.11457/x17.png", "caption": "Figure S.14: Reconstruction results using DUSt3R. We rotate our camera around the multi-object composite and use the predicted images along with the input-view image for reconstruction.", "description": "\uc774 \uadf8\ub9bc\uc740 DUSt3R\uc744 \uc0ac\uc6a9\ud55c 3D \uc7ac\uad6c\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc5ec\ub7ec \uac01\ub3c4\uc5d0\uc11c \uc608\uce21\ub41c \uc774\ubbf8\uc9c0\uc640 \uc785\ub825 \ubdf0 \uc774\ubbf8\uc9c0\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uc5ec \uc5ec\ub7ec \uac1c\uccb4\ub85c \uad6c\uc131\ub41c \uc7a5\uba74\uc744 \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4. \uc8fc\uc5b4\uc9c4 \uc785\ub825 \ubdf0 \uc774\ubbf8\uc9c0\uc640 \uc5ec\ub7ec \uc608\uce21\ub41c \ubdf0 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc6a9\ud558\uc5ec DUSt3R\uc744 \ud1b5\ud574 \uc7a5\uba74\uc758 3D \ubaa8\ub378\uc744 \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4. \uadf8\ub9bc\uc740 \ub2e4\uc591\ud55c \uac01\ub3c4\uc5d0\uc11c \ub80c\ub354\ub9c1\ub41c \uc7ac\uad6c\uc131\ub41c \uc7a5\uba74\uc744 \ubcf4\uc5ec\uc8fc\uba70, \ubaa8\ub378\uc774 \uc7a5\uba74\uc758 3D \uad6c\uc870\ub97c \uc774\ud574\ud558\uace0 \uc77c\uad00\ub41c \uc5ec\ub7ec \ubdf0\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "B.5. Applications"}, {"figure_path": "https://arxiv.org/html/2412.11457/x18.png", "caption": "Figure S.15: More visualized results on C3DFS dataset.", "description": "\uc774 \uadf8\ub9bc\uc740 C3DFS \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uc2dc\uac01\ud654 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc785\ub825 \uc774\ubbf8\uc9c0, \uc608\uce21\ub41c \uc774\ubbf8\uc9c0, \ubaa9\ud45c \uc774\ubbf8\uc9c0, \ub9c8\uc2a4\ud06c \uc774\ubbf8\uc9c0\uac00 \uc21c\uc11c\ub300\ub85c \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uadf8\ub9bc\uc740 \ubaa8\ub378\uc774 \ub2e4\uc591\ud55c \uc785\ub825 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \uc0c8\ub85c\uc6b4 \uc2dc\uc810\uc758 \uc774\ubbf8\uc9c0\uc640 \ub9c8\uc2a4\ud06c\ub97c \uc5bc\ub9c8\ub098 \uc798 \uc608\uce21\ud558\ub294\uc9c0 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "B.4. Results"}]