<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Paper Reviews by AI on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/</link><description>Recent content in Paper Reviews by AI on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Tue, 29 Oct 2024 20:55:37 +0100</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/index.xml" rel="self" type="application/rss+xml"/><item><title>Causal Diffusion Transformers for Generative Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</guid><description>CausalFusion은 확산 및 자기 회귀 모델을 결합하여 생성 모델링에서 최첨단 결과를 달성하고 새로운 기능을 가능하게 합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/cover.png"/></item><item><title>ColorFlow: Retrieval-Augmented Image Sequence Colorization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</guid><description>만화 채색 자동화: ColorFlow는 ID 일관성을 유지하면서 흑백 만화 시퀀스를 채색합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/cover.png"/></item><item><title>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</guid><description>GeoX: MLLM보다 뛰어난 기하학적 문제 해결사!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/cover.png"/></item><item><title>IDArb: Intrinsic Decomposition for Arbitrary Number of Input Views and Illuminations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</guid><description>IDArb: Decomposition under varied lights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/cover.png"/></item><item><title>Just a Simple Transformation is Enough for Data Protection in Vertical Federated Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</guid><description>간단한 변환만으로 수직 연합 학습에서 데이터 보호 가능.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/cover.png"/></item><item><title>MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</guid><description>정보 이득으로 강화 학습 탐색을 강화.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/cover.png"/></item><item><title>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</guid><description>MOVIS는 실내 장면에 대한 멀티-객체 novel view synthesis에서 구조적 인식을 향상시켜 일관성 있고 사실적인 novel view를 생성합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/cover.png"/></item><item><title>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</guid><description>실시간 이미지 보호, 딥페이크 대비책.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/cover.png"/></item><item><title>RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</guid><description>RetroLLM: 검색과 생성을 통합한 RAG 시스템</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/cover.png"/></item><item><title>SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</guid><description>SepLLM은 특수 토큰의 중요성을 활용하여 LLM 추론을 가속화하고 긴 시퀀스를 효율적으로 처리합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/cover.png"/></item><item><title>SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</guid><description>Self-play with refinement boosts instruction-following in LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/cover.png"/></item><item><title>StrandHead: Text to Strand-Disentangled 3D Head Avatars Using Hair Geometric Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</guid><description>&amp;rsquo;&amp;rsquo; StrandHead: 텍스트만으로 사실적인 3D 헤드 아바타와 섬세한 헤어스타일까지 생성.''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/cover.png"/></item><item><title>The Open Source Advantage in Large Language Models (LLMs)</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</guid><description>오픈소스 LLM, 폐쇄형 LLM 대비 투명성과 접근성은 높지만, 성능은 낮음. 하이브리드 전략이 미래.</description></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT: 하이브리드 음성 및 음악 LLM으로, 연속 오디오와 이산 토큰을 결합하여 향상된 성능을 제공합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item><item><title>Wonderland: Navigating 3D Scenes from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</guid><description>단일 이미지로 고품질 3D 장면을 생성하는 효율적이고 확장 가능한 프레임워크</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/cover.png"/></item><item><title>DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</guid><description>DynamicScaler는 텍스트나 이미지에서 긴 &lt;strong>끊김 없는 파노라마 비디오&lt;/strong>를 생성하며, &lt;strong>해상도와 종횡비에 관계없이 일관된 움직임을 유지&lt;/strong>합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/cover.png"/></item><item><title>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</guid><description>GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"/></item><item><title>Reliable, Reproducible, and Really Fast Leaderboards with Evalica</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</guid><description>Evalica: 벤치마킹을 쉽고 빠르고 신뢰할 수 있게 만드는 툴킷</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/cover.png"/></item><item><title>Smaller Language Models Are Better Instruction Evolvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</guid><description>소형 언어 모델이 더 나은 명령 생성자!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/cover.png"/></item><item><title>VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</guid><description>VividFace: 첫 번째 확산 기반 비디오 얼굴 바꾸기 프레임워크로 고충실도 결과 제공.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/cover.png"/></item><item><title>Apollo: An Exploration of Video Understanding in Large Multimodal Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</guid><description>Apollo: 대규모 멀티모달 모델의 비디오 이해를 위한 심층 탐구.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/cover.png"/></item><item><title>BrushEdit: All-In-One Image Inpainting and Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</guid><description>BrushEdit: All-in-One Image Inpainting &amp;amp; Editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/cover.png"/></item><item><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</guid><description>BLT: 바이트 기반 LLM, 토큰보다 패치 우선.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/cover.png"/></item><item><title>Efficient Generative Modeling with Residual Vector Quantization-Based Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</guid><description>ResGen, 고품질 생성과 빠른 샘플링 속도를 모두 달성하는 효율적인 RVQ 기반 생성 모델.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/cover.png"/></item><item><title>Large Action Models: From Inception to Implementation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</guid><description>LLM에서 LAM으로: 실제 작업을 수행하는 AI 에이전트 구축.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/cover.png"/></item><item><title>LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</guid><description>LinGen: 분 단위 고해상도 텍스트-투-비디오 생성, 선형 계산 복잡도로 효율성 극대화</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/cover.png"/></item><item><title>Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attacks on Breast Ultrasound Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</guid><description>P2P: 텍스트 기반의 새로운 적대적 공격으로 의료 영상 DNN의 취약성 공략</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/cover.png"/></item><item><title>RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</guid><description>RLDG는 강화 학습을 통해 생성된 고품질 데이터로 범용 로봇 정책의 성능을 향상시키는 획기적인 방법입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/cover.png"/></item><item><title>SCBench: A KV Cache-Centric Analysis of Long-Context Methods</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</guid><description>SCBench는 멀티턴 및 멀티리퀘스트 시나리오에서 장문 맥락 메서드를 평가하는 새로운 벤치마크입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/cover.png"/></item><item><title>SplineGS: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</guid><description>SplineGS: 실시간 동적 3D 장면을 위한 강력한 모션 적응형 스플라인.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/cover.png"/></item><item><title>TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</guid><description>TraceVLA: 과거의 움직임을 시각적으로 보여줌으로써 로봇의 시공간적 인식을 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/cover.png"/></item><item><title>FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</guid><description>''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/cover.png"/></item><item><title>FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</guid><description>FreeScale로 튜닝 없이 8K 이미지 생성!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/cover.png"/></item><item><title>GenEx: Generating an Explorable World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</guid><description>GenEx: 단일 이미지로 탐색 가능한 3D 세계 생성.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/cover.png"/></item><item><title>GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</guid><description>GREATER는 추론에 대한 그레이디언트를 활용하여 소규모 언어 모델의 프롬프트를 최적화하여 대규모 LLM 없이도 성능을 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/cover.png"/></item><item><title>InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</guid><description>InstanceCap: 인스턴스 인식 구조화 캡션을 통해 텍스트-비디오 생성을 개선합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/cover.png"/></item><item><title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</guid><description>InternLM-XComposer2.5-OmniLive: 실시간 스트리밍 비디오 및 오디오 상호작용을 위한 인간의 인지능력을 모방한 혁신적 다중 모드 AI 시스템</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/cover.png"/></item><item><title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</guid><description>VMB는 텍스트 및 음악 브리지를 활용하여 멀티모달 음악 생성을 위한 새롭고 제어 가능한 프레임워크를 제시합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/cover.png"/></item><item><title>Phi-4 Technical Report</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</guid><description>Phi-4: 140억 매개변수 언어 모델은 &lt;strong>데이터 품질에 중점을 둔 훈련 레시피&lt;/strong>로 개발되어 추론 능력을 대폭 향상시켰습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/cover.png"/></item><item><title>SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</guid><description>SynerGen-VL: 간단한 구조로 이미지 이해 및 생성을 동시에 수행하는 강력한 MLLM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/cover.png"/></item><item><title>ObjectMate: A Recurrence Prior for Object Insertion and Subject-Driven Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</guid><description>객체 합성의 새 시대: ObjectMate로 튜닝 없이 사실적인 결과를 얻으세요.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/cover.png"/></item><item><title>SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</guid><description>Smaller language models reason better with fine-tuned training recipes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/cover.png"/></item><item><title>TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</guid><description>TidyBot++: 저비용, 홀로노믹 이동 조작기 &amp;amp; 핸드폰 텔레오퍼레이션 인터페이스 공개</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/cover.png"/></item><item><title>BiMediX2: Bio-Medical EXpert LMM for Diverse Medical Modalities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</guid><description>BiMediX2: 아랍어-영어 이중 언어 의료 전문가 LMM 출시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/cover.png"/></item><item><title>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</guid><description>Evaluation Agent: 더 빠르고, 유연하며, 설명 가능한 시각적 생성 모델 평가 프레임워크.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/cover.png"/></item><item><title>NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</guid><description>NeuZip dynamically compresses neural network weights, achieving memory-efficient training and inference without performance loss, significantly reducing the memory footprint of large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/cover.png"/></item><item><title>Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.14703/</link><pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.14703/</guid><description>LLM의 개성을 정량적으로 평가하는 새로운 벤치마크 TRAIT 제시: 신뢰성 및 타당성 높은 8,000개의 질문으로 구성, LLM 개성의 독특성과 일관성 규명, 모델 정렬 과정의 영향 분석 및 제한점 제시.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2406.14703/cover.png"/></item><item><title>Background-aware Moment Detection for Video Moment Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2306.02728/</link><pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2306.02728/</guid><description>BM-DETR: 배경 정보 활용으로 비디오 순간 검색의 약한 정렬 문제 해결!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2306.02728/cover.png"/></item></channel></rss>