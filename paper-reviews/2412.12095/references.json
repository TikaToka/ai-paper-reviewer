{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising Diffusion Probabilistic Models", "publication_date": "2020-01-01", "reason": "This paper introduced the foundational framework of denoising diffusion probabilistic models, which is the core concept upon which CausalFusion builds."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion Models Beat GANs on Image Synthesis", "publication_date": "2021-01-01", "reason": "This work demonstrated the superiority of diffusion models over GANs for image synthesis, establishing diffusion as a leading approach for visual generation."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language Models are Few-Shot Learners", "publication_date": "2020-01-01", "reason": "This paper introduced GPT-3 and highlighted the power of autoregressive models, particularly their ability for in-context learning, which is a key aspect integrated into CausalFusion."}, {"fullname_first_author": "William Peebles", "paper_title": "Scalable Diffusion Models with Transformers", "publication_date": "2023-01-01", "reason": "This paper proposed DiT, which utilizes transformers for diffusion models, demonstrating their scalability for high-resolution image generation and serving as the architectural basis for CausalFusion."}, {"fullname_first_author": "Chunting Zhou", "paper_title": "Transfusion: Predict the next token and diffuse images with one multi-modal model", "publication_date": "2024-08-01", "reason": "This work is a relevant concurrent study on unifying next-token prediction and diffusion for multimodal generation and provides a direct comparison point for CausalFusion."}]}