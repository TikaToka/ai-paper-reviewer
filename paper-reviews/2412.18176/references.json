{"references": [{"fullname_first_author": "Yehuda Koren", "paper_title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "publication_date": "2008-08-01", "reason": "This paper is foundational to collaborative filtering, a core concept in sequential recommendation, providing a multifaceted model that significantly improved performance."}, {"fullname_first_author": "Steffen Rendle", "paper_title": "Factorizing personalized Markov chains for next-basket recommendation", "publication_date": "2010-04-01", "reason": "This paper introduced Factorizing Personalized Markov Chains (FPMC), a highly influential model for sequential recommendation that effectively captures user dynamic interests."}, {"fullname_first_author": "Wang-Cheng Kang", "paper_title": "Self-attentive sequential recommendation", "publication_date": "2018-12-01", "reason": "This paper proposed Self-Attentive Sequential Recommendation (SASRec), a pioneering model leveraging self-attention mechanisms for superior performance in capturing sequential patterns."}, {"fullname_first_author": "Guorui Zhou", "paper_title": "Deep interest network for click-through rate prediction", "publication_date": "2018-08-01", "reason": "This paper introduced the Deep Interest Network (DIN), a highly influential model for click-through rate prediction that effectively captures user interests and context, applicable to recommendation systems."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2018-10-18", "reason": "BERT is a highly influential pre-trained language model that greatly advanced natural language processing and is now widely used in multimodal LLMs and recommendation systems."}]}