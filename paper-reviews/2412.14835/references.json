{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-09", "reason": "This paper introduces Flamingo, a visual language model that is foundational to the field of multimodal reasoning, and is directly referenced as such in the introduction."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper introduces the MATH dataset and the concept of training verifiers for mathematical reasoning, which is a core concept used in this paper's methodology."}, {"fullname_first_author": "Guanting Dong", "paper_title": "CORAL: benchmarking multi-turn conversational retrieval-augmentation generation", "publication_date": "2024-10-21", "reason": "This paper introduces the CORAL benchmark, relevant to the evaluation of this paper's framework."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-24", "reason": "This paper introduces the widely used CLIP model, which is fundamental to multimodal reasoning and directly used in this paper's retrieval module."}, {"fullname_first_author": "Pan Lu", "paper_title": "MathVista: Evaluating mathematical reasoning of foundation models in visual contexts", "publication_date": "2024-05-11", "reason": "This paper introduces the MATHVISTA benchmark, one of the primary benchmarks used to evaluate the performance of this paper's proposed framework."}]}