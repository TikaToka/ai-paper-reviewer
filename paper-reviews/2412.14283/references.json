{"references": [{"fullname_first_author": "Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, a foundation for many consistent object editing methods."}, {"fullname_first_author": "Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper demonstrates the ability of diffusion models to generate photorealistic images from text prompts, enabling a crucial component for image editing tasks."}, {"fullname_first_author": "Epstein", "paper_title": "Diffusion self-guidance for controllable image generation", "publication_date": "2023-00-00", "reason": "This paper introduces a training-free method for controllable image generation using diffusion models, which is highly relevant to consistent object editing."}, {"fullname_first_author": "Mou", "paper_title": "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models", "publication_date": "2024-00-00", "reason": "This paper proposes a method for drag-style manipulation of objects in images, directly addressing a key challenge in consistent object editing."}, {"fullname_first_author": "Mou", "paper_title": "DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing", "publication_date": "2024-00-00", "reason": "This paper improves upon previous methods for diffusion-based image editing, enhancing the accuracy and flexibility of consistent object manipulation."}]}