{"references": [{"fullname_first_author": "Das, A.", "paper_title": "Visual Dialog", "publication_date": "2017-07-01", "reason": "This paper introduced the Visual Dialog task, a foundational work in multimodal dialogue systems, which the current paper extends to multi-party conversations."}, {"fullname_first_author": "Ouchi, H.", "paper_title": "Addressee and Response Selection for Multi-Party Conversation", "publication_date": "2016-10-01", "reason": "This paper is a key reference in multi-party conversation research, addressing tasks such as speaker prediction and response selection that are relevant to the current work."}, {"fullname_first_author": "Gu, J.-C.", "paper_title": "MPC-BERT: A Pre-Trained Language Model for Multi-Party Conversation Understanding", "publication_date": "2021-07-01", "reason": "This paper proposed a pre-trained language model specifically for multi-party conversation understanding, which is a relevant approach to the model used in the current paper."}, {"fullname_first_author": "Lowe, R.", "paper_title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems", "publication_date": "2015-06-01", "reason": "This paper introduced the Ubuntu Dialogue Corpus, a large dataset for multi-turn dialogue that is used for comparison with the Friends-MMC dataset."}, {"fullname_first_author": "Poria, S.", "paper_title": "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations", "publication_date": "2018-10-01", "reason": "This paper introduced the MELD dataset, which, although focusing on emotion recognition, shares similarities with the current paper's dataset in its multimodal and multi-party nature."}]}