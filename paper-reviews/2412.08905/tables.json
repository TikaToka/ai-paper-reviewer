[{"content": "|                     |                     | phi-4 14b | phi-3 14b | Qwen 2.5 14b instruct | GPT 4o-mini | Llama-3.3 70b instruct | Qwen 2.5 72b instruct | GPT 4o | \n| :------------------ | :------------------ | :-------- | :-------- | :----------------------- | :---------- | :---------------------- | :--------------------- | :------ | \n| <img src=\"https://arxiv.org/html/2412.08905/simple-evals.png\" width=\"8.0pt\" height=\"46.9pt\" style=\"vertical-align:-21.2pt; transform:rotate(-90deg)\"> | MMLU                | 84.8      | 77.9      | 79.9                     | 81.8        | 86.3                    | 85.3                    | **88.1** | \n|                     | GPQA                 | **56.1**    | 31.2      | 42.9                     | 40.9        | 49.1                    | 49.0                    | 50.6    | \n|                     | MATH                 | **80.4**    | 44.6      | 75.6                     | 73.0        | 66.3                    | 80.0                    | 74.6    | \n|                     | HumanEval            | 82.6      | 67.8      | 72.1                     | **86.2**    | 78.9                    | 80.4                    | **90.6** | \n|                     | MGSM                 | 80.6      | 53.5      | 79.6                     | 86.5        | 89.1                    | 87.3                    | **90.4** | \n|                     | SimpleQA             | 3.0       | 7.6       | 5.4                      | 9.9         | 20.9                    | 10.2                    | **39.4** | \n|                     | DROP                 | 75.5      | 68.3      | 85.5                     | 79.3        | **90.2**                 | 76.7                    | 80.9    | \n|                     | MMLUPro              | 70.4      | 51.3      | 63.2                     | 63.4        | 64.4                    | 69.6                    | **73.0** | \n|                     | HumanEval+           | 82.8      | 69.2      | 79.1                     | 82.0        | 77.9                    | 78.4                    | **88.0** | \n|                     | ArenaHard            | 75.4      | 45.8      | 70.2                     | 76.2        | 65.5                    | **78.4**                 | 75.6    | \n|                     | LiveBench            | 47.6      | 28.1      | 46.6                     | 48.1        | **57.6**                 | 55.3                    | **57.6** | \n|                     | IFEval               | 63.0      | 57.9      | 78.7                     | 80.0        | **89.3**                 | 85.0                    | 84.8    | \n|                     | PhiBench (internal) | 56.2      | 43.9      | 49.8                     | 58.7        | 57.1                    | 64.6                    | **72.4** |", "caption": "Table 1: Performance of phi-4\u00a0 on a set of standard benchmarks. The first set of benchmarks uses OpenAI\u2019s simple-evals framework\u00a0[24], specifying the prompts/extraction/temperature=0.5. We compare to small models of similar inference cost, as well as to larger models.", "description": "\ud45c 1\uc740 phi-4 \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ub2e4\uc591\ud55c \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\uc640 \ud568\uaed8 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. OpenAI\uc758 simple-evals \ud504\ub808\uc784\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uce21\uc815\ud55c \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c \uc810\uc218\ub97c phi-3, Qwen 2.5, GPT, Llama \ub4f1 \ub2e4\ub978 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc \ube44\uad50\ud558\uc5ec phi-4\uc758 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ube44\uad50 \ub300\uc0c1 \ubaa8\ub378\uc740 \uc720\uc0ac\ud55c \ucd94\ub860 \ube44\uc6a9\uc744 \uac00\uc9c4 \uc18c\uaddc\ubaa8 \ubaa8\ub378\uacfc \ub300\uaddc\ubaa8 \ubaa8\ub378 \ubaa8\ub450 \ud3ec\ud568\ud569\ub2c8\ub2e4.  \uc628\ub3c4(temperature) \ub9e4\uac1c\ubcc0\uc218\ub294 0.5\ub85c \uc124\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4.", "section": "1 Introduction"}, {"content": "| Model | MMLU | MMLU pro | GSM8k | Human-Eval | ARCC | MBPP | MATH | TQA |\n|---|---|---|---|---|---|---|---|---|\n| phi-4 (4k) | +3.0 | +10.3 | +2.2 | +7.8 | +1.1 | +6.8 | +8.9 | -0.7 |\n| phi-4 (16k) | +2.7 | +8.9 | +1.2 | +9.0 | +0.9 | +9.6 | +8.4 | -1.5 |", "caption": "Table 2: Pretraining benchmarks for phi-4\u00a0compared to its predecessor, phi-3-medium after pretraining.", "description": "\ud45c 2\ub294 phi-4 \ubaa8\ub378\uc758 pretraining \ub2e8\uacc4 \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. phi-3-medium \ubaa8\ub378\uacfc \ube44\uad50\ud558\uc5ec phi-4 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1 \uc815\ub3c4\ub97c \ub2e4\uc591\ud55c benchmark (MMLU, MMLU pro, GSM8k, Human-Eval, ARCC, MBPP, MATH, TQA)\ub97c \ud1b5\ud574 \uc81c\uc2dc\ud569\ub2c8\ub2e4.  \uac01 benchmark\uc5d0\uc11c phi-4 \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uce58\ub97c \uc218\uce58\ub85c \ub098\ud0c0\ub0b4\uc5b4 phi-4 \ubaa8\ub378\uc758 pretraining \ud6a8\uacfc\ub97c \uad6c\uccb4\uc801\uc73c\ub85c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3 Pretraining details"}, {"content": "|                     | MMLU | MMLU pro | GSM8k | Human-Eval | ARCC | MBPP | MATH | TQA |\n| :------------------ | :---- | :------- | :---- | :--------- | :---- | :---- | :---- | :---- |\n| Synthetic           | +0.8  | +4.0     | +2.2  | +12.1      | 0.0   | +5.0  | +4.9  | -14.8 |\n| Synthetic + Web Rewrites | +0.3  | +4.1     | +1.8  | +13.3      | +3.0  | +7.6  | +8.1  | -7.7 |", "caption": "Table 3: Benchmark performance of 13131313B models (used for ablations only) trained on data mixtures containing no web data. The respective training tokens are either from synthetic sources, or an equal share of synthetic data and web rewrites. All numbers are reported relative to the performance of phi-3-medium, which has seen a combination of web and synthetic data.", "description": "\ud45c 3\uc740 \uc6f9 \ub370\uc774\ud130 \uc5c6\uc774 \ud559\uc2b5\ub41c 130\uc5b5 \ub9e4\uac1c\ubcc0\uc218 \ubaa8\ub378(\uc5d0\uc774\uc804\ud2b8 \uc2e4\ud5d8\uc6a9)\uc758 \ubca4\uce58\ub9c8\ud06c \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud559\uc2b5 \ud1a0\ud070\uc740 \ud569\uc131 \ub370\uc774\ud130 \uc18c\uc2a4 \ub610\ub294 \ud569\uc131 \ub370\uc774\ud130\uc640 \uc6f9 \uc7ac\uc791\uc131 \ub370\uc774\ud130\uc758 \ub3d9\uc77c\ud55c \ube44\uc728\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4. \ubaa8\ub4e0 \uc218\uce58\ub294 \uc6f9 \ubc0f \ud569\uc131 \ub370\uc774\ud130\ub97c \ubaa8\ub450 \uc0ac\uc6a9\ud55c phi-3-medium \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uae30\uc900\uc73c\ub85c \ud569\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ud569\uc131 \ub370\uc774\ud130 \ube44\uc911\uc744 \ub192\uc600\uc744 \ub54c \ubaa8\ub378 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ucd94\uac00 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.", "section": "3.2 \ub370\uc774\ud130 \ud63c\ud569"}, {"content": "|               | MMLU   | MATH   | GSM8k   | Human-Eval | ARCC   | MBPP   | TQA    | MMLU pro | Average |\n| :------------ | :----- | :----- | :----- | :--------- | :----- | :----- | :----- | :------- | :------ |\n| Uniform       | -3.3   | -5.4   | -5.8   | -1.2       | +0.6   | -2.0   | +3.3   | -3.6     | -2.2    |\n| S             | +3.3   | +4.0   | +2.1   | -6.1       | +1.9   | +0.4   | -3.0   | +3.7     | +0.8    |\n| S + WR        | +0.6   | +1.2   | +1.5   | -1.2       | +1.6   | +1.6   | -3.7   | +1.2     | +0.4    |\n| S + W         | -0.6   | -0.7   | -0.7   | -4.3       | +0.3   | -2.0   | +6.9   | +0.9     | 0.0     |", "caption": "Table 4: Ablations on the allocation of 75%percent7575\\%75 % of training tokens to synthetic (S), filtered web (W), and web rewrite (WR) categories, while other data sources are held constant in the remaining 25%percent2525\\%25 % token budget. All benchmark numbers are measured relative to the final data mixture used for training phi-4.", "description": "\uc774 \ud45c\ub294 phi-4 \uc0ac\uc804 \ud6c8\ub828 \ub370\uc774\ud130\uc14b \uad6c\uc131\uc5d0 \ub300\ud55c \ucd94\uac00 \ubd84\uc11d \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc804\uccb4 \ud6c8\ub828 \ud1a0\ud070 \uc911 75%\ub97c \ud569\uc131 \ub370\uc774\ud130(S), \ud544\ud130\ub9c1\ub41c \uc6f9 \ub370\uc774\ud130(W), \uc6f9 \uc7ac\uc791\uc131 \ub370\uc774\ud130(WR) \uc138 \uac00\uc9c0 \ubc94\uc8fc\uc5d0 \ud560\ub2f9\ud558\uace0, \ub098\uba38\uc9c0 25%\ub294 \ub2e4\ub978 \ub370\uc774\ud130 \uc18c\uc2a4\ub97c \uc77c\uc815\ud558\uac8c \uc720\uc9c0\ud569\ub2c8\ub2e4. \ud45c\uc758 \uac01 \uc22b\uc790\ub294 phi-4 \ud6c8\ub828\uc5d0 \uc0ac\uc6a9\ub41c \ucd5c\uc885 \ub370\uc774\ud130 \ubbf9\uc2a4\uc640 \ube44\uad50\ud558\uc5ec \uce21\uc815\ud55c \ubca4\uce58\ub9c8\ud06c \uc131\ub2a5\uc758 \ubcc0\ud654\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "3.2 \ub370\uc774\ud130 \ubbf9\uc2a4"}, {"content": "| Data | Fraction of Training | Unique Token Count | Number of Epochs |\n|---|---|---|---| \n| Web | 15% | 1.3T | 1.2 |\n| Web rewrites | 15% | 290B | 5.2 |\n| Synthetic | 40% | 290B | 13.8 |\n| Code data | 20% | 820B | 2.4 |\n| Acquired sources | 10% | 580B | 1.7 |", "caption": "Table 5: Data mixture for pretraining.", "description": "\ud45c 5\ub294 phi-4 \uc0ac\uc804 \ud559\uc2b5\uc744 \uc704\ud55c \ub370\uc774\ud130 \ud63c\ud569 \ube44\uc728\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc6f9 \ub370\uc774\ud130, \uc6f9 \uc7ac\uc791\uc131 \ub370\uc774\ud130, \ud569\uc131 \ub370\uc774\ud130, \ucf54\ub4dc \ub370\uc774\ud130, \uadf8\ub9ac\uace0 \ubaa9\ud45c \uc9c0\ud5a5\uc801 \ub370\uc774\ud130 \ud68d\ub4dd \ubc0f \uc720\uae30\uc801 \ub370\uc774\ud130\uc758 \ube44\uc728\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc774 \ud45c\ub294, \uac01 \ub370\uc774\ud130 \uc720\ud615\uc758 \uace0\uc720 \ud1a0\ud070 \uc218\uc640 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub41c \uc5d0\ud3ed \uc218\ub97c \ud568\uaed8 \uc81c\uc2dc\ud558\uc5ec \uc0ac\uc804 \ud559\uc2b5 \ub370\uc774\ud130 \uad6c\uc131\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.  \uc774 \uc815\ubcf4\ub294 \ubaa8\ub378\uc758 \uc131\ub2a5\uc5d0 \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \ub370\uc774\ud130 \uc720\ud615\uc758 \uc0c1\ub300\uc801 \uc911\uc694\uc131\uc744 \uc774\ud574\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "3 \uc0ac\uc804 \ud6c8\ub828 \uc138\ubd80 \uc815\ubcf4"}, {"content": "| Model | Max Length | Recall | RAG | ICL | Re-rank | QA | Summ |\n|---|---|---|---|---|---|---|---| \n| phi-4 | 8K | 100.0 | 58.1 | 68.0 | 65.3 | 26.7 | 38.3 |\n| Qwen-2.5-14B | 8K | 100.0 | 62.2 | 67.8 | 58.2 | 24.7 | 37.2 |\n| Llama-3.3-70B | 8K | 92.0 | 65.3 | 69.4 | 64.4 | 30.0 | 37.8 |\n| GPT-4o-mini | 8K | 99.2 | 65.8 | 74.4 | 69.4 | 31.3 | 38.5 |\n| GPT-4o | 8K | 100.0 | 66.9 | 83.0 | 75.1 | 37.3 | 43.0 |\n| phi-4 | 16K | 99.0 | 57.1 | 77.0 | 54.4 | 36.0 | 40.5 |\n| Qwen-2.5-14B | 16K | 100.0 | 59.1 | 67.6 | 50.3 | 29.7 | 42.3 |\n| Llama-3.3-70B | 16K | 92.0 | 62.2 | 70.0 | 63.3 | 36.7 | 41.9 |\n| GPT-4o-mini | 16K | 100.0 | 63.6 | 78.4 | 63.9 | 36.0 | 45.2 |\n| GPT-4o | 16K | 100.0 | 66.7 | 85.6 | 73.8 | 43.7 | 46.3 |", "caption": "Table 6: Evaluation results on the long-context benchmark HELMET\u00a0[35].", "description": "\ud45c 6\uc740 HELMET [35]\ub77c\ub294 \uc7a5\ubb38 \ub9e5\ub77d \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud55c \ud3c9\uac00 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 phi-4\ub97c \ud3ec\ud568\ud55c \uc5ec\ub7ec \uc5b8\uc5b4 \ubaa8\ub378(Qwen-2.5-14B, Llama-3.3-70B, GPT-40-mini, GPT-40)\uc758 \uc131\ub2a5\uc774 8K \ud1a0\ud070\uacfc 16K \ud1a0\ud070\uc758 \ub450 \uac00\uc9c0 \ub2e4\ub978 \ucd5c\ub300 \uae38\uc774\uc5d0 \ub300\ud574 \uc81c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc740 \uc7ac\ud604\uc728(Recall), \uc9c8\uc758\uc751\ub2f5(RAG), \ubb38\ub9e5 \ub0b4 \ud559\uc2b5(ICL), \uc7ac\uc21c\uc704 \uc9c0\uc815(Re-rank), \uc9c8\ubb38\uc751\ub2f5(QA), \uc694\uc57d(Summ) \ub4f1 \ub2e4\uc591\ud55c \uc791\uc5c5\uc5d0 \ub300\ud55c \uc131\ub2a5 \uc810\uc218\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \uc7a5\ubb38 \ub9e5\ub77d \uc774\ud574 \ubc0f \ucc98\ub9ac \ub2a5\ub825\uc744 \ube44\uad50 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.", "section": "6 Performance on Key Benchmarks"}, {"content": "| Dataset Name | Sample Count |\n|---|---| \n| unknown + safety data | 3,000 |\n| generic multiple-choice Q&A | 132,859 |\n| math data | 76,552 |\n| python data | 16,080 |\n| cpp, go, java, js, rust data | 21,806 |", "caption": "Table 9: Performance through the post-training process. DPO stage 1 is pivotal token DPO, and DPO stage 2 is more standard judge-guided DPO. Each also has 1-5% hallucination and safety data mixed in.", "description": "\ud45c 9\ub294 phi-4 \ubaa8\ub378\uc758 post-training \uacfc\uc815\uc5d0\uc11c\uc758 \uc131\ub2a5 \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  post-training\uc740 SFT(Supervised Fine-Tuning), pivotal token DPO(Direct Preference Optimization), \uadf8\ub9ac\uace0 standard judge-guided DPO\uc758 \uc138 \ub2e8\uacc4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.  \uac01 \ub2e8\uacc4\ub294 hallucination \ubc0f safety \ub370\uc774\ud130\ub97c 1~5% \ud3ec\ud568\ud569\ub2c8\ub2e4.  \ud45c\ub294 \uac01 \ub2e8\uacc4\ubcc4 \uc8fc\uc694 \ubca4\uce58\ub9c8\ud06c \uacb0\uacfc\ub97c \ube44\uad50\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5 \ud5a5\uc0c1\uc744 \uc815\ub7c9\uc801\uc73c\ub85c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.", "section": "4 Post-Training"}, {"content": "| Dataset Name | Sample Count |\n|---|---| \n| unknown + safety data | 43,842 |\n| any vs any overall | 266,000 |\n| any vs any accuracy | 532,000 |", "caption": "Table 10: Performance comparison across models. Lower scores are better, except for \u201cGrounding,\u201d where a higher score is better. phi-4\u00a0 values are bold for readability.", "description": "\ud45c 10\uc740 \ub2e4\uc591\ud55c \uc5b8\uc5b4 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \"Grounding\"\uc744 \uc81c\uc678\ud558\uace0\ub294 \uc810\uc218\uac00 \ub0ae\uc744\uc218\ub85d \uc131\ub2a5\uc774 \uc88b\uc2b5\ub2c8\ub2e4. \"Grounding\"\uc758 \uacbd\uc6b0\ub294 \uc810\uc218\uac00 \ub192\uc744\uc218\ub85d \uc88b\uc2b5\ub2c8\ub2e4. phi-4 \ubaa8\ub378\uc758 \uac12\uc740 \uac00\ub3c5\uc131\uc744 \uc704\ud574 \uad75\uac8c \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \uc5ec\ub7ec \uae30\uc900\uc5d0 \ub530\ub77c \uc815\ub7c9\uc801\uc73c\ub85c \ube44\uad50\ud558\uc5ec \uac01 \ubaa8\ub378\uc758 \uac15\uc810\uacfc \uc57d\uc810\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.", "section": "7.1 RAI \ubca4\uce58\ub9c8\ud06c"}]