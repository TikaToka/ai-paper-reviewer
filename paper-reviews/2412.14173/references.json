{"references": [{"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces a foundational video diffusion model that AniDoc builds upon for its video generation capabilities, improving temporal consistency and visual coherence in the generated animation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper provides the core diffusion model technology that AniDoc leverages to generate high-fidelity colorized animation frames."}, {"fullname_first_author": "Zhitong Huang", "paper_title": "LVCD: reference-based lineart video colorization with diffusion models", "publication_date": "2024-00-00", "reason": "This is a direct competitor to AniDoc, offering a reference-based video colorization method which AniDoc improves upon by using more robust and efficient methods."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "ToonCrafter: Generative cartoon interpolation", "publication_date": "2024-00-00", "reason": "This paper presents another related method that AniDoc outperforms, highlighting the advancements made in AniDoc over existing techniques."}, {"fullname_first_author": "Xuanhua He", "paper_title": "ID-animator: Zero-shot identity-preserving human video generation", "publication_date": "2024-00-00", "reason": "This method is used as a comparison in the paper, showing that AniDoc's approach offers superior performance in terms of colorization accuracy and temporal consistency."}]}