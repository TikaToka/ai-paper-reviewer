{"references": [{"fullname_first_author": "E. Wijmans", "paper_title": "DD-PPO: learning near-perfect pointgoal navigators from 2.5 billion frames", "publication_date": "2020-04-26", "reason": "This paper establishes a strong baseline for point goal navigation using a large-scale, on-policy reinforcement learning approach, which the current paper builds upon and improves."}, {"fullname_first_author": "D. Batra", "paper_title": "ObjectNav revisited: On evaluation of embodied agents navigating to objects", "publication_date": "2020-06-20", "reason": "This paper defines the Object Goal Navigation task, a more challenging problem than point goal navigation, which the current paper addresses and significantly advances."}, {"fullname_first_author": "K. Ehsani", "paper_title": "Imitating shortest paths in simulation enables effective navigation and manipulation in the real world", "publication_date": "2024-00-00", "reason": "This paper introduces the SPOC agent, a strong imitation learning baseline that uses transformers, whose approach is directly compared to and improved upon by the current paper's reinforcement learning method."}, {"fullname_first_author": "M. Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2023-00-00", "reason": "This paper provides the visual foundation model (DINOv2) used in Poliformer, a crucial component for visual representation and a key enabler of the model's performance."}, {"fullname_first_author": "M. Deitke", "paper_title": "ProcTHOR: Large-scale embodied AI using procedural generation", "publication_date": "2022-00-00", "reason": "This paper introduces the AI2-THOR simulator and the PROCTHOR environment, the primary simulation environments used for training Poliformer, highlighting its importance for the scale and diversity of training data."}]}