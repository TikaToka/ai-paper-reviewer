{"references": [{"fullname_first_author": "Gantavya Bhatt", "paper_title": "An experimental design framework for label-efficient supervised finetuning of large language models", "publication_date": "2024-01-01", "reason": "This paper provides a framework for efficient supervised fine-tuning of LLMs, which is directly relevant to the core task addressed in the main paper."}, {"fullname_first_author": "Federico Bianchi", "paper_title": "Safety-tuned llamas: Lessons from improving the safety of large language models that follow instructions", "publication_date": "2023-09-01", "reason": "This paper explores the safety aspects of LLMs, which is a crucial consideration in the context of the main paper's focus on noise-robust fine-tuning."}, {"fullname_first_author": "Christopher Clark", "paper_title": "Boolq: Exploring the surprising difficulty of natural yes/no questions", "publication_date": "2019-06-01", "reason": "This paper discusses the challenges in question answering, providing insights into the complexities of handling noisy data and the impact on model performance."}, {"fullname_first_author": "Abhimanyu Dubey", "paper_title": "The llama 3 herd of models", "publication_date": "2024-07-01", "reason": "This paper introduces a collection of Llama models, which are used as the backbone for experiments in the main paper, making it crucial for understanding the results."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2020-09-01", "reason": "This paper presents MMLU, a benchmark dataset used extensively in the experiments of the main paper, establishing its significance in evaluating LLM performance."}]}