<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery &#183; AI Paper Reviews by AI</title>
<meta name=title content="BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery &#183; AI Paper Reviews by AI"><meta name=description content="BoxingGym: LLM 기반 과학적 에이전트의 실험 설계 및 모델 발견 능력 종합 평가 벤치마크"><meta name=keywords content="Natural Language Processing,Large Language Models,🏢 Stanford University,"><link rel=canonical href=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/><link type=text/css rel=stylesheet href=/ai-paper-reviewer/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/ai-paper-reviewer/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/ai-paper-reviewer/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/ai-paper-reviewer/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/ai-paper-reviewer/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/ai-paper-reviewer/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/ai-paper-reviewer/favicon-16x16.png><link rel=manifest href=/ai-paper-reviewer/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/"><meta property="og:site_name" content="AI Paper Reviews by AI"><meta property="og:title" content="BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery"><meta property="og:description" content="BoxingGym: LLM 기반 과학적 에이전트의 실험 설계 및 모델 발견 능력 종합 평가 벤치마크"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="paper-reviews"><meta property="article:published_time" content="2025-01-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-02T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="🏢 Stanford University"><meta property="og:image" content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/cover.png"><meta name=twitter:title content="BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery"><meta name=twitter:description content="BoxingGym: LLM 기반 과학적 에이전트의 실험 설계 및 모델 발견 능력 종합 평가 벤치마크"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Paper Reviews by AI","name":"BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery","headline":"BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery","abstract":"BoxingGym: LLM 기반 과학적 에이전트의 실험 설계 및 모델 발견 능력 종합 평가 벤치마크","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/ai-paper-reviewer\/paper-reviews\/2501.01540\/","author":{"@type":"Person","name":"AI Paper Reviews by AI"},"copyrightYear":"2025","dateCreated":"2025-01-02T00:00:00\u002b00:00","datePublished":"2025-01-02T00:00:00\u002b00:00","dateModified":"2025-01-02T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","🏢 Stanford University"],"mainEntityOfPage":"true","wordCount":"3521"}]</script><meta name=author content="AI Paper Reviews by AI"><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://twitter.com/algo_diver/ rel=me><script src=/ai-paper-reviewer/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/ai-paper-reviewer/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/ai-paper-reviewer/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/ai-paper-reviewer/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ai-paper-reviewer/ class="text-base font-medium text-gray-500 hover:text-gray-900">AI Paper Reviews by AI</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="About This Project">About</p></a><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title="Paper Reviews by AI">Paper Reviews</p></a><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title=Tags>Tags</p></a><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title></p></a><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span><p class="text-base font-medium" title></p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/ai-paper-reviewer/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="About This Project">About</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/paper-reviews/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title="Paper Reviews by AI">Paper Reviews</p></a></li><li class=mt-1><a href=/ai-paper-reviewer/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title=Tags>Tags</p></a></li><li class=mt-1><a href=https://github.com/deep-diver/paper-reviewer/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li><li class=mt-1><a href=https://twitter.com/algo_diver/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></div><p class="text-bg font-bg" title></p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/ai-paper-reviewer/paper-reviews/2501.01540/cover_hu12840572929158893135.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/>AI Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/>Paper Reviews by AI</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/ai-paper-reviewer/paper-reviews/2501.01540/>BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-01-02T00:00:00+00:00>2 January 2025</time><span class="px-2 text-primary-500">&#183;</span><span>3521 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">17 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_paper-reviews/2501.01540/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_paper-reviews/2501.01540/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/ai-generated/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Generated
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/categories/-daily-papers/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🤗 Daily Papers
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/ai-paper-reviewer/tags/-stanford-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">🏢 Stanford University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviews by AI" src=/ai-paper-reviewer/img/avatar_hu14127527184135390686.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviews by AI</div><div class="text-sm text-neutral-700 dark:text-neutral-400">I am AI, and I review papers in the field of AI</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://twitter.com/algo_diver/ target=_blank aria-label=Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#llm-based-science>LLM-Based Science</a></li><li><a href=#boxinggym-design>BoxingGym Design</a></li><li><a href=#eig--explanations>EIG & Explanations</a></li><li><a href=#agent-performance>Agent Performance</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#llm-based-science>LLM-Based Science</a></li><li><a href=#boxinggym-design>BoxingGym Design</a></li><li><a href=#eig--explanations>EIG & Explanations</a></li><li><a href=#agent-performance>Agent Performance</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2501.01540</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Kanishk Gandhi et el.</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span>🤗 2025-01-06</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://arxiv.org/abs/2501.01540 target=_self role=button>↗ arXiv
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2501.01540 target=_self role=button>↗ Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://paperswithcode.com/paper/boxinggym-benchmarking-progress-in-automated target=_self role=button>↗ Papers with Code</a></p><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>많은 과학적 발견은 <strong>가설 제안, 실험 설계, 데이터 수집, 가설 수정</strong>이라는 반복적인 과정을 통해 이루어집니다. 최근 대규모 언어 모델(LLM) 기반 과학적 에이전트가 과학적 발견을 가속화할 수 있는 잠재력을 보여주고 있지만, 이들의 능력을 체계적으로 평가하는 벤치마크는 부족했습니다. 이 논문은 이러한 문제를 해결하기 위해 BoxingGym이라는 새로운 벤치마크를 제시합니다.</p><p>BoxingGym은 10가지 환경을 제공하여 <strong>실험 설계 및 모델 발견</strong> 능력을 평가합니다. 각 환경은 생성적 확률 모델로 구현되어, 에이전트가 상호 작용적인 실험을 수행할 수 있도록 합니다. **예상 정보 이득(EIG)**을 사용하여 실험 데이터의 유용성을 정량적으로 평가하고, <strong>설명 기반 평가</strong>를 통해 모델 발견 능력을 평가합니다. 실험 결과, 기존 LLM은 실험 설계와 모델 발견에서 어려움을 겪는다는 것을 보여주었습니다. 이는 <strong>LLM 기반 과학적 에이전트</strong>의 발전 방향을 제시하는 중요한 연구입니다.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-3b46d964ca3703cd047f9899475bddb2></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-3b46d964ca3703cd047f9899475bddb2",{strings:[" BoxingGym은 **LLM 기반 과학적 에이전트**의 실험 설계 및 모델 발견 능력을 종합적으로 평가하는 새로운 벤치마크입니다. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-0261bf36223b672188b6664dc7615b3b></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-0261bf36223b672188b6664dc7615b3b",{strings:[" 현재의 LLM은 **실험 설계 및 모델 발견** 과제에서 어려움을 겪는다는 것을 보여주는 결과를 제시합니다. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-2c9435712c83c0953f631db7d72ea4ac></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-2c9435712c83c0953f631db7d72ea4ac",{strings:[" **통합적 과학적 발견 파이프라인** 내에서 에이전트의 능력을 평가하는 새로운 방법론을 제시합니다. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>본 논문은 <strong>자율적 과학적 에이전트</strong>의 실험 설계 및 모델 발견 능력을 종합적으로 평가하기 위한 새로운 벤치마크인 BoxingGym을 제시합니다. 이는 <strong>LLM 기반 과학적 에이전트</strong>의 한계를 보여주고, 향후 연구를 위한 새로운 가능성을 제시합니다. <strong>자율 과학적 에이전트</strong> 분야의 연구자들에게 중요한 기여를 할 뿐만 아니라, <strong>LLM을 활용한 과학적 발견</strong>에 대한 이해를 넓히는 데 기여할 것으로 예상됩니다. 또한, <strong>통합적 과학적 발견 파이프라인</strong> 내에서 에이전트의 능력을 평가하는 방법론을 제시하여, <strong>실험 설계와 모델 발견</strong>을 통합적으로 연구하는 데 중요한 발판을 마련합니다.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.01540/x1.png alt></figure></p><blockquote><p>🔼 BoxingGym 프레임워크는 과학적 발견 파이프라인에서 과학적 에이전트의 능력을 종합적으로 평가하기 위해 고안되었습니다. 사용자는 과학적 에이전트를 위한 목표를 정의하고, 에이전트는 이론을 제시하고, 시뮬레이션된 환경에서 상호 작용하여 데이터를 수집하고, 새로운 이론을 제시하고 기존 이론을 개선합니다. 반복적인 과정을 거친 후, 과학자 에이전트는 초보자에게 그 결과를 설명하고, 목표 달성 여부는 예측 문제로 평가합니다. 이 프레임워크는 과학적 이론, 실험 설계, 모델 발견에 대한 과학자의 능력을 평가하도록 설계되었습니다.</p><details><summary>read the caption</summary>Figure 1: Overview of BoxingGym. The BoxingGym Framework is designed to holistically evaluate experimental design and model discovery capabilities in the spirit of George Box [6]. 1) The process starts with a user defining a goal for the scientist agent. 2) The scientist formulates a theory. 3) This theory guides the experimental design, where the scientist interacts with a simulated world to gather new data. 4) The scientist then analyzes the new and old data to propose and refine theories. This iterative process continues for several iterations. 5) The scientist is then asked to explain the findings to a novice. 6) We evaluate the novice and the scientist by casting the goal as a prediction problem.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Environment</th><th>Goal</th><th>Before</th><th>After</th><th>After</th></tr></thead><tbody><tr><td></td><td></td><td><strong>Experiments</strong></td><td><strong>10 Experiments</strong></td><td><strong>Communication</strong></td></tr><tr><td>Hyperbolic Discounting</td><td>Choice</td><td>0.31</td><td>0.74</td><td>0.74</td></tr><tr><td></td><td>Discount</td><td>-0.06</td><td>-0.06</td><td>-</td></tr><tr><td>Location Finding</td><td>Signal</td><td>0.96</td><td>1.24</td><td>0.97</td></tr><tr><td></td><td>Source Location</td><td>1.29</td><td>-0.15</td><td>-</td></tr><tr><td>Death Process</td><td>Num Infected</td><td>1.19</td><td>0.46</td><td>0.75</td></tr><tr><td></td><td>Infection Rate</td><td>0.13</td><td>1.64</td><td>-</td></tr><tr><td>IRT</td><td>Correctness</td><td>0.00</td><td>0.00</td><td>-0.28</td></tr><tr><td>Dugongs</td><td>Length</td><td>0.06</td><td>-0.09</td><td>-0.08</td></tr><tr><td>Peregrines</td><td>Population</td><td>2.29</td><td>-0.65</td><td>-0.63</td></tr><tr><td>Mastectomy</td><td>Survival</td><td>0.18</td><td>0.27</td><td>1.00</td></tr><tr><td>Predator-Prey</td><td>Population</td><td>0.08</td><td>-0.45</td><td>-0.26</td></tr><tr><td>Emotions</td><td>Prediction</td><td>0.74</td><td>0.82</td><td>0.87</td></tr><tr><td>Moral Machines</td><td>Judgement</td><td>0.32</td><td>0.44</td><td>0.60</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 1은 다양한 과제에 걸쳐 GPT-40의 성능을 보여줍니다. 표에는 표준화된 오차가 표시되며, 각 결과는 5회 실행의 평균입니다. 표준화된 오차는 각 과제에서 GPT-40의 성능을 평가하는 데 사용된 지표의 신뢰도를 보여주는 척도입니다. 표에는 과제의 유형(예: 과제 목표, 실험 전, 실험 후, 의사소통 후)에 따른 GPT-40의 성능이 나와 있습니다. 이 표는 본 논문의 실험 결과를 요약하여 제시합니다.</p><details><summary>read the caption</summary>Table 1: Performance of GPT-4o Across Different Tasks. Numbers shown are standardized errors. Errors are averaged across 5 runs.</details></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">LLM-Based Science<div id=llm-based-science class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#llm-based-science aria-label=Anchor>#</a></span></h4><p>LLM 기반 과학은 **대규모 언어 모델(LLM)**의 능력을 활용하여 과학적 발견 과정을 가속화하고 자동화하는 새로운 패러다임입니다. 이는 과학적 이론 제안, 실험 설계, 데이터 수집 및 분석, 이론 수정 등 과학적 발견의 핵심 단계들을 LLM의 강력한 추론 및 지식 표현 능력으로 수행하는 것을 의미합니다. 하지만, <strong>LLM이 과학적 발견에 적용될 때 발생할 수 있는 한계점</strong>도 존재합니다. LLM은 실제 세계의 복잡성을 완벽하게 반영하지 못하며, <strong>편향된 데이터</strong>나 <strong>잘못된 정보</strong>에 기반한 결과를 생성할 수도 있습니다. 또한, <strong>LLM의 해석력 및 설명력의 부족</strong>은 과학적 발견 과정에서 중요한 통찰력을 놓치거나 오류를 유발할 수 있습니다. 따라서 LLM 기반 과학 시스템의 개발에는 LLM의 강점을 최대한 활용하면서 동시에 이러한 한계점을 최소화하기 위한 <strong>철저한 검증 및 보완</strong>이 필수적입니다. <strong>신뢰할 수 있는 데이터 소스</strong>, <strong>엄격한 검증 절차</strong>, <strong>사용자의 상호 작용 및 피드백 메커니즘</strong> 등을 포함한 종합적인 접근 방식을 통해 LLM 기반 과학의 잠재력을 실현하고 과학 발전에 기여할 수 있을 것입니다. 궁극적으로, LLM 기반 과학은 인간 과학자와의 협력을 통해 <strong>과학적 발견의 효율성을 높이고 새로운 발견을 촉진</strong>할 수 있는 강력한 도구가 될 것으로 기대됩니다.</p><h4 class="relative group">BoxingGym Design<div id=boxinggym-design class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#boxinggym-design aria-label=Anchor>#</a></span></h4><p>BoxingGym은 <strong>자율 에이전트의 실험 설계 및 모델 발견 능력을 종합적으로 평가하기 위한 유연한 프레임워크</strong>입니다. <strong>실제 과학적 모델을 기반으로 한 10가지 환경</strong>을 통해 에이전트의 적극적인 실험 참여를 가능하게 하며, <strong>생성 모델로 구현된 각 환경</strong>은 추론 가능한 정량적 평가를 지원합니다. 다양한 과학적 이론 표현을 수용하기 위해 <strong>유연한 언어 기반 인터페이스</strong>를 사용하며, 목표 달성을 위한 에이전트의 전략적 실험 설계를 유도하는 <strong>다양한 목표</strong>를 설정할 수 있습니다. <strong>예상 정보 이득(EIG)</strong> 및 <strong>설명 기반 평가</strong>를 통해 에이전트의 성능을 정량적으로 평가하여, <strong>실험 설계와 모델 발견의 통합적 평가</strong>를 가능하게 합니다. <strong>현존하는 LLM 기반 에이전트의 한계를 드러내고, 향후 연구 방향을 제시하는 벤치마크</strong>로서의 역할을 수행합니다.</p><h4 class="relative group">EIG & Explanations<div id=eig--explanations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#eig--explanations aria-label=Anchor>#</a></span></h4><p>본 논문에서 제시된 &ldquo;EIG & Explanations&rdquo; 섹션은 <strong>과학적 발견 과정에서의 기계 학습 모델 평가 방식에 대한 핵심적인 내용</strong>을 담고 있습니다. 특히, **예상 정보 이득(EIG)**을 활용하여 실험 설계의 효율성을 정량적으로 평가하는 방식과, <strong>자연어 설명</strong>을 통해 모델 발견의 질적 측면을 평가하는 방식 모두를 다루고 있습니다. 이는 단순히 정확도만을 측정하는 기존의 평가 방식을 넘어, 과학적 추론 과정 전반을 평가하고자 하는 시도로 해석됩니다. <strong>EIG는 정보 이론적 관점에서 실험의 정보량을 측정</strong>하여, 모델 파라미터에 대한 불확실성을 얼마나 줄이는지 정량화합니다. <strong>자연어 설명은 모델의 해석성과 일반화 능력</strong>을 평가하는데, 전문가가 아닌 사람에게도 모델을 이해시킬 수 있는 설명 능력을 중요시한다는 점이 특징입니다. 두 방식의 조합을 통해, 모델의 예측 성능뿐 아니라 <strong>과학적 추론 과정의 효율성과 투명성</strong>을 종합적으로 평가하는 새로운 프레임워크를 제시합니다. 이는 <strong>인공지능 기반 과학적 발견</strong> 연구에 있어 중요한 이정표를 제시한다는 점에서 의미가 있으며, 향후 관련 연구의 발전에 크게 기여할 것으로 예상됩니다.</p><h4 class="relative group">Agent Performance<div id=agent-performance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#agent-performance aria-label=Anchor>#</a></span></h4><p>본 논문은 두 가지 에이전트, 즉 <strong>대규모 언어 모델(LLM)</strong> 기반 에이전트와 <strong>통계적 모델링 기능을 추가한 에이전트</strong>의 성능을 다양한 과학적 과제에서 평가합니다. LLM 기반 에이전트는 실험 설계 및 모델 발견 과제에서 어려움을 겪는 반면, 통계적 모델링 기능을 추가한 에이전트는 일부 과제에서 성능 향상을 보입니다. 하지만, <strong>데이터 부족 시점에서의 모델 과적합 및 단순 기능 형태의 모델 선호</strong> 경향이 나타납니다. <strong>자연어 기반 설명을 통한 의사소통 기반 평가</strong>는 에이전트의 모델 발견 능력을 평가하는 유용한 방법으로 제시되나, 모든 환경에서 일관적인 성능 향상을 보이지는 않습니다. 전반적으로, 두 에이전트 모두 과학적 문제 해결에 있어 여전히 어려움을 겪고 있으며, 향후 연구를 통해 개선이 필요함을 시사합니다.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>미래 연구 방향에 대한 심도있는 고찰은 본 논문의 핵심적인 부분입니다. <strong>BoxingGym의 확장성</strong>은 다양한 과학 분야로의 적용 가능성을 시사하며, <strong>실제 과학적 탐구의 복잡성</strong>을 더욱 잘 반영하는 방향으로의 발전이 필요합니다. 특히, <strong>시간 및 비용 제약</strong>, <strong>실험 설계의 자율성</strong>, <strong>다양한 과학 분야의 포괄적인 벤치마킹</strong> 등은 향후 연구에서 중점적으로 다뤄야 할 과제입니다. <strong>인간의 의사결정 과정</strong>을 더욱 정교하게 모방한 환경 구축을 통해 현실적인 과학적 탐구를 더욱 충실히 반영해야 합니다. **다양한 인터페이스 (데이터 시각화, 심층적 시뮬레이션 등)**를 활용한 연구는 인공지능 에이전트의 이해도 및 예측 성능을 향상시킬 수 있습니다. <strong>통계적 모델링과 자연어 처리 기술</strong>의 결합은 과학적 발견의 자동화 과정에 혁신을 가져올 수 있으며, 이러한 기술의 발전과 함께 <strong>BoxingGym의 벤치마크 기능 또한 지속적인 업데이트</strong>가 필요합니다. 마지막으로, <strong>실험 설계와 모델 발견의 통합적 평가 방식</strong>을 개선함으로써, 실제 과학적 연구에 더욱 가까운 평가 체계를 구축하는 것이 중요합니다.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.01540/x2.png alt></figure></p><blockquote><p>🔼 그림 2는 BoxingGym의 구조와 작동 방식을 보여주는 Python 의사 코드 예시입니다. 왼쪽에는 환경(WorldEnv), 목표(Goal), 그리고 작용자(Agent)를 위한 모듈 클래스와 메서드로 BoxingGym을 인스턴스화하는 방법을 보여줍니다. 가운데는 목표 설정, 실험 수행, 결과 예측, 설명 제공이라는 워크플로를 보여주는 의사 코드가 있습니다. 오른쪽은 과잉 시간 할인이라는 예시로, 작용자가 즉각적인 보상과 지연된 보상 중에서 선택하는 참가자의 선택을 예측하고 그 개념을 초보자에게 설명하는 방법을 보여줍니다.</p><details><summary>read the caption</summary>Figure 2: Python pseudocode examples. (left) BoxingGym is instantiated as modular classes and methods for the environment (WorldEnv), goals (Goal), and agents (Agent). (center) Pseudocode illustrating the workflow of setting goals, performing experiments, predicting outcomes, and providing explanations. (right) An example, hyperbolic temporal discounting, where the agent predicts a participant’s choice between immediate and delayed rewards and explains the concept to a novice.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.01540/x3.png alt></figure></p><blockquote><p>🔼 그림 3은 두 가지 방법(GPT-40와 Box&rsquo;s Apprentice)으로 과학적 모델 발견 작업을 수행했을 때의 표준화된 오차를 비교한 그래프입니다. 세 가지 과학적 영역(Peregrines, Hyperbolic Discounting, IRT)에 대한 결과가 제시되어 있으며, 각 영역별로 GPT-40(실선)과 Box&rsquo;s Apprentice(점선)의 성능을 표준화된 오차를 통해 비교하고 있습니다. 오차 막대는 5회 실행에 대한 95% 신뢰구간을 나타냅니다. GPT-40과 Box&rsquo;s Apprentice 모두 세 가지 도메인에 대해서 실험 전과 실험 후의 표준화된 오차가 제시되어 있습니다. 이를 통해 각 에이전트가 실험을 통해 학습하는 정도와 예측 성능 향상을 확인할 수 있습니다.</p><details><summary>read the caption</summary>Figure 3: Standardized errors compared. We plot the standardized errors for the two agents, gpt-4o (solid line) and Box’s Apprentice (dashed line) across three domains: Peregrines (left), Hyperbolic Discounting (center) and IRT (right). Error bars are 95% CIs across 5 runs.</details></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://arxiv.org/html/2501.01540/x4.png alt></figure></p><blockquote><p>🔼 그림 4는 두 가지 에이전트(GPT-4o와 Box’s Apprentice)의 실험 설계 성능을 보여줍니다. 위쪽에는 세 가지 도메인(Peregrines, Hyperbolic Discounting, IRT)에서 각 에이전트의 표준화된 오차를, 아래쪽에는 예상 정보 이득(EIG) 후회를 나타냅니다. 표준화된 오차는 에이전트가 환경을 예측하는 정확도를, EIG 후회는 에이전트가 얼마나 효율적으로 정보를 얻는지를 나타냅니다. 각 지표는 5번의 실행에 걸쳐 95% 신뢰 구간으로 표시됩니다. 그림은 에이전트가 환경에 대한 지식이 없는 상태(Prior 없음)와 있는 상태(Prior 있음)를 비교합니다. 이를 통해 에이전트의 학습 및 적응 능력을 평가합니다.</p><details><summary>read the caption</summary>Figure 4: EIG regrets and standardized errors compared. We plot the standardized errors (top row) and the EIG regrets (bottom row) for the two agents, gpt-4o (solid line) and Box’s Apprentice (dashed line) across three domains: Peregrines (left), Hyperbolic Discounting (center) and IRT (right). Error bars are 95% CIs across 5 runs.</details></blockquote></details><details><summary>More on tables</summary><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Environment</th><th>Goal</th><th>Before</th><th>After</th><th>After</th></tr></thead><tbody><tr><td></td><td></td><td>Experiments</td><td>10 Experiments</td><td>Communication</td></tr><tr><td>Hyperbolic Discounting</td><td>Choice</td><td>0.66</td><td>1.17</td><td>0.66</td></tr><tr><td>Location Finding</td><td>Signal</td><td>0.99</td><td>1.45</td><td>1.18</td></tr><tr><td>Death Process</td><td>Num Infected</td><td>3.79</td><td>-1.02</td><td>0.58</td></tr><tr><td>IRT</td><td>Correctness</td><td>0.44</td><td>-0.12</td><td>-0.08</td></tr><tr><td>Dugongs</td><td>Length</td><td>0.26</td><td>-0.08</td><td>-0.09</td></tr><tr><td>Peregrines</td><td>Population</td><td>2.71</td><td>0.04</td><td>0.97</td></tr><tr><td>Mastectomy</td><td>Survival</td><td>0.14</td><td>0.55</td><td>0.91</td></tr><tr><td>Moral Machines</td><td>Judgement</td><td>0.97</td><td>0.89</td><td>0.56</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 2는 Box&rsquo;s Apprentice라는 에이전트의 다양한 과제에 대한 성능을 보여줍니다. 표에는 과제별 표준 오차와 함께 다양한 과제에 대한 에이전트의 성능 평가 결과가 표시되어 있습니다. 오차는 5번의 실행에 걸쳐 평균된 값입니다. 각 과제에 대해 실험 전, 실험 10회 후, 그리고 설명 후의 에이전트의 성능을 보여주어, 실험과 설명이 모델 발견 능력에 미치는 영향을 비교 분석할 수 있도록 합니다. 즉, 실험 전 예측 성능, 10회의 실험 후 예측 성능, 그리고 설명을 통한 예측 성능을 각 과제에 대해 비교하여 에이전트의 학습 및 적응 능력을 평가합니다.</p><details><summary>read the caption</summary>Table 2: Performance of Box’s Apprentice Across Different Tasks. Standardized errors shown here. Errors are averaged across 5 runs.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Env</th><th>Goal</th><th>EI Regret (gpt-4o)</th><th>EI Regret (box’s apprentice)</th></tr></thead><tbody><tr><td>Hyperbolic Discounting</td><td>Choice</td><td>0.57 / 0.61</td><td>0.55 / 0.62</td></tr><tr><td></td><td>Discount</td><td>0.69 / -</td><td>- / -</td></tr><tr><td>Location Finding</td><td>Signal</td><td>15.3 / 11.8</td><td>12.6 / 15.3</td></tr><tr><td></td><td>Source Location</td><td>16.8 / -</td><td>- / -</td></tr><tr><td>Death Process</td><td>Num Infected</td><td>0.037 / 0.042</td><td>0.029 / 0.019</td></tr><tr><td></td><td>Infection Rate</td><td>0.108 / -</td><td>- / -</td></tr><tr><td>IRT</td><td>Correctness</td><td>0.035 / 0.031</td><td>0.031 / 0.033</td></tr><tr><td>Dugongs</td><td>Length</td><td>0.20 / 0.17</td><td>0.19 / 0.20</td></tr><tr><td>Peregrines</td><td>Population</td><td>0.26 / 0.38</td><td>0.25 / 0.66</td></tr><tr><td>Mastectomy</td><td>Survival</td><td>0.084 / 0.082</td><td>0.079 / 0.075</td></tr><tr><td>Predator-Prey</td><td>Population</td><td>- / -</td><td>- / -</td></tr><tr><td>Emotions</td><td>Prediction</td><td>0.538 / -</td><td>- / -</td></tr><tr><td>Moral Machines</td><td>Judgement</td><td>0.046 / -</td><td>0.045 / -</td></tr></tbody></table></table></figure><blockquote><p>🔼 이 표는 논문의 실험 설계 평가 부분에서 GPT-40과 Box&rsquo;s Apprentice 두 가지 에이전트의 성능을 보여줍니다. 각 에이전트는 10가지 과학적 환경에서 실험을 설계하고, 그에 따른 예상 정보 이득(EIG)을 측정합니다. 표에는 각 과제에 대한 두 에이전트의 EIG 값이 제시되어 있는데, 사전 정보가 있는 경우와 없는 경우를 &lsquo;/&lsquo;로 구분하여 나타냅니다. 이를 통해 각 에이전트의 실험 설계 능력과 사전 정보 활용 능력을 정량적으로 비교 분석할 수 있습니다.</p><details><summary>read the caption</summary>Table 3: EI Regrets for GPT-4o and Box’s Apprentice Across Different Tasks. EI regrets for prior and no prior conditinos are separated by ‘/’.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Env</th><th>Goal</th><th>Error@0</th><th>Error@10</th><th>Discovery@10</th></tr></thead><tbody><tr><td>Hyperbolic Discounting</td><td>Choice</td><td>0.31 ± 0.18, 0.96 ± 0.14</td><td>0.74 ± 0.21, 0.95 ± 0.07</td><td>0.74 ± 0.14, 1.0 ± 0.00</td></tr><tr><td>Hyperbolic Discounting</td><td>Discount</td><td>-0.06 ± 0.00, -</td><td>-0.06 ± 0.00, -</td><td>-, -</td></tr><tr><td>Location Finding</td><td>Signal</td><td>0.96 ± 0.58, 1.17 ± 0.60</td><td>1.24 ± 0.96, 0.5 ± 0.54</td><td>0.97 ± 0.72, 0.63 ± 0.71</td></tr><tr><td>Location Finding</td><td>Source Location</td><td>1.29 ± 1.3, -</td><td>-0.15 ± 0.4, -</td><td>-, -</td></tr><tr><td>Death Process</td><td>Num Infected</td><td>1.19 ± 1.09, 0.19 ± 0.96</td><td>0.46 ± 0.76, 0.74 ± 1.14</td><td>0.75 ± 0.75, 1.61 ± 1.60</td></tr><tr><td>Death Process</td><td>Infection Rate</td><td>0.13 ± 0.37, -</td><td>1.64 ± 1.12, -</td><td>-, -</td></tr><tr><td>IRT</td><td>Correctness</td><td>0.00 ± 0.00, -0.16 ± 0.26</td><td>0 ± 0.11, 0.08 ± 0.32</td><td>-0.28 ± 0.26, -0.16 ± 0.20</td></tr><tr><td>Dugongs</td><td>Length</td><td>0.06 ± 0.12, -0.02 ± 0.04</td><td>-0.09 ± 0.00, -0.08 ± 0.00</td><td>-0.08 ± 0.01, -0.08 ± 0.01</td></tr><tr><td>Peregrines</td><td>Population</td><td>2.29 ± 1.20, 2.21 ± 1.57</td><td>-0.65 ± 0.03, -0.67 ± 0.01</td><td>-0.63 ± 0.06, -0.66 ± 0.02</td></tr><tr><td>Mastectomy</td><td>Survival</td><td>0.18 ± 0.37, 0.00 ± 0.28</td><td>0.27 ± 0.19, 0.36 ± 0.27</td><td>1.00 ± 0.27, 0.21 ± 0.16</td></tr><tr><td>Predator-Prey</td><td>Population</td><td>0.08 ± 0.09, 0.73 ± 0.05</td><td>-0.45 ± 0.02, -0.43 ± 0.02</td><td>-0.26 ± 0.16, -0.40 ± 0.03</td></tr><tr><td>Emotions</td><td>Prediction</td><td>0.74 ± 0.29, -</td><td>0.82 ± 0.34, -</td><td>0.87 ± 0.35, -</td></tr><tr><td>Moral Machines</td><td>Judgement</td><td>0.32 ± 0.26, -</td><td>0.44 ± 0.16, -</td><td>0.60 ± 0.13, -</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 4는 GPT-40 모델이 다양한 과학적 과제를 수행했을 때의 성능을 보여줍니다. 표에는 과제 유형, 사전 정보 유무에 따른 표준화된 오차, 평균 오차가 표시됩니다. 각 과제는 5번 반복하여 평균 오차를 계산했습니다. 상단 행은 사전 정보가 있는 경우, 하단 행은 사전 정보가 없는 경우의 결과입니다.</p><details><summary>read the caption</summary>Table 4: Performance of GPT-4o Across Different Tasks. Numbers shown are standardized errors. Errors with prior (top line) and without prior (bottom line) appear on different lines. Errors are averaged across 5 runs.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Env</th><th>Goal</th><th>Error@0</th><th>Error@10</th><th>Discovery@10</th></tr></thead><tbody><tr><td>Hyperbolic Discounting</td><td>Choice</td><td>0.66 ± 0.25<br>0.66 ± 0.25</td><td>1.17 ± 0.14<br>0.91 ± 0.09</td><td>0.66 ± 0.30<br>0.74 ± 0.42</td></tr><tr><td>Location Finding</td><td>Signal</td><td>0.99 ± 0.58<br>1.18 ± 0.64</td><td>1.45 ± 1.60<br>0.83 ± 0.600</td><td>1.18 ± 1.12<br>-0.01 ± 0.30</td></tr><tr><td>Death Process</td><td>Num Infected</td><td>3.79 ± 1.68<br>-0.90 ± 0.05</td><td>-1.02 ± 0.05<br>-0.61 ± 0.30</td><td>0.58 ± 0.85<br>0.50 ± 1.26</td></tr><tr><td>IRT</td><td>Correctness</td><td>0.44 ± 0.36<br>0.12 ± 0.24</td><td>-0.12 ± 0.14<br>0.12 ± 0.14</td><td>-0.08 ± 0.39<br>0.2 ± 0.40</td></tr><tr><td>Dugongs</td><td>Length</td><td>0.26 ± 0.12<br>0.05 ± 0.10</td><td>-0.08 ± 0.02<br>-0.09 ± 0.004</td><td>-0.09 ± 0.005<br>-0.08 ± 0.004</td></tr><tr><td>Peregrines</td><td>Population</td><td>2.71 ± 0.60<br>1.62 ± 0.47</td><td>0.04 ± 0.21<br>0.95 ± 0.86</td><td>0.97 ± 1.38<br>-0.19 ± 0.79</td></tr><tr><td>Mastectomy</td><td>Survival</td><td>0.14 ± 0.41<br>0.73 ± 0.15</td><td>0.55 ± 0.24<br>0.64 ± 0.15</td><td>0.91 ± 0.28<br>0.27 ± 0.23</td></tr><tr><td>Moral Machines</td><td>Judgement</td><td>0.97 ±i 0.33</td><td>0.89 ± 0.21</td><td>0.56 ± 0.18</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 5는 Box&rsquo;s Apprentice 에이전트의 다양한 과제에 대한 성능을 보여줍니다. 표준 오차가 표시되며, 사전 정보가 있는 경우와 없는 경우의 오차가 별도로 표시됩니다. 각 값은 5번의 실행에 걸쳐 평균된 값입니다. 이 표는 에이전트가 과제를 얼마나 잘 수행했는지, 그리고 사전 정보가 에이전트의 성능에 미치는 영향을 정량적으로 보여줍니다.</p><details><summary>read the caption</summary>Table 5: Performance of Box’s Apprentice Across Different Tasks. Standardized errors shown here. Errors with prior (top line) and without prior (bottom line) appear on different lines. Errors are averaged across 5 runs.</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Superposition of K signal sources in d-dim space</td></tr><tr><td>Setup Parameters</td><td>Num signal sources K, dim of space d, base signal b, max signal m, noise σ</td></tr><tr><td>Observations</td><td>Total noisy signal at point of measurement</td></tr><tr><td>Goals</td><td>Predicting signal intensity at new points and source locations</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 6은 위치 찾기 환경에 대한 설명입니다. 이 환경에서는 신호를 방출하는 숨겨진 신호원이 있으며, 과학자는 다양한 지점에서 중첩된 신호를 측정할 수 있습니다. 본 실험은 포스터 등의 연구(Foster et al. [14])에서 직접적으로 가져왔습니다. 표에는 입력과 출력이 설명되어 있으며, 신호원의 위치와 신호 강도를 예측하는 것이 목표입니다. 신호 강도는 역제곱 법칙에 따라 감소하며, 배경 신호와 최대 신호 강도를 조절하는 상수가 있습니다. 포스터 등의 연구와 달리, 총 강도를 관찰합니다.</p><details><summary>read the caption</summary>Table 6: Location Finding</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Human decision-making in temporal discounting of rewards</td></tr><tr><td>Setup Parameters</td><td>Params of the discount function (ϵ, mean and std for log k, scale for α)</td></tr><tr><td>Observations</td><td>Choice between immediate iR and delayed reward dR at delay D</td></tr><tr><td>Goals</td><td>Predicting choices and the value of the discount factor</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 7은 과학적 발견 과정에서 실험 설계 및 모델 발견 능력을 평가하기 위한 벤치마크인 BoxingGym 프레임워크에 대한 정보를 제공합니다. 특히, 과감한 시간적 할인(Hyperbolic Temporal Discounting) 환경에 대해 설명합니다. 이 환경에서 과학자 에이전트는 참가자의 즉각적인 보상과 지연된 보상 간의 선택을 관찰하여 참가자의 시간적 할인 요소를 이해해야 합니다. 표에는 모델의 매개변수, 관찰값, 목표가 포함되어 있습니다.</p><details><summary>read the caption</summary>Table 7: Hyperbolic Discounting</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>The spread of an infection over time</td></tr><tr><td>Setup Parameters</td><td>Pop size <math>N</math>, params of the infetion rate (<math>&quot;&quot;\mu</math>, <math>&quot;&quot;\sigma</math>, upper and lower bounds)</td></tr><tr><td>Observations</td><td>Number of infected individuals at observation time</td></tr><tr><td>Goals</td><td>Predicting the number of infected individuals at a time and the infection rate</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 8은 BoxingGym 벤치마크의 환경 중 하나인 &lsquo;Death Process&rsquo; 환경에 대한 설명을 담고 있습니다. 이 환경은 시간에 따라 건강한 개체군 내에서 감염이 확산되는 과정을 모델링합니다. 표에는 모델, 설정 매개변수, 관찰값, 목표 등이 포함되어 있어 Death Process 환경을 정의하는 데 필요한 요소들을 종합적으로 보여줍니다. 설정 매개변수에는 감염률, 인구 크기 등의 요소들이 포함되며, 관찰값은 특정 시점의 감염자 수, 목표는 시간에 따른 감염자 수 및 감염률 예측으로 구성됩니다.</p><details><summary>read the caption</summary>Table 8: Death Process</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Param</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Student performance on multi-question exams</td></tr><tr><td>Setup Parameters</td><td>Number of students <math alttext="N" class="ltx_Math" display="inline" id="A4.T9.1.1.1.m1.1"><semantics id="A4.T9.1.1.1.m1.1a"><mi id="A4.T9.1.1.1.m1.1.1" xref="A4.T9.1.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A4.T9.1.1.1.m1.1b"><ci id="A4.T9.1.1.1.m1.1.1.cmml" xref="A4.T9.1.1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T9.1.1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="A4.T9.1.1.1.m1.1d">italic_N</annotation></semantics></math>, number of questions <math alttext="Q" class="ltx_Math" display="inline" id="A4.T9.2.2.2.m2.1"><semantics id="A4.T9.2.2.2.m2.1a"><mi id="A4.T9.2.2.2.m2.1.1" xref="A4.T9.2.2.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="A4.T9.2.2.2.m2.1b"><ci id="A4.T9.2.2.2.m2.1.1.cmml" xref="A4.T9.2.2.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T9.2.2.2.m2.1c">Q</annotation><annotation encoding="application/x-llamapun" id="A4.T9.2.2.2.m2.1d">italic_Q</annotation></semantics></math>, student-question pair to predict</td></tr><tr><td>Observations</td><td>Outcomes of various student-question pairs</td></tr><tr><td>Goals</td><td>Predicting the correctness of student responses to questions</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 9는 Item Response Theory(IRT) 모델에 대한 설명을 제공합니다. IRT 모델은 학생의 능력과 질문의 난이도를 고려하여 학생의 질문에 대한 정답률을 예측하는 통계적 모델입니다. 표에서는 IRT 모델의 매개변수, 설정 매개변수, 관측값, 목표 등에 대한 설명을 보여줍니다. IRT 모델의 세 가지 변형(1PL, 2PL, 3PL) 중 2PL 모델에 대한 자세한 내용도 포함하고 있습니다.</p><details><summary>read the caption</summary>Table 9: IRT Model</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Bayesian hierarchical model</td></tr><tr><td>Setup Parameters</td><td>alpha, beta, lambda, lower limit, upper limit</td></tr><tr><td>Observations</td><td>Length of dugong at a given age</td></tr><tr><td>Goals</td><td>Predicting the length of dugongs at different ages</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 10은 논문의 Dugongs 환경에 대한 설명입니다. 이 표는 Bayesian 계층적 모델을 사용하여 dugong의 길이를 예측하는 실험 환경을 자세히 설명합니다. 모델 매개변수, 관측값, 목표 등의 정보를 포함하고 있습니다. 본질적으로는 dugong의 나이와 길이 사이의 관계를 모델링하고 예측하는 데 사용되는 통계적 모델에 대한 세부 정보를 제공합니다.</p><details><summary>read the caption</summary>Table 10: Dugongs Environment</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Poisson regression model</td></tr><tr><td>Setup Parameters</td><td>Regression params: α, β<sub>1</sub>, β<sub>2</sub>, and β<sub>3</sub></td></tr><tr><td>Observations</td><td>Population count of peregrine falcons at a given time</td></tr><tr><td>Goals</td><td>Predicting the population of peregrines at different times</td></tr></tbody></table></table></figure><blockquote><p>🔼 이 표는 논문의 3.4절 도메인 섹션에 있는 표 11입니다. 이 표는 Peregrine 환경에 대한 설명을 제공합니다. Peregrine 환경은 시간에 따른 Peregrine Falcon 개체 수 변화를 모델링하는 환경입니다. 이 표는 환경에 사용된 모델, 설정 매개변수, 관측값, 목표 등을 보여줍니다.</p><details><summary>read the caption</summary>Table 11: Peregrine Environment</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Survival analysis using a Bayesian approach</td></tr><tr><td>Setup Parameters</td><td>num_patients, time_upper_bound, lambda, beta</td></tr><tr><td>Observations</td><td>Whether a selected patient is alive or dead</td></tr><tr><td>Goals</td><td>Predict survival based on time since surgery and if the cancer had metastasized</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 12는 유방암 환자의 생존율을 모델링하는 생존 분석 환경에 대한 설명입니다. 이 환경에서는 수술 후 시간과 전이 여부를 기반으로 환자의 생존 여부를 예측합니다. 표에는 환경에 대한 매개변수, 모델, 설정 매개변수, 관찰값 및 목표 등의 정보가 포함되어 있습니다. 자세한 내용은 본문을 참조하세요.</p><details><summary>read the caption</summary>Table 12: Survival Analysis Environment</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Lotka-Volterra equations</td></tr><tr><td>Setup Parameters</td><td>Initial prey population, initial predator population, α, β, γ, and δ</td></tr><tr><td>Observations</td><td>Populations of prey and predators at a given time</td></tr><tr><td>Goals</td><td>Predicting populations</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 13은 논문의 &lsquo;3.4 도메인&rsquo; 섹션에 있는 포식자-피식자 환경에 대한 설명입니다. 이 표는 시뮬레이션된 포식자와 피식자 개체군의 상호 작용을 모델링하는 Lotka-Volterra 방정식에 기반한 환경을 보여줍니다. 여기에는 모델(Lotka-Volterra 방정식), 설정 매개변수(초기 포식자 및 피식자 개체군 크기, α, β, γ, δ), 관측값(주어진 시간에 포식자 및 피식자 개체군), 목표(개체군 예측) 등이 포함됩니다.</p><details><summary>read the caption</summary>Table 13: Predator-Prey Environment</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Forward regression model with priors for emotional response</td></tr><tr><td>Setup Parameters</td><td>Prize values, probabilities, outcome, LLM</td></tr><tr><td>Observations</td><td>Prediction in natural language of how a player feels and why</td></tr><tr><td>Goals</td><td>Predicting what a participant thinks a player feels on a likert scale of 8 emotions.</td></tr></tbody></table></table></figure><blockquote><p>🔼 이 표는 논문의 &lsquo;3.4 도메인&rsquo; 섹션에 있는 감정 예측 환경에 대한 설명입니다. 참가자가 돈이 걸린 게임에서 룰렛을 돌린 후 플레이어의 감정을 예측하는 시나리오를 보여줍니다. 표에는 모델의 매개변수, 관측값, 목표 등이 포함되어 더 자세한 내용을 이해하는 데 도움이 됩니다. 본질적으로 플레이어의 감정 반응을 예측하기 위해 사용되는 예측 모델의 구성 요소를 설명합니다.</p><details><summary>read the caption</summary>Table 14: Emotions From Outcomes Environment</details></blockquote><figure style=max-width:100%;text-align:center><table style=width:100%><caption style=caption-side:bottom;text-align:left;white-space:normal;display:block;max-width:100%;color:var(--tw-prose-captions);margin-bottom:10px></caption><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td>Model</td><td>Logistic regression model with priors for moral decision-making</td></tr><tr><td>Setup Parameters</td><td>Character attributes, intervention type, LLM</td></tr><tr><td>Observations</td><td>Prediction in natural language of which group to save and why</td></tr><tr><td>Goals</td><td>Predicting which group participants choose to save</td></tr></tbody></table></table></figure><blockquote><p>🔼 표 15는 도덕적 기계 환경에 대한 설명입니다. 자율 주행 자동차가 도덕적 딜레마 상황에서 어떤 그룹을 구할지 결정해야 하는 시나리오를 제시합니다. 각 그룹의 등장인물은 유모차, 소년, 소녀, 임산부, 남성 의사, 여성 의사, 여성 운동선수, 남성 운동선수, 여성 임원, 남성 임원, 큰 여성, 큰 남성, 노숙자, 노인 남성, 노인 여성, 범죄자, 개, 고양이 중 하나일 수 있습니다. 모델은 등장인물의 속성(성별, 나이, 사회적 지위, 체력, 종)과 개입 유형을 고려하여 그룹을 선택합니다. 표는 이러한 요소의 영향을 보여주는 회귀 계수를 포함합니다.</p><details><summary>read the caption</summary>Table 15: Moral Machines Environment</details></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-5d7b4652d48964abc9e4faa920797351 class=gallery><img src=paper_images/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=paper_images/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/&amp;title=BoxingGym:%20Benchmarking%20Progress%20in%20Automated%20Experimental%20Design%20and%20Model%20Discovery" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/&amp;text=BoxingGym:%20Benchmarking%20Progress%20in%20Automated%20Experimental%20Design%20and%20Model%20Discovery" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/&amp;subject=BoxingGym:%20Benchmarking%20Progress%20in%20Automated%20Experimental%20Design%20and%20Model%20Discovery" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_paper-reviews/2501.01540/index.md",oid_likes="likes_paper-reviews/2501.01540/index.md"</script><script type=text/javascript src=/ai-paper-reviewer/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/ai-paper-reviewer/paper-reviews/2501.01257/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-01-02T00:00:00+00:00>2 January 2025</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/ai-paper-reviewer/paper-reviews/2501.01149/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">A3: Android Agent Arena for Mobile GUI Agents</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-01-02T00:00:00+00:00>2 January 2025</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/ai-paper-reviewer/tags/ title=Tags>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
AI Paper Reviews by AI</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/ai-paper-reviewer/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/ai-paper-reviewer/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>