[{"content": "| Type | Model | FID\u2193 | IS\u2191 | Pre\u2191 | Rec\u2191 | #Para | #Step | Time |\n|---|---|---|---|---|---|---|---|---|\n| GAN\u2020 | StyleGan-XL (Sauer et al., 2022) | 2.30 | 265.1 | 0.78 | 0.53 | 166M | 1 | 0.3 |\n| Diff.\u2020 | ADM (Dhariwal & Nichol, 2021) | 10.94 | 101.0 | 0.69 | 0.63 | 554M | 250 | 168 |\n| Diff.\u2020 | LDM-4-G (Rombach et al., 2022) | 3.60 | 247.7 | - | - | 400M | 250 | - |\n| Diff.\u2020 | DiT-L/2 (Peebles & Xie, 2023) | 5.02 | 167.2 | 0.75 | 0.57 | 458M | 250 | 31 |\n| Diff.\u2020 | L-DiT-7B (Peebles & Xie, 2023) | 2.28 | 316.2 | 0.83 | 0.58 | 7.0B | 250 | >45 |\n| Mask.\u2020 | MaskGIT (Chang et al., 2022) | 6.18 | 182.1 | 0.80 | 0.51 | 227M | 8 | 0.5 |\n| AR\u2020 | VQVAE-2\u2020 (Razavi et al., 2019) | 31.11 | ~45 | 0.36 | 0.57 | 13.5B | 5120 | - |\n| AR\u2020 | VQGAN\u2020 (Esser et al., 2021) | 18.65 | 80.4 | 0.78 | 0.26 | 227M | 256 | 19 |\n| AR | VQGAN (Esser et al., 2021) | 15.78 | 74.3 | - | - | 1.4B | 256 | 24 |\n| AR | ViTVQ (Yu et al., 2021) | 4.17 | 175.1 | - | - | 1.7B | 1024 | >24 |\n| AR | RQTran. (Lee et al., 2022) | 7.55 | 134.0 | - | - | 3.8B | 68 | 21 |\n| AR | VAR-d16 (Tian et al., 2024) | 4.19 | 230.2 | 0.84 | 0.48 | 310M | 10 | 0.133 |\n| AR | VAR-d20 (Tian et al., 2024) | 3.35 | 301.4 | 0.84 | 0.51 | 600M | 10 | - |\n| AR | VAR-d24 (Tian et al., 2024) | 2.51 | 312.2 | 0.82 | 0.53 | 1.03B | 10 | - |\n| AR | LlamaGen-B (Sun et al., 2024) | 5.42 | 193.5 | 0.83 | 0.44 | 111M | 256 | - |\n| AR | LlamaGen-L (Sun et al., 2024) | 4.11 | 283.5 | 0.85 | 0.48 | 343M | 256 | 5.01 |\n| Baseline | VAR-<i>skip-1</i> | 9.52 | 178.9 | 0.68 | 0.54 | 310M | 9 | 0.113 |\n| Baseline | VAR-<i>skip-2</i> | 40.09 | 56.8 | 0.46 | 0.50 | 310M | 8 | 0.098 |\n| Baseline | VAR-<i>onestep*</i> | 157.5 | - | - | - | 1 | - | - |\n| Baseline | LlamaGen-<i>skip-106</i> | 19.14 | 80.39 | 0.42 | 0.43 | 343M | 150 | 2.94 |\n| Baseline | LlamaGen-<i>skip-156</i> | 80.72 | 12.13 | 0.17 | 0.20 | 343M | 100 | 1.95 |\n| Baseline | LlamaGen-<i>onestep*</i> | 220.2 | - | - | - | 1 | - | - |\n| Ours | VAR-d16-DD | 9.94 | 193.6 | 0.80 | 0.37 | 327M | 1 | 0.021 (6.3\u00d7) |\n| Ours | VAR-d16-DD | 7.82 | 197.0 | 0.80 | 0.41 | 327M | 2 | 0.036 (3.7\u00d7) |\n| Ours | VAR-d20-DD | 9.55 | 197.2 | 0.78 | 0.38 | 635M | 1 | - |\n| Ours | VAR-d20-DD | 7.33 | 204.5 | 0.82 | 0.40 | 635M | 2 | - |\n| Ours | VAR-d24-DD | 8.92 | 202.8 | 0.78 | 0.39 | 1.09B | 1 | - |\n| Ours | VAR-d24-DD | 6.95 | 222.5 | 0.83 | 0.43 | 1.09B | 2 | - |\n| Ours | LlamaGen-B-DD | 15.50 | 135.4 | 0.76 | 0.26 | 98.3M | 1 | - |\n| Ours | LlamaGen-B-DD | 11.17 | 154.8 | 0.80 | 0.31 | 98.3M | 2 | - |\n| Ours | LlamaGen-L-DD | 11.35 | 193.6 | 0.81 | 0.30 | 326M | 1 | 0.023 (217.8\u00d7) |\n| Ours | LlamaGen-L-DD | 7.58 | 237.5 | 0.84 | 0.37 | 326M | 2 | 0.043 (116.5\u00d7) |", "caption": "Table 1: \nGenerative performance on class-conditional ImageNet-256. \u201c#Step\u201d indicates the number of model inference to generate one image. \u201cTime\u201d is the wall-time of generating one image in the steady state. Results with \u2020 are taken from the VAR paper (Tian et\u00a0al., 2024).", "description": "\ud45c 1\uc740 \ud074\ub798\uc2a4 \uc870\uac74\ubd80 ImageNet-256 \ub370\uc774\ud130\uc14b\uc5d0\uc11c \uc5ec\ub7ec \uc774\ubbf8\uc9c0 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud55c \ud45c\uc785\ub2c8\ub2e4.  \uac01 \ubaa8\ub378\uc758 FID(Fr\u00e9chet Inception Distance) \uc810\uc218, Inception Score(IS), Precision, Recall, \ub9e4\uac1c\ubcc0\uc218 \uc218, \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc5d0 \ud544\uc694\ud55c \ub2e8\uacc4 \uc218(#Step), \uadf8\ub9ac\uace0 \uc548\uc815\uc801\uc778 \uc0c1\ud0dc\uc5d0\uc11c \uc774\ubbf8\uc9c0 \ud558\ub098\ub97c \uc0dd\uc131\ud558\ub294 \ub370 \uac78\ub9ac\ub294 \uc2dc\uac04(Time)\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  #Step\uc740 \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud558\uae30 \uc704\ud574 \uac70\uccd0\uc57c \ud558\ub294 \ucd94\ub860 \ub2e8\uacc4 \uc218\ub97c \ub098\ud0c0\ub0b4\uba70, Time\uc740 \uc2e4\uc81c \uc18c\uc694 \uc2dc\uac04\uc744 \ucd08 \ub2e8\uc704\ub85c \ud45c\uc2dc\ud569\ub2c8\ub2e4.  Tian et al.(2024) \ub17c\ubb38\uc758 VAR \ubaa8\ub378 \uacb0\uacfc\ub294 \u2020 \ud45c\uc2dc\ub85c \uad6c\ubd84\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud45c\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\uc758 \uc0dd\uc131 \ud488\uc9c8\uacfc \uc18d\ub3c4\ub97c \ube44\uad50\ud558\uc5ec DD \ubaa8\ub378\uc758 \ud6a8\uc728\uc131\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.", "section": "5. \uc2e4\ud5d8 \uacb0\uacfc"}, {"content": "| Type | Model | FID\u2193 | IS\u2191 | Pre\u2191 | Rec\u2191 | #Para | #Step | Time |\n|---|---|---|---|---|---|---|---|---|\n| AR | VAR (Tian et al., 2024) | 4.19 | 230.2 | 0.84 | 0.48 | 310M | 10 | 0.133 |\n| AR | LlamaGen (Sun et al., 2024) | 4.11 | 283.5 | 0.865 | 0.48 | 343M | 256 | 5.01 |\n| Ours | VAR-pre-trained-1-6 | 5.03 | 242.8 | 0.84 | 0.45 | 327M | 6 | 0.090 (1.5\u00d7) |\n| Ours | VAR-pre-trained-4-6 | 5.47 | 230.5 | 0.84 | 0.43 | 327M | 4 | 0.062 (2.1\u00d7) |\n| Ours | VAR-pre-trained-5-6 | 6.54 | 210.8 | 0.83 | 0.42 | 327M | 3 | 0.045 (2.6\u00d7) |\n| Ours | LlamaGen-pre-trained-1-81 | 5.71 | 238.6 | 0.83 | 0.43 | 326M | 81 | 1.725 (2.9\u00d7) |\n| Ours | LlamaGen-pre-trained-41-81 | 6.20 | 233.8 | 0.83 | 0.41 | 326M | 42 | 0.880 (5.7\u00d7) |\n| Ours | LlamaGen-pre-trained-61-81 | 6.76 | 231.4 | 0.83 | 0.40 | 326M | 22 | 0.447 (11.2\u00d7) |", "caption": "Table 2: Generation quality of involving the pre-trained AR model when sampling. The notation pre-trained-n-m means that the pre-trained AR model is used to re-generate the n\ud835\udc5bnitalic_n-th to m\u22121\ud835\udc5a1m-1italic_m - 1-th tokens in the sequence generated by the first step of DD.", "description": "\ud45c 2\ub294 \uc0ac\uc804 \ud6c8\ub828\ub41c \uc790\ub3d9 \ud68c\uadc0(AR) \ubaa8\ub378\uc744 \uc0d8\ud50c\ub9c1 \uacfc\uc815\uc5d0 \ud3ec\ud568\uc2dc\ucf30\uc744 \ub54c\uc758 \uc0dd\uc131 \ud488\uc9c8\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  'pre-trained-n-m' \ud45c\uae30\ubc95\uc740 DD\uc758 \uccab \ubc88\uc9f8 \ub2e8\uacc4\uc5d0\uc11c \uc0dd\uc131\ub41c \uc2dc\ud000\uc2a4 \ub0b4 n\ubc88\uc9f8 \ud1a0\ud070\ubd80\ud130 m-1\ubc88\uc9f8 \ud1a0\ud070\uae4c\uc9c0\ub97c \uc0ac\uc804 \ud6c8\ub828\ub41c AR \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub2e4\uc2dc \uc0dd\uc131\ud588\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.  \uc989, DD \ubaa8\ub378\uc774 \ucc98\uc74c \uba87 \uac1c\uc758 \ud1a0\ud070\uc744 \uc0dd\uc131\ud55c \ud6c4, \uc0ac\uc804 \ud6c8\ub828\ub41c AR \ubaa8\ub378\uc744 \uc774\uc6a9\ud558\uc5ec \ucd94\uac00\uc801\uc778 \ud1a0\ud070\ub4e4\uc744 \uc0dd\uc131\ud558\ub294 \ud558\uc774\ube0c\ub9ac\ub4dc \ubc29\uc2dd\uc758 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\ub294 \ud45c\uc785\ub2c8\ub2e4.  \uc774\ub97c \ud1b5\ud574 \uc0ac\uc804 \ud6c8\ub828\ub41c \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud65c\uc6a9\ud558\uba74\uc11c\ub3c4 DD \ubaa8\ub378\uc758 \uc18d\ub3c4 \ud5a5\uc0c1 \ud6a8\uacfc\ub97c \uc720\uc9c0\ud558\ub294 \ubc29\uc2dd\uc758 \uc131\ub2a5\uc744 \ube44\uad50 \ubd84\uc11d\ud569\ub2c8\ub2e4.", "section": "5.3 Generation Involving the Pre-trained Models"}, {"content": "| Type | Model | FID | #Param | #Step | Time |\n|---|---|---|---|---|---| \n| AR | LlamaGen | 25.70 | 775M | 256 | 7.90 |\n| Ours | LlamaGen-DD | 36.09 | 756M | 1 | 0.052 (151.9x) |\n| Ours | LlamaGen-DD | 28.95 | 756M | 2 | 0.085 (92.9x) |", "caption": "Table 3: Generation results of DD on text-to-image task.", "description": "\ud45c 3\uc740 \uc81c\uc2dc\ub41c \ub17c\ubb38\uc5d0\uc11c DD(Distilled Decoding) \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud55c \ud14d\uc2a4\ud2b8-\uc774\ubbf8\uc9c0 \uc0dd\uc131 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  LlamaGen \ubaa8\ub378\uc744 \uae30\ubc18\uc73c\ub85c \ud559\uc2b5\ub41c DD \ubaa8\ub378\uc774 \uc774\ubbf8\uc9c0 \uc0dd\uc131 \uc18d\ub3c4 \ud5a5\uc0c1\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc744 FID(Fr\u00e9chet Inception Distance) \uc810\uc218, \ub9e4\uac1c\ubcc0\uc218 \uc218, \uc0dd\uc131 \ub2e8\uacc4 \uc218, \uc0dd\uc131 \uc2dc\uac04 \ub4f1\uc744 \ud1b5\ud574 \uc815\ub7c9\uc801\uc73c\ub85c \ud3c9\uac00\ud55c \uacb0\uacfc\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \ubcf8 \ud45c\ub294 LlamaGen \ubaa8\ub378\uc758 \uae30\ubcf8 \uc131\ub2a5\uacfc \ube44\uad50\ud558\uc5ec DD \ubaa8\ub378\uc758 \ud6a8\uc728\uc131 \ubc0f \uc131\ub2a5\uc744 \ud30c\uc545\ud558\ub294 \ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4.", "section": "5.3 Generation involving the pre-trained models"}]