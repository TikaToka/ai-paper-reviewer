[{"content": "| Prompt method | Content |\n|---|---| \n| Vanilla CoT | Let\u2019s think step by step: | \n| CoT with Token Budget | Let\u2019s think step by step and use less than <span class=\"ltx_text\" style=\"color:#FF0000;\">budget</span> tokens: | \n| Example | Let\u2019s think step by step and use less than <span class=\"ltx_text\" style=\"color:#FF0000;\">50</span> tokens:|", "caption": "Table 1: Illustrations of the vanilla CoT prompt and the token-budget-aware prompt.", "description": "\uc774 \ud45c\ub294 \uc77c\ubc18\uc801\uc778 Chain-of-Thought (CoT) \ud504\ub86c\ud504\ud2b8\uc640 \ud1a0\ud070 \uc608\uc0b0\uc744 \uace0\ub824\ud55c CoT \ud504\ub86c\ud504\ud2b8\uc758 \ucc28\uc774\uc810\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  \uc77c\ubc18\uc801\uc778 CoT \ud504\ub86c\ud504\ud2b8\ub294 \ub2e8\uc21c\ud788 '\ub2e8\uacc4\ubcc4\ub85c \uc0dd\uac01\ud574 \ubd05\uc2dc\ub2e4'\ub77c\ub294 \uc9c0\uc2dc\uc5b4\ub9cc \ud3ec\ud568\ud558\ub294 \ubc18\uba74, \ud1a0\ud070 \uc608\uc0b0\uc744 \uace0\ub824\ud55c CoT \ud504\ub86c\ud504\ud2b8\ub294 '\ub2e8\uacc4\ubcc4\ub85c \uc0dd\uac01\ud574\ubcf4\uace0, \ud1a0\ud070 \uc218\ub97c [\uc608\uc0b0]\uac1c \uc774\ud558\ub85c \uc0ac\uc6a9\ud558\uc138\uc694' \uc640 \uac19\uc774 \ud1a0\ud070 \uc0ac\uc6a9\ub7c9\uc5d0 \ub300\ud55c \uc81c\ud55c\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 \ubaa8\ub378\uc774 \ub354\uc6b1 \ud6a8\uc728\uc801\uc778 \ucd94\ub860 \uacfc\uc815\uc744 \uac70\uce58\ub3c4\ub85d \uc720\ub3c4\ud558\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.", "section": "3 Token Redundancy in LLM Reasoning"}, {"content": "| Dataset | Directly Answering |  |  | Vanilla CoT |  |  | TALE (Ours) |  |  |\n|---|---|---|---|---|---|---|---|---|---| \n|  | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 |\n|---|---|---|---|---|---|---|---|---|---| \n| GSM8K | 28.29% | 12.46 | 39.43 | 81.35% | 318.10 | 541.09 | 84.46% | 77.26 | 279.84 |\n| GSM8K-Zero | 97.21% | 18.85 | 91.69 | 99.50% | 252.96 | 886.79 | 98.72% | 22.67 | 276.12 |\n| MathBench-Arithmetic | 59.67% | 41.10 | 9.78 | 75.00% | 313.51 | 78.58 | 73.67% | 39.60 | 18.62 |\n| MathBench-Middle | 33.33% | 5.00 | 3.58 | 84.67% | 553.93 | 68.22 | 79.33% | 238.14 | 42.95 |\n| MathBench-High | 51.33% | 5.00 | 4.07 | 84.00% | 653.24 | 82.44 | 80.00% | 254.82 | 47.61 |\n| MathBench-College | 44.00% | 5.00 | 3.68 | 78.00% | 675.78 | 81.56 | 70.00% | 259.85 | 45.60 |\n| Average | 52.31% | 14.57 | 25.37 | 83.75% | 461.25 | 289.78 | 81.03% | 148.72 | 118.46 |", "caption": "Table 2: Comparison of TALE (Zero-shot Estimator Version) and other prompt engineering methods.\n\u201cDirectly Answering\u201d means prompting LLM without any reasoning process.\n\u201cVanilla CoT\u201d means the vanilla CoT prompting with budget.\nThe model used in our evaluation is GPT-4o-mini\u00a0OpenAI (2024a).\nObserve that TALE achieves an average accuracy (ACC) of 80.22%, with an average output token cost of 138.53 and an average expense of 118.46.\nTALE reduces output token costs by 67%, lowers expenses by 59%, and maintains competitive performance compared to the vanilla CoT approach.\nACC \u2191\u2191\\uparrow\u2191, Output Tokens \u2193\u2193\\downarrow\u2193, Expense (10\u22125\u2062$superscript105currency-dollar10^{-5}\\$10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT $ / sample) \u2193\u2193\\downarrow\u2193.", "description": "\ud45c 2\ub294 \uc81c\ub85c\uc0f7 \ucd94\uc815\uae30 \ubc84\uc804\uc758 TALE\uacfc \ub2e4\ub978 \ud504\ub86c\ud504\ud2b8 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 \ubc29\ubc95\ub4e4\uc744 \ube44\uad50\ud55c \ud45c\uc785\ub2c8\ub2e4. \"\uc9c1\uc811 \uc751\ub2f5\"\uc740 \ucd94\ub860 \uacfc\uc815 \uc5c6\uc774 LLM\uc5d0 \ud504\ub86c\ud504\ud2b8\ub97c \uc81c\uacf5\ud558\ub294 \ubc29\uc2dd\uc774\uace0, \"Vanilla CoT\"\ub294 \uc608\uc0b0\uc774 \uc788\ub294 \uc77c\ubc18\uc801\uc778 CoT \ud504\ub86c\ud504\ud2b8 \ubc29\uc2dd\uc785\ub2c8\ub2e4. \ud3c9\uac00\uc5d0 \uc0ac\uc6a9\ub41c \ubaa8\ub378\uc740 GPT-4o-mini OpenAI (2024a)\uc785\ub2c8\ub2e4. TALE\uc740 \ud3c9\uade0 \uc815\ud655\ub3c4(ACC) 80.22%\ub97c \ub2ec\uc131\ud588\uc73c\uba70, \ud3c9\uade0 \ucd9c\ub825 \ud1a0\ud070 \ube44\uc6a9\uc740 138.53\uac1c, \ud3c9\uade0 \ube44\uc6a9\uc740 118.46\uc774\uc5c8\uc2b5\ub2c8\ub2e4. TALE\uc740 Vanilla CoT \ubc29\uc2dd\uc5d0 \ube44\ud574 \ucd9c\ub825 \ud1a0\ud070 \ube44\uc6a9\uc744 67% \uc904\uc774\uace0, \ube44\uc6a9\uc744 59% \ub0ae\ucd94\uba74\uc11c \uacbd\uc7c1\ub825 \uc788\ub294 \uc131\ub2a5\uc744 \uc720\uc9c0\ud588\uc2b5\ub2c8\ub2e4. ACC\ub294 \uc99d\uac00\ud558\uace0, \ucd9c\ub825 \ud1a0\ud070\uc740 \uac10\uc18c\ud558\uba70, \ube44\uc6a9(\uc0d8\ud50c\ub2f9 10\u207b\u2075 \ub2ec\ub7ec)\ub3c4 \uac10\uc18c\ud588\uc2b5\ub2c8\ub2e4.", "section": "6 Evaluation"}, {"content": "| LLM | Directly Answering |  |  | Vanilla CoT |  |  | TALE (Ours) |  |  |\n|---|---|---|---|---|---|---|---|---|---| \n|  | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 | ACC \u2191 | Output Tokens \u2193 | Expense \u2193 |\n| Yi-lightning | 66.67% | 80.01 | 3.09 | 79.33% | 998.10 | 21.55 | 76.67% | 373.52 | 17.25 |\n| GPT-4o-mini | 44.00% | 5.00 | 3.68 | 78.00% | 675.78 | 81.56 | 70.00% | 259.85 | 45.60 |\n| GPT-4o | 57.33% | 5.00 | 61.34 | 84.00% | 602.29 | 1359.42 | 80.00% | 181.61 | 759.95 |", "caption": "Table 3: The generalization of TALE (Zero-shot Estimator Version) across different LLMs. Yi-lightning\u00a0Wake et\u00a0al. (2024), GPT-4o-mini\u00a0OpenAI (2024a) and GPT-4o\u00a0OpenAI (2024b) are taken into consideration. We conduct the evaluation on MathBench-College. ACC \u2191\u2191\\uparrow\u2191, Output Tokens \u2193\u2193\\downarrow\u2193, Expense (10\u22125\u2062$superscript105currency-dollar10^{-5}\\$10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT $ / sample) \u2193\u2193\\downarrow\u2193.", "description": "\ud45c 3\uc740 \uc81c\ub85c\uc0f7 \ucd94\uc815\uae30 \ubc84\uc804\uc758 TALE\uc744 \ub2e4\uc591\ud55c \ub300\uaddc\ubaa8 \uc5b8\uc5b4 \ubaa8\ub378(LLM)\uc5d0\uc11c \uc77c\ubc18\ud654\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.  Yi-lightning (Wake et al., 2024), GPT-40-mini (OpenAI, 2024a), GPT-40 (OpenAI, 2024b) \uc138 \uac00\uc9c0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec MathBench-College \ub370\uc774\ud130\uc14b\uc744 \ud3c9\uac00\ud588\uc2b5\ub2c8\ub2e4.  \ud45c\uc5d0\ub294 \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4(ACC), \ucd9c\ub825 \ud1a0\ud070 \uc218, \ube44\uc6a9(\uc0d8\ud50c\ub2f9 10\u207b\u2075 \ub2ec\ub7ec)\uc774 \ub098\ud0c0\ub098 \uc788\uc73c\uba70, TALE\uc758 \uc131\ub2a5\uc774 \ubaa8\ub378\uc5d0 \uad00\uacc4\uc5c6\uc774 \uc77c\uad00\ub418\uac8c \uc720\uc9c0\ub418\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud654\uc0b4\ud45c(\u2191\u2193)\ub294 \uac01 \uc9c0\ud45c\uc758 \ubcc0\ud654 \ubc29\ud5a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.  \uc989, \u2191\ub294 \uac12\uc774 \uc99d\uac00\ud588\uace0, \u2193\ub294 \uac12\uc774 \uac10\uc18c\ud588\uc74c\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.", "section": "6. RQ3. \ud6a8\uacfc\uc801\uc778 \uc608\uc0b0 \ucd94\uc815"}]