{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 Technical Report", "publication_date": "2023-03-08", "reason": "This paper is foundational, introducing a large language model (LLM) that is central to the EnerVerse framework's language-visual alignment and action generation capabilities."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets", "publication_date": "2023-11-15", "reason": "This work is highly relevant due to EnerVerse's use of video diffusion models as a crucial component for generating embodied future spaces."}, {"fullname_first_author": "Cheng Chi", "paper_title": "Diffusion Policy: Visuomotor Policy Learning via Action Diffusion", "publication_date": "2024-00-00", "reason": "This paper provides the architecture for the policy head integrated into EnerVerse, enabling the simultaneous generation of videos and corresponding actions."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian Splatting for Real-time Radiance Field Rendering", "publication_date": "2023-00-00", "reason": "The 4D Gaussian splatting data engine pipeline in EnerVerse leverages this method for efficient 4D scene reconstruction from multi-view videos."}, {"fullname_first_author": "Jinbo Xing", "paper_title": "DynamicCrafter: Animating Open-Domain Images with Video Diffusion Priors", "publication_date": "2025-00-00", "reason": "This paper's DynamicCrafter model serves as the base model for the image-to-video task in EnerVerse, providing foundational capabilities for video generation."}]}