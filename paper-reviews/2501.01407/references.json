{"references": [{"fullname_first_author": "Yuval Alaluf", "paper_title": "Cross-image attention for zero-shot appearance transfer", "publication_date": "2023-XX-XX", "reason": "This paper proposes a novel cross-image attention mechanism which is foundational to the nested attention mechanism introduced in this paper."}, {"fullname_first_author": "Yuval Alaluf", "paper_title": "A neural space-time representation for text-to-image personalization", "publication_date": "2023-XX-XX", "reason": "This paper introduces a method for text-to-image personalization that is closely related to the techniques used in the current paper."}, {"fullname_first_author": "Moab Arar", "paper_title": "Domain-agnostic tuning-encoder for fast personalization of text-to-image models", "publication_date": "2023-XX-XX", "reason": "This paper introduces a domain-agnostic tuning-encoder for fast personalization of text-to-image models, which is directly relevant to the current paper's focus on personalization."}, {"fullname_first_author": "Moab Arar", "paper_title": "Palp: Prompt aligned personalization of text-to-image models", "publication_date": "2024-XX-XX", "reason": "This paper addresses the challenge of balancing identity preservation and prompt alignment in text-to-image models, which is a central theme of the current paper."}, {"fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "publication_date": "2022-XX-XX", "reason": "This paper is highly influential for its introduction of a method for personalizing text-to-image generation using textual inversion, which is directly relevant to the current work."}]}