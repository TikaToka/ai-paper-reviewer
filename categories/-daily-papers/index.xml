<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ğŸ¤— Daily Papers on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/</link><description>Recent content in ğŸ¤— Daily Papers on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 AI Paper Reviews by AI</copyright><lastBuildDate>Mon, 06 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/index.xml" rel="self" type="application/rss+xml"/><item><title>Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03225/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03225/</guid><description>AutoConverterëŠ” ì˜¤í”ˆì—”ë“œ ë°©ì‹ì˜ VQA ì§ˆë¬¸ì„ ë‹¤ì§€ì„ ë‹¤í˜• ì§ˆë¬¸ìœ¼ë¡œ ìë™ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ VLM(Vision Language Model) í‰ê°€ì˜ ê°ê´€ì„±ê³¼ ì¬í˜„ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ì§„ì€ AutoConverterë¥¼ ì‚¬ìš©í•˜ì—¬ 20ê°œì˜ ê¸°ì¡´ VQA ë°ì´í„°ì…‹ì„ í†µí•©í•œ VMCBenchë¼ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. VMCBen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03225/cover.png"/></item><item><title>BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03226/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03226/</guid><description>BoostStep: ë‹¨ê³„ë³„ ì¶”ë¡ ìœ¼ë¡œ LLMsì˜ ìˆ˜í•™ì  ëŠ¥ë ¥ í–¥ìƒ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03226/cover.png"/></item><item><title>Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception, Decision, and Reaction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03218/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03218/</guid><description>Dispider: ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ë¶„ë¦¬ëœ ì¸ì‹, ê²°ì •, ë°˜ì‘ì„ ì‚¬ìš©í•˜ëŠ” ë¹„ë””ì˜¤ LLMì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03218/cover.png"/></item><item><title>Samba-ASR: State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02832/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02832/</guid><description>Mamba ì•„í‚¤í…ì²˜ ê¸°ë°˜ì˜ Samba-ASRì€ íš¨ìœ¨ì ì¸ ìƒíƒœ ê³µê°„ ëª¨ë¸ì„ ì´ìš©, ê¸°ì¡´ Transformer ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ìŒì„± ì¸ì‹ ë¶„ì•¼ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02832/cover.png"/></item><item><title>STAR: Spatial-Temporal Augmentation with Text-to-Video Models for Real-World Video Super-Resolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02976/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02976/</guid><description>STAR: T2V ëª¨ë¸ ê¸°ë°˜ ì‹¤ì„¸ê³„ ë¹„ë””ì˜¤ ì´ˆê³ í•´ìƒë„ ê¸°ìˆ ë¡œ í˜„ì‹¤ì ì¸ ê³µê°„ì  ì„¸ë¶€ ì •ë³´ì™€ ê²¬ê³ í•œ ì‹œê°„ì  ì¼ê´€ì„±ì„ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02976/cover.png"/></item><item><title>Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03059/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03059/</guid><description>ë§ˆìŠ¤í¬ ê¸°ë°˜ ëª¨ì…˜ ê²½ë¡œë¥¼ ì´ìš©í•œ 2ë‹¨ê³„ ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ìƒì„± í”„ë ˆì„ì›Œí¬ì¸ THROUGH-THE-MASKê°€ ë‹¤ì¤‘ ê°ì²´ì˜ ì •í™•í•œ ì• ë‹ˆë©”ì´ì…˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03059/cover.png"/></item><item><title>TransPixar: Advancing Text-to-Video Generation with Transparency</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03006/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03006/</guid><description>TransPixar: ì œí•œëœ ë°ì´í„°ë¡œë„ ê³ í’ˆì§ˆ íˆ¬ëª… ë¹„ë””ì˜¤ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.03006/cover.png"/></item><item><title>DepthMaster: Taming Diffusion Models for Monocular Depth Estimation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02576/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02576/</guid><description>DepthMasterëŠ” ë‹¨ì¼ ë‹¨ê³„ í™•ì‚° ëª¨ë¸ì„ ì´ìš©, ìƒì„±ì  íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ëª¨ë…¸í˜ëŸ¬ ê¹Šì´ ì¶”ì •ì˜ ì •í™•ë„ì™€ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02576/cover.png"/></item><item><title>GS-DiT: Advancing Video Generation with Pseudo 4D Gaussian Fields through Efficient Dense 3D Point Tracking</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02690/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02690/</guid><description>GS-DiT: íš¨ìœ¨ì ì¸ 3D ì  ì¶”ì ìœ¼ë¡œ ì˜ì‚¬ 4D ê°€ìš°ìŠ¤ í•„ë“œë¥¼ í™œìš©, 4D ë¹„ë””ì˜¤ ì œì–´ ê°€ëŠ¥í•œ í˜ì‹ ì  ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02690/cover.png"/></item><item><title>Scaling Laws for Floating Point Quantization Training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02423/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02423/</guid><description>ë¶€ë™ ì†Œìˆ˜ì  ì–‘ìí™” í›ˆë ¨ì˜ ìƒˆë¡œìš´ scaling law ë°œê²¬: ì§€ìˆ˜, ë§¨í‹°ì‚¬ ë¹„íŠ¸ ë° ìŠ¤ì¼€ì¼ë§ ì¸ì ê³„ì‚° ì •ë°€ë„ê°€ LLM ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ê·œëª…</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02423/cover.png"/></item><item><title>Test-time Computing: from System-1 Thinking to System-2 Thinking</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02497/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02497/</guid><description>í…ŒìŠ¤íŠ¸ ì‹œê°„ ì»´í“¨íŒ…ì„ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ì‹œìŠ¤í…œ 1 ì‚¬ê³ ì—ì„œ ì‹œìŠ¤í…œ 2 ì‚¬ê³  ìˆ˜ì¤€ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ì œì‹œí•˜ëŠ” íšê¸°ì ì¸ ì—°êµ¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02497/cover.png"/></item><item><title>ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/</guid><description>ToolHop: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë‹¤ì¤‘ ë‹¨ê³„ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì„ ì—„ê²©íˆ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02506/cover.png"/></item><item><title>Personalized Graph-Based Retrieval for Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02157/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02157/</guid><description>ê°œì¸í™”ëœ ê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ ì¦ê°• ìƒì„±(PGraphRAG) í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ í¬ì†Œ ë°ì´í„° ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , LLMì˜ ê°œì¸í™” ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02157/cover.png"/></item><item><title>Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01830/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01830/</guid><description>AUTO-RT: ìë™í™”ëœ ì¬ë° ì „ëµ íƒìƒ‰ìœ¼ë¡œ LLM ì·¨ì•½ì  íš¨ìœ¨ì ìœ¼ë¡œ ë°œê²¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01830/cover.png"/></item><item><title>EnerVerse: Envisioning Embodied Future Space for Robotics Manipulation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01895/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01895/</guid><description>EnerVerse: ë¡œë´‡ ì¡°ì‘ì„ ìœ„í•œ ë¯¸ë˜ ê³µê°„ ìƒì„± í”„ë ˆì„ì›Œí¬ê°€ ì¥ê¸°ê°„ ì‘ì—…ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01895/cover.png"/></item><item><title>Ingredients: Blending Custom Photos with Video Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01790/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01790/</guid><description>ê³ í’ˆì§ˆ ë‹¤ì¤‘ ID ë§ì¶¤í˜• ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ í˜ì‹ ì ì¸ í”„ë ˆì„ì›Œí¬, Ingredients ì†Œê°œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01790/cover.png"/></item><item><title>METAGENE-1: Metagenomic Foundation Model for Pandemic Monitoring</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02045/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02045/</guid><description>70ì–µ ê°œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë©”íƒ€ìœ ì „ì²´ ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(METAGENE-1)ì´ íìˆ˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì–´ ë³‘ì›ê·  íƒì§€ ë° ìœ ì „ì²´ ì„œì—´ ì„ë² ë”© ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.02045/cover.png"/></item><item><title>Virgo: A Preliminary Exploration on Reproducing o1-like MLLM</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01904/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01904/</guid><description>Virgo: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¥ë¬¸ ì‚¬ê³  ë°ì´í„°ë¥¼ í™œìš©, ë‹¤ì–‘í•œ ë©€í‹°ëª¨ë‹¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01904/cover.png"/></item><item><title>VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01957/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01957/</guid><description>VITA-1.5: ì‹¤ì‹œê°„ ì‹œê° ë° ìŒì„± ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ GPT-40 ìˆ˜ì¤€ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ LLM</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01957/cover.png"/></item><item><title>A3: Android Agent Arena for Mobile GUI Agents</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01149/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01149/</guid><description>Android Agent Arena(A3): ì‹¤ì œ ëª¨ë°”ì¼ ì•±ì—ì„œ AI ì—ì´ì „íŠ¸ì˜ ë™ì  ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ í˜ì‹  í”Œë«í¼</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01149/cover.png"/></item><item><title>BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/</guid><description>BoxingGym: LLM ê¸°ë°˜ ê³¼í•™ì  ì—ì´ì „íŠ¸ì˜ ì‹¤í—˜ ì„¤ê³„ ë° ëª¨ë¸ ë°œê²¬ ëŠ¥ë ¥ ì¢…í•© í‰ê°€ ë²¤ì¹˜ë§ˆí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01540/cover.png"/></item><item><title>CodeElo: Benchmarking Competition-level Code Generation of LLMs with Human-comparable Elo Ratings</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01257/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01257/</guid><description>CODEELO ë²¤ì¹˜ë§ˆí¬: ì¸ê°„ ìˆ˜ì¤€ì˜ Elo ë“±ê¸‰ìœ¼ë¡œ LLMì˜ ê²½ìŸì  ì½”ë“œ ìƒì„± ëŠ¥ë ¥ í‰ê°€</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01257/cover.png"/></item><item><title>Dynamic Scaling of Unit Tests for Code Reward Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01054/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01054/</guid><description>ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì˜ ìˆ˜ë¥¼ ëŠ˜ë ¤ ì½”ë“œ ë³´ìƒ ëª¨ë¸ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì„ ì œì‹œí•˜ëŠ” ì—°êµ¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01054/cover.png"/></item><item><title>Graph Generative Pre-trained Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/</guid><description>G2PT: ê·¸ë˜í”„ë¥¼ ì‹œí€€ìŠ¤ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì¸ì½”ë”©í•˜ê³  Transformerë¡œ í•™ìŠµì‹œì¼œ ê·¸ë˜í”„ ìƒì„± ë° ì˜ˆì¸¡ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ ìƒˆë¡œìš´ ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01073/cover.png"/></item><item><title>Nested Attention: Semantic-aware Attention Values for Concept Personalization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01407/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01407/</guid><description>ì¤‘ì²© ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì˜ ê°œì¸í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ Nested Attention ê¸°ë²• ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01407/cover.png"/></item><item><title>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01423/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01423/</guid><description>ê³ ì°¨ì› ì ì¬ ê³µê°„ì—ì„œì˜ ìµœì í™” ë”œë ˆë§ˆë¥¼ í•´ê²°í•˜ëŠ” VA-VAEë¥¼ í†µí•´, ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01423/cover.png"/></item><item><title>SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01320/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01320/</guid><description>SeedVR: ë¬´í•œí•œ í™•ì‚° íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ ì¼ë°˜ì ì¸ ë¹„ë””ì˜¤ ë³µì› í–¥ìƒ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01320/cover.png"/></item><item><title>SeFAR: Semi-supervised Fine-grained Action Recognition with Temporal Perturbation and Learning Stabilization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01245/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01245/</guid><description>SeFAR: ì œí•œëœ ë°ì´í„°ë¡œë„ ì •ë°€ ë™ì‘ ì¸ì‹ì˜ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ì„¸ë¯¸-ìŠˆí¼ë°”ì´ì¦ˆë“œ í•™ìŠµ í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01245/cover.png"/></item><item><title>VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01427/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01427/</guid><description>VideoAnydoor: ì •ë°€í•œ ëª¨ì…˜ ì œì–´ë¥¼ ê°–ì¶˜ ê³ í’ˆì§ˆ ì˜ìƒ ê°ì²´ ì‚½ì…</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.01427/cover.png"/></item><item><title>2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00958/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00958/</guid><description>2.5ë…„ ë¶„ëŸ‰ì˜ êµìœ¡ ë¹„ë””ì˜¤ë¥¼ í™œìš©, ê³ í’ˆì§ˆ ë‹¤ì¤‘ ëª¨ë‹¬ í…ìŠ¤íŠ¸ë¶ ì½”í¼ìŠ¤ êµ¬ì¶• ë° VLMs ì‚¬ì „ í•™ìŠµ ì„±ëŠ¥ í–¥ìƒ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00958/cover.png"/></item><item><title>AutoPresent: Designing Structured Visuals from Scratch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00912/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00912/</guid><description>AUTOPRESENT: ìì—°ì–´ ëª…ë ¹ì–´ë¡œ ì™„ë²½í•œ í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œ ìë™ ìƒì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00912/cover.png"/></item><item><title>Population Aware Diffusion for Time Series Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00910/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00910/</guid><description>ì¸êµ¬ ìˆ˜ì¤€ íŠ¹ì§• ë³´ì¡´ ì‹œê³„ì—´ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ í™•ì‚° ëª¨ë¸ PaD-TS ì œì•ˆ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00910/cover.png"/></item><item><title>Rethinking Addressing in Language Models via Contexualized Equivariant Positional Encoding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00712/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00712/</guid><description>TAPE(conTextualized equivAriant Position Embedding) í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë¬¸ë§¥ ì •ë³´ë¥¼ í™œìš©í•œ ë™ì  ìœ„ì¹˜ ì¸ì½”ë”©ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ìœ„ì¹˜ ê¸°ë°˜ ì£¼ì†Œ ì§€ì • ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00712/cover.png"/></item><item><title>MLLM-as-a-Judge for Image Safety without Human Labeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00192/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00192/</guid><description>ì¸ê°„ ë¼ë²¨ë§ ì—†ì´ ì‚¬ì „ ì •ì˜ëœ ì•ˆì „ ê·œì¹™ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í†µí•´ ì´ë¯¸ì§€ ì•ˆì „ì„±ì„ íŒë‹¨í•˜ëŠ” ìƒˆë¡œìš´ ì œë¡œìƒ· ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00192/cover.png"/></item><item><title>Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00658/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00658/</guid><description>ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ì¥ê¸° ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ëŠ” êµ¬ì¡°ì  ìƒíƒœ ê³µê°„ ëª¨ë¸(SSM)ì˜ í•œê³„ë¥¼ ê·¹ë³µ! ìµœì‹  ì—°êµ¬ì—ì„œ SSMì˜ &lt;strong>ìµœê·¼ í¸í–¥(recency bias)&lt;/strong> ë° &lt;strong>ê³¼ë„í•œ í‰í™œí™”(over-smoothing)&lt;/strong> ë¬¸ì œë¥¼ ê·œëª…í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ëŠ” **ê·¹ì„±í™” ê¸°ë²•(polarization)**ì„ ì œì‹œí•˜ì—¬ ì¥ê¸° í† í° ìƒê´€ê´€ê³„ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00658/cover.png"/></item><item><title>VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/</guid><description>VideoRefer SuiteëŠ” &lt;strong>ì •êµí•œ ê³µê°„-ì‹œê°„ì  ê°œì²´ ì´í•´ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ LLM(VideoRefer)ê³¼ ëŒ€ê·œëª¨ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹(VideoRefer-700K), ì¢…í•©ì ì¸ ë²¤ì¹˜ë§ˆí¬(VideoRefer-Bench)ë¥¼ ì œì‹œ&lt;/strong>í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00599/cover.png"/></item><item><title>Are Vision-Language Models Truly Understanding Multi-vision Sensor?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20750/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20750/</guid><description>ë©€í‹° ë¹„ì „ ì„¼ì„œ ë°ì´í„°ì— ëŒ€í•œ VLMsì˜ ì´í•´ë„ í–¥ìƒì„ ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬(MS-PR)ì™€ DNA ìµœì í™” ê¸°ë²• ì œì‹œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20750/cover.png"/></item><item><title>Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21187/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21187/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê³¼ë„í•œ ì—°ì‚° ë¬¸ì œ í•´ê²°: íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ ìƒˆë¡œìš´ ì§€í‘œ ë° ìê¸° í•™ìŠµ ì „ëµ ì œì‹œ</description></item><item><title>Edicho: Consistent Image Editing in the Wild</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21079/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21079/</guid><description>Edicho: ì´ë¯¸ì§€ ê°„ ì¼ê´€ì„± ìœ ì§€í•˜ë©° ì œë¡œìƒ· ì´ë¯¸ì§€ í¸ì§‘ ê°€ëŠ¥!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21079/cover.png"/></item><item><title>Efficiently Serving LLM Reasoning Programs with Certaindex</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20993/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20993/</guid><description>Dynasorì€ LLM ì¶”ë¡  í”„ë¡œê·¸ë¨ì˜ ìì› ì‚¬ìš©ì„ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œìœ¼ë¡œ, &lt;strong>certaindex&lt;/strong>ë¼ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ í™œìš©í•˜ì—¬ ì–´ë ¤ìš´ ì§ˆì˜ì—ëŠ” ë” ë§ì€ ì—°ì‚°ì„, ê°„ë‹¨í•œ ì§ˆì˜ì—ëŠ” ì ì€ ì—°ì‚°ì„ í• ë‹¹í•˜ê³ , ì „ë§ì´ ì—†ëŠ” ì§ˆì˜ëŠ” ì¡°ê¸°ì— ì¢…ë£Œí•¨ìœ¼ë¡œì¨ ì •í™•ë„, ì§€ì—° ì‹œê°„ ë° ë¹„ìš©ì„ ê· í˜• ìˆê²Œ ë§ì¶¥ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20993/cover.png"/></item><item><title>Facilitating large language model Russian adaptation with Learned Embedding Propagation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21140/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21140/</guid><description>LEP(Learned Embedding Propagation)ëŠ” ì ì€ ì–‘ì˜ í•™ìŠµ ë°ì´í„°ë§Œìœ¼ë¡œë„ ë‹¤êµ­ì–´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì ì‘ì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ê¸°ë²•ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21140/cover.png"/></item><item><title>HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21199/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21199/</guid><description>LLMì˜ ì ì§„ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ HumanEval Pro, MBPP Pro, BigCodeBench-Lite Pro ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21199/cover.png"/></item><item><title>HUNYUANPROVER: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/</guid><description>HunyuanProver: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ í™•ì¥ ê°€ëŠ¥í•œ ë°ì´í„° í•©ì„± í”„ë ˆì„ì›Œí¬ì™€ ì•ˆë‚´ íŠ¸ë¦¬ íƒìƒ‰ì„ í†µí•´ ìµœì²¨ë‹¨ ìë™ ì •ë¦¬ ì¦ëª… ì„±ëŠ¥ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20735/cover.png"/></item><item><title>LTX-Video: Realtime Video Latent Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00103/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00103/</guid><description>LTX-Video: ì´ˆê³ ì† ì‹¤ì‹œê°„ ê³ í•´ìƒë„ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2501.00103/cover.png"/></item><item><title>MapQaTor: A System for Efficient Annotation of Map Query Datasets</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21015/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21015/</guid><description>MAPQATOR: í”ŒëŸ¬ê·¸ì•¤í”Œë ˆì´ ë°©ì‹ì˜ ì§€ë¦¬ê³µê°„ ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹ ìƒì„± ì‹œìŠ¤í…œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21015/cover.png"/></item><item><title>Slow Perception: Let's Perceive Geometric Figures Step-by-step</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20631/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20631/</guid><description>ëŠë¦° ì§€ê°(Slow Perception): ë‹¨ê³„ë³„ ê¸°í•˜í•™ì  ë„í˜• ì¸ì‹ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20631/cover.png"/></item><item><title>TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21037/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21037/</guid><description>TANGOFLUX: ì ì€ ë§¤ê°œë³€ìˆ˜ë¡œ ì´ˆê³ ì†, ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21037/cover.png"/></item><item><title>Training Software Engineering Agents and Verifiers with SWE-Gym</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21139/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21139/</guid><description>SWE-Gym: í˜„ì‹¤ ì„¸ê³„ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì—ì´ì „íŠ¸ í›ˆë ¨ì„ ìœ„í•œ ìµœì´ˆì˜ í™˜ê²½</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.21139/cover.png"/></item><item><title>VMix: Improving Text-to-Image Diffusion Model with Cross-Attention Mixing Control</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20800/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20800/</guid><description>VMix: í¬ë¡œìŠ¤ ì–´í…ì…˜ ë¯¹ì‹± ì œì–´ë¥¼ í†µí•œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ ê°œì„ </description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20800/cover.png"/></item><item><title>Bringing Objects to Life: 4D generation from 3D objects</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20422/</link><pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20422/</guid><description>3to4D: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©ì ì œê³µ 3D ê°ì²´ë¥¼ ì‹¤ê°ë‚˜ê²Œ ì• ë‹ˆë©”ì´ì…˜í™”!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20422/cover.png"/></item><item><title>On the Compositional Generalization of Multimodal LLMs for Medical Imaging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20070/</link><pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20070/</guid><description>ì˜ë£Œ ì˜ìƒì— ëŒ€í•œ ë‹¤ì¤‘ ëª¨ë“œ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒì— êµ¬ì„±ì  ì¼ë°˜í™”(CG)ê°€ í•µì‹¬ ì—­í• ì„ ìˆ˜í–‰í•˜ë©°, ì œí•œëœ ë°ì´í„°ì—ì„œë„ íš¨ê³¼ì ì„ì„ ë°í˜.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20070/cover.png"/></item><item><title>OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/</link><pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/</guid><description>OneKE: ë„ì»¤ ê¸°ë°˜, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ LLM ì§€ì‹ ì¶”ì¶œ ì‹œìŠ¤í…œìœ¼ë¡œ ì›¹, PDFì—ì„œ ë‹¤ì–‘í•œ ë„ë©”ì¸ ì§€ì‹ ì¶”ì¶œ ê°€ëŠ¥</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.20005/cover.png"/></item><item><title>From Elements to Design: A Layered Approach for Automatic Graphic Design Composition</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19712/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19712/</guid><description>LaDeCo: ê³„ì¸µì  ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•œ ìë™ ê·¸ë˜í”½ ë””ìì¸ í•©ì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19712/cover.png"/></item><item><title>OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19723/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19723/</guid><description>OS-GenesisëŠ” ì—­ë°©í–¥ ì‘ì—… í•©ì„±ì„ í†µí•´ GUI ì—ì´ì „íŠ¸ ê¶¤ì  ìƒì„± ìë™í™” ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” í˜ì‹ ì ì¸ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19723/cover.png"/></item><item><title>Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19512/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19512/</guid><description>ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ì•ˆì „ì„±ì´ ì €í•˜ëœ LLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë™ì‹œì— ì•ˆì „ì„±ì„ ìœ ì§€í•˜ëŠ” ê°„í¸í•˜ê³  íš¨ê³¼ì ì¸ ëª¨ë¸ ê²°í•© ë°©ë²• ì œì‹œ!</description></item><item><title>VideoMaker: Zero-shot Customized Video Generation with the Inherent Force of Video Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/</guid><description>VideoMaker: ì˜ìƒ í™•ì‚° ëª¨ë¸ì˜ ê³ ìœ í•œ í˜ì„ ì´ìš©í•œ ì œë¡œìƒ· ë§ì¶¤í˜• ì˜ìƒ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19645/cover.png"/></item><item><title>Xmodel-2 Technical Report</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19638/</link><pubDate>Fri, 27 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19638/</guid><description>Xmodel-2: 12ì–µ ë§¤ê°œë³€ìˆ˜ì˜ ì¶”ë¡  ì „ë¬¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, íš¨ìœ¨ì ì¸ ì„¤ê³„ì™€ í›ˆë ¨ ì „ëµì„ í†µí•´ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19638/cover.png"/></item><item><title>Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19326/</link><pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19326/</guid><description>ì‹œê°ì  ê³¼ì œ ì •ë ¬ì„ í†µí•œ ì‘ì—… ì„ í˜¸ë„ ìµœì í™”(TPO)ë¡œ ë©€í‹°ëª¨ë‹¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.19326/cover.png"/></item><item><title>1.58-bit FLUX</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18653/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18653/</guid><description>1.58-bit FLUX: 99.5%ì˜ íŒŒë¼ë¯¸í„°ë¥¼ 1.58-bitë¡œ ì–‘ìí™”í•˜ì—¬ ëª¨ë¸ í¬ê¸° 7.7ë°°, ì¶”ë¡  ë©”ëª¨ë¦¬ 5.1ë°° ê°ì†Œ, ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„± ìœ ì§€!</description></item><item><title>3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</guid><description>3DGraphLLM: ì˜ë¯¸ë¡ ì  ê·¸ë˜í”„ì™€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ 3D ì¥ë©´ ì´í•´ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ ìµœì²¨ë‹¨ ì—°êµ¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/cover.png"/></item><item><title>CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18702/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18702/</guid><description>ë³¸ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ í˜„ëŒ€ ì§€ì‹ ê·¸ë˜í”„ì—ì„œ LLMì„ ì´ìš©í•œ ì •í™•í•œ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ CypherBenchë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ RDF ê¸°ë°˜ ì§€ì‹ ê·¸ë˜í”„ëŠ” ê³¼ë„í•˜ê²Œ í° ìŠ¤í‚¤ë§ˆì™€ ë¦¬ì†ŒìŠ¤ ì‹ë³„ì ì‚¬ìš©ìœ¼ë¡œ LLMì— ë¹„íš¨ìœ¨ì ì´ë¼ëŠ” ë¬¸ì œì ì„ ë¶„ì„í•©ë‹ˆë‹¤. íŠ¹íˆ, Wikidataì™€ ê°™ì€ í˜„ëŒ€ ì§€ì‹ ê·¸ë˜í”„ëŠ” LLMì˜ ë¬¸ë§¥ ì°½ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆ&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18702/cover.png"/></item><item><title>DepthLab: From Partial to Complete</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</guid><description>DepthLab: ë¶€ë¶„ ê¹Šì´ ì •ë³´ë¡œ ì™„ì „í•œ 3D ì‹œê° ì •ë³´ ë³µì›</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/cover.png"/></item><item><title>DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</guid><description>DiTCtrl: íŠœë‹ ì—†ì´ ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ë¡œ ë§¤ë„ëŸ¬ìš´ ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/cover.png"/></item><item><title>How "Real" is Your Real-Time Simultaneous Speech-to-Text Translation System?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18495/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18495/</guid><description>ì‹¤ì‹œê°„ ë™ì‹œ í†µì—­ ì‹œìŠ¤í…œì˜ í˜„ì‹¤ì ì¸ í•œê³„ë¥¼ ê·œëª…í•˜ê³ , í‘œì¤€í™”ëœ ìš©ì–´ì™€ ì²´ê³„ë¥¼ ì œì‹œí•˜ì—¬ ì—°êµ¬ ë°œì „ì„ ì´‰ì§„í•˜ëŠ” ë…¼ë¬¸.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18495/cover.png"/></item><item><title>MMFactory: A Universal Solution Search Engine for Vision-Language Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18072/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18072/</guid><description>MMFactory: ì‚¬ìš©ì ë§ì¶¤í˜• ë¹„ì „-ì–¸ì–´ ì‘ì—… ì†”ë£¨ì…˜ ê²€ìƒ‰ ì—”ì§„</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18072/cover.png"/></item><item><title>Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18176/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18176/</guid><description>Molar: ë©€í‹°ëª¨ë‹¬ LLMê³¼ í˜‘ì—… í•„í„°ë§ì„ ê²°í•©í•˜ì—¬ ì‹œí€€ì…œ ì¶”ì²œ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ í˜ì‹ ì ì¸ í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18176/cover.png"/></item><item><title>Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18319/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18319/</guid><description>MulberryëŠ” ì§‘ë‹¨ ëª¬í…Œ ì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰(CoMCTS)ì„ ì´ìš©, ë‹¨ê³„ì  ì¶”ë¡  ë° ë°˜ì„± ëŠ¥ë ¥ì„ ê°–ì¶˜ ë‹¤ì¤‘ ëª¨ë“œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(MLLM)ì„ ê°œë°œí•œ ì—°êµ¬ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18319/cover.png"/></item><item><title>Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/</guid><description>ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ë°©í–¥ ì¶”ì •ì˜ ì •í™•ë„ë¥¼ í¬ê²Œ ë†’ì´ëŠ” &amp;lsquo;Orient Anything&amp;rsquo; ëª¨ë¸ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18605/cover.png"/></item><item><title>PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</guid><description>PartGen: ë‹¤ì¤‘ ë·° í™•ì‚° ëª¨ë¸ì„ ì´ìš©, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ê¸°ì¡´ 3D ê°ì²´ë¡œë¶€í„° ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœ ê³ í’ˆì§ˆ 3D ê°ì²´ ìƒì„± ë° ì¬êµ¬ì„±.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/cover.png"/></item><item><title>Token-Budget-Aware LLM Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18547/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18547/</guid><description>í† í° ì˜ˆì‚° ì¸ì‹ LLM ì¶”ë¡  í”„ë ˆì„ì›Œí¬(TALE)ë¥¼ í†µí•´ LLM ì¶”ë¡ ì˜ í† í° ë¹„ìš©ì„ í¬ê²Œ ì¤„ì´ë©´ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ìµœì†Œí™”í–ˆìŠµë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18547/cover.png"/></item><item><title>Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18609/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18609/</guid><description>Video-Panda: ì´ˆê²½ëŸ‰ ì¸ì½”ë” ì—†ëŠ” ë¹„ë””ì˜¤-ì–¸ì–´ ëª¨ë¸ë¡œ, ê³„ì‚° ë¹„ìš©ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì´ë©´ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18609/cover.png"/></item><item><title>B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</guid><description>B-STAR: ìê¸° í•™ìŠµ ì¶”ë¡ ìì—ì„œ íƒìƒ‰ê³¼ í™œìš©ì˜ ê· í˜•ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/cover.png"/></item><item><title>Deliberation in Latent Space via Differentiable Cache Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì¸ â€˜ì°¨ë³„ ê°€ëŠ¥í•œ ìºì‹œ ì¦ê°•â€™ ê¸°ë²• ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/cover.png"/></item><item><title>Diving into Self-Evolving Training for Multimodal Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</guid><description>M-STAR: ë‹¤ëª¨ë‹¬ ì¶”ë¡ ì„ ìœ„í•œ ìê¸° ì§„í™” í›ˆë ¨ì˜ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/cover.png"/></item><item><title>DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</guid><description>DRT-01 ëª¨ë¸ì€ ì¥ë¬¸ì˜ ì‚¬ê³  ê³¼ì •ì„ í™œìš©í•˜ì—¬ ë¬¸í•™ ë²ˆì—­ì˜ ì •í™•ë„ì™€ ìœ ì°½ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description></item><item><title>Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</guid><description>FoPE: ì£¼íŒŒìˆ˜ ì˜ì—­ íŠ¹ì§• ê°œì„ ìœ¼ë¡œ ê¸´ ë¬¸ë§¥ ê¸¸ì´ ì¼ë°˜í™” ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/cover.png"/></item><item><title>Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</guid><description>Friends-MMC: ë°©ëŒ€í•œ ë¹„ë””ì˜¤ ë°ì´í„°ì™€ ì£¼ì„ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ë‹¤ì¤‘ ëª¨ë‹¬ ë‹¤ì¤‘ ì°¸ì—¬ ëŒ€í™” ë°ì´í„°ì…‹ì„ í†µí•´ ì‹¤ì œ ì„¸ê³„ì˜ ëŒ€í™” ì´í•´ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/cover.png"/></item><item><title>In Case You Missed It: ARC 'Challenge' Is Not That Challenging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</guid><description>ê¸°ì¡´ ë‹¤ì¤‘ ì„ íƒ ë¬¸ì œ í‰ê°€ ë°©ì‹ì˜ ì˜¤ë¥˜ë¥¼ ì§€ì í•˜ê³ , ëª¨ë“  ì˜µì…˜ì„ í•¨ê»˜ ê³ ë ¤í•˜ëŠ” ìƒˆë¡œìš´ í‰ê°€ ë°©ì‹ì„ ì œì•ˆí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ì˜ ì •í™•ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/cover.png"/></item><item><title>Large Motion Video Autoencoding with Cross-modal Video VAE</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</guid><description>ê³ í’ˆì§ˆ ì˜ìƒ ìƒì„± ë° íš¨ìœ¨ì  ì••ì¶•ì„ ìœ„í•œ í˜ì‹ ì ì¸ í¬ë¡œìŠ¤ ëª¨ë‹¬ ë¹„ë””ì˜¤ VAE!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/cover.png"/></item><item><title>PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</guid><description>PC AgentëŠ” ì¸ê°„ì˜ ì¸ì§€ ê³¼ì •ì„ AI ì— ì „ì´í•˜ì—¬ ë³µì¡í•œ ë””ì§€í„¸ ì‘ì—…ì„ ìë™í™”í•˜ëŠ” í˜ì‹ ì ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/cover.png"/></item><item><title>ResearchTown: Simulator of Human Research Community</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</guid><description>RESEARCHTOWN: LLM ê¸°ë°˜ ì¸ê°„ ì—°êµ¬ ê³µë™ì²´ ì‹œë®¬ë ˆì´í„°ë¡œ, ë‹¤ì–‘í•œ ì—°êµ¬ í™œë™ì„ í˜„ì‹¤ì ìœ¼ë¡œ ëª¨ë°©í•˜ë©° í•™ì œ ê°„ ì—°êµ¬ ì•„ì´ë””ì–´ ìƒì„± ê°€ëŠ¥</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/cover.png"/></item><item><title>SBS Figures: Pre-training Figure QA from Stage-by-Stage Synthesized Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17606/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17606/</guid><description>SBS Figures: 100ë§Œ ê°œì˜ í•©ì„± ì´ë¯¸ì§€ì™€ QA ìŒìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ, íš¨ìœ¨ì ì¸ Figure QA ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17606/cover.png"/></item><item><title>VidTwin: Video VAE with Decoupled Structure and Dynamics</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17726/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17726/</guid><description>VidTwin: êµ¬ì¡°ì™€ ë™ì—­í•™ì„ ë¶„ë¦¬í•˜ì—¬ ë¹„ë””ì˜¤ ì••ì¶• ë° ìƒì„±ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì œì‹œí•˜ëŠ” í˜ì‹ ì ì¸ ë¹„ë””ì˜¤ ìë™ ì¸ì½”ë”!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17726/cover.png"/></item><item><title>WavePulse: Real-time Content Analytics of Radio Livestreams</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17998/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17998/</guid><description>WavePulse: ì‹¤ì‹œê°„ ë¼ë””ì˜¤ ë°©ì†¡ ì½˜í…ì¸  ë¶„ì„ í”„ë ˆì„ì›Œí¬ê°€ ì •ì¹˜ì  ë‹´ë¡ , ë¯¸ë””ì–´ ìœ í†µ, ì—¬ë¡  ë™í–¥ì„ ì‹¤ì‹œê°„ ë¶„ì„í•˜ì—¬ ì •ì¹˜ ê³¼í•™ ë° ë¯¸ë””ì–´ ì—°êµ¬ì— ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17998/cover.png"/></item><item><title>YuLan-Mini: An Open Data-efficient Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17743/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17743/</guid><description>YuLan-Mini: 24ì–µ ê°œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë°ì´í„° íš¨ìœ¨ì ì¸ ê°œë°©í˜• LLM</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17743/cover.png"/></item><item><title>Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</guid><description>ë‹¨ì¼ ë‹¨ê³„ ìƒ˜í”Œë§ìœ¼ë¡œ ì´ë¯¸ì§€ ìë™ íšŒê·€ ëª¨ë¸ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ ì¦ë¥˜ ë””ì½”ë”©(DD) ê¸°ë²• ì œì•ˆ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/cover.png"/></item><item><title>OpenRFT: Adapting Reasoning Foundation Model for Domain-specific Tasks with Reinforcement Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</guid><description>OpenRFTëŠ” ì œí•œëœ ë„ë©”ì¸ íŠ¹ì • ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë°˜ì ì¸ ì¶”ë¡  ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/cover.png"/></item><item><title>Revisiting In-Context Learning with Long Context Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</guid><description>ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì •êµí•œ ìƒ˜í”Œ ì„ íƒ ì „ëµë³´ë‹¤ &lt;strong>ë¬´ì‘ìœ„ ìƒ˜í”Œë§&lt;/strong>ì´ ICL ì„±ëŠ¥ í–¥ìƒì— ë” íš¨ê³¼ì ì´ë©°, &lt;strong>ë°ì´í„° ì¦ê°•&lt;/strong>ì„ í†µí•´ ì €ìì› ì‘ì—… ì„±ëŠ¥ì„ 5% í–¥ìƒì‹œì¼°ë‹¤ëŠ” ë†€ë¼ìš´ ì—°êµ¬ ê²°ê³¼ë¥¼ ë°œí‘œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/cover.png"/></item><item><title>LearnLM: Improving Gemini for Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</guid><description>LearnLMì€ êµìœ¡ì  ë§¥ë½ì—ì„œ ìƒì„±í˜• AIì˜ í˜ë‹¤ê³ ì§€(Pedagogy)ë¥¼ í–¥ìƒì‹œí‚¨ ëª¨ë¸ì…ë‹ˆë‹¤. &lt;strong>êµì‚¬ë‚˜ ê°œë°œìê°€ ì›í•˜ëŠ” í˜ë‹¤ê³ ì§€ì  íŠ¹ì„±ì„ ëª¨ë¸ì— ì£¼ì…í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬&lt;/strong>ë¥¼ í†µí•´ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ í•™ìŠµ íš¨ê³¼ë¥¼ 31% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/cover.png"/></item><item><title>NILE: Internal Consistency Alignment in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</guid><description>NILE í”„ë ˆì„ì›Œí¬ëŠ” LLMì˜ ë‚´ë¶€ ì§€ì‹ê³¼ IFT ë°ì´í„°ì…‹ì˜ ì„¸ê³„ ì§€ì‹ ê°„ ì¼ê´€ì„±ì„ ë†’ì—¬ LLM ì„±ëŠ¥ì„ ìµœëŒ€ 68.5%ê¹Œì§€ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/cover.png"/></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</guid><description>CLEAR: ì„ í˜•í™”ëœ ì–´í…ì…˜ìœ¼ë¡œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ ë†’ì´ë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/cover.png"/></item><item><title>Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ì•™ìƒë¸”ì„ í†µí•´ ë³µì¡í•œ ì¶”ë¡  ë¬¸ì œë¥¼ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬, LE-MCTSë¥¼ ì œì•ˆí•©ë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/cover.png"/></item><item><title>MotiF: Making Text Count in Image Animation with Motion Focal Loss</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</guid><description>MotiF: ì›€ì§ì„ì— ì´ˆì ì„ ë§ì¶˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ ê°œì„ </description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/cover.png"/></item><item><title>Multi-LLM Text Summarization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</guid><description>ë‹¤ìˆ˜ì˜ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ í˜ì‹ ì ì¸ ì¥ë¬¸ ìš”ì•½ í”„ë ˆì„ì›Œí¬ê°€ ì œì‹œë˜ì–´ ìš”ì•½ í’ˆì§ˆì„ ìµœëŒ€ 3ë°° í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/cover.png"/></item><item><title>Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</guid><description>ì´ˆì •ë°€ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì˜ í™˜ê° ë¬¸ì œ í•´ê²°ì„ ìœ„í•´, LLM-MLLM í˜‘ì—… ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(CapMAS)ì„ ì œì•ˆí•˜ì—¬ ì‚¬ì‹¤ì„±ê³¼ í¬ê´„ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/cover.png"/></item><item><title>AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</guid><description>AceMathëŠ” ì‚¬ì „ í›ˆë ¨ ë° ë³´ìƒ ëª¨ë¸ë§ì„ í†µí•´ ìµœì²¨ë‹¨ ìˆ˜í•™ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‹¬ì„±í•œ í”„ëŸ°í‹°ì–´ê¸‰ ëª¨ë¸ ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/cover.png"/></item><item><title>Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</guid><description>Affordance-Aware Object Insertion: ë°°ê²½ê³¼ ì „ê²½ì˜ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•œ í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ í•©ì„± ê¸°ìˆ !</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/cover.png"/></item><item><title>AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal Audio-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</guid><description>AV-Link: ì‹œê°„ ì •ë ¬ í™•ì‚° ê¸°ëŠ¥ì„ í†µí•œ í¬ë¡œìŠ¤ ëª¨ë‹¬ ì˜¤ë””ì˜¤-ë¹„ë””ì˜¤ ìƒì„±ì˜ íšê¸°ì ì¸ ë°œì „!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/cover.png"/></item><item><title>DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</guid><description>DI-PCGëŠ” ì´ë¯¸ì§€ ì¡°ê±´ìœ¼ë¡œë¶€í„° ê³ í’ˆì§ˆ 3D ìì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ê¸° ìœ„í•´ ê²½ëŸ‰í™”ëœ í™•ì‚° ë³€í™˜ê¸° ëª¨ë¸ì„ í™œìš©í•œ í˜ì‹ ì ì¸ ì—­ë°©í–¥ ì ˆì°¨ì  ì½˜í…ì¸  ìƒì„± ë°©ë²•ë¡ ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/cover.png"/></item><item><title>Fietje: An open, efficient LLM for Dutch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</guid><description>Fietje: ì˜¤í”ˆì†ŒìŠ¤ ì†Œí˜• ë„¤ëœë€ë“œì–´ LLM ê³µê°œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/cover.png"/></item><item><title>Flowing from Words to Pixels: A Framework for Cross-Modality Evolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</guid><description>CrossFlow: ëª¨ë‹¬ë¦¬í‹° ê°„ ì§ì ‘ì  ë³€í™˜ ê°€ëŠ¥í•œ í˜ì‹ ì  í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/cover.png"/></item><item><title>How to Synthesize Text Data without Model Collapse?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</guid><description>í•©ì„± ë°ì´í„° ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ í•™ìŠµì˜ ë¶•ê´´ ë¬¸ì œ í•´ê²°: í† í° í¸ì§‘ ê¸°ë²• ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/cover.png"/></item><item><title>IDOL: Instant Photorealistic 3D Human Creation from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</guid><description>ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì´ˆê³ ì†, ê³ í’ˆì§ˆ, ì• ë‹ˆë©”ì´ì…˜ ê°€ëŠ¥í•œ 3D ì•„ë°”íƒ€ë¥¼ ìƒì„±í•˜ëŠ” IDOL ëª¨ë¸ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/cover.png"/></item><item><title>LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</guid><description>LeviTor: ì‚¬ìš©ìì˜ ê°„í¸í•œ 3D ê¶¤ì  ì…ë ¥ë§Œìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ë¹„ë””ì˜¤ í•©ì„±ì´ ê°€ëŠ¥í•œ í˜ì‹ ì ì¸ ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/cover.png"/></item><item><title>LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</guid><description>M-ALERTëŠ” ë‹¤êµ­ì–´ LLMì˜ ì•ˆì „ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ì˜ì–´, í”„ë‘ìŠ¤ì–´, ë…ì¼ì–´, ì´íƒˆë¦¬ì•„ì–´, ìŠ¤í˜ì¸ì–´ 5ê°œ ì–¸ì–´ì˜ 75,000ê°œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•˜ë©°, ë‹¤ì–‘í•œ ì–¸ì–´ ë° ë²”ì£¼ì—ì„œ LLMì˜ ì•ˆì „ì„± ë¶ˆì¼ì¹˜ë¥¼ ë°í˜€ëƒˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/cover.png"/></item><item><title>MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</guid><description>MegaPairsëŠ” VLMê³¼ ê³µê°œ ë„ë©”ì¸ ì´ë¯¸ì§€ë¥¼ í™œìš©, 2600ë§Œ ê°œ ì´ìƒì˜ ê³ í’ˆì§ˆ ë‹¤ì¤‘ ëª¨ë‹¬ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ë²”ìš© ë‹¤ì¤‘ ëª¨ë‹¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/cover.png"/></item><item><title>MixLLM: LLM Quantization with Global Mixed-precision between Output-features and Highly-efficient System Design</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</guid><description>MixLLM: ì¶œë ¥ íŠ¹ì§• ê°„ì˜ ì „ì—­ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”ì™€ ê³ íš¨ìœ¨ ì‹œìŠ¤í…œ ì„¤ê³„ë¥¼ í†µí•´ LLMì˜ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚¤ëŠ” íšê¸°ì ì¸ ì–‘ìí™” ë°©ë²•</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/cover.png"/></item><item><title>Outcome-Refining Process Supervision for Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</guid><description>ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ì´ í•„ìš”í•œ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ê¸°ì¡´ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ , Outcome-Refining Process Supervision (ORPS) ì œì‹œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/cover.png"/></item><item><title>Parallelized Autoregressive Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</guid><description>ë³¸ ì—°êµ¬ëŠ” í† í° ì˜ì¡´ì„±ì„ ê³ ë ¤í•œ ë³‘ë ¬í™” ì „ëµì„ í†µí•´ ìë™ íšŒê·€ ì‹œê°ì  ìƒì„±ì˜ ì†ë„ë¥¼ ìµœëŒ€ 9.5ë°°ê¹Œì§€ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/cover.png"/></item><item><title>Progressive Multimodal Reasoning via Active Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</guid><description>AR-MCTS: ëŠ¥ë™ì  ê²€ìƒ‰ê³¼ ëª¬í…Œ ì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰ìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  í–¥ìƒ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/cover.png"/></item><item><title>ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</guid><description>ReLU ë¼ìš°íŒ…ì„ ì‚¬ìš©í•˜ëŠ” ì™„ì „ ë¯¸ë¶„ ê°€ëŠ¥í•œ MoE ì•„í‚¤í…ì²˜ ReMoEë¥¼ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì„ íšê¸°ì ìœ¼ë¡œ ê°œì„ í–ˆìŠµë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/cover.png"/></item><item><title>RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</guid><description>ROBUSTFTëŠ” ì¡ìŒì´ í¬í•¨ëœ ì‘ë‹µ ì•„ë˜ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê°•ê±´í•œ ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ì¡ìŒ ê°ì§€ ë° ì¬ë¼ë²¨ë§ì„ í†µí•´ í•˜ë¥˜ ì‘ì—… ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/cover.png"/></item><item><title>Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</guid><description>ê³ í’ˆì§ˆ ë¹„ë””ì˜¤-ì˜¤ë””ì˜¤ í•©ì„±ì„ ìœ„í•œ í˜ì‹ ì ì¸ ë‹¤ì¤‘ ëª¨ë“œ ì¡°ì¸íŠ¸ í•™ìŠµ í”„ë ˆì„ì›Œí¬ MMAudio ì œì•ˆ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/cover.png"/></item><item><title>TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</guid><description>TOMG-Bench: LLM ê¸°ë°˜ ì˜¤í”ˆ ë¶„ì ìƒì„± ë²¤ì¹˜ë§ˆí¬ ì œì‹œ! 25ê°œ LLM í‰ê°€ ë° ìƒˆë¡œìš´ instruction tuning ë°ì´í„°ì…‹ OpenMolIns ê³µê°œë¡œ, ì˜¤í”ˆì†ŒìŠ¤ LLMì˜ ì„±ëŠ¥ í–¥ìƒ ë° ë¶„ì ë°œê²¬ì˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„± ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/cover.png"/></item><item><title>UIP2P: Unsupervised Instruction-based Image Editing via Cycle Edit Consistency</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</guid><description>ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ ìˆœí™˜ í¸ì§‘ ì¼ê´€ì„±(CEC) í™œìš©, ì§€ì‹œì–´ ê¸°ë°˜ ì´ë¯¸ì§€ í¸ì§‘ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/cover.png"/></item><item><title>AniDoc: Animation Creation Made Easier</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</guid><description>AniDoc: í¬ì†Œ ìŠ¤ì¼€ì¹˜ì™€ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í™œìš©, 2D ì• ë‹ˆë©”ì´ì…˜ ìë™ ì±„ìƒ‰ ë° ë³´ê°„ì„ êµ¬í˜„í•˜ëŠ” í˜ì‹ ì  AI ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/cover.png"/></item><item><title>AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</guid><description>AntiLeak-Bench: ìë™í™”ëœ ë²¤ì¹˜ë§ˆí‚¹ìœ¼ë¡œ LLM ë°ì´í„° ì˜¤ì—¼ ë°©ì§€</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/cover.png"/></item><item><title>Autoregressive Video Generation without Vector Quantization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</guid><description>ë²¡í„° ì–‘ìí™” ì—†ì´ë„ íš¨ìœ¨ì ì´ê³  ìœ ì—°í•œ ìê¸°íšŒê·€ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸, NOVA ê°œë°œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/cover.png"/></item><item><title>Descriptive Caption Enhancement with Visual Specialists for Multimodal Perception</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</guid><description>ì‹œê° ì „ë¬¸ê°€ ëª¨ë¸ì„ í™œìš©í•œ ì´ë¯¸ì§€ ìº¡ì…˜ í–¥ìƒìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ </description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/cover.png"/></item><item><title>FashionComposer: Compositional Fashion Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</guid><description>FashionComposer: ë‹¤ì–‘í•œ ì…ë ¥(í…ìŠ¤íŠ¸, ì˜ìƒ ì´ë¯¸ì§€, 3D ëª¨ë¸)ì„ í™œìš©í•´ ì‚¬ì‹¤ì ì¸ íŒ¨ì…˜ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” í˜ì‹ ì ì¸ í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/cover.png"/></item><item><title>GUI Agents: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ GUI ì—ì´ì „íŠ¸ ê¸°ìˆ ì˜ ìµœì‹  ë™í–¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ë²¤ì¹˜ë§ˆí¬, í‰ê°€ ì§€í‘œ, ì•„í‚¤í…ì²˜, í•™ìŠµ ë°©ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.</description></item><item><title>LLaVA-UHD v2: an MLLM Integrating High-Resolution Feature Pyramid via Hierarchical Window Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</guid><description>LLaVA-UHD v2ëŠ” ê³„ì¸µì  ìœˆë„ìš° ë³€í™˜ê¸°ë¥¼ ì´ìš©, ê³ í•´ìƒë„ íŠ¹ì§• í”¼ë¼ë¯¸ë“œë¥¼ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œê°ì  ì„¸ë¶€ ì •ë³´ë¥¼ í¬ì°©í•˜ëŠ” í˜ì‹ ì ì¸ ë‹¤ì¤‘ ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/cover.png"/></item><item><title>PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</guid><description>PixelManì€ í”½ì…€ ì¡°ì‘ ë° ìƒì„±ì„ í†µí•´ í›ˆë ¨ ì—†ì´ë„ ì¼ê´€ì„± ìˆëŠ” ê°ì²´ í¸ì§‘ì„ 16ë‹¨ê³„ ë§Œì— ë‹¬ì„±í•˜ëŠ” í˜ì‹ ì ì¸ í™•ì‚° ëª¨ë¸ ê¸°ë°˜ ë°©ë²•ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/cover.png"/></item><item><title>Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</guid><description>ì €ë ´í•œ ë¼ì´ë‹¤ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•œ 4K ê³ í•´ìƒë„ ì •í™•í•œ ê³„ëŸ‰ì  ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„, Prompt Depth Anything ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/cover.png"/></item><item><title>RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</guid><description>RAG-RewardBench: RAG í™˜ê²½ì—ì„œ ë³´ìƒ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ ìµœì´ˆì˜ ë²¤ì¹˜ë§ˆí¬ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/cover.png"/></item><item><title>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</guid><description>ModernBERT: ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë¯¸ì„¸ ì¡°ì • ë° ì¶”ë¡ ì„ ìœ„í•œ ìµœì²¨ë‹¨ ì–‘ë°©í–¥ ì¸ì½”ë”!</description></item><item><title>TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</guid><description>TheAgentCompany ë²¤ì¹˜ë§ˆí¬ëŠ” ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ í™˜ê²½ì„ ëª¨ë°©í•˜ì—¬ LLM ì—ì´ì „íŠ¸ì˜ ì‹¤ì œ ì—…ë¬´ ìˆ˜í–‰ ëŠ¥ë ¥ì„ í‰ê°€í•˜ë©°, AI ì—ì´ì „íŠ¸ì˜ í˜„ì‹¤ ì„¸ê³„ ì ìš© ê°€ëŠ¥ì„±ê³¼ í•œê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/cover.png"/></item><item><title>Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</guid><description>MLLMì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ëŠ” ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ VSI-Bench ë°œí‘œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/cover.png"/></item><item><title>ChatDiT: A Training-Free Baseline for Task-Agnostic Free-Form Chatting with Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</guid><description>ChatDiT: ì œë¡œìƒ· ë°©ì‹ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ëœ í™•ì‚° ë³€í™˜ê¸°ë¥¼ í™œìš©, ìì—°ì–´ë¡œ ë‹¤ì–‘í•œ ì‹œê°ì  ê³¼ì œ í•´ê²°!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/cover.png"/></item><item><title>DateLogicQA: Benchmarking Temporal Biases in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</guid><description>DateLogicQA: LLMì˜ ì‹œê°„ì  ì¶”ë¡  í¸í–¥ ë²¤ì¹˜ë§ˆí¬ ì œì‹œ! í† í°í™”, í‘œìƒ ë° ë…¼ë¦¬ ìˆ˜ì¤€ í¸í–¥ ë¶„ì„ìœ¼ë¡œ ì‹œê°„ì  ë°ì´í„° ì²˜ë¦¬ ê°œì„  ë°©ì•ˆ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/cover.png"/></item><item><title>Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</guid><description>MoDE: íš¨ìœ¨ì ì¸ ë‹¤ì¤‘ ì‘ì—… í•™ìŠµì„ ìœ„í•œ ì „ë¬¸ê°€ í˜¼í•© ì¡ìŒ ì œê±°ê¸°ë¥¼ ì‚¬ìš©í•œ í™•ì‚° íŠ¸ëœìŠ¤í¬ë¨¸ ì •ì±…</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/cover.png"/></item><item><title>Move-in-2D: 2D-Conditioned Human Motion Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</guid><description>Move-in-2D: 2D ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ í˜„ì‹¤ì ì¸ ì¸ê°„ ë™ì‘ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/cover.png"/></item><item><title>VidTok: A Versatile and Open-Source Video Tokenizer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</guid><description>VidTok: ì˜¤í”ˆì†ŒìŠ¤ ê³ ì„±ëŠ¥ ë¹„ë””ì˜¤ í† í¬ë‚˜ì´ì €ê°€ ì—°ì† ë° ì´ì‚° í† í°í™”ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, íš¨ìœ¨ì ì¸ í•™ìŠµ ì „ëµê³¼ í˜ì‹ ì ì¸ ì–‘ìí™” ê¸°ë²•ì„ í†µí•´ ì˜ìƒ ìƒì„± ë° ì´í•´ ì—°êµ¬ì— ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/cover.png"/></item><item><title>Causal Diffusion Transformers for Generative Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</guid><description>CausalFusionì€ í™•ì‚° ë° ìê¸° íšŒê·€ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ìƒì„± ëª¨ë¸ë§ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ê³  ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/cover.png"/></item><item><title>ColorFlow: Retrieval-Augmented Image Sequence Colorization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</guid><description>ë§Œí™” ì±„ìƒ‰ ìë™í™”: ColorFlowëŠ” ID ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œ í‘ë°± ë§Œí™” ì‹œí€€ìŠ¤ë¥¼ ì±„ìƒ‰í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/cover.png"/></item><item><title>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</guid><description>GeoX: MLLMë³´ë‹¤ ë›°ì–´ë‚œ ê¸°í•˜í•™ì  ë¬¸ì œ í•´ê²°ì‚¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/cover.png"/></item><item><title>IDArb: Intrinsic Decomposition for Arbitrary Number of Input Views and Illuminations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</guid><description>IDArb: Decomposition under varied lights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/cover.png"/></item><item><title>Just a Simple Transformation is Enough for Data Protection in Vertical Federated Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</guid><description>ê°„ë‹¨í•œ ë³€í™˜ë§Œìœ¼ë¡œ ìˆ˜ì§ ì—°í•© í•™ìŠµì—ì„œ ë°ì´í„° ë³´í˜¸ ê°€ëŠ¥.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/cover.png"/></item><item><title>MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</guid><description>ì •ë³´ ì´ë“ìœ¼ë¡œ ê°•í™” í•™ìŠµ íƒìƒ‰ì„ ê°•í™”.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/cover.png"/></item><item><title>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</guid><description>MOVISëŠ” ì‹¤ë‚´ ì¥ë©´ì— ëŒ€í•œ ë©€í‹°-ê°ì²´ novel view synthesisì—ì„œ êµ¬ì¡°ì  ì¸ì‹ì„ í–¥ìƒì‹œì¼œ ì¼ê´€ì„± ìˆê³  ì‚¬ì‹¤ì ì¸ novel viewë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/cover.png"/></item><item><title>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</guid><description>ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ë³´í˜¸, ë”¥í˜ì´í¬ ëŒ€ë¹„ì±….</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/cover.png"/></item><item><title>RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</guid><description>RetroLLM: ê²€ìƒ‰ê³¼ ìƒì„±ì„ í†µí•©í•œ RAG ì‹œìŠ¤í…œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/cover.png"/></item><item><title>SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</guid><description>SepLLMì€ íŠ¹ìˆ˜ í† í°ì˜ ì¤‘ìš”ì„±ì„ í™œìš©í•˜ì—¬ LLM ì¶”ë¡ ì„ ê°€ì†í™”í•˜ê³  ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/cover.png"/></item><item><title>Sequence Matters: Harnessing Video Models in 3D Super-Resolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</guid><description>ë¹„ë””ì˜¤ ì´ˆí•´ìƒë„ ëª¨ë¸ì„ ì´ìš©í•œ í˜ì‹ ì ì¸ 3D ì´ˆí•´ìƒë„ ê¸°ë²•ìœ¼ë¡œ, ì •ë ¬ ê³¼ì • ì—†ì´ë„ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/cover.png"/></item><item><title>SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</guid><description>Self-play with refinement boosts instruction-following in LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/cover.png"/></item><item><title>StrandHead: Text to Strand-Disentangled 3D Head Avatars Using Hair Geometric Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</guid><description>&amp;rsquo;&amp;rsquo; StrandHead: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ 3D í—¤ë“œ ì•„ë°”íƒ€ì™€ ì„¬ì„¸í•œ í—¤ì–´ìŠ¤íƒ€ì¼ê¹Œì§€ ìƒì„±.''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/cover.png"/></item><item><title>The Open Source Advantage in Large Language Models (LLMs)</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</guid><description>ì˜¤í”ˆì†ŒìŠ¤ LLM, íì‡„í˜• LLM ëŒ€ë¹„ íˆ¬ëª…ì„±ê³¼ ì ‘ê·¼ì„±ì€ ë†’ì§€ë§Œ, ì„±ëŠ¥ì€ ë‚®ìŒ. í•˜ì´ë¸Œë¦¬ë“œ ì „ëµì´ ë¯¸ë˜.</description></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT: í•˜ì´ë¸Œë¦¬ë“œ ìŒì„± ë° ìŒì•… LLMìœ¼ë¡œ, ì—°ì† ì˜¤ë””ì˜¤ì™€ ì´ì‚° í† í°ì„ ê²°í•©í•˜ì—¬ í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item><item><title>Wonderland: Navigating 3D Scenes from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</guid><description>ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ ê³ í’ˆì§ˆ 3D ì¥ë©´ì„ ìƒì„±í•˜ëŠ” íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/cover.png"/></item><item><title>DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</guid><description>DynamicScalerëŠ” í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ì—ì„œ ê¸´ &lt;strong>ëŠê¹€ ì—†ëŠ” íŒŒë…¸ë¼ë§ˆ ë¹„ë””ì˜¤&lt;/strong>ë¥¼ ìƒì„±í•˜ë©°, &lt;strong>í•´ìƒë„ì™€ ì¢…íš¡ë¹„ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ì›€ì§ì„ì„ ìœ ì§€&lt;/strong>í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/cover.png"/></item><item><title>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</guid><description>GaussianPropertyëŠ” LMMì„ ì‚¬ìš©í•˜ì—¬ 3D ê°€ìš°ì‹œì•ˆì— ë¬¼ë¦¬ì  ì†ì„±ì„ í†µí•©í•˜ëŠ” í›ˆë ¨ ì—†ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ, ë¬¼ë¦¬ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ë° ë¡œë´‡ ì¥ê¸°ì™€ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"/></item><item><title>Reliable, Reproducible, and Really Fast Leaderboards with Evalica</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</guid><description>Evalica: ë²¤ì¹˜ë§ˆí‚¹ì„ ì‰½ê³  ë¹ ë¥´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” íˆ´í‚·</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/cover.png"/></item><item><title>Smaller Language Models Are Better Instruction Evolvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</guid><description>ì†Œí˜• ì–¸ì–´ ëª¨ë¸ì´ ë” ë‚˜ì€ ëª…ë ¹ ìƒì„±ì!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/cover.png"/></item><item><title>VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</guid><description>VividFace: ì²« ë²ˆì§¸ í™•ì‚° ê¸°ë°˜ ë¹„ë””ì˜¤ ì–¼êµ´ ë°”ê¾¸ê¸° í”„ë ˆì„ì›Œí¬ë¡œ ê³ ì¶©ì‹¤ë„ ê²°ê³¼ ì œê³µ.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/cover.png"/></item><item><title>Apollo: An Exploration of Video Understanding in Large Multimodal Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</guid><description>Apollo: ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ë¹„ë””ì˜¤ ì´í•´ë¥¼ ìœ„í•œ ì‹¬ì¸µ íƒêµ¬.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/cover.png"/></item><item><title>BrushEdit: All-In-One Image Inpainting and Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</guid><description>BrushEdit: All-in-One Image Inpainting &amp;amp; Editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/cover.png"/></item><item><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</guid><description>BLT: ë°”ì´íŠ¸ ê¸°ë°˜ LLM, í† í°ë³´ë‹¤ íŒ¨ì¹˜ ìš°ì„ .</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/cover.png"/></item><item><title>Efficient Generative Modeling with Residual Vector Quantization-Based Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</guid><description>ResGen, ê³ í’ˆì§ˆ ìƒì„±ê³¼ ë¹ ë¥¸ ìƒ˜í”Œë§ ì†ë„ë¥¼ ëª¨ë‘ ë‹¬ì„±í•˜ëŠ” íš¨ìœ¨ì ì¸ RVQ ê¸°ë°˜ ìƒì„± ëª¨ë¸.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/cover.png"/></item><item><title>Large Action Models: From Inception to Implementation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</guid><description>LLMì—ì„œ LAMìœ¼ë¡œ: ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” AI ì—ì´ì „íŠ¸ êµ¬ì¶•.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/cover.png"/></item><item><title>LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</guid><description>LinGen: ë¶„ ë‹¨ìœ„ ê³ í•´ìƒë„ í…ìŠ¤íŠ¸-íˆ¬-ë¹„ë””ì˜¤ ìƒì„±, ì„ í˜• ê³„ì‚° ë³µì¡ë„ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/cover.png"/></item><item><title>Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attacks on Breast Ultrasound Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</guid><description>P2P: í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ ìƒˆë¡œìš´ ì ëŒ€ì  ê³µê²©ìœ¼ë¡œ ì˜ë£Œ ì˜ìƒ DNNì˜ ì·¨ì•½ì„± ê³µëµ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/cover.png"/></item><item><title>RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</guid><description>RLDGëŠ” ê°•í™” í•™ìŠµì„ í†µí•´ ìƒì„±ëœ ê³ í’ˆì§ˆ ë°ì´í„°ë¡œ ë²”ìš© ë¡œë´‡ ì •ì±…ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” íšê¸°ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/cover.png"/></item><item><title>SCBench: A KV Cache-Centric Analysis of Long-Context Methods</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</guid><description>SCBenchëŠ” ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/cover.png"/></item><item><title>SplineGS: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</guid><description>SplineGS: ì‹¤ì‹œê°„ ë™ì  3D ì¥ë©´ì„ ìœ„í•œ ê°•ë ¥í•œ ëª¨ì…˜ ì ì‘í˜• ìŠ¤í”Œë¼ì¸.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/cover.png"/></item><item><title>TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</guid><description>TraceVLA: ê³¼ê±°ì˜ ì›€ì§ì„ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ ë¡œë´‡ì˜ ì‹œê³µê°„ì  ì¸ì‹ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/cover.png"/></item><item><title>FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</guid><description>''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/cover.png"/></item><item><title>FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</guid><description>FreeScaleë¡œ íŠœë‹ ì—†ì´ 8K ì´ë¯¸ì§€ ìƒì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/cover.png"/></item><item><title>GenEx: Generating an Explorable World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</guid><description>GenEx: ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ íƒìƒ‰ ê°€ëŠ¥í•œ 3D ì„¸ê³„ ìƒì„±.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/cover.png"/></item><item><title>GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</guid><description>GREATERëŠ” ì¶”ë¡ ì— ëŒ€í•œ ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì†Œê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•˜ì—¬ ëŒ€ê·œëª¨ LLM ì—†ì´ë„ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/cover.png"/></item><item><title>InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</guid><description>InstanceCap: ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜ì„ í†µí•´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/cover.png"/></item><item><title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</guid><description>InternLM-XComposer2.5-OmniLive: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ ë° ì˜¤ë””ì˜¤ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì¸ê°„ì˜ ì¸ì§€ëŠ¥ë ¥ì„ ëª¨ë°©í•œ í˜ì‹ ì  ë‹¤ì¤‘ ëª¨ë“œ AI ì‹œìŠ¤í…œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/cover.png"/></item><item><title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</guid><description>VMBëŠ” í…ìŠ¤íŠ¸ ë° ìŒì•… ë¸Œë¦¬ì§€ë¥¼ í™œìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ìŒì•… ìƒì„±ì„ ìœ„í•œ ìƒˆë¡­ê³  ì œì–´ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/cover.png"/></item><item><title>Phi-4 Technical Report</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</guid><description>Phi-4: 140ì–µ ë§¤ê°œë³€ìˆ˜ ì–¸ì–´ ëª¨ë¸ì€ &lt;strong>ë°ì´í„° í’ˆì§ˆì— ì¤‘ì ì„ ë‘” í›ˆë ¨ ë ˆì‹œí”¼&lt;/strong>ë¡œ ê°œë°œë˜ì–´ ì¶”ë¡  ëŠ¥ë ¥ì„ ëŒ€í­ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/cover.png"/></item><item><title>SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</guid><description>SynerGen-VL: ê°„ë‹¨í•œ êµ¬ì¡°ë¡œ ì´ë¯¸ì§€ ì´í•´ ë° ìƒì„±ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” ê°•ë ¥í•œ MLLM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/cover.png"/></item><item><title>ObjectMate: A Recurrence Prior for Object Insertion and Subject-Driven Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</guid><description>ê°ì²´ í•©ì„±ì˜ ìƒˆ ì‹œëŒ€: ObjectMateë¡œ íŠœë‹ ì—†ì´ ì‚¬ì‹¤ì ì¸ ê²°ê³¼ë¥¼ ì–»ìœ¼ì„¸ìš”.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/cover.png"/></item><item><title>SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</guid><description>Smaller language models reason better with fine-tuned training recipes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/cover.png"/></item><item><title>TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</guid><description>TidyBot++: ì €ë¹„ìš©, í™€ë¡œë…¸ë¯¹ ì´ë™ ì¡°ì‘ê¸° &amp;amp; í•¸ë“œí° í…”ë ˆì˜¤í¼ë ˆì´ì…˜ ì¸í„°í˜ì´ìŠ¤ ê³µê°œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/cover.png"/></item><item><title>BiMediX2: Bio-Medical EXpert LMM for Diverse Medical Modalities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</guid><description>BiMediX2: ì•„ëì–´-ì˜ì–´ ì´ì¤‘ ì–¸ì–´ ì˜ë£Œ ì „ë¬¸ê°€ LMM ì¶œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/cover.png"/></item><item><title>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</guid><description>Evaluation Agent: ë” ë¹ ë¥´ê³ , ìœ ì—°í•˜ë©°, ì„¤ëª… ê°€ëŠ¥í•œ ì‹œê°ì  ìƒì„± ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/cover.png"/></item><item><title>NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</guid><description>NeuZip dynamically compresses neural network weights, achieving memory-efficient training and inference without performance loss, significantly reducing the memory footprint of large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/cover.png"/></item></channel></rss>