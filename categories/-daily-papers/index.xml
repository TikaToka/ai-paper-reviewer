<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ğŸ¤— Daily Papers on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/</link><description>Recent content in ğŸ¤— Daily Papers on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Tue, 24 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/index.xml" rel="self" type="application/rss+xml"/><item><title>3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</guid><description>3DGraphLLM: ì˜ë¯¸ë¡ ì  ê·¸ë˜í”„ì™€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ 3D ì¥ë©´ ì´í•´ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ ìµœì²¨ë‹¨ ì—°êµ¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/cover.png"/></item><item><title>DepthLab: From Partial to Complete</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</guid><description>DepthLab: ë¶€ë¶„ ê¹Šì´ ì •ë³´ë¡œ ì™„ì „í•œ 3D ì‹œê° ì •ë³´ ë³µì›</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/cover.png"/></item><item><title>DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</guid><description>DiTCtrl: íŠœë‹ ì—†ì´ ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ë¡œ ë§¤ë„ëŸ¬ìš´ ì¥ì‹œê°„ ë¹„ë””ì˜¤ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/cover.png"/></item><item><title>PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</guid><description>PartGen: ë‹¤ì¤‘ ë·° í™•ì‚° ëª¨ë¸ì„ ì´ìš©, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ê¸°ì¡´ 3D ê°ì²´ë¡œë¶€í„° ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœ ê³ í’ˆì§ˆ 3D ê°ì²´ ìƒì„± ë° ì¬êµ¬ì„±.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/cover.png"/></item><item><title>B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</guid><description>B-STAR: ìê¸° í•™ìŠµ ì¶”ë¡ ìì—ì„œ íƒìƒ‰ê³¼ í™œìš©ì˜ ê· í˜•ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/cover.png"/></item><item><title>Deliberation in Latent Space via Differentiable Cache Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì¸ â€˜ì°¨ë³„ ê°€ëŠ¥í•œ ìºì‹œ ì¦ê°•â€™ ê¸°ë²• ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/cover.png"/></item><item><title>Diving into Self-Evolving Training for Multimodal Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</guid><description>M-STAR: ë‹¤ëª¨ë‹¬ ì¶”ë¡ ì„ ìœ„í•œ ìê¸° ì§„í™” í›ˆë ¨ì˜ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/cover.png"/></item><item><title>DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</guid><description>DRT-01 ëª¨ë¸ì€ ì¥ë¬¸ì˜ ì‚¬ê³  ê³¼ì •ì„ í™œìš©í•˜ì—¬ ë¬¸í•™ ë²ˆì—­ì˜ ì •í™•ë„ì™€ ìœ ì°½ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description></item><item><title>Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</guid><description>FoPE: ì£¼íŒŒìˆ˜ ì˜ì—­ íŠ¹ì§• ê°œì„ ìœ¼ë¡œ ê¸´ ë¬¸ë§¥ ê¸¸ì´ ì¼ë°˜í™” ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/cover.png"/></item><item><title>Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</guid><description>Friends-MMC: ë°©ëŒ€í•œ ë¹„ë””ì˜¤ ë°ì´í„°ì™€ ì£¼ì„ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ë‹¤ì¤‘ ëª¨ë‹¬ ë‹¤ì¤‘ ì°¸ì—¬ ëŒ€í™” ë°ì´í„°ì…‹ì„ í†µí•´ ì‹¤ì œ ì„¸ê³„ì˜ ëŒ€í™” ì´í•´ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/cover.png"/></item><item><title>In Case You Missed It: ARC 'Challenge' Is Not That Challenging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</guid><description>ê¸°ì¡´ ë‹¤ì¤‘ ì„ íƒ ë¬¸ì œ í‰ê°€ ë°©ì‹ì˜ ì˜¤ë¥˜ë¥¼ ì§€ì í•˜ê³ , ëª¨ë“  ì˜µì…˜ì„ í•¨ê»˜ ê³ ë ¤í•˜ëŠ” ìƒˆë¡œìš´ í‰ê°€ ë°©ì‹ì„ ì œì•ˆí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ì˜ ì •í™•ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/cover.png"/></item><item><title>Large Motion Video Autoencoding with Cross-modal Video VAE</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</guid><description>ê³ í’ˆì§ˆ ì˜ìƒ ìƒì„± ë° íš¨ìœ¨ì  ì••ì¶•ì„ ìœ„í•œ í˜ì‹ ì ì¸ í¬ë¡œìŠ¤ ëª¨ë‹¬ ë¹„ë””ì˜¤ VAE!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/cover.png"/></item><item><title>PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</guid><description>PC AgentëŠ” ì¸ê°„ì˜ ì¸ì§€ ê³¼ì •ì„ AI ì— ì „ì´í•˜ì—¬ ë³µì¡í•œ ë””ì§€í„¸ ì‘ì—…ì„ ìë™í™”í•˜ëŠ” í˜ì‹ ì ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/cover.png"/></item><item><title>ResearchTown: Simulator of Human Research Community</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</guid><description>RESEARCHTOWN: LLM ê¸°ë°˜ ì¸ê°„ ì—°êµ¬ ê³µë™ì²´ ì‹œë®¬ë ˆì´í„°ë¡œ, ë‹¤ì–‘í•œ ì—°êµ¬ í™œë™ì„ í˜„ì‹¤ì ìœ¼ë¡œ ëª¨ë°©í•˜ë©° í•™ì œ ê°„ ì—°êµ¬ ì•„ì´ë””ì–´ ìƒì„± ê°€ëŠ¥</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/cover.png"/></item><item><title>Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</guid><description>ë‹¨ì¼ ë‹¨ê³„ ìƒ˜í”Œë§ìœ¼ë¡œ ì´ë¯¸ì§€ ìë™ íšŒê·€ ëª¨ë¸ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¨ ì¦ë¥˜ ë””ì½”ë”©(DD) ê¸°ë²• ì œì•ˆ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/cover.png"/></item><item><title>OpenRFT: Adapting Reasoning Foundation Model for Domain-specific Tasks with Reinforcement Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</guid><description>OpenRFTëŠ” ì œí•œëœ ë„ë©”ì¸ íŠ¹ì • ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë°˜ì ì¸ ì¶”ë¡  ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/cover.png"/></item><item><title>Revisiting In-Context Learning with Long Context Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</guid><description>ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì •êµí•œ ìƒ˜í”Œ ì„ íƒ ì „ëµë³´ë‹¤ &lt;strong>ë¬´ì‘ìœ„ ìƒ˜í”Œë§&lt;/strong>ì´ ICL ì„±ëŠ¥ í–¥ìƒì— ë” íš¨ê³¼ì ì´ë©°, &lt;strong>ë°ì´í„° ì¦ê°•&lt;/strong>ì„ í†µí•´ ì €ìì› ì‘ì—… ì„±ëŠ¥ì„ 5% í–¥ìƒì‹œì¼°ë‹¤ëŠ” ë†€ë¼ìš´ ì—°êµ¬ ê²°ê³¼ë¥¼ ë°œí‘œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/cover.png"/></item><item><title>LearnLM: Improving Gemini for Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</guid><description>LearnLMì€ êµìœ¡ì  ë§¥ë½ì—ì„œ ìƒì„±í˜• AIì˜ í˜ë‹¤ê³ ì§€(Pedagogy)ë¥¼ í–¥ìƒì‹œí‚¨ ëª¨ë¸ì…ë‹ˆë‹¤. &lt;strong>êµì‚¬ë‚˜ ê°œë°œìê°€ ì›í•˜ëŠ” í˜ë‹¤ê³ ì§€ì  íŠ¹ì„±ì„ ëª¨ë¸ì— ì£¼ì…í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬&lt;/strong>ë¥¼ í†µí•´ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ í•™ìŠµ íš¨ê³¼ë¥¼ 31% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/cover.png"/></item><item><title>NILE: Internal Consistency Alignment in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</guid><description>NILE í”„ë ˆì„ì›Œí¬ëŠ” LLMì˜ ë‚´ë¶€ ì§€ì‹ê³¼ IFT ë°ì´í„°ì…‹ì˜ ì„¸ê³„ ì§€ì‹ ê°„ ì¼ê´€ì„±ì„ ë†’ì—¬ LLM ì„±ëŠ¥ì„ ìµœëŒ€ 68.5%ê¹Œì§€ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/cover.png"/></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</guid><description>CLEAR: ì„ í˜•í™”ëœ ì–´í…ì…˜ìœ¼ë¡œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ ë†’ì´ë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/cover.png"/></item><item><title>Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ì•™ìƒë¸”ì„ í†µí•´ ë³µì¡í•œ ì¶”ë¡  ë¬¸ì œë¥¼ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬, LE-MCTSë¥¼ ì œì•ˆí•©ë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/cover.png"/></item><item><title>MotiF: Making Text Count in Image Animation with Motion Focal Loss</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</guid><description>MotiF: ì›€ì§ì„ì— ì´ˆì ì„ ë§ì¶˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ ê°œì„ </description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/cover.png"/></item><item><title>Multi-LLM Text Summarization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</guid><description>ë‹¤ìˆ˜ì˜ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ í˜ì‹ ì ì¸ ì¥ë¬¸ ìš”ì•½ í”„ë ˆì„ì›Œí¬ê°€ ì œì‹œë˜ì–´ ìš”ì•½ í’ˆì§ˆì„ ìµœëŒ€ 3ë°° í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/cover.png"/></item><item><title>Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</guid><description>ì´ˆì •ë°€ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì˜ í™˜ê° ë¬¸ì œ í•´ê²°ì„ ìœ„í•´, LLM-MLLM í˜‘ì—… ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ(CapMAS)ì„ ì œì•ˆí•˜ì—¬ ì‚¬ì‹¤ì„±ê³¼ í¬ê´„ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/cover.png"/></item><item><title>AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</guid><description>AceMathëŠ” ì‚¬ì „ í›ˆë ¨ ë° ë³´ìƒ ëª¨ë¸ë§ì„ í†µí•´ ìµœì²¨ë‹¨ ìˆ˜í•™ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‹¬ì„±í•œ í”„ëŸ°í‹°ì–´ê¸‰ ëª¨ë¸ ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/cover.png"/></item><item><title>Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</guid><description>Affordance-Aware Object Insertion: ë°°ê²½ê³¼ ì „ê²½ì˜ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•œ í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ í•©ì„± ê¸°ìˆ !</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/cover.png"/></item><item><title>AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal Audio-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</guid><description>AV-Link: ì‹œê°„ ì •ë ¬ í™•ì‚° ê¸°ëŠ¥ì„ í†µí•œ í¬ë¡œìŠ¤ ëª¨ë‹¬ ì˜¤ë””ì˜¤-ë¹„ë””ì˜¤ ìƒì„±ì˜ íšê¸°ì ì¸ ë°œì „!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/cover.png"/></item><item><title>DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</guid><description>DI-PCGëŠ” ì´ë¯¸ì§€ ì¡°ê±´ìœ¼ë¡œë¶€í„° ê³ í’ˆì§ˆ 3D ìì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ê¸° ìœ„í•´ ê²½ëŸ‰í™”ëœ í™•ì‚° ë³€í™˜ê¸° ëª¨ë¸ì„ í™œìš©í•œ í˜ì‹ ì ì¸ ì—­ë°©í–¥ ì ˆì°¨ì  ì½˜í…ì¸  ìƒì„± ë°©ë²•ë¡ ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/cover.png"/></item><item><title>Fietje: An open, efficient LLM for Dutch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</guid><description>Fietje: ì˜¤í”ˆì†ŒìŠ¤ ì†Œí˜• ë„¤ëœë€ë“œì–´ LLM ê³µê°œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/cover.png"/></item><item><title>Flowing from Words to Pixels: A Framework for Cross-Modality Evolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</guid><description>CrossFlow: ëª¨ë‹¬ë¦¬í‹° ê°„ ì§ì ‘ì  ë³€í™˜ ê°€ëŠ¥í•œ í˜ì‹ ì  í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/cover.png"/></item><item><title>How to Synthesize Text Data without Model Collapse?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</guid><description>í•©ì„± ë°ì´í„° ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ í•™ìŠµì˜ ë¶•ê´´ ë¬¸ì œ í•´ê²°: í† í° í¸ì§‘ ê¸°ë²• ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/cover.png"/></item><item><title>IDOL: Instant Photorealistic 3D Human Creation from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</guid><description>ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì´ˆê³ ì†, ê³ í’ˆì§ˆ, ì• ë‹ˆë©”ì´ì…˜ ê°€ëŠ¥í•œ 3D ì•„ë°”íƒ€ë¥¼ ìƒì„±í•˜ëŠ” IDOL ëª¨ë¸ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/cover.png"/></item><item><title>LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</guid><description>LeviTor: ì‚¬ìš©ìì˜ ê°„í¸í•œ 3D ê¶¤ì  ì…ë ¥ë§Œìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ë¹„ë””ì˜¤ í•©ì„±ì´ ê°€ëŠ¥í•œ í˜ì‹ ì ì¸ ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/cover.png"/></item><item><title>LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</guid><description>M-ALERTëŠ” ë‹¤êµ­ì–´ LLMì˜ ì•ˆì „ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ì˜ì–´, í”„ë‘ìŠ¤ì–´, ë…ì¼ì–´, ì´íƒˆë¦¬ì•„ì–´, ìŠ¤í˜ì¸ì–´ 5ê°œ ì–¸ì–´ì˜ 75,000ê°œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•˜ë©°, ë‹¤ì–‘í•œ ì–¸ì–´ ë° ë²”ì£¼ì—ì„œ LLMì˜ ì•ˆì „ì„± ë¶ˆì¼ì¹˜ë¥¼ ë°í˜€ëƒˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/cover.png"/></item><item><title>MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</guid><description>MegaPairsëŠ” VLMê³¼ ê³µê°œ ë„ë©”ì¸ ì´ë¯¸ì§€ë¥¼ í™œìš©, 2600ë§Œ ê°œ ì´ìƒì˜ ê³ í’ˆì§ˆ ë‹¤ì¤‘ ëª¨ë‹¬ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ë²”ìš© ë‹¤ì¤‘ ëª¨ë‹¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/cover.png"/></item><item><title>MixLLM: LLM Quantization with Global Mixed-precision between Output-features and Highly-efficient System Design</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</guid><description>MixLLM: ì¶œë ¥ íŠ¹ì§• ê°„ì˜ ì „ì—­ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”ì™€ ê³ íš¨ìœ¨ ì‹œìŠ¤í…œ ì„¤ê³„ë¥¼ í†µí•´ LLMì˜ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚¤ëŠ” íšê¸°ì ì¸ ì–‘ìí™” ë°©ë²•</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/cover.png"/></item><item><title>Outcome-Refining Process Supervision for Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</guid><description>ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ì´ í•„ìš”í•œ ì½”ë“œ ìƒì„± ê³¼ì œì—ì„œ ê¸°ì¡´ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ , Outcome-Refining Process Supervision (ORPS) ì œì‹œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/cover.png"/></item><item><title>Parallelized Autoregressive Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</guid><description>ë³¸ ì—°êµ¬ëŠ” í† í° ì˜ì¡´ì„±ì„ ê³ ë ¤í•œ ë³‘ë ¬í™” ì „ëµì„ í†µí•´ ìë™ íšŒê·€ ì‹œê°ì  ìƒì„±ì˜ ì†ë„ë¥¼ ìµœëŒ€ 9.5ë°°ê¹Œì§€ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/cover.png"/></item><item><title>Progressive Multimodal Reasoning via Active Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</guid><description>AR-MCTS: ëŠ¥ë™ì  ê²€ìƒ‰ê³¼ ëª¬í…Œ ì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰ìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  í–¥ìƒ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/cover.png"/></item><item><title>ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</guid><description>ReLU ë¼ìš°íŒ…ì„ ì‚¬ìš©í•˜ëŠ” ì™„ì „ ë¯¸ë¶„ ê°€ëŠ¥í•œ MoE ì•„í‚¤í…ì²˜ ReMoEë¥¼ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì„ íšê¸°ì ìœ¼ë¡œ ê°œì„ í–ˆìŠµë‹ˆë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/cover.png"/></item><item><title>RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</guid><description>ROBUSTFTëŠ” ì¡ìŒì´ í¬í•¨ëœ ì‘ë‹µ ì•„ë˜ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê°•ê±´í•œ ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ì¡ìŒ ê°ì§€ ë° ì¬ë¼ë²¨ë§ì„ í†µí•´ í•˜ë¥˜ ì‘ì—… ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/cover.png"/></item><item><title>Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</guid><description>ê³ í’ˆì§ˆ ë¹„ë””ì˜¤-ì˜¤ë””ì˜¤ í•©ì„±ì„ ìœ„í•œ í˜ì‹ ì ì¸ ë‹¤ì¤‘ ëª¨ë“œ ì¡°ì¸íŠ¸ í•™ìŠµ í”„ë ˆì„ì›Œí¬ MMAudio ì œì•ˆ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/cover.png"/></item><item><title>TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</guid><description>TOMG-Bench: LLM ê¸°ë°˜ ì˜¤í”ˆ ë¶„ì ìƒì„± ë²¤ì¹˜ë§ˆí¬ ì œì‹œ! 25ê°œ LLM í‰ê°€ ë° ìƒˆë¡œìš´ instruction tuning ë°ì´í„°ì…‹ OpenMolIns ê³µê°œë¡œ, ì˜¤í”ˆì†ŒìŠ¤ LLMì˜ ì„±ëŠ¥ í–¥ìƒ ë° ë¶„ì ë°œê²¬ì˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„± ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/cover.png"/></item><item><title>UIP2P: Unsupervised Instruction-based Image Editing via Cycle Edit Consistency</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</guid><description>ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ ìˆœí™˜ í¸ì§‘ ì¼ê´€ì„±(CEC) í™œìš©, ì§€ì‹œì–´ ê¸°ë°˜ ì´ë¯¸ì§€ í¸ì§‘ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ë‹¤!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/cover.png"/></item><item><title>AniDoc: Animation Creation Made Easier</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</guid><description>AniDoc: í¬ì†Œ ìŠ¤ì¼€ì¹˜ì™€ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í™œìš©, 2D ì• ë‹ˆë©”ì´ì…˜ ìë™ ì±„ìƒ‰ ë° ë³´ê°„ì„ êµ¬í˜„í•˜ëŠ” í˜ì‹ ì  AI ëª¨ë¸!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/cover.png"/></item><item><title>AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</guid><description>AntiLeak-Bench: ìë™í™”ëœ ë²¤ì¹˜ë§ˆí‚¹ìœ¼ë¡œ LLM ë°ì´í„° ì˜¤ì—¼ ë°©ì§€</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/cover.png"/></item><item><title>Autoregressive Video Generation without Vector Quantization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</guid><description>ë²¡í„° ì–‘ìí™” ì—†ì´ë„ íš¨ìœ¨ì ì´ê³  ìœ ì—°í•œ ìê¸°íšŒê·€ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸, NOVA ê°œë°œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/cover.png"/></item><item><title>Descriptive Caption Enhancement with Visual Specialists for Multimodal Perception</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</guid><description>ì‹œê° ì „ë¬¸ê°€ ëª¨ë¸ì„ í™œìš©í•œ ì´ë¯¸ì§€ ìº¡ì…˜ í–¥ìƒìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ </description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/cover.png"/></item><item><title>FashionComposer: Compositional Fashion Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</guid><description>FashionComposer: ë‹¤ì–‘í•œ ì…ë ¥(í…ìŠ¤íŠ¸, ì˜ìƒ ì´ë¯¸ì§€, 3D ëª¨ë¸)ì„ í™œìš©í•´ ì‚¬ì‹¤ì ì¸ íŒ¨ì…˜ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” í˜ì‹ ì ì¸ í”„ë ˆì„ì›Œí¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/cover.png"/></item><item><title>GUI Agents: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</guid><description>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ GUI ì—ì´ì „íŠ¸ ê¸°ìˆ ì˜ ìµœì‹  ë™í–¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ë²¤ì¹˜ë§ˆí¬, í‰ê°€ ì§€í‘œ, ì•„í‚¤í…ì²˜, í•™ìŠµ ë°©ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.</description></item><item><title>LLaVA-UHD v2: an MLLM Integrating High-Resolution Feature Pyramid via Hierarchical Window Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</guid><description>LLaVA-UHD v2ëŠ” ê³„ì¸µì  ìœˆë„ìš° ë³€í™˜ê¸°ë¥¼ ì´ìš©, ê³ í•´ìƒë„ íŠ¹ì§• í”¼ë¼ë¯¸ë“œë¥¼ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œê°ì  ì„¸ë¶€ ì •ë³´ë¥¼ í¬ì°©í•˜ëŠ” í˜ì‹ ì ì¸ ë‹¤ì¤‘ ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/cover.png"/></item><item><title>PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</guid><description>PixelManì€ í”½ì…€ ì¡°ì‘ ë° ìƒì„±ì„ í†µí•´ í›ˆë ¨ ì—†ì´ë„ ì¼ê´€ì„± ìˆëŠ” ê°ì²´ í¸ì§‘ì„ 16ë‹¨ê³„ ë§Œì— ë‹¬ì„±í•˜ëŠ” í˜ì‹ ì ì¸ í™•ì‚° ëª¨ë¸ ê¸°ë°˜ ë°©ë²•ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/cover.png"/></item><item><title>Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</guid><description>ì €ë ´í•œ ë¼ì´ë‹¤ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•œ 4K ê³ í•´ìƒë„ ì •í™•í•œ ê³„ëŸ‰ì  ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„, Prompt Depth Anything ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/cover.png"/></item><item><title>RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</guid><description>RAG-RewardBench: RAG í™˜ê²½ì—ì„œ ë³´ìƒ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ ìµœì´ˆì˜ ë²¤ì¹˜ë§ˆí¬ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/cover.png"/></item><item><title>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</guid><description>ModernBERT: ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸ ë¯¸ì„¸ ì¡°ì • ë° ì¶”ë¡ ì„ ìœ„í•œ ìµœì²¨ë‹¨ ì–‘ë°©í–¥ ì¸ì½”ë”!</description></item><item><title>TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</guid><description>TheAgentCompany ë²¤ì¹˜ë§ˆí¬ëŠ” ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ í™˜ê²½ì„ ëª¨ë°©í•˜ì—¬ LLM ì—ì´ì „íŠ¸ì˜ ì‹¤ì œ ì—…ë¬´ ìˆ˜í–‰ ëŠ¥ë ¥ì„ í‰ê°€í•˜ë©°, AI ì—ì´ì „íŠ¸ì˜ í˜„ì‹¤ ì„¸ê³„ ì ìš© ê°€ëŠ¥ì„±ê³¼ í•œê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/cover.png"/></item><item><title>Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</guid><description>MLLMì˜ ì‹œê°-ê³µê°„ ì§€ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ëŠ” ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ VSI-Bench ë°œí‘œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/cover.png"/></item><item><title>ChatDiT: A Training-Free Baseline for Task-Agnostic Free-Form Chatting with Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</guid><description>ChatDiT: ì œë¡œìƒ· ë°©ì‹ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨ëœ í™•ì‚° ë³€í™˜ê¸°ë¥¼ í™œìš©, ìì—°ì–´ë¡œ ë‹¤ì–‘í•œ ì‹œê°ì  ê³¼ì œ í•´ê²°!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/cover.png"/></item><item><title>DateLogicQA: Benchmarking Temporal Biases in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</guid><description>DateLogicQA: LLMì˜ ì‹œê°„ì  ì¶”ë¡  í¸í–¥ ë²¤ì¹˜ë§ˆí¬ ì œì‹œ! í† í°í™”, í‘œìƒ ë° ë…¼ë¦¬ ìˆ˜ì¤€ í¸í–¥ ë¶„ì„ìœ¼ë¡œ ì‹œê°„ì  ë°ì´í„° ì²˜ë¦¬ ê°œì„  ë°©ì•ˆ ì œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/cover.png"/></item><item><title>Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</guid><description>MoDE: íš¨ìœ¨ì ì¸ ë‹¤ì¤‘ ì‘ì—… í•™ìŠµì„ ìœ„í•œ ì „ë¬¸ê°€ í˜¼í•© ì¡ìŒ ì œê±°ê¸°ë¥¼ ì‚¬ìš©í•œ í™•ì‚° íŠ¸ëœìŠ¤í¬ë¨¸ ì •ì±…</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/cover.png"/></item><item><title>Move-in-2D: 2D-Conditioned Human Motion Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</guid><description>Move-in-2D: 2D ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ í˜„ì‹¤ì ì¸ ì¸ê°„ ë™ì‘ ìƒì„±</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/cover.png"/></item><item><title>VidTok: A Versatile and Open-Source Video Tokenizer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</guid><description>VidTok: ì˜¤í”ˆì†ŒìŠ¤ ê³ ì„±ëŠ¥ ë¹„ë””ì˜¤ í† í¬ë‚˜ì´ì €ê°€ ì—°ì† ë° ì´ì‚° í† í°í™”ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, íš¨ìœ¨ì ì¸ í•™ìŠµ ì „ëµê³¼ í˜ì‹ ì ì¸ ì–‘ìí™” ê¸°ë²•ì„ í†µí•´ ì˜ìƒ ìƒì„± ë° ì´í•´ ì—°êµ¬ì— ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/cover.png"/></item><item><title>Causal Diffusion Transformers for Generative Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</guid><description>CausalFusionì€ í™•ì‚° ë° ìê¸° íšŒê·€ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ìƒì„± ëª¨ë¸ë§ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ê³  ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/cover.png"/></item><item><title>ColorFlow: Retrieval-Augmented Image Sequence Colorization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</guid><description>ë§Œí™” ì±„ìƒ‰ ìë™í™”: ColorFlowëŠ” ID ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œ í‘ë°± ë§Œí™” ì‹œí€€ìŠ¤ë¥¼ ì±„ìƒ‰í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/cover.png"/></item><item><title>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</guid><description>GeoX: MLLMë³´ë‹¤ ë›°ì–´ë‚œ ê¸°í•˜í•™ì  ë¬¸ì œ í•´ê²°ì‚¬!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/cover.png"/></item><item><title>IDArb: Intrinsic Decomposition for Arbitrary Number of Input Views and Illuminations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</guid><description>IDArb: Decomposition under varied lights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/cover.png"/></item><item><title>Just a Simple Transformation is Enough for Data Protection in Vertical Federated Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</guid><description>ê°„ë‹¨í•œ ë³€í™˜ë§Œìœ¼ë¡œ ìˆ˜ì§ ì—°í•© í•™ìŠµì—ì„œ ë°ì´í„° ë³´í˜¸ ê°€ëŠ¥.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/cover.png"/></item><item><title>MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</guid><description>ì •ë³´ ì´ë“ìœ¼ë¡œ ê°•í™” í•™ìŠµ íƒìƒ‰ì„ ê°•í™”.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/cover.png"/></item><item><title>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</guid><description>MOVISëŠ” ì‹¤ë‚´ ì¥ë©´ì— ëŒ€í•œ ë©€í‹°-ê°ì²´ novel view synthesisì—ì„œ êµ¬ì¡°ì  ì¸ì‹ì„ í–¥ìƒì‹œì¼œ ì¼ê´€ì„± ìˆê³  ì‚¬ì‹¤ì ì¸ novel viewë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/cover.png"/></item><item><title>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</guid><description>ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ë³´í˜¸, ë”¥í˜ì´í¬ ëŒ€ë¹„ì±….</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/cover.png"/></item><item><title>RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</guid><description>RetroLLM: ê²€ìƒ‰ê³¼ ìƒì„±ì„ í†µí•©í•œ RAG ì‹œìŠ¤í…œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/cover.png"/></item><item><title>SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</guid><description>SepLLMì€ íŠ¹ìˆ˜ í† í°ì˜ ì¤‘ìš”ì„±ì„ í™œìš©í•˜ì—¬ LLM ì¶”ë¡ ì„ ê°€ì†í™”í•˜ê³  ê¸´ ì‹œí€€ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/cover.png"/></item><item><title>Sequence Matters: Harnessing Video Models in 3D Super-Resolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</guid><description>ë¹„ë””ì˜¤ ì´ˆí•´ìƒë„ ëª¨ë¸ì„ ì´ìš©í•œ í˜ì‹ ì ì¸ 3D ì´ˆí•´ìƒë„ ê¸°ë²•ìœ¼ë¡œ, ì •ë ¬ ê³¼ì • ì—†ì´ë„ ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/cover.png"/></item><item><title>SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</guid><description>Self-play with refinement boosts instruction-following in LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/cover.png"/></item><item><title>StrandHead: Text to Strand-Disentangled 3D Head Avatars Using Hair Geometric Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</guid><description>&amp;rsquo;&amp;rsquo; StrandHead: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ 3D í—¤ë“œ ì•„ë°”íƒ€ì™€ ì„¬ì„¸í•œ í—¤ì–´ìŠ¤íƒ€ì¼ê¹Œì§€ ìƒì„±.''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/cover.png"/></item><item><title>The Open Source Advantage in Large Language Models (LLMs)</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</guid><description>ì˜¤í”ˆì†ŒìŠ¤ LLM, íì‡„í˜• LLM ëŒ€ë¹„ íˆ¬ëª…ì„±ê³¼ ì ‘ê·¼ì„±ì€ ë†’ì§€ë§Œ, ì„±ëŠ¥ì€ ë‚®ìŒ. í•˜ì´ë¸Œë¦¬ë“œ ì „ëµì´ ë¯¸ë˜.</description></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT: í•˜ì´ë¸Œë¦¬ë“œ ìŒì„± ë° ìŒì•… LLMìœ¼ë¡œ, ì—°ì† ì˜¤ë””ì˜¤ì™€ ì´ì‚° í† í°ì„ ê²°í•©í•˜ì—¬ í–¥ìƒëœ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item><item><title>Wonderland: Navigating 3D Scenes from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</guid><description>ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ ê³ í’ˆì§ˆ 3D ì¥ë©´ì„ ìƒì„±í•˜ëŠ” íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/cover.png"/></item><item><title>DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</guid><description>DynamicScalerëŠ” í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ì—ì„œ ê¸´ &lt;strong>ëŠê¹€ ì—†ëŠ” íŒŒë…¸ë¼ë§ˆ ë¹„ë””ì˜¤&lt;/strong>ë¥¼ ìƒì„±í•˜ë©°, &lt;strong>í•´ìƒë„ì™€ ì¢…íš¡ë¹„ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ ì›€ì§ì„ì„ ìœ ì§€&lt;/strong>í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/cover.png"/></item><item><title>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</guid><description>GaussianPropertyëŠ” LMMì„ ì‚¬ìš©í•˜ì—¬ 3D ê°€ìš°ì‹œì•ˆì— ë¬¼ë¦¬ì  ì†ì„±ì„ í†µí•©í•˜ëŠ” í›ˆë ¨ ì—†ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ, ë¬¼ë¦¬ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ë° ë¡œë´‡ ì¥ê¸°ì™€ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"/></item><item><title>Reliable, Reproducible, and Really Fast Leaderboards with Evalica</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</guid><description>Evalica: ë²¤ì¹˜ë§ˆí‚¹ì„ ì‰½ê³  ë¹ ë¥´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” íˆ´í‚·</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/cover.png"/></item><item><title>Smaller Language Models Are Better Instruction Evolvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</guid><description>ì†Œí˜• ì–¸ì–´ ëª¨ë¸ì´ ë” ë‚˜ì€ ëª…ë ¹ ìƒì„±ì!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/cover.png"/></item><item><title>VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</guid><description>VividFace: ì²« ë²ˆì§¸ í™•ì‚° ê¸°ë°˜ ë¹„ë””ì˜¤ ì–¼êµ´ ë°”ê¾¸ê¸° í”„ë ˆì„ì›Œí¬ë¡œ ê³ ì¶©ì‹¤ë„ ê²°ê³¼ ì œê³µ.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/cover.png"/></item><item><title>Apollo: An Exploration of Video Understanding in Large Multimodal Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</guid><description>Apollo: ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ë¹„ë””ì˜¤ ì´í•´ë¥¼ ìœ„í•œ ì‹¬ì¸µ íƒêµ¬.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/cover.png"/></item><item><title>BrushEdit: All-In-One Image Inpainting and Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</guid><description>BrushEdit: All-in-One Image Inpainting &amp;amp; Editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/cover.png"/></item><item><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</guid><description>BLT: ë°”ì´íŠ¸ ê¸°ë°˜ LLM, í† í°ë³´ë‹¤ íŒ¨ì¹˜ ìš°ì„ .</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/cover.png"/></item><item><title>Efficient Generative Modeling with Residual Vector Quantization-Based Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</guid><description>ResGen, ê³ í’ˆì§ˆ ìƒì„±ê³¼ ë¹ ë¥¸ ìƒ˜í”Œë§ ì†ë„ë¥¼ ëª¨ë‘ ë‹¬ì„±í•˜ëŠ” íš¨ìœ¨ì ì¸ RVQ ê¸°ë°˜ ìƒì„± ëª¨ë¸.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/cover.png"/></item><item><title>Large Action Models: From Inception to Implementation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</guid><description>LLMì—ì„œ LAMìœ¼ë¡œ: ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” AI ì—ì´ì „íŠ¸ êµ¬ì¶•.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/cover.png"/></item><item><title>LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</guid><description>LinGen: ë¶„ ë‹¨ìœ„ ê³ í•´ìƒë„ í…ìŠ¤íŠ¸-íˆ¬-ë¹„ë””ì˜¤ ìƒì„±, ì„ í˜• ê³„ì‚° ë³µì¡ë„ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/cover.png"/></item><item><title>Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attacks on Breast Ultrasound Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</guid><description>P2P: í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ ìƒˆë¡œìš´ ì ëŒ€ì  ê³µê²©ìœ¼ë¡œ ì˜ë£Œ ì˜ìƒ DNNì˜ ì·¨ì•½ì„± ê³µëµ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/cover.png"/></item><item><title>RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</guid><description>RLDGëŠ” ê°•í™” í•™ìŠµì„ í†µí•´ ìƒì„±ëœ ê³ í’ˆì§ˆ ë°ì´í„°ë¡œ ë²”ìš© ë¡œë´‡ ì •ì±…ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” íšê¸°ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/cover.png"/></item><item><title>SCBench: A KV Cache-Centric Analysis of Long-Context Methods</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</guid><description>SCBenchëŠ” ë©€í‹°í„´ ë° ë©€í‹°ë¦¬í€˜ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¥ë¬¸ ë§¥ë½ ë©”ì„œë“œë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/cover.png"/></item><item><title>SplineGS: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</guid><description>SplineGS: ì‹¤ì‹œê°„ ë™ì  3D ì¥ë©´ì„ ìœ„í•œ ê°•ë ¥í•œ ëª¨ì…˜ ì ì‘í˜• ìŠ¤í”Œë¼ì¸.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/cover.png"/></item><item><title>TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</guid><description>TraceVLA: ê³¼ê±°ì˜ ì›€ì§ì„ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ ë¡œë´‡ì˜ ì‹œê³µê°„ì  ì¸ì‹ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/cover.png"/></item><item><title>FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</guid><description>''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/cover.png"/></item><item><title>FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</guid><description>FreeScaleë¡œ íŠœë‹ ì—†ì´ 8K ì´ë¯¸ì§€ ìƒì„±!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/cover.png"/></item><item><title>GenEx: Generating an Explorable World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</guid><description>GenEx: ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ íƒìƒ‰ ê°€ëŠ¥í•œ 3D ì„¸ê³„ ìƒì„±.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/cover.png"/></item><item><title>GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</guid><description>GREATERëŠ” ì¶”ë¡ ì— ëŒ€í•œ ê·¸ë ˆì´ë””ì–¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì†Œê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•˜ì—¬ ëŒ€ê·œëª¨ LLM ì—†ì´ë„ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/cover.png"/></item><item><title>InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</guid><description>InstanceCap: ì¸ìŠ¤í„´ìŠ¤ ì¸ì‹ êµ¬ì¡°í™” ìº¡ì…˜ì„ í†µí•´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/cover.png"/></item><item><title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</guid><description>InternLM-XComposer2.5-OmniLive: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë¹„ë””ì˜¤ ë° ì˜¤ë””ì˜¤ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì¸ê°„ì˜ ì¸ì§€ëŠ¥ë ¥ì„ ëª¨ë°©í•œ í˜ì‹ ì  ë‹¤ì¤‘ ëª¨ë“œ AI ì‹œìŠ¤í…œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/cover.png"/></item><item><title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</guid><description>VMBëŠ” í…ìŠ¤íŠ¸ ë° ìŒì•… ë¸Œë¦¬ì§€ë¥¼ í™œìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ìŒì•… ìƒì„±ì„ ìœ„í•œ ìƒˆë¡­ê³  ì œì–´ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/cover.png"/></item><item><title>Phi-4 Technical Report</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</guid><description>Phi-4: 140ì–µ ë§¤ê°œë³€ìˆ˜ ì–¸ì–´ ëª¨ë¸ì€ &lt;strong>ë°ì´í„° í’ˆì§ˆì— ì¤‘ì ì„ ë‘” í›ˆë ¨ ë ˆì‹œí”¼&lt;/strong>ë¡œ ê°œë°œë˜ì–´ ì¶”ë¡  ëŠ¥ë ¥ì„ ëŒ€í­ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/cover.png"/></item><item><title>SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</guid><description>SynerGen-VL: ê°„ë‹¨í•œ êµ¬ì¡°ë¡œ ì´ë¯¸ì§€ ì´í•´ ë° ìƒì„±ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” ê°•ë ¥í•œ MLLM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/cover.png"/></item><item><title>ObjectMate: A Recurrence Prior for Object Insertion and Subject-Driven Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</guid><description>ê°ì²´ í•©ì„±ì˜ ìƒˆ ì‹œëŒ€: ObjectMateë¡œ íŠœë‹ ì—†ì´ ì‚¬ì‹¤ì ì¸ ê²°ê³¼ë¥¼ ì–»ìœ¼ì„¸ìš”.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/cover.png"/></item><item><title>SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</guid><description>Smaller language models reason better with fine-tuned training recipes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/cover.png"/></item><item><title>TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</guid><description>TidyBot++: ì €ë¹„ìš©, í™€ë¡œë…¸ë¯¹ ì´ë™ ì¡°ì‘ê¸° &amp;amp; í•¸ë“œí° í…”ë ˆì˜¤í¼ë ˆì´ì…˜ ì¸í„°í˜ì´ìŠ¤ ê³µê°œ</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/cover.png"/></item><item><title>BiMediX2: Bio-Medical EXpert LMM for Diverse Medical Modalities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</guid><description>BiMediX2: ì•„ëì–´-ì˜ì–´ ì´ì¤‘ ì–¸ì–´ ì˜ë£Œ ì „ë¬¸ê°€ LMM ì¶œì‹œ!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/cover.png"/></item><item><title>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</guid><description>Evaluation Agent: ë” ë¹ ë¥´ê³ , ìœ ì—°í•˜ë©°, ì„¤ëª… ê°€ëŠ¥í•œ ì‹œê°ì  ìƒì„± ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/cover.png"/></item><item><title>NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</guid><description>NeuZip dynamically compresses neural network weights, achieving memory-efficient training and inference without performance loss, significantly reducing the memory footprint of large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/cover.png"/></item></channel></rss>