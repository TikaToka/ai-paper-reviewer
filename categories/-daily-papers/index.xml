<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>🤗 Daily Papers on AI Paper Reviews by AI</title><link>https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/</link><description>Recent content in 🤗 Daily Papers on AI Paper Reviews by AI</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviews by AI</copyright><lastBuildDate>Tue, 24 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/ai-paper-reviewer/categories/-daily-papers/index.xml" rel="self" type="application/rss+xml"/><item><title>3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/</guid><description>3DGraphLLM: 의미론적 그래프와 거대 언어 모델을 결합하여 3D 장면 이해 성능을 획기적으로 향상시킨 최첨단 연구!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18450/cover.png"/></item><item><title>DepthLab: From Partial to Complete</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/</guid><description>DepthLab: 부분 깊이 정보로 완전한 3D 시각 정보 복원</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18153/cover.png"/></item><item><title>DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/</guid><description>DiTCtrl: 튜닝 없이 다중 프롬프트로 매끄러운 장시간 비디오 생성</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18597/cover.png"/></item><item><title>PartGen: Part-level 3D Generation and Reconstruction with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/</guid><description>PartGen: 다중 뷰 확산 모델을 이용, 텍스트, 이미지, 기존 3D 객체로부터 의미있는 부분으로 구성된 고품질 3D 객체 생성 및 재구성.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.18608/cover.png"/></item><item><title>B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/</guid><description>B-STAR: 자기 학습 추론자에서 탐색과 활용의 균형을 모니터링하고 조정하여 성능을 향상시키는 새로운 프레임워크</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17256/cover.png"/></item><item><title>Deliberation in Latent Space via Differentiable Cache Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/</guid><description>대규모 언어 모델의 추론 성능을 향상시키는 새로운 방법인 ‘차별 가능한 캐시 증강’ 기법 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17747/cover.png"/></item><item><title>Diving into Self-Evolving Training for Multimodal Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/</guid><description>M-STAR: 다모달 추론을 위한 자기 진화 훈련의 새로운 프레임워크를 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17451/cover.png"/></item><item><title>DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17498/</guid><description>DRT-01 모델은 장문의 사고 과정을 활용하여 문학 번역의 정확도와 유창성을 크게 향상시켰습니다.</description></item><item><title>Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/</guid><description>FoPE: 주파수 영역 특징 개선으로 긴 문맥 길이 일반화 달성!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17739/cover.png"/></item><item><title>Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/</guid><description>Friends-MMC: 방대한 비디오 데이터와 주석을 포함한 새로운 다중 모달 다중 참여 대화 데이터셋을 통해 실제 세계의 대화 이해를 위한 새로운 가능성을 제시합니다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17295/cover.png"/></item><item><title>In Case You Missed It: ARC 'Challenge' Is Not That Challenging</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/</guid><description>기존 다중 선택 문제 평가 방식의 오류를 지적하고, 모든 옵션을 함께 고려하는 새로운 평가 방식을 제안하여 모델 성능 평가의 정확성을 높였습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17758/cover.png"/></item><item><title>Large Motion Video Autoencoding with Cross-modal Video VAE</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/</guid><description>고품질 영상 생성 및 효율적 압축을 위한 혁신적인 크로스 모달 비디오 VAE!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17805/cover.png"/></item><item><title>PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/</guid><description>PC Agent는 인간의 인지 과정을 AI 에 전이하여 복잡한 디지털 작업을 자동화하는 혁신적인 시스템입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17589/cover.png"/></item><item><title>ResearchTown: Simulator of Human Research Community</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/</guid><description>RESEARCHTOWN: LLM 기반 인간 연구 공동체 시뮬레이터로, 다양한 연구 활동을 현실적으로 모방하며 학제 간 연구 아이디어 생성 가능</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17767/cover.png"/></item><item><title>Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/</guid><description>단일 단계 샘플링으로 이미지 자동 회귀 모델 속도를 획기적으로 향상시킨 증류 디코딩(DD) 기법 제안!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.17153/cover.png"/></item><item><title>OpenRFT: Adapting Reasoning Foundation Model for Domain-specific Tasks with Reinforcement Fine-Tuning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/</guid><description>OpenRFT는 제한된 도메인 특정 데이터를 사용하여 일반적인 추론 모델을 미세 조정하는 새로운 방법을 제시합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16849/cover.png"/></item><item><title>Revisiting In-Context Learning with Long Context Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</link><pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/</guid><description>장문 컨텍스트 언어 모델에서 정교한 샘플 선택 전략보다 &lt;strong>무작위 샘플링&lt;/strong>이 ICL 성능 향상에 더 효과적이며, &lt;strong>데이터 증강&lt;/strong>을 통해 저자원 작업 성능을 5% 향상시켰다는 놀라운 연구 결과를 발표!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16926/cover.png"/></item><item><title>LearnLM: Improving Gemini for Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/</guid><description>LearnLM은 교육적 맥락에서 생성형 AI의 페다고지(Pedagogy)를 향상시킨 모델입니다. &lt;strong>교사나 개발자가 원하는 페다고지적 특성을 모델에 주입하는 새로운 프레임워크&lt;/strong>를 통해 기존 모델보다 학습 효과를 31% 향상시켰습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16429/cover.png"/></item><item><title>NILE: Internal Consistency Alignment in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</link><pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/</guid><description>NILE 프레임워크는 LLM의 내부 지식과 IFT 데이터셋의 세계 지식 간 일관성을 높여 LLM 성능을 최대 68.5%까지 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16686/cover.png"/></item><item><title>CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/</guid><description>CLEAR: 선형화된 어텐션으로 고해상도 이미지 생성 속도를 획기적으로 높이다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16112/cover.png"/></item><item><title>Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/</guid><description>대규모 언어 모델들의 앙상블을 통해 복잡한 추론 문제를 더욱 효과적으로 해결하는 새로운 프레임워크, LE-MCTS를 제안합니다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15797/cover.png"/></item><item><title>MotiF: Making Text Count in Image Animation with Motion Focal Loss</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/</guid><description>MotiF: 움직임에 초점을 맞춘 손실 함수로 텍스트 기반 이미지 애니메이션 개선</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.16153/cover.png"/></item><item><title>Multi-LLM Text Summarization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/</guid><description>다수의 거대 언어 모델(LLM)을 활용한 혁신적인 장문 요약 프레임워크가 제시되어 요약 품질을 최대 3배 향상시켰습니다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15487/cover.png"/></item><item><title>Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</link><pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/</guid><description>초정밀 이미지 캡션 생성의 환각 문제 해결을 위해, LLM-MLLM 협업 기반의 다중 에이전트 시스템(CapMAS)을 제안하여 사실성과 포괄성을 높였습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15484/cover.png"/></item><item><title>AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/</guid><description>AceMath는 사전 훈련 및 보상 모델링을 통해 최첨단 수학 추론 능력을 달성한 프런티어급 모델 시리즈입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15084/cover.png"/></item><item><title>Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/</guid><description>Affordance-Aware Object Insertion: 배경과 전경의 상호작용을 고려한 현실적인 이미지 합성 기술!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14462/cover.png"/></item><item><title>AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal Audio-Video Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/</guid><description>AV-Link: 시간 정렬 확산 기능을 통한 크로스 모달 오디오-비디오 생성의 획기적인 발전!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15191/cover.png"/></item><item><title>DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/</guid><description>DI-PCG는 이미지 조건으로부터 고품질 3D 자산을 효율적으로 생성하기 위해 경량화된 확산 변환기 모델을 활용한 혁신적인 역방향 절차적 콘텐츠 생성 방법론입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15200/cover.png"/></item><item><title>Fietje: An open, efficient LLM for Dutch</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/</guid><description>Fietje: 오픈소스 소형 네덜란드어 LLM 공개!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15450/cover.png"/></item><item><title>Flowing from Words to Pixels: A Framework for Cross-Modality Evolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/</guid><description>CrossFlow: 모달리티 간 직접적 변환 가능한 혁신적 프레임워크!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15213/cover.png"/></item><item><title>How to Synthesize Text Data without Model Collapse?</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/</guid><description>합성 데이터 기반 언어 모델 학습의 붕괴 문제 해결: 토큰 편집 기법 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14689/cover.png"/></item><item><title>IDOL: Instant Photorealistic 3D Human Creation from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/</guid><description>단일 이미지에서 초고속, 고품질, 애니메이션 가능한 3D 아바타를 생성하는 IDOL 모델 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14963/cover.png"/></item><item><title>LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/</guid><description>LeviTor: 사용자의 간편한 3D 궤적 입력만으로 사실적인 비디오 합성이 가능한 혁신적인 모델!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15214/cover.png"/></item><item><title>LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/</guid><description>M-ALERT는 다국어 LLM의 안전성을 평가하기 위한 새로운 벤치마크입니다. 영어, 프랑스어, 독일어, 이탈리아어, 스페인어 5개 언어의 75,000개 프롬프트를 포함하며, 다양한 언어 및 범주에서 LLM의 안전성 불일치를 밝혀냈습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15035/cover.png"/></item><item><title>MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/</guid><description>MegaPairs는 VLM과 공개 도메인 이미지를 활용, 2600만 개 이상의 고품질 다중 모달 학습 데이터를 생성하여 범용 다중 모달 검색 성능을 획기적으로 향상시켰습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14475/cover.png"/></item><item><title>MixLLM: LLM Quantization with Global Mixed-precision between Output-features and Highly-efficient System Design</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/</guid><description>MixLLM: 출력 특징 간의 전역 혼합 정밀도 양자화와 고효율 시스템 설계를 통해 LLM의 정확도와 효율성을 동시에 향상시키는 획기적인 양자화 방법</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14590/cover.png"/></item><item><title>Outcome-Refining Process Supervision for Code Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/</guid><description>복잡한 알고리즘 추론이 필요한 코드 생성 과제에서 기존의 한계를 극복하는 새로운 방법론, Outcome-Refining Process Supervision (ORPS) 제시</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15118/cover.png"/></item><item><title>Parallelized Autoregressive Visual Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/</guid><description>본 연구는 토큰 의존성을 고려한 병렬화 전략을 통해 자동 회귀 시각적 생성의 속도를 최대 9.5배까지 향상시켰습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15119/cover.png"/></item><item><title>Progressive Multimodal Reasoning via Active Retrieval</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/</guid><description>AR-MCTS: 능동적 검색과 몬테 카를로 트리 탐색으로 멀티모달 추론 향상</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14835/cover.png"/></item><item><title>ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/</guid><description>ReLU 라우팅을 사용하는 완전 미분 가능한 MoE 아키텍처 ReMoE를 통해 대규모 언어 모델의 확장성과 효율성을 획기적으로 개선했습니다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14711/cover.png"/></item><item><title>RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/</guid><description>ROBUSTFT는 잡음이 포함된 응답 아래에서 대규모 언어 모델의 강건한 지도 학습 미세 조정을 위한 프레임워크로, 잡음 감지 및 재라벨링을 통해 하류 작업 성능을 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14922/cover.png"/></item><item><title>Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/</guid><description>고품질 비디오-오디오 합성을 위한 혁신적인 다중 모드 조인트 학습 프레임워크 MMAudio 제안!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15322/cover.png"/></item><item><title>TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/</guid><description>TOMG-Bench: LLM 기반 오픈 분자 생성 벤치마크 제시! 25개 LLM 평가 및 새로운 instruction tuning 데이터셋 OpenMolIns 공개로, 오픈소스 LLM의 성능 향상 및 분자 발견의 새로운 가능성 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14642/cover.png"/></item><item><title>UIP2P: Unsupervised Instruction-based Image Editing via Cycle Edit Consistency</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</link><pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/</guid><description>비지도 학습 기반 순환 편집 일관성(CEC) 활용, 지시어 기반 이미지 편집의 새로운 지평을 열다!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.15216/cover.png"/></item><item><title>AniDoc: Animation Creation Made Easier</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/</guid><description>AniDoc: 희소 스케치와 참조 이미지를 활용, 2D 애니메이션 자동 채색 및 보간을 구현하는 혁신적 AI 모델!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14173/cover.png"/></item><item><title>AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/</guid><description>AntiLeak-Bench: 자동화된 벤치마킹으로 LLM 데이터 오염 방지</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13670/cover.png"/></item><item><title>Autoregressive Video Generation without Vector Quantization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/</guid><description>벡터 양자화 없이도 효율적이고 유연한 자기회귀 비디오 생성 모델, NOVA 개발!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14169/cover.png"/></item><item><title>Descriptive Caption Enhancement with Visual Specialists for Multimodal Perception</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/</guid><description>시각 전문가 모델을 활용한 이미지 캡션 향상으로 다중 모달 모델 성능 개선</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14233/cover.png"/></item><item><title>FashionComposer: Compositional Fashion Image Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/</guid><description>FashionComposer: 다양한 입력(텍스트, 의상 이미지, 3D 모델)을 활용해 사실적인 패션 이미지를 합성하는 혁신적인 프레임워크!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14168/cover.png"/></item><item><title>GUI Agents: A Survey</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13501/</guid><description>대규모 언어 모델 기반 GUI 에이전트 기술의 최신 동향을 종합적으로 분석하고, 벤치마크, 평가 지표, 아키텍처, 학습 방법을 체계적으로 분류하여 통합 프레임워크를 제시합니다.</description></item><item><title>LLaVA-UHD v2: an MLLM Integrating High-Resolution Feature Pyramid via Hierarchical Window Transformer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/</guid><description>LLaVA-UHD v2는 계층적 윈도우 변환기를 이용, 고해상도 특징 피라미드를 통합하여 다양한 시각적 세부 정보를 포착하는 혁신적인 다중 모달 언어 모델입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13871/cover.png"/></item><item><title>PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/</guid><description>PixelMan은 픽셀 조작 및 생성을 통해 훈련 없이도 일관성 있는 객체 편집을 16단계 만에 달성하는 혁신적인 확산 모델 기반 방법입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14283/cover.png"/></item><item><title>Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/</guid><description>저렴한 라이다 프롬프트를 사용한 4K 고해상도 정확한 계량적 깊이 추정을 위한 새로운 패러다임, Prompt Depth Anything 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14015/cover.png"/></item><item><title>RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/</guid><description>RAG-RewardBench: RAG 환경에서 보상 모델 평가를 위한 최초의 벤치마크 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13746/cover.png"/></item><item><title>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13663/</guid><description>ModernBERT: 빠르고 메모리 효율적인 장문 컨텍스트 미세 조정 및 추론을 위한 최첨단 양방향 인코더!</description></item><item><title>TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/</guid><description>TheAgentCompany 벤치마크는 실제 소프트웨어 회사 환경을 모방하여 LLM 에이전트의 실제 업무 수행 능력을 평가하며, AI 에이전트의 현실 세계 적용 가능성과 한계를 보여줍니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14161/cover.png"/></item><item><title>Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/</guid><description>MLLM의 시각-공간 지능 향상에 도움이 되는 새로운 비디오 기반 벤치마크 VSI-Bench 발표!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.14171/cover.png"/></item><item><title>ChatDiT: A Training-Free Baseline for Task-Agnostic Free-Form Chatting with Diffusion Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/</guid><description>ChatDiT: 제로샷 방식으로 사전 훈련된 확산 변환기를 활용, 자연어로 다양한 시각적 과제 해결!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12571/cover.png"/></item><item><title>DateLogicQA: Benchmarking Temporal Biases in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/</guid><description>DateLogicQA: LLM의 시간적 추론 편향 벤치마크 제시! 토큰화, 표상 및 논리 수준 편향 분석으로 시간적 데이터 처리 개선 방안 제시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13377/cover.png"/></item><item><title>Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/</guid><description>MoDE: 효율적인 다중 작업 학습을 위한 전문가 혼합 잡음 제거기를 사용한 확산 트랜스포머 정책</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12953/cover.png"/></item><item><title>Move-in-2D: 2D-Conditioned Human Motion Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/</guid><description>Move-in-2D: 2D 이미지와 텍스트 프롬프트로 현실적인 인간 동작 생성</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13185/cover.png"/></item><item><title>VidTok: A Versatile and Open-Source Video Tokenizer</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/</guid><description>VidTok: 오픈소스 고성능 비디오 토크나이저가 연속 및 이산 토큰화에서 최첨단 성능을 달성하며, 효율적인 학습 전략과 혁신적인 양자화 기법을 통해 영상 생성 및 이해 연구에 새로운 가능성을 열었습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.13061/cover.png"/></item><item><title>Causal Diffusion Transformers for Generative Modeling</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/</guid><description>CausalFusion은 확산 및 자기 회귀 모델을 결합하여 생성 모델링에서 최첨단 결과를 달성하고 새로운 기능을 가능하게 합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12095/cover.png"/></item><item><title>ColorFlow: Retrieval-Augmented Image Sequence Colorization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/</guid><description>만화 채색 자동화: ColorFlow는 ID 일관성을 유지하면서 흑백 만화 시퀀스를 채색합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11815/cover.png"/></item><item><title>GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/</guid><description>GeoX: MLLM보다 뛰어난 기하학적 문제 해결사!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11863/cover.png"/></item><item><title>IDArb: Intrinsic Decomposition for Arbitrary Number of Input Views and Illuminations</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/</guid><description>IDArb: Decomposition under varied lights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12083/cover.png"/></item><item><title>Just a Simple Transformation is Enough for Data Protection in Vertical Federated Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/</guid><description>간단한 변환만으로 수직 연합 학습에서 데이터 보호 가능.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11689/cover.png"/></item><item><title>MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/</guid><description>정보 이득으로 강화 학습 탐색을 강화.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12098/cover.png"/></item><item><title>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/</guid><description>MOVIS는 실내 장면에 대한 멀티-객체 novel view synthesis에서 구조적 인식을 향상시켜 일관성 있고 사실적인 novel view를 생성합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11457/cover.png"/></item><item><title>Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/</guid><description>실시간 이미지 보호, 딥페이크 대비책.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11423/cover.png"/></item><item><title>RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/</guid><description>RetroLLM: 검색과 생성을 통합한 RAG 시스템</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11919/cover.png"/></item><item><title>SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/</guid><description>SepLLM은 특수 토큰의 중요성을 활용하여 LLM 추론을 가속화하고 긴 시퀀스를 효율적으로 처리합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12094/cover.png"/></item><item><title>Sequence Matters: Harnessing Video Models in 3D Super-Resolution</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/</guid><description>비디오 초해상도 모델을 이용한 혁신적인 3D 초해상도 기법으로, 정렬 과정 없이도 최첨단 성능 달성!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11525/cover.png"/></item><item><title>SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/</guid><description>Self-play with refinement boosts instruction-following in LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11605/cover.png"/></item><item><title>StrandHead: Text to Strand-Disentangled 3D Head Avatars Using Hair Geometric Priors</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/</guid><description>&amp;rsquo;&amp;rsquo; StrandHead: 텍스트만으로 사실적인 3D 헤드 아바타와 섬세한 헤어스타일까지 생성.''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11586/cover.png"/></item><item><title>The Open Source Advantage in Large Language Models (LLMs)</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12004/</guid><description>오픈소스 LLM, 폐쇄형 LLM 대비 투명성과 접근성은 높지만, 성능은 낮음. 하이브리드 전략이 미래.</description></item><item><title>Whisper-GPT: A Hybrid Representation Audio Large Language Model</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/</guid><description>Whisper-GPT: 하이브리드 음성 및 음악 LLM으로, 연속 오디오와 이산 토큰을 결합하여 향상된 성능을 제공합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11449/cover.png"/></item><item><title>Wonderland: Navigating 3D Scenes from a Single Image</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/</guid><description>단일 이미지로 고품질 3D 장면을 생성하는 효율적이고 확장 가능한 프레임워크</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.12091/cover.png"/></item><item><title>DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/</guid><description>DynamicScaler는 텍스트나 이미지에서 긴 &lt;strong>끊김 없는 파노라마 비디오&lt;/strong>를 생성하며, &lt;strong>해상도와 종횡비에 관계없이 일관된 움직임을 유지&lt;/strong>합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11100/cover.png"/></item><item><title>GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/</guid><description>GaussianProperty는 LMM을 사용하여 3D 가우시안에 물리적 속성을 통합하는 훈련 없는 프레임워크로, 물리 기반 시뮬레이션 및 로봇 쥐기와 같은 다운스트림 작업을 가능하게 합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11258/cover.png"/></item><item><title>Reliable, Reproducible, and Really Fast Leaderboards with Evalica</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/</guid><description>Evalica: 벤치마킹을 쉽고 빠르고 신뢰할 수 있게 만드는 툴킷</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11314/cover.png"/></item><item><title>Smaller Language Models Are Better Instruction Evolvers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/</guid><description>소형 언어 모델이 더 나은 명령 생성자!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11231/cover.png"/></item><item><title>VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</link><pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/</guid><description>VividFace: 첫 번째 확산 기반 비디오 얼굴 바꾸기 프레임워크로 고충실도 결과 제공.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.11279/cover.png"/></item><item><title>Apollo: An Exploration of Video Understanding in Large Multimodal Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/</guid><description>Apollo: 대규모 멀티모달 모델의 비디오 이해를 위한 심층 탐구.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10360/cover.png"/></item><item><title>BrushEdit: All-In-One Image Inpainting and Editing</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/</guid><description>BrushEdit: All-in-One Image Inpainting &amp;amp; Editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10316/cover.png"/></item><item><title>Byte Latent Transformer: Patches Scale Better Than Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/</guid><description>BLT: 바이트 기반 LLM, 토큰보다 패치 우선.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09871/cover.png"/></item><item><title>Efficient Generative Modeling with Residual Vector Quantization-Based Tokens</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/</guid><description>ResGen, 고품질 생성과 빠른 샘플링 속도를 모두 달성하는 효율적인 RVQ 기반 생성 모델.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10208/cover.png"/></item><item><title>Large Action Models: From Inception to Implementation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/</guid><description>LLM에서 LAM으로: 실제 작업을 수행하는 AI 에이전트 구축.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10047/cover.png"/></item><item><title>LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/</guid><description>LinGen: 분 단위 고해상도 텍스트-투-비디오 생성, 선형 계산 복잡도로 효율성 극대화</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09856/cover.png"/></item><item><title>Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attacks on Breast Ultrasound Images</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/</guid><description>P2P: 텍스트 기반의 새로운 적대적 공격으로 의료 영상 DNN의 취약성 공략</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09910/cover.png"/></item><item><title>RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/</guid><description>RLDG는 강화 학습을 통해 생성된 고품질 데이터로 범용 로봇 정책의 성능을 향상시키는 획기적인 방법입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09858/cover.png"/></item><item><title>SCBench: A KV Cache-Centric Analysis of Long-Context Methods</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/</guid><description>SCBench는 멀티턴 및 멀티리퀘스트 시나리오에서 장문 맥락 메서드를 평가하는 새로운 벤치마크입니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10319/cover.png"/></item><item><title>SplineGS: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/</guid><description>SplineGS: 실시간 동적 3D 장면을 위한 강력한 모션 적응형 스플라인.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09982/cover.png"/></item><item><title>TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/</guid><description>TraceVLA: 과거의 움직임을 시각적으로 보여줌으로써 로봇의 시공간적 인식을 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10345/cover.png"/></item><item><title>FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/</guid><description>''</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09611/cover.png"/></item><item><title>FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/</guid><description>FreeScale로 튜닝 없이 8K 이미지 생성!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09626/cover.png"/></item><item><title>GenEx: Generating an Explorable World</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/</guid><description>GenEx: 단일 이미지로 탐색 가능한 3D 세계 생성.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09624/cover.png"/></item><item><title>GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/</guid><description>GREATER는 추론에 대한 그레이디언트를 활용하여 소규모 언어 모델의 프롬프트를 최적화하여 대규모 LLM 없이도 성능을 향상시킵니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09722/cover.png"/></item><item><title>InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/</guid><description>InstanceCap: 인스턴스 인식 구조화 캡션을 통해 텍스트-비디오 생성을 개선합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09283/cover.png"/></item><item><title>InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/</guid><description>InternLM-XComposer2.5-OmniLive: 실시간 스트리밍 비디오 및 오디오 상호작용을 위한 인간의 인지능력을 모방한 혁신적 다중 모드 AI 시스템</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09596/cover.png"/></item><item><title>Multimodal Music Generation with Explicit Bridges and Retrieval Augmentation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/</guid><description>VMB는 텍스트 및 음악 브리지를 활용하여 멀티모달 음악 생성을 위한 새롭고 제어 가능한 프레임워크를 제시합니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09428/cover.png"/></item><item><title>Phi-4 Technical Report</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/</guid><description>Phi-4: 140억 매개변수 언어 모델은 &lt;strong>데이터 품질에 중점을 둔 훈련 레시피&lt;/strong>로 개발되어 추론 능력을 대폭 향상시켰습니다.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08905/cover.png"/></item><item><title>SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/</guid><description>SynerGen-VL: 간단한 구조로 이미지 이해 및 생성을 동시에 수행하는 강력한 MLLM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09604/cover.png"/></item><item><title>ObjectMate: A Recurrence Prior for Object Insertion and Subject-Driven Generation</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/</guid><description>객체 합성의 새 시대: ObjectMate로 튜닝 없이 사실적인 결과를 얻으세요.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08645/cover.png"/></item><item><title>SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/</guid><description>Smaller language models reason better with fine-tuned training recipes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.08347/cover.png"/></item><item><title>TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/</guid><description>TidyBot++: 저비용, 홀로노믹 이동 조작기 &amp;amp; 핸드폰 텔레오퍼레이션 인터페이스 공개</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.10447/cover.png"/></item><item><title>BiMediX2: Bio-Medical EXpert LMM for Diverse Medical Modalities</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/</guid><description>BiMediX2: 아랍어-영어 이중 언어 의료 전문가 LMM 출시!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.07769/cover.png"/></item><item><title>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</link><pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/</guid><description>Evaluation Agent: 더 빠르고, 유연하며, 설명 가능한 시각적 생성 모델 평가 프레임워크.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2412.09645/cover.png"/></item><item><title>NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks</title><link>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/</guid><description>NeuZip dynamically compresses neural network weights, achieving memory-efficient training and inference without performance loss, significantly reducing the memory footprint of large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/ai-paper-reviewer/paper-reviews/2410.20650/cover.png"/></item></channel></rss>